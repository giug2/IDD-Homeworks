<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.05807] Federated Learning Empowered by Generative Content</title><meta property="og:description" content="Federated learning (FL) enables leveraging distributed private data for model training in a privacy-preserving way.
However, data heterogeneity significantly limits the performance of current FL methods.
In this paper,…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning Empowered by Generative Content">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning Empowered by Generative Content">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.05807">

<!--Generated on Tue Feb 27 14:48:58 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning Empowered by 
<br class="ltx_break">Generative Content</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rui Ye<sup id="id1.1.id1" class="ltx_sup">1</sup>, Xinyu Zhu<sup id="id2.2.id2" class="ltx_sup">1</sup>, Jingyi Chai<sup id="id3.3.id3" class="ltx_sup">1</sup>, Siheng Chen<sup id="id4.4.id4" class="ltx_sup">1,2🖂</sup>, Yanfeng Wang<sup id="id5.5.id5" class="ltx_sup">2,1</sup> 
<br class="ltx_break"><sup id="id6.6.id6" class="ltx_sup">1</sup>Shanghai Jiao Tong University, <sup id="id7.7.id7" class="ltx_sup">2</sup>Shanghai AI Laboratory 
<br class="ltx_break"><span id="id8.8.id8" class="ltx_text ltx_font_typewriter">{yr991129,zhuxinyu,chaijingyi,sihengc,wangyanfeng}@sjtu.edu.cn</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Federated learning (FL) enables leveraging distributed private data for model training in a privacy-preserving way.
However, data heterogeneity significantly limits the performance of current FL methods.
In this paper, we propose a novel FL framework termed FedGC, designed to mitigate data heterogeneity issues by diversifying private data with generative content.
FedGC is a simple-to-implement framework as it only introduces a one-shot step of data generation.
In data generation, we summarize three crucial and worth-exploring aspects (budget allocation, prompt design, and generation guidance) and propose three solution candidates for each aspect.
Specifically, to achieve a better trade-off between data diversity and fidelity for generation guidance, we propose to generate data based on the guidance of prompts and real data simultaneously.
The generated data is then merged with private data to facilitate local model training.
Such generative data increases the diversity of private data to prevent each client from fitting the potentially biased private data, alleviating the issue of data heterogeneity.
We conduct a systematic empirical study on FedGC, covering diverse baselines, datasets, scenarios, and modalities.
Interesting findings include (1) FedGC consistently and significantly enhances the performance of FL methods, even when notable disparities exist between generative and private data;
(2) FedGC achieves both better performance and privacy-preservation.
We wish this work can inspire future works to further explore the potential of enhancing FL with generative content.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) is a privacy-preserving machine learning paradigm that enables multiple clients to collaboratively train a global model without directly sharing their raw data <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib24" title="" class="ltx_ref">2017</a>; Kairouz et al., <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>. With the increasing concerns about privacy, FL has attracted significant attention and has been applied to diverse real-world fields such as natural language processing, healthcare, finance, Internet of Things (IoT), and autonomous vehicles <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Data heterogeneity presents a prominent and fundamental challenge in FL, significantly impacting FL’s overall performance <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib24" title="" class="ltx_ref">2017</a>; Hsu et al., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>. This heterogeneity arises inherently due to the varied environments and preferences in which clients’ datasets are collected. Consequently, it results in biased and divergent local models, posing difficulties in achieving a well-generalized aggregated model capable of effectively addressing diverse data sources.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Addressing this issue, many optimization-based works are proposed from diverse perspectives <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite>.
On the client side, they regularize the distance between local and global model <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib22" title="" class="ltx_ref">2020b</a>; Acar et al., <a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite>, introduce control variates to correct local gradients <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, align the feature space <cite class="ltx_cite ltx_citemacro_citep">(Ye et al., <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Li et al., <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.
On the server side, they introduce momentum to update global model <cite class="ltx_cite ltx_citemacro_citep">(Reddi et al., <a href="#bib.bib32" title="" class="ltx_ref">2020</a>; Hsu et al., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, adjust the process of aggregating local models <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2020b</a>; Jhunjhunwala et al., <a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite>, modify model initialization <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Chen et al., <a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite>.
However, the performance of all these methods is still severely limited as data heterogeneity fundamentally exists.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose a new idea of fundamentally mitigating the effects of data heterogeneity with the help of diverse generative content.
To realize this idea, we propose a novel framework, Federated Learning with Generative Content (FedGC).
In FedGC, each client uses a publicly available generative model conditioned on task-related prompts to generate diverse data, which supplements the originally client-specific (the root of data heterogeneity) data.
The supplemented dataset can subsequently facilitate client model training by encouraging the local model to also learn diverse patterns rather than only patterns of its private data.
Despite the simplicity, FedGC can significantly mitigate data heterogeneity as generative diverse data introduces informative and general patterns, thus preventing each client from over-fitting its potentially biased private data.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">Furthermore, FedGC is a flexible framework with multiple potential directions.
Considering generation efficiency, data diversity, and data fidelity, we summarize four critical aspects in FedGC, including budget allocation, prompt design, generation guidance, and training strategy.
In each aspect, we propose three representative solutions as candidates.
For example, to achieve a better trade-off between diversity and fidelity during generation, we propose real-data-guidance which generates data conditioned on real data and task-related prompts simultaneously.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">To prove the effectiveness of FedGC and deepen understanding, we conduct a systematic empirical study from diverse perspectives, including compatibility with FL baselines, different datasets, different modalities, and different data heterogeneity types; and have several interesting findings.
1) Adding generative data is a more direct, concise, and effective solution to tackle data heterogeneity, than many sophisticated algorithm designs.
2) FedGC can achieve both better privacy preservation and performance.
3) Despite failing to resemble real data, generative data still contributes to enhanced performance as it can implicitly reduce data heterogeneity and model divergence.</p>
</div>
<div id="S1.p7" class="ltx_para ltx_noindent">
<p id="S1.p7.1" class="ltx_p">Our contributions are as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose FedGC, a new, simple yet effective FL framework that handles data heterogeneity from a new perspective: generating diverse data to supplement private real data.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We summarize four critical and worth-exploring facets in FedGC and propose three solution candidates for each, underscoring its flexibility and potential for future explorations.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i3.p1.1" class="ltx_p">We provide a systematic empirical study on FedGC framework, showing its effectiveness for tackling data heterogeneity and providing new insights for future works through several interesting experimental findings.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Federated learning</span> (FL) enables multiple clients to collaboratively train a global model without sharing raw data <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite>, which has attracted much attention due to its privacy-preserving property <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib21" title="" class="ltx_ref">2020a</a>; Kairouz et al., <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>.
Data heterogeneity is one representative challenge in FL that significantly limits the FL’s performance <cite class="ltx_cite ltx_citemacro_citep">(Hsu et al., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>; Li et al., <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>.
Addressing this, many methods are proposed to mitigate its adverse effects from the perspective of optimization.
(1) On client-side optimization, FedProx <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib22" title="" class="ltx_ref">2020b</a>)</cite> and SCAFFOLD <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite> propose to conduct model-level correction such as regularizing <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S2.p1.1.m1.1a"><msub id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">ℓ</mi><mn id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\ell_{2}</annotation></semantics></math> distance between local and global model and introducing a control variate to correct gradient of local model.
MOON <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> and FedDecorr <cite class="ltx_cite ltx_citemacro_citep">(Shi et al., <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite> propose to regularize feature space.
(2) On server-side optimization, FedNova <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2020b</a>)</cite> and FedDisco <cite class="ltx_cite ltx_citemacro_citep">(Ye et al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite> propose to modify aggregation weights to obtain better-aggregated model.
<cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Chen et al., <a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite> explore the effects of model initialization.
FedAvgM <cite class="ltx_cite ltx_citemacro_citep">(Hsu et al., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite> and FedOPT <cite class="ltx_cite ltx_citemacro_citep">(Reddi et al., <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> apply momentum-based optimization to improve global model updating.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">Unlike these optimization-level methods that still fundamentally suffer from data heterogeneity, our FedGC framework focuses on data-level improvement, which mitigates heterogeneity of the distributed real data by complementing it with diverse generative data.
Besides, our FedGC framework is orthogonal to these methods, allowing seamless integration within our framework.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Generative models</span> have demonstrated remarkable performance across multiple domains such as large language models <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a href="#bib.bib28" title="" class="ltx_ref">2022</a>; OpenAI, <a href="#bib.bib27" title="" class="ltx_ref">2023</a>; Touvron et al., <a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite> for language generation and diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Nichol et al., <a href="#bib.bib26" title="" class="ltx_ref">2022</a>; Rombach et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Saharia et al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> for image generation.
Though these models can generate high-quality data for general cases, the generated data is not sufficient to train a well-perform model due to its incapability of representing real data <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, especially for uncommon cases such as medical tasks <cite class="ltx_cite ltx_citemacro_citep">(Eysenbach et al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>; Celard et al., <a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite>.
Recently, <cite class="ltx_cite ltx_citemacro_citep">(Shipard et al., <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite> shows the importance of data diversity for zero-shot image classification tasks.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">In this paper, we systematically explore the potential of using generative models to assist FL on private data. Based on our FedGC framework, we verify that despite failing to fully represent real data, generated data can still contribute to improving the performance of FL under heterogeneous private data. Besides, FedGC is applicable to both image and text regimes.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Learning with Generative Content</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">We propose FedGC, a new FL framework that leverages generative content to tackle the issue of data heterogeneity in FL.
Based on FedGC, we summarize four aspects worth exploring and propose three methods for each aspect, which serves to provide more insights for future works.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>FedGC Framework Overview</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">Our FedGC follows the standard FedAvg framework, encompassing of four iterative phases: global model broadcasting, local model training, local model uploading, and global model aggregation.
Our goal is to generate diverse data to supplement private data to facilitate local model training.
Considering communication cost and flexibility, we generate data on the client (local) side, which avoids additional communication cost required for server-to-client transmitting generative data, and enables using the local data as prior to generate more specific data.
Thus, we focus on local model training, which is decomposed into: <span id="S3.SS1.p1.1.1" class="ltx_text ltx_framed ltx_framed_underline">data generation</span> and <span id="S3.SS1.p1.1.2" class="ltx_text ltx_framed ltx_framed_underline">local model training</span>.
Specifically, in FedGC, we 1) design to generate diverse data, 2) merge the generative and private dataset, and 3) train the local model, where the first two are required for only once; see Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2 Data Generation in FedGC ‣ 3 Federated Learning with Generative Content ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for the overview. Although FedGC is versatile across modalities, our illustration herein will on images for easier understanding.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Generation in FedGC</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">On the designs for data generation in FedGC framework, we consider the following criteria: <span id="S3.SS2.p1.1.1" class="ltx_text ltx_framed ltx_framed_underline">generation efficiency</span>, <span id="S3.SS2.p1.1.2" class="ltx_text ltx_framed ltx_framed_underline">data diversity</span>, and <span id="S3.SS2.p1.1.3" class="ltx_text ltx_framed ltx_framed_underline">data fidelity</span>.
Following the criteria, we explore three crucial aspects, including budget allocation, prompt design, and generation guidance, and propose three representative solutions as candidates for each aspect.
Without loss of generality, we use the text-guided latent diffusion model <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> to generate images based on prompts for image task, and ChatGPT <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> to generate texts based on prompts for text task.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Budget allocation for efficiency.</span>
Though, (1) the process of data generation is just one-shot and (2) FedGC does not compromise on the two first-order concerns in FL: communication cost and privacy <cite class="ltx_cite ltx_citemacro_citep">(Kairouz et al., <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>, it still costs some computation budget in exchange for algorithm utility <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite>.
Thus, it is essential to design efficient strategies to allocate the generation budget (i.e., the total number of generative samples, denoted as <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">M</annotation></semantics></math>) to each client and label.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.6" class="ltx_p">To achieve this, we design three allocation strategies.
(1) The equal allocation strategy allocates the budget equally to each client and each category, which is the simplest and most general allocation strategy.
That is, each client can generate <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\frac{M}{KC}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mfrac id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">M</mi><mrow id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.1.1.3.1" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.1.m1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.cmml">C</mi></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><divide id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"></divide><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑀</ci><apply id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"><times id="S3.SS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.3.2">𝐾</ci><ci id="S3.SS2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\frac{M}{KC}</annotation></semantics></math> data samples for each category.
(2) Inverse allocation strategy allocates the budget inversely to each client according its number of data samples.
Specifically, each client <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">k</annotation></semantics></math> can generate <math id="S3.SS2.p3.3.m3.2" class="ltx_Math" alttext="\frac{M\cdot(N_{max}-N_{k})}{C\cdot\sum_{i}(N_{max}-N_{i})}" display="inline"><semantics id="S3.SS2.p3.3.m3.2a"><mfrac id="S3.SS2.p3.3.m3.2.2" xref="S3.SS2.p3.3.m3.2.2.cmml"><mrow id="S3.SS2.p3.3.m3.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.3" xref="S3.SS2.p3.3.m3.1.1.1.3.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.3.m3.1.1.1.2" xref="S3.SS2.p3.3.m3.1.1.1.2.cmml">⋅</mo><mrow id="S3.SS2.p3.3.m3.1.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.3.m3.1.1.1.1.1.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.3.m3.1.1.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.cmml"><msub id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.2.cmml">N</mi><mrow id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.1a" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.4" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S3.SS2.p3.3.m3.1.1.1.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.2.cmml">N</mi><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.3.cmml">k</mi></msub></mrow><mo stretchy="false" id="S3.SS2.p3.3.m3.1.1.1.1.1.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.SS2.p3.3.m3.2.2.2" xref="S3.SS2.p3.3.m3.2.2.2.cmml"><mi id="S3.SS2.p3.3.m3.2.2.2.3" xref="S3.SS2.p3.3.m3.2.2.2.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.3.m3.2.2.2.2" xref="S3.SS2.p3.3.m3.2.2.2.2.cmml">⋅</mo><mrow id="S3.SS2.p3.3.m3.2.2.2.1" xref="S3.SS2.p3.3.m3.2.2.2.1.cmml"><mstyle displaystyle="false" id="S3.SS2.p3.3.m3.2.2.2.1.2" xref="S3.SS2.p3.3.m3.2.2.2.1.2.cmml"><msub id="S3.SS2.p3.3.m3.2.2.2.1.2a" xref="S3.SS2.p3.3.m3.2.2.2.1.2.cmml"><mo id="S3.SS2.p3.3.m3.2.2.2.1.2.2" xref="S3.SS2.p3.3.m3.2.2.2.1.2.2.cmml">∑</mo><mi id="S3.SS2.p3.3.m3.2.2.2.1.2.3" xref="S3.SS2.p3.3.m3.2.2.2.1.2.3.cmml">i</mi></msub></mstyle><mrow id="S3.SS2.p3.3.m3.2.2.2.1.1.1" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.3.m3.2.2.2.1.1.1.2" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.cmml"><msub id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.cmml"><mi id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.2" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.2.cmml">N</mi><mrow id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.2" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.1" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.3" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.1a" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.4" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.1" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.1.cmml">−</mo><msub id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.2" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.2.cmml">N</mi><mi id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.3" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.SS2.p3.3.m3.2.2.2.1.1.1.3" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.2b"><apply id="S3.SS2.p3.3.m3.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2"><divide id="S3.SS2.p3.3.m3.2.2.3.cmml" xref="S3.SS2.p3.3.m3.2.2"></divide><apply id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1"><ci id="S3.SS2.p3.3.m3.1.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.2">⋅</ci><ci id="S3.SS2.p3.3.m3.1.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.3">𝑀</ci><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1"><minus id="S3.SS2.p3.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.1"></minus><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.2">𝑁</ci><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3"><times id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.2">𝑚</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.3">𝑎</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.4.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.2.3.4">𝑥</ci></apply></apply><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.2">𝑁</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.1.3.3">𝑘</ci></apply></apply></apply><apply id="S3.SS2.p3.3.m3.2.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2"><ci id="S3.SS2.p3.3.m3.2.2.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.2">⋅</ci><ci id="S3.SS2.p3.3.m3.2.2.2.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.3">𝐶</ci><apply id="S3.SS2.p3.3.m3.2.2.2.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1"><apply id="S3.SS2.p3.3.m3.2.2.2.1.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.2.2.1.2.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.2">subscript</csymbol><sum id="S3.SS2.p3.3.m3.2.2.2.1.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.2.2"></sum><ci id="S3.SS2.p3.3.m3.2.2.2.1.2.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.2.3">𝑖</ci></apply><apply id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1"><minus id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.1"></minus><apply id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.2">𝑁</ci><apply id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3"><times id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.2">𝑚</ci><ci id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.3">𝑎</ci><ci id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.4.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.2.3.4">𝑥</ci></apply></apply><apply id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.2">𝑁</ci><ci id="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.2c">\frac{M\cdot(N_{max}-N_{k})}{C\cdot\sum_{i}(N_{max}-N_{i})}</annotation></semantics></math> samples for each category, where <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="N_{max}" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">N</mi><mrow id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.1.1.3.1" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.4.m4.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.1.1.3.1a" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.4.m4.1.1.3.4" xref="S3.SS2.p3.4.m4.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝑁</ci><apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3"><times id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3.1"></times><ci id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">𝑚</ci><ci id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">𝑎</ci><ci id="S3.SS2.p3.4.m4.1.1.3.4.cmml" xref="S3.SS2.p3.4.m4.1.1.3.4">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">N_{max}</annotation></semantics></math> denotes the maximum number in <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\{N_{i}\}_{i}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><msub id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mrow id="S3.SS2.p3.5.m5.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.5.m5.1.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.2.cmml">{</mo><msub id="S3.SS2.p3.5.m5.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2.cmml">N</mi><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p3.5.m5.1.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.2.cmml">}</mo></mrow><mi id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1">subscript</csymbol><set id="S3.SS2.p3.5.m5.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1"><apply id="S3.SS2.p3.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2">𝑁</ci><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.3">𝑖</ci></apply></set><ci id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\{N_{i}\}_{i}</annotation></semantics></math>.
(3) Water-filling-based: each client can generate <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="\frac{M}{K}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mfrac id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">M</mi><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">K</mi></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><divide id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"></divide><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝑀</ci><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">\frac{M}{K}</annotation></semantics></math> samples in total, and apply water filling algorithm to allocate samples to each category <cite class="ltx_cite ltx_citemacro_citep">(Proakis, <a href="#bib.bib29" title="" class="ltx_ref">2008</a>)</cite>.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Prompt design for diversity.</span>
Data diversity plays a key role in learning a generalized model in many domains such as image <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> and text <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>.
To increase the diversity, it is essential to design appropriate prompts since they directly guide the process of generation.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para ltx_noindent">
<p id="S3.SS2.p5.1" class="ltx_p">For image task, we consider three diversity levels.
(1) Single prompt, where we use “a photo of {class}” <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>.
(2) Multiple prompts, where we consider diverse formats such as “{class}”.
(3) LLM-based diversified prompts, where we instruct an LLM such as ChatGPT to diversify the prompts.
While for text generation, we only design one prompt since the ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> is sufficient to generate diverse content if we instruct it to be diverse; see Table <a href="#A1.T8" title="Table 8 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para ltx_noindent">
<p id="S3.SS2.p6.1" class="ltx_p"><span id="S3.SS2.p6.1.1" class="ltx_text ltx_font_bold">Generation guidance for diversity and fidelity.</span>
Finally, we feed the prompts to the generative models for generation.
Besides designing prompts, we randomly set the guidance scale for diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> (or non-zero temperature for LLMs) to enhance the data diversity.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para ltx_noindent">
<p id="S3.SS2.p7.1" class="ltx_p">(Prompt-Only Guidance) However, data diversity may not be sufficient to ensure improving model training, while data fidelity is also a critical factor.
For cases where the domain gap between the generative and real data is too large, the benefits of increasing diversity may be outweighed by the negative effects of the domain gap, leading to degraded performance <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para ltx_noindent">
<p id="S3.SS2.p8.5" class="ltx_p">(Real-Data Guidance) To alleviate this issue, we propose a new real-data-guided generation approach, which conditions data generation on both real data and prompts.
For image task, unlike the original text-guided generation that starts from a random Gaussian noise at latent space <math id="S3.SS2.p8.1.m1.1" class="ltx_Math" alttext="{\bm{z}}^{1}_{T}" display="inline"><semantics id="S3.SS2.p8.1.m1.1a"><msubsup id="S3.SS2.p8.1.m1.1.1" xref="S3.SS2.p8.1.m1.1.1.cmml"><mi id="S3.SS2.p8.1.m1.1.1.2.2" xref="S3.SS2.p8.1.m1.1.1.2.2.cmml">𝒛</mi><mi id="S3.SS2.p8.1.m1.1.1.3" xref="S3.SS2.p8.1.m1.1.1.3.cmml">T</mi><mn id="S3.SS2.p8.1.m1.1.1.2.3" xref="S3.SS2.p8.1.m1.1.1.2.3.cmml">1</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.1.m1.1b"><apply id="S3.SS2.p8.1.m1.1.1.cmml" xref="S3.SS2.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p8.1.m1.1.1.1.cmml" xref="S3.SS2.p8.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.p8.1.m1.1.1.2.cmml" xref="S3.SS2.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p8.1.m1.1.1.2.1.cmml" xref="S3.SS2.p8.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p8.1.m1.1.1.2.2.cmml" xref="S3.SS2.p8.1.m1.1.1.2.2">𝒛</ci><cn type="integer" id="S3.SS2.p8.1.m1.1.1.2.3.cmml" xref="S3.SS2.p8.1.m1.1.1.2.3">1</cn></apply><ci id="S3.SS2.p8.1.m1.1.1.3.cmml" xref="S3.SS2.p8.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.1.m1.1c">{\bm{z}}^{1}_{T}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, we propose to inject information of real data into the starting noise.
Specifically, we first use the auto-encoder to encode the real image <math id="S3.SS2.p8.2.m2.1" class="ltx_Math" alttext="{\bm{x}}" display="inline"><semantics id="S3.SS2.p8.2.m2.1a"><mi id="S3.SS2.p8.2.m2.1.1" xref="S3.SS2.p8.2.m2.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.2.m2.1b"><ci id="S3.SS2.p8.2.m2.1.1.cmml" xref="S3.SS2.p8.2.m2.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.2.m2.1c">{\bm{x}}</annotation></semantics></math> to latent representation <math id="S3.SS2.p8.3.m3.1" class="ltx_Math" alttext="{\bm{z}}" display="inline"><semantics id="S3.SS2.p8.3.m3.1a"><mi id="S3.SS2.p8.3.m3.1.1" xref="S3.SS2.p8.3.m3.1.1.cmml">𝒛</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.3.m3.1b"><ci id="S3.SS2.p8.3.m3.1.1.cmml" xref="S3.SS2.p8.3.m3.1.1">𝒛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.3.m3.1c">{\bm{z}}</annotation></semantics></math>, then add some Gaussian variation to obtain a new <math id="S3.SS2.p8.4.m4.1" class="ltx_Math" alttext="{\bm{z}}^{2}_{T}" display="inline"><semantics id="S3.SS2.p8.4.m4.1a"><msubsup id="S3.SS2.p8.4.m4.1.1" xref="S3.SS2.p8.4.m4.1.1.cmml"><mi id="S3.SS2.p8.4.m4.1.1.2.2" xref="S3.SS2.p8.4.m4.1.1.2.2.cmml">𝒛</mi><mi id="S3.SS2.p8.4.m4.1.1.3" xref="S3.SS2.p8.4.m4.1.1.3.cmml">T</mi><mn id="S3.SS2.p8.4.m4.1.1.2.3" xref="S3.SS2.p8.4.m4.1.1.2.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.4.m4.1b"><apply id="S3.SS2.p8.4.m4.1.1.cmml" xref="S3.SS2.p8.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p8.4.m4.1.1.1.cmml" xref="S3.SS2.p8.4.m4.1.1">subscript</csymbol><apply id="S3.SS2.p8.4.m4.1.1.2.cmml" xref="S3.SS2.p8.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p8.4.m4.1.1.2.1.cmml" xref="S3.SS2.p8.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p8.4.m4.1.1.2.2.cmml" xref="S3.SS2.p8.4.m4.1.1.2.2">𝒛</ci><cn type="integer" id="S3.SS2.p8.4.m4.1.1.2.3.cmml" xref="S3.SS2.p8.4.m4.1.1.2.3">2</cn></apply><ci id="S3.SS2.p8.4.m4.1.1.3.cmml" xref="S3.SS2.p8.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.4.m4.1c">{\bm{z}}^{2}_{T}</annotation></semantics></math>, which substitutes <math id="S3.SS2.p8.5.m5.1" class="ltx_Math" alttext="{\bm{z}}^{1}_{T}" display="inline"><semantics id="S3.SS2.p8.5.m5.1a"><msubsup id="S3.SS2.p8.5.m5.1.1" xref="S3.SS2.p8.5.m5.1.1.cmml"><mi id="S3.SS2.p8.5.m5.1.1.2.2" xref="S3.SS2.p8.5.m5.1.1.2.2.cmml">𝒛</mi><mi id="S3.SS2.p8.5.m5.1.1.3" xref="S3.SS2.p8.5.m5.1.1.3.cmml">T</mi><mn id="S3.SS2.p8.5.m5.1.1.2.3" xref="S3.SS2.p8.5.m5.1.1.2.3.cmml">1</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.5.m5.1b"><apply id="S3.SS2.p8.5.m5.1.1.cmml" xref="S3.SS2.p8.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p8.5.m5.1.1.1.cmml" xref="S3.SS2.p8.5.m5.1.1">subscript</csymbol><apply id="S3.SS2.p8.5.m5.1.1.2.cmml" xref="S3.SS2.p8.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p8.5.m5.1.1.2.1.cmml" xref="S3.SS2.p8.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p8.5.m5.1.1.2.2.cmml" xref="S3.SS2.p8.5.m5.1.1.2.2">𝒛</ci><cn type="integer" id="S3.SS2.p8.5.m5.1.1.2.3.cmml" xref="S3.SS2.p8.5.m5.1.1.2.3">1</cn></apply><ci id="S3.SS2.p8.5.m5.1.1.3.cmml" xref="S3.SS2.p8.5.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.5.m5.1c">{\bm{z}}^{1}_{T}</annotation></semantics></math> as the starting point; see illustration in  <a href="#A1.F7" title="Figure 7 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
This enriched latent representation, infused with real data insights, enables the generative model to produce outputs closely resembling real data, optimizing the trade-off between diversity and fidelity.
For text task, see illustration in Table <a href="#A1.T8" title="Table 8 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> using ChatGPT.</p>
</div>
<div id="S3.SS2.p9" class="ltx_para ltx_noindent">
<p id="S3.SS2.p9.10" class="ltx_p">(Mixed Guidance) Furthermore, given that certain clients may lack data samples from specific categories, we propose a mixed guidance strategy.
Specifically, for a given budget <math id="S3.SS2.p9.1.m1.2" class="ltx_Math" alttext="N_{k,c}" display="inline"><semantics id="S3.SS2.p9.1.m1.2a"><msub id="S3.SS2.p9.1.m1.2.3" xref="S3.SS2.p9.1.m1.2.3.cmml"><mi id="S3.SS2.p9.1.m1.2.3.2" xref="S3.SS2.p9.1.m1.2.3.2.cmml">N</mi><mrow id="S3.SS2.p9.1.m1.2.2.2.4" xref="S3.SS2.p9.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p9.1.m1.1.1.1.1" xref="S3.SS2.p9.1.m1.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p9.1.m1.2.2.2.4.1" xref="S3.SS2.p9.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p9.1.m1.2.2.2.2" xref="S3.SS2.p9.1.m1.2.2.2.2.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.1.m1.2b"><apply id="S3.SS2.p9.1.m1.2.3.cmml" xref="S3.SS2.p9.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p9.1.m1.2.3.1.cmml" xref="S3.SS2.p9.1.m1.2.3">subscript</csymbol><ci id="S3.SS2.p9.1.m1.2.3.2.cmml" xref="S3.SS2.p9.1.m1.2.3.2">𝑁</ci><list id="S3.SS2.p9.1.m1.2.2.2.3.cmml" xref="S3.SS2.p9.1.m1.2.2.2.4"><ci id="S3.SS2.p9.1.m1.1.1.1.1.cmml" xref="S3.SS2.p9.1.m1.1.1.1.1">𝑘</ci><ci id="S3.SS2.p9.1.m1.2.2.2.2.cmml" xref="S3.SS2.p9.1.m1.2.2.2.2">𝑐</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.1.m1.2c">N_{k,c}</annotation></semantics></math> for client <math id="S3.SS2.p9.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p9.2.m2.1a"><mi id="S3.SS2.p9.2.m2.1.1" xref="S3.SS2.p9.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.2.m2.1b"><ci id="S3.SS2.p9.2.m2.1.1.cmml" xref="S3.SS2.p9.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.2.m2.1c">k</annotation></semantics></math> in category <math id="S3.SS2.p9.3.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p9.3.m3.1a"><mi id="S3.SS2.p9.3.m3.1.1" xref="S3.SS2.p9.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.3.m3.1b"><ci id="S3.SS2.p9.3.m3.1.1.cmml" xref="S3.SS2.p9.3.m3.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.3.m3.1c">c</annotation></semantics></math>,
(1) if client <math id="S3.SS2.p9.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p9.4.m4.1a"><mi id="S3.SS2.p9.4.m4.1.1" xref="S3.SS2.p9.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.4.m4.1b"><ci id="S3.SS2.p9.4.m4.1.1.cmml" xref="S3.SS2.p9.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.4.m4.1c">k</annotation></semantics></math> possesses samples from category <math id="S3.SS2.p9.5.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p9.5.m5.1a"><mi id="S3.SS2.p9.5.m5.1.1" xref="S3.SS2.p9.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.5.m5.1b"><ci id="S3.SS2.p9.5.m5.1.1.cmml" xref="S3.SS2.p9.5.m5.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.5.m5.1c">c</annotation></semantics></math>, it generates <math id="S3.SS2.p9.6.m6.2" class="ltx_Math" alttext="N_{k,c}/2" display="inline"><semantics id="S3.SS2.p9.6.m6.2a"><mrow id="S3.SS2.p9.6.m6.2.3" xref="S3.SS2.p9.6.m6.2.3.cmml"><msub id="S3.SS2.p9.6.m6.2.3.2" xref="S3.SS2.p9.6.m6.2.3.2.cmml"><mi id="S3.SS2.p9.6.m6.2.3.2.2" xref="S3.SS2.p9.6.m6.2.3.2.2.cmml">N</mi><mrow id="S3.SS2.p9.6.m6.2.2.2.4" xref="S3.SS2.p9.6.m6.2.2.2.3.cmml"><mi id="S3.SS2.p9.6.m6.1.1.1.1" xref="S3.SS2.p9.6.m6.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p9.6.m6.2.2.2.4.1" xref="S3.SS2.p9.6.m6.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p9.6.m6.2.2.2.2" xref="S3.SS2.p9.6.m6.2.2.2.2.cmml">c</mi></mrow></msub><mo id="S3.SS2.p9.6.m6.2.3.1" xref="S3.SS2.p9.6.m6.2.3.1.cmml">/</mo><mn id="S3.SS2.p9.6.m6.2.3.3" xref="S3.SS2.p9.6.m6.2.3.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.6.m6.2b"><apply id="S3.SS2.p9.6.m6.2.3.cmml" xref="S3.SS2.p9.6.m6.2.3"><divide id="S3.SS2.p9.6.m6.2.3.1.cmml" xref="S3.SS2.p9.6.m6.2.3.1"></divide><apply id="S3.SS2.p9.6.m6.2.3.2.cmml" xref="S3.SS2.p9.6.m6.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p9.6.m6.2.3.2.1.cmml" xref="S3.SS2.p9.6.m6.2.3.2">subscript</csymbol><ci id="S3.SS2.p9.6.m6.2.3.2.2.cmml" xref="S3.SS2.p9.6.m6.2.3.2.2">𝑁</ci><list id="S3.SS2.p9.6.m6.2.2.2.3.cmml" xref="S3.SS2.p9.6.m6.2.2.2.4"><ci id="S3.SS2.p9.6.m6.1.1.1.1.cmml" xref="S3.SS2.p9.6.m6.1.1.1.1">𝑘</ci><ci id="S3.SS2.p9.6.m6.2.2.2.2.cmml" xref="S3.SS2.p9.6.m6.2.2.2.2">𝑐</ci></list></apply><cn type="integer" id="S3.SS2.p9.6.m6.2.3.3.cmml" xref="S3.SS2.p9.6.m6.2.3.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.6.m6.2c">N_{k,c}/2</annotation></semantics></math> samples using text-only guidance and <math id="S3.SS2.p9.7.m7.2" class="ltx_Math" alttext="N_{k,c}/2" display="inline"><semantics id="S3.SS2.p9.7.m7.2a"><mrow id="S3.SS2.p9.7.m7.2.3" xref="S3.SS2.p9.7.m7.2.3.cmml"><msub id="S3.SS2.p9.7.m7.2.3.2" xref="S3.SS2.p9.7.m7.2.3.2.cmml"><mi id="S3.SS2.p9.7.m7.2.3.2.2" xref="S3.SS2.p9.7.m7.2.3.2.2.cmml">N</mi><mrow id="S3.SS2.p9.7.m7.2.2.2.4" xref="S3.SS2.p9.7.m7.2.2.2.3.cmml"><mi id="S3.SS2.p9.7.m7.1.1.1.1" xref="S3.SS2.p9.7.m7.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p9.7.m7.2.2.2.4.1" xref="S3.SS2.p9.7.m7.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p9.7.m7.2.2.2.2" xref="S3.SS2.p9.7.m7.2.2.2.2.cmml">c</mi></mrow></msub><mo id="S3.SS2.p9.7.m7.2.3.1" xref="S3.SS2.p9.7.m7.2.3.1.cmml">/</mo><mn id="S3.SS2.p9.7.m7.2.3.3" xref="S3.SS2.p9.7.m7.2.3.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.7.m7.2b"><apply id="S3.SS2.p9.7.m7.2.3.cmml" xref="S3.SS2.p9.7.m7.2.3"><divide id="S3.SS2.p9.7.m7.2.3.1.cmml" xref="S3.SS2.p9.7.m7.2.3.1"></divide><apply id="S3.SS2.p9.7.m7.2.3.2.cmml" xref="S3.SS2.p9.7.m7.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p9.7.m7.2.3.2.1.cmml" xref="S3.SS2.p9.7.m7.2.3.2">subscript</csymbol><ci id="S3.SS2.p9.7.m7.2.3.2.2.cmml" xref="S3.SS2.p9.7.m7.2.3.2.2">𝑁</ci><list id="S3.SS2.p9.7.m7.2.2.2.3.cmml" xref="S3.SS2.p9.7.m7.2.2.2.4"><ci id="S3.SS2.p9.7.m7.1.1.1.1.cmml" xref="S3.SS2.p9.7.m7.1.1.1.1">𝑘</ci><ci id="S3.SS2.p9.7.m7.2.2.2.2.cmml" xref="S3.SS2.p9.7.m7.2.2.2.2">𝑐</ci></list></apply><cn type="integer" id="S3.SS2.p9.7.m7.2.3.3.cmml" xref="S3.SS2.p9.7.m7.2.3.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.7.m7.2c">N_{k,c}/2</annotation></semantics></math> samples with real-data guidance;
(2) in the absence of samples for client <math id="S3.SS2.p9.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p9.8.m8.1a"><mi id="S3.SS2.p9.8.m8.1.1" xref="S3.SS2.p9.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.8.m8.1b"><ci id="S3.SS2.p9.8.m8.1.1.cmml" xref="S3.SS2.p9.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.8.m8.1c">k</annotation></semantics></math> from category <math id="S3.SS2.p9.9.m9.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p9.9.m9.1a"><mi id="S3.SS2.p9.9.m9.1.1" xref="S3.SS2.p9.9.m9.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.9.m9.1b"><ci id="S3.SS2.p9.9.m9.1.1.cmml" xref="S3.SS2.p9.9.m9.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.9.m9.1c">c</annotation></semantics></math>, it generates all the <math id="S3.SS2.p9.10.m10.2" class="ltx_Math" alttext="N_{k,c}" display="inline"><semantics id="S3.SS2.p9.10.m10.2a"><msub id="S3.SS2.p9.10.m10.2.3" xref="S3.SS2.p9.10.m10.2.3.cmml"><mi id="S3.SS2.p9.10.m10.2.3.2" xref="S3.SS2.p9.10.m10.2.3.2.cmml">N</mi><mrow id="S3.SS2.p9.10.m10.2.2.2.4" xref="S3.SS2.p9.10.m10.2.2.2.3.cmml"><mi id="S3.SS2.p9.10.m10.1.1.1.1" xref="S3.SS2.p9.10.m10.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p9.10.m10.2.2.2.4.1" xref="S3.SS2.p9.10.m10.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p9.10.m10.2.2.2.2" xref="S3.SS2.p9.10.m10.2.2.2.2.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.10.m10.2b"><apply id="S3.SS2.p9.10.m10.2.3.cmml" xref="S3.SS2.p9.10.m10.2.3"><csymbol cd="ambiguous" id="S3.SS2.p9.10.m10.2.3.1.cmml" xref="S3.SS2.p9.10.m10.2.3">subscript</csymbol><ci id="S3.SS2.p9.10.m10.2.3.2.cmml" xref="S3.SS2.p9.10.m10.2.3.2">𝑁</ci><list id="S3.SS2.p9.10.m10.2.2.2.3.cmml" xref="S3.SS2.p9.10.m10.2.2.2.4"><ci id="S3.SS2.p9.10.m10.1.1.1.1.cmml" xref="S3.SS2.p9.10.m10.1.1.1.1">𝑘</ci><ci id="S3.SS2.p9.10.m10.2.2.2.2.cmml" xref="S3.SS2.p9.10.m10.2.2.2.2">𝑐</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.10.m10.2c">N_{k,c}</annotation></semantics></math> samples using text-only guidance.
This approach effectively addresses category omissions and refines the trade-off between diversity and fidelity.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2312.05807/assets/x1.png" id="S3.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="380" height="256" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the designs of FedGC on client side. Above, we summarize four crucial aspects that are worth exploring and propose three solutions for each aspect. Below is the pipeline of local training, where each client first generates data based on the generation recipe, then merges the generative and private dataset, and finally trains the local model based on the training recipe.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Local Model Training in FedGC</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.2" class="ltx_p">By choosing generation recipe from the three aspects above, we can generate data using the generative model to assist local model training.
Given the generative dataset <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">𝒟</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝒟</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathcal{D}_{g}</annotation></semantics></math> and the private dataset <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{p}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">𝒟</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝒟</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\mathcal{D}_{p}</annotation></semantics></math>, there could be diverse training strategies such as sequential training (optimizing on the two datasets sequentially) and mixed training (optimizing on the mixed dataset).</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.10" class="ltx_p">We find that the mixed training strategy is the most effective despite its simplicity.
Thus, we directly merge the two datasets as the final new training dataset <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{m}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">𝒟</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝒟</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathcal{D}_{m}</annotation></semantics></math>, based on which we train the local model at the same training manner protocol as other FL methods. Specifically, at the <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">t</annotation></semantics></math>-th FL communication round, each client <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">k</annotation></semantics></math> first receives the global model <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\bm{\theta}^{t}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><msup id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">𝜽</mi><mi id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">𝜽</ci><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\bm{\theta}^{t}</annotation></semantics></math> and re-initializes its local model with <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="\bm{\theta}^{t}" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><msup id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">𝜽</mi><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝜽</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">\bm{\theta}^{t}</annotation></semantics></math>. Then, each client conducts model training based on the merged dataset <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{D}_{m}" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><msub id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">𝒟</mi><mi id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝒟</ci><ci id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">\mathcal{D}_{m}</annotation></semantics></math> for several optimization steps. Finally, each client <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mi id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><ci id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">k</annotation></semantics></math> obtains its local model <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="\bm{\theta}_{k}^{t}" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><msubsup id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2.2" xref="S3.SS3.p2.8.m8.1.1.2.2.cmml">𝜽</mi><mi id="S3.SS3.p2.8.m8.1.1.2.3" xref="S3.SS3.p2.8.m8.1.1.2.3.cmml">k</mi><mi id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">superscript</csymbol><apply id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.2.1.cmml" xref="S3.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.2.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2.2">𝜽</ci><ci id="S3.SS3.p2.8.m8.1.1.2.3.cmml" xref="S3.SS3.p2.8.m8.1.1.2.3">𝑘</ci></apply><ci id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">\bm{\theta}_{k}^{t}</annotation></semantics></math>, which is subsequently sent to the server for model aggregation (<math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="\bm{\theta}^{t+1}:=\sum_{k}p_{k}\bm{\theta}_{k}^{t}" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><mrow id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml"><msup id="S3.SS3.p2.9.m9.1.1.2" xref="S3.SS3.p2.9.m9.1.1.2.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2.2" xref="S3.SS3.p2.9.m9.1.1.2.2.cmml">𝜽</mi><mrow id="S3.SS3.p2.9.m9.1.1.2.3" xref="S3.SS3.p2.9.m9.1.1.2.3.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2.3.2" xref="S3.SS3.p2.9.m9.1.1.2.3.2.cmml">t</mi><mo id="S3.SS3.p2.9.m9.1.1.2.3.1" xref="S3.SS3.p2.9.m9.1.1.2.3.1.cmml">+</mo><mn id="S3.SS3.p2.9.m9.1.1.2.3.3" xref="S3.SS3.p2.9.m9.1.1.2.3.3.cmml">1</mn></mrow></msup><mo lspace="0.278em" rspace="0.111em" id="S3.SS3.p2.9.m9.1.1.1" xref="S3.SS3.p2.9.m9.1.1.1.cmml">:=</mo><mrow id="S3.SS3.p2.9.m9.1.1.3" xref="S3.SS3.p2.9.m9.1.1.3.cmml"><msub id="S3.SS3.p2.9.m9.1.1.3.1" xref="S3.SS3.p2.9.m9.1.1.3.1.cmml"><mo id="S3.SS3.p2.9.m9.1.1.3.1.2" xref="S3.SS3.p2.9.m9.1.1.3.1.2.cmml">∑</mo><mi id="S3.SS3.p2.9.m9.1.1.3.1.3" xref="S3.SS3.p2.9.m9.1.1.3.1.3.cmml">k</mi></msub><mrow id="S3.SS3.p2.9.m9.1.1.3.2" xref="S3.SS3.p2.9.m9.1.1.3.2.cmml"><msub id="S3.SS3.p2.9.m9.1.1.3.2.2" xref="S3.SS3.p2.9.m9.1.1.3.2.2.cmml"><mi id="S3.SS3.p2.9.m9.1.1.3.2.2.2" xref="S3.SS3.p2.9.m9.1.1.3.2.2.2.cmml">p</mi><mi id="S3.SS3.p2.9.m9.1.1.3.2.2.3" xref="S3.SS3.p2.9.m9.1.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p2.9.m9.1.1.3.2.1" xref="S3.SS3.p2.9.m9.1.1.3.2.1.cmml">​</mo><msubsup id="S3.SS3.p2.9.m9.1.1.3.2.3" xref="S3.SS3.p2.9.m9.1.1.3.2.3.cmml"><mi id="S3.SS3.p2.9.m9.1.1.3.2.3.2.2" xref="S3.SS3.p2.9.m9.1.1.3.2.3.2.2.cmml">𝜽</mi><mi id="S3.SS3.p2.9.m9.1.1.3.2.3.2.3" xref="S3.SS3.p2.9.m9.1.1.3.2.3.2.3.cmml">k</mi><mi id="S3.SS3.p2.9.m9.1.1.3.2.3.3" xref="S3.SS3.p2.9.m9.1.1.3.2.3.3.cmml">t</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><apply id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1"><csymbol cd="latexml" id="S3.SS3.p2.9.m9.1.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1.1">assign</csymbol><apply id="S3.SS3.p2.9.m9.1.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.2.1.cmml" xref="S3.SS3.p2.9.m9.1.1.2">superscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.2.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2.2">𝜽</ci><apply id="S3.SS3.p2.9.m9.1.1.2.3.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3"><plus id="S3.SS3.p2.9.m9.1.1.2.3.1.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.1"></plus><ci id="S3.SS3.p2.9.m9.1.1.2.3.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.2">𝑡</ci><cn type="integer" id="S3.SS3.p2.9.m9.1.1.2.3.3.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.3">1</cn></apply></apply><apply id="S3.SS3.p2.9.m9.1.1.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3"><apply id="S3.SS3.p2.9.m9.1.1.3.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.3.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.1">subscript</csymbol><sum id="S3.SS3.p2.9.m9.1.1.3.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.1.2"></sum><ci id="S3.SS3.p2.9.m9.1.1.3.1.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.1.3">𝑘</ci></apply><apply id="S3.SS3.p2.9.m9.1.1.3.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2"><times id="S3.SS3.p2.9.m9.1.1.3.2.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.1"></times><apply id="S3.SS3.p2.9.m9.1.1.3.2.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.3.2.2.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.2">subscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.3.2.2.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.2.2">𝑝</ci><ci id="S3.SS3.p2.9.m9.1.1.3.2.2.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.2.3">𝑘</ci></apply><apply id="S3.SS3.p2.9.m9.1.1.3.2.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.3.2.3.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3">superscript</csymbol><apply id="S3.SS3.p2.9.m9.1.1.3.2.3.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.3.2.3.2.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3">subscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.3.2.3.2.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3.2.2">𝜽</ci><ci id="S3.SS3.p2.9.m9.1.1.3.2.3.2.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3.2.3">𝑘</ci></apply><ci id="S3.SS3.p2.9.m9.1.1.3.2.3.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">\bm{\theta}^{t+1}:=\sum_{k}p_{k}\bm{\theta}_{k}^{t}</annotation></semantics></math>, where <math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="p_{k}=N_{k}/\sum_{i}N_{i}" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><mrow id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml"><msub id="S3.SS3.p2.10.m10.1.1.2" xref="S3.SS3.p2.10.m10.1.1.2.cmml"><mi id="S3.SS3.p2.10.m10.1.1.2.2" xref="S3.SS3.p2.10.m10.1.1.2.2.cmml">p</mi><mi id="S3.SS3.p2.10.m10.1.1.2.3" xref="S3.SS3.p2.10.m10.1.1.2.3.cmml">k</mi></msub><mo id="S3.SS3.p2.10.m10.1.1.1" xref="S3.SS3.p2.10.m10.1.1.1.cmml">=</mo><mrow id="S3.SS3.p2.10.m10.1.1.3" xref="S3.SS3.p2.10.m10.1.1.3.cmml"><msub id="S3.SS3.p2.10.m10.1.1.3.2" xref="S3.SS3.p2.10.m10.1.1.3.2.cmml"><mi id="S3.SS3.p2.10.m10.1.1.3.2.2" xref="S3.SS3.p2.10.m10.1.1.3.2.2.cmml">N</mi><mi id="S3.SS3.p2.10.m10.1.1.3.2.3" xref="S3.SS3.p2.10.m10.1.1.3.2.3.cmml">k</mi></msub><mo rspace="0.055em" id="S3.SS3.p2.10.m10.1.1.3.1" xref="S3.SS3.p2.10.m10.1.1.3.1.cmml">/</mo><mrow id="S3.SS3.p2.10.m10.1.1.3.3" xref="S3.SS3.p2.10.m10.1.1.3.3.cmml"><msub id="S3.SS3.p2.10.m10.1.1.3.3.1" xref="S3.SS3.p2.10.m10.1.1.3.3.1.cmml"><mo id="S3.SS3.p2.10.m10.1.1.3.3.1.2" xref="S3.SS3.p2.10.m10.1.1.3.3.1.2.cmml">∑</mo><mi id="S3.SS3.p2.10.m10.1.1.3.3.1.3" xref="S3.SS3.p2.10.m10.1.1.3.3.1.3.cmml">i</mi></msub><msub id="S3.SS3.p2.10.m10.1.1.3.3.2" xref="S3.SS3.p2.10.m10.1.1.3.3.2.cmml"><mi id="S3.SS3.p2.10.m10.1.1.3.3.2.2" xref="S3.SS3.p2.10.m10.1.1.3.3.2.2.cmml">N</mi><mi id="S3.SS3.p2.10.m10.1.1.3.3.2.3" xref="S3.SS3.p2.10.m10.1.1.3.3.2.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><apply id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1"><eq id="S3.SS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1.1"></eq><apply id="S3.SS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.2.1.cmml" xref="S3.SS3.p2.10.m10.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.2.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2.2">𝑝</ci><ci id="S3.SS3.p2.10.m10.1.1.2.3.cmml" xref="S3.SS3.p2.10.m10.1.1.2.3">𝑘</ci></apply><apply id="S3.SS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3"><divide id="S3.SS3.p2.10.m10.1.1.3.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.1"></divide><apply id="S3.SS3.p2.10.m10.1.1.3.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.3.2.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.3.2.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.2.2">𝑁</ci><ci id="S3.SS3.p2.10.m10.1.1.3.2.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3.2.3">𝑘</ci></apply><apply id="S3.SS3.p2.10.m10.1.1.3.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3"><apply id="S3.SS3.p2.10.m10.1.1.3.3.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.3.3.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.1">subscript</csymbol><sum id="S3.SS3.p2.10.m10.1.1.3.3.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.1.2"></sum><ci id="S3.SS3.p2.10.m10.1.1.3.3.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.1.3">𝑖</ci></apply><apply id="S3.SS3.p2.10.m10.1.1.3.3.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.3.3.2.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.2">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.3.3.2.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.2.2">𝑁</ci><ci id="S3.SS3.p2.10.m10.1.1.3.3.2.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">p_{k}=N_{k}/\sum_{i}N_{i}</annotation></semantics></math> is the relative dataset size).</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p">Note that this process is orthogonal to local training algorithm, which can be SGD-based training <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite>, proximity-based training <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib22" title="" class="ltx_ref">2020b</a>)</cite>, control-variate-based training <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, or feature-alignment-based training <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Experiments on two heterogeneity types, four datasets, two heterogeneity levels, and six baselines. Test accuracy (%) averaged over three trials is reported. FedGC consistently and significantly brings performance gain over baselines across diverse settings.</figcaption>
<table id="S4.T1.1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="3"><span id="S4.T1.1.1.2.1.1.1" class="ltx_text">Baseline</span></th>
<th id="S4.T1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;">H-Type</th>
<th id="S4.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="4">Label Level</th>
<th id="S4.T1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="4">Feature Level</th>
<th id="S4.T1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.2.1.5.1" class="ltx_text ltx_font_bold">Avg.</span></th>
</tr>
<tr id="S4.T1.1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Dataset</th>
<th id="S4.T1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="2">CIFAR-10</th>
<th id="S4.T1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="2">EuroSAT</th>
<th id="S4.T1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="2">PACS</th>
<th id="S4.T1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="2">VLCS</th>
<th id="S4.T1.1.1.3.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.3.2.6.1" class="ltx_text ltx_font_bold">Acc.</span></th>
</tr>
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">H-Level</th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">High</th>
<th id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">Low</th>
<th id="S4.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">High</th>
<th id="S4.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Low</th>
<th id="S4.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">High</th>
<th id="S4.T1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">Low</th>
<th id="S4.T1.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">High</th>
<th id="S4.T1.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Low</th>
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;"><math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\bm{\Delta}" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mi id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">𝚫</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">𝚫</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\bm{\Delta}</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.4.1" class="ltx_tr">
<td id="S4.T1.1.1.4.1.1" class="ltx_td ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="S4.T1.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="S4.T1.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">61.25</td>
<td id="S4.T1.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">75.88</td>
<td id="S4.T1.1.1.4.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">53.82</td>
<td id="S4.T1.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">75.59</td>
<td id="S4.T1.1.1.4.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">27.16</td>
<td id="S4.T1.1.1.4.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">36.47</td>
<td id="S4.T1.1.1.4.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">43.69</td>
<td id="S4.T1.1.1.4.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">47.95</td>
<td id="S4.T1.1.1.4.1.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="S4.T1.1.1.4.1.11.1" class="ltx_text ltx_font_bold">+12.26</span></td>
</tr>
<tr id="S4.T1.1.1.5.2" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T1.1.1.5.2.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.1.1" class="ltx_text" style="background-color:#FFFFFF;">FedAvg</span></td>
<td id="S4.T1.1.1.5.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="S4.T1.1.1.5.2.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.3.1" class="ltx_text" style="background-color:#ECECEC;">74.50</span></td>
<td id="S4.T1.1.1.5.2.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.4.1" class="ltx_text" style="background-color:#ECECEC;">79.73</span></td>
<td id="S4.T1.1.1.5.2.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.5.1" class="ltx_text" style="background-color:#ECECEC;">74.83</span></td>
<td id="S4.T1.1.1.5.2.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.6.1" class="ltx_text" style="background-color:#ECECEC;">84.46</span></td>
<td id="S4.T1.1.1.5.2.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.7.1" class="ltx_text" style="background-color:#ECECEC;">54.43</span></td>
<td id="S4.T1.1.1.5.2.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.8.1" class="ltx_text" style="background-color:#ECECEC;">53.93</span></td>
<td id="S4.T1.1.1.5.2.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.9.1" class="ltx_text" style="background-color:#ECECEC;">46.49</span></td>
<td id="S4.T1.1.1.5.2.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.5.2.10.1" class="ltx_text" style="background-color:#ECECEC;">50.50</span></td>
</tr>
<tr id="S4.T1.1.1.6.3" class="ltx_tr">
<td id="S4.T1.1.1.6.3.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="S4.T1.1.1.6.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="S4.T1.1.1.6.3.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">60.83</td>
<td id="S4.T1.1.1.6.3.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">74.40</td>
<td id="S4.T1.1.1.6.3.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">50.91</td>
<td id="S4.T1.1.1.6.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">72.80</td>
<td id="S4.T1.1.1.6.3.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">28.96</td>
<td id="S4.T1.1.1.6.3.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">34.52</td>
<td id="S4.T1.1.1.6.3.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">46.64</td>
<td id="S4.T1.1.1.6.3.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">45.74</td>
<td id="S4.T1.1.1.6.3.11" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="S4.T1.1.1.6.3.11.1" class="ltx_text ltx_font_bold">+13.04</span></td>
</tr>
<tr id="S4.T1.1.1.7.4" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T1.1.1.7.4.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.1.1" class="ltx_text" style="background-color:#FFFFFF;">FedAvgM</span></td>
<td id="S4.T1.1.1.7.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="S4.T1.1.1.7.4.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.3.1" class="ltx_text" style="background-color:#ECECEC;">73.84</span></td>
<td id="S4.T1.1.1.7.4.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.4.1" class="ltx_text" style="background-color:#ECECEC;">78.90</span></td>
<td id="S4.T1.1.1.7.4.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.5.1" class="ltx_text" style="background-color:#ECECEC;">73.48</span></td>
<td id="S4.T1.1.1.7.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.6.1" class="ltx_text" style="background-color:#ECECEC;">84.87</span></td>
<td id="S4.T1.1.1.7.4.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.7.1" class="ltx_text" style="background-color:#ECECEC;">53.23</span></td>
<td id="S4.T1.1.1.7.4.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.8.1" class="ltx_text" style="background-color:#ECECEC;">55.73</span></td>
<td id="S4.T1.1.1.7.4.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.9.1" class="ltx_text" style="background-color:#ECECEC;">48.45</span></td>
<td id="S4.T1.1.1.7.4.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.7.4.10.1" class="ltx_text" style="background-color:#ECECEC;">50.65</span></td>
</tr>
<tr id="S4.T1.1.1.8.5" class="ltx_tr">
<td id="S4.T1.1.1.8.5.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="S4.T1.1.1.8.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="S4.T1.1.1.8.5.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">64.02</td>
<td id="S4.T1.1.1.8.5.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">75.62</td>
<td id="S4.T1.1.1.8.5.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">59.61</td>
<td id="S4.T1.1.1.8.5.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">73.20</td>
<td id="S4.T1.1.1.8.5.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">27.71</td>
<td id="S4.T1.1.1.8.5.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">39.52</td>
<td id="S4.T1.1.1.8.5.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">38.83</td>
<td id="S4.T1.1.1.8.5.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">48.50</td>
<td id="S4.T1.1.1.8.5.11" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="S4.T1.1.1.8.5.11.1" class="ltx_text ltx_font_bold">+11.49</span></td>
</tr>
<tr id="S4.T1.1.1.9.6" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T1.1.1.9.6.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.1.1" class="ltx_text" style="background-color:#FFFFFF;">FedProx</span></td>
<td id="S4.T1.1.1.9.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="S4.T1.1.1.9.6.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.3.1" class="ltx_text" style="background-color:#ECECEC;">74.36</span></td>
<td id="S4.T1.1.1.9.6.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.4.1" class="ltx_text" style="background-color:#ECECEC;">79.25</span></td>
<td id="S4.T1.1.1.9.6.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.5.1" class="ltx_text" style="background-color:#ECECEC;">73.04</span></td>
<td id="S4.T1.1.1.9.6.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.6.1" class="ltx_text" style="background-color:#ECECEC;">84.76</span></td>
<td id="S4.T1.1.1.9.6.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.7.1" class="ltx_text" style="background-color:#ECECEC;">54.28</span></td>
<td id="S4.T1.1.1.9.6.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.8.1" class="ltx_text" style="background-color:#ECECEC;">55.83</span></td>
<td id="S4.T1.1.1.9.6.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.9.1" class="ltx_text" style="background-color:#ECECEC;">45.69</span></td>
<td id="S4.T1.1.1.9.6.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.9.6.10.1" class="ltx_text" style="background-color:#ECECEC;">51.70</span></td>
</tr>
<tr id="S4.T1.1.1.10.7" class="ltx_tr">
<td id="S4.T1.1.1.10.7.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="S4.T1.1.1.10.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="S4.T1.1.1.10.7.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">63.98</td>
<td id="S4.T1.1.1.10.7.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">78.79</td>
<td id="S4.T1.1.1.10.7.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">52.72</td>
<td id="S4.T1.1.1.10.7.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">76.80</td>
<td id="S4.T1.1.1.10.7.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">29.72</td>
<td id="S4.T1.1.1.10.7.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">37.52</td>
<td id="S4.T1.1.1.10.7.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">43.64</td>
<td id="S4.T1.1.1.10.7.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">40.83</td>
<td id="S4.T1.1.1.10.7.11" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="S4.T1.1.1.10.7.11.1" class="ltx_text ltx_font_bold">+12.57</span></td>
</tr>
<tr id="S4.T1.1.1.11.8" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T1.1.1.11.8.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.1.1" class="ltx_text" style="background-color:#FFFFFF;">SCAFFOLD</span></td>
<td id="S4.T1.1.1.11.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="S4.T1.1.1.11.8.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.3.1" class="ltx_text" style="background-color:#ECECEC;">73.96</span></td>
<td id="S4.T1.1.1.11.8.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.4.1" class="ltx_text" style="background-color:#ECECEC;">80.29</span></td>
<td id="S4.T1.1.1.11.8.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.5.1" class="ltx_text" style="background-color:#ECECEC;">69.48</span></td>
<td id="S4.T1.1.1.11.8.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.6.1" class="ltx_text" style="background-color:#ECECEC;">81.04</span></td>
<td id="S4.T1.1.1.11.8.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.7.1" class="ltx_text" style="background-color:#ECECEC;">59.73</span></td>
<td id="S4.T1.1.1.11.8.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.8.1" class="ltx_text" style="background-color:#ECECEC;">60.63</span></td>
<td id="S4.T1.1.1.11.8.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.9.1" class="ltx_text" style="background-color:#ECECEC;">47.65</span></td>
<td id="S4.T1.1.1.11.8.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.11.8.10.1" class="ltx_text" style="background-color:#ECECEC;">51.75</span></td>
</tr>
<tr id="S4.T1.1.1.12.9" class="ltx_tr">
<td id="S4.T1.1.1.12.9.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="S4.T1.1.1.12.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="S4.T1.1.1.12.9.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">63.40</td>
<td id="S4.T1.1.1.12.9.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">75.43</td>
<td id="S4.T1.1.1.12.9.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">52.67</td>
<td id="S4.T1.1.1.12.9.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">70.02</td>
<td id="S4.T1.1.1.12.9.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">27.91</td>
<td id="S4.T1.1.1.12.9.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">36.52</td>
<td id="S4.T1.1.1.12.9.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">45.89</td>
<td id="S4.T1.1.1.12.9.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">48.30</td>
<td id="S4.T1.1.1.12.9.11" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="S4.T1.1.1.12.9.11.1" class="ltx_text ltx_font_bold">+12.47</span></td>
</tr>
<tr id="S4.T1.1.1.13.10" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T1.1.1.13.10.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.1.1" class="ltx_text" style="background-color:#FFFFFF;">MOON</span></td>
<td id="S4.T1.1.1.13.10.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="S4.T1.1.1.13.10.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.3.1" class="ltx_text" style="background-color:#ECECEC;">74.02</span></td>
<td id="S4.T1.1.1.13.10.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.4.1" class="ltx_text" style="background-color:#ECECEC;">79.82</span></td>
<td id="S4.T1.1.1.13.10.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.5.1" class="ltx_text" style="background-color:#ECECEC;">73.69</span></td>
<td id="S4.T1.1.1.13.10.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.6.1" class="ltx_text" style="background-color:#ECECEC;">86.06</span></td>
<td id="S4.T1.1.1.13.10.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.7.1" class="ltx_text" style="background-color:#ECECEC;">53.81</span></td>
<td id="S4.T1.1.1.13.10.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.8.1" class="ltx_text" style="background-color:#ECECEC;">55.08</span></td>
<td id="S4.T1.1.1.13.10.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.9.1" class="ltx_text" style="background-color:#ECECEC;">48.05</span></td>
<td id="S4.T1.1.1.13.10.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.13.10.10.1" class="ltx_text" style="background-color:#ECECEC;">49.35</span></td>
</tr>
<tr id="S4.T1.1.1.14.11" class="ltx_tr">
<td id="S4.T1.1.1.14.11.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="S4.T1.1.1.14.11.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="S4.T1.1.1.14.11.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">64.14</td>
<td id="S4.T1.1.1.14.11.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">76.19</td>
<td id="S4.T1.1.1.14.11.5" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">63.74</td>
<td id="S4.T1.1.1.14.11.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">69.57</td>
<td id="S4.T1.1.1.14.11.7" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">27.51</td>
<td id="S4.T1.1.1.14.11.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">29.07</td>
<td id="S4.T1.1.1.14.11.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">37.02</td>
<td id="S4.T1.1.1.14.11.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">47.70</td>
<td id="S4.T1.1.1.14.11.11" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="S4.T1.1.1.14.11.11.1" class="ltx_text ltx_font_bold">+9.62</span></td>
</tr>
<tr id="S4.T1.1.1.15.12" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T1.1.1.15.12.1" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.1.1" class="ltx_text" style="background-color:#FFFFFF;">FedDecorr</span></td>
<td id="S4.T1.1.1.15.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="S4.T1.1.1.15.12.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.3.1" class="ltx_text" style="background-color:#ECECEC;">73.94</span></td>
<td id="S4.T1.1.1.15.12.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.4.1" class="ltx_text" style="background-color:#ECECEC;">78.16</span></td>
<td id="S4.T1.1.1.15.12.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.5.1" class="ltx_text" style="background-color:#ECECEC;">69.93</span></td>
<td id="S4.T1.1.1.15.12.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.6.1" class="ltx_text" style="background-color:#ECECEC;">81.30</span></td>
<td id="S4.T1.1.1.15.12.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.7.1" class="ltx_text" style="background-color:#ECECEC;">48.77</span></td>
<td id="S4.T1.1.1.15.12.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.8.1" class="ltx_text" style="background-color:#ECECEC;">47.42</span></td>
<td id="S4.T1.1.1.15.12.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.9.1" class="ltx_text" style="background-color:#ECECEC;">43.39</span></td>
<td id="S4.T1.1.1.15.12.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="S4.T1.1.1.15.12.10.1" class="ltx_text" style="background-color:#ECECEC;">49.00</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implementation Details</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">We set the number of communication rounds as 100. Table <a href="#A1.T9" title="Table 9 ‣ A.2 Implementation Details ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> lists client number for each dataset.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.3" class="ltx_p"><span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">Data Heterogeneity and Datasets.</span>
We consider two types of data heterogeneity for image tasks.
For label heterogeneity, we consider CIFAR-10 <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al., <a href="#bib.bib19" title="" class="ltx_ref">2009</a>)</cite> and EuroSAT <cite class="ltx_cite ltx_citemacro_citep">(Helber et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>, where we allocate the original training dataset to clients based on the frequently used strategy in FL: Dirichlet distribution <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib41" title="" class="ltx_ref">2020a</a>)</cite>.
<math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\beta</annotation></semantics></math> controls the level of heterogeneity, where we denote <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="0.05" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn type="float" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">0.05</annotation></semantics></math> as high and <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mn id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><cn type="float" id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">0.1</annotation></semantics></math> as low.
For feature heterogeneity, we consider PACS <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> and VLCS <cite class="ltx_cite ltx_citemacro_citep">(Fang et al., <a href="#bib.bib8" title="" class="ltx_ref">2013</a>)</cite>, where we allocate training dataset of each domain to several clients according to Dirichlet distribution.
This captures both the properties of feature- and label-level heterogeneity.
For text datasets, we consider Sentiment140 from LEAF benchmark <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> (naturally allocated) and Yahoo! Answers <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib48" title="" class="ltx_ref">2015</a>)</cite> (split by Dirichlet distribution).</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Training Details.</span>
The number of iterations for local model training is 200 and uses SGD as the optimizer with a batch size of 64.
The learning rate is set to 0.01 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib20" title="" class="ltx_ref">2021</a>; Ye et al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>.
We use ResNet-20 <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib10" title="" class="ltx_ref">2016</a>)</cite> for image task and LSTM for text task <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Results</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">FedGC significantly improves the FL performance under data heterogeneity.</span> In Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we show experimental results on two heterogeneity types (label-level and feature-level heterogeneity), two datasets for each type (CIFAR-10, EuroSAT, PACS, and VLCS), and two heterogeneity levels for each dataset.
From the table, we see that (1) incorporating baseline in our FedGC framework can consistently and significantly improve the performance of baseline across diverse settings.
(2) FedGC is extremely helpful when the heterogeneity level is relatively high, convincingly supporting our idea of introducing generative data to mitigate the effects of data heterogeneity.
Specifically, based on FedAvg, FedGC brings 21.01 absolute accuracy improvement under a high heterogeneity level on EuroSAT and 12.26 absolute accuracy improvement on average.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">FedGC is compatible with existing FL methods.</span> From Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we see that FedGC consistently and significantly brings performance gain across 6 different baselines, including FedAvg, FedAvgM, FedProx, SCAFFOLD, MOON, and FedDecorr.
For example, FedGC averagely brings 12.68 absolute accuracy improvement to SCAFFOLD <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>.
This demonstrates the compatibility and universality of our proposed FedGC framework.</p>
</div>
<figure id="S4.F2" class="ltx_figure ltx_align_floatright">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/privacy_acc_50k.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_img_square" width="144" height="117" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>50k Real Samples</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/privacy_acc_10k.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_img_square" width="144" height="117" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>10k Real Samples</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>FedGC achieves both better task accuracy and privacy preservation (lower attack accuracy).</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">FedGC achieves better performance and privacy preservation at the same time.</span> In Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show the performance and privacy preservation trade-off comparisons before and after using FedGC.
To measure privacy preservation, we use a simple membership inference attack method based on loss evaluation <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a href="#bib.bib47" title="" class="ltx_ref">2021</a>; Sablayrolles et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> to evaluate attack accuracy, see details in Section <a href="#A1.SS3" title="A.3 Membership Inference Attack ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>.
Lower attack accuracy indicates better privacy preservation.
From the figure, we have an interesting finding that our FedGC framework can not only improve the performance under data heterogeneity, but also enhance the privacy preservation.
We also show in Table <a href="#A1.T10" title="Table 10 ‣ A.3 Membership Inference Attack ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> that FedGC achieves significantly lower attack accuracy when similar task accuracy is achieved.
This is surprising yet reasonable since FedGC requires the model to learn from both the private data and the diverse generative data, meaning that the generative data can dilute the concentration of real, sensitive data.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p">This explanation can be further verified since (1) as the number of generated samples increases, FedGC achieves lower attack accuracy (better privacy preservation). (2) When the number of real training samples is smaller (from 50k to 10k), we see a much larger reduction in attack accuracy and improvement in task accuracy, since the ratio of private data samples in the whole dataset is lowered.</p>
</div>
<figure id="S4.F3" class="ltx_figure ltx_align_floatright">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/Alg_Sentiment140_delta_bar.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="138" height="112" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Sentiment140</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/Alg_YahooAnswers_delta_bar.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="138" height="112" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Yahoo! Answers</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Performance comparisons on two text datasets. Our proposed FedGC consistently and significantly brings performance gain.</figcaption>
</figure>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">FedGC is general across modalities.</span>
In Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we report the performance of FedGC in text modality.
We consider two datasets, Sentiment140 and Yahoo! Answers, consisting of 1000 and 100 clients, respectively.
Here, we use ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite> as the generative model.
We apply equal budget allocation and single prompt (where we increase the diversity by directly instructing ChatGPT to “be diverse”).
For real-data-guidance, we take advantage of LLM’s few-shot learning ability by giving several real examples in the context <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>.
From the figure, we see that FedGC still consistently and significantly brings performance gain to all three baselines across two datasets.
This experiment verifies that our proposed FedGC framework has the potential to generalize well to diverse modalities.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para ltx_noindent">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Applicability to diverse scenarios.</span>
We also
(1) consider scenarios where only a partial of the clients are capable of generating data in Section <a href="#A1.SS6" title="A.6 FedGC with Partial Clients Capable of Generation ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.6</span></a>;
(2) experiment on partial client participation scenarios in Section <a href="#A1.SS8" title="A.8 FedGC for Partial Client Participation Scenarios ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.8</span></a>;
(3) experiment under different heterogeneity levels in Section <a href="#A1.SS7" title="A.7 FedGC under Different Heterogeneity Levels ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.7</span></a>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Towards Different Designs of FedGC</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.2" class="ltx_p"><span id="S4.SS3.p1.2.1" class="ltx_text ltx_font_bold">Generating more data could make FedAvg prevail.</span> In Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Towards Different Designs of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we explore the effects of number of generated samples on FL’s performance. 0 denotes vanilla FL baseline. Experiments are conducted on CIFAR-10 (<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\beta=0.05" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">β</mi><mo id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><eq id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></eq><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">𝛽</ci><cn type="float" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\beta=0.05</annotation></semantics></math>). From the table, we have an interesting finding: (1) when the number of generated samples is relatively small (0<math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mo id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\sim</annotation></semantics></math>2000), FedGC can enlarge the gap between standard FedAvg and the method (SCAFFOLD) that is specifically designed for addressing data heterogeneity; (2) however, as the number continues to grow, the situation is reversed that the basic FL method FedAvg prevails. This finding suggests that apart from carefully designing FL algorithm, it is also a promising direction to explore the greater potential from the perspective of generative data.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Increasing number of generated samples makes FedAvg <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite> prevail.</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">No. Gen.</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">0</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">100</th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">200</th>
<th id="S4.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">500</th>
<th id="S4.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">1000</th>
<th id="S4.T2.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">2000</th>
<th id="S4.T2.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">5000</th>
<th id="S4.T2.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">10000</th>
<th id="S4.T2.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">20000</th>
<th id="S4.T2.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">50000</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">FedAvg</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">61.25</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">63.67</td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">66.21</td>
<td id="S4.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">67.13</td>
<td id="S4.T2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">66.98</td>
<td id="S4.T2.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">66.28</td>
<td id="S4.T2.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">71.65</td>
<td id="S4.T2.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.2.1.9.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">74.50</span></td>
<td id="S4.T2.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.2.1.10.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">76.93</span></td>
<td id="S4.T2.1.2.1.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.2.1.11.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">76.39</span></td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-left:5.0pt;padding-right:5.0pt;">FedProx</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.3.2.2.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">64.02</span></td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">66.47</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">67.40</td>
<td id="S4.T2.1.3.2.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">67.05</td>
<td id="S4.T2.1.3.2.6" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">68.55</td>
<td id="S4.T2.1.3.2.7" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">69.19</td>
<td id="S4.T2.1.3.2.8" class="ltx_td ltx_align_center" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.3.2.8.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">72.10</span></td>
<td id="S4.T2.1.3.2.9" class="ltx_td ltx_align_center" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.3.2.9.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">74.36</span></td>
<td id="S4.T2.1.3.2.10" class="ltx_td ltx_align_center" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.3.2.10.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">76.81</span></td>
<td id="S4.T2.1.3.2.11" class="ltx_td ltx_align_center" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.3.2.11.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">76.73</span></td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">SCAFFOLD</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.4.3.2.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">63.98</span></td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.4.3.3.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">69.05</span></td>
<td id="S4.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.4.3.4.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">71.33</span></td>
<td id="S4.T2.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.4.3.5.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">71.55</span></td>
<td id="S4.T2.1.4.3.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.4.3.6.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">71.33</span></td>
<td id="S4.T2.1.4.3.7" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#EBEBFF;padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T2.1.4.3.7.1" class="ltx_text ltx_font_bold" style="background-color:#EBEBFF;">70.04</span></td>
<td id="S4.T2.1.4.3.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">70.34</td>
<td id="S4.T2.1.4.3.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">73.96</td>
<td id="S4.T2.1.4.3.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">74.88</td>
<td id="S4.T2.1.4.3.11" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">73.98</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.SS3.2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.SS3.1.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:198.7pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T3" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Different prompt designs of FedGC applied on baselines. The design of multiple prompt formats is preferred for its effectiveness, diversity, and simplicity.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.SS3.1.fig1.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS3.1.fig1.1.1.1" class="ltx_tr">
<th id="S4.SS3.1.fig1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.3pt;padding-right:3.3pt;">Baseline</th>
<th id="S4.SS3.1.fig1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.3pt;padding-right:3.3pt;">No-GC</th>
<th id="S4.SS3.1.fig1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.3pt;padding-right:3.3pt;">Single</th>
<th id="S4.SS3.1.fig1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="background-color:#ECECEC;padding-left:3.3pt;padding-right:3.3pt;"><span id="S4.SS3.1.fig1.1.1.1.4.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">Multiple</span></th>
<th id="S4.SS3.1.fig1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.3pt;padding-right:3.3pt;">LLM</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS3.1.fig1.1.2.1" class="ltx_tr">
<td id="S4.SS3.1.fig1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.3pt;padding-right:3.3pt;">FedAvg</td>
<td id="S4.SS3.1.fig1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.3pt;padding-right:3.3pt;">27.06</td>
<td id="S4.SS3.1.fig1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.3pt;padding-right:3.3pt;">50.53</td>
<td id="S4.SS3.1.fig1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#ECECEC;padding-left:3.3pt;padding-right:3.3pt;"><span id="S4.SS3.1.fig1.1.2.1.4.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">54.08</span></td>
<td id="S4.SS3.1.fig1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.3pt;padding-right:3.3pt;">41.32</td>
</tr>
<tr id="S4.SS3.1.fig1.1.3.2" class="ltx_tr">
<td id="S4.SS3.1.fig1.1.3.2.1" class="ltx_td ltx_align_center" style="padding-left:3.3pt;padding-right:3.3pt;">FedProx</td>
<td id="S4.SS3.1.fig1.1.3.2.2" class="ltx_td ltx_align_center" style="padding-left:3.3pt;padding-right:3.3pt;">29.12</td>
<td id="S4.SS3.1.fig1.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:3.3pt;padding-right:3.3pt;">50.48</td>
<td id="S4.SS3.1.fig1.1.3.2.4" class="ltx_td ltx_align_center" style="background-color:#ECECEC;padding-left:3.3pt;padding-right:3.3pt;"><span id="S4.SS3.1.fig1.1.3.2.4.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">53.03</span></td>
<td id="S4.SS3.1.fig1.1.3.2.5" class="ltx_td ltx_align_center" style="padding-left:3.3pt;padding-right:3.3pt;">40.82</td>
</tr>
<tr id="S4.SS3.1.fig1.1.4.3" class="ltx_tr">
<td id="S4.SS3.1.fig1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.3pt;padding-right:3.3pt;">SCAFFOLD</td>
<td id="S4.SS3.1.fig1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.3pt;padding-right:3.3pt;">28.56</td>
<td id="S4.SS3.1.fig1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.3pt;padding-right:3.3pt;">54.13</td>
<td id="S4.SS3.1.fig1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#ECECEC;padding-left:3.3pt;padding-right:3.3pt;"><span id="S4.SS3.1.fig1.1.4.3.4.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">58.53</span></td>
<td id="S4.SS3.1.fig1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.3pt;padding-right:3.3pt;">45.87</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.SS3.2.fig2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:186.8pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T4" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Different generation guidance designs of FedGC applied on baselines. The mixed guidance that combines text2img and img&amp;text2img is the most effective strategy.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.SS3.2.fig2.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS3.2.fig2.1.1.1" class="ltx_tr">
<th id="S4.SS3.2.fig2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</th>
<th id="S4.SS3.2.fig2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Pri.</th>
<th id="S4.SS3.2.fig2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">T2I</th>
<th id="S4.SS3.2.fig2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">IT2I</th>
<th id="S4.SS3.2.fig2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.2.fig2.1.1.1.5.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">Mixed</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS3.2.fig2.1.2.1" class="ltx_tr">
<td id="S4.SS3.2.fig2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">FedAvg</td>
<td id="S4.SS3.2.fig2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">48.57</td>
<td id="S4.SS3.2.fig2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">51.91</td>
<td id="S4.SS3.2.fig2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">42.38</td>
<td id="S4.SS3.2.fig2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.2.fig2.1.2.1.5.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">56.67</span></td>
</tr>
<tr id="S4.SS3.2.fig2.1.3.2" class="ltx_tr">
<td id="S4.SS3.2.fig2.1.3.2.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">FedProx</td>
<td id="S4.SS3.2.fig2.1.3.2.2" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">49.52</td>
<td id="S4.SS3.2.fig2.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">51.43</td>
<td id="S4.SS3.2.fig2.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">44.76</td>
<td id="S4.SS3.2.fig2.1.3.2.5" class="ltx_td ltx_align_center" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.2.fig2.1.3.2.5.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">56.19</span></td>
</tr>
<tr id="S4.SS3.2.fig2.1.4.3" class="ltx_tr">
<td id="S4.SS3.2.fig2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">SCAFFOLD</td>
<td id="S4.SS3.2.fig2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">54.76</td>
<td id="S4.SS3.2.fig2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">56.67</td>
<td id="S4.SS3.2.fig2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">49.52</td>
<td id="S4.SS3.2.fig2.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.2.fig2.1.4.3.5.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">58.57</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</figure>
<figure id="S4.SS3.4" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.SS3.3.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:163.0pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T5" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Different budget allocation strategies of FedGC applied on baselines. Equal allocation is preferred for its effectiveness and simplicity.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.SS3.3.fig1.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS3.3.fig1.1.1.1" class="ltx_tr">
<th id="S4.SS3.3.fig1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</th>
<th id="S4.SS3.3.fig1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.3.fig1.1.1.1.2.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">Equal</span></th>
<th id="S4.SS3.3.fig1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Inverse</th>
<th id="S4.SS3.3.fig1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Water</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS3.3.fig1.1.2.1" class="ltx_tr">
<td id="S4.SS3.3.fig1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">FedAvg</td>
<td id="S4.SS3.3.fig1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.3.fig1.1.2.1.2.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">74.50</span></td>
<td id="S4.SS3.3.fig1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">68.10</td>
<td id="S4.SS3.3.fig1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">71.26</td>
</tr>
<tr id="S4.SS3.3.fig1.1.3.2" class="ltx_tr">
<td id="S4.SS3.3.fig1.1.3.2.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">FedProx</td>
<td id="S4.SS3.3.fig1.1.3.2.2" class="ltx_td ltx_align_center" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.3.fig1.1.3.2.2.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">74.36</span></td>
<td id="S4.SS3.3.fig1.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">68.51</td>
<td id="S4.SS3.3.fig1.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">72.23</td>
</tr>
<tr id="S4.SS3.3.fig1.1.4.3" class="ltx_tr">
<td id="S4.SS3.3.fig1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">SCAFFOLD</td>
<td id="S4.SS3.3.fig1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.3.fig1.1.4.3.2.1" class="ltx_text" style="background-color:#ECECEC;">73.96</span></td>
<td id="S4.SS3.3.fig1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">73.94</td>
<td id="S4.SS3.3.fig1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.3.fig1.1.4.3.4.1" class="ltx_text ltx_font_bold">74.43</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.SS3.4.fig2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:218.6pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T6" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Different training strategies of FedGC applied on baselines. <span id="S4.T6.3.1" class="ltx_text" style="color:#FF0000;">Generated</span> data can only exhibit its efficacy when used in conjunction with real data. <span id="S4.T6.4.2" class="ltx_text ltx_font_bold">Mixed</span> training is the most effective.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.SS3.4.fig2.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS3.4.fig2.1.1.1" class="ltx_tr">
<th id="S4.SS3.4.fig2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</th>
<th id="S4.SS3.4.fig2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Pri.</th>
<th id="S4.SS3.4.fig2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.1.1.3.1" class="ltx_text" style="color:#FF0000;">Gen.</span></th>
<th id="S4.SS3.4.fig2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">P2G</th>
<th id="S4.SS3.4.fig2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">G2P</th>
<th id="S4.SS3.4.fig2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.1.1.6.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">Mixed</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS3.4.fig2.1.2.1" class="ltx_tr">
<td id="S4.SS3.4.fig2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">FedAvg</td>
<td id="S4.SS3.4.fig2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">60.77</td>
<td id="S4.SS3.4.fig2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.2.1.3.1" class="ltx_text" style="color:#FF0000;">41.85</span></td>
<td id="S4.SS3.4.fig2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">67.06</td>
<td id="S4.SS3.4.fig2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">67.11</td>
<td id="S4.SS3.4.fig2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.2.1.6.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">73.99</span></td>
</tr>
<tr id="S4.SS3.4.fig2.1.3.2" class="ltx_tr">
<td id="S4.SS3.4.fig2.1.3.2.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">FedProx</td>
<td id="S4.SS3.4.fig2.1.3.2.2" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">63.62</td>
<td id="S4.SS3.4.fig2.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.3.2.3.1" class="ltx_text" style="color:#FF0000;">40.93</span></td>
<td id="S4.SS3.4.fig2.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">67.23</td>
<td id="S4.SS3.4.fig2.1.3.2.5" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">69.04</td>
<td id="S4.SS3.4.fig2.1.3.2.6" class="ltx_td ltx_align_center" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.3.2.6.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">73.69</span></td>
</tr>
<tr id="S4.SS3.4.fig2.1.4.3" class="ltx_tr">
<td id="S4.SS3.4.fig2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">SCAFFOLD</td>
<td id="S4.SS3.4.fig2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">65.00</td>
<td id="S4.SS3.4.fig2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.4.3.3.1" class="ltx_text" style="color:#FF0000;">43.45</span></td>
<td id="S4.SS3.4.fig2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">66.73</td>
<td id="S4.SS3.4.fig2.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">69.50</td>
<td id="S4.SS3.4.fig2.1.4.3.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#ECECEC;padding-left:4.0pt;padding-right:4.0pt;"><span id="S4.SS3.4.fig2.1.4.3.6.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">75.79</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</figure>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Equal allocation is a preferred allocation strategy for its effectiveness and simplicity.</span> In Table <a href="#S4.T5" title="Table 5 ‣ 4.3 Towards Different Designs of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we compare different budget allocation strategies on CIFAR-10, including equal allocation, inverse allocation, and water-filling-based allocation. Experiments show that equal allocation contributes to better performance for both FedAvg and FedProx, and comparable performance compared with water-filling-based allocation for SCAFFOLD. Considering effectiveness and simplicity, we conclude that equal allocation is a preferred allocation strategy.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Multiple prompts lead to better performance, while LLM-based diversification might be unnecessary.</span>
In Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Towards Different Designs of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we explore different prompt designs on PACS dataset. PACS contains significant label-level and feature-level variations, making it an apt choice for this exploration.
We compare baseline without FedGC, FedGC with single, multiple, and LLM-based prompts (see prompt generation in Table <a href="#A1.T7" title="Table 7 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).
From the table, (1) we see that FedGC incorporated with all the prompt designs improves the performance of baselines (see improvement over the No-GC column).
(2) We see that multiple prompts consistently and significantly perform better, while LLM-based prompts perform ordinarily.
This may result from the fact that the scene descriptions from the LLM are usually complicated, causing multifaceted patterns in one sample, thereby complicating model training.
Overall, we prefer the design of multiple prompts for its effectiveness, diversity, and simplicity.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para ltx_noindent">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Mixed guidance contributes to higher performance for rare tasks.</span>
In Table <a href="#S4.T4" title="Table 4 ‣ 4.3 Towards Different Designs of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we compare different generation guidance designs on a medical dataset HAM10000 <cite class="ltx_cite ltx_citemacro_citep">(Tschandl et al., <a href="#bib.bib40" title="" class="ltx_ref">2018</a>)</cite>.
The reason for choosing this dataset is that the diffusion model <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> fails to correctly understand medical prompts <cite class="ltx_cite ltx_citemacro_citep">(Kazerouni et al., <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>, which helps support our claim more convincingly. We consider three designs, including text-guided generation (T2I), our proposed data generation with guidance of text and real data (IT2I), and the <span id="S4.SS3.p4.1.2" class="ltx_text ltx_framed ltx_framed_underline">mixed usage</span> of T2I and IT2I. These experiments convey three interesting findings: (1) even though the diffusion model fails to generate data that visually agrees with real data, the generated data still contributes to enhancing the performance of FL (see improvement from Pri. to T2I). (2) IT2I itself fails to bring performance gain, which may result from the limited diversity and incapability to generate for missing classes. (3) Mixing these two strategies contributes to consistently and significantly better performance.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para ltx_noindent">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">Mixed training is the most effective training strategy.</span> In Table <a href="#S4.T6" title="Table 6 ‣ 4.3 Towards Different Designs of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we compare different training strategies on CIFAR-10, including training only on the private dataset (Pri.), training only on the generative dataset (Gen.), sequential training with private dataset first (P2G), sequential training with generative dataset first (G2P), and mixed training. Experiments show that 1) generative data itself fails to ensure training, indicating that there is a gap between generative data and real private data. 2) However, when using generative data together with real private data, we see consistent performance gain compared to training on private data. This indicates that despite the incapability of fully representing real data, the generative data still contributes to improving training by increasing diversity. 3) Mixed training consistently and significantly achieves better performance.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Towards Deeper Understanding of FedGC</h3>

<figure id="S4.F4" class="ltx_figure ltx_align_floatright"><img src="/html/2312.05807/assets/vis_local_model_acc_beta0.05.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="180" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Local models in FedGC better preserve capability in general tasks.</figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">Generated data is diverse, but may not be similar to real data.</span> In Figure <a href="#A1.F8" title="Figure 8 ‣ A.3 Membership Inference Attack ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we visualize the real data and generated data on EuroSAT.
We notice that the generated data samples do not always closely resemble real images, indicating the gap between generative data and real private data (at least visually).
Yet, their inclusion still improves the FL’s performance under data heterogeneity, which may result from two perspectives.
(1) The generative data might act as a form of data augmentation, which potentially introduces variations that are not covered by the original dataset.
(2) The generative data diversify the dataset, which serves as a form of implicit regularization, preventing the model from over-fitting to the potentially biased private local data.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">FedGC alleviates over-fitting local data distribution.</span> In Figure <a href="#S4.F4" title="Figure 4 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we compare the averaged test accuracy of local models on the global test dataset.
From the figure, we can see a clear accuracy gap between our FedGC and the baseline FedAvg.
(1) This indicates that our proposed FedGC can encourage each client to preserve the capability on the global general task, rather than overly fit the local specific task (local data distribution).
(2) This also helps explain why the generative data can bring performance gain even though they may fail to resemble real data.</p>
</div>
<figure id="S4.F5" class="ltx_figure ltx_align_floatright"><img src="/html/2312.05807/assets/feature_cos_sim.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="210" height="140" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>FedGC increases cosine similarity between local datasets (i.e., reduces data heterogeneity).</figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para ltx_noindent">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">FedGC reduces data heterogeneity.</span>
In Figure <a href="#S4.F5" title="Figure 5 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we explore the effects of FedGC on data heterogeneity from the perspective of data.
To measure the data heterogeneity, we first extract the features of data for each client using a pre-trained ResNet-18 <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib10" title="" class="ltx_ref">2016</a>)</cite>, average the features, and compute the pair-wise cosine similarity among the averaged features of all clients.
Figure <a href="#S4.F5" title="Figure 5 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the pair-wise similarity using Client 9 as the reference.
From the figure, we consistently see that FedGC can significantly increase the similarity between datasets of two clients, verifying that FedGC can contribute to mitigating data heterogeneity.
We also report <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><msub id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.SS4.p3.1.m1.1.1.2" xref="S4.SS4.p3.1.m1.1.1.2.cmml">ℓ</mi><mn id="S4.SS4.p3.1.m1.1.1.3" xref="S4.SS4.p3.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><apply id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.1.m1.1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.p3.1.m1.1.1.2.cmml" xref="S4.SS4.p3.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S4.SS4.p3.1.m1.1.1.3.cmml" xref="S4.SS4.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">\ell_{2}</annotation></semantics></math> distance as metric and results on PACS in Figure <a href="#A1.F9" title="Figure 9 ‣ A.5 FedGC Mitigates Data Heterogeneity ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#A1.F10" title="Figure 10 ‣ A.5 FedGC Mitigates Data Heterogeneity ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/vis_div_beta0.05_global_model2.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_img_square" width="186" height="157" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Model Divergence at <math id="S4.F6.sf1.2.m1.1" class="ltx_Math" alttext="\beta=0.05" display="inline"><semantics id="S4.F6.sf1.2.m1.1b"><mrow id="S4.F6.sf1.2.m1.1.1" xref="S4.F6.sf1.2.m1.1.1.cmml"><mi id="S4.F6.sf1.2.m1.1.1.2" xref="S4.F6.sf1.2.m1.1.1.2.cmml">β</mi><mo id="S4.F6.sf1.2.m1.1.1.1" xref="S4.F6.sf1.2.m1.1.1.1.cmml">=</mo><mn id="S4.F6.sf1.2.m1.1.1.3" xref="S4.F6.sf1.2.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.sf1.2.m1.1c"><apply id="S4.F6.sf1.2.m1.1.1.cmml" xref="S4.F6.sf1.2.m1.1.1"><eq id="S4.F6.sf1.2.m1.1.1.1.cmml" xref="S4.F6.sf1.2.m1.1.1.1"></eq><ci id="S4.F6.sf1.2.m1.1.1.2.cmml" xref="S4.F6.sf1.2.m1.1.1.2">𝛽</ci><cn type="float" id="S4.F6.sf1.2.m1.1.1.3.cmml" xref="S4.F6.sf1.2.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf1.2.m1.1d">\beta=0.05</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/vis_div_beta0.1_global_model2.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_img_square" width="186" height="157" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Model Divergence at <math id="S4.F6.sf2.2.m1.1" class="ltx_Math" alttext="\beta=0.1" display="inline"><semantics id="S4.F6.sf2.2.m1.1b"><mrow id="S4.F6.sf2.2.m1.1.1" xref="S4.F6.sf2.2.m1.1.1.cmml"><mi id="S4.F6.sf2.2.m1.1.1.2" xref="S4.F6.sf2.2.m1.1.1.2.cmml">β</mi><mo id="S4.F6.sf2.2.m1.1.1.1" xref="S4.F6.sf2.2.m1.1.1.1.cmml">=</mo><mn id="S4.F6.sf2.2.m1.1.1.3" xref="S4.F6.sf2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.sf2.2.m1.1c"><apply id="S4.F6.sf2.2.m1.1.1.cmml" xref="S4.F6.sf2.2.m1.1.1"><eq id="S4.F6.sf2.2.m1.1.1.1.cmml" xref="S4.F6.sf2.2.m1.1.1.1"></eq><ci id="S4.F6.sf2.2.m1.1.1.2.cmml" xref="S4.F6.sf2.2.m1.1.1.2">𝛽</ci><cn type="float" id="S4.F6.sf2.2.m1.1.1.3.cmml" xref="S4.F6.sf2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf2.2.m1.1d">\beta=0.1</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/acc_div.png" id="S4.F6.sf3.g1" class="ltx_graphics ltx_img_square" width="186" height="158" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Divergence v.s. Accuracy</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>FedGC implicitly reduces model divergence. Notably, even with higher divergence in final rounds, we still observe higher accuracy, reflecting the potential dual nature of data diversity.</figcaption>
</figure>
<div id="S4.SS4.p4" class="ltx_para ltx_noindent">
<p id="S4.SS4.p4.2" class="ltx_p"><span id="S4.SS4.p4.2.1" class="ltx_text ltx_font_bold">FedGC implicitly reduces model divergence.</span> In Figure <a href="#S4.F6" title="Figure 6 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we visualize the local model divergence along with the round increases.
Specifically, at each round, we compute the <math id="S4.SS4.p4.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S4.SS4.p4.1.m1.1a"><msub id="S4.SS4.p4.1.m1.1.1" xref="S4.SS4.p4.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.SS4.p4.1.m1.1.1.2" xref="S4.SS4.p4.1.m1.1.1.2.cmml">ℓ</mi><mn id="S4.SS4.p4.1.m1.1.1.3" xref="S4.SS4.p4.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.1.m1.1b"><apply id="S4.SS4.p4.1.m1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p4.1.m1.1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.p4.1.m1.1.1.2.cmml" xref="S4.SS4.p4.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S4.SS4.p4.1.m1.1.1.3.cmml" xref="S4.SS4.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.1.m1.1c">\ell_{2}</annotation></semantics></math> difference between each local model and the aggregated global model <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib22" title="" class="ltx_ref">2020b</a>)</cite> and report the averaged difference.
(1) From Figure <a href="#S4.F6.sf1" title="In Figure 6 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, we see that FedGC consistently and significantly reduces the model divergence of local models under severe heterogeneity level (<math id="S4.SS4.p4.2.m2.1" class="ltx_Math" alttext="\beta=0.05" display="inline"><semantics id="S4.SS4.p4.2.m2.1a"><mrow id="S4.SS4.p4.2.m2.1.1" xref="S4.SS4.p4.2.m2.1.1.cmml"><mi id="S4.SS4.p4.2.m2.1.1.2" xref="S4.SS4.p4.2.m2.1.1.2.cmml">β</mi><mo id="S4.SS4.p4.2.m2.1.1.1" xref="S4.SS4.p4.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS4.p4.2.m2.1.1.3" xref="S4.SS4.p4.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.2.m2.1b"><apply id="S4.SS4.p4.2.m2.1.1.cmml" xref="S4.SS4.p4.2.m2.1.1"><eq id="S4.SS4.p4.2.m2.1.1.1.cmml" xref="S4.SS4.p4.2.m2.1.1.1"></eq><ci id="S4.SS4.p4.2.m2.1.1.2.cmml" xref="S4.SS4.p4.2.m2.1.1.2">𝛽</ci><cn type="float" id="S4.SS4.p4.2.m2.1.1.3.cmml" xref="S4.SS4.p4.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.2.m2.1c">\beta=0.05</annotation></semantics></math>).
This result well supports the claim that FedGC is a pleasant FL framework for tackling the issue of data heterogeneity since it has been shown that data heterogeneity leads to larger model divergence and thus mediocre performance empirically <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib22" title="" class="ltx_ref">2020b</a>)</cite> and theoretically <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib43" title="" class="ltx_ref">2021</a>; Li et al., <a href="#bib.bib21" title="" class="ltx_ref">2020a</a>)</cite>.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para ltx_noindent">
<p id="S4.SS4.p5.1" class="ltx_p">(2) From Figure <a href="#S4.F6.sf2" title="In Figure 6 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, though the divergence of FedGC increases at the final rounds, we still observe improved accuracy during these rounds.
This observation is interesting as it seems to contradict the current viewpoint.
Based on this, we hypothesize that data diversity has two sides:
(1) it can reduce data heterogeneity, thus reducing model divergence;
(2) but it can also increase model divergence as the data is more diverse.
Nevertheless, data diversity still contributes to enhanced model performance despite the increased divergence as suggested in Figure <a href="#S4.F6.sf3" title="In Figure 6 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a> (see the red scatters).
This interesting finding calls for more theoretical future works to model data diversity rather than only model divergence in the FL theory <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>; Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussions and Future Directions</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">As an initial exploration of tackling data heterogeneity in FL using generative content, we mainly focus on designing under two standards: simplicity and effectiveness.
However, there are also diverse interesting future directions that are worth exploring.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Filtering.</span>
Previously, we find that the positive effects of data diversity on data heterogeneity outweigh the negative effects of some low-quality generated samples and the gap between generated and real data.
Still, it could benefit if we can propose to appropriately filter out low-quality samples, such as applying the KNN method <cite class="ltx_cite ltx_citemacro_citep">(Fix &amp; Hodges, <a href="#bib.bib9" title="" class="ltx_ref">1989</a>)</cite> using real data as reference.
We propose an initial attempt using the global model as a discriminator to filter data in Section <a href="#A1.SS9" title="A.9 Global-model-based Data Filtering ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Personalized generation.</span>
It would also be advantageous to narrow the gap between generated and real data.
Beyond our proposed real-data-guided generation, delving into personalized data generation to more closely resemble real data is worth investigating.
For example, we can fine-tune generative models on real data using parameter-efficient fine-tuning techniques <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Theory.</span>
As shown in Figure <a href="#S4.F6.sf2" title="In Figure 6 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> and <a href="#S4.F6.sf3" title="In Figure 6 ‣ 4.4 Towards Deeper Understanding of FedGC ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a>, model divergence <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib23" title="" class="ltx_ref">2019</a>; <a href="#bib.bib22" title="" class="ltx_ref">2020b</a>; Wang et al., <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite> may not fully represent the property of distributed data, calling for more future theory works.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations and Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text ltx_font_italic">Limitations and Future Works.</span> Despite putting much effort into diversifying the experimental settings, there are still cases not covered.
For example, we only explore one diffusion model and LLM respectively.
There could be future works to explore the effects of different generative models.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_italic">Conclusion.</span>
This paper focuses on the notorious issue of data heterogeneity in FL.
We propose a new, simple yet effective FL framework termed FedGC, which leverages generative data to promote FL under heterogeneous private data.
We summarize four crucial aspects that are worth exploring and propose three solutions for each aspect.
Extensive experiments show that our FedGC framework can consistently and significantly improve the performance of diverse FL baselines under data heterogeneity.
Moreover, we provide a systematic empirical analysis based on FedGC and provide new insights throughout the experimental section.
Our research serves as an initial exploration of boosting federated learning on private data in the era of generative content.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">This research is supported by the National Key R&amp;D Program of China under Grant 2021ZD0112801, NSFC under Grant 62171276 and the Science and Technology Commission of Shanghai Municipal under Grant 21511100900 and 22DZ2229005.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acar et al. (2020)</span>
<span class="ltx_bibblock">
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and Venkatesh Saligrama.

</span>
<span class="ltx_bibblock">Federated learning based on dynamic regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:1877–1901, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Celard et al. (2023)</span>
<span class="ltx_bibblock">
Pedro Celard, EL Iglesias, JM Sorribes-Fdez, Rubén Romero, A Seara Vieira, and L Borrajo.

</span>
<span class="ltx_bibblock">A survey on deep learning applied to medical images: from simple artificial neural networks to generative models.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Neural Computing and Applications</em>, 35(3):2291–2323, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Hong-You Chen, Cheng-Hao Tu, Ziwei Li, Han Wei Shen, and Wei-Lun Chao.

</span>
<span class="ltx_bibblock">On the importance and applicability of pre-training for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">A simple framework for contrastive learning of visual representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pp.  1597–1607. PMLR, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eysenbach et al. (2023)</span>
<span class="ltx_bibblock">
Gunther Eysenbach et al.

</span>
<span class="ltx_bibblock">The role of chatgpt, generative language models, and artificial intelligence in medical education: a conversation with chatgpt and a call for papers.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">JMIR Medical Education</em>, 9(1):e46885, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. (2013)</span>
<span class="ltx_bibblock">
Chen Fang, Ye Xu, and Daniel N Rockmore.

</span>
<span class="ltx_bibblock">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer Vision</em>, pp.  1657–1664, 2013.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fix &amp; Hodges (1989)</span>
<span class="ltx_bibblock">
Evelyn Fix and Joseph Lawson Hodges.

</span>
<span class="ltx_bibblock">Discriminatory analysis. nonparametric discrimination: Consistency properties.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Statistical Review/Revue Internationale de Statistique</em>, 57(3):238–247, 1989.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  770–778, 2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2022)</span>
<span class="ltx_bibblock">
Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, and XIAOJUAN QI.

</span>
<span class="ltx_bibblock">Is synthetic data from generative models ready for image recognition?

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Helber et al. (2019)</span>
<span class="ltx_bibblock">
Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth.

</span>
<span class="ltx_bibblock">Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, 12(7):2217–2226, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. (2019)</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data distribution for federated visual classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.06335</em>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jhunjhunwala et al. (2022)</span>
<span class="ltx_bibblock">
Divyansh Jhunjhunwala, Shiqiang Wang, and Gauri Joshi.

</span>
<span class="ltx_bibblock">Fedexp: Speeding up federated averaging via extrapolation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al. (2021)</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>, 14(1–2):1–210, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al. (2020)</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.  5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kazerouni et al. (2022)</span>
<span class="ltx_bibblock">
Amirhossein Kazerouni, Ehsan Khodapanah Aghdam, Moein Heidari, Reza Azad, Mohsen Fayyaz, Ilker Hacihaliloglu, and Dorit Merhof.

</span>
<span class="ltx_bibblock">Diffusion models for medical image analysis: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.07804</em>, 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al. (2009)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Qinbin Li, Bingsheng He, and Dawn Song.

</span>
<span class="ltx_bibblock">Model-contrastive federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  10713–10722, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020a)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, 37(3):50–60, 2020a.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020b)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>, 2:429–450, 2020b.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2019)</span>
<span class="ltx_bibblock">
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.

</span>
<span class="ltx_bibblock">On the convergence of fedavg on non-iid data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>, pp.  1273–1282. PMLR, 2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. (2022)</span>
<span class="ltx_bibblock">
John Nguyen, Jianyu Wang, Kshitiz Malik, Maziar Sanjabi, and Michael Rabbat.

</span>
<span class="ltx_bibblock">Where to begin? on the impact of pre-training and initialization in federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol et al. (2022)</span>
<span class="ltx_bibblock">
Alexander Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya Sutskever, and Mark Chen.

</span>
<span class="ltx_bibblock">Glide: Towards photorealistic image generation and editing with text-guided diffusion models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.  16784–16804. PMLR, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:27730–27744, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Proakis (2008)</span>
<span class="ltx_bibblock">
John G Proakis.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Digital communications</em>.

</span>
<span class="ltx_bibblock">McGraw-Hill, Higher Education, 2008.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pp.  8748–8763. PMLR, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddi et al. (2020)</span>
<span class="ltx_bibblock">
Sashank J Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konečnỳ, Sanjiv Kumar, and Hugh Brendan McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  10684–10695, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ronneberger et al. (2015)</span>
<span class="ltx_bibblock">
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.

</span>
<span class="ltx_bibblock">U-net: Convolutional networks for biomedical image segmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18</em>, pp.  234–241. Springer, 2015.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sablayrolles et al. (2019)</span>
<span class="ltx_bibblock">
Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Yann Ollivier, and Hervé Jégou.

</span>
<span class="ltx_bibblock">White-box vs black-box: Bayes optimal strategies for membership inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.  5558–5567. PMLR, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et al. (2022)</span>
<span class="ltx_bibblock">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.

</span>
<span class="ltx_bibblock">Photorealistic text-to-image diffusion models with deep language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:36479–36494, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2022)</span>
<span class="ltx_bibblock">
Yujun Shi, Jian Liang, Wenqing Zhang, Vincent YF Tan, and Song Bai.

</span>
<span class="ltx_bibblock">Towards understanding and mitigating dimensional collapse in heterogeneous federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.00226</em>, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shipard et al. (2023)</span>
<span class="ltx_bibblock">
Jordan Shipard, Arnold Wiliem, Kien Nguyen Thanh, Wei Xiang, and Clinton Fookes.

</span>
<span class="ltx_bibblock">Diversity is definitely needed: Improving model-agnostic zero-shot classification via stable diffusion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  769–778, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tschandl et al. (2018)</span>
<span class="ltx_bibblock">
Philipp Tschandl, Cliff Rosendahl, and Harald Kittler.

</span>
<span class="ltx_bibblock">The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Scientific data</em>, 5(1):1–9, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020a)</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020a.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=BkluqlSFDS" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=BkluqlSFDS</a>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020b)</span>
<span class="ltx_bibblock">
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Tackling the objective inconsistency problem in heterogeneous federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:7611–7623, 2020b.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H Brendan McMahan, Maruan Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data, et al.

</span>
<span class="ltx_bibblock">A field guide to federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06917</em>, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, 10(2):1–19, 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2022)</span>
<span class="ltx_bibblock">
Rui Ye, Zhenyang Ni, Chenxin Xu, Jianyu Wang, Siheng Chen, and Yonina C Eldar.

</span>
<span class="ltx_bibblock">Fedfm: Anchor-based feature matching for data heterogeneity in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.07615</em>, 2022.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023)</span>
<span class="ltx_bibblock">
Rui Ye, Mingkai Xu, Jianyu Wang, Chenxin Xu, Siheng Chen, and Yanfeng Wang.

</span>
<span class="ltx_bibblock">Feddisco: Federated learning with discrepancy-aware collaboration.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.19229</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021)</span>
<span class="ltx_bibblock">
Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">How does data augmentation affect privacy in machine learning?

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 35, pp.  10746–10753, 2021.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2015)</span>
<span class="ltx_bibblock">
Xiang Zhang, Junbo Zhao, and Yann LeCun.

</span>
<span class="ltx_bibblock">Character-level convolutional networks for text classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 28, 2015.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
Xiaojin Zhang, Yan Kang, Kai Chen, Lixin Fan, and Qiang Yang.

</span>
<span class="ltx_bibblock">Trading off privacy, utility and efficiency in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.00230</em>, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2020)</span>
<span class="ltx_bibblock">
Kaiyang Zhou, Yongxin Yang, Timothy Hospedales, and Tao Xiang.

</span>
<span class="ltx_bibblock">Deep domain-adversarial image generation for domain generalisation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</em>, volume 34, pp.  13025–13032, 2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>More Illustration of FedGC</h3>

<div id="A1.SS1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.p1.1" class="ltx_p">For the prompts conditioned on the latent diffusion model, we show the LLM-based prompts for generating images in Table <a href="#A1.T7" title="Table 7 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
In detail, we instruct ChatGPT through System Prompt and User Prompt, to help us create text samples containing the corresponding class name for image generation. Utilizing ChatGPT’s rich imagination of scenarios and the diversity of text styles, we can achieve a diversity of prompts. Therefore, it helps Stable-diffusion to generate diverse and more realistic pictures.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para ltx_noindent">
<p id="A1.SS1.p2.1" class="ltx_p">For generation guidance beyond prompts, we show the real-data guidance for image generation using diffusion models in Figure <a href="#A1.F7" title="Figure 7 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. First of all, the latent features are meticulously initialized using actual real-image data.
Subsequently, controlled noise is introduced into the latent representations, which serves to perturb and diversify the features while maintaining the underlying structure. Following this, with conditioned prompts, we denoise this combined feature using U-Net <cite class="ltx_cite ltx_citemacro_citep">(Ronneberger et al., <a href="#bib.bib34" title="" class="ltx_ref">2015</a>)</cite>. Finally, passing through the image decoder, we obtain generated images.</p>
</div>
<div id="A1.SS1.p3" class="ltx_para ltx_noindent">
<p id="A1.SS1.p3.1" class="ltx_p">We show the real-data-guidance for text generation using ChatGPT in Table <a href="#A1.T8" title="Table 8 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
Compared to prompts containing class num, here we instruct ChatGPT to imitate the theme and content of the corresponding text and directly expand the amount of text data.
In our illustrative examples shown in Table <a href="#A1.T8" title="Table 8 ‣ A.1 More Illustration of FedGC ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we simulate real-world data scenarios by incorporating four actual instances and generating an additional set of four synthetic instances. In this experimental setup, we task ChatGPT with the generation of data that exhibits diverse patterns akin to those found in authentic real data. Furthermore, we guide ChatGPT to produce two distinct samples for each distinct label category, fostering a balanced and representative dataset.</p>
</div>
<figure id="A1.F7" class="ltx_figure"><img src="/html/2312.05807/assets/x2.png" id="A1.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="137" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Real-data-guidance for image generation based on diffusion model. The real-data-guidance method involves 4 steps: (1) initializing latent features with real-image data, (2) adding controlled noise, (3) denoising with text features, and (4) generating new images using the decoder.</figcaption>
</figure>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Obtaining LLM-based prompts for generating images using diffusion models. Instructions for generating scene descriptions (i.e., prompts for diffusion models) given a class name using ChatGPT. Here, we provide an example on the dog category of PACS dataset.</figcaption><svg id="A1.T7.pic1" class="ltx_picture" height="239.11" overflow="visible" version="1.1" width="600"><g transform="translate(0,239.11) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 233.21 C 0 236.47 2.64 239.11 5.91 239.11 L 594.09 239.11 C 597.36 239.11 600 236.47 600 233.21 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FAFAFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 233.21 C 1.97 235.38 3.73 237.14 5.91 237.14 L 594.09 237.14 C 596.27 237.14 598.03 235.38 598.03 233.21 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="211.55" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" class="ltx_p"><span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">System Prompt:
<br class="ltx_break"></span>You are an AI assistant that helps people find information.</span>
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" class="ltx_p"><span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">User Prompt:
<br class="ltx_break"></span>Please help me come up with scene descriptions that contain a dog while not containing an elephant, giraffe, guitar, horse, house, person.</span>
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.4" class="ltx_p">For example:</span>
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_p"><math id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\left[\text{``A dog is running on the grass'', ``A dog is sleeping on the floor''}\right]" display="inline"><semantics id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.2" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.1.cmml"><mo id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.2.1" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.1.1.cmml">[</mo><mtext id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1a.cmml">“A dog is running on the grass”, “A dog is sleeping on the floor”</mtext><mo id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.2.2" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.1.cmml" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.2"><csymbol cd="latexml" id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.1.1.cmml" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.2.2.1">delimited-[]</csymbol><ci id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1a.cmml" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><mtext id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">“A dog is running on the grass”, “A dog is sleeping on the floor”</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\left[\text{``A dog is running on the grass'', ``A dog is sleeping on the floor''}\right]</annotation></semantics></math></span>
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.5" class="ltx_p">Please generate 10 samples in the format of a list.</span>
<span id="A1.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.6" class="ltx_p">Remember: each description should be within 10 words.</span>
</span></foreignObject></g></g></svg>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Real-data-guidance for text generation using ChatGPT. Real data is modeled in the examples, where we provide four real examples and generate four new examples. We instruct the ChatGPT to generate diverse data that has a similar pattern to real data. We also instruct the ChatGPT to generate two samples for each label.</figcaption><svg id="A1.T8.pic1" class="ltx_picture" height="340.28" overflow="visible" version="1.1" width="600"><g transform="translate(0,340.28) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 334.37 C 0 337.63 2.64 340.28 5.91 340.28 L 594.09 340.28 C 597.36 340.28 600 337.63 600 334.37 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FAFAFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 334.37 C 1.97 336.54 3.73 338.31 5.91 338.31 L 594.09 338.31 C 596.27 338.31 598.03 336.54 598.03 334.37 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="312.72" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.T8.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="A1.T8.pic1.1.1.1.1.1.1" class="ltx_p"><span id="A1.T8.pic1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">System Prompt:
<br class="ltx_break"></span>Assistant is an intelligent chatbot designed to help users generate similar data. Users will provide a few real samples and the Assistant will generate data that follows the pattern of real samples. This is a binary dataset on sentiment analysis, where 0 denotes negative and 1 denotes positive.</span>
<span id="A1.T8.pic1.1.1.1.1.1.2" class="ltx_p">Instructions:</span>
<span id="A1.T8.pic1.1.1.1.1.1.3" class="ltx_p">1. Generate two samples with label 0 and two samples with label 1, try to make the content diverse</span>
<span id="A1.T8.pic1.1.1.1.1.1.4" class="ltx_p">2. Should have a similar pattern of users’ data.</span>
<span id="A1.T8.pic1.1.1.1.1.1.5" class="ltx_p"><span id="A1.T8.pic1.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">User Prompt:
<br class="ltx_break"></span>**Data: {example_input_1}, Label: {example_label_1}**</span>
<span id="A1.T8.pic1.1.1.1.1.1.6" class="ltx_p">**Data: {example_input_2}, Label: {example_label_2}**</span>
<span id="A1.T8.pic1.1.1.1.1.1.7" class="ltx_p">**Data: {example_input_3}, Label: {example_label_3}**</span>
<span id="A1.T8.pic1.1.1.1.1.1.8" class="ltx_p">**Data: {example_input_4}, Label: {example_label_4}**</span>
<span id="A1.T8.pic1.1.1.1.1.1.9" class="ltx_p">Generate two samples with label 0 and two samples with label 1.</span>
<span id="A1.T8.pic1.1.1.1.1.1.10" class="ltx_p">In the format of Data: {}, Label: {}. Each sample should start with ** and end with **.</span>
</span></foreignObject></g></g></svg>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Implementation Details</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS2.p1.1" class="ltx_p">We list the number of clients for each dataset in Table <a href="#A1.T9" title="Table 9 ‣ A.2 Implementation Details ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="A1.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Number of clients for each dataset.</figcaption>
<table id="A1.T9.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T9.1.1.1" class="ltx_tr">
<th id="A1.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">Dataset</th>
<th id="A1.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">CIFAR-10</th>
<th id="A1.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">EuroSAT</th>
<th id="A1.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">PACS</th>
<th id="A1.T9.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">VLCS</th>
<th id="A1.T9.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">HAM10000</th>
<th id="A1.T9.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">Sentiment</th>
<th id="A1.T9.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;">Yahoo!</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T9.1.2.1" class="ltx_tr">
<th id="A1.T9.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Client Number</th>
<td id="A1.T9.1.2.1.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">10</td>
<td id="A1.T9.1.2.1.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">10</td>
<td id="A1.T9.1.2.1.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">20</td>
<td id="A1.T9.1.2.1.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">20</td>
<td id="A1.T9.1.2.1.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">10</td>
<td id="A1.T9.1.2.1.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">1000</td>
<td id="A1.T9.1.2.1.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">100</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Membership Inference Attack</h3>

<div id="A1.SS3.p1" class="ltx_para ltx_noindent">
<p id="A1.SS3.p1.1" class="ltx_p">To measure the privacy preservation of FedAvg and FedGC, we carry out a simple membership inference attack based on loss evaluation, as <cite class="ltx_cite ltx_citemacro_citep">(Sablayrolles et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> has shown that it is reasonable to use the loss of the model to infer membership. We consider a scene where an attacker who has a tiny amount of training data can get the global model and wants to figure out whether a similar datum (i.e. also a photo of an airplane) has been used to train the model or not. During the attack, the attacker feeds its few data to the global model and trains a binary classifier based on the loss of each training-used and not-training-used datum.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para ltx_noindent">
<p id="A1.SS3.p2.1" class="ltx_p">We conduct our experiment on CIFAR-10 dataset. In the training process, we set the client number to 10 and the Dirichlet distribution parameter to <math id="A1.SS3.p2.1.m1.1" class="ltx_Math" alttext="\beta=0.1" display="inline"><semantics id="A1.SS3.p2.1.m1.1a"><mrow id="A1.SS3.p2.1.m1.1.1" xref="A1.SS3.p2.1.m1.1.1.cmml"><mi id="A1.SS3.p2.1.m1.1.1.2" xref="A1.SS3.p2.1.m1.1.1.2.cmml">β</mi><mo id="A1.SS3.p2.1.m1.1.1.1" xref="A1.SS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="A1.SS3.p2.1.m1.1.1.3" xref="A1.SS3.p2.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.1.m1.1b"><apply id="A1.SS3.p2.1.m1.1.1.cmml" xref="A1.SS3.p2.1.m1.1.1"><eq id="A1.SS3.p2.1.m1.1.1.1.cmml" xref="A1.SS3.p2.1.m1.1.1.1"></eq><ci id="A1.SS3.p2.1.m1.1.1.2.cmml" xref="A1.SS3.p2.1.m1.1.1.2">𝛽</ci><cn type="float" id="A1.SS3.p2.1.m1.1.1.3.cmml" xref="A1.SS3.p2.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.1.m1.1c">\beta=0.1</annotation></semantics></math>. We also discard data augmentations (i.e. flipping and cropping) for more clear comparisons. In the main body, we compare both task accuracy and attack accuracy, as shown in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2 Experimental Results ‣ 4 Experiments ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="A1.SS3.p3" class="ltx_para ltx_noindent">
<p id="A1.SS3.p3.1" class="ltx_p">We also compare the attack accuracy at the point when FedAvg and FedGC achieve similar task accuracy in Table <a href="#A1.T10" title="Table 10 ‣ A.3 Membership Inference Attack ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.
From the table, we see a much more significant reduction in privacy leakage (i.e., much lower attack accuracy).
This is reasonable as FedGC can accelerate the convergence speed, which means FedGC requires fewer steps of optimization on the sensitive private data to achieve the same.</p>
</div>
<figure id="A1.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span>Membership inference attack accuracy comparisons when FedAvg and FedGC achieve similar task accuracy. We consider two scenarios where the total number of clients’ real samples is 50k and 10k, respectively. We also explore the effects of using different number of generated samples. FedGC can reduce privacy leakage to a very low level (since random guess is 50%) while maintaining task accuracy at the same time. </figcaption>
<table id="A1.T10.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T10.1.1.1" class="ltx_tr">
<th id="A1.T10.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" colspan="2">Number of Real Samples</th>
<th id="A1.T10.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" colspan="2">50k</th>
<th id="A1.T10.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2">10k</th>
</tr>
<tr id="A1.T10.1.2.2" class="ltx_tr">
<th id="A1.T10.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" colspan="2">Accuracy</th>
<th id="A1.T10.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Task</th>
<th id="A1.T10.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Attack</th>
<th id="A1.T10.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Task</th>
<th id="A1.T10.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Attack</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T10.1.3.1" class="ltx_tr">
<th id="A1.T10.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="6"><span id="A1.T10.1.3.1.1.1" class="ltx_text">No. of Generated Samples</span></th>
<td id="A1.T10.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<th id="A1.T10.1.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">59.71</th>
<td id="A1.T10.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.55</td>
<th id="A1.T10.1.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">35.48</th>
<td id="A1.T10.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">77.55</td>
</tr>
<tr id="A1.T10.1.4.2" class="ltx_tr">
<td id="A1.T10.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r">10k</td>
<th id="A1.T10.1.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">61.65</th>
<td id="A1.T10.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">52.05</td>
<th id="A1.T10.1.4.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">35.97</th>
<td id="A1.T10.1.4.2.5" class="ltx_td ltx_align_center">52.80</td>
</tr>
<tr id="A1.T10.1.5.3" class="ltx_tr">
<td id="A1.T10.1.5.3.1" class="ltx_td ltx_align_center ltx_border_r">20k</td>
<th id="A1.T10.1.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">62.49</th>
<td id="A1.T10.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r">51.20</td>
<th id="A1.T10.1.5.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">39.18</th>
<td id="A1.T10.1.5.3.5" class="ltx_td ltx_align_center">52.85</td>
</tr>
<tr id="A1.T10.1.6.4" class="ltx_tr">
<td id="A1.T10.1.6.4.1" class="ltx_td ltx_align_center ltx_border_r">30k</td>
<th id="A1.T10.1.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">61.82</th>
<td id="A1.T10.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r">51.95</td>
<th id="A1.T10.1.6.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">39.40</th>
<td id="A1.T10.1.6.4.5" class="ltx_td ltx_align_center">52.50</td>
</tr>
<tr id="A1.T10.1.7.5" class="ltx_tr">
<td id="A1.T10.1.7.5.1" class="ltx_td ltx_align_center ltx_border_r">40k</td>
<th id="A1.T10.1.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">60.38</th>
<td id="A1.T10.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r">51.20</td>
<th id="A1.T10.1.7.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">37.17</th>
<td id="A1.T10.1.7.5.5" class="ltx_td ltx_align_center">52.75</td>
</tr>
<tr id="A1.T10.1.8.6" class="ltx_tr">
<td id="A1.T10.1.8.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">50k</td>
<th id="A1.T10.1.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">62.49</th>
<td id="A1.T10.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">51.60</td>
<th id="A1.T10.1.8.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">38.68</th>
<td id="A1.T10.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb">52.35</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/vis_eurosat_real.png" id="A1.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="88" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>EuroSAT: real data samples</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/vis_eurosat_good.png" id="A1.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="88" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>EuroSAT: generated similar samples</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/vis_eurosat_bad.png" id="A1.F8.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="88" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>EuroSAT: generated dissimilar samples</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Visualization of real and generated data. (a) Visualization of real data samples from the EuroSAT dataset. (b) Visualization of generated data samples that are more aligned with the corresponding semantic or real data. (c) Visualization of generated data samples that are not aligned with the corresponding semantic or real data.</figcaption>
</figure>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Visualization of Real and Generated Data</h3>

<div id="A1.SS4.p1" class="ltx_para ltx_noindent">
<p id="A1.SS4.p1.1" class="ltx_p">We visualize the real data and generated data on EuroSAT <cite class="ltx_cite ltx_citemacro_citep">(Helber et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> in Figure <a href="#A1.F8" title="Figure 8 ‣ A.3 Membership Inference Attack ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. For the uncommon and detailed satellite images in EuroSAT <cite class="ltx_cite ltx_citemacro_citep">(Helber et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>, the quality of the data generated by the diffusion models varies. From the naked eye, the data generated by some diffusion can capture the semantic information brought by the label very well. For example, the generated images with the label ”River” as guidance do contain rivers, but hard to achieve a similar satellite style to actual images.
Although the gap between generated and actual data definitely exists, generated data obviously improves specific task performance, which is demonstrated by our extensive experiments.</p>
</div>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>FedGC Mitigates Data Heterogeneity</h3>

<div id="A1.SS5.p1" class="ltx_para ltx_noindent">
<p id="A1.SS5.p1.2" class="ltx_p">We visualize the cosine similarity and <math id="A1.SS5.p1.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.SS5.p1.1.m1.1a"><msub id="A1.SS5.p1.1.m1.1.1" xref="A1.SS5.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="A1.SS5.p1.1.m1.1.1.2" xref="A1.SS5.p1.1.m1.1.1.2.cmml">ℓ</mi><mn id="A1.SS5.p1.1.m1.1.1.3" xref="A1.SS5.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.1.m1.1b"><apply id="A1.SS5.p1.1.m1.1.1.cmml" xref="A1.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS5.p1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS5.p1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.1.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.SS5.p1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.1.m1.1c">\ell_{2}</annotation></semantics></math> distance of features on EuroSAT and PACS in Figure <a href="#A1.F9" title="Figure 9 ‣ A.5 FedGC Mitigates Data Heterogeneity ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and Figure <a href="#A1.F10" title="Figure 10 ‣ A.5 FedGC Mitigates Data Heterogeneity ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> respectively.
We measure the discrepancy among local data in clients on the feature level, using 2 metrics: cosine similarity and <math id="A1.SS5.p1.2.m2.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.SS5.p1.2.m2.1a"><msub id="A1.SS5.p1.2.m2.1.1" xref="A1.SS5.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="A1.SS5.p1.2.m2.1.1.2" xref="A1.SS5.p1.2.m2.1.1.2.cmml">ℓ</mi><mn id="A1.SS5.p1.2.m2.1.1.3" xref="A1.SS5.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.2.m2.1b"><apply id="A1.SS5.p1.2.m2.1.1.cmml" xref="A1.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS5.p1.2.m2.1.1.1.cmml" xref="A1.SS5.p1.2.m2.1.1">subscript</csymbol><ci id="A1.SS5.p1.2.m2.1.1.2.cmml" xref="A1.SS5.p1.2.m2.1.1.2">ℓ</ci><cn type="integer" id="A1.SS5.p1.2.m2.1.1.3.cmml" xref="A1.SS5.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.2.m2.1c">\ell_{2}</annotation></semantics></math> distance.
To be specific, we calculate the average features with pre-trained ResNet-18 <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib10" title="" class="ltx_ref">2016</a>)</cite> on each client in turn, and then measure the indicators between all pairs of clients.</p>
</div>
<div id="A1.SS5.p2" class="ltx_para ltx_noindent">
<p id="A1.SS5.p2.1" class="ltx_p">Results in the figures manifest that after applying FedGC, the cosine similarity and <math id="A1.SS5.p2.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.SS5.p2.1.m1.1a"><msub id="A1.SS5.p2.1.m1.1.1" xref="A1.SS5.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="A1.SS5.p2.1.m1.1.1.2" xref="A1.SS5.p2.1.m1.1.1.2.cmml">ℓ</mi><mn id="A1.SS5.p2.1.m1.1.1.3" xref="A1.SS5.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.1.m1.1b"><apply id="A1.SS5.p2.1.m1.1.1.cmml" xref="A1.SS5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS5.p2.1.m1.1.1.1.cmml" xref="A1.SS5.p2.1.m1.1.1">subscript</csymbol><ci id="A1.SS5.p2.1.m1.1.1.2.cmml" xref="A1.SS5.p2.1.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.SS5.p2.1.m1.1.1.3.cmml" xref="A1.SS5.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.1.m1.1c">\ell_{2}</annotation></semantics></math> distance among client pairs separately increase and decrease. In other words, local data possessed by clients are more homogeneous than before. FedGC efficiently mitigates data heterogeneity by generating corresponding data on the client side. From the feature respective, we show the latent reason for significant performance improvement brought by FedGC.</p>
</div>
<figure id="A1.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_Cosine-similarity_Eurosat_beta0.05.png" id="A1.F9.sf1.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>cosine: FedAvg</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_Cosine-similarity_Eurosat_beta0.05_fedgc.png" id="A1.F9.sf2.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>cosine: FedGC</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F9.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_L2-distance_Eurosat_beta0.05.png" id="A1.F9.sf3.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><math id="A1.F9.sf3.2.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.F9.sf3.2.m1.1b"><msub id="A1.F9.sf3.2.m1.1.1" xref="A1.F9.sf3.2.m1.1.1.cmml"><mi mathvariant="normal" id="A1.F9.sf3.2.m1.1.1.2" xref="A1.F9.sf3.2.m1.1.1.2.cmml">ℓ</mi><mn id="A1.F9.sf3.2.m1.1.1.3" xref="A1.F9.sf3.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.F9.sf3.2.m1.1c"><apply id="A1.F9.sf3.2.m1.1.1.cmml" xref="A1.F9.sf3.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F9.sf3.2.m1.1.1.1.cmml" xref="A1.F9.sf3.2.m1.1.1">subscript</csymbol><ci id="A1.F9.sf3.2.m1.1.1.2.cmml" xref="A1.F9.sf3.2.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.F9.sf3.2.m1.1.1.3.cmml" xref="A1.F9.sf3.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F9.sf3.2.m1.1d">\ell_{2}</annotation></semantics></math>: FedAvg</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F9.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_L2-distance_Eurosat_beta0.05_fedgc.png" id="A1.F9.sf4.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span><math id="A1.F9.sf4.2.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.F9.sf4.2.m1.1b"><msub id="A1.F9.sf4.2.m1.1.1" xref="A1.F9.sf4.2.m1.1.1.cmml"><mi mathvariant="normal" id="A1.F9.sf4.2.m1.1.1.2" xref="A1.F9.sf4.2.m1.1.1.2.cmml">ℓ</mi><mn id="A1.F9.sf4.2.m1.1.1.3" xref="A1.F9.sf4.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.F9.sf4.2.m1.1c"><apply id="A1.F9.sf4.2.m1.1.1.cmml" xref="A1.F9.sf4.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F9.sf4.2.m1.1.1.1.cmml" xref="A1.F9.sf4.2.m1.1.1">subscript</csymbol><ci id="A1.F9.sf4.2.m1.1.1.2.cmml" xref="A1.F9.sf4.2.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.F9.sf4.2.m1.1.1.3.cmml" xref="A1.F9.sf4.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F9.sf4.2.m1.1d">\ell_{2}</annotation></semantics></math>: FedGC</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Feature cosine similarity and <math id="A1.F9.2.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.F9.2.m1.1b"><msub id="A1.F9.2.m1.1.1" xref="A1.F9.2.m1.1.1.cmml"><mi mathvariant="normal" id="A1.F9.2.m1.1.1.2" xref="A1.F9.2.m1.1.1.2.cmml">ℓ</mi><mn id="A1.F9.2.m1.1.1.3" xref="A1.F9.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.F9.2.m1.1c"><apply id="A1.F9.2.m1.1.1.cmml" xref="A1.F9.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F9.2.m1.1.1.1.cmml" xref="A1.F9.2.m1.1.1">subscript</csymbol><ci id="A1.F9.2.m1.1.1.2.cmml" xref="A1.F9.2.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.F9.2.m1.1.1.3.cmml" xref="A1.F9.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F9.2.m1.1d">\ell_{2}</annotation></semantics></math> distance heatmap among 10 clients on EuroSAT. We calculate the two metrics on average data features among clients using the pre-trained ResNet-18 <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib10" title="" class="ltx_ref">2016</a>)</cite>. FedGC enhances the feature similarity and closes their distance, which effectively mitigates the feature-level heterogeneity on EuroSAT.</figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_Cosine-similarity_Pacs_beta0.05.png" id="A1.F10.sf1.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>cosine: FedAvg</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_Cosine-similarity_Pacs_beta0.05_fedgc.png" id="A1.F10.sf2.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>cosine: FedGC</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F10.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_L2-distance_Pacs_beta0.05.png" id="A1.F10.sf3.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><math id="A1.F10.sf3.2.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.F10.sf3.2.m1.1b"><msub id="A1.F10.sf3.2.m1.1.1" xref="A1.F10.sf3.2.m1.1.1.cmml"><mi mathvariant="normal" id="A1.F10.sf3.2.m1.1.1.2" xref="A1.F10.sf3.2.m1.1.1.2.cmml">ℓ</mi><mn id="A1.F10.sf3.2.m1.1.1.3" xref="A1.F10.sf3.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.F10.sf3.2.m1.1c"><apply id="A1.F10.sf3.2.m1.1.1.cmml" xref="A1.F10.sf3.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F10.sf3.2.m1.1.1.1.cmml" xref="A1.F10.sf3.2.m1.1.1">subscript</csymbol><ci id="A1.F10.sf3.2.m1.1.1.2.cmml" xref="A1.F10.sf3.2.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.F10.sf3.2.m1.1.1.3.cmml" xref="A1.F10.sf3.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F10.sf3.2.m1.1d">\ell_{2}</annotation></semantics></math>: FedAvg</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A1.F10.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/feature_heatmap_L2-distance_Pacs_beta0.05_fedgc.png" id="A1.F10.sf4.g1" class="ltx_graphics ltx_img_square" width="138" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span><math id="A1.F10.sf4.2.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.F10.sf4.2.m1.1b"><msub id="A1.F10.sf4.2.m1.1.1" xref="A1.F10.sf4.2.m1.1.1.cmml"><mi mathvariant="normal" id="A1.F10.sf4.2.m1.1.1.2" xref="A1.F10.sf4.2.m1.1.1.2.cmml">ℓ</mi><mn id="A1.F10.sf4.2.m1.1.1.3" xref="A1.F10.sf4.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.F10.sf4.2.m1.1c"><apply id="A1.F10.sf4.2.m1.1.1.cmml" xref="A1.F10.sf4.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F10.sf4.2.m1.1.1.1.cmml" xref="A1.F10.sf4.2.m1.1.1">subscript</csymbol><ci id="A1.F10.sf4.2.m1.1.1.2.cmml" xref="A1.F10.sf4.2.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.F10.sf4.2.m1.1.1.3.cmml" xref="A1.F10.sf4.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F10.sf4.2.m1.1d">\ell_{2}</annotation></semantics></math>: FedGC</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Feature cosine similarity and <math id="A1.F10.2.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.F10.2.m1.1b"><msub id="A1.F10.2.m1.1.1" xref="A1.F10.2.m1.1.1.cmml"><mi mathvariant="normal" id="A1.F10.2.m1.1.1.2" xref="A1.F10.2.m1.1.1.2.cmml">ℓ</mi><mn id="A1.F10.2.m1.1.1.3" xref="A1.F10.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.F10.2.m1.1c"><apply id="A1.F10.2.m1.1.1.cmml" xref="A1.F10.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F10.2.m1.1.1.1.cmml" xref="A1.F10.2.m1.1.1">subscript</csymbol><ci id="A1.F10.2.m1.1.1.2.cmml" xref="A1.F10.2.m1.1.1.2">ℓ</ci><cn type="integer" id="A1.F10.2.m1.1.1.3.cmml" xref="A1.F10.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F10.2.m1.1d">\ell_{2}</annotation></semantics></math> distance heatmap among 4 clients on PACS. We calculate the two metrics on average data features among clients using the pre-trained ResNet-18. FedGC enhances the feature similarity and closes their distance, which effectively mitigates the feature-level heterogeneity on PACS.</figcaption>
</figure>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>FedGC with Partial Clients Capable of Generation</h3>

<div id="A1.SS6.p1" class="ltx_para ltx_noindent">
<p id="A1.SS6.p1.1" class="ltx_p">Our proposed FedGC framework is also applicable in cases where not every client has the capability to generate data. Here, we experiment on CIFAR-10 under two different heterogeneity levels. In Table <a href="#A1.T11" title="Table 11 ‣ A.6 FedGC with Partial Clients Capable of Generation ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, we compare vanilla baseline with no generative data, FedGC where all clients can generate data, and FedGC where only half of the clients can generate data.</p>
</div>
<div id="A1.SS6.p2" class="ltx_para ltx_noindent">
<p id="A1.SS6.p2.1" class="ltx_p">From the table, we see that
(1) our proposed FedGC can consistently and significantly achieve the best performance despite the amount of generation-capable clients.
(2) Surprisingly, we find that under low heterogeneity level, when applied to SCAFFOLD <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, FedGC with few generation-capable clients even performs better.
This interesting finding demonstrates that our framework may be further improved by more fine-grained designs regarding who is responsible for data generation and the volume of data to be generated.</p>
</div>
<figure id="A1.T11" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11: </span>Experiments of a scene in which partial clients are capable of generation. 1k/50% indicates only half of the clients are capable of generation. However, FedGC still significantly outperforms the baseline with no generative data.</figcaption>
<table id="A1.T11.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T11.1.1.1" class="ltx_tr">
<th id="A1.T11.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">H-Level</th>
<th id="A1.T11.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3">High</th>
<th id="A1.T11.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3">Low</th>
</tr>
<tr id="A1.T11.1.2.2" class="ltx_tr">
<th id="A1.T11.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r">Generation</th>
<th id="A1.T11.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">No</th>
<th id="A1.T11.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">1k/100%</th>
<th id="A1.T11.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">1k/50%</th>
<th id="A1.T11.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">No</th>
<th id="A1.T11.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">1k/100%</th>
<th id="A1.T11.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">1k/50%</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T11.1.3.1" class="ltx_tr">
<th id="A1.T11.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">FedAvg</th>
<td id="A1.T11.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">60.77</td>
<td id="A1.T11.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">73.99</td>
<td id="A1.T11.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.53</td>
<td id="A1.T11.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">71.57</td>
<td id="A1.T11.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">79.73</td>
<td id="A1.T11.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">77.45</td>
</tr>
<tr id="A1.T11.1.4.2" class="ltx_tr">
<th id="A1.T11.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FedProx</th>
<td id="A1.T11.1.4.2.2" class="ltx_td ltx_align_center">63.62</td>
<td id="A1.T11.1.4.2.3" class="ltx_td ltx_align_center">73.69</td>
<td id="A1.T11.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">72.65</td>
<td id="A1.T11.1.4.2.5" class="ltx_td ltx_align_center">75.76</td>
<td id="A1.T11.1.4.2.6" class="ltx_td ltx_align_center">79.25</td>
<td id="A1.T11.1.4.2.7" class="ltx_td ltx_align_center">79.23</td>
</tr>
<tr id="A1.T11.1.5.3" class="ltx_tr">
<th id="A1.T11.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">SCAFFOLD</th>
<td id="A1.T11.1.5.3.2" class="ltx_td ltx_align_center ltx_border_bb">65.00</td>
<td id="A1.T11.1.5.3.3" class="ltx_td ltx_align_center ltx_border_bb">75.75</td>
<td id="A1.T11.1.5.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">73.28</td>
<td id="A1.T11.1.5.3.5" class="ltx_td ltx_align_center ltx_border_bb">78.74</td>
<td id="A1.T11.1.5.3.6" class="ltx_td ltx_align_center ltx_border_bb">80.29</td>
<td id="A1.T11.1.5.3.7" class="ltx_td ltx_align_center ltx_border_bb">81.27</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A1.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>FedGC under Different Heterogeneity Levels</h3>

<div id="A1.SS7.p1" class="ltx_para ltx_noindent">
<p id="A1.SS7.p1.2" class="ltx_p">Here, we conduct experiments of three baselines including FedAvg, FedProx, and SCAFFOLD, with different heterogeneity levels on CIFAR-10. The Beta <math id="A1.SS7.p1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.SS7.p1.1.m1.1a"><mi id="A1.SS7.p1.1.m1.1.1" xref="A1.SS7.p1.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.1.m1.1b"><ci id="A1.SS7.p1.1.m1.1.1.cmml" xref="A1.SS7.p1.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.1.m1.1c">\beta</annotation></semantics></math> stands for the hyper-parameter in the Dirichlet distribution. As <math id="A1.SS7.p1.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.SS7.p1.2.m2.1a"><mi id="A1.SS7.p1.2.m2.1.1" xref="A1.SS7.p1.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.2.m2.1b"><ci id="A1.SS7.p1.2.m2.1.1.cmml" xref="A1.SS7.p1.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.2.m2.1c">\beta</annotation></semantics></math> increases in [0.05, 0.07, 0.1, 0.3, 0.5, 1.0, 5.0], the data heterogeneity level reduces.
Illustrated in Figure <a href="#A1.F11" title="Figure 11 ‣ A.7 FedGC under Different Heterogeneity Levels ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, we can observe that (1) FedGC consistently outperforms these three algorithms in all different data heterogeneity levels. (2) As the heterogeneity level increases, the accuracy improvement brought by FedGC significantly elevates, which showcases the reliability of FedGC to mitigate heterogeneity, one of the intricate issues in FL.</p>
</div>
<figure id="A1.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A1.F11.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/FedAvg_beta_curve.png" id="A1.F11.sf1.g1" class="ltx_graphics ltx_img_landscape" width="186" height="127" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>FedAVg</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A1.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/FedProx_beta_curve.png" id="A1.F11.sf2.g1" class="ltx_graphics ltx_img_landscape" width="186" height="127" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>FedProx</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A1.F11.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.05807/assets/SCAFFOLD_beta_curve.png" id="A1.F11.sf3.g1" class="ltx_graphics ltx_img_landscape" width="186" height="127" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>SCAFFOLD</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Performance comparisons between vanilla baseline and baseline in FedGC framework under different heterogeneity levels on CIFAR-10. Beta (<math id="A1.F11.2.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.F11.2.m1.1b"><mi id="A1.F11.2.m1.1.1" xref="A1.F11.2.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A1.F11.2.m1.1c"><ci id="A1.F11.2.m1.1.1.cmml" xref="A1.F11.2.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F11.2.m1.1d">\beta</annotation></semantics></math>) is the hyper-parameter in Dirichlet distribution. As the heterogeneity level increases (Beta decreases), the improvement brought by FedGC becomes more significant. This indicates that FedGC can effectively alleviate the issue of data heterogeneity. </figcaption>
</figure>
</section>
<section id="A1.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.8 </span>FedGC for Partial Client Participation Scenarios</h3>

<div id="A1.SS8.p1" class="ltx_para ltx_noindent">
<p id="A1.SS8.p1.1" class="ltx_p">Here, we conduct experiments of three baselines including FedAvg, FedProx, and SCAFFOLD on CIFAR-10 with Dirichlet distribution parameter <math id="A1.SS8.p1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.SS8.p1.1.m1.1a"><mi id="A1.SS8.p1.1.m1.1.1" xref="A1.SS8.p1.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A1.SS8.p1.1.m1.1b"><ci id="A1.SS8.p1.1.m1.1.1.cmml" xref="A1.SS8.p1.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS8.p1.1.m1.1c">\beta</annotation></semantics></math> = 0.1. Specifically, we set the communication round to 200, local iteration number to 100, and try different client number and participation rate. As illustrated in Table <a href="#A1.T12" title="Table 12 ‣ A.8 FedGC for Partial Client Participation Scenarios ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, we can observe that FedGC still significantly outperforms the baseline with no generated data under each circumstance.</p>
</div>
<figure id="A1.T12" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 12: </span>Experiments of a scene in which only partial clients participate in training each round. We conduct experiments on three different total client numbers and several different participation rates. For example, client 200 and participation rate 5% means randomly selecting 10 clients to participate in training each round. In each case, FedGC still significantly outperforms the baseline with no generative data. </figcaption>
<table id="A1.T12.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T12.1.1.1" class="ltx_tr">
<th id="A1.T12.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" rowspan="2"><span id="A1.T12.1.1.1.1.1" class="ltx_text">Baseline</span></th>
<th id="A1.T12.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;">Client</th>
<th id="A1.T12.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="3">200</th>
<th id="A1.T12.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="2">100</th>
<th id="A1.T12.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.5pt;padding-right:4.5pt;" colspan="2">50</th>
</tr>
<tr id="A1.T12.1.2.2" class="ltx_tr">
<th id="A1.T12.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Participation</th>
<th id="A1.T12.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">5%</th>
<th id="A1.T12.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">10%</th>
<th id="A1.T12.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">20%</th>
<th id="A1.T12.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">10%</th>
<th id="A1.T12.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">20%</th>
<th id="A1.T12.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">10%</th>
<th id="A1.T12.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:4.5pt;padding-right:4.5pt;">20%</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T12.1.3.1" class="ltx_tr">
<td id="A1.T12.1.3.1.1" class="ltx_td ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="A1.T12.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="A1.T12.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">53.62</td>
<td id="A1.T12.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">60.00</td>
<td id="A1.T12.1.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">65.76</td>
<td id="A1.T12.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">56.53</td>
<td id="A1.T12.1.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">57.69</td>
<td id="A1.T12.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">55.90</td>
<td id="A1.T12.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.5pt;padding-right:4.5pt;">63.33</td>
</tr>
<tr id="A1.T12.1.4.2" class="ltx_tr" style="background-color:#ECECEC;">
<td id="A1.T12.1.4.2.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.1.1" class="ltx_text" style="background-color:#FFFFFF;">FedAvg</span></td>
<td id="A1.T12.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="A1.T12.1.4.2.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.3.1" class="ltx_text" style="background-color:#ECECEC;">68.93</span></td>
<td id="A1.T12.1.4.2.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.4.1" class="ltx_text" style="background-color:#ECECEC;">74.06</span></td>
<td id="A1.T12.1.4.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.5.1" class="ltx_text" style="background-color:#ECECEC;">75.74</span></td>
<td id="A1.T12.1.4.2.6" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.6.1" class="ltx_text" style="background-color:#ECECEC;">74.16</span></td>
<td id="A1.T12.1.4.2.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.7.1" class="ltx_text" style="background-color:#ECECEC;">74.26</span></td>
<td id="A1.T12.1.4.2.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.8.1" class="ltx_text" style="background-color:#ECECEC;">75.34</span></td>
<td id="A1.T12.1.4.2.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.4.2.9.1" class="ltx_text" style="background-color:#ECECEC;">77.20</span></td>
</tr>
<tr id="A1.T12.1.5.3" class="ltx_tr">
<td id="A1.T12.1.5.3.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="A1.T12.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="A1.T12.1.5.3.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">53.93</td>
<td id="A1.T12.1.5.3.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">59.95</td>
<td id="A1.T12.1.5.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">64.53</td>
<td id="A1.T12.1.5.3.6" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">56.74</td>
<td id="A1.T12.1.5.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">59.54</td>
<td id="A1.T12.1.5.3.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">56.36</td>
<td id="A1.T12.1.5.3.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">65.66</td>
</tr>
<tr id="A1.T12.1.6.4" class="ltx_tr" style="background-color:#ECECEC;">
<td id="A1.T12.1.6.4.1" class="ltx_td ltx_align_center" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.1.1" class="ltx_text" style="background-color:#FFFFFF;">FedProx</span></td>
<td id="A1.T12.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="A1.T12.1.6.4.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.3.1" class="ltx_text" style="background-color:#ECECEC;">70.23</span></td>
<td id="A1.T12.1.6.4.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.4.1" class="ltx_text" style="background-color:#ECECEC;">73.79</span></td>
<td id="A1.T12.1.6.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.5.1" class="ltx_text" style="background-color:#ECECEC;">75.07</span></td>
<td id="A1.T12.1.6.4.6" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.6.1" class="ltx_text" style="background-color:#ECECEC;">74.39</span></td>
<td id="A1.T12.1.6.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.7.1" class="ltx_text" style="background-color:#ECECEC;">74.05</span></td>
<td id="A1.T12.1.6.4.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.8.1" class="ltx_text" style="background-color:#ECECEC;">75.47</span></td>
<td id="A1.T12.1.6.4.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.6.4.9.1" class="ltx_text" style="background-color:#ECECEC;">77.47</span></td>
</tr>
<tr id="A1.T12.1.7.5" class="ltx_tr">
<td id="A1.T12.1.7.5.1" class="ltx_td" style="padding-left:4.5pt;padding-right:4.5pt;"></td>
<td id="A1.T12.1.7.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">Vanilla</td>
<td id="A1.T12.1.7.5.3" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">60.41</td>
<td id="A1.T12.1.7.5.4" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">68.02</td>
<td id="A1.T12.1.7.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">70.15</td>
<td id="A1.T12.1.7.5.6" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">65.03</td>
<td id="A1.T12.1.7.5.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;">68.12</td>
<td id="A1.T12.1.7.5.8" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">65.73</td>
<td id="A1.T12.1.7.5.9" class="ltx_td ltx_align_center" style="padding-left:4.5pt;padding-right:4.5pt;">72.42</td>
</tr>
<tr id="A1.T12.1.8.6" class="ltx_tr" style="background-color:#ECECEC;">
<td id="A1.T12.1.8.6.1" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFFFFF;padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.1.1" class="ltx_text" style="background-color:#FFFFFF;">SCAFFOLD</span></td>
<td id="A1.T12.1.8.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.2.1" class="ltx_text" style="background-color:#ECECEC;">+ FedGC</span></td>
<td id="A1.T12.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.3.1" class="ltx_text" style="background-color:#ECECEC;">71.65</span></td>
<td id="A1.T12.1.8.6.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.4.1" class="ltx_text" style="background-color:#ECECEC;">74.83</span></td>
<td id="A1.T12.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.5.1" class="ltx_text" style="background-color:#ECECEC;">77.54</span></td>
<td id="A1.T12.1.8.6.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.6.1" class="ltx_text" style="background-color:#ECECEC;">74.38</span></td>
<td id="A1.T12.1.8.6.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.7.1" class="ltx_text" style="background-color:#ECECEC;">76.26</span></td>
<td id="A1.T12.1.8.6.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.8.1" class="ltx_text" style="background-color:#ECECEC;">72.74</span></td>
<td id="A1.T12.1.8.6.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.5pt;padding-right:4.5pt;"><span id="A1.T12.1.8.6.9.1" class="ltx_text" style="background-color:#ECECEC;">77.56</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A1.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.9 </span>Global-model-based Data Filtering</h3>

<div id="A1.SS9.p1" class="ltx_para ltx_noindent">
<p id="A1.SS9.p1.2" class="ltx_p">We propose global-model-based data filtering, where each client conducts data filtering on the client side according to the received global model before local model training.
Specifically, to determine which data to filter, a client feeds its generated data to the global model to evaluate the loss value for each data sample.
Then, each client selects the top <math id="A1.SS9.p1.1.m1.1" class="ltx_Math" alttext="x\%" display="inline"><semantics id="A1.SS9.p1.1.m1.1a"><mrow id="A1.SS9.p1.1.m1.1.1" xref="A1.SS9.p1.1.m1.1.1.cmml"><mi id="A1.SS9.p1.1.m1.1.1.2" xref="A1.SS9.p1.1.m1.1.1.2.cmml">x</mi><mo id="A1.SS9.p1.1.m1.1.1.1" xref="A1.SS9.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS9.p1.1.m1.1b"><apply id="A1.SS9.p1.1.m1.1.1.cmml" xref="A1.SS9.p1.1.m1.1.1"><csymbol cd="latexml" id="A1.SS9.p1.1.m1.1.1.1.cmml" xref="A1.SS9.p1.1.m1.1.1.1">percent</csymbol><ci id="A1.SS9.p1.1.m1.1.1.2.cmml" xref="A1.SS9.p1.1.m1.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS9.p1.1.m1.1c">x\%</annotation></semantics></math> data (we set <math id="A1.SS9.p1.2.m2.1" class="ltx_Math" alttext="x=90" display="inline"><semantics id="A1.SS9.p1.2.m2.1a"><mrow id="A1.SS9.p1.2.m2.1.1" xref="A1.SS9.p1.2.m2.1.1.cmml"><mi id="A1.SS9.p1.2.m2.1.1.2" xref="A1.SS9.p1.2.m2.1.1.2.cmml">x</mi><mo id="A1.SS9.p1.2.m2.1.1.1" xref="A1.SS9.p1.2.m2.1.1.1.cmml">=</mo><mn id="A1.SS9.p1.2.m2.1.1.3" xref="A1.SS9.p1.2.m2.1.1.3.cmml">90</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS9.p1.2.m2.1b"><apply id="A1.SS9.p1.2.m2.1.1.cmml" xref="A1.SS9.p1.2.m2.1.1"><eq id="A1.SS9.p1.2.m2.1.1.1.cmml" xref="A1.SS9.p1.2.m2.1.1.1"></eq><ci id="A1.SS9.p1.2.m2.1.1.2.cmml" xref="A1.SS9.p1.2.m2.1.1.2">𝑥</ci><cn type="integer" id="A1.SS9.p1.2.m2.1.1.3.cmml" xref="A1.SS9.p1.2.m2.1.1.3">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS9.p1.2.m2.1c">x=90</annotation></semantics></math> here) and mixes the selected generated data with its real data.</p>
</div>
<div id="A1.SS9.p2" class="ltx_para ltx_noindent">
<p id="A1.SS9.p2.1" class="ltx_p">Furthermore, since the global model might perform drastically differently on different categories, simply selecting according to the loss of all data samples may result in imbalanced filtering.
That is, this could make to global model filter out most of the samples where it performs poorly.
Addressing this, we further propose category-wise data filtering based on global model, which filers the same ratio of data for each category.</p>
</div>
<div id="A1.SS9.p3" class="ltx_para ltx_noindent">
<p id="A1.SS9.p3.1" class="ltx_p">Here, we perform experiments on EuroSAT dataset with two heterogeneity levels in Table <a href="#A1.T13" title="Table 13 ‣ A.9 Global-model-based Data Filtering ‣ Appendix A Appendix ‣ Federated Learning Empowered by Generative Content" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>.
Vanilla denotes FedAvg itself, No F denotes FedGC without filtering, F@50 denotes filtering from round 50, F@50-C denotes category-wise filtering.
From the table, we see that (1) under a high heterogeneity level, F@75 contributes to higher performance than No F, even with only 90% of data at final rounds.
(2) Category-wise filtering generally performs better than unified filtering, indicating its effectiveness.
(3) Nevertheless, such filtering technique can not always ensure performance improvement, calling for more future work.
The performance drop could result from reduced number of data samples and ineffective filtering.</p>
</div>
<div id="A1.SS9.p4" class="ltx_para ltx_noindent">
<p id="A1.SS9.p4.1" class="ltx_p">Overall, here we just provide an initial attempt to consider the potential of data filtering.
We believe more future works could be proposed to better filter the generated data such that we could use the generated data more efficiently.</p>
</div>
<figure id="A1.T13" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 13: </span>Experiments of global-model-based data filtering. We conduct our initial attempt on EuroSAT dataset with two heterogeneity types. F@50 means start filtering after 50 communication rounds and C means filtering by each class.</figcaption>
<table id="A1.T13.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T13.1.1.1" class="ltx_tr">
<th id="A1.T13.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Heterogeneity Level</th>
<th id="A1.T13.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Vanilla</th>
<th id="A1.T13.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">No F</th>
<th id="A1.T13.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">F@50</th>
<th id="A1.T13.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">F@75</th>
<th id="A1.T13.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">F@50-C</th>
<th id="A1.T13.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">F@75-C</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T13.1.2.1" class="ltx_tr">
<th id="A1.T13.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">High</th>
<td id="A1.T13.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">53.82</td>
<td id="A1.T13.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">74.83</td>
<td id="A1.T13.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">72.96</td>
<td id="A1.T13.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">74.93</td>
<td id="A1.T13.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">73.50</td>
<td id="A1.T13.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">74.20</td>
</tr>
<tr id="A1.T13.1.3.2" class="ltx_tr">
<th id="A1.T13.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Low</th>
<td id="A1.T13.1.3.2.2" class="ltx_td ltx_align_center ltx_border_bb">75.59</td>
<td id="A1.T13.1.3.2.3" class="ltx_td ltx_align_center ltx_border_bb">84.46</td>
<td id="A1.T13.1.3.2.4" class="ltx_td ltx_align_center ltx_border_bb">83.82</td>
<td id="A1.T13.1.3.2.5" class="ltx_td ltx_align_center ltx_border_bb">83.83</td>
<td id="A1.T13.1.3.2.6" class="ltx_td ltx_align_center ltx_border_bb">84.19</td>
<td id="A1.T13.1.3.2.7" class="ltx_td ltx_align_center ltx_border_bb">83.83</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.05806" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.05807" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.05807">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.05807" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.05808" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 14:48:58 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
