<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach</title>
<!--Generated on Wed Jun 12 11:52:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="" lang="en" name="keywords"/>
<base href="/html/2406.08120v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S1" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S2" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Approach</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.SS1" title="In III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">GUI Prototype Abstraction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.SS2" title="In III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">User Story Implementation Detection</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.SS3" title="In III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">User Story GUI Component Matching</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.SS4" title="In III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">User Story Implementation Recommendation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.SS5" title="In III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-E</span> </span><span class="ltx_text ltx_font_italic">Proposed Integrated System</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S4" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S4.SS1" title="In IV Evaluation ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Data Collection</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S4.SS2" title="In IV Evaluation ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">RQ<sub class="ltx_sub">1</sub>: User Story Implementation Detection</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S4.SS3" title="In IV Evaluation ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">RQ<sub class="ltx_sub">2</sub>: User Story GUI Component Matching</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results and Discussion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.SS1" title="In V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">RQ<sub class="ltx_sub">1</sub>: User Story Implementation Detection</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.SS2" title="In V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">RQ<sub class="ltx_sub">2</sub>: User Story GUI Component Matching</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.SS3" title="In V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Preliminary Recommendation Results</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S6" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Limitations and Potential Risks</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S7" title="In Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Research Plan and Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\noautomath</span><span class="ltx_ERROR undefined" id="p1.2">\AddToShipoutPictureBG</span>
<p class="ltx_p" id="p1.3">*<span class="ltx_ERROR undefined" id="p1.3.1">\AtPageLowerLeft</span>
<span class="ltx_text" id="p1.3.2" lang="en"></span></p>
</div>
<h1 class="ltx_title ltx_title_document" lang="en">Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname" lang="en">

Kristian Kolthoff21,
Felix Kretzer31,
Christian Bartelt2,
Alexander Maedche3,
and Simone Paolo Ponzetto4
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation" lang="en">1
Authors contributed equally to the paper.
</span>
<span class="ltx_contact ltx_role_affiliation" lang="en">
2Institute for Enterprise Systems,
University of Mannheim, Mannheim, Germany
<br class="ltx_break"/>Email: {kolthoff, bartelt} @es.uni-mannheim.de
</span>
<span class="ltx_contact ltx_role_affiliation" lang="en">3
Human-Centered Systems Lab,
Karlsruhe Institute of Technology, Karlsruhe, Germany
<br class="ltx_break"/>Email: {felix.kretzer, alexander.maedche} @kit.edu
</span>
<span class="ltx_contact ltx_role_affiliation" lang="en">4
Data and Web Science Group,
University of Mannheim, Mannheim, Germany
<br class="ltx_break"/>Email: simone@informatik.uni-mannheim.de
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1"><span class="ltx_text" id="id1.id1.1" lang="en">Interactive systems are omnipresent today and the need to create graphical user interfaces (GUIs) is just as ubiquitous. For the elicitation and validation of requirements, GUI prototyping is a well-known and effective technique, typically employed after gathering initial user requirements represented in natural language (NL) (e.g., in the form of <span class="ltx_text ltx_font_italic" id="id1.id1.1.1">user stories</span>). Unfortunately, GUI prototyping often requires extensive resources, resulting in a costly and time-consuming process. Despite various easy-to-use prototyping tools in practice, there is often a lack of adequate resources for developing GUI prototypes based on given user requirements. In this work, we present a novel Large Language Model (LLM)-based approach providing assistance for validating the implementation of functional NL-based requirements in a GUI prototype embedded in a prototyping tool. In particular, our approach aims to detect functional user stories that are not implemented in a GUI prototype and provides recommendations for suitable GUI components directly implementing the requirements. We collected requirements for existing GUIs in the form of user stories and evaluated our proposed validation and recommendation approach with this dataset. The obtained results are promising for user story validation and we demonstrate feasibility for the GUI component recommendations.</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
<span class="ltx_text" id="id2.id1" lang="en">
GUI Prototyping, Requirements Elicitation, Requirements Validation, User Stories, Assistance
</span>
</div>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Graphical user interfaces (GUIs) have become ubiquitous, allowing users to interact with software applications in most aspects of our daily lives. This trend has led to an increasing demand for GUIs. Today, providing GUIs that meet requirements is an essential commercial success factor for software applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib1" title="">1</a>]</cite>. In practice, agile methods have increasingly been used instead of traditional phase-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib2" title="">2</a>]</cite>. <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">Agile requirements engineering</span> attempts to address the changes that agile methods bring with them, such as requirements engineering and design activities being carried out continuously throughout development projects <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib3" title="">3</a>]</cite>. This can also lead to a deeper integration of stakeholders into the development process, promising better overall results (<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib7" title="">7</a>]</cite>).</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">A popular technique to involve stakeholders in the development phases and facilitate reflection on requirements, is <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">prototyping</span> of GUIs. The use of prototypes in requirements elicitation was already investigated more than two decades ago <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib8" title="">8</a>]</cite>. Recent analyses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib9" title="">9</a>]</cite> have shown that prototypes serve for ”efficient feedback and collaboration among stakeholders” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib9" title="">9</a>, p. 372]</cite>, as a tool to reflect on collected requirements and as a catalyst reducing elicitation time <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">However, GUI prototyping often requires substantial resources <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib10" title="">10</a>]</cite> making it a costly and time-consuming process (e.g., because creating GUI prototypes can require knowledge in interface design and programming <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib11" title="">11</a>]</cite>).
A particular challenge, while using GUI prototypes for requirements elicitation, results from the iterative change of requirements (e.g., user stories) in requirements elicitation. Debnath et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib12" title="">12</a>]</cite>, as an example, present a study, where less than half of the later user stories ”include content that can be fully traced to the initial ones” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib12" title="">12</a>, p. 233]</cite>, and a high percentage of resulting user stories were new or refinements of the initial ones. Due to the iterative change of formalized requirements, GUI prototypes are often redesigned with new or changed requirements. Time and effort lie in recognizing whether requirements have already been implemented and then implementing new requirements in GUI prototypes.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">While others have looked into supporting users tasked with creating GUI prototypes from different perspectives, to the best of our knowledge, there exists no approach that automatically checks requirements (e.g., in the popular form of user stories) against implemented components in GUI prototypes and provides recommendations for not-implemented requirements that can directly be integrated. With recommendations for improvements, users tasked with creating GUI prototypes can be enabled to create more effective GUI prototypes for requirements elicitation and validation. While different NL-based GUI retrieval strategies (e.g.,<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib16" title="">16</a>]</cite>) were proposed in this area, those GUI retrieval strategies mainly aim to generate first GUI inspirations and cannot be utilized to automatically assess whether or to what degree a GUI prototype meets single requirements. Work on generating images of GUIs from textual descriptions (e.g., using stable diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib17" title="">17</a>]</cite>) often comes with the limitations inherent to its output format – images – namely challenges in assessing the implementation of individual user stories on images, and complicated processing of images in follow-up prototyping steps, since images cannot be modified with prototyping tools from practice such as Figma <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib18" title="">18</a>]</cite>. Assistants tailored at supporting prototyping within dedicated tools (e.g., GUIComp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib19" title="">19</a>]</cite>) either provide examples based on initial GUI prototypes as source of inspiration or optimize prototypes with design metrics. Those tools are not primarily connected to context-dependent requirements and, to some degree, do not consider how users can effectively translate requirements into a (initial) prototype.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In order to address the presented research gap, we explore the question of <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">how to effectively detect functional user stories not implemented in GUI prototypes and provide recommendations for suitable GUI components</span>? With our approach, we investigate how prototypes can be effectively aligned with functional user stories, e.g., to be used later for reflection with stakeholders (e.g., as throwaway or evolutionary prototypes). For our approach, we focus on directly linking requirements and prototypes and consider an initial set of requirements (formalized as user stories) as given. We decided for user stories in our approach since they represent a popular formalization of requirements in practice, and literature <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We contribute by <span class="ltx_text ltx_font_italic" id="S1.p6.1.1">first</span> proposing and evaluating an approach detecting functional user stories not implemented in GUI prototypes and providing recommendations for suitable GUI components directly implementing the requirement, <span class="ltx_text ltx_font_italic" id="S1.p6.1.2">second</span> by outlining a system implementing our approach and by providing a research plan on how to evaluate the proposed system, and <span class="ltx_text ltx_font_italic" id="S1.p6.1.3">third</span> by making our code, dataset, and material needed to reproduce our approach and foster future research publicly available at <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib20" title="">20</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Various approaches in previous research address automated support for requirements engineering, validation, or GUI prototyping in general (for an overview, see, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib22" title="">22</a>]</cite>).
Umar and Lano <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib22" title="">22</a>]</cite> present a summary of automated support for requirements engineering. They note that most automated tools for requirements elicitation support aim to create <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">Unified Modelling Language</span> (UML) from less structured requirements. The automated creation of UML differs significantly from our approach since UML is less intuitive and more complex for stakeholders. Furthermore, UML lacks the capabilities to visualize basic functionality and interactions in direct comparison to GUI prototypes. Therefore, UML can present a challenge when eliciting and validating requirements with stakeholders, whereas GUI prototypes are suitable.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Prior research such as <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">Guigle</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib13" title="">13</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">GUI2WiRe</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib16" title="">16</a>]</cite> and <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">RaWi</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib14" title="">14</a>]</cite> presented NL-based GUI retrieval strategies exploiting the large-scale GUI repository <span class="ltx_text ltx_font_italic" id="S2.p2.1.4">Rico</span>. Their approaches primarily focus on the exploration and assessment of diverse techniques for NL-based GUI retrieval, with the aim for providing GUI design ideas or useful support for requirements analysts in a requirements elicitation context, respectively. In contrast, our proposed approach supports requirements analysts while creating GUI prototypes on a finer-grained user story level. Moreover, our recommendation approach provides support for custom requirements compared to the restriction to the available repository of retrieval-based approaches.
Furthermore, numerous GUI retrieval methods leveraging visual input have been previously suggested. Swire <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib23" title="">23</a>]</cite>, for instance, exploits visual embeddings as a means to retrieve GUIs from hand-drawn sketches. GUIFetch <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib24" title="">24</a>]</cite>, on the other hand, offers retrieval of comprehensive applications based on exhaustive Android application sketches.
Moreover, VINS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib25" title="">25</a>]</cite> advocates GUI retrieval employing either a rudimentary wireframe prototype or a fully implemented GUI prototype as input. GUIComp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib19" title="">19</a>]</cite> polls similar GUIs from a finite set of pre-build GUIs based on initial GUI prototypes. While these approaches can support requirements analysts during the GUI prototyping phase, they merely support sketches as input and therefore neglect NL requirements in the form of user stories that often are gathered in the initial requirements elicitation phase.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Additionally, with the arrival of generative AI in many research areas, tools like UI-Diffuser <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib17" title="">17</a>]</cite> allow the fast generation of GUI prototypes based on prompts using stable diffusion. However, approaches like UI-Diffuser come with limitations inherent to the output format: images. Generated images can currently not serve as a basis to automatically detect whether all requirements have been implemented in the generated images. In addition, there is a disconnection from prototyping in practice, as images cannot be used as input for prototyping tools (e.g., Figma <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib18" title="">18</a>]</cite>). Therefore, even minor adjustments cannot be made in familiar prototyping tools.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Some approaches have already investigated automated testing of user stories on GUI prototypes. Silva et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib26" title="">26</a>]</cite> present a Behaviour-Driven Development (BDD) based approach that enables the automated testing of user stories on interactive GUI prototypes with web browser automation tools. However, the interactive GUI prototypes required for this are often already further developed and not in the scope of rapid prototyping to elicit and validate requirements. Furthermore, in said approach no recommendations are generated or directly implemented into GUI prototypes in comparison to our proposed approach.</p>
</div>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Approach</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section provides an overview of our proposed approach to support prototype developers during the creation of GUI prototypes from user stories. Requirements elicitation typically starts with an elicitation interview with stakeholders and initial NL requirements are often gathered in the form of user stories and cleansed afterwards <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib27" title="">27</a>]</cite>. Subsequently, initial low-fidelity GUI prototypes are created often using GUI prototyping tools, e.g. Figma <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib18" title="">18</a>]</cite>. Depending on the problem, GUI prototypes are created from scratch or based on templates (e.g. retrieved by <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">RaWi</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib14" title="">14</a>]</cite>) that already fractionally match the gathered user stories. In such a scenario, our approach aims to support the prototype developer by <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">(i)</span> validating the current GUI prototype state against the user story collection to show missing user stories and <span class="ltx_text ltx_font_italic" id="S3.p1.1.3">(ii)</span> providing implementation recommendations in the form of visualized GUI-DSL (Domain-Specific Language) for the user stories. Our approach is divided into several main components as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.F1" title="Figure 1 ‣ III-B User Story Implementation Detection ‣ III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">1</span></a>. First, <span class="ltx_text ltx_font_italic" id="S3.p1.1.4">(A)</span> a GUI prototype abstraction component to transform the DSL of the GUI prototyping editor to an abstracted textual representation, <span class="ltx_text ltx_font_italic" id="S3.p1.1.5">(B)</span> an user story validation component that utilizes the GUI abstraction and user story collection in an LLM-based approach to classify weather a user story is already implemented, <span class="ltx_text ltx_font_italic" id="S3.p1.1.6">(C)</span> a component matching the GUI components to implemented user stories and <span class="ltx_text ltx_font_italic" id="S3.p1.1.7">(D)</span> a recommendation component to provide GUI suggestions of how the user story could be implemented.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.6.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.7.2">GUI Prototype Abstraction</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">As an input to the previously mentioned LLM-based methods, the GUI prototype requires to be transformed to a simplified abstract textual representation. Typically, prototyping tools employ a custom DSL or object model to hierarchically represent the GUI prototype. To enable the different prediction and recommendation tasks, we focus on extracting merely functional aspects from the prototypes, i.e. component types, their displayed texts, their names providing important semantic information and their boundaries. Reducing the extracted information to the mentioned aspects helps in both reducing consumed context length in the LLMs and focusing the model solely on functional aspects. Currently, the approach is not fully integrated into a GUI prototyping tool. Therefore, in our preliminary evaluation we employ the <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Rico<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S3.SS1.p1.1.1.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib28" title="">28</a><span class="ltx_text ltx_font_upright" id="S3.SS1.p1.1.1.2.2">]</span></cite></span> GUI repository to obtain initial results, as we can similarly extract all the mentioned aspects from the semi-automatically gathered GUIs. For each extracted GUI component, we then create a textual representation using the following abstract pattern followed by three examples created from <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">Rico</span> GUIs:</p>
</div>
<div class="ltx_logical-block" id="S3.SS1.1">
<div class="ltx_para" id="S3.SS1.1.p1">
<p class="ltx_p ltx_align_center" id="S3.SS1.1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.1.p1.1.1">”uicomp-text”</span> <span class="ltx_text ltx_font_bold" id="S3.SS1.1.p1.1.2">(uicomp-type)</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.1.p1.1.3">(uicomp-name)</span></p>
<p class="ltx_p ltx_align_center" id="S3.SS1.1.p1.2"><span class="ltx_text ltx_font_italic" id="S3.SS1.1.p1.2.1">”+7.10”</span> <span class="ltx_text ltx_font_bold" id="S3.SS1.1.p1.2.2">(Label)</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.1.p1.2.3">(price Change TV)
<br class="ltx_break"/></span><span class="ltx_text ltx_font_italic" id="S3.SS1.1.p1.2.4">”Install App”</span> <span class="ltx_text ltx_font_bold" id="S3.SS1.1.p1.2.5">(Button)</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.1.p1.2.6">(native Ad Call To)</span></p>
<p class="ltx_p ltx_align_center" id="S3.SS1.1.p1.3"><span class="ltx_text ltx_font_italic" id="S3.SS1.1.p1.3.1">”Example: ’New York’”</span> <span class="ltx_text ltx_font_bold" id="S3.SS1.1.p1.3.2">(Text Input)</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.1.p1.3.3">(location)</span></p>
</div>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Specifically, the <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">uicomp-text</span> refers to the displayed text of the component, the <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.2">uicomp-type</span> refers to the basic GUI component type (e.g. Label, Button, Checkbox etc.) and the <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.3">uicomp-name</span> refers to the name of the component given within the prototyping editor. In the absence of any of the components, the respective field is left empty. This textual representation of the GUI components encompasses relevant information from a functional perspective. Moreover, we derive clustering elements from the semantic annotations of <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.4">Rico</span>, which incorporate categories such as <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.5">List Item</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.6">Card</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.7">Toolbar</span>, among others. These represent names of layout groups and can similarly be extracted from a GUI prototyping editor. To identify clusters for the remaining components not encompassed by the preceding groups, we further extracted layout clusters from the original GUI hierarchy by aligning them with the GUI components. Subsequently, we fabricate the GUI representation as two-tier bullet points, with the outer tier representing the layout groups and the inner tier denoting their corresponding GUI components. Prior to generating the string representation, the layout groups are arranged based on their boundaries from the top-left to the bottom-right, and in a similar fashion, the GUI components within each group are organized shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.F1" title="Figure 1 ‣ III-B User Story Implementation Detection ‣ III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">1</span></a> to resemble the original GUI layout.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">User Story Implementation Detection</span>
</h3>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="291" id="S3.F1.g1" src="extracted/5651105/Figures/us_prototyping_support_large_new.png" width="281"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">Overview of our proposed approach pipeline (A-D)</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To tackle the problem of identifying whether a user story is implemented in a GUI prototype, we propose several LLM-based methods and approach it as a binary classification problem. The recent surge in popularity of LLMs can be attributed to their capacity for swift learning and adaptation to novel tasks, relying solely on a limited number of examples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib30" title="">30</a>]</cite>. These models are particularly versatile, capable of being tailored to a wide array of specific tasks through a method known as <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">In-Context Learning (ICL)</span> or <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">prompting</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib31" title="">31</a>]</cite>, respectively. Given the extensive knowledge encapsulated within LLMs and the access to this knowledge via prompting, the integration of these models for the detection and recommendation problems at hand are promising.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">In particular, we adopt the <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Zero-Shot (ZS)</span> prompting method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib30" title="">30</a>]</cite> by creating a prompting template divided into <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">(i)</span> a task instruction providing clear guidelines for the model, <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.3">(ii)</span> the user story to validate followed by <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.4">(iii)</span> the generated GUI abstraction. We instruct the model to predict a single token for the classification and we extract the log probabilities for both labels, which provides a user story ranking mechanism. In particular, the extracted probability can be employed to estimate the certainty of the classification. This probability can be further exploited to rank the user stories from high to low probabilities (e.g., for later visualization to users).</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">In addition, we adopt the <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Few-Shot (FS)</span> prompting method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib29" title="">29</a>]</cite> showing often enhanced performance for various tasks. In <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.2">FS</span> prompting, we basically follow the <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.3">ZS</span> pattern, however, we additionally provide several <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.4">input-output</span> pairs to guide the model for the specific task. For our preliminary evaluation, we created multiple <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.5">FS</span> prompting templates (varying examples).</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Moreover, we adopt the <span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Chain-of-Thought (COT)</span> prompting method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib32" title="">32</a>]</cite>, in which the LLM is instructed to create multiple intermediate reasoning steps before generating a prediction. Thus, we instruct the model to first generate an explanation providing reasoning whether the user story is implemented. In addition, this provides an interpretable explanation that can further be used for later error analysis.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">User Story GUI Component Matching</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In addition to solely predict the coverage of a user story in a GUI prototype, we further investigate the task of extracting all GUI components from the prototype that are required to fulfill the user story. This represents a natural extension of the previous task, enabling direct interlinking the user story with its respective GUI components and gaining deeper insights in the LLMs predictions. Similarly to the previous task, we adopt <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">ZS</span>, <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.2">FS</span> and <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.3">CoT</span> prompting models for this matching task. However, we extend the GUI abstraction by adding identifiers to each GUI component and correspondingly adapt the instructions and prompting templates to enable the LLM to output a parsable collection of GUI component identifiers.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.5.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.6.2">User Story Implementation Recommendation</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Finally, in order to not only interlink user stories with the GUI prototype and detect missing user stories but also directly support the prototype developer to implement missing user stories in the GUI prototype, the last component in our pipeline represents a LLM-based recommendation approach. In particular, we adopt <span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.1">FS</span> and <span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.2">FS-CoT</span> prompting models to generate a ranking of possible implementations of the user story contextualized based on the current GUI prototype state. In our preliminary investigation of these methods, we decided to generate recommendations in the form of HTML/CSS due to <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.3">(i)</span> the employed LLMs typically being pretrained on large amounts of HTML documents (generate error-free syntax) and <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.4">(ii)</span> the easy visualization of the generated recommendations. For the integration of these methods into a GUI prototyping tool, we aim for generating a DSL syntactically close the editor-DSL facilitating the integration of the recommendation into the GUI. This can be achieved either by fine-tuning the LLM on the DSL or potentially solely by employing <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.5">ICL</span>, as shown earlier for a DSL in robotic planning environment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib33" title="">33</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS5.5.1.1">III-E</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS5.6.2">Proposed Integrated System</span>
</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="221" id="S3.F2.g1" src="extracted/5651105/Figures/RE_System_V5.png" width="348"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Proposed system integrating user story based validation and GUI recommendations into dedicated prototyping tools</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">In this section, we propose an integrated system (illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.F2" title="Figure 2 ‣ III-E Proposed Integrated System ‣ III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">2</span></a>) to demonstrate the implementation of our approach. In line with <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib34" title="">34</a>]</cite>, we propose integrating our approach directly into dedicated prototyping tools (such as, e.g., Figma <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib18" title="">18</a>]</cite> or Adobe xD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib35" title="">35</a>]</cite>). The direct integration - e.g., in the form of a plug-in - supports the rapid creation of prototypes directly in the appropriate tools and, simultaneously, makes it possible to access the DSL required for our approach (illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S3.F1" title="Figure 1 ‣ III-B User Story Implementation Detection ‣ III Approach ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">1</span></a>). We propose four main features: First, <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.1">(i)</span> a list of all user stories classified as <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.2">implemented</span> and <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.3">not-implemented</span> may be displayed directly next to the GUI prototype. In addition, communicating the probability with which the respective user story was classified may support users by communicating uncertainty.
<span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.4">Second</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.5">(ii)</span> with direct integration, users can let our system highlight all GUI components matching a single user story classified as implemented and thereby gain an understanding of the classification and which components are related to a particular feature.
<span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.6">Third</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.7">(iii)</span> users can contribute to continuous learning and fine-tuning our approach with integrated user feedback for each user story, e.g., by marking incorrectly classified user stories as such in our system.
<span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.8">Fourth</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.9">(iv)</span> our system’s recommendations - generated in the respective DSL - can be directly integrated into a GUI prototype since our system can interact with the prototypes in dedicated prototyping tools. In this regard, our system can potentially reduce resource consumption when creating initial prototypes.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Evaluation</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This section delineates the design of our preliminary evaluation of the proposed approach. Since the approach is not yet fully implemented, we focus the evaluation on two main aspects of the approach including the user story implementation detection and GUI component matching methods. For enabling this preliminary evaluation, we constructed a gold standard of user stories and GUI prototype annotations. To this end, we formulate the subsequent two research questions:</p>
</div>
<div class="ltx_para" id="S4.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.ix1.p1.1.1">RQ<sub class="ltx_sub" id="S4.I1.ix1.p1.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S4.I1.ix1.p1.1.1.1.1">1</span></sub></span>: How effective are LLM-based approaches for detecting user story implementation in GUI prototypes?</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="S4.I1.ix2.p1">
<p class="ltx_p" id="S4.I1.ix2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.ix2.p1.1.1">RQ<sub class="ltx_sub" id="S4.I1.ix2.p1.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S4.I1.ix2.p1.1.1.1.1">2</span></sub></span>: How effective are LLM-based approaches for extracting GUI components fulfilling a user story from a GUI prototype?</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Data Collection</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To evaluate our approach, a dataset of GUIs and associated user stories was required. While there are established datasets of GUI prototypes available (e.g. <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">Rico</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib28" title="">28</a>]</cite>), to our knowledge there exists no dataset combining GUI prototypes with user stories. We therefore decided to collect user stories for existing GUI prototypes from <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">Rico</span>. The following section introduces how we collected and preprocessed the dataset by presenting existing GUIs to study participants creating the user stories.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1">GUI Sample</span>. In order to get a broad selection of different <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.2">Rico</span> GUIs, our initial GUI sample was randomly drawn from ten different domains. Following our exclusion criteria, we then selected valid GUIs from our random sample. We decided ex-ante to exclude interfaces with non-English text, personal data displayed, overlays (such as pop-ups) shown, components without annotations in the <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.3">Rico</span> dataset, trivial GUIs (e.g., simple log-in screens resulting in the same repetitive user stories), and to exclude interfaces with unclear functionality. Our final sample included 60 GUIs from the domains: <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.4">Shopping</span> (8), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.5">Health &amp; Fitness</span> (11), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.6">Education</span> (5), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.7">News</span> (4), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.8">Sports</span> (6), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.9">Travel</span> (6), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.10">Books</span> (5), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.11">Music</span> (6), <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.12">Finance</span> (4), and <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.13">Food &amp; Drink</span> (5). We additionally created GUI versions where each component was annotated with a number so that participants could assign their user stories to one or more GUI components.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.1">Procedure and Survey</span>. User stories were collected using a questionnaire. The participants were presented with information about the study, data protection, and the conditions of participation. They then learned how to write functional user stories. Learning content was supported with examples of user stories and concluded with comprehension checks. Participants had two chances for each comprehension check before a screenout took place. Participants then created user stories for nine consecutively shown GUIs. We instructed the participants to create three to five functional user stories describing features already implemented and provided a user stories template for guidance. After creating user stories for nine GUIs, the participants’ final task was to specify for each user story which components of the GUI belong to the respective user story. The participants were shown one after the other the identical nine GUIs with the already created user stories, but the GUIs now contained numbers that annotated each GUI component.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.1">Participants</span>. We selected 8 participants (2 female, 6 male) from a student pool. Participants were on average 24.3 years old, had 1.1 years of experience creating and 1.0 years experience in evaluating visual designs, such as GUI prototypes. Each participant generated on average 4.5 user stories per GUI.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.1">Data Processing</span>. Overall, the participants created 327 user stories, with duplicate user stories and varying quality (e.g., despite explicit instructions, some user stories were written for <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.2">not-implemented</span> features). In order to obtain a usable dataset, the user stories were cleaned up. Therefore, two paper authors labeled each user story independently. For this purpose, the first step was to determine whether the user story <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.3">a)</span> fully meets the requirements, <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.4">b)</span> contains one or more errors, or <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.5">c)</span> is a duplicate of a previous user story. After the separate labeling, the inter-coder reliability was calculated (Cohen’s Kappa <math alttext="\kappa=.548" class="ltx_Math" display="inline" id="S4.SS1.p5.1.m1.1"><semantics id="S4.SS1.p5.1.m1.1a"><mrow id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml"><mi id="S4.SS1.p5.1.m1.1.1.2" xref="S4.SS1.p5.1.m1.1.1.2.cmml">κ</mi><mo id="S4.SS1.p5.1.m1.1.1.1" xref="S4.SS1.p5.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p5.1.m1.1.1.3" xref="S4.SS1.p5.1.m1.1.1.3.cmml">.548</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><apply id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1"><eq id="S4.SS1.p5.1.m1.1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1.1"></eq><ci id="S4.SS1.p5.1.m1.1.1.2.cmml" xref="S4.SS1.p5.1.m1.1.1.2">𝜅</ci><cn id="S4.SS1.p5.1.m1.1.1.3.cmml" type="float" xref="S4.SS1.p5.1.m1.1.1.3">.548</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">\kappa=.548</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.1.m1.1d">italic_κ = .548</annotation></semantics></math>). After resolving disputes, 231 user stories (with their respective GUI prototypes) were included in the final data set, whereas 96 user stories (16 duplicates, 80 different exclusion criteria) were not considered further. The applied exclusion criteria are provided in our accompanying repository <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib20" title="">20</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.6.2.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.1.1">RQ<sub class="ltx_sub" id="S4.SS2.1.1.1">1</sub>: User Story Implementation Detection</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.7">To answer RQ<sub class="ltx_sub" id="S4.SS2.p1.7.3"><span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.3.1">1</span></sub>, we evaluated the ability of various LLM-based prompting techniques to predict whether a user story is contained in a GUI prototype. To this end, we created a gold standard based on the collected user stories and GUI annotation pairs. First, we randomly selected 5 GUIs comprising 21 user stories to be employed as examples for the <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.7.4">FS</span> prompting. The remaining 210 US-GUI-pairs form the basis for the gold standard. This procedure ensures the avoidance of overlapping GUI abstraction data between gold standard and <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.7.5">FS</span>-examples and introducing bias. Next, we randomly assigned half of the examples (105) the class <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.6">Implemented (1)</span> and the remainder the class <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.7">Not-Implemented (0)</span>. While the GUI data for the first class remains unchanged, in the GUI abstraction of the second class the paired GUI component annotations were removed. For example, consider the second GUI of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.F3" title="Figure 3 ‣ V-B RQ2: User Story GUI Component Matching ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">3</span></a>. For the shown US, the respective GUI components associated with the US according to the gold standard are marked in the GUI. To include such an US as a negative example in the gold standard, we would remove the respective GUI components from the GUI abstraction (two labels and a checkbox). We compute precision (<math alttext="P" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_P</annotation></semantics></math>), recall (<math alttext="R" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">italic_R</annotation></semantics></math>), F1-measure (<math alttext="F1" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">F</mi><mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">⁢</mo><mn id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><times id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></times><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">𝐹</ci><cn id="S4.SS2.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">italic_F 1</annotation></semantics></math>) and accuracy (<math alttext="ACC" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">A</mi><mo id="S4.SS2.p1.5.m5.1.1.1" xref="S4.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">C</mi><mo id="S4.SS2.p1.5.m5.1.1.1a" xref="S4.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.5.m5.1.1.4" xref="S4.SS2.p1.5.m5.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><times id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1"></times><ci id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">𝐴</ci><ci id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">𝐶</ci><ci id="S4.SS2.p1.5.m5.1.1.4.cmml" xref="S4.SS2.p1.5.m5.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">ACC</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.5.m5.1d">italic_A italic_C italic_C</annotation></semantics></math>). To conduct the experiments, we employed the most recent <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.8">GPT-4</span> model<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib36" title="">36</a>]</cite> (8,192 tokens context length, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.9">temperature=0</span>, accessed in February 2024) as our base LLM, holding the benchmark on many NLP tasks. For the <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.7.10">FS</span> prompting, we evaluated one model with five (<span class="ltx_text ltx_font_bold" id="S4.SS2.p1.6.1">FS<sub class="ltx_sub" id="S4.SS2.p1.6.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S4.SS2.p1.6.1.1.1">5</span></sub></span>) and another with ten examples (<span class="ltx_text ltx_font_bold" id="S4.SS2.p1.7.2">FS<sub class="ltx_sub" id="S4.SS2.p1.7.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S4.SS2.p1.7.2.1.1">10</span></sub></span>), respectively. In addition, we evaluated four <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.7.11">CoT</span> models with varying <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.12">temperature</span>. This is based on the idea that with varying <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.7.13">temperature</span>, we restrict or allow the model to provide more or less diverse explanations.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.6.2.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.1.1">RQ<sub class="ltx_sub" id="S4.SS3.1.1.1">2</sub>: User Story GUI Component Matching</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.5">To answer RQ<sub class="ltx_sub" id="S4.SS3.p1.5.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p1.5.1.1">2</span></sub>, we evaluated the ability of several LLM-based prompting techniques to extract all GUI components relevant to fulfill a given user story. Therefore, we employed the same gold standard as previously described, however, using the original unchanged abstraction for each of the 210 GUIs and the labels being the annotated GUI component identifiers from the gold standard. Precisely, as the input, the model received the GUI abstraction (each GUI component marked by an ID) and a US to predict a set of GUI components IDs relevant for the US. Next, we compared the set of extracted GUI component identifiers with the gold standard set of identifiers and computed <math alttext="P" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">italic_P</annotation></semantics></math>, <math alttext="R" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">italic_R</annotation></semantics></math> and <math alttext="F1" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml">F</mi><mo id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">⁢</mo><mn id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><times id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></times><ci id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">𝐹</ci><cn id="S4.SS3.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS3.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">italic_F 1</annotation></semantics></math> measure. We computed these metrics for each example in the dataset and averaged them over the gold standard to obtain <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.5.2">macro</span> values. Therefore, <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.5.3">macro</span> values represent the average of each metric over the gold standard. Although metric values for two US examples might be equal, the absolute amount of correct or erroneous classifications might differ significantly between US depending on the GUI component set length. For example, the second US example from Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.F3" title="Figure 3 ‣ V-B RQ2: User Story GUI Component Matching ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">3</span></a> is only associated with three respective GUI components, whereas another US from the gold standard about visualizing an overview of the daily nutrients consumed daily (see gold standard example 78 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib20" title="">20</a>]</cite>) has 20 associated GUI components. To take into account these set length differences across the gold standard and thus counter potential inaccurateness introduced by set length, we additionally constructed binary prediction arrays to compute respective <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.5.4">micro</span> values possessing correct weights i.e. double GUI component set length leads to double the influence on the final metric result. To conduct the experiments, we employed the identical setup of LLMs as described previously for RQ<sub class="ltx_sub" id="S4.SS3.p1.5.5"><span class="ltx_text ltx_font_italic" id="S4.SS3.p1.5.5.1">1</span></sub>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results and Discussion</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we briefly present the preliminary evaluation results and provide answers to our guiding research questions.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.6.2.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.1.1">RQ<sub class="ltx_sub" id="S5.SS1.1.1.1">1</sub>: User Story Implementation Detection</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.10">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.T1" title="Table I ‣ V-A RQ1: User Story Implementation Detection ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">I</span></a> illustrates the evaluation results for RQ<sub class="ltx_sub" id="S5.SS1.p1.10.3"><span class="ltx_text ltx_font_italic" id="S5.SS1.p1.10.3.1">1</span></sub>, showing the <math alttext="P" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mi id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><ci id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">italic_P</annotation></semantics></math>, <math alttext="R" class="ltx_Math" display="inline" id="S5.SS1.p1.3.m3.1"><semantics id="S5.SS1.p1.3.m3.1a"><mi id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><ci id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.3.m3.1d">italic_R</annotation></semantics></math> and <math alttext="F1" class="ltx_Math" display="inline" id="S5.SS1.p1.4.m4.1"><semantics id="S5.SS1.p1.4.m4.1a"><mrow id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml"><mi id="S5.SS1.p1.4.m4.1.1.2" xref="S5.SS1.p1.4.m4.1.1.2.cmml">F</mi><mo id="S5.SS1.p1.4.m4.1.1.1" xref="S5.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mn id="S5.SS1.p1.4.m4.1.1.3" xref="S5.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><apply id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1"><times id="S5.SS1.p1.4.m4.1.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1.1"></times><ci id="S5.SS1.p1.4.m4.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.2">𝐹</ci><cn id="S5.SS1.p1.4.m4.1.1.3.cmml" type="integer" xref="S5.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.4.m4.1d">italic_F 1</annotation></semantics></math> metrics for both classes and the <math alttext="ACC" class="ltx_Math" display="inline" id="S5.SS1.p1.5.m5.1"><semantics id="S5.SS1.p1.5.m5.1a"><mrow id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml"><mi id="S5.SS1.p1.5.m5.1.1.2" xref="S5.SS1.p1.5.m5.1.1.2.cmml">A</mi><mo id="S5.SS1.p1.5.m5.1.1.1" xref="S5.SS1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.5.m5.1.1.3" xref="S5.SS1.p1.5.m5.1.1.3.cmml">C</mi><mo id="S5.SS1.p1.5.m5.1.1.1a" xref="S5.SS1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.5.m5.1.1.4" xref="S5.SS1.p1.5.m5.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><apply id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1"><times id="S5.SS1.p1.5.m5.1.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1.1"></times><ci id="S5.SS1.p1.5.m5.1.1.2.cmml" xref="S5.SS1.p1.5.m5.1.1.2">𝐴</ci><ci id="S5.SS1.p1.5.m5.1.1.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3">𝐶</ci><ci id="S5.SS1.p1.5.m5.1.1.4.cmml" xref="S5.SS1.p1.5.m5.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">ACC</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.5.m5.1d">italic_A italic_C italic_C</annotation></semantics></math> over the created gold standard. First, we can observe a substantially high absolute performance across all of the investigated prompting methods indicated by, for example, <math alttext="ACC" class="ltx_Math" display="inline" id="S5.SS1.p1.6.m6.1"><semantics id="S5.SS1.p1.6.m6.1a"><mrow id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml"><mi id="S5.SS1.p1.6.m6.1.1.2" xref="S5.SS1.p1.6.m6.1.1.2.cmml">A</mi><mo id="S5.SS1.p1.6.m6.1.1.1" xref="S5.SS1.p1.6.m6.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.1.1.3" xref="S5.SS1.p1.6.m6.1.1.3.cmml">C</mi><mo id="S5.SS1.p1.6.m6.1.1.1a" xref="S5.SS1.p1.6.m6.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.1.1.4" xref="S5.SS1.p1.6.m6.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><apply id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1"><times id="S5.SS1.p1.6.m6.1.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1.1"></times><ci id="S5.SS1.p1.6.m6.1.1.2.cmml" xref="S5.SS1.p1.6.m6.1.1.2">𝐴</ci><ci id="S5.SS1.p1.6.m6.1.1.3.cmml" xref="S5.SS1.p1.6.m6.1.1.3">𝐶</ci><ci id="S5.SS1.p1.6.m6.1.1.4.cmml" xref="S5.SS1.p1.6.m6.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">ACC</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.6.m6.1d">italic_A italic_C italic_C</annotation></semantics></math> scores of .852 (<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.10.4">ZS</span>), .848 (<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.7.1">FS<sub class="ltx_sub" id="S5.SS1.p1.7.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS1.p1.7.1.1.1">5</span></sub></span>) and .829 (<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.8.2">CoT<sub class="ltx_sub" id="S5.SS1.p1.8.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS1.p1.8.2.1.1">t=1</span></sub></span>). This indicates that LLMs are capable of effectively processing the semantics of the created GUI abstraction and match it to the semantics of the functionality encompassed in the user stories. These high metric values indicate that LLMs can produce promising results for the approach. Although the <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.10.5">ZS</span> method seems to perform best overall, the respective pairwise <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.10.6">McNemar</span> tests between each of the seemingly best performing models of each prompting method indicates no statistical significance. Moreover, the <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.10.7">CoT</span> methods apparently tend to be more restrictive about predicting that a user story is implemented, as indicated by the highest <math alttext="P_{1}" class="ltx_Math" display="inline" id="S5.SS1.p1.9.m7.1"><semantics id="S5.SS1.p1.9.m7.1a"><msub id="S5.SS1.p1.9.m7.1.1" xref="S5.SS1.p1.9.m7.1.1.cmml"><mi id="S5.SS1.p1.9.m7.1.1.2" xref="S5.SS1.p1.9.m7.1.1.2.cmml">P</mi><mn id="S5.SS1.p1.9.m7.1.1.3" xref="S5.SS1.p1.9.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.9.m7.1b"><apply id="S5.SS1.p1.9.m7.1.1.cmml" xref="S5.SS1.p1.9.m7.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.9.m7.1.1.1.cmml" xref="S5.SS1.p1.9.m7.1.1">subscript</csymbol><ci id="S5.SS1.p1.9.m7.1.1.2.cmml" xref="S5.SS1.p1.9.m7.1.1.2">𝑃</ci><cn id="S5.SS1.p1.9.m7.1.1.3.cmml" type="integer" xref="S5.SS1.p1.9.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.9.m7.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.9.m7.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="R_{0}" class="ltx_Math" display="inline" id="S5.SS1.p1.10.m8.1"><semantics id="S5.SS1.p1.10.m8.1a"><msub id="S5.SS1.p1.10.m8.1.1" xref="S5.SS1.p1.10.m8.1.1.cmml"><mi id="S5.SS1.p1.10.m8.1.1.2" xref="S5.SS1.p1.10.m8.1.1.2.cmml">R</mi><mn id="S5.SS1.p1.10.m8.1.1.3" xref="S5.SS1.p1.10.m8.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.10.m8.1b"><apply id="S5.SS1.p1.10.m8.1.1.cmml" xref="S5.SS1.p1.10.m8.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.10.m8.1.1.1.cmml" xref="S5.SS1.p1.10.m8.1.1">subscript</csymbol><ci id="S5.SS1.p1.10.m8.1.1.2.cmml" xref="S5.SS1.p1.10.m8.1.1.2">𝑅</ci><cn id="S5.SS1.p1.10.m8.1.1.3.cmml" type="integer" xref="S5.SS1.p1.10.m8.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.10.m8.1c">R_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.10.m8.1d">italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> values. In contrast, the <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.10.8">ZS</span> and <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.10.9">FS</span> methods appear to be more balanced among the metrics and classes.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T1.17.1.1" style="font-size:113%;">Table I</span>: </span><span class="ltx_text" id="S5.T1.18.2" style="font-size:113%;">Evaluation results of various LLM-based prompting approaches for US validation in GUI prototypes (Binary class.)</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T1.13">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.13.14.1">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S5.T1.13.14.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S5.T1.13.14.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.13.14.1.2.1" style="font-size:80%;">US Implemented (1)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S5.T1.13.14.1.3"><span class="ltx_text ltx_font_bold" id="S5.T1.13.14.1.3.1" style="font-size:80%;">Not-Implemented (0)</span></td>
<td class="ltx_td ltx_border_tt" id="S5.T1.13.14.1.4"></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7">
<td class="ltx_td ltx_border_r" id="S5.T1.7.7.8"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.1"><math alttext="P_{1}" class="ltx_Math" display="inline" id="S5.T1.1.1.1.m1.1"><semantics id="S5.T1.1.1.1.m1.1a"><msub id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml"><mi id="S5.T1.1.1.1.m1.1.1.2" mathsize="80%" xref="S5.T1.1.1.1.m1.1.1.2.cmml">P</mi><mn id="S5.T1.1.1.1.m1.1.1.3" mathsize="80%" xref="S5.T1.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T1.1.1.1.m1.1.1.2.cmml" xref="S5.T1.1.1.1.m1.1.1.2">𝑃</ci><cn id="S5.T1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.2.2.2"><math alttext="R_{1}" class="ltx_Math" display="inline" id="S5.T1.2.2.2.m1.1"><semantics id="S5.T1.2.2.2.m1.1a"><msub id="S5.T1.2.2.2.m1.1.1" xref="S5.T1.2.2.2.m1.1.1.cmml"><mi id="S5.T1.2.2.2.m1.1.1.2" mathsize="80%" xref="S5.T1.2.2.2.m1.1.1.2.cmml">R</mi><mn id="S5.T1.2.2.2.m1.1.1.3" mathsize="80%" xref="S5.T1.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.m1.1b"><apply id="S5.T1.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.2.2.2.m1.1.1.1.cmml" xref="S5.T1.2.2.2.m1.1.1">subscript</csymbol><ci id="S5.T1.2.2.2.m1.1.1.2.cmml" xref="S5.T1.2.2.2.m1.1.1.2">𝑅</ci><cn id="S5.T1.2.2.2.m1.1.1.3.cmml" type="integer" xref="S5.T1.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.m1.1c">R_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.2.2.2.m1.1d">italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.3.3.3"><math alttext="F1_{1}" class="ltx_Math" display="inline" id="S5.T1.3.3.3.m1.1"><semantics id="S5.T1.3.3.3.m1.1a"><mrow id="S5.T1.3.3.3.m1.1.1" xref="S5.T1.3.3.3.m1.1.1.cmml"><mi id="S5.T1.3.3.3.m1.1.1.2" mathsize="80%" xref="S5.T1.3.3.3.m1.1.1.2.cmml">F</mi><mo id="S5.T1.3.3.3.m1.1.1.1" xref="S5.T1.3.3.3.m1.1.1.1.cmml">⁢</mo><msub id="S5.T1.3.3.3.m1.1.1.3" xref="S5.T1.3.3.3.m1.1.1.3.cmml"><mn id="S5.T1.3.3.3.m1.1.1.3.2" mathsize="80%" xref="S5.T1.3.3.3.m1.1.1.3.2.cmml">1</mn><mn id="S5.T1.3.3.3.m1.1.1.3.3" mathsize="80%" xref="S5.T1.3.3.3.m1.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.m1.1b"><apply id="S5.T1.3.3.3.m1.1.1.cmml" xref="S5.T1.3.3.3.m1.1.1"><times id="S5.T1.3.3.3.m1.1.1.1.cmml" xref="S5.T1.3.3.3.m1.1.1.1"></times><ci id="S5.T1.3.3.3.m1.1.1.2.cmml" xref="S5.T1.3.3.3.m1.1.1.2">𝐹</ci><apply id="S5.T1.3.3.3.m1.1.1.3.cmml" xref="S5.T1.3.3.3.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T1.3.3.3.m1.1.1.3.1.cmml" xref="S5.T1.3.3.3.m1.1.1.3">subscript</csymbol><cn id="S5.T1.3.3.3.m1.1.1.3.2.cmml" type="integer" xref="S5.T1.3.3.3.m1.1.1.3.2">1</cn><cn id="S5.T1.3.3.3.m1.1.1.3.3.cmml" type="integer" xref="S5.T1.3.3.3.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.m1.1c">F1_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.3.3.3.m1.1d">italic_F 1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.4.4.4"><math alttext="P_{0}" class="ltx_Math" display="inline" id="S5.T1.4.4.4.m1.1"><semantics id="S5.T1.4.4.4.m1.1a"><msub id="S5.T1.4.4.4.m1.1.1" xref="S5.T1.4.4.4.m1.1.1.cmml"><mi id="S5.T1.4.4.4.m1.1.1.2" mathsize="80%" xref="S5.T1.4.4.4.m1.1.1.2.cmml">P</mi><mn id="S5.T1.4.4.4.m1.1.1.3" mathsize="80%" xref="S5.T1.4.4.4.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.m1.1b"><apply id="S5.T1.4.4.4.m1.1.1.cmml" xref="S5.T1.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.4.4.4.m1.1.1.1.cmml" xref="S5.T1.4.4.4.m1.1.1">subscript</csymbol><ci id="S5.T1.4.4.4.m1.1.1.2.cmml" xref="S5.T1.4.4.4.m1.1.1.2">𝑃</ci><cn id="S5.T1.4.4.4.m1.1.1.3.cmml" type="integer" xref="S5.T1.4.4.4.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.m1.1c">P_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.4.4.4.m1.1d">italic_P start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.5.5.5"><math alttext="R_{0}" class="ltx_Math" display="inline" id="S5.T1.5.5.5.m1.1"><semantics id="S5.T1.5.5.5.m1.1a"><msub id="S5.T1.5.5.5.m1.1.1" xref="S5.T1.5.5.5.m1.1.1.cmml"><mi id="S5.T1.5.5.5.m1.1.1.2" mathsize="80%" xref="S5.T1.5.5.5.m1.1.1.2.cmml">R</mi><mn id="S5.T1.5.5.5.m1.1.1.3" mathsize="80%" xref="S5.T1.5.5.5.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.m1.1b"><apply id="S5.T1.5.5.5.m1.1.1.cmml" xref="S5.T1.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.5.5.5.m1.1.1.1.cmml" xref="S5.T1.5.5.5.m1.1.1">subscript</csymbol><ci id="S5.T1.5.5.5.m1.1.1.2.cmml" xref="S5.T1.5.5.5.m1.1.1.2">𝑅</ci><cn id="S5.T1.5.5.5.m1.1.1.3.cmml" type="integer" xref="S5.T1.5.5.5.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.m1.1c">R_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.5.5.5.m1.1d">italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.6.6.6"><math alttext="F1_{0}" class="ltx_Math" display="inline" id="S5.T1.6.6.6.m1.1"><semantics id="S5.T1.6.6.6.m1.1a"><mrow id="S5.T1.6.6.6.m1.1.1" xref="S5.T1.6.6.6.m1.1.1.cmml"><mi id="S5.T1.6.6.6.m1.1.1.2" mathsize="80%" xref="S5.T1.6.6.6.m1.1.1.2.cmml">F</mi><mo id="S5.T1.6.6.6.m1.1.1.1" xref="S5.T1.6.6.6.m1.1.1.1.cmml">⁢</mo><msub id="S5.T1.6.6.6.m1.1.1.3" xref="S5.T1.6.6.6.m1.1.1.3.cmml"><mn id="S5.T1.6.6.6.m1.1.1.3.2" mathsize="80%" xref="S5.T1.6.6.6.m1.1.1.3.2.cmml">1</mn><mn id="S5.T1.6.6.6.m1.1.1.3.3" mathsize="80%" xref="S5.T1.6.6.6.m1.1.1.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.m1.1b"><apply id="S5.T1.6.6.6.m1.1.1.cmml" xref="S5.T1.6.6.6.m1.1.1"><times id="S5.T1.6.6.6.m1.1.1.1.cmml" xref="S5.T1.6.6.6.m1.1.1.1"></times><ci id="S5.T1.6.6.6.m1.1.1.2.cmml" xref="S5.T1.6.6.6.m1.1.1.2">𝐹</ci><apply id="S5.T1.6.6.6.m1.1.1.3.cmml" xref="S5.T1.6.6.6.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T1.6.6.6.m1.1.1.3.1.cmml" xref="S5.T1.6.6.6.m1.1.1.3">subscript</csymbol><cn id="S5.T1.6.6.6.m1.1.1.3.2.cmml" type="integer" xref="S5.T1.6.6.6.m1.1.1.3.2">1</cn><cn id="S5.T1.6.6.6.m1.1.1.3.3.cmml" type="integer" xref="S5.T1.6.6.6.m1.1.1.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.m1.1c">F1_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.6.6.6.m1.1d">italic_F 1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.7.7.7"><math alttext="ACC" class="ltx_Math" display="inline" id="S5.T1.7.7.7.m1.1"><semantics id="S5.T1.7.7.7.m1.1a"><mrow id="S5.T1.7.7.7.m1.1.1" xref="S5.T1.7.7.7.m1.1.1.cmml"><mi id="S5.T1.7.7.7.m1.1.1.2" mathsize="80%" xref="S5.T1.7.7.7.m1.1.1.2.cmml">A</mi><mo id="S5.T1.7.7.7.m1.1.1.1" xref="S5.T1.7.7.7.m1.1.1.1.cmml">⁢</mo><mi id="S5.T1.7.7.7.m1.1.1.3" mathsize="80%" xref="S5.T1.7.7.7.m1.1.1.3.cmml">C</mi><mo id="S5.T1.7.7.7.m1.1.1.1a" xref="S5.T1.7.7.7.m1.1.1.1.cmml">⁢</mo><mi id="S5.T1.7.7.7.m1.1.1.4" mathsize="80%" xref="S5.T1.7.7.7.m1.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.7.m1.1b"><apply id="S5.T1.7.7.7.m1.1.1.cmml" xref="S5.T1.7.7.7.m1.1.1"><times id="S5.T1.7.7.7.m1.1.1.1.cmml" xref="S5.T1.7.7.7.m1.1.1.1"></times><ci id="S5.T1.7.7.7.m1.1.1.2.cmml" xref="S5.T1.7.7.7.m1.1.1.2">𝐴</ci><ci id="S5.T1.7.7.7.m1.1.1.3.cmml" xref="S5.T1.7.7.7.m1.1.1.3">𝐶</ci><ci id="S5.T1.7.7.7.m1.1.1.4.cmml" xref="S5.T1.7.7.7.m1.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.7.m1.1c">ACC</annotation><annotation encoding="application/x-llamapun" id="S5.T1.7.7.7.m1.1d">italic_A italic_C italic_C</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T1.13.15.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.13.15.2.1"><span class="ltx_text ltx_font_bold" id="S5.T1.13.15.2.1.1" style="font-size:80%;">Zero-Shot</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.13.15.2.2"><span class="ltx_text" id="S5.T1.13.15.2.2.1" style="font-size:80%;">.830</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.13.15.2.3"><span class="ltx_text" id="S5.T1.13.15.2.3.1" style="font-size:80%;">.886</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.13.15.2.4"><span class="ltx_text" id="S5.T1.13.15.2.4.1" style="font-size:80%;">.857</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.13.15.2.5"><span class="ltx_text" id="S5.T1.13.15.2.5.1" style="font-size:80%;">.878</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.13.15.2.6"><span class="ltx_text" id="S5.T1.13.15.2.6.1" style="font-size:80%;">.819</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.13.15.2.7"><span class="ltx_text" id="S5.T1.13.15.2.7.1" style="font-size:80%;">.847</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.13.15.2.8"><span class="ltx_text" id="S5.T1.13.15.2.8.1" style="font-size:80%;">.852</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.8.8" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.8.8.1"><span class="ltx_text ltx_font_bold" id="S5.T1.8.8.1.1" style="font-size:80%;background-color:#E6E6E6;">Few-Shot<sub class="ltx_sub" id="S5.T1.8.8.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T1.8.8.1.1.1.1">5</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.8.8.2"><span class="ltx_text" id="S5.T1.8.8.2.1" style="font-size:80%;background-color:#E6E6E6;">.829</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.8.8.3"><span class="ltx_text" id="S5.T1.8.8.3.1" style="font-size:80%;background-color:#E6E6E6;">.876</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.8.8.4"><span class="ltx_text" id="S5.T1.8.8.4.1" style="font-size:80%;background-color:#E6E6E6;">.852</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.8.8.5"><span class="ltx_text" id="S5.T1.8.8.5.1" style="font-size:80%;background-color:#E6E6E6;">.869</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.8.8.6"><span class="ltx_text" id="S5.T1.8.8.6.1" style="font-size:80%;background-color:#E6E6E6;">.819</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.8.8.7"><span class="ltx_text" id="S5.T1.8.8.7.1" style="font-size:80%;background-color:#E6E6E6;">.843</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.8.8.8"><span class="ltx_text" id="S5.T1.8.8.8.1" style="font-size:80%;background-color:#E6E6E6;">.848</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.9.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.9.9.1"><span class="ltx_text ltx_font_bold" id="S5.T1.9.9.1.1" style="font-size:80%;">Few-Shot<sub class="ltx_sub" id="S5.T1.9.9.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T1.9.9.1.1.1.1">10</span></sub></span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.9.2"><span class="ltx_text" id="S5.T1.9.9.2.1" style="font-size:80%;">.818</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.9.3"><span class="ltx_text" id="S5.T1.9.9.3.1" style="font-size:80%;">.857</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.9.9.4"><span class="ltx_text" id="S5.T1.9.9.4.1" style="font-size:80%;">.837</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.9.5"><span class="ltx_text" id="S5.T1.9.9.5.1" style="font-size:80%;">.850</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.9.6"><span class="ltx_text" id="S5.T1.9.9.6.1" style="font-size:80%;">.810</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.9.9.7"><span class="ltx_text" id="S5.T1.9.9.7.1" style="font-size:80%;">.829</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.9.8"><span class="ltx_text" id="S5.T1.9.9.8.1" style="font-size:80%;">.833</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.10.10" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.10.10.1"><span class="ltx_text ltx_font_bold" id="S5.T1.10.10.1.1" style="font-size:80%;background-color:#E6E6E6;">CoT<sub class="ltx_sub" id="S5.T1.10.10.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T1.10.10.1.1.1.1">t=0</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.10.10.2"><span class="ltx_text" id="S5.T1.10.10.2.1" style="font-size:80%;background-color:#E6E6E6;">.900</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.10.10.3"><span class="ltx_text" id="S5.T1.10.10.3.1" style="font-size:80%;background-color:#E6E6E6;">.686</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.10.10.4"><span class="ltx_text" id="S5.T1.10.10.4.1" style="font-size:80%;background-color:#E6E6E6;">.778</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.10.10.5"><span class="ltx_text" id="S5.T1.10.10.5.1" style="font-size:80%;background-color:#E6E6E6;">.746</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.10.10.6"><span class="ltx_text" id="S5.T1.10.10.6.1" style="font-size:80%;background-color:#E6E6E6;">.924</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.10.10.7"><span class="ltx_text" id="S5.T1.10.10.7.1" style="font-size:80%;background-color:#E6E6E6;">.826</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.10.10.8"><span class="ltx_text" id="S5.T1.10.10.8.1" style="font-size:80%;background-color:#E6E6E6;">.805</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.11.11.1"><span class="ltx_text ltx_font_bold" id="S5.T1.11.11.1.1" style="font-size:80%;">CoT<sub class="ltx_sub" id="S5.T1.11.11.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T1.11.11.1.1.1.1">t=.5</span></sub></span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.11.2"><span class="ltx_text" id="S5.T1.11.11.2.1" style="font-size:80%;">.888</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.11.3"><span class="ltx_text" id="S5.T1.11.11.3.1" style="font-size:80%;">.676</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.11.11.4"><span class="ltx_text" id="S5.T1.11.11.4.1" style="font-size:80%;">.768</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.11.5"><span class="ltx_text" id="S5.T1.11.11.5.1" style="font-size:80%;">.738</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.11.6"><span class="ltx_text" id="S5.T1.11.11.6.1" style="font-size:80%;">.914</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.11.11.7"><span class="ltx_text" id="S5.T1.11.11.7.1" style="font-size:80%;">.817</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.11.8"><span class="ltx_text" id="S5.T1.11.11.8.1" style="font-size:80%;">.795</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.12" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.12.12.1"><span class="ltx_text ltx_font_bold" id="S5.T1.12.12.1.1" style="font-size:80%;background-color:#E6E6E6;">CoT<sub class="ltx_sub" id="S5.T1.12.12.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T1.12.12.1.1.1.1">t=1</span></sub></span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.12.2"><span class="ltx_text" id="S5.T1.12.12.2.1" style="font-size:80%;background-color:#E6E6E6;">.888</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.12.3"><span class="ltx_text" id="S5.T1.12.12.3.1" style="font-size:80%;background-color:#E6E6E6;">.752</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.12.12.4"><span class="ltx_text" id="S5.T1.12.12.4.1" style="font-size:80%;background-color:#E6E6E6;">.814</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.12.5"><span class="ltx_text" id="S5.T1.12.12.5.1" style="font-size:80%;background-color:#E6E6E6;">.785</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.12.6"><span class="ltx_text" id="S5.T1.12.12.6.1" style="font-size:80%;background-color:#E6E6E6;">.905</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.12.12.7"><span class="ltx_text" id="S5.T1.12.12.7.1" style="font-size:80%;background-color:#E6E6E6;">.841</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.12.8"><span class="ltx_text" id="S5.T1.12.12.8.1" style="font-size:80%;background-color:#E6E6E6;">.829</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.13.13">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_r" id="S5.T1.13.13.1"><span class="ltx_text ltx_font_bold" id="S5.T1.13.13.1.1" style="font-size:80%;">CoT<sub class="ltx_sub" id="S5.T1.13.13.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T1.13.13.1.1.1.1">t=1.3</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T1.13.13.2"><span class="ltx_text" id="S5.T1.13.13.2.1" style="font-size:80%;">.812</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T1.13.13.3"><span class="ltx_text" id="S5.T1.13.13.3.1" style="font-size:80%;">.743</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r" id="S5.T1.13.13.4"><span class="ltx_text" id="S5.T1.13.13.4.1" style="font-size:80%;">.776</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T1.13.13.5"><span class="ltx_text" id="S5.T1.13.13.5.1" style="font-size:80%;">.763</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T1.13.13.6"><span class="ltx_text" id="S5.T1.13.13.6.1" style="font-size:80%;">.829</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r" id="S5.T1.13.13.7"><span class="ltx_text" id="S5.T1.13.13.7.1" style="font-size:80%;">.795</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T1.13.13.8"><span class="ltx_text" id="S5.T1.13.13.8.1" style="font-size:80%;">.786</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.3">To enhance the understanding of the misclassifications made by the LLM, we conducted an error analysis and investigated the <math alttext="FP" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">F</mi><mo id="S5.SS1.p2.1.m1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><times id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1"></times><ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">𝐹</ci><ci id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">FP</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">italic_F italic_P</annotation></semantics></math> and <math alttext="FN" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1"><semantics id="S5.SS1.p2.2.m2.1a"><mrow id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml"><mi id="S5.SS1.p2.2.m2.1.1.2" xref="S5.SS1.p2.2.m2.1.1.2.cmml">F</mi><mo id="S5.SS1.p2.2.m2.1.1.1" xref="S5.SS1.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><times id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1"></times><ci id="S5.SS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.2">𝐹</ci><ci id="S5.SS1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">FN</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.1d">italic_F italic_N</annotation></semantics></math> instances. For the <math alttext="FP" class="ltx_Math" display="inline" id="S5.SS1.p2.3.m3.1"><semantics id="S5.SS1.p2.3.m3.1a"><mrow id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><mi id="S5.SS1.p2.3.m3.1.1.2" xref="S5.SS1.p2.3.m3.1.1.2.cmml">F</mi><mo id="S5.SS1.p2.3.m3.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p2.3.m3.1.1.3" xref="S5.SS1.p2.3.m3.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><times id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1.1"></times><ci id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2">𝐹</ci><ci id="S5.SS1.p2.3.m3.1.1.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">FP</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.3.m3.1d">italic_F italic_P</annotation></semantics></math> instances, the main root cause for misclassifications appears to be a semantic misinterpretation of GUI components with reference to the user story by the LLM. For example, for a user story that describes to provide addresses of the nearest stores the LLM identifies the component <span class="ltx_text ltx_font_italic" id="S5.SS1.p2.3.1">”SAN FRANCISCO, Store #6498”</span> <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.3.2">(Button)</span> <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.3.3">(storelocator address line1)</span> as fulfilling the user story, although this component merely provides the city name and the detailed address fields were absent. Similarly, for the user story to enable/disable the ability to mark days as complete within a settings GUI of a fitness app, the LLM identified the GUI component <span class="ltx_text ltx_font_italic" id="S5.SS1.p2.3.4">”check”</span> <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.3.5">(Icon)</span> <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.3.6">(done)</span> as fulfilling the user story. However, this component is located in the GUI toolbar and refers to saving the overall settings.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">For the <math alttext="FN" class="ltx_Math" display="inline" id="S5.SS1.p3.1.m1.1"><semantics id="S5.SS1.p3.1.m1.1a"><mrow id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mi id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">F</mi><mo id="S5.SS1.p3.1.m1.1.1.1" xref="S5.SS1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><times id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1.1"></times><ci id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">𝐹</ci><ci id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">FN</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.1.m1.1d">italic_F italic_N</annotation></semantics></math> instances, we identified several similar main root causes. Often, detailed semantic information about the functionality of the GUI components might be absent in the created GUI abstraction resulting in the LLM being restrictive about positively identifying the user story as fulfilled. For example, a user story requiring a donation button to easily donate money could not be detected, since the GUI component was implemented as an image without any further textual description, hence, the image information is not accessible to the model. Similarly, a user story to add new shopping lists to a collection of lists could not be identified since the description of the GUI component <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.1.1">”add”</span> <span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.2">(Icon)</span> <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p3.1.3">(overview viewpager fab)</span> is general and ambiguous for detection.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.6.2.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.1.1">RQ<sub class="ltx_sub" id="S5.SS2.1.1.1">2</sub>: User Story GUI Component Matching</span>
</h3>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.18.1.1" style="font-size:113%;">Table II</span>: </span><span class="ltx_text" id="S5.T2.19.2" style="font-size:113%;">Evaluation results of various LLM-based prompting approaches for (comp.) matching of US in GUI prototypes</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.14">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.14.15.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.14.15.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S5.T2.14.15.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.14.15.1.2.1" style="font-size:80%;">Macro</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S5.T2.14.15.1.3"><span class="ltx_text ltx_font_bold" id="S5.T2.14.15.1.3.1" style="font-size:80%;">Micro</span></th>
</tr>
<tr class="ltx_tr" id="S5.T2.7.7">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S5.T2.7.7.8"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.1"><math alttext="P" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.m1.1a"><mi id="S5.T2.1.1.1.m1.1.1" mathsize="80%" xref="S5.T2.1.1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.m1.1d">italic_P</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.2.2.2"><math alttext="R" class="ltx_Math" display="inline" id="S5.T2.2.2.2.m1.1"><semantics id="S5.T2.2.2.2.m1.1a"><mi id="S5.T2.2.2.2.m1.1.1" mathsize="80%" xref="S5.T2.2.2.2.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.m1.1d">italic_R</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.3.3.3"><math alttext="F1" class="ltx_Math" display="inline" id="S5.T2.3.3.3.m1.1"><semantics id="S5.T2.3.3.3.m1.1a"><mrow id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml"><mi id="S5.T2.3.3.3.m1.1.1.2" mathsize="80%" xref="S5.T2.3.3.3.m1.1.1.2.cmml">F</mi><mo id="S5.T2.3.3.3.m1.1.1.1" xref="S5.T2.3.3.3.m1.1.1.1.cmml">⁢</mo><mn id="S5.T2.3.3.3.m1.1.1.3" mathsize="80%" xref="S5.T2.3.3.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><apply id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1"><times id="S5.T2.3.3.3.m1.1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1.1"></times><ci id="S5.T2.3.3.3.m1.1.1.2.cmml" xref="S5.T2.3.3.3.m1.1.1.2">𝐹</ci><cn id="S5.T2.3.3.3.m1.1.1.3.cmml" type="integer" xref="S5.T2.3.3.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.m1.1d">italic_F 1</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.4.4.4"><math alttext="P" class="ltx_Math" display="inline" id="S5.T2.4.4.4.m1.1"><semantics id="S5.T2.4.4.4.m1.1a"><mi id="S5.T2.4.4.4.m1.1.1" mathsize="80%" xref="S5.T2.4.4.4.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.m1.1b"><ci id="S5.T2.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.4.m1.1d">italic_P</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.5.5.5"><math alttext="R" class="ltx_Math" display="inline" id="S5.T2.5.5.5.m1.1"><semantics id="S5.T2.5.5.5.m1.1a"><mi id="S5.T2.5.5.5.m1.1.1" mathsize="80%" xref="S5.T2.5.5.5.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.m1.1b"><ci id="S5.T2.5.5.5.m1.1.1.cmml" xref="S5.T2.5.5.5.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.m1.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.5.m1.1d">italic_R</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.6.6.6"><math alttext="F1" class="ltx_Math" display="inline" id="S5.T2.6.6.6.m1.1"><semantics id="S5.T2.6.6.6.m1.1a"><mrow id="S5.T2.6.6.6.m1.1.1" xref="S5.T2.6.6.6.m1.1.1.cmml"><mi id="S5.T2.6.6.6.m1.1.1.2" mathsize="80%" xref="S5.T2.6.6.6.m1.1.1.2.cmml">F</mi><mo id="S5.T2.6.6.6.m1.1.1.1" xref="S5.T2.6.6.6.m1.1.1.1.cmml">⁢</mo><mn id="S5.T2.6.6.6.m1.1.1.3" mathsize="80%" xref="S5.T2.6.6.6.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.m1.1b"><apply id="S5.T2.6.6.6.m1.1.1.cmml" xref="S5.T2.6.6.6.m1.1.1"><times id="S5.T2.6.6.6.m1.1.1.1.cmml" xref="S5.T2.6.6.6.m1.1.1.1"></times><ci id="S5.T2.6.6.6.m1.1.1.2.cmml" xref="S5.T2.6.6.6.m1.1.1.2">𝐹</ci><cn id="S5.T2.6.6.6.m1.1.1.3.cmml" type="integer" xref="S5.T2.6.6.6.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.6.m1.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.6.m1.1d">italic_F 1</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.7.7"><math alttext="ACC" class="ltx_Math" display="inline" id="S5.T2.7.7.7.m1.1"><semantics id="S5.T2.7.7.7.m1.1a"><mrow id="S5.T2.7.7.7.m1.1.1" xref="S5.T2.7.7.7.m1.1.1.cmml"><mi id="S5.T2.7.7.7.m1.1.1.2" mathsize="80%" xref="S5.T2.7.7.7.m1.1.1.2.cmml">A</mi><mo id="S5.T2.7.7.7.m1.1.1.1" xref="S5.T2.7.7.7.m1.1.1.1.cmml">⁢</mo><mi id="S5.T2.7.7.7.m1.1.1.3" mathsize="80%" xref="S5.T2.7.7.7.m1.1.1.3.cmml">C</mi><mo id="S5.T2.7.7.7.m1.1.1.1a" xref="S5.T2.7.7.7.m1.1.1.1.cmml">⁢</mo><mi id="S5.T2.7.7.7.m1.1.1.4" mathsize="80%" xref="S5.T2.7.7.7.m1.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.m1.1b"><apply id="S5.T2.7.7.7.m1.1.1.cmml" xref="S5.T2.7.7.7.m1.1.1"><times id="S5.T2.7.7.7.m1.1.1.1.cmml" xref="S5.T2.7.7.7.m1.1.1.1"></times><ci id="S5.T2.7.7.7.m1.1.1.2.cmml" xref="S5.T2.7.7.7.m1.1.1.2">𝐴</ci><ci id="S5.T2.7.7.7.m1.1.1.3.cmml" xref="S5.T2.7.7.7.m1.1.1.3">𝐶</ci><ci id="S5.T2.7.7.7.m1.1.1.4.cmml" xref="S5.T2.7.7.7.m1.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.7.m1.1c">ACC</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.7.7.m1.1d">italic_A italic_C italic_C</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.8.8">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.8.8.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.8.1.1" style="font-size:80%;">Zero-Shot<sub class="ltx_sub" id="S5.T2.8.8.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.8.8.1.1.1.1">A</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.8.2"><span class="ltx_text" id="S5.T2.8.8.2.1" style="font-size:80%;">.784</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.8.3"><span class="ltx_text" id="S5.T2.8.8.3.1" style="font-size:80%;">.819</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.8.4"><span class="ltx_text" id="S5.T2.8.8.4.1" style="font-size:80%;">.755</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.8.5"><span class="ltx_text" id="S5.T2.8.8.5.1" style="font-size:80%;">.620</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.8.6"><span class="ltx_text" id="S5.T2.8.8.6.1" style="font-size:80%;">.755</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.8.7"><span class="ltx_text" id="S5.T2.8.8.7.1" style="font-size:80%;">.681</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.8.8"><span class="ltx_text" id="S5.T2.8.8.8.1" style="font-size:80%;">.516</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.9" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.9.9.1"><span class="ltx_text ltx_font_bold" id="S5.T2.9.9.1.1" style="font-size:80%;background-color:#E6E6E6;">Zero-Shot<sub class="ltx_sub" id="S5.T2.9.9.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.9.9.1.1.1.1">B</span></sub></span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.2"><span class="ltx_text" id="S5.T2.9.9.2.1" style="font-size:80%;background-color:#E6E6E6;">.718</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.3"><span class="ltx_text" id="S5.T2.9.9.3.1" style="font-size:80%;background-color:#E6E6E6;">.903</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.9.9.4"><span class="ltx_text" id="S5.T2.9.9.4.1" style="font-size:80%;background-color:#E6E6E6;">.743</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.5"><span class="ltx_text" id="S5.T2.9.9.5.1" style="font-size:80%;background-color:#E6E6E6;">.502</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.6"><span class="ltx_text" id="S5.T2.9.9.6.1" style="font-size:80%;background-color:#E6E6E6;">.858</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.7"><span class="ltx_text" id="S5.T2.9.9.7.1" style="font-size:80%;background-color:#E6E6E6;">.633</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.8"><span class="ltx_text" id="S5.T2.9.9.8.1" style="font-size:80%;background-color:#E6E6E6;">.463</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.10.10.1"><span class="ltx_text ltx_font_bold" id="S5.T2.10.10.1.1" style="font-size:80%;">Few-Shot<sub class="ltx_sub" id="S5.T2.10.10.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.10.10.1.1.1.1">5</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.2"><span class="ltx_text" id="S5.T2.10.10.2.1" style="font-size:80%;">.850</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.3"><span class="ltx_text" id="S5.T2.10.10.3.1" style="font-size:80%;">.755</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.10.10.4"><span class="ltx_text" id="S5.T2.10.10.4.1" style="font-size:80%;">.765</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.5"><span class="ltx_text" id="S5.T2.10.10.5.1" style="font-size:80%;">.677</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.6"><span class="ltx_text" id="S5.T2.10.10.6.1" style="font-size:80%;">.643</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.7"><span class="ltx_text" id="S5.T2.10.10.7.1" style="font-size:80%;">.659</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.8"><span class="ltx_text" id="S5.T2.10.10.8.1" style="font-size:80%;">.492</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.11.11.1"><span class="ltx_text ltx_font_bold" id="S5.T2.11.11.1.1" style="font-size:80%;background-color:#E6E6E6;">CoT<sub class="ltx_sub" id="S5.T2.11.11.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.11.11.1.1.1.1">t=0</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.2"><span class="ltx_text" id="S5.T2.11.11.2.1" style="font-size:80%;background-color:#E6E6E6;">.758</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.3"><span class="ltx_text" id="S5.T2.11.11.3.1" style="font-size:80%;background-color:#E6E6E6;">.806</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.11.11.4"><span class="ltx_text" id="S5.T2.11.11.4.1" style="font-size:80%;background-color:#E6E6E6;">.727</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.5"><span class="ltx_text" id="S5.T2.11.11.5.1" style="font-size:80%;background-color:#E6E6E6;">.557</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.6"><span class="ltx_text" id="S5.T2.11.11.6.1" style="font-size:80%;background-color:#E6E6E6;">.731</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.7"><span class="ltx_text" id="S5.T2.11.11.7.1" style="font-size:80%;background-color:#E6E6E6;">.632</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.8"><span class="ltx_text" id="S5.T2.11.11.8.1" style="font-size:80%;background-color:#E6E6E6;">.462</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.12.12.1"><span class="ltx_text ltx_font_bold" id="S5.T2.12.12.1.1" style="font-size:80%;">CoT<sub class="ltx_sub" id="S5.T2.12.12.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.12.12.1.1.1.1">t=.5</span></sub></span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.2"><span class="ltx_text" id="S5.T2.12.12.2.1" style="font-size:80%;">.721</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.3"><span class="ltx_text" id="S5.T2.12.12.3.1" style="font-size:80%;">.788</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.12.12.4"><span class="ltx_text" id="S5.T2.12.12.4.1" style="font-size:80%;">.688</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.5"><span class="ltx_text" id="S5.T2.12.12.5.1" style="font-size:80%;">.492</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.6"><span class="ltx_text" id="S5.T2.12.12.6.1" style="font-size:80%;">.710</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.7"><span class="ltx_text" id="S5.T2.12.12.7.1" style="font-size:80%;">.581</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.8"><span class="ltx_text" id="S5.T2.12.12.8.1" style="font-size:80%;">.409</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.13" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.13.13.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.13.1.1" style="font-size:80%;background-color:#E6E6E6;">CoT<sub class="ltx_sub" id="S5.T2.13.13.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.13.13.1.1.1.1">t=1</span></sub></span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.13.2"><span class="ltx_text" id="S5.T2.13.13.2.1" style="font-size:80%;background-color:#E6E6E6;">.698</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.13.3"><span class="ltx_text" id="S5.T2.13.13.3.1" style="font-size:80%;background-color:#E6E6E6;">.809</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.13.13.4"><span class="ltx_text" id="S5.T2.13.13.4.1" style="font-size:80%;background-color:#E6E6E6;">.690</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.13.5"><span class="ltx_text" id="S5.T2.13.13.5.1" style="font-size:80%;background-color:#E6E6E6;">.534</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.13.6"><span class="ltx_text" id="S5.T2.13.13.6.1" style="font-size:80%;background-color:#E6E6E6;">.746</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.13.7"><span class="ltx_text" id="S5.T2.13.13.7.1" style="font-size:80%;background-color:#E6E6E6;">.622</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.13.8"><span class="ltx_text" id="S5.T2.13.13.8.1" style="font-size:80%;background-color:#E6E6E6;">.452</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.14.14">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_r" id="S5.T2.14.14.1"><span class="ltx_text ltx_font_bold" id="S5.T2.14.14.1.1" style="font-size:80%;">CoT<sub class="ltx_sub" id="S5.T2.14.14.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.14.14.1.1.1.1">t=1.3</span></sub></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T2.14.14.2"><span class="ltx_text" id="S5.T2.14.14.2.1" style="font-size:80%;">.677</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T2.14.14.3"><span class="ltx_text" id="S5.T2.14.14.3.1" style="font-size:80%;">.740</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r" id="S5.T2.14.14.4"><span class="ltx_text" id="S5.T2.14.14.4.1" style="font-size:80%;">.654</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T2.14.14.5"><span class="ltx_text" id="S5.T2.14.14.5.1" style="font-size:80%;">.562</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T2.14.14.6"><span class="ltx_text" id="S5.T2.14.14.6.1" style="font-size:80%;">.646</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T2.14.14.7"><span class="ltx_text" id="S5.T2.14.14.7.1" style="font-size:80%;">.601</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T2.14.14.8"><span class="ltx_text" id="S5.T2.14.14.8.1" style="font-size:80%;">.430</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.16">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.T2" title="Table II ‣ V-B RQ2: User Story GUI Component Matching ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">II</span></a> illustrates the evaluation results for RQ<sub class="ltx_sub" id="S5.SS2.p1.16.7"><span class="ltx_text ltx_font_italic" id="S5.SS2.p1.16.7.1">2</span></sub>, showing the macro and micro <math alttext="P" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><mi id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><ci id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.1d">italic_P</annotation></semantics></math>, <math alttext="R" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><mi id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><ci id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">italic_R</annotation></semantics></math> and <math alttext="F1" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><mrow id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml"><mi id="S5.SS2.p1.4.m4.1.1.2" xref="S5.SS2.p1.4.m4.1.1.2.cmml">F</mi><mo id="S5.SS2.p1.4.m4.1.1.1" xref="S5.SS2.p1.4.m4.1.1.1.cmml">⁢</mo><mn id="S5.SS2.p1.4.m4.1.1.3" xref="S5.SS2.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><apply id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1"><times id="S5.SS2.p1.4.m4.1.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1.1"></times><ci id="S5.SS2.p1.4.m4.1.1.2.cmml" xref="S5.SS2.p1.4.m4.1.1.2">𝐹</ci><cn id="S5.SS2.p1.4.m4.1.1.3.cmml" type="integer" xref="S5.SS2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">italic_F 1</annotation></semantics></math> metrics and the micro <math alttext="ACC" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><mrow id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml"><mi id="S5.SS2.p1.5.m5.1.1.2" xref="S5.SS2.p1.5.m5.1.1.2.cmml">A</mi><mo id="S5.SS2.p1.5.m5.1.1.1" xref="S5.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p1.5.m5.1.1.3" xref="S5.SS2.p1.5.m5.1.1.3.cmml">C</mi><mo id="S5.SS2.p1.5.m5.1.1.1a" xref="S5.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p1.5.m5.1.1.4" xref="S5.SS2.p1.5.m5.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1"><times id="S5.SS2.p1.5.m5.1.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1.1"></times><ci id="S5.SS2.p1.5.m5.1.1.2.cmml" xref="S5.SS2.p1.5.m5.1.1.2">𝐴</ci><ci id="S5.SS2.p1.5.m5.1.1.3.cmml" xref="S5.SS2.p1.5.m5.1.1.3">𝐶</ci><ci id="S5.SS2.p1.5.m5.1.1.4.cmml" xref="S5.SS2.p1.5.m5.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">ACC</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.5.m5.1d">italic_A italic_C italic_C</annotation></semantics></math> values. Overall, the results indicate that the models achieve a moderate to good performance of matching GUI components to user stories shown by, for example, <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.16.8">Micro</span>-<math alttext="F1" class="ltx_Math" display="inline" id="S5.SS2.p1.6.m6.1"><semantics id="S5.SS2.p1.6.m6.1a"><mrow id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml"><mi id="S5.SS2.p1.6.m6.1.1.2" xref="S5.SS2.p1.6.m6.1.1.2.cmml">F</mi><mo id="S5.SS2.p1.6.m6.1.1.1" xref="S5.SS2.p1.6.m6.1.1.1.cmml">⁢</mo><mn id="S5.SS2.p1.6.m6.1.1.3" xref="S5.SS2.p1.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><apply id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1"><times id="S5.SS2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1.1"></times><ci id="S5.SS2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.2">𝐹</ci><cn id="S5.SS2.p1.6.m6.1.1.3.cmml" type="integer" xref="S5.SS2.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.6.m6.1d">italic_F 1</annotation></semantics></math> scores of .681 (<span class="ltx_text ltx_font_bold" id="S5.SS2.p1.7.1">ZS<sub class="ltx_sub" id="S5.SS2.p1.7.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS2.p1.7.1.1.1">A</span></sub></span>), .659 (<span class="ltx_text ltx_font_bold" id="S5.SS2.p1.8.2">FS<sub class="ltx_sub" id="S5.SS2.p1.8.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS2.p1.8.2.1.1">5</span></sub></span>) and .632 (<span class="ltx_text ltx_font_bold" id="S5.SS2.p1.9.3">CoT<sub class="ltx_sub" id="S5.SS2.p1.9.3.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS2.p1.9.3.1.1">t=0</span></sub></span>). Although a direct comparison with the results of the task discussed in RQ<sub class="ltx_sub" id="S5.SS2.p1.16.9"><span class="ltx_text ltx_font_italic" id="S5.SS2.p1.16.9.1">1</span></sub> is difficult due to the difference in datasets, still the matching task can be seen as an extension of the classification task, since classification models probably perform similar computations (e.g., as indicated by explanations from <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.16.10">CoT</span> models) as part of their reasoning sequence. As can be observed, the performance difference of the tasks indicates that the matching task is significantly more difficult for the LLMs. However, we argue that the obtained results are promising due to the model being capable of extracting the majority of GUI components correctly shown by the metric values. As indicated by the Wilcoxon-signed-ranked test between the <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.16.11">Macro</span>-<math alttext="F1" class="ltx_Math" display="inline" id="S5.SS2.p1.11.m8.1"><semantics id="S5.SS2.p1.11.m8.1a"><mrow id="S5.SS2.p1.11.m8.1.1" xref="S5.SS2.p1.11.m8.1.1.cmml"><mi id="S5.SS2.p1.11.m8.1.1.2" xref="S5.SS2.p1.11.m8.1.1.2.cmml">F</mi><mo id="S5.SS2.p1.11.m8.1.1.1" xref="S5.SS2.p1.11.m8.1.1.1.cmml">⁢</mo><mn id="S5.SS2.p1.11.m8.1.1.3" xref="S5.SS2.p1.11.m8.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.11.m8.1b"><apply id="S5.SS2.p1.11.m8.1.1.cmml" xref="S5.SS2.p1.11.m8.1.1"><times id="S5.SS2.p1.11.m8.1.1.1.cmml" xref="S5.SS2.p1.11.m8.1.1.1"></times><ci id="S5.SS2.p1.11.m8.1.1.2.cmml" xref="S5.SS2.p1.11.m8.1.1.2">𝐹</ci><cn id="S5.SS2.p1.11.m8.1.1.3.cmml" type="integer" xref="S5.SS2.p1.11.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.11.m8.1c">F1</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.11.m8.1d">italic_F 1</annotation></semantics></math> scores of the method, the <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.16.12">CoT</span> prompting methods perform significantly worse, whereas the differences of the <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.16.13">ZS</span> and <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.16.14">FS</span> methods are insignificant. In addition, the <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.12.4">ZS<sub class="ltx_sub" id="S5.SS2.p1.12.4.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS2.p1.12.4.1.1">B</span></sub></span> prompting method has significantly better <math alttext="R" class="ltx_Math" display="inline" id="S5.SS2.p1.13.m9.1"><semantics id="S5.SS2.p1.13.m9.1a"><mi id="S5.SS2.p1.13.m9.1.1" xref="S5.SS2.p1.13.m9.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.13.m9.1b"><ci id="S5.SS2.p1.13.m9.1.1.cmml" xref="S5.SS2.p1.13.m9.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.13.m9.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.13.m9.1d">italic_R</annotation></semantics></math> values compared to <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.14.5">ZS<sub class="ltx_sub" id="S5.SS2.p1.14.5.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS2.p1.14.5.1.1">A</span></sub></span> (in vice versa for <math alttext="P" class="ltx_Math" display="inline" id="S5.SS2.p1.15.m10.1"><semantics id="S5.SS2.p1.15.m10.1a"><mi id="S5.SS2.p1.15.m10.1.1" xref="S5.SS2.p1.15.m10.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.15.m10.1b"><ci id="S5.SS2.p1.15.m10.1.1.cmml" xref="S5.SS2.p1.15.m10.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.15.m10.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.15.m10.1d">italic_P</annotation></semantics></math> values), indicating that the prompt extension in <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.16.6">ZS<sub class="ltx_sub" id="S5.SS2.p1.16.6.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.SS2.p1.16.6.1.1">B</span></sub></span> optimizes the model for not missing component matches. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.F3" title="Figure 3 ‣ V-B RQ2: User Story GUI Component Matching ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">3</span></a> shows example GUIs from the gold standard and highlighted GUI component matches as generated by the LLM.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="255" id="S5.F3.g1" src="extracted/5651105/Figures/RE_Detection_V3.png" width="290"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.3.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S5.F3.4.2" style="font-size:90%;">GUI component matches to user stories. Redrawn from Rico <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib28" title="">28</a>]</cite> using components from <span class="ltx_text ltx_font_italic" id="S5.F3.4.2.1">Material Design</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib37" title="">37</a>]</cite></span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="509" id="S5.F4.g1" src="extracted/5651105/Figures/RE_Recom_10_Examples_V4.png" width="284"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S5.F4.3.2" style="font-size:90%;">GUI feature recommendations (randomly sampled)</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.4">Moreover, we investigated <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.1">low</span> <math alttext="P" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mi id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><ci id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_P</annotation></semantics></math> and/or <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.2">low</span> <math alttext="R" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mi id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><ci id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">italic_R</annotation></semantics></math> instances to improve the understanding of errors made by the LLM. For the cases of <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.3">low</span> <math alttext="P" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mi id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><ci id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">italic_P</annotation></semantics></math>, the LLM often extracted wrong GUI components that were semantically related. For example, for the user story to specify the number of guests in a hotel search GUI, the models also erroneously extracts components for the number of rooms. For the instances possessing <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.4">low</span> <math alttext="R" class="ltx_Math" display="inline" id="S5.SS2.p2.4.m4.1"><semantics id="S5.SS2.p2.4.m4.1a"><mi id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><ci id="S5.SS2.p2.4.m4.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.4.m4.1d">italic_R</annotation></semantics></math>, similar to the misclassifications discussed earlier, we identified missing or ambiguous descriptions of GUI components as a main cause. For example, for a user story to be able to download videos to watch them offline, the GUI components offering download functionality were represented as <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.4.5">(Image)</span> <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.4.6">(document)</span>. Although the succeeding GUI component <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.7">”0.7 MB”</span> <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.4.8">(Label)</span> <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.4.9">(document size)</span> could act as a hint, the naming as a <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.10">document</span> and the component being marked as an image introduces ambiguity. Finally, some cases possess ambiguity that is difficult to resolve without the stakeholder. For example, for the user story requesting to see an overview of the course (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.F3" title="Figure 3 ‣ V-B RQ2: User Story GUI Component Matching ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">3</span></a>) the LLM extracts all listed lessons, whereas the annotation marks only the overview course item.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Preliminary Recommendation Results</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Due to the early stage of the proposed approach, we did not yet fully evaluate the recommendation performance of LLM-based prompting techniques. However, we provide preliminary results for the recommendation task in the following. To this end, we generated recommendations (HTML/CSS) with both <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">FS</span> and <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.2">FS-CoT</span> prompting models for all user stories in our gold standard. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.F4" title="Figure 4 ‣ V-B RQ2: User Story GUI Component Matching ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag">4</span></a> shows ten randomly sampled recommendations generated by the <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.3">FS</span> model and their respective US. For example, for the first US the model creates all required GUI components i.e. a <span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.4">color picker</span>, an <span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.5">apply button</span> and the respective <span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.6">labels</span>. In addition, consider the fifth example, for which the model not only recommends a reasonable main GUI component (<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.7">drop down selection</span>), but also pre-fills it with matching domain information, exploiting the wide domain and general knowledge embedded in LLMs. Due to the small amount of provided few-shot examples, the designs of the generated recommendations appear repetitive. However, since our focus primarily lies on generating the functionality required for the US, this represents only a minor issue. In the future, this could be mitigated by providing more few-shot examples and fine-tuning. We generated the recommendations for both <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.8">FS</span> and <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.9">FS-CoT</span> methods and all user stories of our gold standard and provide them as HTML documents and image visualizations in our repository <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib20" title="">20</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Limitations and Potential Risks</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Reflecting on our approach and the proposed integrated system, we identified several limitations and potential risks for our research plan. In the following, we highlight some key limitations, potential risks, and mitigation strategies.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_italic" id="S6.p2.1.1">Evaluation dataset</span>. <span class="ltx_text ltx_font_italic" id="S6.p2.1.2">Rico</span> is widely adopted in research and thus indicates suitability for GUI-based evaluation tasks. Nevertheless, the dataset is influenced by the collection methods. Rico GUIs present a sample of free mobile applications from the Google Play store. Therefore, our used data set lacks non-mobile GUIs and has a tendency for GUIs based on Google’s material design system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib37" title="">37</a>]</cite>. Additionally, to our knowledge there exists no dataset combining GUI prototypes with user stories. We therefore decided to collect user stories for existing GUIs, which does not represent the natural order of requirements elicitation. The exhaustiveness of user stories per GUI in our data set may be limited, as a fixed number of user stories were written by 8 participants for the respective GUIs. Despite independent labeling, calculating inter-coder reliability and resolving conflicts, a further limitation might be introduced by the authors’ evaluation of collected user stories. We also focused on functional user stories first. To expand our dataset, we plan to collect user stories from participants before the corresponding GUIs are developed.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_italic" id="S6.p3.1.1">Prototyping tool integration.</span>
In our proposed integrated system, our approach is directly integrated into dedicated prototyping tools. This requires a vica-versa translation between the DSL of the prototyping tool and our textual representation. We have examined translations for Figma <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#bib.bib18" title="">18</a>]</cite> and discuss the resulting limitations in the following paragraph. Overall, our approach can be integrated into different prototyping tools, but also works directly with markup language for web browsers (i.e., HTML and CSS, where a translation to our textual representation is feasible). Direct integration into prototyping tools may limit the operational capabilities of our approach. However, tool integration offers advantages such as the fast and cost-effective creation of GUI prototype iterations to communicate with stakeholders before more resource-intensive development steps (e.g. in HTML and CSS) follow.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_italic" id="S6.p4.1.1">Data quality in prototyping tools</span>. While we consider user stories and GUI prototypes for our approach as given, our approach depends on the quality of both. Prototyping tools from practice do not strictly enforce the GUI qualities (e.g., suitable naming of the components, or that parts of a single component are grouped together). Often prototyping tools use a tree structure for ordering components and allow that parts, e.g., of a button (lines, labels, or colored areas), being arranged in confusing parts of the underlying tree. Low quality inputs affect recognition and recommendations.
We aim at mitigating the risk of fluctuating input quality in our system. Besides educating participants when creating GUI prototypes, we propose pre-built components (e.g., a button that has pre-grouped and pre-labeled parts). Pre-built components are also standard in practice since corporate design often finds its way into prototyping tools through pre-built GUI design libraries.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1"><span class="ltx_text ltx_font_italic" id="S6.p5.1.1">Evaluating recommendations</span>. While we have yet to evaluate the recommendations generated by our approach, we have generated a broad sample of user story-based recommendations. Some of the recommendations are also described in this paper in section <a class="ltx_ref" href="https://arxiv.org/html/2406.08120v1#S5.SS3" title="V-C Preliminary Recommendation Results ‣ V Results and Discussion ‣ Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-based Approach"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span></span></a>. However, an in-detail evaluation, as part of our research plan, will be addressed in future work.</p>
</div>
<div class="ltx_para" id="S6.p6">
<p class="ltx_p" id="S6.p6.1"><span class="ltx_text ltx_font_italic" id="S6.p6.1.1">Generating initial GUI prototypes</span>.
Our approach aims at detecting whether user stories are present in GUI prototypes. Consequently, creating initial GUI prototypes is a natural step before matching user stories. We have yet to evaluate how effective our proposed system can generate recommendations before initial GUI prototypes are build. However, we are confident that our approach can create effective recommendations for a blank canvas based solely on user stories.</p>
</div>
</section>
<section class="ltx_section" id="S7" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Research Plan and Conclusion</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we present an approach and integrated system for detecting functional user story implementation in GUI prototypes and providing GUI component recommendations. To further evaluate our approach and the integrated system, we plan multiple next research steps:</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1"><span class="ltx_text ltx_font_italic" id="S7.p2.1.1">Evaluating recommendations</span>. Our preliminary evaluation demonstrated the feasibility of LLMs to generate relevant GUI component recommendations for a given user story. However, we have yet to evaluate these recommendations on a broad scale. As one of the following steps, we plan to evaluate the recommendations regarding perceived usability by prototyping experts, along with the proposed research question of how effective LLM-based recommendations from functional user stories are for improving prototypes. In particular, we plan to conduct a user-based evaluation by collecting relevance annotations for LLM-generated GUI feature implementation recommendations for a larger set of user stories.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1"><span class="ltx_text ltx_font_italic" id="S7.p3.1.1">Expanding our dataset</span>. As described in the limitations, we asked participants to create user stories for existing GUIs. While the feasibility of our approach can already be demonstrated based on this data, we plan to collect data in a natural sequence next. The initial elicitation will precede the creation of initial GUI prototypes.</p>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1"><span class="ltx_text ltx_font_italic" id="S7.p4.1.1">Evaluating proposed integrated system</span>.
Our proposed system integrates our approach into dedicated prototyping tools, enabling a holistic evaluation of our approach. As part of our research plan, we plan to evaluate the entire system in a controlled between-subjects user study while asking how effective an integrated prototyping system is in detecting user story implementation and providing recommendations.</p>
</div>
<div class="ltx_para" id="S7.p5">
<p class="ltx_p" id="S7.p5.1">Although there are still unanswered research questions for our approach and integrated system, our preliminary results not only show promising potential for the user story validation and GUI component matching tasks, but also demonstrate feasibility for the GUI feature recommendation task. In addition, the future of our approach holds further potential in supporting requirements elicitation, validation, and overall improvements for users prototyping GUIs.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B. J. Jansen, “The graphical user interface,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">ACM SIGCHI Bulletin</em>, vol. 30, no. 2, pp. 22–26, Apr. 1998. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/279044.279051" title="">https://dl.acm.org/doi/10.1145/279044.279051</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
E. Bjarnason, K. Wnuk, and B. Regnell, “A case study on benefits and side-effects of agile practices in large-scale requirements engineering,” in <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 1st Workshop on Agile Requirements Engineering</em>, ser. AREW ’11.   New York, NY, USA: Association for Computing Machinery, 2011. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2068783.2068786" title="">https://doi.org/10.1145/2068783.2068786</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Käpyaho and M. Kauppinen, “Agile requirements engineering with prototyping: A case study,” in <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">2015 IEEE 23rd International Requirements Engineering Conference (RE)</em>, 2015, pp. 334–343.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Brhel, H. Meth, A. Maedche, and K. Werder, “Exploring principles of user-centered agile software development: A literature review,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Information and Software Technology</em>, vol. 61, pp. 163–181, 2015. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/science/article/pii/S0950584915000129" title="">https://www.sciencedirect.com/science/article/pii/S0950584915000129</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. D. McKeen, T. Guimaraes, and J. C. Wetherbe, “The relationship between user participation and user satisfaction: An investigation of four contingency factors,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">MIS Quarterly</em>, vol. 18, no. 4, pp. 427–451, 1994. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.jstor.org/stable/249523" title="">http://www.jstor.org/stable/249523</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
K. Vredenburg, J.-Y. Mao, P. W. Smith, and T. Carey, “A survey of user-centered design practice,” in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’02.   New York, NY, USA: Association for Computing Machinery, 2002, p. 471–478. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/503376.503460" title="">https://doi.org/10.1145/503376.503460</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J.-Y. Mao, K. Vredenburg, P. W. Smith, and T. Carey, “The state of user-centered design practice,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Commun. ACM</em>, vol. 48, no. 3, p. 105–109, mar 2005. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1047671.1047677" title="">https://doi.org/10.1145/1047671.1047677</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Mannio and U. Nikula, “Requirements elicitation using a combination of prototypes and scenarios,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Workshop em Engenharia de Requisitos</em>, 2001. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:15021206" title="">https://api.semanticscholar.org/CorpusID:15021206</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
C. Pacheco, I. García, and M. Reyes, “Requirements elicitation techniques: a systematic literature review based on the maturity of the techniques,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">IET Software</em>, vol. 12, no. 4, pp. 365–378, 2018. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-sen.2017.0144" title="">https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-sen.2017.0144</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Q. K. Shams-ul Arif and S. Gahyyur, “Requirements engineering processes, tools/technologies, &amp; methodologies,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">International Journal of reviews in computing</em>, vol. 2, no. 6, pp. 41–56, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. Rudd, K. Stern, and S. Isensee, “Low vs. high-fidelity prototyping debate,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Interactions</em>, vol. 3, no. 1, p. 76–85, jan 1996. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/223500.223514" title="">https://doi.org/10.1145/223500.223514</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S. Debnath, P. Spoletini, and A. Ferrari, “From ideas to expressed needs: an empirical study on the evolution of requirements during elicitation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">2021 IEEE 29th International Requirements Engineering Conference (RE)</em>, 2021, pp. 233–244.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
C. Bernal-Cárdenas, K. Moran, M. Tufano, Z. Liu, L. Nan, Z. Shi, and D. Poshyvanyk, “Guigle: a gui search engine for android apps,” in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)</em>.   IEEE, 2019, pp. 71–74.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
K. Kolthoff, C. Bartelt, and S. P. Ponzetto, “Data-driven prototyping via natural-language-based GUI retrieval,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Automated Software Engineering</em>, vol. 30, no. 1, p. 13, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10515-023-00377-x" title="">https://doi.org/10.1007/s10515-023-00377-x</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
——, “Gui2wire: Rapid wireframing with a mined and large-scale gui repository using natural language requirements,” in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">35th IEEE/ACM International Conference on Automated Software Engineering (ASE ’20)</em>.   ACM, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
——, “Automated retrieval of graphical user interface prototypes from natural language requirements,” in <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International Conference on Applications of Natural Language to Information Systems</em>.   Springer, 2021, pp. 376–384.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Wei, A.-L. Courbis, T. Lambolais, B. Xu, P. L. Bernard, and G. Dray, “Boosting gui prototyping with diffusion models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">2023 IEEE 31st International Requirements Engineering Conference (RE)</em>, 2023, pp. 275–280.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
“Figma,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.figma.com/" title="">https://www.figma.com/</a>, 2024, accessed: 2024-02-06.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
C. Lee, S. Kim, D. Han, H. Yang, Y.-W. Park, B. C. Kwon, and S. Ko, “Guicomp: A gui design assistant with real-time, multi-faceted feedback,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’20.   New York, NY, USA: Association for Computing Machinery, 2020, p. 1–13. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3313831.3376327" title="">https://doi.org/10.1145/3313831.3376327</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
“Ius-gui - interlinking user stories and gui prototyping: A semi-automatic llm-based approach github repository,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/IUS-GUI-Prototyping/IUS-GUI" title="">https://github.com/IUS-GUI-Prototyping/IUS-GUI</a> and <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zenodo.org/records/10652222" title="">https://zenodo.org/records/10652222</a>, accessed: 2024-02-12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
H. Meth, M. Brhel, and A. Maedche, “The state of the art in automated requirements elicitation,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Information and Software Technology</em>, vol. 55, no. 10, pp. 1695–1709, 2013. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/science/article/pii/S0950584913000827" title="">https://www.sciencedirect.com/science/article/pii/S0950584913000827</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. A. Umar and K. Lano, “Advances in automated support for requirements engineering: a systematic literature review,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Requirements Engineering</em>, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s00766-023-00411-0" title="">https://doi.org/10.1007/s00766-023-00411-0</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
F. Huang, J. F. Canny, and J. Nichols, “Swire: Sketch-based user interface retrieval,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</em>, 2019, pp. 1–10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
F. Behrang, S. P. Reiss, and A. Orso, “Guifetch: supporting app design and development through gui search,” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 5th International Conference on Mobile Software Engineering and Systems</em>, 2018, pp. 236–246.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S. Bunian, K. Li, C. Jemmali, C. Harteveld, Y. Fu, and M. S. El-Nasr, “Vins: Visual search for mobile user interface design,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2102.05216</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T. Rocha Silva, M. Winckler, and H. Trætteberg, “Ensuring the consistency between user requirements and graphical user interfaces: A behavior-based automated approach,” in <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Computational Science and Its Applications – ICCSA 2019</em>, S. Misra, O. Gervasi, B. Murgante, E. Stankova, V. Korkhov, C. Torre, A. M. A. Rocha, D. Taniar, B. O. Apduhan, and E. Tarantino, Eds.   Cham: Springer International Publishing, 2019, pp. 616–632.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
K. Schneider, “Generating fast feedback in requirements elicitation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">International working conference on requirements engineering: Foundation for software quality</em>.   Springer, 2007, pp. 160–174.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
B. Deka, Z. Huang, C. Franzen, J. Hibschman, D. Afergan, Y. Li, J. Nichols, and R. Kumar, “Rico: A mobile app dataset for building data-driven design applications,” in <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology</em>, ser. UIST ’17.   New York, NY, USA: Association for Computing Machinery, 2017, p. 845–854. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3126594.3126651" title="">https://doi.org/10.1145/3126594.3126651</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">et al.</em>, “Language models are few-shot learners,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.2.2">Advances in neural information processing systems</em>, vol. 33, pp. 1877–1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large language models are zero-shot reasoners,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in neural information processing systems</em>, vol. 35, pp. 22 199–22 213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing,” <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">ACM Computing Surveys</em>, vol. 55, no. 9, pp. 1–35, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">et al.</em>, “Chain-of-thought prompting elicits reasoning in large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.2.2">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 24 824–24 837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
N. Wake, A. Kanehira, K. Sasabuchi, J. Takamatsu, and K. Ikeuchi, “Chatgpt empowered long-step robot control in various environments: A case application,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2304.03893</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
F. Kretzer and A. Maedche, “Making usability test data actionable! a quantitative test-driven prototyping approach,” in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems</em>, ser. CHI EA ’23.   New York, NY, USA: Association for Computing Machinery, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3544549.3585659" title="">https://doi.org/10.1145/3544549.3585659</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Adobe Inc., “Adobe XD,” accessed: 2024-02-06. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://helpx.adobe.com/support/xd.html" title="">https://helpx.adobe.com/support/xd.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
OpenAI, “Gpt-4 technical report,” <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Google LLC, “Material design,” accessed: 2024-02-06. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://m3.material.io/" title="">https://m3.material.io/</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 12 11:52:02 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
