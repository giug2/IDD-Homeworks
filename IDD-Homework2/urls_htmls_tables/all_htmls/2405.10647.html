<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.10647] Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning</title><meta property="og:description" content="Federated Learning (FL) has gained attention for addressing data scarcity and privacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable performance, they face challenges in scenarios with diverse neâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.10647">

<!--Generated on Wed Jun  5 17:34:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">â€…Haoyue Song 
<br class="ltx_break">National Institute for Data Science in Health and Medicine
<br class="ltx_break">Xiamen University
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">hysong@stu.xmu.edu.cn</span> 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>â€…Jiacheng Wang 
<br class="ltx_break">Department of Computer Science
<br class="ltx_break">Xiamen University
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">jiachengw@stu.xmu.edu.cn</span> 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_ERROR undefined">\And</span>â€…Liansheng Wang 
<br class="ltx_break">Department of Computer Science
<br class="ltx_break">Xiamen University
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">lswang@xmu.edu.cn</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Federated Learning (FL) has gained attention for addressing data scarcity and privacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable performance, they face challenges in scenarios with diverse network speeds and concerns about centralized control, especially in multi-institutional collaborations like the medical domain.
Serial FL presents an alternative solution, circumventing these challenges by transferring model updates serially between devices in a cyclical manner. Nevertheless, it is deemed inferior to parallel FL in that (1) its performance shows undesirable fluctuations, and (2) it converges to a lower plateau, particularly when dealing with non-IID data. The observed phenomenon is attributed to catastrophic forgetting due to knowledge loss from previous sites. In this paper, to overcome fluctuation and low efficiency in the iterative learning and forgetting process, we introduce cyclical weight consolidation (CWC), a straightforward yet potent approach specifically tailored for serial FL.
CWC employs a consolidation matrix to regulate local optimization. This matrix tracks the significance of each parameter on the overall federation throughout the entire training trajectory, preventing abrupt changes in significant weights. During revisitation, to maintain adaptability, old memory undergoes decay to incorporate new information. Our comprehensive evaluations demonstrate that in various non-IID settings, CWC mitigates the fluctuation behavior of the original serial FL approach and enhances the converged performance consistently and significantly. The improved performance is either comparable to or better than the parallel vanilla.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2405.10647/assets/images/mot.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="419" height="352" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
A comparison between CWT and FedAvg on MNIST reveals the inferiority of CWT in causing undesirable fluctuations in performance and converging to a lower plateau when confronted with non-IID data. We present figures under various Dirichlet concentration parameters <math id="S1.F1.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S1.F1.3.m1.1b"><mi id="S1.F1.3.m1.1.1" xref="S1.F1.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S1.F1.3.m1.1c"><ci id="S1.F1.3.m1.1.1.cmml" xref="S1.F1.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.3.m1.1d">\alpha</annotation></semantics></math> (i.e., 0.01, 0.1, 1.0, and 10.0, arranged from top to bottom and left to right). A smaller <math id="S1.F1.4.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S1.F1.4.m2.1b"><mi id="S1.F1.4.m2.1.1" xref="S1.F1.4.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S1.F1.4.m2.1c"><ci id="S1.F1.4.m2.1.1.cmml" xref="S1.F1.4.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.m2.1d">\alpha</annotation></semantics></math> corresponds to greater data heterogeneity.
</figcaption>
</figure>
<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">In recent years, federated learning (FL)Â <cite class="ltx_cite ltx_citemacro_cite">Yang etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>); Kairouz etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>); Wang etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2022</a>, <a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite> has shown remarkable performance across various domains, including medicine, finance, and IoT. FL addresses the challenge of data scarcity among isolated clients, often bound by privacy regulations, by training a global model in a distributed manner, enhancing model performance while respecting data ownership. These achievements are largely credited to parallel FL algorithms like FedAvgÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite>, which involve a central server coordinating the aggregation of updated weights from participating clients iteratively until convergence. However, itâ€™s vital to acknowledge that parallel FL may not be the optimal solution for all scenarios, especially when logistical challengesÂ <cite class="ltx_cite ltx_citemacro_cite">Chang etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite> and concerns regarding a centralized third partyÂ <cite class="ltx_cite ltx_citemacro_cite">Kalra etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite> are paramount. The former scenario arises when collaborators have significantly different network connection speeds or deep learning hardware, while the latter situation is particularly undesirable in multi-institutional collaborations. This is especially true in the medical domain, where each hospital may insist on autonomy over its own model to comply with regulations.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">To circumvent these challenges, serial FL (i.e. CWTÂ <cite class="ltx_cite ltx_citemacro_cite">Chang etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite>) presents as an alternative solution by transferring model updates serially between devices in a cyclical manner. Nevertheless, it is deemed inferior to parallel FL in that (1) its performance shows undesirable fluctuations, and (2) it converges to a lower plateau, particularly when dealing with non-IID dataÂ <cite class="ltx_cite ltx_citemacro_cite">Sheller etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2019</a>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>. This phenomenon (Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) is attributed to <span id="S1.p2.1.1" class="ltx_text ltx_font_bold">catastrophic forgetting</span>Â <cite class="ltx_cite ltx_citemacro_cite">French (<a href="#bib.bib10" title="" class="ltx_ref">1999</a>); Goodfellow etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2013</a>); Kemker etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>, where previously acquired knowledge from prior sites gradually fades as the model assimilates new information. Consequently, when the learning process at a new site concludes, the model performs well in the new data environment but at the cost of deteriorating performance on datasets from previously visited sites. The repetitive cycle of learning and forgetting leads to oscillating learning dynamics, significantly diminishing efficiency and resulting in undesirable convergence performance.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">To address catastrophic forgetting induced by heterogeneous data distribution in serial FL, prior research has employed simple heuristics such as balanced mini-batch sampling or a weighted cross-entropy lossÂ <cite class="ltx_cite ltx_citemacro_cite">Balachandar etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>. To the best of our knowledge, no existing work has delved into the intricate mechanism of catastrophic forgetting within the cyclical weight transfer process and provided a targeted solution. Furthermore, although serial FL bears resemblance to continual learning (CL)Â <cite class="ltx_cite ltx_citemacro_cite">DeÂ Lange etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>); Hadsell etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Parisi etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>, where catastrophic forgetting is also a primary concern, techniques from CL cannot be directly applied to serial FL. This disparity stems from the inherent differences between the two tasks: while CL aims to sequentially learn and adapt to new tasks over time while preserving knowledge from past experiences, serial FL distinguishes itself by cyclically revisiting previously accessed sites. This unique characteristic necessitates the development of a new anti-catastrophic forgetting design that can fully leverage this cyclic revisitation feature, thereby enhancing overall performance.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">In this paper, we present a straightforward yet potent approach, termed Cyclical Weight Consolidation (CWC), to address the challenge of catastrophic forgetting in serial federated learning. Instead of granting the model unrestricted autonomy to update itself, CWC opts for local optimization under the regularization of a consolidation matrix. This matrix encapsulates knowledge from previously visited sites, thereby preventing significant weights from undergoing abrupt changes. Following the optimization at the current site, the matrix updates itself by assimilating important weight estimations specific to that site. Given the cyclical revisitation of all sitesâ€™ data, the consolidation matrix undergoes attenuation at the onset of each new communication round, preventing permanent adherence to out-of-date knowledge and preserving the modelâ€™s adaptability. Our comprehensive evaluations illustrate that, across various non-IID settings, CWC alleviates the fluctuation behavior exhibited by the original serial FL approach and consistently and significantly enhances convergence performance. The improved performance is either comparable to or surpasses that of the parallel vanilla. In a nutshell, our contributions are summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present our algorithm for serial federated learning (CWC). Through experimental demonstrations, we show that by utilizing the consolidation matrix to regularize the local optimization process, CWC significantly mitigates the issue of catastrophic forgetting stemming from non-IID data distributions.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Extensive experiments highlight the superiority of CWC over serial federated learning vanilla (CWT). CWC effectively mitigates the fluctuation behavior observed in the original serial FL approach and consistently and significantly enhances convergence performance. Moreover, CWC has the capability to boost convergence by intensifying local computation, a feature not achievable in CWT.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i3.p1.1" class="ltx_p">Extensive experiments affirm that CWC either matches or surpasses the performance of FedAvg. To the best of our knowledge, this marks the first instance where the serial FL method achieves performance comparable to the parallel vanilla approach in non-IID settings.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Serial Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p">Federated learning has been proposed as a solution to address privacy concerns in distributed learning environments. In contrast to the pioneering federated method, FedAvgÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite>, which trains a global model by aggregating local model parameters concurrently, serial FL methods, exemplified by CWTÂ <cite class="ltx_cite ltx_citemacro_cite">Chang etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite> and Split learningÂ <cite class="ltx_cite ltx_citemacro_cite">Vepakomma etÂ al. (<a href="#bib.bib17" title="" class="ltx_ref">2018</a>)</cite>, train each local model sequentially rather than simultaneously. This sequential process continues iteratively, allowing the model to be refined over time as it incorporates insights from different clients in each round. However, serial FL is highly sensitive to data heterogeneity, leading to fluctuation behavior and lower convergence performance due to catastrophic forgettingÂ <cite class="ltx_cite ltx_citemacro_cite">French (<a href="#bib.bib10" title="" class="ltx_ref">1999</a>); Goodfellow etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2013</a>); Kemker etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>. Consequently, serial FL is considered an inferior paradigm compared to FedAvgÂ <cite class="ltx_cite ltx_citemacro_cite">Sheller etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2019</a>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>. To address these challenges, Â <cite class="ltx_cite ltx_citemacro_cite">Balachandar etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> employs proportional local training iterations, cyclical learning rates for sample size variability, and locally weighted mini-batch sampling, along with cyclically weighted loss for label distribution variability. While these simple heuristics demonstrate some effectiveness, they are only applicable in settings with moderate heterogeneity and offer limited improvement. They are inadequate for handling highly heterogeneous distributions such as partitions with mutual exclusive classesÂ <cite class="ltx_cite ltx_citemacro_cite">Zenke etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>); Wang etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>); Sun etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2009</a>)</cite>. To the best of our knowledge, no existing work has thoroughly explored the intricate mechanism of catastrophic forgetting within the cyclical weight transfer process and provided a targeted solution.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Catastrophic Forgetting</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">Catastrophic forgettingÂ <cite class="ltx_cite ltx_citemacro_cite">French (<a href="#bib.bib10" title="" class="ltx_ref">1999</a>); Goodfellow etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2013</a>); Kemker etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>, also known as catastrophic interferenceÂ <cite class="ltx_cite ltx_citemacro_cite">McCloskey and Cohen (<a href="#bib.bib21" title="" class="ltx_ref">1989</a>); He and Jaeger (<a href="#bib.bib22" title="" class="ltx_ref">2018</a>); Zhang etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite>, refers to a phenomenon in machine learning and artificial intelligence where a model that has been trained on one task significantly forgets or loses its ability to perform well on a previous task when it is trained on a new, unrelated task. In other words, as the model learns new information, it unintentionally erases or overwrites previously learned knowledge, leading to a decline in performance on earlier tasks. This issue is especially prominent in continual or lifelong learning scenariosÂ <cite class="ltx_cite ltx_citemacro_cite">DeÂ Lange etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>); Hadsell etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Parisi etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2019</a>); Aljundi etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2019</a>); Kudithipudi etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite>, where a model needs to adapt to new tasks over time. Proposed CL methods to overcome catastrophic forgetting can be broadly classified into three categories: rehearsal, architectural, and regularization methods. Rehearsal methodsÂ <cite class="ltx_cite ltx_citemacro_cite">Rebuffi etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2017</a>); Rolnick etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>); Isele and Cosgun (<a href="#bib.bib28" title="" class="ltx_ref">2018</a>); Chaudhry etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite> involve storing and replaying essential samples from previous tasks during the training of a model on new tasks. This periodic revisitation of past experiences allows the model to retain knowledge about earlier tasks, thereby mitigating the risk of forgetting. However, rehearsal methods are not applicable in the context of serial FL, as they violate privacy requirements. Architectural methodsÂ <cite class="ltx_cite ltx_citemacro_cite">Aljundi etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2017</a>); Rusu etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2016</a>); Xu and Zhu (<a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite> focus on designing neural networks with separate modules or compartments dedicated to different tasks. This modular approach ensures that knowledge acquired for each task is stored in distinct compartments, reducing interference between tasks and minimizing catastrophic forgetting. Regularization techniquesÂ <cite class="ltx_cite ltx_citemacro_cite">Kirkpatrick etÂ al. (<a href="#bib.bib33" title="" class="ltx_ref">2017</a>); Zenke etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>); Lee etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2017</a>); Aljundi etÂ al. (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> introduce constraints into the learning process to prevent the model from becoming overly specialized on the current task and forgetting previously acquired information. Despite the effectiveness of these methods in CL tasks, their direct application to serial FL is not feasible. This discrepancy stems from the inherent differences between the two tasks: while CL focuses on sequential learning and adaptation to new tasks over time while preserving knowledge from past experiences, serial FL stands out by cyclically revisiting previously accessed sites. This distinctive characteristic calls for the development of a novel anti-catastrophic forgetting design that can fully exploit this cyclic revisitation feature, thereby enhancing overall performance.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2405.10647/assets/x1.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
The procedure of our proposed cyclical weight consolidation (CWC). The red circle indicates the parameters being optimized during the optimization process, and the blue circle refers to the parameters being consolidated. The light blue circle with a dashed border indicates the attenuated consolidated parameters. And the rectangular box denotes the entire parameter set of the model.
</figcaption>
</figure>
<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">In this section, we begin by formally defining serial federated learning. Following this, we delve into the concept of cyclical weight consolidation, elucidating its underlying mechanisms that aid in overcoming catastrophic forgetting in serial FL.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Formulation</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.4" class="ltx_p">In the context of federated learning involving a total of <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">K</annotation></semantics></math> clients, the optimization objective is to learn a optimal global model <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\theta</annotation></semantics></math> which can generalize well to all the <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">K</annotation></semantics></math> clientsâ€™ datasets <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\{D_{k}\}_{k=1}^{K}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msubsup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mrow id="S3.SS1.p1.4.m4.1.1.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.4.m4.1.1.1.1.1.2" xref="S3.SS1.p1.4.m4.1.1.1.1.2.cmml">{</mo><msub id="S3.SS1.p1.4.m4.1.1.1.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.1.2" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.1.3" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S3.SS1.p1.4.m4.1.1.1.1.1.3" xref="S3.SS1.p1.4.m4.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p1.4.m4.1.1.1.3" xref="S3.SS1.p1.4.m4.1.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.1.3.2.cmml">k</mi><mo id="S3.SS1.p1.4.m4.1.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.p1.4.m4.1.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">K</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1">superscript</csymbol><apply id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><set id="S3.SS1.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1"><apply id="S3.SS1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.2">ğ·</ci><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.3">ğ‘˜</ci></apply></set><apply id="S3.SS1.p1.4.m4.1.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.3"><eq id="S3.SS1.p1.4.m4.1.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.3.1"></eq><ci id="S3.SS1.p1.4.m4.1.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.3.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.p1.4.m4.1.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\{D_{k}\}_{k=1}^{K}</annotation></semantics></math>:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="minF(\theta):=\frac{1}{K}\sum_{k=1}^{K}\mathcal{L}_{k}" display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.2" xref="S3.E1.m1.1.2.cmml"><mrow id="S3.E1.m1.1.2.2" xref="S3.E1.m1.1.2.2.cmml"><mi id="S3.E1.m1.1.2.2.2" xref="S3.E1.m1.1.2.2.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.2.2.1" xref="S3.E1.m1.1.2.2.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.2.2.3" xref="S3.E1.m1.1.2.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.2.2.1a" xref="S3.E1.m1.1.2.2.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.2.2.4" xref="S3.E1.m1.1.2.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.2.2.1b" xref="S3.E1.m1.1.2.2.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.2.2.5" xref="S3.E1.m1.1.2.2.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.2.2.1c" xref="S3.E1.m1.1.2.2.1.cmml">â€‹</mo><mrow id="S3.E1.m1.1.2.2.6.2" xref="S3.E1.m1.1.2.2.cmml"><mo stretchy="false" id="S3.E1.m1.1.2.2.6.2.1" xref="S3.E1.m1.1.2.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">Î¸</mi><mo rspace="0.278em" stretchy="false" id="S3.E1.m1.1.2.2.6.2.2" xref="S3.E1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S3.E1.m1.1.2.1" xref="S3.E1.m1.1.2.1.cmml">:=</mo><mrow id="S3.E1.m1.1.2.3" xref="S3.E1.m1.1.2.3.cmml"><mfrac id="S3.E1.m1.1.2.3.2" xref="S3.E1.m1.1.2.3.2.cmml"><mn id="S3.E1.m1.1.2.3.2.2" xref="S3.E1.m1.1.2.3.2.2.cmml">1</mn><mi id="S3.E1.m1.1.2.3.2.3" xref="S3.E1.m1.1.2.3.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.2.3.1" xref="S3.E1.m1.1.2.3.1.cmml">â€‹</mo><mrow id="S3.E1.m1.1.2.3.3" xref="S3.E1.m1.1.2.3.3.cmml"><munderover id="S3.E1.m1.1.2.3.3.1" xref="S3.E1.m1.1.2.3.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.1.2.3.3.1.2.2" xref="S3.E1.m1.1.2.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.1.2.3.3.1.2.3" xref="S3.E1.m1.1.2.3.3.1.2.3.cmml"><mi id="S3.E1.m1.1.2.3.3.1.2.3.2" xref="S3.E1.m1.1.2.3.3.1.2.3.2.cmml">k</mi><mo id="S3.E1.m1.1.2.3.3.1.2.3.1" xref="S3.E1.m1.1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.1.2.3.3.1.2.3.3" xref="S3.E1.m1.1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.1.2.3.3.1.3" xref="S3.E1.m1.1.2.3.3.1.3.cmml">K</mi></munderover><msub id="S3.E1.m1.1.2.3.3.2" xref="S3.E1.m1.1.2.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.2.3.3.2.2" xref="S3.E1.m1.1.2.3.3.2.2.cmml">â„’</mi><mi id="S3.E1.m1.1.2.3.3.2.3" xref="S3.E1.m1.1.2.3.3.2.3.cmml">k</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.2.cmml" xref="S3.E1.m1.1.2"><csymbol cd="latexml" id="S3.E1.m1.1.2.1.cmml" xref="S3.E1.m1.1.2.1">assign</csymbol><apply id="S3.E1.m1.1.2.2.cmml" xref="S3.E1.m1.1.2.2"><times id="S3.E1.m1.1.2.2.1.cmml" xref="S3.E1.m1.1.2.2.1"></times><ci id="S3.E1.m1.1.2.2.2.cmml" xref="S3.E1.m1.1.2.2.2">ğ‘š</ci><ci id="S3.E1.m1.1.2.2.3.cmml" xref="S3.E1.m1.1.2.2.3">ğ‘–</ci><ci id="S3.E1.m1.1.2.2.4.cmml" xref="S3.E1.m1.1.2.2.4">ğ‘›</ci><ci id="S3.E1.m1.1.2.2.5.cmml" xref="S3.E1.m1.1.2.2.5">ğ¹</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğœƒ</ci></apply><apply id="S3.E1.m1.1.2.3.cmml" xref="S3.E1.m1.1.2.3"><times id="S3.E1.m1.1.2.3.1.cmml" xref="S3.E1.m1.1.2.3.1"></times><apply id="S3.E1.m1.1.2.3.2.cmml" xref="S3.E1.m1.1.2.3.2"><divide id="S3.E1.m1.1.2.3.2.1.cmml" xref="S3.E1.m1.1.2.3.2"></divide><cn type="integer" id="S3.E1.m1.1.2.3.2.2.cmml" xref="S3.E1.m1.1.2.3.2.2">1</cn><ci id="S3.E1.m1.1.2.3.2.3.cmml" xref="S3.E1.m1.1.2.3.2.3">ğ¾</ci></apply><apply id="S3.E1.m1.1.2.3.3.cmml" xref="S3.E1.m1.1.2.3.3"><apply id="S3.E1.m1.1.2.3.3.1.cmml" xref="S3.E1.m1.1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.2.3.3.1.1.cmml" xref="S3.E1.m1.1.2.3.3.1">superscript</csymbol><apply id="S3.E1.m1.1.2.3.3.1.2.cmml" xref="S3.E1.m1.1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.2.3.3.1.2.1.cmml" xref="S3.E1.m1.1.2.3.3.1">subscript</csymbol><sum id="S3.E1.m1.1.2.3.3.1.2.2.cmml" xref="S3.E1.m1.1.2.3.3.1.2.2"></sum><apply id="S3.E1.m1.1.2.3.3.1.2.3.cmml" xref="S3.E1.m1.1.2.3.3.1.2.3"><eq id="S3.E1.m1.1.2.3.3.1.2.3.1.cmml" xref="S3.E1.m1.1.2.3.3.1.2.3.1"></eq><ci id="S3.E1.m1.1.2.3.3.1.2.3.2.cmml" xref="S3.E1.m1.1.2.3.3.1.2.3.2">ğ‘˜</ci><cn type="integer" id="S3.E1.m1.1.2.3.3.1.2.3.3.cmml" xref="S3.E1.m1.1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.1.2.3.3.1.3.cmml" xref="S3.E1.m1.1.2.3.3.1.3">ğ¾</ci></apply><apply id="S3.E1.m1.1.2.3.3.2.cmml" xref="S3.E1.m1.1.2.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.2.3.3.2.1.cmml" xref="S3.E1.m1.1.2.3.3.2">subscript</csymbol><ci id="S3.E1.m1.1.2.3.3.2.2.cmml" xref="S3.E1.m1.1.2.3.3.2.2">â„’</ci><ci id="S3.E1.m1.1.2.3.3.2.3.cmml" xref="S3.E1.m1.1.2.3.3.2.3">ğ‘˜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">minF(\theta):=\frac{1}{K}\sum_{k=1}^{K}\mathcal{L}_{k}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.9" class="ltx_p">where <math id="S3.SS1.p1.5.m1.1" class="ltx_Math" alttext="\theta\in\mathbb{R}^{d}" display="inline"><semantics id="S3.SS1.p1.5.m1.1a"><mrow id="S3.SS1.p1.5.m1.1.1" xref="S3.SS1.p1.5.m1.1.1.cmml"><mi id="S3.SS1.p1.5.m1.1.1.2" xref="S3.SS1.p1.5.m1.1.1.2.cmml">Î¸</mi><mo id="S3.SS1.p1.5.m1.1.1.1" xref="S3.SS1.p1.5.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.5.m1.1.1.3" xref="S3.SS1.p1.5.m1.1.1.3.cmml"><mi id="S3.SS1.p1.5.m1.1.1.3.2" xref="S3.SS1.p1.5.m1.1.1.3.2.cmml">â„</mi><mi id="S3.SS1.p1.5.m1.1.1.3.3" xref="S3.SS1.p1.5.m1.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m1.1b"><apply id="S3.SS1.p1.5.m1.1.1.cmml" xref="S3.SS1.p1.5.m1.1.1"><in id="S3.SS1.p1.5.m1.1.1.1.cmml" xref="S3.SS1.p1.5.m1.1.1.1"></in><ci id="S3.SS1.p1.5.m1.1.1.2.cmml" xref="S3.SS1.p1.5.m1.1.1.2">ğœƒ</ci><apply id="S3.SS1.p1.5.m1.1.1.3.cmml" xref="S3.SS1.p1.5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m1.1.1.3.1.cmml" xref="S3.SS1.p1.5.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.5.m1.1.1.3.2.cmml" xref="S3.SS1.p1.5.m1.1.1.3.2">â„</ci><ci id="S3.SS1.p1.5.m1.1.1.3.3.cmml" xref="S3.SS1.p1.5.m1.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m1.1c">\theta\in\mathbb{R}^{d}</annotation></semantics></math> encodes the parameters of the global model and <math id="S3.SS1.p1.6.m2.1" class="ltx_Math" alttext="\mathcal{L}_{k}" display="inline"><semantics id="S3.SS1.p1.6.m2.1a"><msub id="S3.SS1.p1.6.m2.1.1" xref="S3.SS1.p1.6.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.6.m2.1.1.2" xref="S3.SS1.p1.6.m2.1.1.2.cmml">â„’</mi><mi id="S3.SS1.p1.6.m2.1.1.3" xref="S3.SS1.p1.6.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m2.1b"><apply id="S3.SS1.p1.6.m2.1.1.cmml" xref="S3.SS1.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m2.1.1.1.cmml" xref="S3.SS1.p1.6.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m2.1.1.2.cmml" xref="S3.SS1.p1.6.m2.1.1.2">â„’</ci><ci id="S3.SS1.p1.6.m2.1.1.3.cmml" xref="S3.SS1.p1.6.m2.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m2.1c">\mathcal{L}_{k}</annotation></semantics></math> represents the loss incurred by client <math id="S3.SS1.p1.7.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p1.7.m3.1a"><mi id="S3.SS1.p1.7.m3.1.1" xref="S3.SS1.p1.7.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m3.1b"><ci id="S3.SS1.p1.7.m3.1.1.cmml" xref="S3.SS1.p1.7.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m3.1c">k</annotation></semantics></math> when fitting the model <math id="S3.SS1.p1.8.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS1.p1.8.m4.1a"><mi id="S3.SS1.p1.8.m4.1.1" xref="S3.SS1.p1.8.m4.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m4.1b"><ci id="S3.SS1.p1.8.m4.1.1.cmml" xref="S3.SS1.p1.8.m4.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m4.1c">\theta</annotation></semantics></math> to its local dataset <math id="S3.SS1.p1.9.m5.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S3.SS1.p1.9.m5.1a"><msub id="S3.SS1.p1.9.m5.1.1" xref="S3.SS1.p1.9.m5.1.1.cmml"><mi id="S3.SS1.p1.9.m5.1.1.2" xref="S3.SS1.p1.9.m5.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.9.m5.1.1.3" xref="S3.SS1.p1.9.m5.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m5.1b"><apply id="S3.SS1.p1.9.m5.1.1.cmml" xref="S3.SS1.p1.9.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m5.1.1.1.cmml" xref="S3.SS1.p1.9.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m5.1.1.2.cmml" xref="S3.SS1.p1.9.m5.1.1.2">ğ·</ci><ci id="S3.SS1.p1.9.m5.1.1.3.cmml" xref="S3.SS1.p1.9.m5.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m5.1c">D_{k}</annotation></semantics></math>:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.4" class="ltx_Math" alttext="\mathcal{L}_{k}:=E_{(x,y)\sim{D_{k}}}[\mathcal{L}_{k}(\theta;D_{k})]" display="block"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><msub id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.4.4.3.2" xref="S3.E2.m1.4.4.3.2.cmml">â„’</mi><mi id="S3.E2.m1.4.4.3.3" xref="S3.E2.m1.4.4.3.3.cmml">k</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml">:=</mo><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.cmml"><msub id="S3.E2.m1.4.4.1.3" xref="S3.E2.m1.4.4.1.3.cmml"><mi id="S3.E2.m1.4.4.1.3.2" xref="S3.E2.m1.4.4.1.3.2.cmml">E</mi><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mrow id="S3.E2.m1.2.2.2.4.2" xref="S3.E2.m1.2.2.2.4.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.4.2.1" xref="S3.E2.m1.2.2.2.4.1.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">x</mi><mo id="S3.E2.m1.2.2.2.4.2.2" xref="S3.E2.m1.2.2.2.4.1.cmml">,</mo><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">y</mi><mo stretchy="false" id="S3.E2.m1.2.2.2.4.2.3" xref="S3.E2.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">âˆ¼</mo><msub id="S3.E2.m1.2.2.2.5" xref="S3.E2.m1.2.2.2.5.cmml"><mi id="S3.E2.m1.2.2.2.5.2" xref="S3.E2.m1.2.2.2.5.2.cmml">D</mi><mi id="S3.E2.m1.2.2.2.5.3" xref="S3.E2.m1.2.2.2.5.3.cmml">k</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.2" xref="S3.E2.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S3.E2.m1.4.4.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.cmml"><msub id="S3.E2.m1.4.4.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.4.4.1.1.1.1.3.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.cmml">â„’</mi><mi id="S3.E2.m1.4.4.1.1.1.1.3.3" xref="S3.E2.m1.4.4.1.1.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">Î¸</mi><mo id="S3.E2.m1.4.4.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml">;</mo><msub id="S3.E2.m1.4.4.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml">D</mi><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.4" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.3" xref="S3.E2.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><csymbol cd="latexml" id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2">assign</csymbol><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.1.cmml" xref="S3.E2.m1.4.4.3">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2">â„’</ci><ci id="S3.E2.m1.4.4.3.3.cmml" xref="S3.E2.m1.4.4.3.3">ğ‘˜</ci></apply><apply id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.4.1"><times id="S3.E2.m1.4.4.1.2.cmml" xref="S3.E2.m1.4.4.1.2"></times><apply id="S3.E2.m1.4.4.1.3.cmml" xref="S3.E2.m1.4.4.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.3.1.cmml" xref="S3.E2.m1.4.4.1.3">subscript</csymbol><ci id="S3.E2.m1.4.4.1.3.2.cmml" xref="S3.E2.m1.4.4.1.3.2">ğ¸</ci><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><csymbol cd="latexml" id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3">similar-to</csymbol><interval closure="open" id="S3.E2.m1.2.2.2.4.1.cmml" xref="S3.E2.m1.2.2.2.4.2"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">ğ‘¥</ci><ci id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">ğ‘¦</ci></interval><apply id="S3.E2.m1.2.2.2.5.cmml" xref="S3.E2.m1.2.2.2.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.5.1.cmml" xref="S3.E2.m1.2.2.2.5">subscript</csymbol><ci id="S3.E2.m1.2.2.2.5.2.cmml" xref="S3.E2.m1.2.2.2.5.2">ğ·</ci><ci id="S3.E2.m1.2.2.2.5.3.cmml" xref="S3.E2.m1.2.2.2.5.3">ğ‘˜</ci></apply></apply></apply><apply id="S3.E2.m1.4.4.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2"></times><apply id="S3.E2.m1.4.4.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2">â„’</ci><ci id="S3.E2.m1.4.4.1.1.1.1.3.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3">ğ‘˜</ci></apply><list id="S3.E2.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1"><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">ğœƒ</ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.2">ğ·</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.3">ğ‘˜</ci></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\mathcal{L}_{k}:=E_{(x,y)\sim{D_{k}}}[\mathcal{L}_{k}(\theta;D_{k})]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.10" class="ltx_p">In the absence of a centralized dataset, serial federated learning (i.e. CWT), approximates the objective through a sequential and cyclical training approach. During each training round, CWT sequentially trains the global model <math id="S3.SS1.p1.10.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS1.p1.10.m1.1a"><mi id="S3.SS1.p1.10.m1.1.1" xref="S3.SS1.p1.10.m1.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m1.1b"><ci id="S3.SS1.p1.10.m1.1.1.cmml" xref="S3.SS1.p1.10.m1.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m1.1c">\theta</annotation></semantics></math> on individual local clients using their respective local data for a specified number of epochs. Subsequently, the global model is transferred to the next client for a similar training process. This cycle continues until all local clients have undergone training. The process iterates through the clients until convergence or the completion of a predetermined number of communication rounds.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">The native CWT algorithm encounters challenges in serial federated learning scenarios characterized by heterogeneous client data distributions. Catastrophic forgetting manifests shortly after the model is transferred to the next site and begins adapting to the new data distribution. The previously acquired knowledge from the prior sites gradually fades as the model assimilates new information. Consequently, when the learning process at the new site concludes, the model excels in the new data environment but at the expense of deteriorating performance on datasets from previously visited sites. Hence, our goal is to reduce the negative effects of catastrophic forgetting.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Cyclical Weight Consolidation</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.6" class="ltx_p">We depict the process of cyclical weight consolidation in Fig.Â <a href="#S3.F2" title="Figure 2 â€£ 3 Approach â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The concept behind our proposed algorithm is that, instead of granting the model absolute freedom to update itself in the new data environment, we opt to conduct local optimization under the regularization of a consolidation matrix <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="C^{k,r}" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><msup id="S3.SS2.p1.1.m1.2.3" xref="S3.SS2.p1.1.m1.2.3.cmml"><mi id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.2.cmml">C</mi><mrow id="S3.SS2.p1.1.m1.2.2.2.4" xref="S3.SS2.p1.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p1.1.m1.2.2.2.4.1" xref="S3.SS2.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.1.m1.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml">r</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><apply id="S3.SS2.p1.1.m1.2.3.cmml" xref="S3.SS2.p1.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3">superscript</csymbol><ci id="S3.SS2.p1.1.m1.2.3.2.cmml" xref="S3.SS2.p1.1.m1.2.3.2">ğ¶</ci><list id="S3.SS2.p1.1.m1.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.4"><ci id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1">ğ‘˜</ci><ci id="S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2">ğ‘Ÿ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">C^{k,r}</annotation></semantics></math>, where <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">k</annotation></semantics></math> and <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">r</annotation></semantics></math> index the <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">k</annotation></semantics></math>-th client and <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">r</annotation></semantics></math>-th communication round, respectively. The consolidation matrix tracks the significance of each parameter on the overall federation (Eq.Â (<a href="#S3.E1" title="In 3.1 Problem Formulation â€£ 3 Approach â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>)) throughout the entire training trajectory. Therefore, it resides in the same vector space as the model parameter <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\theta</annotation></semantics></math>. With CWC, the optimization term (Eq.Â (<a href="#S3.E2" title="In 3.1 Problem Formulation â€£ 3 Approach â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>)) is now extended to:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="\mathcal{L^{\prime}}_{k}=\mathcal{L}_{k}+\sigma\sum_{i}C_{i}^{k,r}(\theta_{i}-\theta_{i}^{prev})^{2}" display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mmultiscripts id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.3.2.2" xref="S3.E3.m1.3.3.3.2.2.cmml">â„’</mi><mrow id="S3.E3.m1.3.3.3a" xref="S3.E3.m1.3.3.3.cmml"></mrow><mo id="S3.E3.m1.3.3.3.2.3" xref="S3.E3.m1.3.3.3.2.3.cmml">â€²</mo><mi id="S3.E3.m1.3.3.3.3" xref="S3.E3.m1.3.3.3.3.cmml">k</mi><mrow id="S3.E3.m1.3.3.3b" xref="S3.E3.m1.3.3.3.cmml"></mrow></mmultiscripts><mo id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><msub id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.3.3.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.3.2" xref="S3.E3.m1.3.3.1.3.2.cmml">â„’</mi><mi id="S3.E3.m1.3.3.1.3.3" xref="S3.E3.m1.3.3.1.3.3.cmml">k</mi></msub><mo id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.2.cmml">+</mo><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.3" xref="S3.E3.m1.3.3.1.1.3.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.cmml"><munder id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E3.m1.3.3.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.E3.m1.3.3.1.1.1.2.3" xref="S3.E3.m1.3.3.1.1.1.2.3.cmml">i</mi></munder><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><msubsup id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.2.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.2.cmml">C</mi><mi id="S3.E3.m1.3.3.1.1.1.1.3.2.3" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">k</mi><mo id="S3.E3.m1.2.2.2.4.1" xref="S3.E3.m1.2.2.2.3.cmml">,</mo><mi id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml">r</mi></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">â€‹</mo><msup id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml">Î¸</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.2.cmml">Î¸</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1a" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.4" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1b" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.5" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.5.cmml">v</mi></mrow></msubsup></mrow><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S3.E3.m1.3.3.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></eq><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3">subscript</csymbol><apply id="S3.E3.m1.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.2.1.cmml" xref="S3.E3.m1.3.3.3">superscript</csymbol><ci id="S3.E3.m1.3.3.3.2.2.cmml" xref="S3.E3.m1.3.3.3.2.2">â„’</ci><ci id="S3.E3.m1.3.3.3.2.3.cmml" xref="S3.E3.m1.3.3.3.2.3">â€²</ci></apply><ci id="S3.E3.m1.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3">ğ‘˜</ci></apply><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><plus id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></plus><apply id="S3.E3.m1.3.3.1.3.cmml" xref="S3.E3.m1.3.3.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.3.1.cmml" xref="S3.E3.m1.3.3.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.3.2.cmml" xref="S3.E3.m1.3.3.1.3.2">â„’</ci><ci id="S3.E3.m1.3.3.1.3.3.cmml" xref="S3.E3.m1.3.3.1.3.3">ğ‘˜</ci></apply><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1.1"><times id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"></times><ci id="S3.E3.m1.3.3.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.3">ğœ</ci><apply id="S3.E3.m1.3.3.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><apply id="S3.E3.m1.3.3.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.3.3.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2.2"></sum><ci id="S3.E3.m1.3.3.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"></times><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2.2">ğ¶</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3">ğ‘–</ci></apply><list id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.4"><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">ğ‘˜</ci><ci id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2">ğ‘Ÿ</ci></list></apply><apply id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><minus id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.2">ğœƒ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.2">ğœƒ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2">ğ‘</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.4">ğ‘’</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.5.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.5">ğ‘£</ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{L^{\prime}}_{k}=\mathcal{L}_{k}+\sigma\sum_{i}C_{i}^{k,r}(\theta_{i}-\theta_{i}^{prev})^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.9" class="ltx_p">where <math id="S3.SS2.p1.7.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS2.p1.7.m1.1a"><mi id="S3.SS2.p1.7.m1.1.1" xref="S3.SS2.p1.7.m1.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m1.1b"><ci id="S3.SS2.p1.7.m1.1.1.cmml" xref="S3.SS2.p1.7.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m1.1c">\sigma</annotation></semantics></math> is the consolidation factor, balancing between old acquired knowledge and the new one, <math id="S3.SS2.p1.8.m2.1" class="ltx_Math" alttext="\theta^{prev}" display="inline"><semantics id="S3.SS2.p1.8.m2.1a"><msup id="S3.SS2.p1.8.m2.1.1" xref="S3.SS2.p1.8.m2.1.1.cmml"><mi id="S3.SS2.p1.8.m2.1.1.2" xref="S3.SS2.p1.8.m2.1.1.2.cmml">Î¸</mi><mrow id="S3.SS2.p1.8.m2.1.1.3" xref="S3.SS2.p1.8.m2.1.1.3.cmml"><mi id="S3.SS2.p1.8.m2.1.1.3.2" xref="S3.SS2.p1.8.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.8.m2.1.1.3.1" xref="S3.SS2.p1.8.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.8.m2.1.1.3.3" xref="S3.SS2.p1.8.m2.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.8.m2.1.1.3.1a" xref="S3.SS2.p1.8.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.8.m2.1.1.3.4" xref="S3.SS2.p1.8.m2.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.8.m2.1.1.3.1b" xref="S3.SS2.p1.8.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.8.m2.1.1.3.5" xref="S3.SS2.p1.8.m2.1.1.3.5.cmml">v</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m2.1b"><apply id="S3.SS2.p1.8.m2.1.1.cmml" xref="S3.SS2.p1.8.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.8.m2.1.1.1.cmml" xref="S3.SS2.p1.8.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.8.m2.1.1.2.cmml" xref="S3.SS2.p1.8.m2.1.1.2">ğœƒ</ci><apply id="S3.SS2.p1.8.m2.1.1.3.cmml" xref="S3.SS2.p1.8.m2.1.1.3"><times id="S3.SS2.p1.8.m2.1.1.3.1.cmml" xref="S3.SS2.p1.8.m2.1.1.3.1"></times><ci id="S3.SS2.p1.8.m2.1.1.3.2.cmml" xref="S3.SS2.p1.8.m2.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p1.8.m2.1.1.3.3.cmml" xref="S3.SS2.p1.8.m2.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.SS2.p1.8.m2.1.1.3.4.cmml" xref="S3.SS2.p1.8.m2.1.1.3.4">ğ‘’</ci><ci id="S3.SS2.p1.8.m2.1.1.3.5.cmml" xref="S3.SS2.p1.8.m2.1.1.3.5">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m2.1c">\theta^{prev}</annotation></semantics></math> represents the updated parameters transferred from the previous site and <math id="S3.SS2.p1.9.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p1.9.m3.1a"><mi id="S3.SS2.p1.9.m3.1.1" xref="S3.SS2.p1.9.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m3.1b"><ci id="S3.SS2.p1.9.m3.1.1.cmml" xref="S3.SS2.p1.9.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m3.1c">i</annotation></semantics></math> labels each parameter.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.6" class="ltx_p">The calculation of the consolidation matrix involves obtaining accurate important weight estimation for a specific task, an aspect extensively studied in the context of continual learning. We can leverage the Fisher information matrix (i.e., EWCÂ <cite class="ltx_cite ltx_citemacro_cite">Kirkpatrick etÂ al. (<a href="#bib.bib33" title="" class="ltx_ref">2017</a>)</cite>) or compute the sensitivity of the task loss to each parameter (i.e., SIÂ <cite class="ltx_cite ltx_citemacro_cite">Zenke etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite>) to find a good estimation. Through either method, we can obtain the important weight estimation <math id="S3.SS2.p2.1.m1.2" class="ltx_Math" alttext="E_{i}^{k,r}" display="inline"><semantics id="S3.SS2.p2.1.m1.2a"><msubsup id="S3.SS2.p2.1.m1.2.3" xref="S3.SS2.p2.1.m1.2.3.cmml"><mi id="S3.SS2.p2.1.m1.2.3.2.2" xref="S3.SS2.p2.1.m1.2.3.2.2.cmml">E</mi><mi id="S3.SS2.p2.1.m1.2.3.2.3" xref="S3.SS2.p2.1.m1.2.3.2.3.cmml">i</mi><mrow id="S3.SS2.p2.1.m1.2.2.2.4" xref="S3.SS2.p2.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p2.1.m1.2.2.2.4.1" xref="S3.SS2.p2.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.1.m1.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.cmml">r</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.2b"><apply id="S3.SS2.p2.1.m1.2.3.cmml" xref="S3.SS2.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.3.1.cmml" xref="S3.SS2.p2.1.m1.2.3">superscript</csymbol><apply id="S3.SS2.p2.1.m1.2.3.2.cmml" xref="S3.SS2.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.3.2.1.cmml" xref="S3.SS2.p2.1.m1.2.3">subscript</csymbol><ci id="S3.SS2.p2.1.m1.2.3.2.2.cmml" xref="S3.SS2.p2.1.m1.2.3.2.2">ğ¸</ci><ci id="S3.SS2.p2.1.m1.2.3.2.3.cmml" xref="S3.SS2.p2.1.m1.2.3.2.3">ğ‘–</ci></apply><list id="S3.SS2.p2.1.m1.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2.4"><ci id="S3.SS2.p2.1.m1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1">ğ‘˜</ci><ci id="S3.SS2.p2.1.m1.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2">ğ‘Ÿ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.2c">E_{i}^{k,r}</annotation></semantics></math>, which quantifies the significance of each parameter <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">i</annotation></semantics></math> concerning site <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">k</annotation></semantics></math> at round <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">r</annotation></semantics></math>. With the obtained important weight estimation <math id="S3.SS2.p2.5.m5.2" class="ltx_Math" alttext="E_{i}^{k,r}" display="inline"><semantics id="S3.SS2.p2.5.m5.2a"><msubsup id="S3.SS2.p2.5.m5.2.3" xref="S3.SS2.p2.5.m5.2.3.cmml"><mi id="S3.SS2.p2.5.m5.2.3.2.2" xref="S3.SS2.p2.5.m5.2.3.2.2.cmml">E</mi><mi id="S3.SS2.p2.5.m5.2.3.2.3" xref="S3.SS2.p2.5.m5.2.3.2.3.cmml">i</mi><mrow id="S3.SS2.p2.5.m5.2.2.2.4" xref="S3.SS2.p2.5.m5.2.2.2.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p2.5.m5.2.2.2.4.1" xref="S3.SS2.p2.5.m5.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.5.m5.2.2.2.2" xref="S3.SS2.p2.5.m5.2.2.2.2.cmml">r</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.2b"><apply id="S3.SS2.p2.5.m5.2.3.cmml" xref="S3.SS2.p2.5.m5.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.2.3.1.cmml" xref="S3.SS2.p2.5.m5.2.3">superscript</csymbol><apply id="S3.SS2.p2.5.m5.2.3.2.cmml" xref="S3.SS2.p2.5.m5.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.2.3.2.1.cmml" xref="S3.SS2.p2.5.m5.2.3">subscript</csymbol><ci id="S3.SS2.p2.5.m5.2.3.2.2.cmml" xref="S3.SS2.p2.5.m5.2.3.2.2">ğ¸</ci><ci id="S3.SS2.p2.5.m5.2.3.2.3.cmml" xref="S3.SS2.p2.5.m5.2.3.2.3">ğ‘–</ci></apply><list id="S3.SS2.p2.5.m5.2.2.2.3.cmml" xref="S3.SS2.p2.5.m5.2.2.2.4"><ci id="S3.SS2.p2.5.m5.1.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1">ğ‘˜</ci><ci id="S3.SS2.p2.5.m5.2.2.2.2.cmml" xref="S3.SS2.p2.5.m5.2.2.2.2">ğ‘Ÿ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.2c">E_{i}^{k,r}</annotation></semantics></math>, we calculate <math id="S3.SS2.p2.6.m6.2" class="ltx_Math" alttext="C_{i}^{k,r}" display="inline"><semantics id="S3.SS2.p2.6.m6.2a"><msubsup id="S3.SS2.p2.6.m6.2.3" xref="S3.SS2.p2.6.m6.2.3.cmml"><mi id="S3.SS2.p2.6.m6.2.3.2.2" xref="S3.SS2.p2.6.m6.2.3.2.2.cmml">C</mi><mi id="S3.SS2.p2.6.m6.2.3.2.3" xref="S3.SS2.p2.6.m6.2.3.2.3.cmml">i</mi><mrow id="S3.SS2.p2.6.m6.2.2.2.4" xref="S3.SS2.p2.6.m6.2.2.2.3.cmml"><mi id="S3.SS2.p2.6.m6.1.1.1.1" xref="S3.SS2.p2.6.m6.1.1.1.1.cmml">k</mi><mo id="S3.SS2.p2.6.m6.2.2.2.4.1" xref="S3.SS2.p2.6.m6.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.6.m6.2.2.2.2" xref="S3.SS2.p2.6.m6.2.2.2.2.cmml">r</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.2b"><apply id="S3.SS2.p2.6.m6.2.3.cmml" xref="S3.SS2.p2.6.m6.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.2.3.1.cmml" xref="S3.SS2.p2.6.m6.2.3">superscript</csymbol><apply id="S3.SS2.p2.6.m6.2.3.2.cmml" xref="S3.SS2.p2.6.m6.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.2.3.2.1.cmml" xref="S3.SS2.p2.6.m6.2.3">subscript</csymbol><ci id="S3.SS2.p2.6.m6.2.3.2.2.cmml" xref="S3.SS2.p2.6.m6.2.3.2.2">ğ¶</ci><ci id="S3.SS2.p2.6.m6.2.3.2.3.cmml" xref="S3.SS2.p2.6.m6.2.3.2.3">ğ‘–</ci></apply><list id="S3.SS2.p2.6.m6.2.2.2.3.cmml" xref="S3.SS2.p2.6.m6.2.2.2.4"><ci id="S3.SS2.p2.6.m6.1.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1.1">ğ‘˜</ci><ci id="S3.SS2.p2.6.m6.2.2.2.2.cmml" xref="S3.SS2.p2.6.m6.2.2.2.2">ğ‘Ÿ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.2c">C_{i}^{k,r}</annotation></semantics></math> as follows:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.6" class="ltx_Math" alttext="C_{i}^{k,r}=\sum_{p=1}^{k-1}E_{i}^{p,r},\;for\;2\leq k\leq K" display="block"><semantics id="S3.E4.m1.6a"><mrow id="S3.E4.m1.6.6.2" xref="S3.E4.m1.6.6.3.cmml"><mrow id="S3.E4.m1.5.5.1.1" xref="S3.E4.m1.5.5.1.1.cmml"><msubsup id="S3.E4.m1.5.5.1.1.2" xref="S3.E4.m1.5.5.1.1.2.cmml"><mi id="S3.E4.m1.5.5.1.1.2.2.2" xref="S3.E4.m1.5.5.1.1.2.2.2.cmml">C</mi><mi id="S3.E4.m1.5.5.1.1.2.2.3" xref="S3.E4.m1.5.5.1.1.2.2.3.cmml">i</mi><mrow id="S3.E4.m1.2.2.2.4" xref="S3.E4.m1.2.2.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml">k</mi><mo id="S3.E4.m1.2.2.2.4.1" xref="S3.E4.m1.2.2.2.3.cmml">,</mo><mi id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.cmml">r</mi></mrow></msubsup><mo rspace="0.111em" id="S3.E4.m1.5.5.1.1.1" xref="S3.E4.m1.5.5.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.5.5.1.1.3" xref="S3.E4.m1.5.5.1.1.3.cmml"><munderover id="S3.E4.m1.5.5.1.1.3.1" xref="S3.E4.m1.5.5.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E4.m1.5.5.1.1.3.1.2.2" xref="S3.E4.m1.5.5.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.5.5.1.1.3.1.2.3" xref="S3.E4.m1.5.5.1.1.3.1.2.3.cmml"><mi id="S3.E4.m1.5.5.1.1.3.1.2.3.2" xref="S3.E4.m1.5.5.1.1.3.1.2.3.2.cmml">p</mi><mo id="S3.E4.m1.5.5.1.1.3.1.2.3.1" xref="S3.E4.m1.5.5.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E4.m1.5.5.1.1.3.1.2.3.3" xref="S3.E4.m1.5.5.1.1.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E4.m1.5.5.1.1.3.1.3" xref="S3.E4.m1.5.5.1.1.3.1.3.cmml"><mi id="S3.E4.m1.5.5.1.1.3.1.3.2" xref="S3.E4.m1.5.5.1.1.3.1.3.2.cmml">k</mi><mo id="S3.E4.m1.5.5.1.1.3.1.3.1" xref="S3.E4.m1.5.5.1.1.3.1.3.1.cmml">âˆ’</mo><mn id="S3.E4.m1.5.5.1.1.3.1.3.3" xref="S3.E4.m1.5.5.1.1.3.1.3.3.cmml">1</mn></mrow></munderover><msubsup id="S3.E4.m1.5.5.1.1.3.2" xref="S3.E4.m1.5.5.1.1.3.2.cmml"><mi id="S3.E4.m1.5.5.1.1.3.2.2.2" xref="S3.E4.m1.5.5.1.1.3.2.2.2.cmml">E</mi><mi id="S3.E4.m1.5.5.1.1.3.2.2.3" xref="S3.E4.m1.5.5.1.1.3.2.2.3.cmml">i</mi><mrow id="S3.E4.m1.4.4.2.4" xref="S3.E4.m1.4.4.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml">p</mi><mo id="S3.E4.m1.4.4.2.4.1" xref="S3.E4.m1.4.4.2.3.cmml">,</mo><mi id="S3.E4.m1.4.4.2.2" xref="S3.E4.m1.4.4.2.2.cmml">r</mi></mrow></msubsup></mrow></mrow><mo rspace="0.447em" id="S3.E4.m1.6.6.2.3" xref="S3.E4.m1.6.6.3a.cmml">,</mo><mrow id="S3.E4.m1.6.6.2.2" xref="S3.E4.m1.6.6.2.2.cmml"><mrow id="S3.E4.m1.6.6.2.2.2" xref="S3.E4.m1.6.6.2.2.2.cmml"><mi id="S3.E4.m1.6.6.2.2.2.2" xref="S3.E4.m1.6.6.2.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.2.2.2.1" xref="S3.E4.m1.6.6.2.2.2.1.cmml">â€‹</mo><mi id="S3.E4.m1.6.6.2.2.2.3" xref="S3.E4.m1.6.6.2.2.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.2.2.2.1a" xref="S3.E4.m1.6.6.2.2.2.1.cmml">â€‹</mo><mi id="S3.E4.m1.6.6.2.2.2.4" xref="S3.E4.m1.6.6.2.2.2.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.2.2.2.1b" xref="S3.E4.m1.6.6.2.2.2.1.cmml">â€‹</mo><mn id="S3.E4.m1.6.6.2.2.2.5" xref="S3.E4.m1.6.6.2.2.2.5.cmml">â€„2</mn></mrow><mo id="S3.E4.m1.6.6.2.2.3" xref="S3.E4.m1.6.6.2.2.3.cmml">â‰¤</mo><mi id="S3.E4.m1.6.6.2.2.4" xref="S3.E4.m1.6.6.2.2.4.cmml">k</mi><mo id="S3.E4.m1.6.6.2.2.5" xref="S3.E4.m1.6.6.2.2.5.cmml">â‰¤</mo><mi id="S3.E4.m1.6.6.2.2.6" xref="S3.E4.m1.6.6.2.2.6.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.6b"><apply id="S3.E4.m1.6.6.3.cmml" xref="S3.E4.m1.6.6.2"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.3a.cmml" xref="S3.E4.m1.6.6.2.3">formulae-sequence</csymbol><apply id="S3.E4.m1.5.5.1.1.cmml" xref="S3.E4.m1.5.5.1.1"><eq id="S3.E4.m1.5.5.1.1.1.cmml" xref="S3.E4.m1.5.5.1.1.1"></eq><apply id="S3.E4.m1.5.5.1.1.2.cmml" xref="S3.E4.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.2.1.cmml" xref="S3.E4.m1.5.5.1.1.2">superscript</csymbol><apply id="S3.E4.m1.5.5.1.1.2.2.cmml" xref="S3.E4.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.2.2.1.cmml" xref="S3.E4.m1.5.5.1.1.2">subscript</csymbol><ci id="S3.E4.m1.5.5.1.1.2.2.2.cmml" xref="S3.E4.m1.5.5.1.1.2.2.2">ğ¶</ci><ci id="S3.E4.m1.5.5.1.1.2.2.3.cmml" xref="S3.E4.m1.5.5.1.1.2.2.3">ğ‘–</ci></apply><list id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.4"><ci id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1">ğ‘˜</ci><ci id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2">ğ‘Ÿ</ci></list></apply><apply id="S3.E4.m1.5.5.1.1.3.cmml" xref="S3.E4.m1.5.5.1.1.3"><apply id="S3.E4.m1.5.5.1.1.3.1.cmml" xref="S3.E4.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.3.1.1.cmml" xref="S3.E4.m1.5.5.1.1.3.1">superscript</csymbol><apply id="S3.E4.m1.5.5.1.1.3.1.2.cmml" xref="S3.E4.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.3.1.2.1.cmml" xref="S3.E4.m1.5.5.1.1.3.1">subscript</csymbol><sum id="S3.E4.m1.5.5.1.1.3.1.2.2.cmml" xref="S3.E4.m1.5.5.1.1.3.1.2.2"></sum><apply id="S3.E4.m1.5.5.1.1.3.1.2.3.cmml" xref="S3.E4.m1.5.5.1.1.3.1.2.3"><eq id="S3.E4.m1.5.5.1.1.3.1.2.3.1.cmml" xref="S3.E4.m1.5.5.1.1.3.1.2.3.1"></eq><ci id="S3.E4.m1.5.5.1.1.3.1.2.3.2.cmml" xref="S3.E4.m1.5.5.1.1.3.1.2.3.2">ğ‘</ci><cn type="integer" id="S3.E4.m1.5.5.1.1.3.1.2.3.3.cmml" xref="S3.E4.m1.5.5.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="S3.E4.m1.5.5.1.1.3.1.3.cmml" xref="S3.E4.m1.5.5.1.1.3.1.3"><minus id="S3.E4.m1.5.5.1.1.3.1.3.1.cmml" xref="S3.E4.m1.5.5.1.1.3.1.3.1"></minus><ci id="S3.E4.m1.5.5.1.1.3.1.3.2.cmml" xref="S3.E4.m1.5.5.1.1.3.1.3.2">ğ‘˜</ci><cn type="integer" id="S3.E4.m1.5.5.1.1.3.1.3.3.cmml" xref="S3.E4.m1.5.5.1.1.3.1.3.3">1</cn></apply></apply><apply id="S3.E4.m1.5.5.1.1.3.2.cmml" xref="S3.E4.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.3.2.1.cmml" xref="S3.E4.m1.5.5.1.1.3.2">superscript</csymbol><apply id="S3.E4.m1.5.5.1.1.3.2.2.cmml" xref="S3.E4.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.3.2.2.1.cmml" xref="S3.E4.m1.5.5.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.5.5.1.1.3.2.2.2.cmml" xref="S3.E4.m1.5.5.1.1.3.2.2.2">ğ¸</ci><ci id="S3.E4.m1.5.5.1.1.3.2.2.3.cmml" xref="S3.E4.m1.5.5.1.1.3.2.2.3">ğ‘–</ci></apply><list id="S3.E4.m1.4.4.2.3.cmml" xref="S3.E4.m1.4.4.2.4"><ci id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1">ğ‘</ci><ci id="S3.E4.m1.4.4.2.2.cmml" xref="S3.E4.m1.4.4.2.2">ğ‘Ÿ</ci></list></apply></apply></apply><apply id="S3.E4.m1.6.6.2.2.cmml" xref="S3.E4.m1.6.6.2.2"><and id="S3.E4.m1.6.6.2.2a.cmml" xref="S3.E4.m1.6.6.2.2"></and><apply id="S3.E4.m1.6.6.2.2b.cmml" xref="S3.E4.m1.6.6.2.2"><leq id="S3.E4.m1.6.6.2.2.3.cmml" xref="S3.E4.m1.6.6.2.2.3"></leq><apply id="S3.E4.m1.6.6.2.2.2.cmml" xref="S3.E4.m1.6.6.2.2.2"><times id="S3.E4.m1.6.6.2.2.2.1.cmml" xref="S3.E4.m1.6.6.2.2.2.1"></times><ci id="S3.E4.m1.6.6.2.2.2.2.cmml" xref="S3.E4.m1.6.6.2.2.2.2">ğ‘“</ci><ci id="S3.E4.m1.6.6.2.2.2.3.cmml" xref="S3.E4.m1.6.6.2.2.2.3">ğ‘œ</ci><ci id="S3.E4.m1.6.6.2.2.2.4.cmml" xref="S3.E4.m1.6.6.2.2.2.4">ğ‘Ÿ</ci><cn type="integer" id="S3.E4.m1.6.6.2.2.2.5.cmml" xref="S3.E4.m1.6.6.2.2.2.5">2</cn></apply><ci id="S3.E4.m1.6.6.2.2.4.cmml" xref="S3.E4.m1.6.6.2.2.4">ğ‘˜</ci></apply><apply id="S3.E4.m1.6.6.2.2c.cmml" xref="S3.E4.m1.6.6.2.2"><leq id="S3.E4.m1.6.6.2.2.5.cmml" xref="S3.E4.m1.6.6.2.2.5"></leq><share href="#S3.E4.m1.6.6.2.2.4.cmml" id="S3.E4.m1.6.6.2.2d.cmml" xref="S3.E4.m1.6.6.2.2"></share><ci id="S3.E4.m1.6.6.2.2.6.cmml" xref="S3.E4.m1.6.6.2.2.6">ğ¾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.6c">C_{i}^{k,r}=\sum_{p=1}^{k-1}E_{i}^{p,r},\;for\;2\leq k\leq K</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.8" class="ltx_p">Note that in this step, we aggregate all relevant important weight estimations from prior sites to compute the consolidation matrix for the current site. For the initial optimization, we set <math id="S3.SS2.p2.7.m1.2" class="ltx_Math" alttext="C^{k=1,r=1}_{i}=0" display="inline"><semantics id="S3.SS2.p2.7.m1.2a"><mrow id="S3.SS2.p2.7.m1.2.3" xref="S3.SS2.p2.7.m1.2.3.cmml"><msubsup id="S3.SS2.p2.7.m1.2.3.2" xref="S3.SS2.p2.7.m1.2.3.2.cmml"><mi id="S3.SS2.p2.7.m1.2.3.2.2.2" xref="S3.SS2.p2.7.m1.2.3.2.2.2.cmml">C</mi><mi id="S3.SS2.p2.7.m1.2.3.2.3" xref="S3.SS2.p2.7.m1.2.3.2.3.cmml">i</mi><mrow id="S3.SS2.p2.7.m1.2.2.2.2" xref="S3.SS2.p2.7.m1.2.2.2.3.cmml"><mrow id="S3.SS2.p2.7.m1.1.1.1.1.1" xref="S3.SS2.p2.7.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.7.m1.1.1.1.1.1.2" xref="S3.SS2.p2.7.m1.1.1.1.1.1.2.cmml">k</mi><mo id="S3.SS2.p2.7.m1.1.1.1.1.1.1" xref="S3.SS2.p2.7.m1.1.1.1.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.7.m1.1.1.1.1.1.3" xref="S3.SS2.p2.7.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p2.7.m1.2.2.2.2.3" xref="S3.SS2.p2.7.m1.2.2.2.3a.cmml">,</mo><mrow id="S3.SS2.p2.7.m1.2.2.2.2.2" xref="S3.SS2.p2.7.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.7.m1.2.2.2.2.2.2" xref="S3.SS2.p2.7.m1.2.2.2.2.2.2.cmml">r</mi><mo id="S3.SS2.p2.7.m1.2.2.2.2.2.1" xref="S3.SS2.p2.7.m1.2.2.2.2.2.1.cmml">=</mo><mn id="S3.SS2.p2.7.m1.2.2.2.2.2.3" xref="S3.SS2.p2.7.m1.2.2.2.2.2.3.cmml">1</mn></mrow></mrow></msubsup><mo id="S3.SS2.p2.7.m1.2.3.1" xref="S3.SS2.p2.7.m1.2.3.1.cmml">=</mo><mn id="S3.SS2.p2.7.m1.2.3.3" xref="S3.SS2.p2.7.m1.2.3.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m1.2b"><apply id="S3.SS2.p2.7.m1.2.3.cmml" xref="S3.SS2.p2.7.m1.2.3"><eq id="S3.SS2.p2.7.m1.2.3.1.cmml" xref="S3.SS2.p2.7.m1.2.3.1"></eq><apply id="S3.SS2.p2.7.m1.2.3.2.cmml" xref="S3.SS2.p2.7.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m1.2.3.2.1.cmml" xref="S3.SS2.p2.7.m1.2.3.2">subscript</csymbol><apply id="S3.SS2.p2.7.m1.2.3.2.2.cmml" xref="S3.SS2.p2.7.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m1.2.3.2.2.1.cmml" xref="S3.SS2.p2.7.m1.2.3.2">superscript</csymbol><ci id="S3.SS2.p2.7.m1.2.3.2.2.2.cmml" xref="S3.SS2.p2.7.m1.2.3.2.2.2">ğ¶</ci><apply id="S3.SS2.p2.7.m1.2.2.2.3.cmml" xref="S3.SS2.p2.7.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m1.2.2.2.3a.cmml" xref="S3.SS2.p2.7.m1.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p2.7.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m1.1.1.1.1.1"><eq id="S3.SS2.p2.7.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m1.1.1.1.1.1.1"></eq><ci id="S3.SS2.p2.7.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.m1.1.1.1.1.1.2">ğ‘˜</ci><cn type="integer" id="S3.SS2.p2.7.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.7.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p2.7.m1.2.2.2.2.2.cmml" xref="S3.SS2.p2.7.m1.2.2.2.2.2"><eq id="S3.SS2.p2.7.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.7.m1.2.2.2.2.2.1"></eq><ci id="S3.SS2.p2.7.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.7.m1.2.2.2.2.2.2">ğ‘Ÿ</ci><cn type="integer" id="S3.SS2.p2.7.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.7.m1.2.2.2.2.2.3">1</cn></apply></apply></apply><ci id="S3.SS2.p2.7.m1.2.3.2.3.cmml" xref="S3.SS2.p2.7.m1.2.3.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS2.p2.7.m1.2.3.3.cmml" xref="S3.SS2.p2.7.m1.2.3.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m1.2c">C^{k=1,r=1}_{i}=0</annotation></semantics></math> as there is no previously consolidated information available. Since the algorithm cyclically revisits the <math id="S3.SS2.p2.8.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p2.8.m2.1a"><mi id="S3.SS2.p2.8.m2.1.1" xref="S3.SS2.p2.8.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m2.1b"><ci id="S3.SS2.p2.8.m2.1.1.cmml" xref="S3.SS2.p2.8.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m2.1c">K</annotation></semantics></math> sites, we attenuate the consolidation matrix at the start of a new communication round. This ensures that the model is not overly influenced by the out-of-date information, preserving its adaptability:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.7" class="ltx_Math" alttext="C_{i}^{1,r+1}=\gamma(C_{i}^{K,r}+E_{i}^{K,r})" display="block"><semantics id="S3.E5.m1.7a"><mrow id="S3.E5.m1.7.7" xref="S3.E5.m1.7.7.cmml"><msubsup id="S3.E5.m1.7.7.3" xref="S3.E5.m1.7.7.3.cmml"><mi id="S3.E5.m1.7.7.3.2.2" xref="S3.E5.m1.7.7.3.2.2.cmml">C</mi><mi id="S3.E5.m1.7.7.3.2.3" xref="S3.E5.m1.7.7.3.2.3.cmml">i</mi><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml"><mn id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">1</mn><mo id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><mrow id="S3.E5.m1.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.1.cmml"><mi id="S3.E5.m1.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.1.2.cmml">r</mi><mo id="S3.E5.m1.2.2.2.2.1.1" xref="S3.E5.m1.2.2.2.2.1.1.cmml">+</mo><mn id="S3.E5.m1.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.1.3.cmml">1</mn></mrow></mrow></msubsup><mo id="S3.E5.m1.7.7.2" xref="S3.E5.m1.7.7.2.cmml">=</mo><mrow id="S3.E5.m1.7.7.1" xref="S3.E5.m1.7.7.1.cmml"><mi id="S3.E5.m1.7.7.1.3" xref="S3.E5.m1.7.7.1.3.cmml">Î³</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.2" xref="S3.E5.m1.7.7.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.7.7.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.2" xref="S3.E5.m1.7.7.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.7.7.1.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.cmml"><msubsup id="S3.E5.m1.7.7.1.1.1.1.2" xref="S3.E5.m1.7.7.1.1.1.1.2.cmml"><mi id="S3.E5.m1.7.7.1.1.1.1.2.2.2" xref="S3.E5.m1.7.7.1.1.1.1.2.2.2.cmml">C</mi><mi id="S3.E5.m1.7.7.1.1.1.1.2.2.3" xref="S3.E5.m1.7.7.1.1.1.1.2.2.3.cmml">i</mi><mrow id="S3.E5.m1.4.4.2.4" xref="S3.E5.m1.4.4.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml">K</mi><mo id="S3.E5.m1.4.4.2.4.1" xref="S3.E5.m1.4.4.2.3.cmml">,</mo><mi id="S3.E5.m1.4.4.2.2" xref="S3.E5.m1.4.4.2.2.cmml">r</mi></mrow></msubsup><mo id="S3.E5.m1.7.7.1.1.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.1.cmml">+</mo><msubsup id="S3.E5.m1.7.7.1.1.1.1.3" xref="S3.E5.m1.7.7.1.1.1.1.3.cmml"><mi id="S3.E5.m1.7.7.1.1.1.1.3.2.2" xref="S3.E5.m1.7.7.1.1.1.1.3.2.2.cmml">E</mi><mi id="S3.E5.m1.7.7.1.1.1.1.3.2.3" xref="S3.E5.m1.7.7.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S3.E5.m1.6.6.2.4" xref="S3.E5.m1.6.6.2.3.cmml"><mi id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml">K</mi><mo id="S3.E5.m1.6.6.2.4.1" xref="S3.E5.m1.6.6.2.3.cmml">,</mo><mi id="S3.E5.m1.6.6.2.2" xref="S3.E5.m1.6.6.2.2.cmml">r</mi></mrow></msubsup></mrow><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.3" xref="S3.E5.m1.7.7.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.7b"><apply id="S3.E5.m1.7.7.cmml" xref="S3.E5.m1.7.7"><eq id="S3.E5.m1.7.7.2.cmml" xref="S3.E5.m1.7.7.2"></eq><apply id="S3.E5.m1.7.7.3.cmml" xref="S3.E5.m1.7.7.3"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.3.1.cmml" xref="S3.E5.m1.7.7.3">superscript</csymbol><apply id="S3.E5.m1.7.7.3.2.cmml" xref="S3.E5.m1.7.7.3"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.3.2.1.cmml" xref="S3.E5.m1.7.7.3">subscript</csymbol><ci id="S3.E5.m1.7.7.3.2.2.cmml" xref="S3.E5.m1.7.7.3.2.2">ğ¶</ci><ci id="S3.E5.m1.7.7.3.2.3.cmml" xref="S3.E5.m1.7.7.3.2.3">ğ‘–</ci></apply><list id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2"><cn type="integer" id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">1</cn><apply id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1"><plus id="S3.E5.m1.2.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1"></plus><ci id="S3.E5.m1.2.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.2">ğ‘Ÿ</ci><cn type="integer" id="S3.E5.m1.2.2.2.2.1.3.cmml" xref="S3.E5.m1.2.2.2.2.1.3">1</cn></apply></list></apply><apply id="S3.E5.m1.7.7.1.cmml" xref="S3.E5.m1.7.7.1"><times id="S3.E5.m1.7.7.1.2.cmml" xref="S3.E5.m1.7.7.1.2"></times><ci id="S3.E5.m1.7.7.1.3.cmml" xref="S3.E5.m1.7.7.1.3">ğ›¾</ci><apply id="S3.E5.m1.7.7.1.1.1.1.cmml" xref="S3.E5.m1.7.7.1.1.1"><plus id="S3.E5.m1.7.7.1.1.1.1.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.1"></plus><apply id="S3.E5.m1.7.7.1.1.1.1.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.1.1.2.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.7.7.1.1.1.1.2.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.7.7.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2.2.2">ğ¶</ci><ci id="S3.E5.m1.7.7.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2.2.3">ğ‘–</ci></apply><list id="S3.E5.m1.4.4.2.3.cmml" xref="S3.E5.m1.4.4.2.4"><ci id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1">ğ¾</ci><ci id="S3.E5.m1.4.4.2.2.cmml" xref="S3.E5.m1.4.4.2.2">ğ‘Ÿ</ci></list></apply><apply id="S3.E5.m1.7.7.1.1.1.1.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.1.1.3.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3">superscript</csymbol><apply id="S3.E5.m1.7.7.1.1.1.1.3.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.7.7.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.2.2">ğ¸</ci><ci id="S3.E5.m1.7.7.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.2.3">ğ‘–</ci></apply><list id="S3.E5.m1.6.6.2.3.cmml" xref="S3.E5.m1.6.6.2.4"><ci id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1.1">ğ¾</ci><ci id="S3.E5.m1.6.6.2.2.cmml" xref="S3.E5.m1.6.6.2.2">ğ‘Ÿ</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.7c">C_{i}^{1,r+1}=\gamma(C_{i}^{K,r}+E_{i}^{K,r})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.9" class="ltx_p">where <math id="S3.SS2.p2.9.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS2.p2.9.m1.1a"><mi id="S3.SS2.p2.9.m1.1.1" xref="S3.SS2.p2.9.m1.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m1.1b"><ci id="S3.SS2.p2.9.m1.1.1.cmml" xref="S3.SS2.p2.9.m1.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m1.1c">\gamma</annotation></semantics></math> is the attenuation rate.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2405.10647/assets/images/dirichlet.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="334" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
Visualize the overall performance of three algorithms on MNIST and CIFAR10 under three non-IID settings (i.e., <math id="S4.F3.4.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.F3.4.m1.1b"><mrow id="S4.F3.4.m1.1.1" xref="S4.F3.4.m1.1.1.cmml"><mi id="S4.F3.4.m1.1.1.2" xref="S4.F3.4.m1.1.1.2.cmml">Î±</mi><mo id="S4.F3.4.m1.1.1.1" xref="S4.F3.4.m1.1.1.1.cmml">=</mo><mn id="S4.F3.4.m1.1.1.3" xref="S4.F3.4.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.4.m1.1c"><apply id="S4.F3.4.m1.1.1.cmml" xref="S4.F3.4.m1.1.1"><eq id="S4.F3.4.m1.1.1.1.cmml" xref="S4.F3.4.m1.1.1.1"></eq><ci id="S4.F3.4.m1.1.1.2.cmml" xref="S4.F3.4.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.F3.4.m1.1.1.3.cmml" xref="S4.F3.4.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.4.m1.1d">\alpha=0.01</annotation></semantics></math>, <math id="S4.F3.5.m2.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.F3.5.m2.1b"><mrow id="S4.F3.5.m2.1.1" xref="S4.F3.5.m2.1.1.cmml"><mi id="S4.F3.5.m2.1.1.2" xref="S4.F3.5.m2.1.1.2.cmml">Î±</mi><mo id="S4.F3.5.m2.1.1.1" xref="S4.F3.5.m2.1.1.1.cmml">=</mo><mn id="S4.F3.5.m2.1.1.3" xref="S4.F3.5.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.5.m2.1c"><apply id="S4.F3.5.m2.1.1.cmml" xref="S4.F3.5.m2.1.1"><eq id="S4.F3.5.m2.1.1.1.cmml" xref="S4.F3.5.m2.1.1.1"></eq><ci id="S4.F3.5.m2.1.1.2.cmml" xref="S4.F3.5.m2.1.1.2">ğ›¼</ci><cn type="float" id="S4.F3.5.m2.1.1.3.cmml" xref="S4.F3.5.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.5.m2.1d">\alpha=0.1</annotation></semantics></math>, <math id="S4.F3.6.m3.1" class="ltx_Math" alttext="\alpha=1.0" display="inline"><semantics id="S4.F3.6.m3.1b"><mrow id="S4.F3.6.m3.1.1" xref="S4.F3.6.m3.1.1.cmml"><mi id="S4.F3.6.m3.1.1.2" xref="S4.F3.6.m3.1.1.2.cmml">Î±</mi><mo id="S4.F3.6.m3.1.1.1" xref="S4.F3.6.m3.1.1.1.cmml">=</mo><mn id="S4.F3.6.m3.1.1.3" xref="S4.F3.6.m3.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.6.m3.1c"><apply id="S4.F3.6.m3.1.1.cmml" xref="S4.F3.6.m3.1.1"><eq id="S4.F3.6.m3.1.1.1.cmml" xref="S4.F3.6.m3.1.1.1"></eq><ci id="S4.F3.6.m3.1.1.2.cmml" xref="S4.F3.6.m3.1.1.2">ğ›¼</ci><cn type="float" id="S4.F3.6.m3.1.1.3.cmml" xref="S4.F3.6.m3.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.6.m3.1d">\alpha=1.0</annotation></semantics></math> from left to right). The curves plot the classification accuracy on the balanced global test set alongside training epochs. It is important to note that serial federated learning is evaluated at the end of each training epoch, while parallel federated learning is evaluated every four training epochs (i.e., one communication round).
</figcaption>
</figure>
<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In this section, we conduct a thorough evaluation of the effectiveness of CWC on three benchmarks: MNISTÂ <cite class="ltx_cite ltx_citemacro_cite">LeCun etÂ al. (<a href="#bib.bib36" title="" class="ltx_ref">1998</a>)</cite> and CIFAR10Â <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky etÂ al. (<a href="#bib.bib37" title="" class="ltx_ref">2009</a>)</cite> with Dirichlet heterogeneous partitions, ISIC2018Â <cite class="ltx_cite ltx_citemacro_cite">Tschandl etÂ al. (<a href="#bib.bib38" title="" class="ltx_ref">2018</a>); Codella etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite> skin disease classification also simulated with Dirichlet distribution, and a benchmark featuring extremely heterogeneous partitions. The results demonstrate that CWC consistently outperforms CWT significantly and achieves comparable or superior performance to FedAvg. Finally, we undertake an analytical study to investigate the influence of local training epochs and the consolidation factor on our CWC algorithm.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dirichlet Benchmark on MNIST and CIFAR10</h3>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2405.10647/assets/images/details.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
On the left, the plots display the classification accuracy on the balanced global test set based on the model that has just been updated on each site. In the middle, the plots illustrate the classification accuracy on the site-specific private test set across the entire training trajectory, while on the right, an amplification of the middleâ€™s initial stage is presented.
</figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.10" class="ltx_p"><span id="S4.SS1.p1.10.1" class="ltx_text ltx_font_bold">Implementation Details.</span> We initiate our assessment by evaluating the effectiveness of our algorithm in image classification tasks using the MNIST and CIFAR10 datasets. To introduce data heterogeneity, we incorporate a Dirichlet distributionÂ <cite class="ltx_cite ltx_citemacro_cite">Lin etÂ al. (<a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite>, utilizing the concentration parameter <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\alpha</annotation></semantics></math> to control the level of heterogeneity. A smaller <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\alpha</annotation></semantics></math> value indicates a more imbalanced distribution of data across clients. In our experiments, we explore <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\alpha</annotation></semantics></math> values from the set <math id="S4.SS1.p1.4.m4.3" class="ltx_Math" alttext="\{0.01,0.1,1.0\}" display="inline"><semantics id="S4.SS1.p1.4.m4.3a"><mrow id="S4.SS1.p1.4.m4.3.4.2" xref="S4.SS1.p1.4.m4.3.4.1.cmml"><mo stretchy="false" id="S4.SS1.p1.4.m4.3.4.2.1" xref="S4.SS1.p1.4.m4.3.4.1.cmml">{</mo><mn id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">0.01</mn><mo id="S4.SS1.p1.4.m4.3.4.2.2" xref="S4.SS1.p1.4.m4.3.4.1.cmml">,</mo><mn id="S4.SS1.p1.4.m4.2.2" xref="S4.SS1.p1.4.m4.2.2.cmml">0.1</mn><mo id="S4.SS1.p1.4.m4.3.4.2.3" xref="S4.SS1.p1.4.m4.3.4.1.cmml">,</mo><mn id="S4.SS1.p1.4.m4.3.3" xref="S4.SS1.p1.4.m4.3.3.cmml">1.0</mn><mo stretchy="false" id="S4.SS1.p1.4.m4.3.4.2.4" xref="S4.SS1.p1.4.m4.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.3b"><set id="S4.SS1.p1.4.m4.3.4.1.cmml" xref="S4.SS1.p1.4.m4.3.4.2"><cn type="float" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">0.01</cn><cn type="float" id="S4.SS1.p1.4.m4.2.2.cmml" xref="S4.SS1.p1.4.m4.2.2">0.1</cn><cn type="float" id="S4.SS1.p1.4.m4.3.3.cmml" xref="S4.SS1.p1.4.m4.3.3">1.0</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.3c">\{0.01,0.1,1.0\}</annotation></semantics></math>. For this study, we generate a total of four simulated clients. To ensure that the local test set and local train set within the same client are derived from the same distribution, we initially merge the train and test sets of MNIST and CIFAR10. Subsequently, we simulate four heterogeneous data silos for each client based on the specified concentration parameter <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\alpha</annotation></semantics></math>. Within these silos, we further balance the data into local train and local test sets. To assess the overall model performance, we aggregate all local test sets into a global test set. This global test set maintains a balanced class distribution, enabling an unbiased evaluation of the modelâ€™s performance. We employ a compact multi-layer perceptron (MLP) with two hidden layers, featuring 256 units for MNIST and 1024 units for CIFAR10. Each layer incorporates ReLU nonlinearities, and the model utilizes a standard categorical cross-entropy loss function. For MNIST, we set <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="\sigma=0.1" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mrow id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">Ïƒ</mi><mo id="S4.SS1.p1.6.m6.1.1.1" xref="S4.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><eq id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1.1"></eq><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">ğœ</ci><cn type="float" id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">\sigma=0.1</annotation></semantics></math> and <math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="\gamma=0.5" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><mrow id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2" xref="S4.SS1.p1.7.m7.1.1.2.cmml">Î³</mi><mo id="S4.SS1.p1.7.m7.1.1.1" xref="S4.SS1.p1.7.m7.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><eq id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1.1"></eq><ci id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2">ğ›¾</ci><cn type="float" id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">\gamma=0.5</annotation></semantics></math>, while for CIFAR10, we set <math id="S4.SS1.p1.8.m8.1" class="ltx_Math" alttext="\sigma=10.0" display="inline"><semantics id="S4.SS1.p1.8.m8.1a"><mrow id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml"><mi id="S4.SS1.p1.8.m8.1.1.2" xref="S4.SS1.p1.8.m8.1.1.2.cmml">Ïƒ</mi><mo id="S4.SS1.p1.8.m8.1.1.1" xref="S4.SS1.p1.8.m8.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.8.m8.1.1.3" xref="S4.SS1.p1.8.m8.1.1.3.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><apply id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1"><eq id="S4.SS1.p1.8.m8.1.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1.1"></eq><ci id="S4.SS1.p1.8.m8.1.1.2.cmml" xref="S4.SS1.p1.8.m8.1.1.2">ğœ</ci><cn type="float" id="S4.SS1.p1.8.m8.1.1.3.cmml" xref="S4.SS1.p1.8.m8.1.1.3">10.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">\sigma=10.0</annotation></semantics></math> and <math id="S4.SS1.p1.9.m9.1" class="ltx_Math" alttext="\gamma=0.9" display="inline"><semantics id="S4.SS1.p1.9.m9.1a"><mrow id="S4.SS1.p1.9.m9.1.1" xref="S4.SS1.p1.9.m9.1.1.cmml"><mi id="S4.SS1.p1.9.m9.1.1.2" xref="S4.SS1.p1.9.m9.1.1.2.cmml">Î³</mi><mo id="S4.SS1.p1.9.m9.1.1.1" xref="S4.SS1.p1.9.m9.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.9.m9.1.1.3" xref="S4.SS1.p1.9.m9.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.1b"><apply id="S4.SS1.p1.9.m9.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1"><eq id="S4.SS1.p1.9.m9.1.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1.1"></eq><ci id="S4.SS1.p1.9.m9.1.1.2.cmml" xref="S4.SS1.p1.9.m9.1.1.2">ğ›¾</ci><cn type="float" id="S4.SS1.p1.9.m9.1.1.3.cmml" xref="S4.SS1.p1.9.m9.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.1c">\gamma=0.9</annotation></semantics></math>. And we employ SIÂ <cite class="ltx_cite ltx_citemacro_cite">Zenke etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> as the important weight estimator. To ensure a fair comparison between serial FL (i.e., CWT, CWC) and FedAvg, we standardize the evaluation in terms of communication rounds, as each client receives and transmits the updated model weights once in both serial and parallel FL during each communication round, which suggests same communication cost. However, given that serial FL trains the global model sequentially, we conduct a total of <math id="S4.SS1.p1.10.m10.1" class="ltx_Math" alttext="K=4" display="inline"><semantics id="S4.SS1.p1.10.m10.1a"><mrow id="S4.SS1.p1.10.m10.1.1" xref="S4.SS1.p1.10.m10.1.1.cmml"><mi id="S4.SS1.p1.10.m10.1.1.2" xref="S4.SS1.p1.10.m10.1.1.2.cmml">K</mi><mo id="S4.SS1.p1.10.m10.1.1.1" xref="S4.SS1.p1.10.m10.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.10.m10.1.1.3" xref="S4.SS1.p1.10.m10.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m10.1b"><apply id="S4.SS1.p1.10.m10.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1"><eq id="S4.SS1.p1.10.m10.1.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1.1"></eq><ci id="S4.SS1.p1.10.m10.1.1.2.cmml" xref="S4.SS1.p1.10.m10.1.1.2">ğ¾</ci><cn type="integer" id="S4.SS1.p1.10.m10.1.1.3.cmml" xref="S4.SS1.p1.10.m10.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m10.1c">K=4</annotation></semantics></math> evaluations, in contrast to the single evaluation performed with the aggregated model in parallel FedAvg. For optimal convergence, we optimize our network one epoch per communication round and for a total of 100 rounds (equivalent to 400 training epochs). To achieve robust absolute performance with a reduced number of epochs, we utilize the adaptive optimizer AdamÂ <cite class="ltx_cite ltx_citemacro_cite">Kingma and Ba (<a href="#bib.bib41" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.3" class="ltx_p"><span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">Main Results.</span> Fig.Â <a href="#S4.F3" title="Figure 3 â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.2 ISIC2018 Benchmark â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates a comparative analysis of overall performance among FedAvg, CWT, and Our CWC. To begin, we examine CWC against CWT, the serial approach without consolidation. Notably, CWC consistently outperforms CWT in all the three non-IID scenarios, alleviating performance fluctuations faced by CWT and achieving higher convergence scores. As data heterogeneity increases (from <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\alpha=1.0" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><eq id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></eq><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\alpha=1.0</annotation></semantics></math> to <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">Î±</mi><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><eq id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></eq><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\alpha=0.01</annotation></semantics></math>), CWT encounters challenges, particularly in addressing the exacerbated issue of catastrophic forgetting due to more heterogeneous distribution. The oscillation amplitude increases, resulting in lower convergence values. Moreover, in CIFAR10, CWT struggles to learn, evidenced by declining accuracy with increasing training epochs. In contrast, CWC, incorporating a cyclical consolidation mechanism, overcomes the inefficiency in the iterative process of learning and forgetting. This is evident in its more steadily growing trend and eventual convergence to higher accuracy. The figure also demonstrates the robustness of CWC to increasing data heterogeneity. As heterogeneity increases, the performance loss is moderate, in contrast to CWT and FedAvg. Remarkably, with cyclical weight consolidation, the serial federated learning approach becomes comparable to FedAvg and even outperforms it in highly heterogeneous scenarios (<math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">Î±</mi><mo id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><eq id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1"></eq><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\alpha=0.01</annotation></semantics></math>).</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">In-depth Analysis.</span> The left figure of Fig.Â <a href="#S4.F4" title="Figure 4 â€£ 4.1 Dirichlet Benchmark on MNIST and CIFAR10 â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> displays the learning dynamics of the just-updated model for each site. As FedAvg does not have the site-specific evaluation, we substitute it with the global version. It can be observed that the CWT curve exhibits less oscillation compared to the plot showing its entire training trajectory in Fig.Â <a href="#S4.F3" title="Figure 3 â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, reinforcing the idea that the fluctuation behavior in serial federated learning stems from the transition between sites. In contrast, CWC remains fairly stable, as illustrated by a similar trend in all four sites. This observation validates that a model trained with cyclical weight consolidation preserves the previously acquired knowledge when fitting the data from another dissimilar distribution, confirming the efficacy of our consolidation mechanism. The middle figure of Fig.Â <a href="#S4.F4" title="Figure 4 â€£ 4.1 Dirichlet Benchmark on MNIST and CIFAR10 â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the classification accuracy on the site-specific private test set along the entire training trajectory, while the right figure of Fig.Â <a href="#S4.F4" title="Figure 4 â€£ 4.1 Dirichlet Benchmark on MNIST and CIFAR10 â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the amplification of the middleâ€™s initial stage. As observed, initially, for both serial federated learning algorithms, the on-site test score experiences an extreme fluctuation trend: after fitting the on-site training samples, it reaches up to 100%; however, when the model transitions and adapts to the data of the next site, the accuracy suddenly drops to a very low level. As the model undergoes more training epochs, the lowest value it drops to in a communication round exhibits a growing trend, indicating its ability to preserve a certain amount of the previously learned knowledge as it continually adapts to other distinct distributions. However, in CWT, the learning efficiency is extremely low, taking hundreds of communication rounds to converge to the level of 50%. Moreover, the marginal gain also decreases over time. In contrast, CWC showcases its superiority with a faster convergence speed, proving its capacity to preserve previously acquired knowledge and its plasticity to learn knowledge from other data distributions.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>ISIC2018 Benchmark</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Classification accuracy on the global test set under three heterogeneous settings. The final results are determined by selecting the best scores within 100 communication rounds. The results for MNIST are presented above, while those for CIFAR10 are displayed below.</figcaption>
<div id="S4.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:211.6pt;height:107.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.7pt,9.4pt) scale(0.85,0.85) ;">
<table id="S4.T1.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.3.3" class="ltx_tr">
<th id="S4.T1.3.3.3.4" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mrow id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T1.1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.T1.1.1.1.1.m1.1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1"><eq id="S4.T1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1.1"></eq><ci id="S4.T1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\alpha=0.01</annotation></semantics></math></th>
<th id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><math id="S4.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.T1.2.2.2.2.m1.1a"><mrow id="S4.T1.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.cmml"><mi id="S4.T1.2.2.2.2.m1.1.1.2" xref="S4.T1.2.2.2.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.T1.2.2.2.2.m1.1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T1.2.2.2.2.m1.1.1.3" xref="S4.T1.2.2.2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1"><eq id="S4.T1.2.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1.1"></eq><ci id="S4.T1.2.2.2.2.m1.1.1.2.cmml" xref="S4.T1.2.2.2.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T1.2.2.2.2.m1.1.1.3.cmml" xref="S4.T1.2.2.2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\alpha=0.1</annotation></semantics></math></th>
<th id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><math id="S4.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\alpha=1.0" display="inline"><semantics id="S4.T1.3.3.3.3.m1.1a"><mrow id="S4.T1.3.3.3.3.m1.1.1" xref="S4.T1.3.3.3.3.m1.1.1.cmml"><mi id="S4.T1.3.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.3.m1.1.1.2.cmml">Î±</mi><mo id="S4.T1.3.3.3.3.m1.1.1.1" xref="S4.T1.3.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T1.3.3.3.3.m1.1.1.3" xref="S4.T1.3.3.3.3.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1"><eq id="S4.T1.3.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1.1"></eq><ci id="S4.T1.3.3.3.3.m1.1.1.2.cmml" xref="S4.T1.3.3.3.3.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T1.3.3.3.3.m1.1.1.3.cmml" xref="S4.T1.3.3.3.3.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.m1.1c">\alpha=1.0</annotation></semantics></math></th>
<th id="S4.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.3.4.1" class="ltx_tr">
<th id="S4.T1.3.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">FedAvg</th>
<td id="S4.T1.3.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.64</td>
<td id="S4.T1.3.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.10</td>
<td id="S4.T1.3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.16</td>
<td id="S4.T1.3.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t">96.30</td>
</tr>
<tr id="S4.T1.3.3.5.2" class="ltx_tr">
<th id="S4.T1.3.3.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CWT</th>
<td id="S4.T1.3.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r">85.54</td>
<td id="S4.T1.3.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r">94.58</td>
<td id="S4.T1.3.3.5.2.4" class="ltx_td ltx_align_center ltx_border_r">98.15</td>
<td id="S4.T1.3.3.5.2.5" class="ltx_td ltx_align_center">92.76</td>
</tr>
<tr id="S4.T1.3.3.6.3" class="ltx_tr">
<th id="S4.T1.3.3.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CWC (ours)</th>
<td id="S4.T1.3.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.3.6.3.2.1" class="ltx_text ltx_font_bold">97.97</span></td>
<td id="S4.T1.3.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.3.6.3.3.1" class="ltx_text ltx_font_bold">97.66</span></td>
<td id="S4.T1.3.3.6.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.3.6.3.4.1" class="ltx_text ltx_font_bold">98.26</span></td>
<td id="S4.T1.3.3.6.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.6.3.5.1" class="ltx_text ltx_font_bold">97.96</span></td>
</tr>
<tr id="S4.T1.3.3.7.4" class="ltx_tr">
<th id="S4.T1.3.3.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">FedAvg</th>
<td id="S4.T1.3.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.36</td>
<td id="S4.T1.3.3.7.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.7.4.3.1" class="ltx_text ltx_font_bold">46.07</span></td>
<td id="S4.T1.3.3.7.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.40</td>
<td id="S4.T1.3.3.7.4.5" class="ltx_td ltx_align_center ltx_border_t">42.94</td>
</tr>
<tr id="S4.T1.3.3.8.5" class="ltx_tr">
<th id="S4.T1.3.3.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CWT</th>
<td id="S4.T1.3.3.8.5.2" class="ltx_td ltx_align_center ltx_border_r">24.92</td>
<td id="S4.T1.3.3.8.5.3" class="ltx_td ltx_align_center ltx_border_r">28.38</td>
<td id="S4.T1.3.3.8.5.4" class="ltx_td ltx_align_center ltx_border_r">47.38</td>
<td id="S4.T1.3.3.8.5.5" class="ltx_td ltx_align_center">33.56</td>
</tr>
<tr id="S4.T1.3.3.9.6" class="ltx_tr">
<th id="S4.T1.3.3.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">CWC (ours)</th>
<td id="S4.T1.3.3.9.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.3.3.9.6.2.1" class="ltx_text ltx_font_bold">42.04</span></td>
<td id="S4.T1.3.3.9.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">44.22</td>
<td id="S4.T1.3.3.9.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.3.3.9.6.4.1" class="ltx_text ltx_font_bold">50.50</span></td>
<td id="S4.T1.3.3.9.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.3.3.9.6.5.1" class="ltx_text ltx_font_bold">45.59</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Balanced classification accuracy on the global test set under three heterogeneous settings. The final results are determined by selecting the best scores within 150 communication rounds.</figcaption>
<div id="S4.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:211.6pt;height:61.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.7pt,5.4pt) scale(0.85,0.85) ;">
<table id="S4.T2.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.3.3.3" class="ltx_tr">
<th id="S4.T2.3.3.3.4" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml"><mi id="S4.T2.1.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.T2.1.1.1.1.m1.1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T2.1.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1"><eq id="S4.T2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1"></eq><ci id="S4.T2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\alpha=0.1</annotation></semantics></math></th>
<th id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><math id="S4.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\alpha=1.0" display="inline"><semantics id="S4.T2.2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml"><mi id="S4.T2.2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.T2.2.2.2.2.m1.1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T2.2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.2.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1"><eq id="S4.T2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.1"></eq><ci id="S4.T2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\alpha=1.0</annotation></semantics></math></th>
<th id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><math id="S4.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="\alpha=10.0" display="inline"><semantics id="S4.T2.3.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.3.m1.1.1.2.cmml">Î±</mi><mo id="S4.T2.3.3.3.3.m1.1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T2.3.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.3.m1.1.1.3.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1"><eq id="S4.T2.3.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1.1"></eq><ci id="S4.T2.3.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.3.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T2.3.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.3.m1.1.1.3">10.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">\alpha=10.0</annotation></semantics></math></th>
<th id="S4.T2.3.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.3.4.1" class="ltx_tr">
<td id="S4.T2.3.3.4.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T2.3.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">39.28</td>
<td id="S4.T2.3.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.05</td>
<td id="S4.T2.3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.37</td>
<td id="S4.T2.3.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t">42.90</td>
</tr>
<tr id="S4.T2.3.3.5.2" class="ltx_tr">
<td id="S4.T2.3.3.5.2.1" class="ltx_td ltx_align_left ltx_border_r">CWT</td>
<td id="S4.T2.3.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r">34.70</td>
<td id="S4.T2.3.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r">48.47</td>
<td id="S4.T2.3.3.5.2.4" class="ltx_td ltx_align_center ltx_border_r">49.58</td>
<td id="S4.T2.3.3.5.2.5" class="ltx_td ltx_align_center">44.25</td>
</tr>
<tr id="S4.T2.3.3.6.3" class="ltx_tr">
<td id="S4.T2.3.3.6.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">CWC (ours)</td>
<td id="S4.T2.3.3.6.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T2.3.3.6.3.2.1" class="ltx_text ltx_font_bold">45.67</span></td>
<td id="S4.T2.3.3.6.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T2.3.3.6.3.3.1" class="ltx_text ltx_font_bold">56.39</span></td>
<td id="S4.T2.3.3.6.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T2.3.3.6.3.4.1" class="ltx_text ltx_font_bold">54.75</span></td>
<td id="S4.T2.3.3.6.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.3.6.3.5.1" class="ltx_text ltx_font_bold">52.27</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2405.10647/assets/images/isic.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="124" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>
Balanced accuracy on the global test set along with training epochs under the setting of <math id="S4.F5.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.F5.2.m1.1b"><mrow id="S4.F5.2.m1.1.1" xref="S4.F5.2.m1.1.1.cmml"><mi id="S4.F5.2.m1.1.1.2" xref="S4.F5.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.F5.2.m1.1.1.1" xref="S4.F5.2.m1.1.1.1.cmml">=</mo><mn id="S4.F5.2.m1.1.1.3" xref="S4.F5.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.2.m1.1c"><apply id="S4.F5.2.m1.1.1.cmml" xref="S4.F5.2.m1.1.1"><eq id="S4.F5.2.m1.1.1.1.cmml" xref="S4.F5.2.m1.1.1.1"></eq><ci id="S4.F5.2.m1.1.1.2.cmml" xref="S4.F5.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.F5.2.m1.1.1.3.cmml" xref="S4.F5.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.2.m1.1d">\alpha=0.1</annotation></semantics></math>. From left to right, we depict the learning dynamics of FedAvg, CWT, and our CWC.
</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.3" class="ltx_p">To assess whether cyclical weight consolidation can also mitigate catastrophic forgetting in more complex datasets and larger models, we conducted experiments on a skin disease classification task based on ISIC2018Â <cite class="ltx_cite ltx_citemacro_cite">Codella etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>); Tschandl etÂ al. (<a href="#bib.bib38" title="" class="ltx_ref">2018</a>)</cite>, containing over 10,000 images covering 7 disease categories. Specifically, we trained a ResNet50Â <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2016</a>)</cite> without pretraining. Similar to previous benchmarks, we employed the Dirichlet distribution with a total of four clients to simulate various non-IID scenarios. However, in this benchmark, we used <math id="S4.SS2.p1.1.m1.3" class="ltx_Math" alttext="\alpha\in\{0.1,1.0,10.0\}" display="inline"><semantics id="S4.SS2.p1.1.m1.3a"><mrow id="S4.SS2.p1.1.m1.3.4" xref="S4.SS2.p1.1.m1.3.4.cmml"><mi id="S4.SS2.p1.1.m1.3.4.2" xref="S4.SS2.p1.1.m1.3.4.2.cmml">Î±</mi><mo id="S4.SS2.p1.1.m1.3.4.1" xref="S4.SS2.p1.1.m1.3.4.1.cmml">âˆˆ</mo><mrow id="S4.SS2.p1.1.m1.3.4.3.2" xref="S4.SS2.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.3.4.3.2.1" xref="S4.SS2.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">0.1</mn><mo id="S4.SS2.p1.1.m1.3.4.3.2.2" xref="S4.SS2.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S4.SS2.p1.1.m1.2.2" xref="S4.SS2.p1.1.m1.2.2.cmml">1.0</mn><mo id="S4.SS2.p1.1.m1.3.4.3.2.3" xref="S4.SS2.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S4.SS2.p1.1.m1.3.3" xref="S4.SS2.p1.1.m1.3.3.cmml">10.0</mn><mo stretchy="false" id="S4.SS2.p1.1.m1.3.4.3.2.4" xref="S4.SS2.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.3b"><apply id="S4.SS2.p1.1.m1.3.4.cmml" xref="S4.SS2.p1.1.m1.3.4"><in id="S4.SS2.p1.1.m1.3.4.1.cmml" xref="S4.SS2.p1.1.m1.3.4.1"></in><ci id="S4.SS2.p1.1.m1.3.4.2.cmml" xref="S4.SS2.p1.1.m1.3.4.2">ğ›¼</ci><set id="S4.SS2.p1.1.m1.3.4.3.1.cmml" xref="S4.SS2.p1.1.m1.3.4.3.2"><cn type="float" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">0.1</cn><cn type="float" id="S4.SS2.p1.1.m1.2.2.cmml" xref="S4.SS2.p1.1.m1.2.2">1.0</cn><cn type="float" id="S4.SS2.p1.1.m1.3.3.cmml" xref="S4.SS2.p1.1.m1.3.3">10.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.3c">\alpha\in\{0.1,1.0,10.0\}</annotation></semantics></math>. Given the imbalanced classes in ISIC2018, followingÂ <cite class="ltx_cite ltx_citemacro_cite">Codella etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite>, we adopted balanced accuracy (BACC) as our evaluation metric. And we set <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\sigma=10.0" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">Ïƒ</mi><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><eq id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></eq><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ğœ</ci><cn type="float" id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">10.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\sigma=10.0</annotation></semantics></math> and <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="\gamma=0.95" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">Î³</mi><mo id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><eq id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></eq><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">ğ›¾</ci><cn type="float" id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\gamma=0.95</annotation></semantics></math>. To ensure proper convergence, we trained one epoch per communication round and for 150 communication rounds in total.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 ISIC2018 Benchmark â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> showcases the superiority of CWC against CWT and FedAvg in this scenario. Interestingly, FedAvg achieves the lowest performance in this class-imbalanced classification task, with a score of 42.9%, slightly lower than CWTâ€™s 44.25%. Evidently, CWC surpasses both with a significant margin. Fig.Â <a href="#S4.F5" title="Figure 5 â€£ 4.2 ISIC2018 Benchmark â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> plots the learning dynamics under the setting of <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><eq id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1"></eq><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\alpha=0.1</annotation></semantics></math>. It is observed that significant fluctuation is present in all three algorithms, as the noise introduced by the highly imbalanced class distribution is unavoidable.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Benchmark on Extremely Heterogeneous Distribution</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we evaluate CWC on distributions characterized by extreme heterogeneity. The complete MNIST and CIFAR10 training datasets are partitioned into five subsets of consecutive categories, with each client assigned two consecutive categories. And we utilized the official balanced test set for model performance evaluation. Unlike the Dirichlet benchmark, there is no class overlap in the samples from different sites, posing a significant challenge for FL algorithms. The remaining configurations are maintained consistent with the Dirichlet benchmark. Fig.Â <a href="#S4.F6" title="Figure 6 â€£ 4.3 Benchmark on Extremely Heterogeneous Distribution â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the model performance on the official test set across different algorithms. CWC stands out by outperforming CWT and FedAvg by a considerable margin. Given that each site processes samples from mutually exclusive categories, different sites share minimal overlapping knowledge. Therefore local data optimizes the model in distinct directions, leading to substantial forgetting in CWT and notable client drift in FedAvg. Consequently, these two baseline algorithms struggle to generalize effectively. Contrastingly, CWC maintains strong performance in this benchmark, even comparable to the results obtained in Dirichlet experiments, albeit with a slight lag. The resilience of CWC under extreme heterogeneity highlights its ability to adapt and learn from diverse local data, overcoming challenges associated with the absence of shared knowledge across sites.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2405.10647/assets/images/split.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="237" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Test accuracy on the global test set along with training epochs for FedAvg, CWT, and our CWC. The upper part displays the results for MNIST, while the lower part shows the results for CIFAR10.
</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Impact of Local Training Epochs</h3>

<figure id="S4.F7" class="ltx_figure"><img src="/html/2405.10647/assets/images/epochs.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>
The learning dynamics in the startup stage under the setting of two local training epochs (left) and four local training epochs (right).
</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Number of communication rounds (along with training epochs) needed to achieve 75% accuracy on MNIST Dirichlet (<math id="S4.T3.2.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.T3.2.m1.1b"><mrow id="S4.T3.2.m1.1.1" xref="S4.T3.2.m1.1.1.cmml"><mi id="S4.T3.2.m1.1.1.2" xref="S4.T3.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.T3.2.m1.1.1.1" xref="S4.T3.2.m1.1.1.1.cmml">=</mo><mn id="S4.T3.2.m1.1.1.3" xref="S4.T3.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.m1.1c"><apply id="S4.T3.2.m1.1.1.cmml" xref="S4.T3.2.m1.1.1"><eq id="S4.T3.2.m1.1.1.1.cmml" xref="S4.T3.2.m1.1.1.1"></eq><ci id="S4.T3.2.m1.1.1.2.cmml" xref="S4.T3.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T3.2.m1.1.1.3.cmml" xref="S4.T3.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.m1.1d">\alpha=0.01</annotation></semantics></math>) for varying local training epochs</figcaption>
<div id="S4.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:217.2pt;height:43.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.1pt,5.4pt) scale(0.8,0.8) ;">
<table id="S4.T3.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.3.1.1.1" class="ltx_tr">
<th id="S4.T3.3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Local Epochs</span></th>
<th id="S4.T3.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.3.1.1.1.2.1" class="ltx_text ltx_font_bold">1</span></th>
<th id="S4.T3.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.3.1.1.1.3.1" class="ltx_text ltx_font_bold">2</span></th>
<th id="S4.T3.3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.3.1.1.1.4.1" class="ltx_text ltx_font_bold">4</span></th>
<th id="S4.T3.3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.3.1.1.1.5.1" class="ltx_text ltx_font_bold">8</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.1.2.1" class="ltx_tr">
<th id="S4.T3.3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">CWT</th>
<td id="S4.T3.3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">37 (148)</td>
<td id="S4.T3.3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">41 (321)</td>
<td id="S4.T3.3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">50 (787)</td>
<td id="S4.T3.3.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">39 (1240)</td>
</tr>
<tr id="S4.T3.3.1.3.2" class="ltx_tr">
<th id="S4.T3.3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">CWC (ours)</th>
<td id="S4.T3.3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_bb">6 (21)</td>
<td id="S4.T3.3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_bb">4 (25)</td>
<td id="S4.T3.3.1.3.2.4" class="ltx_td ltx_align_center ltx_border_bb">3 (33)</td>
<td id="S4.T3.3.1.3.2.5" class="ltx_td ltx_align_center ltx_border_bb">3 (66)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p">In parallel FL, the number of local training epochs is increased to reduce communication costsÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite>. The model can converge to the same performance with fewer communication rounds at the expense of more intense local computing. However, as pointed out inÂ <cite class="ltx_cite ltx_citemacro_cite">Sheller etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2019</a>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>, the benefit of increasing local training epochs in CWT is limited. CWTâ€™s performance is sensitive to the number of local training epochs because a longer exposure to heterogeneous data demands a stronger ability to preserve previously acquired knowledge. An increased number of local training epochs pose a significant challenge to its inherently mediocre memory. TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.4 Impact of Local Training Epochs â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> displays the number of communication rounds (along with training epochs) required to reach 75% accuracy on MNIST Dirichlet (<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><eq id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1"></eq><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\alpha=0.01</annotation></semantics></math>) for different local training epochs. Observing the results, an increase in the amount of local computation has no effect on the convergence speed in terms of CWT. In fact, it takes more communication rounds to reach the same preset accuracy (communication rounds increase to 41 and 50 under 2 and 8 epochs, respectively). In contrast, CWC experiences a boost in convergence speed with increased local epochs, similar to FedAvg. This is further demonstrated in Fig.Â <a href="#S4.F7" title="Figure 7 â€£ 4.4 Impact of Local Training Epochs â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, which shows the startup learning dynamics under the setup of 2 and 4 local epochs: After experiencing a total of four communication rounds, CWCâ€™s test accuracy converges to a higher level with a doubling in local training epochs.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Impact of Consolidation Factor</h3>

<figure id="S4.F8" class="ltx_figure"><img src="/html/2405.10647/assets/images/consolidation.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="261" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>
Test accuracy along with training epochs for CIFAR10 Dirichlet (<math id="S4.F8.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.F8.2.m1.1b"><mrow id="S4.F8.2.m1.1.1" xref="S4.F8.2.m1.1.1.cmml"><mi id="S4.F8.2.m1.1.1.2" xref="S4.F8.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.F8.2.m1.1.1.1" xref="S4.F8.2.m1.1.1.1.cmml">=</mo><mn id="S4.F8.2.m1.1.1.3" xref="S4.F8.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.2.m1.1c"><apply id="S4.F8.2.m1.1.1.cmml" xref="S4.F8.2.m1.1.1"><eq id="S4.F8.2.m1.1.1.1.cmml" xref="S4.F8.2.m1.1.1.1"></eq><ci id="S4.F8.2.m1.1.1.2.cmml" xref="S4.F8.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.F8.2.m1.1.1.3.cmml" xref="S4.F8.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.2.m1.1d">\alpha=0.1</annotation></semantics></math>) under four consolidation factors (i.e., 0.0, 1.0, 10.0, and 100.0 in the order from top to bottom, left to right).
</figcaption>
</figure>
<div id="S4.SS5.p1" class="ltx_para ltx_noindent">
<p id="S4.SS5.p1.5" class="ltx_p">In this investigation, we explore the impact of the consolidation factor <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mi id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><ci id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">\sigma</annotation></semantics></math> on CIFAR10 Dirichlet (<math id="S4.SS5.p1.2.m2.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.SS5.p1.2.m2.1a"><mrow id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml"><mi id="S4.SS5.p1.2.m2.1.1.2" xref="S4.SS5.p1.2.m2.1.1.2.cmml">Î±</mi><mo id="S4.SS5.p1.2.m2.1.1.1" xref="S4.SS5.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS5.p1.2.m2.1.1.3" xref="S4.SS5.p1.2.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><apply id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1"><eq id="S4.SS5.p1.2.m2.1.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1.1"></eq><ci id="S4.SS5.p1.2.m2.1.1.2.cmml" xref="S4.SS5.p1.2.m2.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS5.p1.2.m2.1.1.3.cmml" xref="S4.SS5.p1.2.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">\alpha=0.1</annotation></semantics></math>). The test accuracy, plotted against training epochs, is depicted in Fig.Â <a href="#S4.F8" title="Figure 8 â€£ 4.5 Impact of Consolidation Factor â€£ 4 Experiments â€£ Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> for four consolidation factors (i.e., 0.0, 1.0, 10.0, and 100.0). As expected, CWC without a consolidation mechanism fails to generalize to the global test set. With an increased consolidation effect (using <math id="S4.SS5.p1.3.m3.1" class="ltx_Math" alttext="\sigma=1.0" display="inline"><semantics id="S4.SS5.p1.3.m3.1a"><mrow id="S4.SS5.p1.3.m3.1.1" xref="S4.SS5.p1.3.m3.1.1.cmml"><mi id="S4.SS5.p1.3.m3.1.1.2" xref="S4.SS5.p1.3.m3.1.1.2.cmml">Ïƒ</mi><mo id="S4.SS5.p1.3.m3.1.1.1" xref="S4.SS5.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS5.p1.3.m3.1.1.3" xref="S4.SS5.p1.3.m3.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b"><apply id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1"><eq id="S4.SS5.p1.3.m3.1.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1.1"></eq><ci id="S4.SS5.p1.3.m3.1.1.2.cmml" xref="S4.SS5.p1.3.m3.1.1.2">ğœ</ci><cn type="float" id="S4.SS5.p1.3.m3.1.1.3.cmml" xref="S4.SS5.p1.3.m3.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">\sigma=1.0</annotation></semantics></math>), the modelâ€™s performance exhibits an upward trend over time, accompanied by noticeable oscillation. When <math id="S4.SS5.p1.4.m4.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS5.p1.4.m4.1a"><mi id="S4.SS5.p1.4.m4.1.1" xref="S4.SS5.p1.4.m4.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.4.m4.1b"><ci id="S4.SS5.p1.4.m4.1.1.cmml" xref="S4.SS5.p1.4.m4.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.4.m4.1c">\sigma</annotation></semantics></math> is set to 10.0, the oscillation is attenuated, resulting in improved convergence performance. Further increasing <math id="S4.SS5.p1.5.m5.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS5.p1.5.m5.1a"><mi id="S4.SS5.p1.5.m5.1.1" xref="S4.SS5.p1.5.m5.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.5.m5.1b"><ci id="S4.SS5.p1.5.m5.1.1.cmml" xref="S4.SS5.p1.5.m5.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.5.m5.1c">\sigma</annotation></semantics></math> to 100.0 eliminates oscillation, but the curve converges to a lower level. From these observations, we can infer that the consolidation factor plays a crucial role in balancing resilience to previously acquired knowledge and plasticity to adapt to new knowledge. Achieving an optimal performance requires finding a delicate balance in between.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this study, we propose cyclical weight consolidation to address catastrophic forgetting in serial FL. Our extensive evaluations demonstrate the effectiveness of CWC in mitigating the fluctuation behavior of the original serial FL approach and consistently achieving higher convergence performance. We illustrated that CWC can adapt to more complex datasets and larger models, as evidenced by its success in a skin disease classification task. Notably, CWC outperformed CWT and FedAvg in extremely heterogeneous distributions, showcasing its robustness in challenging scenarios where other methods fail. Furthermore, our results indicate that CWC achieves performance comparable to parallel FL, marking a significant milestone for serial FL. The capability of CWC to boost convergence by intensifying local computation provides an additional advantage not achievable in CWT. We conducted a thorough analysis of the impact of the consolidation factor, demonstrating that optimal performance in CWC relies on striking a delicate balance between resilience to prior knowledge and adaptability to incorporate new information. Overall, our findings underscore the potential of CWC as a valuable tool in serial FL, offering a robust and efficient solution to the challenges posed by non-IID data distributions and knowledge retention across diverse sites.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. [2019]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, 10(2):1â€“19, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz etÂ al. [2021]</span>
<span class="ltx_bibblock">
Peter Kairouz, HÂ Brendan McMahan, Brendan Avent, AurÃ©lien Bellet, Mehdi Bennis, ArjunÂ Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, etÂ al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Foundations and TrendsÂ® in Machine Learning</em>, 14(1â€“2):1â€“210, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2022]</span>
<span class="ltx_bibblock">
Jiacheng Wang, Yueming Jin, and Liansheng Wang.

</span>
<span class="ltx_bibblock">Personalizing federated medical image segmentation via local calibration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>, pages 456â€“472. Springer, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2023]</span>
<span class="ltx_bibblock">
Jiacheng Wang, Yueming Jin, Danail Stoyanov, and Liansheng Wang.

</span>
<span class="ltx_bibblock">Feddp: Dual personalization in federated medical image segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Medical Imaging</em>, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan etÂ al. [2023]</span>
<span class="ltx_bibblock">
H.Â Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ AgÃ¼era yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang etÂ al. [2018]</span>
<span class="ltx_bibblock">
Ken Chang, Niranjan Balachandar, Carson Lam, Darvin Yi, James Brown, Andrew Beers, Bruce Rosen, DanielÂ L Rubin, and Jayashree Kalpathy-Cramer.

</span>
<span class="ltx_bibblock">Distributed deep learning networks among institutions for medical imaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics Association</em>, 25(8):945â€“954, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kalra etÂ al. [2023]</span>
<span class="ltx_bibblock">
Shivam Kalra, Junfeng Wen, JesseÂ C Cresswell, Maksims Volkovs, and HRÂ Tizhoosh.

</span>
<span class="ltx_bibblock">Decentralized federated learning through proxy model sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Nature communications</em>, 14(1):2899, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheller etÂ al. [2019]</span>
<span class="ltx_bibblock">
Micah Sheller, G.Â Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Multi-institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation: 4th International Workshop, BrainLes 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Revised Selected Papers, Part I</em>, volume 11383, pages 92â€“104.

</span>
<span class="ltx_bibblock">01 2019.

</span>
<span class="ltx_bibblock">ISBN 978-3-030-11722-1.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1007/978-3-030-11723-8_9" title="" class="ltx_ref ltx_href">10.1007/978-3-030-11723-8_9</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheller etÂ al. [2020]</span>
<span class="ltx_bibblock">
Micah Sheller, Brandon Edwards, G.Â Reina, Jason Martin, Sarthak Pati, Aikaterini Kotrotsou, Mikhail Milchenko, Weilin Xu, Daniel Marcus, Rivka Colen, and Spyridon Bakas.

</span>
<span class="ltx_bibblock">Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Scientific Reports</em>, 10, 07 2020.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1038/s41598-020-69250-1" title="" class="ltx_ref ltx_href">10.1038/s41598-020-69250-1</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">French [1999]</span>
<span class="ltx_bibblock">
RobertÂ M French.

</span>
<span class="ltx_bibblock">Catastrophic forgetting in connectionist networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Trends in cognitive sciences</em>, 3(4):128â€“135, 1999.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow etÂ al. [2013]</span>
<span class="ltx_bibblock">
IanÂ J Goodfellow, Mehdi Mirza, DaÂ Xiao, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">An empirical investigation of catastrophic forgetting in gradient-based neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6211</em>, 2013.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kemker etÂ al. [2018]</span>
<span class="ltx_bibblock">
Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, and Christopher Kanan.

</span>
<span class="ltx_bibblock">Measuring catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</em>, volumeÂ 32, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balachandar etÂ al. [2020]</span>
<span class="ltx_bibblock">
Niranjan Balachandar, Ken Chang, Jayashree Kalpathy-Cramer, and DanielÂ L Rubin.

</span>
<span class="ltx_bibblock">Accounting for data variability in multi-institutional distributed deep learning for medical imaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics Association</em>, 27(5):700â€“708, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeÂ Lange etÂ al. [2021]</span>
<span class="ltx_bibblock">
Matthias DeÂ Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, XuÂ Jia, AleÅ¡ Leonardis, Gregory Slabaugh, and Tinne Tuytelaars.

</span>
<span class="ltx_bibblock">A continual learning survey: Defying forgetting in classification tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</em>, 44(7):3366â€“3385, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hadsell etÂ al. [2020]</span>
<span class="ltx_bibblock">
Raia Hadsell, Dushyant Rao, AndreiÂ A Rusu, and Razvan Pascanu.

</span>
<span class="ltx_bibblock">Embracing change: Continual learning in deep neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Trends in cognitive sciences</em>, 24(12):1028â€“1040, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parisi etÂ al. [2019]</span>
<span class="ltx_bibblock">
GermanÂ I Parisi, Ronald Kemker, JoseÂ L Part, Christopher Kanan, and Stefan Wermter.

</span>
<span class="ltx_bibblock">Continual lifelong learning with neural networks: A review.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Neural networks</em>, 113:54â€“71, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vepakomma etÂ al. [2018]</span>
<span class="ltx_bibblock">
Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar.

</span>
<span class="ltx_bibblock">Split learning for health: Distributed deep learning without sharing raw patient data.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.00564</em>, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zenke etÂ al. [2017]</span>
<span class="ltx_bibblock">
Friedemann Zenke, Ben Poole, and Surya Ganguli.

</span>
<span class="ltx_bibblock">Continual learning through synaptic intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of machine learning research</em>, 70:3987â€“3995, 01 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2021]</span>
<span class="ltx_bibblock">
Lixu Wang, Shichao Xu, Xiao Wang, and QiÂ Zhu.

</span>
<span class="ltx_bibblock">Addressing class imbalance in federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volumeÂ 35, pages 10165â€“10173, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. [2009]</span>
<span class="ltx_bibblock">
Yanmin Sun, AndrewÂ KC Wong, and MohamedÂ S Kamel.

</span>
<span class="ltx_bibblock">Classification of imbalanced data: A review.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International journal of pattern recognition and artificial intelligence</em>, 23(04):687â€“719, 2009.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen [1989]</span>
<span class="ltx_bibblock">
Michael McCloskey and NealÂ J Cohen.

</span>
<span class="ltx_bibblock">Catastrophic interference in connectionist networks: The sequential learning problem.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Psychology of learning and motivation</em>, volumeÂ 24, pages 109â€“165. Elsevier, 1989.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He and Jaeger [2018]</span>
<span class="ltx_bibblock">
XuÂ He and Herbert Jaeger.

</span>
<span class="ltx_bibblock">Overcoming catastrophic interference using conceptor-aided backpropagation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. [2022]</span>
<span class="ltx_bibblock">
Tiantian Zhang, Xueqian Wang, Bin Liang, and BoÂ Yuan.

</span>
<span class="ltx_bibblock">Catastrophic interference in reinforcement learning: A solution based on context division and knowledge distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aljundi etÂ al. [2019]</span>
<span class="ltx_bibblock">
Rahaf Aljundi, Klaas Kelchtermans, and Tinne Tuytelaars.

</span>
<span class="ltx_bibblock">Task-free continual learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 11254â€“11263, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudithipudi etÂ al. [2022]</span>
<span class="ltx_bibblock">
Dhireesha Kudithipudi, Mario Aguilar-Simon, Jonathan Babb, Maxim Bazhenov, Douglas Blackiston, Josh Bongard, AndrewÂ P Brna, Suraj ChakravarthiÂ Raja, Nick Cheney, Jeff Clune, etÂ al.

</span>
<span class="ltx_bibblock">Biological underpinnings for lifelong learning machines.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, 4(3):196â€“210, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rebuffi etÂ al. [2017]</span>
<span class="ltx_bibblock">
Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and ChristophÂ H Lampert.

</span>
<span class="ltx_bibblock">icarl: Incremental classifier and representation learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</em>, pages 2001â€“2010, 2017.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rolnick etÂ al. [2019]</span>
<span class="ltx_bibblock">
David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory Wayne.

</span>
<span class="ltx_bibblock">Experience replay for continual learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 32, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Isele and Cosgun [2018]</span>
<span class="ltx_bibblock">
David Isele and Akansel Cosgun.

</span>
<span class="ltx_bibblock">Selective experience replay for lifelong learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volumeÂ 32, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhry etÂ al. [2019]</span>
<span class="ltx_bibblock">
Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, PÂ Dokania, PÂ Torr, and MÂ Ranzato.

</span>
<span class="ltx_bibblock">Continual learning with tiny episodic memories.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Workshop on Multi-Task and Lifelong Reinforcement Learning</em>, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aljundi etÂ al. [2017]</span>
<span class="ltx_bibblock">
Rahaf Aljundi, Punarjay Chakravarty, and Tinne Tuytelaars.

</span>
<span class="ltx_bibblock">Expert gate: Lifelong learning with a network of experts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 3366â€“3375, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rusu etÂ al. [2016]</span>
<span class="ltx_bibblock">
AndreiÂ A Rusu, NeilÂ C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell.

</span>
<span class="ltx_bibblock">Progressive neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.04671</em>, 2016.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Zhu [2018]</span>
<span class="ltx_bibblock">
JuÂ Xu and Zhanxing Zhu.

</span>
<span class="ltx_bibblock">Reinforced continual learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 31, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick etÂ al. [2017]</span>
<span class="ltx_bibblock">
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, AndreiÂ A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences</em>, 114(13):3521â€“3526, 2017.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1073/pnas.1611835114" title="" class="ltx_ref ltx_href">10.1073/pnas.1611835114</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.pnas.org/doi/abs/10.1073/pnas.1611835114" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.pnas.org/doi/abs/10.1073/pnas.1611835114</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. [2017]</span>
<span class="ltx_bibblock">
Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, and Byoung-Tak Zhang.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting by incremental moment matching.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aljundi etÂ al. [2018]</span>
<span class="ltx_bibblock">
Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and Tinne Tuytelaars.

</span>
<span class="ltx_bibblock">Memory aware synapses: Learning what (not) to forget.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on computer vision (ECCV)</em>, pages 139â€“154, 2018.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun etÂ al. [1998]</span>
<span class="ltx_bibblock">
Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 86(11):2278â€“2324, 1998.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky etÂ al. [2009]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, etÂ al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tschandl etÂ al. [2018]</span>
<span class="ltx_bibblock">
Philipp Tschandl, Cliff Rosendahl, and Harald Kittler.

</span>
<span class="ltx_bibblock">The ham10000 dataset: A large collection of multi-source dermatoscopic images of common pigmented skin lesions.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Scientific Data</em>, 5, 08 2018.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1038/sdata.2018.161" title="" class="ltx_ref ltx_href">10.1038/sdata.2018.161</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Codella etÂ al. [2019]</span>
<span class="ltx_bibblock">
Noel Codella, Veronica Rotemberg, Philipp Tschandl, M.Â Emre Celebi, Stephen Dusza, David Gutman, Brian Helba, Aadi Kalloo, Konstantinos Liopyris, Michael Marchetti, Harald Kittler, and Allan Halpern.

</span>
<span class="ltx_bibblock">Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (isic), 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. [2020]</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong, SebastianÂ U Stich, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 33:2351â€“2363, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba [2017]</span>
<span class="ltx_bibblock">
DiederikÂ P. Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization, 2017.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2016]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 770â€“778, 2016.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:creator" content="David S.Â Hippocampus, Elias D.Â Striatum"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="First keyword, Second keyword, More"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="q-bio.NC, q-bio.QM"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="A template for the arxiv style"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.10646" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.10647" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.10647">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.10647" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.10648" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 17:34:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
