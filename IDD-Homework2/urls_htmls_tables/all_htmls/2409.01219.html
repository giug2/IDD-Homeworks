<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches</title>
<!--Generated on Mon Sep  2 12:55:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.01219v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#S1" title="In A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#S2" title="In A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#S3" title="In A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#S4" title="In A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#S5" title="In A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kim Jinwoo
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Image retrieval is a crucial research topic in computer vision, with broad application prospects ranging from online product searches to security surveillance systems. In recent years, the accuracy and efficiency of image retrieval have significantly improved due to advancements in deep learning. However, existing methods still face numerous challenges, particularly in handling large-scale datasets, cross-domain retrieval, and image perturbations that can arise from real-world conditions such as variations in lighting, occlusion, and viewpoint. Data augmentation techniques and adversarial learning methods have been widely applied in the field of image retrieval to address these challenges. Data augmentation enhances the model’s generalization ability and robustness by generating more diverse training samples, simulating real-world variations, and reducing overfitting. Meanwhile, adversarial attacks and defenses introduce perturbations during training to improve the model’s robustness against potential attacks, ensuring reliability in practical applications. This review comprehensively summarizes the latest research advancements in image retrieval, with a particular focus on the roles of data augmentation and adversarial learning techniques in enhancing retrieval performance. Future directions and potential challenges are also discussed.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Image retrieval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib12" title="">12</a>]</cite> is an important and growing research area within computer vision, aiming to retrieve target images similar to the query image from a large-scale image database. With the rapid development of the internet and multimedia technologies, the explosion of image data across various domains such as e-commerce, social media, and surveillance has made the demand for efficient and accurate image retrieval techniques increasingly urgent. This has led to significant advancements in deep learning methods, particularly Convolutional Neural Networks (CNNs), which have become the de facto standard for feature extraction and matching in image retrieval systems.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite these advancements, existing methods still struggle to perform satisfactorily in complex and diverse real-world scenarios. Challenges include cross-domain retrieval, where the visual appearance of the same object can vary significantly under different conditions; dealing with image noise and perturbations, which can arise due to variations in lighting, occlusions, and viewpoint changes; and the sheer scale of modern image databases, which can contain millions or even billions of images. These challenges highlight the need for more robust and generalized retrieval systems.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address these challenges, researchers have turned to data augmentation and adversarial learning. Data augmentation techniques expand the diversity of the training dataset by transforming original images or generating new synthetic samples, thereby improving the model’s ability to generalize to unseen data. This is particularly important in image retrieval, where the diversity and variability of the dataset can directly impact the system’s performance. Common data augmentation methods include geometric transformations, color jittering, image cropping, and generating synthetic images using Generative Adversarial Networks (GANs). These methods help in reducing overfitting and enhancing the model’s robustness.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Adversarial learning techniques, on the other hand, focus on improving the robustness of the retrieval model against adversarial attacks. These attacks involve adding small perturbations to the input images that are often imperceptible to the human eye but can significantly degrade the model’s performance. By introducing adversarial examples during training, adversarial learning aims to make the model more resilient to such perturbations, ensuring that the retrieval system remains reliable even in the presence of potential attacks.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This review aims to systematically summarize the latest research advancements in data augmentation and adversarial learning techniques in the field of image retrieval. We emphasize the application value of these technologies in enhancing retrieval performance, analyze existing research shortcomings, and propose future research directions. The rest of this paper is organized as follows: Section II reviews related work in image retrieval, data augmentation, and adversarial learning; Section III details the methodologies employed in these areas; Section IV discusses the implications of these techniques and potential avenues for future research; and Section V concludes the paper.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In recent years, image retrieval techniques have made significant strides, primarily driven by advancements in deep learning. Convolutional Neural Networks (CNNs) have become the cornerstone of modern image retrieval systems due to their powerful feature extraction capabilities. Many studies have focused on enhancing the accuracy and efficiency of feature extraction, which is critical for effective image retrieval. For instance, Han et al. proposed a multi-scale feature fusion method, which combines features extracted at different scales to improve retrieval performance across varied image conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib17" title="">17</a>]</cite>. However, as the size and diversity of datasets increase, these models are prone to overfitting and often lack the necessary generalization capabilities, especially when faced with cross-domain retrieval tasks.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Data augmentation techniques have been widely adopted to mitigate these issues. He et al. utilized data augmentation to generate a more diverse set of training samples, which helped to improve the model’s performance in cross-domain retrieval tasks by providing more representative examples during training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib10" title="">10</a>]</cite>. This approach has been particularly effective in scenarios where labeled data is scarce or expensive to obtain. Data augmentation methods such as geometric transformations, color adjustments, and image synthesis using GANs have shown promise in enhancing the robustness of retrieval models by simulating various real-world conditions during training.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Adversarial learning has also emerged as a critical area of research in image retrieval. Adversarial attacks, first introduced by Goodfellow et al., involve adding carefully crafted perturbations to images that are designed to fool the model into making incorrect predictions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib6" title="">6</a>]</cite>. These attacks have exposed significant vulnerabilities in deep learning models, particularly in security-sensitive applications such as surveillance and autonomous driving. To counter these threats, adversarial training methods have been developed. Miyato et al. proposed virtual adversarial training (VAT), a method that introduces adversarial perturbations during training to improve the model’s robustness against such attacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.01219v1#bib.bib10" title="">10</a>]</cite>. This technique has been shown to significantly enhance the resilience of image retrieval models, making them more reliable in the face of adversarial conditions.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In the context of image retrieval, data augmentation and adversarial learning serve complementary roles in improving model performance and robustness. Data augmentation techniques are primarily used to enhance the diversity of the training dataset, which is crucial for developing models that generalize well to unseen data. Common augmentation techniques include geometric transformations (such as rotation, scaling, and translation), color jittering, random cropping, and image synthesis using GANs. These methods introduce variations in the training data that mimic real-world conditions, thereby helping the model learn to recognize objects under different scenarios.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">For instance, geometric transformations such as rotation and scaling can simulate changes in viewpoint and size, which are common in real-world image retrieval tasks. Similarly, color jittering can simulate variations in lighting conditions, while random cropping helps the model become invariant to changes in object positioning within the image. The use of GANs for data augmentation has gained traction, as these models can generate realistic synthetic images that further expand the diversity of the training set, making the model more robust.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Adversarial learning techniques, on the other hand, focus on improving the model’s robustness against adversarial attacks. Adversarial examples are generated by adding carefully crafted perturbations to the input images, which are designed to mislead the model into making incorrect predictions. The key to effective adversarial training is generating perturbations that are strong enough to challenge the model, but subtle enough to avoid detection by humans.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">In adversarial training, the model is exposed to a mixture of normal and adversarial examples during training. This forces the model to learn to distinguish between genuine and perturbed images, thereby improving its resilience to attacks. Techniques such as VAT introduce virtual adversarial examples that do not require labeled data, making them particularly useful in semi-supervised learning scenarios. By enhancing the model’s robustness through adversarial training, image retrieval systems can become more reliable in real-world applications where security and accuracy are paramount.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">While data augmentation and adversarial learning have shown significant promise in improving image retrieval performance, there are still several challenges that need to be addressed. One of the primary limitations of data augmentation is that it relies on predefined transformation strategies, which may not cover all possible variations encountered in real-world scenarios. As a result, the model may still struggle with certain types of image perturbations that were not adequately represented in the training data. Future research could explore more adaptive and context-aware augmentation techniques that dynamically generate transformations based on the specific characteristics of the dataset.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Adversarial learning, while effective, also has its challenges. The success of adversarial training heavily depends on the quality and diversity of the adversarial examples generated during training. If the perturbations are too weak, they may not effectively challenge the model, leading to insufficient robustness. Conversely, if the perturbations are too strong, they may interfere with the model’s ability to learn from genuine examples, potentially reducing overall performance. Finding the right balance in adversarial training remains an open research question. Additionally, the computational cost of generating adversarial examples can be significant, particularly for large-scale datasets, which may limit the practicality of these methods in real-world applications.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Future research directions could include the development of more efficient adversarial example generation techniques that reduce computational overhead while maintaining effectiveness. Moreover, combining data augmentation and adversarial learning with other techniques, such as multi-task learning and transfer learning, could further enhance the robustness and generalization capabilities of image retrieval models. These approaches could help bridge the gap between the performance of models in controlled research environments and their performance in real-world applications.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Image retrieval, as one of the core tasks in computer vision, faces numerous challenges that require robust and adaptable solutions. Data augmentation and adversarial learning techniques provide powerful tools to enhance image retrieval performance by improving the model’s generalization ability and resilience to perturbations. By generating diverse training samples and introducing adversarial examples, these techniques address some of the key challenges associated with large-scale datasets and real-world variability. However, there is still room for improvement, particularly in developing more adaptive and efficient methods. Future research will continue to explore how these techniques can be refined and combined with other approaches to meet the demands of increasingly complex real-world scenarios.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
Shekoofeh Azizi, Laura Culp, Jan Freyberg, Basil Mustafa, Sebastien Baur, Simon
Kornblith, Ting Chen, Nenad Tomasev, Jovana Mitrović, Patricia Strachan,
et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.2.1" style="font-size:90%;">Robust and data-efficient generalization of self-supervised machine
learning for diagnostic imaging.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.3.1" style="font-size:90%;">Nature Biomedical Engineering</span><span class="ltx_text" id="bib.bib1.4.2" style="font-size:90%;">, 7(6):756–779, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor
Darrell, Yuval Noah Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz,
et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.2.1" style="font-size:90%;">Managing extreme ai risks amid rapid progress.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.3.1" style="font-size:90%;">Science</span><span class="ltx_text" id="bib.bib2.4.2" style="font-size:90%;">, 384(6698):842–845, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
Yunpeng Gong et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.2.1" style="font-size:90%;">Cross-modality perturbation synergy attack for person
re-identification.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.3.1" style="font-size:90%;">arXiv preprint arXiv:2401.10090</span><span class="ltx_text" id="bib.bib3.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
Yunpeng Gong, Yongjie Hou, Chuangliang Zhang, and Min Jiang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.2.1" style="font-size:90%;">Beyond augmentation: Empowering model robustness under extreme
capture environments.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.3.1" style="font-size:90%;">arXiv preprint arXiv:2407.13640</span><span class="ltx_text" id="bib.bib4.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
Yunpeng Gong, Liqing Huang, and Lifei Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.2.1" style="font-size:90%;">Eliminate deviation with deviation for data augmentation and a
general multi-modal data learning method.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.3.1" style="font-size:90%;">arXiv preprint arXiv:2101.08533</span><span class="ltx_text" id="bib.bib5.4.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
Yunpeng Gong, Liqing Huang, and Lifei Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.2.1" style="font-size:90%;">Person re-identification method based on color attack and joint
defence.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span class="ltx_text" id="bib.bib6.5.3" style="font-size:90%;">, pages 4313–4322, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
Yunpeng Gong, Jiaquan Li, Lifei Chen, and Min Jiang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.2.1" style="font-size:90%;">Exploring color invariance through image-level ensemble learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.3.1" style="font-size:90%;">arXiv preprint arXiv:2401.10512</span><span class="ltx_text" id="bib.bib7.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Yunpeng Gong and Zhiyong Zeng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.2.1" style="font-size:90%;">An effective data augmentation for person re-identification.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.3.1" style="font-size:90%;">ArXiv, abs</span><span class="ltx_text" id="bib.bib8.4.2" style="font-size:90%;">, 2101, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
Yunpeng Gong, Zhiyong Zeng, Liwen Chen, Yifan Luo, Bin Weng, and Feng Ye.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.2.1" style="font-size:90%;">A person re-identification data augmentation method with adversarial
defense effect.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.3.1" style="font-size:90%;">arXiv preprint arXiv:2101.08783</span><span class="ltx_text" id="bib.bib9.4.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
Yunpeng GONG, Zhiyong ZENG, and Feng YE.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.2.1" style="font-size:90%;">Person re-identification method based on grayscale feature
enhancement.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.3.1" style="font-size:90%;">Journal of Computer Applications</span><span class="ltx_text" id="bib.bib10.4.2" style="font-size:90%;">, 41(12):3590, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
Yunpeng Gong, Chuangliang Zhang, Yongjie Hou, Lifei Chen, and Min Jiang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.2.1" style="font-size:90%;">Beyond dropout: Robust convolutional neural networks based on local
feature masking.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.3.1" style="font-size:90%;">arXiv preprint arXiv:2407.13646</span><span class="ltx_text" id="bib.bib11.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
Alex Krizhevsky, Geoffrey Hinton, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.2.1" style="font-size:90%;">Learning multiple layers of features from tiny images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.3.1" style="font-size:90%;">2009.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.2.1" style="font-size:90%;">Imagenet classification with deep convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.3.1" style="font-size:90%;">Advances in neural information processing systems</span><span class="ltx_text" id="bib.bib13.4.2" style="font-size:90%;">, 25, 2012.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.2.1" style="font-size:90%;">Deep learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.3.1" style="font-size:90%;">nature</span><span class="ltx_text" id="bib.bib14.4.2" style="font-size:90%;">, 521(7553):436–444, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.2.1" style="font-size:90%;">Learning internal representations by error propagation, parallel
distributed processing, explorations in the microstructure of cognition, ed.
de rumelhart and j. mcclelland. vol. 1. 1986.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.3.1" style="font-size:90%;">Biometrika</span><span class="ltx_text" id="bib.bib15.4.2" style="font-size:90%;">, 71(599-607):6, 1986.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.2.1" style="font-size:90%;">Dropout: a simple way to prevent neural networks from overfitting.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.3.1" style="font-size:90%;">The journal of machine learning research</span><span class="ltx_text" id="bib.bib16.4.2" style="font-size:90%;">, 15(1):1929–1958,
2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
Laurens Van der Maaten and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.2.1" style="font-size:90%;">Visualizing data using t-sne.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.3.1" style="font-size:90%;">Journal of machine learning research</span><span class="ltx_text" id="bib.bib17.4.2" style="font-size:90%;">, 9(11), 2008.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep  2 12:55:04 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
