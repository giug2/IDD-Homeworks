<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Rethinking Recommender Systems: Cluster-based Algorithm Selection</title>
<!--Generated on Tue May 28 09:48:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommender Systems,  Algorithm Selection Problem,  Clustering,  Automated Recommender Systems,  AutoRecSys,  Clustering Selection Problem" lang="en" name="keywords"/>
<base href="/html/2405.18011v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S1" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S2" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Cluster-based AutoRecSys</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.SS1" title="In 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Clustering with <math alttext="k" class="ltx_Math" display="inline"><semantics><mi>k</mi><annotation-xml encoding="MathML-Content"><ci>𝑘</ci></annotation-xml><annotation encoding="application/x-tex">k</annotation><annotation encoding="application/x-llamapun">italic_k</annotation></semantics></math>-Means</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.SS1.SSS0.Px1" title="In 3.1. Clustering with 𝑘-Means ‣ 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Clustering by Number of Interactions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.SS1.SSS0.Px2" title="In 3.1. Clustering with 𝑘-Means ‣ 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Clustering by Item-Interaction Vector</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.SS2" title="In 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Clustering with Graphs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4.SS1" title="In 4. Methodology ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Design Decisions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4.SS2" title="In 4. Methodology ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Algorithms and Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4.SS3" title="In 4. Methodology ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Experimental Pipeline</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.SS0.SSS0.Px1" title="In 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Figure <span class="ltx_text ltx_ref_tag">3</span>. <math alttext="k" class="ltx_Math" display="inline"><semantics><mi>k</mi><annotation-xml encoding="MathML-Content"><ci>𝑘</ci></annotation-xml><annotation encoding="application/x-tex">k</annotation><annotation encoding="application/x-llamapun">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic">-Means number of interactions</span> with <span class="ltx_text ltx_font_italic">nDCG@10</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.SS0.SSS0.Px2" title="In 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Figure <span class="ltx_text ltx_ref_tag">4</span>. <math alttext="k" class="ltx_Math" display="inline"><semantics><mi>k</mi><annotation-xml encoding="MathML-Content"><ci>𝑘</ci></annotation-xml><annotation encoding="application/x-tex">k</annotation><annotation encoding="application/x-llamapun">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic">-Means item-interaction vector</span> with <span class="ltx_text ltx_font_italic">nDCG@10</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.SS0.SSS0.Px3" title="In 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Figure <span class="ltx_text ltx_ref_tag">5</span>. Louvain with <span class="ltx_text ltx_font_italic">nDCG@10</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.SS0.SSS0.Px4" title="In 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Figure <span class="ltx_text ltx_ref_tag">6</span>. <span class="ltx_text ltx_font_italic">Greedy Modularity</span> with <span class="ltx_text ltx_font_italic">nDCG@10</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.SS0.SSS0.Px5" title="In 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title">Maximum Best Combined Recommender</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S6" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S7" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S8" title="In Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Future Work and Limitations</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Rethinking Recommender Systems: Cluster-based Algorithm Selection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andreas Lizenberger
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">University Siegen</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:andreas.lizenberger@student.uni-siegen.de">andreas.lizenberger@student.uni-siegen.de</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ferdinand Pfeifer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">University Siegen</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ferdinand.pfeifer@student.uni-siegen.de">ferdinand.pfeifer@student.uni-siegen.de</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bastian Polewka
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:bastian.polewka@student.uni-siegen.de">bastian.polewka@student.uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">University Siegen</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">Germany</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id10.id1"><span class="ltx_text ltx_font_bold" id="id10.id1.1">Abstract.</span>
Cluster-based algorithm selection deals with selecting recommendation algorithms on clusters of users to obtain performance gains.
No studies have been attempted for many combinations of clustering approaches and recommendation algorithms.
We want to show that clustering users prior to algorithm selection increases the performance of recommendation algorithms.
Our study covers eight datasets, four clustering approaches, and eight recommendation algorithms. We select the best performing recommendation algorithm for each cluster.
Our work shows that cluster-based algorithm selection is an effective technique for optimizing recommendation algorithm performance. For five out of eight datasets, we report an increase in <span class="ltx_text ltx_font_italic" id="id10.id1.2">nDCG@10</span> between 19.28% (0.032) and 360.38% (0.191) compared to algorithm selection without prior clustering.</p>
</div>
<div class="ltx_keywords">Recommender Systems, Algorithm Selection Problem, Clustering, Automated Recommender Systems, AutoRecSys, Clustering Selection Problem
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Conference; Date; Location</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>Conference,
MonthName Month–Day, Year, City, State</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>ISBN</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Clustering and classification</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Social and professional topics Automation</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In the digital age online platforms offer a vast number of products (items), such as movies <cite class="ltx_cite ltx_citemacro_citep">(netflix.com, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib30" title="">2023</a>)</cite>, clothing <cite class="ltx_cite ltx_citemacro_citep">(zalando.com, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib46" title="">[n. d.]</a>)</cite>, music <cite class="ltx_cite ltx_citemacro_citep">(spotifiy.com, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib36" title="">[n. d.]</a>)</cite>, and many more. Online platforms want to encourage users to interact with as many items as possible, but online platforms can only display a fraction of items at any given time. Therefore, displaying items that match the preferences and tastes of users is important and motivates the integration of recommender systems. Recommender systems recommend a fraction of items based on previous interactions between users and items <cite class="ltx_cite ltx_citemacro_citep">(Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib21" title="">2022</a>)</cite>.
For example, Netflix deploys a recommender system to encourage users to watch more movies from their vast library of up to 18,214 movies and series <cite class="ltx_cite ltx_citemacro_citep">(netflix.com, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib30" title="">2023</a>)</cite>. A user who frequently watches action movies is probably interested in the action genre. The recommender system deployed by Netflix recommends movies from the action genre to display the recommended movies to the user.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The performance of recommendation algorithms varies strongly which motivates algorithm selection for recommender systems <cite class="ltx_cite ltx_citemacro_citep">(Beel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib2" title="">2016</a>)</cite>. Recommendation algorithms are the core of recommender systems and generate recommendations for users <cite class="ltx_cite ltx_citemacro_citep">(Jalili et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib24" title="">2018</a>)</cite>. The algorithm selection problem defines criteria for comparing a set of algorithms in order to select the best algorithm <cite class="ltx_cite ltx_citemacro_citep">(Rice, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib33" title="">1976</a>)</cite>.
For example, applying different recommendation algorithms to news websites can result in a precision increase of up to 330% (0.43) <cite class="ltx_cite ltx_citemacro_citep">(Beel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib2" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The problem is selecting the single best recommendation algorithm for all users does not account for clusters of users. Clusters contain users with similar behavior and preferences. Clustering approaches detect these similarities and generate clusters of users <cite class="ltx_cite ltx_citemacro_citep">(Xu and Tian, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib42" title="">2015</a>)</cite>. By selecting recommendation algorithms for each cluster we can leverage the unique strengths of each recommendation algorithm. We argue that cluster-based algorithm selection accounts for clusters of users resulting in an increase of overall recommendation performance.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Therefore, we want to determine whether selecting recommendation algorithms for clusters of users improves the overall recommendation performance of recommender systems. In our work, we aim to answer the following research question:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.1.1.1">RQ1</span></span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">What is the influence of clustering on the performance of recommendation algorithms?</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To address our research question, we combine clustering with an already existing pipeline for training recommendation algorithms. For a total of eight datasets, we conduct a study on the recommendation performance achieved by selecting the best algorithms on each automatically generated cluster. <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Our contribution</span> is cluster-based algorithm selection which increases the average <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">nDCG@10</span> by 66.47% compared to algorithm selection. We find combinations of clustering approaches and recommendation algorithms that significantly increase recommendation performance, answering <span class="ltx_text ltx_font_bold" id="S1.p5.1.3">RQ1</span>.
Our long-term goal is to establish cluster-based algorithm selection.
</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our implementation is publicly available on our GitHub repository<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://code.isg.beel.org/PG_SS_23" title="">https://code.isg.beel.org/PG_SS_23</a></span></span></span> and
contains documentation for the reproducibility of our experiments.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Cluster-based algorithm selection is still open to research. To the best of our knowledge, existing work covers a single clustering approach prior to algorithm selection. We review related work to cluster-based algorithm selection in the fields: clustering, meta-learning, automated recommender systems (AutoRecSys) and ensembling.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Alexander Nechaev et al. propose an approach to select algorithms based on user groups that is similar to our approach. The authors generate user groups by clustering with <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">HDBSCAN</span>. <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">HDBSCAN</span> clusters users with the following meta-features: relative count, standard deviation and skewness of user’s ratings. The authors employ the following recommendation algorithms: <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">SVD</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.4">SVD++</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.5">KNN Baseline</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.6">Baseline Only</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.7">Co-Clustering</span>. The authors select the best performing algorithm for each cluster <cite class="ltx_cite ltx_citemacro_citep">(Meltsov, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib28" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The influence of cluster-based algorithm selection on the performance of recommender systems is not researched extensively yet. The authors suggest a single clustering approach in combination with collaborative filtering. Cluster-based collaborative filtering attempts to improve adaptability and scalability of recommender systems while maintaining coverage and performance of recommendations. The problem is a marginal recommendation performance increase compared to collaborative filtering without prior clustering <cite class="ltx_cite ltx_citemacro_citep">(Bellogin and Parapar, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib4" title="">2012</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib20" title="">2015</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Xue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib43" title="">2005</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Li and Kim, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib25" title="">2003</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Meta-learning is an approach to deal with the algorithm selection problem. The idea of meta-learning is to analyze meta-information derived from datasets and performances of algorithms. The authors perform meta-learning algorithm selection on different levels: the global-level which covers datasets <cite class="ltx_cite ltx_citemacro_citep">(Romero et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib34" title="">2013</a>; Matuszyk and Spiliopoulou, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib27" title="">2014</a>; Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib9" title="">2016</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib10" title="">2018</a>)</cite>, the middle-level which covers groups of users or single users <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand and Riedl, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib16" title="">2012</a>)</cite>, and the micro-level which covers user-item pairs <cite class="ltx_cite ltx_citemacro_citep">(Edenhofer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib15" title="">2019</a>; Collins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib8" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">AutoRecSys defines a pipeline to standardize and automate the stages of recommender systems to deal with the combined algorithm selection and hyperparameter optimization problem (CASH). AutoRecSys approaches deal with the CASH problem by training multiple algorithms with varying hyperparameters according to a search strategy, e.g. <span class="ltx_text ltx_font_italic" id="S2.p5.1.1">Random Search</span>, <span class="ltx_text ltx_font_italic" id="S2.p5.1.2">Bayesian optimization</span>, and selecting the best algorithm after hyperparameter optimization <cite class="ltx_cite ltx_citemacro_citep">(Vente et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib39" title="">2023</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib41" title="">2020</a>; Vente, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib38" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Ensembling is a technique to improve the performance of a recommender system. Jahrer et al. demonstrate that multiple recommendation algorithm perform better than a single recommendation algorithm <cite class="ltx_cite ltx_citemacro_citep">(Jahrer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib23" title="">2010</a>)</cite>. Ensembling works with a broader range of user interactions when both explicit and implicit feedback is available <cite class="ltx_cite ltx_citemacro_citep">(Da Costa and Manzato, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib11" title="">2014</a>; da Costa Fortes and Manzato, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib12" title="">2014</a>)</cite>. Ensembling is not only applicable to make recommendations to the users, but is also applicable in the context of detecting similarities of users <cite class="ltx_cite ltx_citemacro_citep">(Forouzandeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib18" title="">2021</a>)</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Cluster-based AutoRecSys</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1"><span class="ltx_text ltx_font_italic" id="S3.p1.1.1">LensKit-Auto</span> <cite class="ltx_cite ltx_citemacro_citep">(Vente et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib39" title="">2023</a>)</cite> is an AutoRecSys toolkit to automate the recommender systems pipeline. <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">LensKit-Auto</span> offers preprocessing, hyperparameter optimization and algorithm training for the development of recommender systems. Hyperparameter optimization can be performed with a search strategy, e.g. <span class="ltx_text ltx_font_italic" id="S3.p1.1.3">Random Search</span> or <span class="ltx_text ltx_font_italic" id="S3.p1.1.4">Bayesian Optimization</span>. For each recommendation algorithm we use <span class="ltx_text ltx_font_italic" id="S3.p1.1.5">LensKit-Auto</span> to perform <span class="ltx_text ltx_font_italic" id="S3.p1.1.6">Random Search</span> to find optimized hyperparameters. We recommend based on the optimized hyperparameters. Optimizing hyperparameters enables our comparison to focus on the performance of the different recommendation algorithms rather than the choice of hyperparameters. We assess the performance of each recommendation algorithm by comparing either <span class="ltx_text ltx_font_italic" id="S3.p1.1.7">nDCG</span> or <span class="ltx_text ltx_font_italic" id="S3.p1.1.8">Precision</span>.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="142" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Cluster-based AutoRecSys process.</figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We employ cluster-based AutoRecSys to find the best algorithms on each cluster to solve the cluster-based algorithm selection problem. First, we iterate over a list of clustering approaches and parameters to generate a set of disjoint clusters. Then, we apply the AutoRecSys library <span class="ltx_text ltx_font_italic" id="S3.p2.1.1">LensKit-Auto</span> to train recommendation algorithms on each cluster. For each cluster we select the best performing recommendation algorithm. We combine the selected best performing algorithms to a combined recommender (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.F1" title="Figure 1 ‣ 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">1</span></a>). Our approach can be classified as middle-level algorithm selection, because our approach operates on sets of clusters of users. We introduce our selected clustering approaches in the sections <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.SS1" title="3.1. Clustering with 𝑘-Means ‣ 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">3.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3.SS2" title="3.2. Clustering with Graphs ‣ 3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Clustering with <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.1.m1.1"><semantics id="S3.SS1.1.m1.1b"><mi id="S3.SS1.1.m1.1.1" xref="S3.SS1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.1.m1.1c"><ci id="S3.SS1.1.m1.1.1.cmml" xref="S3.SS1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.1.m1.1e">italic_k</annotation></semantics></math>-Means</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4"><math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_K</annotation></semantics></math>-Means <cite class="ltx_cite ltx_citemacro_citep">(MacQueen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib26" title="">1967</a>)</cite> is a centroid-based clustering approach that generates clusters around centroids. Each centroid represents the center of a cluster. <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math>-Means select <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_k</annotation></semantics></math> many centroids in order to generate <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_k</annotation></semantics></math> many clusters. For each user the distance to all centroids is computed. Users are assigned to a cluster based on the smallest computed distance to the centroid of the cluster. For each cluster the centroid is recomputed as the mean of all users of the cluster. The assignment and recomputing step are repeated until the cluster assignment from the current iteration is equal to the cluster assignment from the previous iteration <cite class="ltx_cite ltx_citemacro_citep">(MacQueen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib26" title="">1967</a>)</cite>.
For example, we want to cluster users by age. Given two clusters, the first cluster has a mean age of 20 and the second cluster a mean age of 40. A 25 year old user has a distance of 5 years to the centroid of the first cluster and a distance of 15 years to the centroid of the second cluster. Therefore, the 25 year old user is assigned to the first cluster with the mean age of 20. Once all users are assigned to a cluster, the mean age of the clusters is recomputed.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Clustering by Number of Interactions</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">The first meta-information we choose for clustering with <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.1.m1.1d">italic_k</annotation></semantics></math>-Means is the number of interactions between users and items. Number of interactions is the sum of all interactions that users have with items. We choose number of interactions for two reasons. The first reason is that generating clusters that separate users with a different number of interactions improves the recommendation score for users with many interactions <cite class="ltx_cite ltx_citemacro_citep">(Beel and Brunel, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib3" title="">2019</a>)</cite>. The second reason is that Jianling Wang et al. indicate that removing interactions from users with many interactions improves the recommendations for users with fewer interactions <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib40" title="">2022</a>)</cite>.
For example, we have user A and B who both watched 40 movies and user C who watched 200 movies. Both user B and C share 20 of their watched movies with user A. We want to recommend a movie to user A. The recommendations provided by utilizing user B are more relevant to user A because user A and B share 50% of their watched movies and user A and C share only 10% of their watched movies.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Clustering by Item-Interaction Vector</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.5">The second meta-information we choose for clustering with <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.1.m1.1d">italic_k</annotation></semantics></math>-Means is the item-interaction vector of each user. The item-interaction vector encodes binarily whether users interacted with items or not and number of interactions as the last entry. For example, if a user interacted with item A, item B but not with item C, the item-interaction vector is <math alttext="(1,1,0,2)^{T}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.2.m2.4"><semantics id="S3.SS1.SSS0.Px2.p1.2.m2.4a"><msup id="S3.SS1.SSS0.Px2.p1.2.m2.4.5" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.cmml"><mrow id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml"><mo id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2.1" stretchy="false" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml">(</mo><mn id="S3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.2.m2.2.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.2.2.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.2.m2.3.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.3.3.cmml">0</mn><mo id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2.4" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.2.m2.4.4" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.4.cmml">2</mn><mo id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2.5" stretchy="false" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml">)</mo></mrow><mi id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.2.m2.4b"><apply id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5">superscript</csymbol><vector id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.2.2"><cn id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1">1</cn><cn id="S3.SS1.SSS0.Px2.p1.2.m2.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.2.m2.2.2">1</cn><cn id="S3.SS1.SSS0.Px2.p1.2.m2.3.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.2.m2.3.3">0</cn><cn id="S3.SS1.SSS0.Px2.p1.2.m2.4.4.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.4">2</cn></vector><ci id="S3.SS1.SSS0.Px2.p1.2.m2.4.5.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.4.5.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.2.m2.4c">(1,1,0,2)^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.2.m2.4d">( 1 , 1 , 0 , 2 ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>.
Only considering number of interactions can lead to clusters with an insufficient number of users. The problem is that recommendation algorithms trained on clusters with an insufficient number of users perform poorly in our tests.
For example, clusters with an insufficient number of users can occur if we have a dataset with 10.000 users of which three users have 1000 interactions and remaining users have less than 20 interactions. Clustering based on number of interactions would result in a cluster with only three users, because the users have a similar number of interactions.
Clustering with item-interaction vector benefits <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px2.p1.3.m3.1a"><mi id="S3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.3.m3.1b"><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.3.m3.1d">italic_k</annotation></semantics></math>-Means, because additional meta-information is available to find similarities between users.
We demonstrate the availability of additional meta-information using an example of four users A, B, C, D, and two items A and B.
User A and B have an interaction with item A but not with item B, so the item-interaction vector is <math alttext="(1,0,1)^{T}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.4.m4.3"><semantics id="S3.SS1.SSS0.Px2.p1.4.m4.3a"><msup id="S3.SS1.SSS0.Px2.p1.4.m4.3.4" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.cmml"><mrow id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.2" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.1.cmml"><mo id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.2.1" stretchy="false" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.1.cmml">(</mo><mn id="S3.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.2.2" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.4.m4.2.2" xref="S3.SS1.SSS0.Px2.p1.4.m4.2.2.cmml">0</mn><mo id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.2.3" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.4.m4.3.3" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.3.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.2.4" stretchy="false" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.1.cmml">)</mo></mrow><mi id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.3" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.4.m4.3b"><apply id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4">superscript</csymbol><vector id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.2.2"><cn id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1">1</cn><cn id="S3.SS1.SSS0.Px2.p1.4.m4.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.4.m4.2.2">0</cn><cn id="S3.SS1.SSS0.Px2.p1.4.m4.3.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.3">1</cn></vector><ci id="S3.SS1.SSS0.Px2.p1.4.m4.3.4.3.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.3.4.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.4.m4.3c">(1,0,1)^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.4.m4.3d">( 1 , 0 , 1 ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>.
User C and D have an interaction with item B but not with item A, so the item-interaction vector is <math alttext="(0,1,1)^{T}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.5.m5.3"><semantics id="S3.SS1.SSS0.Px2.p1.5.m5.3a"><msup id="S3.SS1.SSS0.Px2.p1.5.m5.3.4" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.cmml"><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.1.cmml"><mo id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.2.1" stretchy="false" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.1.cmml">(</mo><mn id="S3.SS1.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.cmml">0</mn><mo id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.5.m5.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.2.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p1.5.m5.3.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.3.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.2.4" stretchy="false" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.1.cmml">)</mo></mrow><mi id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.5.m5.3b"><apply id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4">superscript</csymbol><vector id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.2.2"><cn id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1">0</cn><cn id="S3.SS1.SSS0.Px2.p1.5.m5.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2">1</cn><cn id="S3.SS1.SSS0.Px2.p1.5.m5.3.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.3">1</cn></vector><ci id="S3.SS1.SSS0.Px2.p1.5.m5.3.4.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.3.4.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.5.m5.3c">(0,1,1)^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.5.m5.3d">( 0 , 1 , 1 ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>.
If we cluster the users based on number of interactions then the four users form a single cluster, because all users have same number of interactions.
With the item-interaction vector we can additionally cluster the users based on the items that the users have interacted with, resulting in a cluster with user A and B, and a cluster with user C and D.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Clustering with Graphs</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Our final two clustering approaches are the graph-based approaches <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">Louvain Method for Community Detection</span> (<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">Louvain</span>) <cite class="ltx_cite ltx_citemacro_citep">(Blondel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib5" title="">2008</a>)</cite> and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.3">Greedy Modularity</span> <cite class="ltx_cite ltx_citemacro_citep">(Clauset et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib7" title="">2004</a>)</cite>. Graph-based clustering approaches analyze graphs and generate clusters by detecting densely interconnected subgraphs called communities. User-item interactions represent a graph: users and items are nodes, interactions are edges.
<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.4">Louvain</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.5">Greedy Modularity</span> find communities based on modularity. Modularity measures the density of edges within communities compared to edges between communities. Initially, all nodes represent a community. Iteratively, <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.6">Louvain</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.7">Greedy Modularity</span> check for each node whether modularity is improved by moving the node to a neighboring community. The process of moving nodes to neighboring communities stops when the modularity cannot be further improved <cite class="ltx_cite ltx_citemacro_citep">(Blondel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib5" title="">2008</a>; Clauset et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib7" title="">2004</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The meta-information we choose for graph-based clustering is a graph encoding of the user-item interaction matrix. We generate the graph by deriving all unique users and items. For every user and items we add a node to the graph. We add edges between users and items by traversing each user interaction entry and connecting the user and item contained in the entries. In order to obtain clusters using graph based approaches, we find communities by applying the graph-based approaches. The resulting communities consist of user and item nodes. We generate a cluster for each community by extracting all users from the community. The items are not relevant for our user-based clustering approaches, therefore we can ignore the item nodes.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Methodology</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our work analyzes the influence of clustering on algorithm selection. Each clustering approach generates a set of clusters. For each cluster in the generated set of clusters we evaluate the performance of recommendation algorithms. We select the best performing algorithm for each cluster. For each set of clusters we obtain a combined recommender that uses the best performing recommendation algorithm of each cluster. In order to measure the influence of clustering, we compare the combined recommender to a baseline. The baseline performance is the performance of the recommendation algorithm that performs best on the dataset prior to clustering. The performance of our combined recommender is the weighted sum of the best performing algorithm of each cluster. The algorithms are weighted by the number of users in the respective cluster divided by the number of all users in the dataset. We are interested in finding a combined recommender that outperforms the baseline.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The experiment was executed on a computer cluster, where each node has in total 64 cores from two AMD EPYC 7452 CPUs and 256 GB DDR4 3200MHz RAM.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Design Decisions</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We explain the reasoning behind our parameter choices for our experimental pipeline. The clustering approaches utilize two clustering parameters: cluster count and resolution. Cluster count sets the number of clusters for the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">-Means clustering approach</span>, while <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">Greedy Modularity</span> uses it as an upper limit to generate clusters. In our experiments cluster count ranges from two to eight clusters. We reason the upper limit of eight clusters based on previous tests of our pipeline on an upper limit of 15 clusters. We measured no increase in performance with more than seven clusters. A higher cluster count could be feasible if the size of the dataset is larger than our tested datasets. <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">Louvain</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.4">Greedy Modularity</span> generate clusters based on resolution. Resolutions greater than one lead to many small clusters and resolutions smaller than one lead to few big clusters <cite class="ltx_cite ltx_citemacro_citep">(Blondel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib5" title="">2008</a>; Clauset et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib7" title="">2004</a>)</cite>. In our experiments we choose resolutions 0.8, 0.9, default of 1.0, 1.1, and 1.2. With <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.5">LensKit-Auto</span> we choose the <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.6">Random Search</span> strategy for hyperparameter optimization, because <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.7">Random Search</span> allows us to optimize for our two metrics <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.8">nDCG</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.9">Precision</span> simultaneously. We argue that with a limit of 100 iterations and a search limit of four hours, <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.10">Random Search</span> will find enough optimized hyperparameters to compare the clustering approaches.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Algorithms and Datasets</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We use eight recommendation algorithms of which two are baseline algorithms and eight different datasets.
The recommendation algorithms are from the libraries <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.1">LensKit</span> <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib17" title="">2020</a>)</cite> and <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.2">Implicit</span> <cite class="ltx_cite ltx_citemacro_citep">(Frederickson, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib19" title="">2023</a>)</cite>.
From <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.3">LensKit</span> we use the algorithms: <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.4">Random</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.5">PopScore</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.6">Item-Item Nearest Neighbour</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.7">User-User Nearest Neighbour</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.8">Implicit Matrix Factorization</span>.
The algorithms from Implicit are: <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.9">Alternating Least Square</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.10">Bayesian Personalized Ranking</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.11">Logistic Matrix Factorization</span>.
The datasets come from a variety of domains, such as: Articles, Locations, Movies, Music and Socials. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4.T1" title="Table 1 ‣ 4.2. Algorithms and Datasets ‣ 4. Methodology ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">1</span></a> shows all datasets with information about the number of users, items, interactions and domain of the data.
The implicit feedback datasets are: <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.12">Globo</span> <cite class="ltx_cite ltx_citemacro_citep">(de Souza Pereira Moreira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib13" title="">2018</a>; Moreira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib29" title="">2019</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.13">Hetrec-Lastfm</span> <cite class="ltx_cite ltx_citemacro_citep">(Cantador et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib6" title="">2011</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.14">Nowplaying</span> <cite class="ltx_cite ltx_citemacro_citep">(Poddar, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib31" title="">2020</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.15">Retailrocket</span> <cite class="ltx_cite ltx_citemacro_citep">(Retailrocket, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib32" title="">2023</a>)</cite> and <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.16">Sketchfab</span> <cite class="ltx_cite ltx_citemacro_citep">(Rosenthal, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib35" title="">2017</a>)</cite>. The explicit feedback data sets are: <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.17">MovieLens-1M</span> <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib22" title="">2015</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.18">MovieLens-100k</span> <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib22" title="">2015</a>)</cite>, and <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.19">MovieTweetings</span> <cite class="ltx_cite ltx_citemacro_citep">(Dooms, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib14" title="">2021</a>)</cite>.
All of the mentioned datasets are five-core pruned, so that every user and item has at least five interactions <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib37" title="">2019</a>; Yue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib44" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#bib.bib45" title="">2022</a>)</cite>.
Five-core pruning is necessary to prevent cold start problems with our recommendation algorithms.
We convert the explicit datasets into implicit datasets by dropping the rating column.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Five-core pruned dataset statistics. Implicit datasets upper part, explicit datasets lower part.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.1">Name</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.2">#Interactions</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.3">#Users</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.4">#Items</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.5">Avg.#Int./User</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.6">Avg.#Int/Item</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.1.7">Sparsity</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.1.8">Domain</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.1">Globo</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.2">2,482,163</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.3">157,926</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.4">11,832</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.5">15.72</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.6">209.78</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.2.7">99.87%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.8">Articles</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.1">Hetrec-Lastfm</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.2">71,355</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.3">1,859</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.4">2,823</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.5">38.38</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.6">25.28</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.3.7">98.64%</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.3.3.8">Music</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.1">Nowplaying</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.2">2,447,318</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.3">64,392</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.4">95,277</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.5">38.01</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.6">25.69</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.4.7">99.96%</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.4.4.8">Music</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.1">Retailrocket</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.2">240,938</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.3">22,178</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.4">17,803</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.5">10.86</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.6">13.53</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.5.5.7">99.94%</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.8">Shopping</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.1">Sketchfab</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.2">547,477</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.3">25,655</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.4">15,274</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.5">21.34</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.6">35.84</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.6.6.7">99.86%</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.8">Social</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.1">MovieLens-100k</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.2">81,697</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.3">943</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.4">1,203</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.5">86.64</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.6">67.91</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.7.7">92.8%</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.7.7.8">Movies</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.1">MovieLens-1M</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.2">835,789</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.3">6,038</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.4">3,307</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.5">138.42</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.6">252.73</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.8.8.7">95.81%</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.8">Movies</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.1">MovieTweetings</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.2">563,309</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.3">20,643</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.4">8,810</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.5">27.29</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.6">63.94</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.9.9.7">99.69%</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.8">Movies</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S4.F2.g1" src="x2.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Normalized Histogram: number of interactions to number of users.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4.F2" title="Figure 2 ‣ 4.2. Algorithms and Datasets ‣ 4. Methodology ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">2</span></a> shows a normalized histogram of number of interactions with number of users as frequency over all datasets. Except for <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">Hetrec-lastfm</span>, the distribution of number of users shows a similar decrease for every dataset.
The distribution of number of users for <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">Hetrec-lastfm</span> grows with number of interactions, because <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.3">Hetrec-lastfm</span> has many users that have many interactions but a small number of users with small number of interactions. The distribution of number of users for <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.4">MovieLens-100k</span> and <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.5">MovieLens-1M</span> fluctuates for increasing number of interactions.
The distribution of number of users for <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.6">MovieTweetings</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.7">Sketchfab</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.8">Globo</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.9">Retailrocket</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.10">Nowplaying</span> decreases gradually for increasing number of interactions.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Experimental Pipeline</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We use four clustering approaches to create clusters on which the rest of the pipeline is executed (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S3" title="3. Cluster-based AutoRecSys ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">3</span></a>).
Depending on the clustering approach we have different number of attempts to find fitting clustering parameters.
<span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.1">Louvain</span> has the least attempts with five attempts for each dataset due to five resolution values.
Both <math alttext="k" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_k</annotation></semantics></math>-Means clustering approaches have seven attempts for each dataset.
<span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.2">Greedy Modularity</span> has 35 attempts due to each cluster count having five different resolutions.
We randomly split each cluster with five-fold cross validation resulting in 80% train and 20% test data. During the training stage <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.3">Lenskit-Auto</span> splits the 80% train data into 80% train and 20% validation data. If the training stage fails due to a lack of data, we lower the train split by 10% and increase the validation split by 10%.
The increasing and lowering of both splits is limited to a 50-50 split between train and validation split.
If the training still fails, we use <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.4">PopScore</span> as a fallback recommendation algorithm.
We optimize hyperparameters and train the given recommendation algorithms with <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.5">LensKit-Auto</span>. <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.6">LensKit-Auto</span> performs hyperparameter optimization using <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.7">Random Search</span>, which is limited to a search of 100 iterations. If the <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.8">Random Search</span> exceeds four hours, it terminates the search regardless of the iterations. We evaluate the recommendation algorithms performances using <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.9">nDCG@10</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.10">Precision@10</span>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.4">We structure our results in the following way. First, we present the performance of the baseline and the combined recommenders. For each clustering approach, we summarize the results in a line diagram. Each line represents a dataset and shows the <span class="ltx_text ltx_font_italic" id="S5.p1.4.1">nDCG@10</span> of the baseline and the combined recommenders.
We conduct our experiments for <span class="ltx_text ltx_font_italic" id="S5.p1.4.2">nDCG@10</span> and <span class="ltx_text ltx_font_italic" id="S5.p1.4.3">Precision@10</span>, but only show <span class="ltx_text ltx_font_italic" id="S5.p1.4.4">nDCG@10</span> since <span class="ltx_text ltx_font_italic" id="S5.p1.4.5">Precision@10</span> shows a similar trend. We round the <span class="ltx_text ltx_font_italic" id="S5.p1.4.6">nDCG@10</span> to three positions behind the decimal point. <math alttext="K" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">italic_K</annotation></semantics></math>-Means number of interactions and <math alttext="k" class="ltx_Math" display="inline" id="S5.p1.2.m2.1"><semantics id="S5.p1.2.m2.1a"><mi id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><ci id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.1d">italic_k</annotation></semantics></math>-Means item-interaction vector use the clustering parameter cluster count. <span class="ltx_text ltx_font_italic" id="S5.p1.4.7">Louvain</span> uses the clustering parameter resolution. <span class="ltx_text ltx_font_italic" id="S5.p1.4.8">Greedy Modularity</span> uses the clustering parameters cluster count and resolution, where for every cluster count the best performing cluster count over all resolution is selected. For <math alttext="k" class="ltx_Math" display="inline" id="S5.p1.3.m3.1"><semantics id="S5.p1.3.m3.1a"><mi id="S5.p1.3.m3.1.1" xref="S5.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.p1.3.m3.1b"><ci id="S5.p1.3.m3.1.1.cmml" xref="S5.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.p1.3.m3.1d">italic_k</annotation></semantics></math>-Means number of interactions, <math alttext="k" class="ltx_Math" display="inline" id="S5.p1.4.m4.1"><semantics id="S5.p1.4.m4.1a"><mi id="S5.p1.4.m4.1.1" xref="S5.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.p1.4.m4.1b"><ci id="S5.p1.4.m4.1.1.cmml" xref="S5.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.p1.4.m4.1d">italic_k</annotation></semantics></math>-Means item-interaction vector and <span class="ltx_text ltx_font_italic" id="S5.p1.4.9">Greedy Modularity</span> we plot cluster count on the x-axis. For <span class="ltx_text ltx_font_italic" id="S5.p1.4.10">Louvain</span> we plot resolution on the x-axis, as it generates a variable amount of clusters based on resolution. Second, we aggregate the performance of all combined recommenders over all clustering approaches. We obtain a maximum best combined recommender for each dataset.
Third, we present the most selected recommendation algorithms per clustering approaches.
Finally, we show the average parallel runtimes of our clustering approaches compared to the baseline (base).</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S5.F3.g1" src="x3.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span><math alttext="k" class="ltx_Math" display="inline" id="S5.F3.2.m1.1"><semantics id="S5.F3.2.m1.1b"><mi id="S5.F3.2.m1.1.1" xref="S5.F3.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><ci id="S5.F3.2.m1.1.1.cmml" xref="S5.F3.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.F3.2.m1.1e">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.F3.5.1">-Means number of interactions</span> with <span class="ltx_text ltx_font_italic" id="S5.F3.6.2">nDCG@10</span>.</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F3" title="Figure 3 ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">3</span></a>. <math alttext="k" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px1.1.m1.1"><semantics id="S5.SS0.SSS0.Px1.1.m1.1b"><mi id="S5.SS0.SSS0.Px1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.1.m1.1c"><ci id="S5.SS0.SSS0.Px1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px1.1.m1.1e">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.2.1">-Means number of interactions</span> with <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.3.2">nDCG@10</span>
</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.2"><math alttext="K" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S5.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px1.p1.1.m1.1d">italic_K</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.1">-Means number of interactions</span> increases the average <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.2">nDCG@10</span> over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.3">Nowplaying</span> by 63.07% (0.033). <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.4">Globo</span> has an on average decreasing <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.5">nDCG@10</span> of 2.24% (0.002), but the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.6">nDCG@10</span> increases by 6.02% (0.005) with three clusters.
For <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.7">Nowplaying</span>, <math alttext="k" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="S5.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="S5.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px1.p1.2.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.8">-Means number of interactions</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.9">nDCG@10</span> by up to 128.30% (0.068) with four clusters. <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.10">Nowplaying</span> has an increase in the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.11">nDCG@10</span> for every cluster count.
The <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.12">nDCG@10</span> of <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.13">Nowplaying</span> peaks at cluster counts four and seven, but has a plateau at five and six clusters.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.14">MovieTweetings</span> has the highest <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.15">nDCG@10</span> decrease out of all datasets. The <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.16">nDCG@10</span> decreases by 46.99% (0.078) on average over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.17">MovieTweetings</span>. With an increasing cluster count the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.18">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.19">MovieTweetings</span> decreases.
The decrease of 57.83% (0.096) is also the highest decrease out of all clustering approaches.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.20">MovieLens-100k</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.21">MovieLens-1M</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.22">Retailrocket</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.23">Hetrec-lastfm</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.24">Sketchfab</span> have a similar decrease in <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.2.25">nDCG@10</span>.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S5.F4.g1" src="x4.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span><math alttext="k" class="ltx_Math" display="inline" id="S5.F4.2.m1.1"><semantics id="S5.F4.2.m1.1b"><mi id="S5.F4.2.m1.1.1" xref="S5.F4.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F4.2.m1.1c"><ci id="S5.F4.2.m1.1.1.cmml" xref="S5.F4.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.F4.2.m1.1e">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.F4.5.1">-Means item-interaction vector</span> with <span class="ltx_text ltx_font_italic" id="S5.F4.6.2">nDCG@10</span>.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F4" title="Figure 4 ‣ Figure 3. 𝑘-Means number of interactions with nDCG@10 ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">4</span></a>. <math alttext="k" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px2.1.m1.1"><semantics id="S5.SS0.SSS0.Px2.1.m1.1b"><mi id="S5.SS0.SSS0.Px2.1.m1.1.1" xref="S5.SS0.SSS0.Px2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px2.1.m1.1c"><ci id="S5.SS0.SSS0.Px2.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px2.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px2.1.m1.1e">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.2.1">-Means item-interaction vector</span> with <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.3.2">nDCG@10</span>
</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.3"><math alttext="K" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S5.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S5.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px2.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px2.p1.1.m1.1d">italic_K</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.1">-Means item-interaction vector</span> increases the average <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.2">nDCG@10</span> over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.3">Sketchfab</span> by 11.61% (0.013), <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.4">Retailrocket</span> by 9.96% (0.006) and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.5">Nowplaying</span> by 244.20% (0.13).
For <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.6">Nowplaying</span>, <math alttext="k" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S5.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S5.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S5.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px2.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px2.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px2.p1.2.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.7">-Means item-interaction vector</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.8">nDCG@10</span> by up to 360.38% (0.191) with seven clusters. <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.9">Nowplaying</span> has an increase in the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.10">nDCG@10</span> for every cluster count. With an increasing cluster count the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.11">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.12">Nowplaying</span> increases for two to seven clusters.
<math alttext="K" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S5.SS0.SSS0.Px2.p1.3.m3.1a"><mi id="S5.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S5.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px2.p1.3.m3.1b"><ci id="S5.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S5.SS0.SSS0.Px2.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px2.p1.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px2.p1.3.m3.1d">italic_K</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.13">-Means item-interaction vector</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.14">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.15">Sketchfab</span> by 75.00% (0.084) with two clusters, and by 55.36% (0.062) with three clusters. From four to eight clusters the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.16">nDCG@10</span> decreases for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.17">Sketchfab</span>.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.18">MovieTweetings</span> has the highest <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.19">nDCG@10</span> decrease out of all datasets. The <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.20">nDCG@10</span> decreases by 54.58% (0.091) on average over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.21">MovieTweetings</span>. With an increasing cluster count the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.22">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.3.23">MovieTweetings</span> decreases.</p>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S5.F5.g1" src="x5.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span><span class="ltx_text ltx_font_italic" id="S5.F5.3.1">Louvain</span> with <span class="ltx_text ltx_font_italic" id="S5.F5.4.2">nDCG@10</span>.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Number of clusters for every resolution of <span class="ltx_text ltx_font_italic" id="S5.T2.2.1">Louvain</span>.</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T2.3.1.1.1">dataset</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.3.1.1.2">0.8</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.3.1.1.3">0.9</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.3.1.1.4">1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.3.1.1.5">1.1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.3.1.1.6">1.2</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.3.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.3.2.1.1">Globo</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.3.2.1.2">7</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.3.2.1.3">8</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.3.2.1.4">9</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.3.2.1.5">11</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.3.2.1.6">16</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.3.2.1">Hetrec-lastfm</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.3.2.2">6</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.3.2.3">7</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.3.2.4">8</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.3.2.5">8</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.3.2.6">8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.4.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.4.3.1">Nowplaying</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.4.3.2">10</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.4.3.3">11</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.4.3.4">14</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.4.3.5">16</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.4.3.6">14</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.5.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.5.4.1">Retailrocket</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.5.4.2">20</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.5.4.3">20</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.5.4.4">25</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.5.4.5">26</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.5.4.6">29</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.6.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.6.5.1">Sketchfab</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.6.5.2">22</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.6.5.3">25</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.6.5.4">22</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.6.5.5">27</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.6.5.6">24</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.7.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.7.6.1">MovieLens-100k</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.7.6.2">3</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.7.6.3">3</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.7.6.4">4</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.7.6.5">5</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.7.6.6">6</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.8.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.8.7.1">MovieLens-1M</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.8.7.2">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.8.7.3">3</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.8.7.4">5</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.8.7.5">6</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.8.7.6">8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.9.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.3.9.8.1">MovieTweetings</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.9.8.2">4</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.9.8.3">5</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.9.8.4">6</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.9.8.5">6</td>
<td class="ltx_td ltx_align_left" id="S5.T2.3.9.8.6">8</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F5" title="Figure 5 ‣ Figure 4. 𝑘-Means item-interaction vector with nDCG@10 ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">5</span></a>. Louvain with <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.1.1">nDCG@10</span>
</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1"><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.1">Louvain</span> uses resolution as the clustering parameter and generates a varying number of clusters. The datasets <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.2">MovieLens-100k</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.3">MovieLens-1M</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.4">Hetrec-lastfm</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.5">MovieTweetings</span> are split into a range of three to eight clusters. The datasets <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.6">Sketchfab</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.7">Globo</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.8">Retailrocket</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.9">Nowplaying</span> are split into seven to 29 clusters (see Table <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.T2" title="Table 2 ‣ Figure 4. 𝑘-Means item-interaction vector with nDCG@10 ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">2</span></a>).
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.10">Louvain</span> increases the average <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.11">nDCG@10</span> over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.12">MovieLens-100k</span> by 1.58% (0.006), <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.13">Retailrocket</span> by 27.27% (0.018), <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.14">Sketchfab</span> by 10.00% (0.011), <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.15">Globo</span> by 20.96% (0.018) and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.16">Nowplaying</span> by 122.64% (0.065).
For <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.17">Nowplaying</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.18">Louvain</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.19">nDCG@10</span> by up to 141.51% (0.075) with eleven clusters (0.9 resolution). <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.20">Nowplaying</span> has an increase in the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.21">nDCG@10</span> for every cluster count. The datasets that show the most increase are the datasets with a low <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.22">nDCG@10</span> for the baseline.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.23">Louvain</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.24">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.25">Globo</span> by an average of 16.57% (0.014) with seven to eleven clusters (0.8 to 1.1 resolution), and by 38.55% (0.032) with 16 clusters (1.2 resolution).
Out of all datasets, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.26">Hetrec-lastfm</span> has the highest average <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.27">nDCG@10</span> decrease with 8.86% (0.018) over all cluster counts.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.28">Hetrec-lastfm</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.29">MovieLens-1m</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.30">MovieTweetings</span> have a similar decrease in <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.31">nDCG@10</span>.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S5.F6.g1" src="x6.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span><span class="ltx_text ltx_font_italic" id="S5.F6.3.1">Greedy Modularity</span> with <span class="ltx_text ltx_font_italic" id="S5.F6.4.2">nDCG@10</span>.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F6" title="Figure 6 ‣ Figure 5. Louvain with nDCG@10 ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">6</span></a>. <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.1.1">Greedy Modularity</span> with <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.2.2">nDCG@10</span>
</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px4.p1.1"><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.1">Greedy Modularity</span> creates a maximum of five clusters for MovieLens-100k and a maximum of seven clusters for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.2">Hetrec-lastfm</span>. <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.3">Globo</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.4">Nowplaying</span> hit the time limit of six hours for the clustering stage, therefore <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.5">Globo</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.6">Nowplaying</span> do not have results for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.7">Greedy Modularity</span>.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.8">Greedy Modularity</span> increases the average <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.9">nDCG@10</span> over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.10">Sketchfab</span> by 48.34% (0.054) and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.11">Retailrocket</span> by 13.42% (0.009).
For <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.12">Sketchfab</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.13">Greedy Modularity</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.14">nDCG@10</span> by up to 72.32% (0.08) with four clusters. <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.15">Sketchfab</span> has an increase in the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.16">nDCG@10</span> for every cluster count. With an increasing cluster count the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.17">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.18">Sketchfab</span> increases for two to four clusters. For a cluster count of five to eight clusters the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.19">nDCG@10</span> increases on average by 42.41% (0.047).
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.20">Greedy Modularity</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.21">nDCG@10</span> for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.22">MovieTweetings</span> on average by 17.83% (0.029) with two to six clusters. From seven to eight clusters the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.23">nDCG@10</span> decreases for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.24">MovieTweetings</span>.
For <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.25">MovieLens-100k</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.26">Greedy Modularity</span> increases the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.27">nDCG@10</span> by 4.10% (0.016) with two clusters. From three to five clusters the <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.28">nDCG@10</span> decreases for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.29">MovieLens-100k</span>.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.30">Hetrec-lastfm</span> has the highest <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.31">nDCG@10</span> decrease out of all datasets. The <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.32">nDCG@10</span> decreases by 4.52% (0.038) on average over all cluster counts for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.33">Hetrec-lastfm</span>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Maximum Best Combined Recommender</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px5.p1.2"><math alttext="K" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px5.p1.1.m1.1"><semantics id="S5.SS0.SSS0.Px5.p1.1.m1.1a"><mi id="S5.SS0.SSS0.Px5.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px5.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px5.p1.1.m1.1b"><ci id="S5.SS0.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px5.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px5.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px5.p1.1.m1.1d">italic_K</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.1">-means number of interactions</span> is the best clustering approach for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.2">MovieLens-1M</span>, but provides no increase (0.00) in maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.3">nDCG@10</span>.
<math alttext="K" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px5.p1.2.m2.1"><semantics id="S5.SS0.SSS0.Px5.p1.2.m2.1a"><mi id="S5.SS0.SSS0.Px5.p1.2.m2.1.1" xref="S5.SS0.SSS0.Px5.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px5.p1.2.m2.1b"><ci id="S5.SS0.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px5.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px5.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px5.p1.2.m2.1d">italic_K</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.4">-means item interaction vector</span> is the best clustering approach for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.5">Sketchfab</span> with a maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.6">nDCG@10</span> increase of 75% (0.084) and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.7">Nowplaying</span> with a maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.8">nDCG@10</span> increase of 360% (0.191).
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.9">Louvain</span> is the best clustering approach for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.10">Retailrocket</span> with a maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.11">nDCG@10</span> increase of 36.36% (0.024) and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.12">Globo</span> with a maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.13">nDCG@10</span> increase of 38.55% (0.032).
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.14">Greedy Modularity</span> is the best clustering approach for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.15">Hetrec-lastfm</span> with a minimum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.16">nDCG@10</span> decrease of 1.90% (0.003), <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.17">MovieLens-100k</span> with a maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.18">nDCG@10</span> increase of 4.10% (0.016) and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.19">MovieTweetings</span> with a maximum <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.20">nDCG@10</span> increase of 19.28% (0.032).
We aggregate the maximum increases of our clustering approaches which results in an average <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p1.2.21">nDCG@10</span> increase of 66.47% across all datasets.</p>
</div>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S5.F7.g1" src="x7.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Parallel runtime of clustering approaches and baseline.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S5.SS0.SSS0.Px5.p2.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F7" title="Figure 7 ‣ Maximum Best Combined Recommender ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">7</span></a> we can see the average parallel runtime of all clustering approaches and the baseline over the stages cluster, fit and predict.
The baseline recommends over the whole dataset without the use of clusters.
The parallel runtime is the maximum runtime of a clustering approach in a given stage.
We then average the parallel runtime over all datasets, excluding <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p2.1.1">Globo</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p2.1.2">Nowplaying</span>, as these two datasets hit the time limit of six hours for the clustering stage.
The biggest differences for the runtime are in the cluster and fit stage.
For the cluster stage only <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p2.1.3">Greedy Modularity</span> shows a long runtime.
For the fit stage the baseline has the longest runtime.
<math alttext="K" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px5.p2.1.m1.1"><semantics id="S5.SS0.SSS0.Px5.p2.1.m1.1a"><mi id="S5.SS0.SSS0.Px5.p2.1.m1.1.1" xref="S5.SS0.SSS0.Px5.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px5.p2.1.m1.1b"><ci id="S5.SS0.SSS0.Px5.p2.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px5.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px5.p2.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px5.p2.1.m1.1d">italic_K</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p2.1.4">-means number of interactions</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p2.1.5">Greedy Modularity</span> have a similar parallel runtime on average.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p2.1.6">Louvain</span> is the clustering approach with fastest runtime overall.
In total, every clustering approach has a faster runtime than the baseline.</p>
</div>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S5.F8.g1" src="x8.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>Best performing recommendation algorithm per clustering approach.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS0.SSS0.Px5.p3">
<p class="ltx_p" id="S5.SS0.SSS0.Px5.p3.2">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F8" title="Figure 8 ‣ Maximum Best Combined Recommender ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">8</span></a> represents how many times a recommendation algorithm has the best <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.1">nDCG@10</span> on each cluster per clustering approach.
The top three best performing recommendation algorithm are <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.2">User-User Nearest Neighbour</span>, <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.3">Item-Item Nearest Neighbour</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.4">Implicit Matrix Factorization</span>.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.5">User-User Nearest Neighbour</span> performs best for <math alttext="k" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px5.p3.1.m1.1"><semantics id="S5.SS0.SSS0.Px5.p3.1.m1.1a"><mi id="S5.SS0.SSS0.Px5.p3.1.m1.1.1" xref="S5.SS0.SSS0.Px5.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px5.p3.1.m1.1b"><ci id="S5.SS0.SSS0.Px5.p3.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px5.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px5.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px5.p3.1.m1.1d">italic_k</annotation></semantics></math>-Means item interaction vector with 50.71%, <math alttext="k" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px5.p3.2.m2.1"><semantics id="S5.SS0.SSS0.Px5.p3.2.m2.1a"><mi id="S5.SS0.SSS0.Px5.p3.2.m2.1.1" xref="S5.SS0.SSS0.Px5.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px5.p3.2.m2.1b"><ci id="S5.SS0.SSS0.Px5.p3.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px5.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px5.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS0.SSS0.Px5.p3.2.m2.1d">italic_k</annotation></semantics></math>-Mean number of interactions with 37.14% and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.6">Greedy Modularity</span> with 36.19%.
<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.7">Item-Item Nearest Neighbour</span> performs best for <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.8">Louvain</span> with 31.05%.
For every clustering approach a different recommendation algorithm performs best on the clusters.
The worst performing algorithms across all clusters are <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.9">Random</span> and <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.10">PopScore</span>. <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px5.p3.2.11">PopScore</span> never performs best for any cluster.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In our results, we see that all clustering approaches have a positive influence on different datasets, except for <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">Hetrec-lastfm</span>. Due to the unique distribution of <span class="ltx_text ltx_font_italic" id="S6.p1.1.2">Hetrec-lastfm</span>, we decide to exclude <span class="ltx_text ltx_font_italic" id="S6.p1.1.3">Hetrec-lastfm</span> from further discussions. All clustering approaches occur in the maximum best combined recommender. Therefore, the cluster-based algorithm selection problem cannot be solved with a single clustering approach. We conclude that we must select the optimal clustering approach to obtain the maximum best combined recommender for each dataset. We call the problem of selecting the optimal clustering approach <span class="ltx_text ltx_font_italic" id="S6.p1.1.4">clustering selection problem</span>.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.2">Our results suggest that <math alttext="k" class="ltx_Math" display="inline" id="S6.p2.1.m1.1"><semantics id="S6.p2.1.m1.1a"><mi id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><ci id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.p2.1.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S6.p2.2.1">-Means number of interactions</span> increases the recommendation performance for datasets fulfilling two criteria. First, the dataset contains significantly more items than users. Second, a significant portion of users share about the same number of interactions. We find that <math alttext="k" class="ltx_Math" display="inline" id="S6.p2.2.m2.1"><semantics id="S6.p2.2.m2.1a"><mi id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><ci id="S6.p2.2.m2.1.1.cmml" xref="S6.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.p2.2.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S6.p2.2.2">-Means number of interactions</span> increases the average <span class="ltx_text ltx_font_italic" id="S6.p2.2.3">nDCG@10</span> across all cluster counts for <span class="ltx_text ltx_font_italic" id="S6.p2.2.4">Nowplaying</span> by 63.07% (0.034). <span class="ltx_text ltx_font_italic" id="S6.p2.2.5">Nowplaying</span> has 47.96% more items than users, and 38.01 average interactions per user (see Table <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S4.T1" title="Table 1 ‣ 4.2. Algorithms and Datasets ‣ 4. Methodology ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">1</span></a>). The generated clusters separate the users that have differing number of interactions from the majority of users with a similar number of interactions. Selecting recommendation algorithms for these clusters results in the measured increase in recommendation performance.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">All clustering approaches we measure for <span class="ltx_text ltx_font_italic" id="S6.p3.1.1">Nowplaying</span> increase the recommendation performance regardless of cluster count and resolution. A reason for <span class="ltx_text ltx_font_italic" id="S6.p3.1.2">Nowplaying</span> to benefit from all clustering approaches can be the sheer number of users and items and average number of interactions of 38.01 per user. Additionally, <span class="ltx_text ltx_font_italic" id="S6.p3.1.3">Nowplaying</span> contains 47.96% more items than users. We assume that clustering in general has a positive influence for large datasets.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">The smallest recommendation performance increases are on <span class="ltx_text ltx_font_italic" id="S6.p4.1.1">MovieLens-1m</span>, <span class="ltx_text ltx_font_italic" id="S6.p4.1.2">MovieLens-100k</span> and <span class="ltx_text ltx_font_italic" id="S6.p4.1.3">MovieTweetings</span>. These three datasets are the only explicit feedback datasets. We convert the explicit feedback into implicit feedback by counting every rating as an interaction. This conversion could distort the meta-information used by our clustering approaches. For example, user A with ten 5 star ratings and user B with ten 1 star ratings are both converted into users with ten interactions. Our clustering approaches would cluster user A and B into the same cluster, although their interactions are different.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1"><span class="ltx_text ltx_font_italic" id="S6.p5.1.1">MovieLens-1m</span> and <span class="ltx_text ltx_font_italic" id="S6.p5.1.2">MovieLens-100k</span> have a minimum number of 20 interactions per user, and not a minimum number of five interactions per user like the other datasets. A different threshold for pruning can decrease the influence of clustering. A big portion of users, on which clustering could improve recommendation performance, is missing. The big portion of missing users presents a missed opportunity for clustering to separate users.
Additionally, clustering can only increase the performance of recommendation algorithms when the clusters use different best recommendation algorithms. If the same recommendation algorithm is used for all clusters, the performance remains the same at best. For example, <span class="ltx_text ltx_font_italic" id="S6.p5.1.3">User-User Nearest Neighbour</span> is the single best recommendation algorithm and is selected for most clusters across all clustering approaches for <span class="ltx_text ltx_font_italic" id="S6.p5.1.4">MovieLens-1m</span>.</p>
</div>
<div class="ltx_para" id="S6.p6">
<p class="ltx_p" id="S6.p6.1"><span class="ltx_text ltx_font_italic" id="S6.p6.1.1">Random</span> algorithm is unexpectedly selected in 0.71% (2) of cases for <math alttext="k" class="ltx_Math" display="inline" id="S6.p6.1.m1.1"><semantics id="S6.p6.1.m1.1a"><mi id="S6.p6.1.m1.1.1" xref="S6.p6.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.p6.1.m1.1b"><ci id="S6.p6.1.m1.1.1.cmml" xref="S6.p6.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.p6.1.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S6.p6.1.2">-Means item interaction vector</span> and in 0.36% (3) of cases for <span class="ltx_text ltx_font_italic" id="S6.p6.1.3">Greedy Modularity</span> (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F8" title="Figure 8 ‣ Maximum Best Combined Recommender ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">8</span></a>). Without clustering, the random algorithm has an average <span class="ltx_text ltx_font_italic" id="S6.p6.1.4">nDCG@10</span> of 0.003, which is always below every other recommendation algorithm. The reason for the unexpected recommendation performance of the <span class="ltx_text ltx_font_italic" id="S6.p6.1.5">Random</span> algorithm is that clustering can result in clusters with few users who have many interactions. For those few users the <span class="ltx_text ltx_font_italic" id="S6.p6.1.6">Random</span> recommendation algorithm can recommend the correct items by pure chance. Therefore, <span class="ltx_text ltx_font_italic" id="S6.p6.1.7">Random</span> recommendation algorithm is in five cases the best.</p>
</div>
<div class="ltx_para" id="S6.p7">
<p class="ltx_p" id="S6.p7.1">We see multiple reasons for <span class="ltx_text ltx_font_italic" id="S6.p7.1.1">Louvain</span> being the best clustering approach. <span class="ltx_text ltx_font_italic" id="S6.p7.1.2">Louvain</span> is the overall best clustering approach increasing the recommendation performance on six out of eight datasets. <span class="ltx_text ltx_font_italic" id="S6.p7.1.3">Louvain</span> scales well for larger datasets, because <span class="ltx_text ltx_font_italic" id="S6.p7.1.4">Louvain</span> performs clustering based on resolution resulting in a variable cluster count. <span class="ltx_text ltx_font_italic" id="S6.p7.1.5">Louvain</span> already performs well with default resolution increasing the <span class="ltx_text ltx_font_italic" id="S6.p7.1.6">nDCG@10</span> on average by 19.95% across all datasets. <span class="ltx_text ltx_font_italic" id="S6.p7.1.7">Louvain</span> has on average the smallest parallel runtime among all clustering approaches.</p>
</div>
<div class="ltx_para" id="S6.p8">
<p class="ltx_p" id="S6.p8.1">Clustering can improve hyperparameter optimization. For large datasets, the recommendation algorithms have a long runtime and may not complete all 100 iterations of random search hitting the time limit. Clusters are smaller and recommendation algorithms can run up to 100 iterations of random search and therefore can find better hyperparameters, resulting in better recommendation performance. However, smaller clusters do not guarantee a performance increase. Otherwise our combined recommenders regardless of the clustering approach should increase the recommendation performance. The choice of clustering approach is the decisive factor.</p>
</div>
<div class="ltx_para" id="S6.p9">
<p class="ltx_p" id="S6.p9.1">Clustering speeds up the parallel runtime of hyperparameter optimization (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F7" title="Figure 7 ‣ Maximum Best Combined Recommender ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">7</span></a>). The parallel runtime is the maximum runtime of the hyperparameter optimization of all clusters. Due to clustering, we have less users to optimize for in each optimization. While the number of runs increases by one for each cluster, each run is fully parallelizable.
If we parallelize every stage our total parallel runtime is always smaller than the baseline (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.18011v1#S5.F7" title="Figure 7 ‣ Maximum Best Combined Recommender ‣ 5. Results ‣ Rethinking Recommender Systems: Cluster-based Algorithm Selection"><span class="ltx_text ltx_ref_tag">7</span></a>). Due to clustering we see a considerable decrease in parallel runtime for the fit stage. The decrease of parallel runtime can be accounted to less users in a cluster which need to be fit. During the fit stage, <span class="ltx_text ltx_font_italic" id="S6.p9.1.1">Greedy Modularity</span> has an average parallel runtime compared to the other clustering approaches. However, <span class="ltx_text ltx_font_italic" id="S6.p9.1.2">Greedy Modularity</span> is the only clustering approach with a noticeable parallel runtime for the cluster stage. Summing up the parallel runtime of the cluster and fit stage, <span class="ltx_text ltx_font_italic" id="S6.p9.1.3">Greedy Modularity</span> is the clustering approach with the longest parallel runtime.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In our research question we ask how clustering influences the performance of recommendation algorithms. We demonstrate that cluster-based algorithm selection can yield significantly better results than algorithm selection without clustering. For five out of eight datasets we see a drastic increase in <span class="ltx_text ltx_font_italic" id="S7.p1.1.1">nDCG@10</span> that ranges between 19.28% (0.032) and 360.38% (0.191). We demonstrate that clustering is an effective technique for optimizing recommendation algorithm performance. For <span class="ltx_text ltx_font_italic" id="S7.p1.1.2">MovieLens-100k</span> and <span class="ltx_text ltx_font_italic" id="S7.p1.1.3">MovieLens-1m</span> the single best recommender is at the same time the best choice for most clusters resulting in performance increases of 4.10% (0.016) and 0.00% with clustering. We might see an increase for a larger selection of recommendation algorithms.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">We derive the clustering selection problem as the problem of selecting the optimal clustering approach that yields an increase in performance for a given dataset. Our work shows, there is no single best clustering approach that fits all datasets. We suggest to test a wide variety of clustering approaches and recommendation algorithms.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Clustering has been overlooked as a valid approach to increase performance of recommendation algorithms. We hope that our work changes the perception of the community on clustering for recommender systems. As seen in our experiments, we confirm that certain combinations of datasets, clustering approaches and recommendation algorithms show no performance increase. We identified a downward trend and plateauing for over half of our combinations. This appears to be in line with related work. However, as seen with the maximum best combined recommender, we only need to find a single combination to drastically improve performance.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Future Work and Limitations</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">Future work could consider more clustering approaches and meta-information to further improve cluster-based algorithm selection.
In our work, we use four clustering approaches. Each clustering approach considers one specific meta-information derived from the datasets, e.g. number of interactions, even though the datasets may contain additional meta-information for the clustering approaches. We do not know which meta-information enables our clustering approaches to increase recommendation performance. The lack of performance increasing meta-information limits the capabilities of our clustering approaches to perform cluster-based algorithm selection.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">Future work should further analyze the structure of the datasets and the relation of the structure to the resulting recommendation performance. We hope the analysis of the dataset structure provides insights to better select the best clustering approach and even clustering parameters for the datasets.
The datasets we use in our work vary in structure such as number of users, number of items, number of interactions, sparsity, etc. Cluster-based algorithm selection uses parts of the structural meta-information to increase recommendation performance. The recommendation performances achieved by our clustering approaches varies drastically across different datasets. We can not find a conclusive connection between the structural meta-information and the recommendation performances achieved by our clustering approaches yet.</p>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">Future work could research the correlation between clustering-quality measures, e.g. silhouette score, and the recommendation performance of the maximum best combined recommender to reduce training overhead.
We currently determine the influence of clustering on the recommendation performance after training and predicting. To determine the influence of clustering on the recommendation performance, we train recommendation algorithms on each cluster for each set of clusters. We use the recommendation performance of the combined recommenders on each set of clusters to select the maximum best combined recommender. This ”trial and error” method leads to a lot of trained recommendation algorithms which will never be used. Knowing which clustering approach and parameters perform well before training and predicting saves a lot of time. We require additional metrics to estimate the resulting recommendation performance of the clustering approach and clustering parameters before training.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We thank Tobias Vente for supervising our work.
The results reported in this research were computed using the OMNI cluster of the University of Siegen.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beel et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Joeran Beel, Corinna Breitinger, Stefan Langer, Andreas Lommatzsch, and Bela Gipp. 2016.

</span>
<span class="ltx_bibblock">Towards reproducibility in recommender-systems research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">User Modeling and User-Adapted Interaction</em> 26, 1 (mar 2016), 69–101.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s11257-016-9174-x" title="">https://doi.org/10.1007/s11257-016-9174-x</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beel and Brunel (2019)</span>
<span class="ltx_bibblock">
Joeran Beel and Victor Brunel. 2019.

</span>
<span class="ltx_bibblock">Data pruning in recommender systems research: Best-practice or malpractice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">ACM RecSys</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellogin and Parapar (2012)</span>
<span class="ltx_bibblock">
Alejandro Bellogin and Javier Parapar. 2012.

</span>
<span class="ltx_bibblock">Using graph partitioning techniques for neighbour selection in user-based collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the Sixth ACM Conference on Recommender Systems</em> (Dublin, Ireland) <em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2">(RecSys ’12)</em>. Association for Computing Machinery, New York, NY, USA, 213–216.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2365952.2365997" title="">https://doi.org/10.1145/2365952.2365997</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blondel et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2008)</span>
<span class="ltx_bibblock">
Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008.

</span>
<span class="ltx_bibblock">Fast unfolding of communities in large networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Journal of Statistical Mechanics: Theory and Experiment</em> 2008, 10 (oct 2008), P10008.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1088/1742-5468/2008/10/P10008" title="">https://doi.org/10.1088/1742-5468/2008/10/P10008</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cantador et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Ivan Cantador, Peter Brusilovsky, and Tsvi Kuflik. 2011.

</span>
<span class="ltx_bibblock">Second workshop on information heterogeneity and fusion in recommender systems (HetRec2011). In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proceedings of the Fifth ACM Conference on Recommender Systems</em> (Chicago, Illinois, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib6.4.2">(RecSys ’11)</em>. Association for Computing Machinery, New York, NY, USA, 387–388.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2043932.2044016" title="">https://doi.org/10.1145/2043932.2044016</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clauset et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2004)</span>
<span class="ltx_bibblock">
Aaron Clauset, M. E. J. Newman, and Cristopher Moore. 2004.

</span>
<span class="ltx_bibblock">Finding community structure in very large networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Phys. Rev. E</em> 70 (Dec 2004), 066111.

</span>
<span class="ltx_bibblock">Issue 6.

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1103/PhysRevE.70.066111" title="">https://doi.org/10.1103/PhysRevE.70.066111</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Collins, Dominika Tkaczyk, and Joeran Beel. 2018.

</span>
<span class="ltx_bibblock">A Novel Approach to Recommendation Algorithm Selection using Meta-Learning.. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">AICS</em>. 210–219.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2016.

</span>
<span class="ltx_bibblock">Selecting Collaborative Filtering Algorithms Using Metalearning. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Machine Learning and Knowledge Discovery in Databases</em>, Paolo Frasconi, Niels Landwehr, Giuseppe Manco, and Jilles Vreeken (Eds.). Springer International Publishing, Cham, 393–409.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2018.

</span>
<span class="ltx_bibblock">CF4CF: recommending collaborative filtering algorithms using collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of the 12th ACM Conference on Recommender Systems</em> (Vancouver, British Columbia, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib10.4.2">(RecSys ’18)</em>. Association for Computing Machinery, New York, NY, USA, 357–361.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3240323.3240378" title="">https://doi.org/10.1145/3240323.3240378</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Da Costa and Manzato (2014)</span>
<span class="ltx_bibblock">
Arthur F. Da Costa and Marcelo Garcia Manzato. 2014.

</span>
<span class="ltx_bibblock">Multimodal Interactions in Recommender Systems: An Ensembling Approach. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">2014 Brazilian Conference on Intelligent Systems</em>. 67–72.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/BRACIS.2014.23" title="">https://doi.org/10.1109/BRACIS.2014.23</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">da Costa Fortes and Manzato (2014)</span>
<span class="ltx_bibblock">
Arthur da Costa Fortes and Marcelo Garcia Manzato. 2014.

</span>
<span class="ltx_bibblock">Ensemble Learning in Recommender Systems: Combining Multiple User Interactions for Ranking Personalization. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 20th Brazilian Symposium on Multimedia and the Web</em> (João Pessoa, Brazil) <em class="ltx_emph ltx_font_italic" id="bib.bib12.2.2">(WebMedia ’14)</em>. Association for Computing Machinery, New York, NY, USA, 47–54.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2664551.2664556" title="">https://doi.org/10.1145/2664551.2664556</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Souza Pereira Moreira et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Gabriel de Souza Pereira Moreira, Felipe Ferreira, and Adilson Marques da Cunha. 2018.

</span>
<span class="ltx_bibblock">News Session-Based Recommendations using Deep Neural Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Proceedings of the 3rd Workshop on Deep Learning for Recommender Systems</em> (Vancouver, BC, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib13.4.2">(DLRS 2018)</em>. Association for Computing Machinery, New York, NY, USA, 15–23.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3270323.3270328" title="">https://doi.org/10.1145/3270323.3270328</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dooms (2021)</span>
<span class="ltx_bibblock">
Simon Dooms. 2021.

</span>
<span class="ltx_bibblock">A Live Movie Rating Dataset Collected From Twitter.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sidooms/MovieTweetings" title="">https://github.com/sidooms/MovieTweetings</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edenhofer et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Gordian Edenhofer, Andrew Collins, Akiko Aizawa, and Joeran Beel. 2019.

</span>
<span class="ltx_bibblock">Augmenting the DonorsChoose. org Corpus for Meta-Learning.. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">AMIR@ ECIR</em>. 32–38.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand and Riedl (2012)</span>
<span class="ltx_bibblock">
Michael Ekstrand and John Riedl. 2012.

</span>
<span class="ltx_bibblock">When recommenders fail: predicting recommender failure for algorithm selection and combination. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the Sixth ACM Conference on Recommender Systems</em> (Dublin, Ireland) <em class="ltx_emph ltx_font_italic" id="bib.bib16.2.2">(RecSys ’12)</em>. Association for Computing Machinery, New York, NY, USA, 233–236.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2365952.2366002" title="">https://doi.org/10.1145/2365952.2366002</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand (2020)</span>
<span class="ltx_bibblock">
Michael D. Ekstrand. 2020.

</span>
<span class="ltx_bibblock">LensKit for Python: Next-Generation Software for Recommender Systems Experiments. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em> (Virtual Event, Ireland) <em class="ltx_emph ltx_font_italic" id="bib.bib17.2.2">(CIKM ’20)</em>. Association for Computing Machinery, New York, NY, USA, 2999–3006.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3340531.3412778" title="">https://doi.org/10.1145/3340531.3412778</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Forouzandeh et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Saman Forouzandeh, Kamal Berahmand, and Mehrdad Rostami. 2021.

</span>
<span class="ltx_bibblock">Presentation of a recommender system with ensemble learning and graph embedding: a case on MovieLens.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Multimedia Tools and Applications</em> 80, 5 (2021), 7805–7832.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s11042-020-09949-5" title="">https://doi.org/10.1007/s11042-020-09949-5</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frederickson (2023)</span>
<span class="ltx_bibblock">
Ben Frederickson. 2023.

</span>
<span class="ltx_bibblock">Fast Python Collaborative Filtering for Implicit Feedback Datasets.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/benfred/implicit" title="">https://github.com/benfred/implicit</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Guibing Guo, Jie Zhang, and Neil Yorke-Smith. 2015.

</span>
<span class="ltx_bibblock">Leveraging multiviews of trust and similarity to enhance clustering-based recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Knowledge-Based Systems</em> 74 (2015), 14–27.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.knosys.2014.10.016" title="">https://doi.org/10.1016/j.knosys.2014.10.016</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, and Qing He. 2022.

</span>
<span class="ltx_bibblock">A Survey on Knowledge Graph-Based Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">IEEE Transactions on Knowledge and Data Engineering</em> 34, 8 (Aug 2022), 3549–3568.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TKDE.2020.3028705" title="">https://doi.org/10.1109/TKDE.2020.3028705</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F. Maxwell Harper and Joseph A. Konstan. 2015.

</span>
<span class="ltx_bibblock">The MovieLens Datasets: History and Context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ACM Trans. Interact. Intell. Syst.</em> 5, 4, Article 19 (dec 2015), 19 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2827872" title="">https://doi.org/10.1145/2827872</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jahrer et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Michael Jahrer, Andreas Töscher, and Robert Legenstein. 2010.

</span>
<span class="ltx_bibblock">Combining predictions for accurate recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (Washington, DC, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib23.4.2">(KDD ’10)</em>. Association for Computing Machinery, New York, NY, USA, 693–702.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1835804.1835893" title="">https://doi.org/10.1145/1835804.1835893</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jalili et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Mahdi Jalili, Sajad Ahmadian, Maliheh Izadi, Parham Moradi, and Mostafa Salehi. 2018.

</span>
<span class="ltx_bibblock">Evaluating Collaborative Filtering Recommender Algorithms: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">IEEE Access</em> 6 (2018), 74003–74024.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2018.2883742" title="">https://doi.org/10.1109/ACCESS.2018.2883742</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Kim (2003)</span>
<span class="ltx_bibblock">
Qing Li and Byeong Man Kim. 2003.

</span>
<span class="ltx_bibblock">Clustering approach for hybrid recommender system. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003)</em>. 33–38.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/WI.2003.1241167" title="">https://doi.org/10.1109/WI.2003.1241167</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MacQueen et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (1967)</span>
<span class="ltx_bibblock">
James MacQueen et al<span class="ltx_text" id="bib.bib26.3.1">.</span> 1967.

</span>
<span class="ltx_bibblock">Some methods for classification and analysis of multivariate observations. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.4.1">Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</em>, Vol. 1. Oakland, CA, USA, 281–297.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Matuszyk and Spiliopoulou (2014)</span>
<span class="ltx_bibblock">
Pawel Matuszyk and Myra Spiliopoulou. 2014.

</span>
<span class="ltx_bibblock">Predicting the Performance of Collaborative Filtering Algorithms. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 4th International Conference on Web Intelligence, Mining and Semantics (WIMS14)</em> (Thessaloniki, Greece) <em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2">(WIMS ’14)</em>. Association for Computing Machinery, New York, NY, USA, Article 38, 6 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2611040.2611054" title="">https://doi.org/10.1145/2611040.2611054</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meltsov (2019)</span>
<span class="ltx_bibblock">
Vasily Meltsov. 2019.

</span>
<span class="ltx_bibblock">Utilizing Metadata to Select a Recommendation Algorithm for a User or an Item.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moreira et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Gabriel De Souza P. Moreira, Dietmar Jannach, and Adilson Marques Da Cunha. 2019.

</span>
<span class="ltx_bibblock">Contextual Hybrid Session-Based News Recommendation With Recurrent Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">IEEE Access</em> 7 (2019), 169185–169203.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2019.2954957" title="">https://doi.org/10.1109/ACCESS.2019.2954957</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">netflix.com (2023)</span>
<span class="ltx_bibblock">
netflix.com. 2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">What We Watched: A Netflix Engagement Report</em>.

</span>
<span class="ltx_bibblock">
Retrieved March 19, 2024 from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report" title="">https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poddar (2020)</span>
<span class="ltx_bibblock">
Asmita Poddar. 2020.

</span>
<span class="ltx_bibblock">nowplaying-RS: Music Recommendation using Factorization Machines.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/asmitapoddar/nowplaying-RS-Music-Reco-FM" title="">https://github.com/asmitapoddar/nowplaying-RS-Music-Reco-FM</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Retailrocket (2023)</span>
<span class="ltx_bibblock">
Retailrocket. 2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Retailrocket recommender system dataset</em>.

</span>
<span class="ltx_bibblock">Retailrocket.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset" title="">https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rice (1976)</span>
<span class="ltx_bibblock">
John R. Rice. 1976.

</span>
<span class="ltx_bibblock">The Algorithm Selection Problem**This work was partially supported by the National Science Foundation through Grant GP-32940X. This chapter was presented as the George E. Forsythe Memorial Lecture at the Computer Science Conference, February 19, 1975, Washington, D. C.

</span>
<span class="ltx_bibblock">Advances in Computers, Vol. 15. Elsevier, 65–118.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/S0065-2458(08)60520-3" title="">https://doi.org/10.1016/S0065-2458(08)60520-3</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Romero et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Cristobal Romero, Juan Luis Olmo, and Sebastián Ventura. 2013.

</span>
<span class="ltx_bibblock">A meta-learning approach for recommending a subset of white-box classification algorithms for Moodle datasets. In <em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">Educational Data Mining 2013</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rosenthal (2017)</span>
<span class="ltx_bibblock">
Ethan Rosenthal. 2017.

</span>
<span class="ltx_bibblock">Sketchfab: content discovery… IN 3D.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/EthanRosenthal/rec-a-sketch" title="">https://github.com/EthanRosenthal/rec-a-sketch</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">spotifiy.com ([n. d.])</span>
<span class="ltx_bibblock">
spotifiy.com. [n. d.].

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">About Spotify</em>.

</span>
<span class="ltx_bibblock">
Retrieved March 19, 2024 from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://newsroom.spotify.com/company-info/" title="">https://newsroom.spotify.com/company-info/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em> (Beijing, China) <em class="ltx_emph ltx_font_italic" id="bib.bib37.4.2">(CIKM ’19)</em>. Association for Computing Machinery, New York, NY, USA, 1441–1450.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3357384.3357895" title="">https://doi.org/10.1145/3357384.3357895</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vente (2023)</span>
<span class="ltx_bibblock">
Tobias Vente. 2023.

</span>
<span class="ltx_bibblock">Advancing Automation of Design Decisions in Recommender System Pipelines. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib38.2.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1355–1360.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608886" title="">https://doi.org/10.1145/3604915.3608886</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vente et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tobias Vente, Michael Ekstrand, and Joeran Beel. 2023.

</span>
<span class="ltx_bibblock">Introducing LensKit-Auto, an Experimental Automated Recommender System (AutoRecSys) Toolkit. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib39.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1212–1216.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3610656" title="">https://doi.org/10.1145/3604915.3610656</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jianling Wang, Ya Le, Bo Chang, Yuyan Wang, Ed H. Chi, and Minmin Chen. 2022.

</span>
<span class="ltx_bibblock">Learning to Augment for Casual User Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the ACM Web Conference 2022</em> (¡conf-loc¿, ¡city¿Virtual Event, Lyon¡/city¿, ¡country¿France¡/country¿, ¡/conf-loc¿) <em class="ltx_emph ltx_font_italic" id="bib.bib40.4.2">(WWW ’22)</em>. Association for Computing Machinery, New York, NY, USA, 2183–2194.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3485447.3512147" title="">https://doi.org/10.1145/3485447.3512147</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Ting-Hsiang Wang, Xia Hu, Haifeng Jin, Qingquan Song, Xiaotian Han, and Zirui Liu. 2020.

</span>
<span class="ltx_bibblock">AutoRec: An Automated Recommender System. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proceedings of the 14th ACM Conference on Recommender Systems</em> (Virtual Event, Brazil) <em class="ltx_emph ltx_font_italic" id="bib.bib41.4.2">(RecSys ’20)</em>. Association for Computing Machinery, New York, NY, USA, 582–584.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3383313.3411529" title="">https://doi.org/10.1145/3383313.3411529</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Tian (2015)</span>
<span class="ltx_bibblock">
Dongkuan Xu and Yingjie Tian. 2015.

</span>
<span class="ltx_bibblock">A comprehensive survey of clustering algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Annals of Data Science</em> 2 (2015), 165–193.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s40745-015-0040-1" title="">https://doi.org/10.1007/s40745-015-0040-1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Gui-Rong Xue, Chenxi Lin, Qiang Yang, WenSi Xi, Hua-Jun Zeng, Yong Yu, and Zheng Chen. 2005.

</span>
<span class="ltx_bibblock">Scalable collaborative filtering using cluster-based smoothing. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Salvador, Brazil) <em class="ltx_emph ltx_font_italic" id="bib.bib43.4.2">(SIGIR ’05)</em>. Association for Computing Machinery, New York, NY, USA, 114–121.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1076034.1076056" title="">https://doi.org/10.1145/1076034.1076056</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhenrui Yue, Zhankui He, Huimin Zeng, and Julian McAuley. 2021.

</span>
<span class="ltx_bibblock">Black-Box Attacks on Sequential Recommenders via Data-Free Model Extraction. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Proceedings of the 15th ACM Conference on Recommender Systems</em> (Amsterdam, Netherlands) <em class="ltx_emph ltx_font_italic" id="bib.bib44.4.2">(RecSys ’21)</em>. Association for Computing Machinery, New York, NY, USA, 44–54.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3460231.3474275" title="">https://doi.org/10.1145/3460231.3474275</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhenrui Yue, Huimin Zeng, Ziyi Kou, Lanyu Shang, and Dong Wang. 2022.

</span>
<span class="ltx_bibblock">Defending Substitution-Based Profile Pollution Attacks on Sequential Recommenders. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em> (¡conf-loc¿, ¡city¿Seattle¡/city¿, ¡state¿WA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿) <em class="ltx_emph ltx_font_italic" id="bib.bib45.4.2">(RecSys ’22)</em>. Association for Computing Machinery, New York, NY, USA, 59–70.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3546770" title="">https://doi.org/10.1145/3523227.3546770</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">zalando.com ([n. d.])</span>
<span class="ltx_bibblock">
zalando.com. [n. d.].

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">A holistic strategy for a connected fashion world</em>.

</span>
<span class="ltx_bibblock">
Retrieved March 19, 2024 from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://corporate.zalando.com/en/about-us/holistic-strategy-connected-fashion-world" title="">https://corporate.zalando.com/en/about-us/holistic-strategy-connected-fashion-world</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue May 28 09:48:05 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
