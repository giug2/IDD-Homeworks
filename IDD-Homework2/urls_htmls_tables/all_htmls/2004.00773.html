<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2004.00773] A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus</title><meta property="og:description" content="Federated learning has been widely studied and applied to various scenarios. In mobile computing scenarios, federated learning protects users from exposing their private data, while cooperatively training the global mo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2004.00773">

<!--Generated on Sun Mar 17 07:41:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Blockchain,  Federated learning,  Validation consensus,  Robustness
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuzheng Li, Chuan Chen1, Nan Liu, Huawei Huang, Zibin Zheng and Qiang Yan2
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China
</span>
<span class="ltx_contact ltx_role_affiliation">National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangzhou, China
</span>
<span class="ltx_contact ltx_role_affiliation">2WeBank Co. Ltd., China
</span>
<span class="ltx_contact ltx_role_affiliation">1Email: chenchuan@mail.sysu.edu.cn
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning has been widely studied and applied to various scenarios. In mobile computing scenarios, federated learning protects users from exposing their private data, while cooperatively training the global model for a variety of real-world applications. However, the security of federated learning is increasingly being questioned, due to the malicious clients or central servers’ constant attack to the global model or user privacy data. To address these security issues, we proposed a decentralized federated learning framework based on blockchain, i.e., a Blockchain-based Federated Learning framework with Committee consensus (BFLC). The framework uses blockchain for the global model storage and the local model update exchange. To enable the proposed BFLC, we also devised an innovative committee consensus mechanism, which can effectively reduce the amount of consensus computing and reduce malicious attacks. We then discussed the scalability of BFLC, including theoretical security, storage optimization, and incentives. Finally, we performed experiments using real-world datasets to verify the effectiveness of the BFLC framework.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Blockchain, Federated learning, Validation consensus, Robustness

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the introduction of GDPR, both industry and academia began to pay more attention to the privacy protection of machine learning. User-generated private data should not be exposed or uploaded to a central server. Google proposed Federated Learning (FL) in 2016 to solve the problem of collaborative training for privacy protection. FL proposes a distributed training model with two roles: the participating devices and the central server. Instead of uploading private data, nodes locally update the global model and then upload the model updates (i.e., the local gradients). The central server collects these updates and integrates them to form an updated model. Because of this privacy feature, FL is attracting more and more researchers’ attention in recent years.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In FL settings, a server performs the central operations of update aggregation, client selection, global model maintenance. The server needs to collect updates from numerous clients to complete the aggregation operation, and it also needs to broadcast a new global model to these clients, which puts a high demand on network bandwidth. Also, cloud-based servers are affected by the stability of cloud service providers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. A centralized server can skew the global model by favoring some clients. Moreover, some malicious central servers can poison the model and even collect clients’ privacy data from updates. Therefore, the stability, fairness, and security of the central server are crucial to FL.
</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">A direct idea is to remove the server and execute the central tasks on distributed client nodes. The blockchain, which is viewed as decentralized storage, can serve as the basis for maintaining FL. In detail, we can design protocols to execute the aggregation task on clients. BAFFLE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> mentions using blockchain to store and share the global model, and using perform aggregation with smart contracts. With the removal of the central server, the above challenges need not be considered. However, the computation and network transmission pressure of this task are all transferred to the nodes. In particular, when all nodes have to deal with consensus tasks, the computational overhead per round is huge.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Zhou <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> propose using blockchain to maintain the global model within a community and reach a consensus, and leveraging allreduce protocolto transmit and update the model among multiple communities. The global model is updated continuously and promoted by various communities. Chen <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> propose to leverage the blockchain to record the updates from nodes and the evaluation of that updates. Underrated nodes may be kicked out of the community as a defense against malicious devices. However, maintaining multiple blockchains at the same time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> is not conducive to model sharing, and nodes in different communities can hardly obtain models or update records of other communities. If a community as a whole is malicious, it is difficult for other honest communities to detect and resist, then a trusty global detection might be needed.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Through the literature review, it would be an effective way for blockchain to serve as an effective decentralized storage and replace the central FL servers. However, the efficiency of consensus is in urgent need of improvement. Although storing models and model updates in blockchain brings many security advantages, it is also a huge burden of the storage capacity on blockchain nodes. Therefore, how to reduce the consumption of a blockchain-based FL is also a key challenge.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In this article, we propose a decentralized, autonomous blockchain-based FL architecture to address these challenges (shown in Figure <a href="#S2.F1" title="Figure 1 ‣ II Related Work ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). With respect to the management of FL nodes, the architecture based on the alliance chain ensures the node permission control. In terms of storage, we design the storage pattern on the chain of models and updates, and via this pattern, the nodes can get the latest model quickly. Each validated update is recorded and kept untampered on the blockchain. Considering the huge storage consumption on the blockchain, partial nodes can abandon the historical blocks to release the storage space. In terms of the block consensus mechanism, a novel <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">committee consensus</em> mechanism is proposed, which can only increase a few validation consumptions and achieve more stability under malicious attacks. In each round of FL, updates are validated and packaged by a small number of nodes (i.e., the <em id="S1.p6.1.2" class="ltx_emph ltx_font_italic">committee</em>). The committee consensus mechanism allows most honest nodes to reinforce each other and continuously improve the global model. A small number of incorrect or malicious node updates will be ignored to avoid damaging the global model. In the meantime, the BFLC training community is flexible, where the nodes can join or leave at any time without damaging the training process. Combined with an effective incentive mechanism, the nodes who contribute can gain actual rewards, thus promoting the development of the whole training community in a virtuous circle.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Our contributions are summarized as follows.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a blockchain-based FL framework BFLC, which defines the model storage patterns, the training process and a novel committee consensus in detail.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We technically discuss the scalability of BFLC, including the node management in the community, the analysis of malicious node attacks, and the storage optimization.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We demonstrate the effectiveness of BFLC by experiments on real-world FL dataset. We also verify the security of BFLC by simulating the malicious attacks.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Konecný <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> proposed Federated Learning whose goal is to train a high-quality centralized model while training data remains distributed over a large number of clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The network situation of FL is unreliable and relatively slow, and the clients are not always online. In these years, FL is applied in many scenarios like video analysis, information inspection, and classification, credit card fraud detection while keeping the personal data sensitivity safe. Besides, the theoretical studies of convergence, network latency or malicious attacks on FL are also active fields.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The centralized federated server has been challenged and questioned growly in these years. It is a natural thought that keeping the concept of server at a minimum or even avoiding it completely. The study of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> assumed that the data remains at the edge devices, but it requires no aggregation server or any central component. Hu <em id="S2.p2.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed a segmented gossip approach, which makes full utilization of node-to-node bandwidth then can achieve a convergence efficiently.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Meanwhile, decentralization may be the most direct way to avoid the above risks. Blockchain, a distributed ledger technique, can store the historical operations and keep it tamper-resistant. With the aim of the blockchain, collaborative machine learning methods can get rid of the centralized server and improve security. Blaz <em id="S2.p3.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed a machine learning-based method to fasten the transaction signing process while also including a personalized identification of anomalous transactions. Deep reinforcement learning is also applied on blockchain-based scenarios, such as industrial Internet of things, mobile edge computing, cognitive radio networksand Internet of vehicle. </p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">In recent years, FL is an emerging research focus on the blockchain system.It is reasonable to assume that the clients in FL might be malicious. Therefore, the local updates from all clients should be recorded under blockchain-based FL settings. You <em id="S2.p4.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> focused on the stability and convergence speed of FL, and proposed a blockchain-based method to address these challenges. Umer <em id="S2.p4.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> propose a blockchain-based architecture, which can perform parallel learning for multiple global models. Bao <em id="S2.p4.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> proposed a public blockchain-based FL architecture, which provides trusty consensus basing on nodes’ data amount and historical performance.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">These blockchain-based learning methods can effectively record the nodes’ performance to reduce malicious attacks. However, there are still three main challenges:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><em id="S2.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Consensus efficiency</em>. It is an inevitable process for blockchain-based methods to reach a consensus for each packing block. Considering the vast amount of learning nodes in the FL settings, a broadcasting consensus is highly time-consuming. Therefore, reducing the consensus cost is non-trivial. One <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> of the related works selects a leader to execute the consensus. However, the criterion relies on many outer data.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><em id="S2.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Model security</em>. The framework should prevent the global model from exposing to unauthorized devices and from poisoning. The security of the system is rarely studied under blockchain-based FL settings.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><em id="S2.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Framework scalability</em>. When applying these training frameworks to real-world applications, we always need to add detail rules to adapt to different scenarios. Therefore, the scalability of frameworks determines their scope of applications.</p>
</div>
</li>
</ol>
<p id="S2.p5.2" class="ltx_p">In the following sections, we will describe our proposed methods to tackle these challenges.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2004.00773/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="220" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The training process of the proposed BFLC framework. (1) Training nodes acquire the newest global model and perform local training. (2) Training nodes send local updates to committee (3) Committee validate the updates and record new model or updates onto blockchain.
</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">The Proposed Framework</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Federated Learning (FL) enables the machine learning algorithms training across multiple distributed clients without exchanging their data samples. In the original FL settings, one centralized server takes control of the training process, including client management, global model maintenance, and gradient aggregation. During each training round, the server broadcasts the current model to some participating nodes. After receiving the model, nodes locally update it with their local data and submit the update gradients to the server. The server then aggregates and applies the local gradients into the model for the next round.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The decentralized nature of blockchain can replace the place of the central server. As aforementioned, the functions of the centralized server can be implemented by the Smart Contract (SC) instead, and be actuated by transactions on the blockchain. To tackle this vision, we propose BFLC, which is a <span id="S3.p2.1.1" class="ltx_text ltx_framed ltx_framed_underline">B</span>lockchain-based <span id="S3.p2.1.2" class="ltx_text ltx_framed ltx_framed_underline">F</span>ederated <span id="S3.p2.1.3" class="ltx_text ltx_framed ltx_framed_underline">L</span>earning framework with <span id="S3.p2.1.4" class="ltx_text ltx_framed ltx_framed_underline">C</span>ommittee consensus. Without any centralized server, the participating nodes perform FL via blockchain, which maintains the global models and local updates. Considering the communication cost of FL, we leverage a novel delegated consensus mechanism to tackle the missions of gradients selection and blocks generation. In the following sub-sections, we will elaborate on the various components of the framework.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Blockchain Storage</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To enable authority control, the storage of BFLC is an alliance blockchain system, and only the authorized devices can access the FL training contents. On the blockchain, we design two different blocks to store the global model and local update (as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III-A Blockchain Storage ‣ III The Proposed Framework ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), which are collectively known as learning information. For the sake of simplicity, we assume that only one learning information is placed in a block.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In the beginning, a randomly initialized model was placed into the #0 block, then the <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><cn type="integer" id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">0</cn></annotation-xml></semantics></math>-th round of training starts. Nodes access the current model and execute local training, and put the verified local gradients to new update blocks. When there are continuously enough update blocks, the smart contract triggers the aggregation, and a new model of the next round is generated and placed on the chain. We should note that the FL training only relies on the latest model block, and the historical block is stored for failure fallback and block verification.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.8" class="ltx_p">We denote the number of required updates for each round as <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">k</annotation></semantics></math>, and denote the number of rounds as <math id="S3.SS1.p3.2.m2.3" class="ltx_Math" alttext="t=0,1,..." display="inline"><semantics id="S3.SS1.p3.2.m2.3a"><mrow id="S3.SS1.p3.2.m2.3.4" xref="S3.SS1.p3.2.m2.3.4.cmml"><mi id="S3.SS1.p3.2.m2.3.4.2" xref="S3.SS1.p3.2.m2.3.4.2.cmml">t</mi><mo id="S3.SS1.p3.2.m2.3.4.1" xref="S3.SS1.p3.2.m2.3.4.1.cmml">=</mo><mrow id="S3.SS1.p3.2.m2.3.4.3.2" xref="S3.SS1.p3.2.m2.3.4.3.1.cmml"><mn id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">0</mn><mo id="S3.SS1.p3.2.m2.3.4.3.2.1" xref="S3.SS1.p3.2.m2.3.4.3.1.cmml">,</mo><mn id="S3.SS1.p3.2.m2.2.2" xref="S3.SS1.p3.2.m2.2.2.cmml">1</mn><mo id="S3.SS1.p3.2.m2.3.4.3.2.2" xref="S3.SS1.p3.2.m2.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p3.2.m2.3.3" xref="S3.SS1.p3.2.m2.3.3.cmml">…</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.3b"><apply id="S3.SS1.p3.2.m2.3.4.cmml" xref="S3.SS1.p3.2.m2.3.4"><eq id="S3.SS1.p3.2.m2.3.4.1.cmml" xref="S3.SS1.p3.2.m2.3.4.1"></eq><ci id="S3.SS1.p3.2.m2.3.4.2.cmml" xref="S3.SS1.p3.2.m2.3.4.2">𝑡</ci><list id="S3.SS1.p3.2.m2.3.4.3.1.cmml" xref="S3.SS1.p3.2.m2.3.4.3.2"><cn type="integer" id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">0</cn><cn type="integer" id="S3.SS1.p3.2.m2.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2">1</cn><ci id="S3.SS1.p3.2.m2.3.3.cmml" xref="S3.SS1.p3.2.m2.3.3">…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.3c">t=0,1,...</annotation></semantics></math>. Then we have: the # <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="t\times(k+1)" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mrow id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">t</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">×</mo><mrow id="S3.SS1.p3.3.m3.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p3.3.m3.1.1.1.1.2" xref="S3.SS1.p3.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p3.3.m3.1.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.1.1.1.2" xref="S3.SS1.p3.3.m3.1.1.1.1.1.2.cmml">k</mi><mo id="S3.SS1.p3.3.m3.1.1.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.3.m3.1.1.1.1.1.3" xref="S3.SS1.p3.3.m3.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS1.p3.3.m3.1.1.1.1.3" xref="S3.SS1.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><times id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2"></times><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">𝑡</ci><apply id="S3.SS1.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1"><plus id="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1"></plus><ci id="S3.SS1.p3.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1.2">𝑘</ci><cn type="integer" id="S3.SS1.p3.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">t\times(k+1)</annotation></semantics></math> block contains the model of <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">t</annotation></semantics></math>-th round, which is called <em id="S3.SS1.p3.8.1" class="ltx_emph ltx_font_italic">model block</em>, and the # <math id="S3.SS1.p3.5.m5.2" class="ltx_Math" alttext="[t\times(k+1)+1,(t+1)\times(k+1)-1]" display="inline"><semantics id="S3.SS1.p3.5.m5.2a"><mrow id="S3.SS1.p3.5.m5.2.2.2" xref="S3.SS1.p3.5.m5.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p3.5.m5.2.2.2.3" xref="S3.SS1.p3.5.m5.2.2.3.cmml">[</mo><mrow id="S3.SS1.p3.5.m5.1.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.1.cmml"><mrow id="S3.SS1.p3.5.m5.1.1.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.1.1.1.3" xref="S3.SS1.p3.5.m5.1.1.1.1.1.3.cmml">t</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.5.m5.1.1.1.1.1.2" xref="S3.SS1.p3.5.m5.1.1.1.1.1.2.cmml">×</mo><mrow id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.2" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.2.cmml">k</mi><mo id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.3" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p3.5.m5.1.1.1.1.2" xref="S3.SS1.p3.5.m5.1.1.1.1.2.cmml">+</mo><mn id="S3.SS1.p3.5.m5.1.1.1.1.3" xref="S3.SS1.p3.5.m5.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p3.5.m5.2.2.2.4" xref="S3.SS1.p3.5.m5.2.2.3.cmml">,</mo><mrow id="S3.SS1.p3.5.m5.2.2.2.2" xref="S3.SS1.p3.5.m5.2.2.2.2.cmml"><mrow id="S3.SS1.p3.5.m5.2.2.2.2.2" xref="S3.SS1.p3.5.m5.2.2.2.2.2.cmml"><mrow id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.2" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.2" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.2.cmml">t</mi><mo id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.1" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.3" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo rspace="0.055em" stretchy="false" id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.3" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.SS1.p3.5.m5.2.2.2.2.2.3" xref="S3.SS1.p3.5.m5.2.2.2.2.2.3.cmml">×</mo><mrow id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.2" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.cmml">(</mo><mrow id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.cmml"><mi id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.2" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.2.cmml">k</mi><mo id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.1" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.3" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.3" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p3.5.m5.2.2.2.2.3" xref="S3.SS1.p3.5.m5.2.2.2.2.3.cmml">−</mo><mn id="S3.SS1.p3.5.m5.2.2.2.2.4" xref="S3.SS1.p3.5.m5.2.2.2.2.4.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS1.p3.5.m5.2.2.2.5" xref="S3.SS1.p3.5.m5.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.2b"><interval closure="closed" id="S3.SS1.p3.5.m5.2.2.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2"><apply id="S3.SS1.p3.5.m5.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1"><plus id="S3.SS1.p3.5.m5.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.2"></plus><apply id="S3.SS1.p3.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1"><times id="S3.SS1.p3.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1.2"></times><ci id="S3.SS1.p3.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1.3">𝑡</ci><apply id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1"><plus id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.1"></plus><ci id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.2">𝑘</ci><cn type="integer" id="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.1.1.1.1.3">1</cn></apply></apply><cn type="integer" id="S3.SS1.p3.5.m5.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p3.5.m5.2.2.2.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2"><minus id="S3.SS1.p3.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.3"></minus><apply id="S3.SS1.p3.5.m5.2.2.2.2.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.2"><times id="S3.SS1.p3.5.m5.2.2.2.2.2.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.2.3"></times><apply id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1"><plus id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.1"></plus><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.2">𝑡</ci><cn type="integer" id="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1"><plus id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.1"></plus><ci id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.2">𝑘</ci><cn type="integer" id="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.2.2.1.1.3">1</cn></apply></apply><cn type="integer" id="S3.SS1.p3.5.m5.2.2.2.2.4.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.4">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.2c">[t\times(k+1)+1,(t+1)\times(k+1)-1]</annotation></semantics></math> blocks contain the updates of <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">t</annotation></semantics></math>-th rounds, which are called <em id="S3.SS1.p3.8.2" class="ltx_emph ltx_font_italic">update block</em>s. From an implementation perspective, one model block should includes: block headers, number of round <math id="S3.SS1.p3.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p3.7.m7.1a"><mi id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><ci id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">t</annotation></semantics></math> and global model, while one update block includes: block headers, number of round <math id="S3.SS1.p3.8.m8.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p3.8.m8.1a"><mi id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><ci id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">t</annotation></semantics></math>, local update gradient, uploader address and update score.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2004.00773/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="437" height="282" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The FL storage structure on blockchain system, and the provided functions.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Committee Consensus Mechanism</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The chain structure of blockchain guarantees the immutability. Therefore, appending the correct blocks to the chain is a crucial component which is the consensus mechanisms work for. The competition-based consensus mechanisms append blocks on the chain first, whereafter, the consensus meets. Conversely, the communication-based generate mechanisms reach an agreement before appending blocks.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Considering the computation and communication cost of consensus, we propose an efficient and secure Committee Consensus Mechanism (CCM) to validate the local gradients <em id="S3.SS2.p2.1.1" class="ltx_emph ltx_font_italic">before</em> appending it to the chain. Under this setting, a few honest nodes will constitute a <em id="S3.SS2.p2.1.2" class="ltx_emph ltx_font_italic">committee</em> in charge of verification of local gradients and blocks generation. In the meantime, the rest nodes execute local training and send the local updates to the committee. The committee then validates the updates and assign a score on them. Only the qualified updates will be packed onto the blockchain. At the beginning of the next round, a new committee is elected basing on the scores of nodes in the previous round, which means that the committee will not be re-elected. It is noteworthy that the update validation is a pivotal component of the CCM, therefore, we describe a feasible approach: the committee members validate the local updates by treating their data as a validation set, and the validation accuracy becomes the score. This is the minimized approach that acquires no further operation of the committee, but only the basic ability to run the learning model. After combining the scores from the various committee members, the median will become the score of this update.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Working with this mechanism, BFLC can achieve these advantages:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><em id="S3.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">High efficiency</em>: only a few nodes will validate the updates, rather than broadcasting to every node and reach an agreement.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><em id="S3.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">K-fold cross-validation</em>: the committee members will not participate in the local training in the round. Therefore, the local data of the committee are taken as a validation set. As the alternating of committee members at each round, the validation set changes as well. In this setting, k-fold cross-validation on FL achieved.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><em id="S3.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Anti-malevolence</em>: based on the validation scores, the corresponding nodes with better performance will be elected by the smart contract and constitute the new committee for the next training round. which means the selected local data distribution is gregarious and the node is not malicious.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Model Training</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Nodes other than committees perform local training each round. In FL, for the sake of security and privacy, raw data will be kept in nodes locally, and these nodes only upload the gradients to the blockchain. Furthermore, there are two main challenges:</p>
<ol id="S3.I2" class="ltx_enumerate">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">The local data distribution might be not Independent and Identically Distributed (non-IID)</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">The devices are not always available</p>
</div>
</li>
</ol>
<p id="S3.SS3.p1.2" class="ltx_p">To address the first challenge, only a certain number of local updates are requisite for each round, and the committee consensus mechanism could maximize the generalization ability of the global model by validating the local updates with committee members’ data distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. To address the second one, we design an initiative local learning progress for nodes.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Nodes can actively obtain the current global model at any time and perform local training. The gradients will be sent to the committee and be validated. When eligible updates are packaged on the blockchain, as a reward, tokens can be attached to them. We will discuss the incentive in the next section.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">As aforementioned, a certain number of valid updates are required for each round. Therefore, when the committee validates enough local updates, the aggregation process is activated. These validated updates are aggregated by the committee into a new global model. The aggregation can be performed on the local gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> or the local models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and the network transmission consumptions of these two methods are equal.
After the new global model is packed on the blockchain, the committee will be elected again, and the next training round begins.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Node Management and Incentive</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The BFLC training process depends on the mutual promotion of nodes, and node management is also a key part of BFLC. The participant nodes can not only access the global model but can also upload updates to affect the global model. To control permissions, we have designated the initial nodes that constitute the training community to be responsible for node management, i.e., to be the managers. Each device must be verified by the managers before joining the training community. This verification is in blacklist mode: if the device has been kicked out of the community for misconduct (such as submitting misleading updates, spreading a private model), the device will be rejected.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Depending on the proposed blockchain storage structure, the latest global model can be quickly found on the chain after new nodes joined. Nodes can immediately use the model to complete their local tasks, or they can update the model with local data and gain scores on the chain after verification by the consensus committee. It is noteworthy that only a certain number of valid updates are required for aggregation at each round, and only part of nodes are online to participate as well. Therefore, as long as the nodes actively submit updates, it is likely to participate in the global model updating and gain scores. Meanwhile, partial offline nodes will not impede FL progress.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Nodes in a community can always use the model without committing updates, so an effective incentive is required to encourage nodes to provide updates to the global model. To address this problem, we propose an incentive mechanism called <em id="S4.SS1.p3.1.1" class="ltx_emph ltx_font_italic">profit sharing by contribution</em>.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><em id="S4.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Permission fee</em>: each device should pay for the access permission of the global model, and these fees are kept by the managers. Nodes then have unlimited access to the latest models in the community.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><em id="S4.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Profit sharing</em>: After aggregation of each round, the managers distribute rewards to the corresponding nodes basing on the scores of their submitted updates.</p>
</div>
</li>
</ul>
<p id="S4.SS1.p3.2" class="ltx_p">As a result, frequently providing updates could earn more rewards, and the constantly updated global model will attract more nodes to participate. This incentive mechanism has high scalability to adapt to different real-world applications. For instance, the configurations of the permission fee, the profit-sharing proportion or the dividend modes are worth studying.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Committee Election</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">At the end of each round, a new committee is elected from the providers of validated updates. In decentralized training settings, this election significantly affects the performance of the global model, because the committee decides which local updates will be aggregated. Committee election methods include the following categories:</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><em id="S4.I2.i1.p1.1.1" class="ltx_emph ltx_font_italic">Random election</em>: new committee members are randomly selected from validated nodes. From a machine learning perspective, this approach improves the generalization of the model and reduces overfitting. However, the resistance to malicious attacks is weak while the malicious nodes disguise as normal ones.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><em id="S4.I2.i2.p1.1.1" class="ltx_emph ltx_font_italic">Election by score</em>: the providers with top validation scores constitute the new committee. This may exacerbate the uneven distribution of samples due to the absence of partial nodes into the committee. However, for malicious node attacks, this approach significantly increases the cost of the attack and brings more security and stability.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><em id="S4.I2.i3.p1.1.1" class="ltx_emph ltx_font_italic">Multi-factor optimization</em>: this approach considers multiple factors of the device (i.e., the network transmission rate) and the validation scores for optimal election. However, this optimization will bring additional computing overhead. Therefore, this approach should be applied depending on the realistic scenario and the associated requirements.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Malicious Nodes</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">A malicious node is defined as a node submitting incorrect, malicious model updates. In the original FL settings, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> aggregates all the updates into a new global model. If there are malicious updates, the global model will be poisoned and obtains lower performance. As aforementioned, under the CCM, the updates will be verified by the committee before being aggregated. In this sub-section, we theoretically analyze the factors and the success possibility of malicious attacks.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.7" class="ltx_p">We denote the amount of all nodes as <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">N</annotation></semantics></math>, in which the amount of committee members is <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">M</annotation></semantics></math>, and the rest <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="N-M" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">N</mi><mo id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">−</mo><mi id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><minus id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></minus><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">𝑁</ci><ci id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">N-M</annotation></semantics></math> nodes are training nodes. Distinctly, a malicious update is accepted to the aggregation if and only if more than <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="\frac{M}{2}" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mfrac id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">M</mi><mn id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><divide id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"></divide><ci id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">𝑀</ci><cn type="integer" id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\frac{M}{2}</annotation></semantics></math> committee members are cooperating with. However, the committee members are the <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mi id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><ci id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">M</annotation></semantics></math> of the best performers at last round, which means these malicious committee members’ updates are accepted by other <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="\frac{M}{2}" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mfrac id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml"><mi id="S4.SS3.p2.6.m6.1.1.2" xref="S4.SS3.p2.6.m6.1.1.2.cmml">M</mi><mn id="S4.SS3.p2.6.m6.1.1.3" xref="S4.SS3.p2.6.m6.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><apply id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1"><divide id="S4.SS3.p2.6.m6.1.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1"></divide><ci id="S4.SS3.p2.6.m6.1.1.2.cmml" xref="S4.SS3.p2.6.m6.1.1.2">𝑀</ci><cn type="integer" id="S4.SS3.p2.6.m6.1.1.3.cmml" xref="S4.SS3.p2.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">\frac{M}{2}</annotation></semantics></math> malicious nodes in the last committee. It is an infinite dependency loop, therefore, as long as there are more than <math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="\frac{M}{2}" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><mfrac id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml"><mi id="S4.SS3.p2.7.m7.1.1.2" xref="S4.SS3.p2.7.m7.1.1.2.cmml">M</mi><mn id="S4.SS3.p2.7.m7.1.1.3" xref="S4.SS3.p2.7.m7.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><apply id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"><divide id="S4.SS3.p2.7.m7.1.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"></divide><ci id="S4.SS3.p2.7.m7.1.1.2.cmml" xref="S4.SS3.p2.7.m7.1.1.2">𝑀</ci><cn type="integer" id="S4.SS3.p2.7.m7.1.1.3.cmml" xref="S4.SS3.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">\frac{M}{2}</annotation></semantics></math> honest nodes in the first committee, no malicious node could enter the committee and harm the global model.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.11" class="ltx_p">Considering another extreme situation: the malicious nodes conspire together to earn the committee seats by pretending as normal nodes. When the malicious nodes hold half of the seats, the attack begins. To analyze this attack mode, we denote the amount of participating nodes as <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">A</annotation></semantics></math>, the percentage of malicious nodes in <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">A</annotation></semantics></math> is <math id="S4.SS3.p3.3.m3.2" class="ltx_Math" alttext="q\in(0,1)" display="inline"><semantics id="S4.SS3.p3.3.m3.2a"><mrow id="S4.SS3.p3.3.m3.2.3" xref="S4.SS3.p3.3.m3.2.3.cmml"><mi id="S4.SS3.p3.3.m3.2.3.2" xref="S4.SS3.p3.3.m3.2.3.2.cmml">q</mi><mo id="S4.SS3.p3.3.m3.2.3.1" xref="S4.SS3.p3.3.m3.2.3.1.cmml">∈</mo><mrow id="S4.SS3.p3.3.m3.2.3.3.2" xref="S4.SS3.p3.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p3.3.m3.2.3.3.2.1" xref="S4.SS3.p3.3.m3.2.3.3.1.cmml">(</mo><mn id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">0</mn><mo id="S4.SS3.p3.3.m3.2.3.3.2.2" xref="S4.SS3.p3.3.m3.2.3.3.1.cmml">,</mo><mn id="S4.SS3.p3.3.m3.2.2" xref="S4.SS3.p3.3.m3.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS3.p3.3.m3.2.3.3.2.3" xref="S4.SS3.p3.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.2b"><apply id="S4.SS3.p3.3.m3.2.3.cmml" xref="S4.SS3.p3.3.m3.2.3"><in id="S4.SS3.p3.3.m3.2.3.1.cmml" xref="S4.SS3.p3.3.m3.2.3.1"></in><ci id="S4.SS3.p3.3.m3.2.3.2.cmml" xref="S4.SS3.p3.3.m3.2.3.2">𝑞</ci><interval closure="open" id="S4.SS3.p3.3.m3.2.3.3.1.cmml" xref="S4.SS3.p3.3.m3.2.3.3.2"><cn type="integer" id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">0</cn><cn type="integer" id="S4.SS3.p3.3.m3.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.2c">q\in(0,1)</annotation></semantics></math>, and the percentage of the committee is <math id="S4.SS3.p3.4.m4.2" class="ltx_Math" alttext="p\in(0,1)" display="inline"><semantics id="S4.SS3.p3.4.m4.2a"><mrow id="S4.SS3.p3.4.m4.2.3" xref="S4.SS3.p3.4.m4.2.3.cmml"><mi id="S4.SS3.p3.4.m4.2.3.2" xref="S4.SS3.p3.4.m4.2.3.2.cmml">p</mi><mo id="S4.SS3.p3.4.m4.2.3.1" xref="S4.SS3.p3.4.m4.2.3.1.cmml">∈</mo><mrow id="S4.SS3.p3.4.m4.2.3.3.2" xref="S4.SS3.p3.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p3.4.m4.2.3.3.2.1" xref="S4.SS3.p3.4.m4.2.3.3.1.cmml">(</mo><mn id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">0</mn><mo id="S4.SS3.p3.4.m4.2.3.3.2.2" xref="S4.SS3.p3.4.m4.2.3.3.1.cmml">,</mo><mn id="S4.SS3.p3.4.m4.2.2" xref="S4.SS3.p3.4.m4.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS3.p3.4.m4.2.3.3.2.3" xref="S4.SS3.p3.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.2b"><apply id="S4.SS3.p3.4.m4.2.3.cmml" xref="S4.SS3.p3.4.m4.2.3"><in id="S4.SS3.p3.4.m4.2.3.1.cmml" xref="S4.SS3.p3.4.m4.2.3.1"></in><ci id="S4.SS3.p3.4.m4.2.3.2.cmml" xref="S4.SS3.p3.4.m4.2.3.2">𝑝</ci><interval closure="open" id="S4.SS3.p3.4.m4.2.3.3.1.cmml" xref="S4.SS3.p3.4.m4.2.3.3.2"><cn type="integer" id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">0</cn><cn type="integer" id="S4.SS3.p3.4.m4.2.2.cmml" xref="S4.SS3.p3.4.m4.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.2c">p\in(0,1)</annotation></semantics></math>. The attack target is holding more than <math id="S4.SS3.p3.5.m5.1" class="ltx_Math" alttext="\frac{A\times p}{2}" display="inline"><semantics id="S4.SS3.p3.5.m5.1a"><mfrac id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml"><mrow id="S4.SS3.p3.5.m5.1.1.2" xref="S4.SS3.p3.5.m5.1.1.2.cmml"><mi id="S4.SS3.p3.5.m5.1.1.2.2" xref="S4.SS3.p3.5.m5.1.1.2.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p3.5.m5.1.1.2.1" xref="S4.SS3.p3.5.m5.1.1.2.1.cmml">×</mo><mi id="S4.SS3.p3.5.m5.1.1.2.3" xref="S4.SS3.p3.5.m5.1.1.2.3.cmml">p</mi></mrow><mn id="S4.SS3.p3.5.m5.1.1.3" xref="S4.SS3.p3.5.m5.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><apply id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1"><divide id="S4.SS3.p3.5.m5.1.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1"></divide><apply id="S4.SS3.p3.5.m5.1.1.2.cmml" xref="S4.SS3.p3.5.m5.1.1.2"><times id="S4.SS3.p3.5.m5.1.1.2.1.cmml" xref="S4.SS3.p3.5.m5.1.1.2.1"></times><ci id="S4.SS3.p3.5.m5.1.1.2.2.cmml" xref="S4.SS3.p3.5.m5.1.1.2.2">𝐴</ci><ci id="S4.SS3.p3.5.m5.1.1.2.3.cmml" xref="S4.SS3.p3.5.m5.1.1.2.3">𝑝</ci></apply><cn type="integer" id="S4.SS3.p3.5.m5.1.1.3.cmml" xref="S4.SS3.p3.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">\frac{A\times p}{2}</annotation></semantics></math> seats in committee. We assume that the performance of each node is similar. Therefore, the attack success probability can be calculated as the probability of this event: extracting <math id="S4.SS3.p3.6.m6.1" class="ltx_Math" alttext="A\times p" display="inline"><semantics id="S4.SS3.p3.6.m6.1a"><mrow id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml"><mi id="S4.SS3.p3.6.m6.1.1.2" xref="S4.SS3.p3.6.m6.1.1.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p3.6.m6.1.1.1" xref="S4.SS3.p3.6.m6.1.1.1.cmml">×</mo><mi id="S4.SS3.p3.6.m6.1.1.3" xref="S4.SS3.p3.6.m6.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><apply id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1"><times id="S4.SS3.p3.6.m6.1.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1.1"></times><ci id="S4.SS3.p3.6.m6.1.1.2.cmml" xref="S4.SS3.p3.6.m6.1.1.2">𝐴</ci><ci id="S4.SS3.p3.6.m6.1.1.3.cmml" xref="S4.SS3.p3.6.m6.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">A\times p</annotation></semantics></math> nodes from <math id="S4.SS3.p3.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS3.p3.7.m7.1a"><mi id="S4.SS3.p3.7.m7.1.1" xref="S4.SS3.p3.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.7.m7.1b"><ci id="S4.SS3.p3.7.m7.1.1.cmml" xref="S4.SS3.p3.7.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.7.m7.1c">A</annotation></semantics></math> nodes, more than half of which come from <math id="S4.SS3.p3.8.m8.1" class="ltx_Math" alttext="A\times q" display="inline"><semantics id="S4.SS3.p3.8.m8.1a"><mrow id="S4.SS3.p3.8.m8.1.1" xref="S4.SS3.p3.8.m8.1.1.cmml"><mi id="S4.SS3.p3.8.m8.1.1.2" xref="S4.SS3.p3.8.m8.1.1.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p3.8.m8.1.1.1" xref="S4.SS3.p3.8.m8.1.1.1.cmml">×</mo><mi id="S4.SS3.p3.8.m8.1.1.3" xref="S4.SS3.p3.8.m8.1.1.3.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.8.m8.1b"><apply id="S4.SS3.p3.8.m8.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1"><times id="S4.SS3.p3.8.m8.1.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1.1"></times><ci id="S4.SS3.p3.8.m8.1.1.2.cmml" xref="S4.SS3.p3.8.m8.1.1.2">𝐴</ci><ci id="S4.SS3.p3.8.m8.1.1.3.cmml" xref="S4.SS3.p3.8.m8.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.8.m8.1c">A\times q</annotation></semantics></math>.
By fixing <math id="S4.SS3.p3.9.m9.1" class="ltx_Math" alttext="A=1000" display="inline"><semantics id="S4.SS3.p3.9.m9.1a"><mrow id="S4.SS3.p3.9.m9.1.1" xref="S4.SS3.p3.9.m9.1.1.cmml"><mi id="S4.SS3.p3.9.m9.1.1.2" xref="S4.SS3.p3.9.m9.1.1.2.cmml">A</mi><mo id="S4.SS3.p3.9.m9.1.1.1" xref="S4.SS3.p3.9.m9.1.1.1.cmml">=</mo><mn id="S4.SS3.p3.9.m9.1.1.3" xref="S4.SS3.p3.9.m9.1.1.3.cmml">1000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.9.m9.1b"><apply id="S4.SS3.p3.9.m9.1.1.cmml" xref="S4.SS3.p3.9.m9.1.1"><eq id="S4.SS3.p3.9.m9.1.1.1.cmml" xref="S4.SS3.p3.9.m9.1.1.1"></eq><ci id="S4.SS3.p3.9.m9.1.1.2.cmml" xref="S4.SS3.p3.9.m9.1.1.2">𝐴</ci><cn type="integer" id="S4.SS3.p3.9.m9.1.1.3.cmml" xref="S4.SS3.p3.9.m9.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.9.m9.1c">A=1000</annotation></semantics></math>, we plot the probability change along <math id="S4.SS3.p3.10.m10.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS3.p3.10.m10.1a"><mi id="S4.SS3.p3.10.m10.1.1" xref="S4.SS3.p3.10.m10.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.10.m10.1b"><ci id="S4.SS3.p3.10.m10.1.1.cmml" xref="S4.SS3.p3.10.m10.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.10.m10.1c">p</annotation></semantics></math> and <math id="S4.SS3.p3.11.m11.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS3.p3.11.m11.1a"><mi id="S4.SS3.p3.11.m11.1.1" xref="S4.SS3.p3.11.m11.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.11.m11.1b"><ci id="S4.SS3.p3.11.m11.1.1.cmml" xref="S4.SS3.p3.11.m11.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.11.m11.1c">q</annotation></semantics></math> in Figure <a href="#S4.F3" title="Figure 3 ‣ IV-C Malicious Nodes ‣ IV Discussion ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We should note that, only when the malicious percentage greater than 50%, the attack success probability could be greater than 0 markedly. This conclusion is similar to the 51% attack in the PoW blockchain system. In other words, in a decentralized community, the malicious nodes should hold 51% computational resources to attack the system, where the cost far outweighs the benefit. Furthermore, the historical models and updates are stored on the blockchain, therefore, failback is always an option after the attack happened.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2004.00773/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The attack success probability changing along with <math id="S4.F3.3.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.F3.3.m1.1b"><mi id="S4.F3.3.m1.1.1" xref="S4.F3.3.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.F3.3.m1.1c"><ci id="S4.F3.3.m1.1.1.cmml" xref="S4.F3.3.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.3.m1.1d">p</annotation></semantics></math> and <math id="S4.F3.4.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.F3.4.m2.1b"><mi id="S4.F3.4.m2.1.1" xref="S4.F3.4.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.F3.4.m2.1c"><ci id="S4.F3.4.m2.1.1.cmml" xref="S4.F3.4.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.4.m2.1d">q</annotation></semantics></math>.</figcaption>
</figure>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Accuracy of BFLC, Basic FL and stand-alone on FEMINST dataset with different proportion of active nodes </figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.1.1.2.1" class="ltx_text">Frameworks</span></th>
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5">proportion <math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mi id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">k</annotation></semantics></math>% of active nodes</th>
</tr>
<tr id="S4.T1.1.2.1" class="ltx_tr">
<td id="S4.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">10%</td>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">20%</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">30%</td>
<td id="S4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">40%</td>
<td id="S4.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">50%</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">BFLC</th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">89.33%</td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">89.89%</td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">90.02%</td>
<td id="S4.T1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_t">89.87%</td>
<td id="S4.T1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_t">89.78%</td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Basic FL</th>
<td id="S4.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">90.02%</td>
<td id="S4.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">90.20%</td>
<td id="S4.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">90.29%</td>
<td id="S4.T1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t">90.11%</td>
<td id="S4.T1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t">90.42%</td>
</tr>
<tr id="S4.T1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Stand-alone</th>
<td id="S4.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" colspan="5">91.34%</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Storage Optimization</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In real-world applications, storage overhead is an important factor that determines the hardware requirements for the training devices. Based on the above-mentioned blockchain storage scheme (as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III-A Blockchain Storage ‣ III The Proposed Framework ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), the latest global model can be found quickly. Although historical models and updates can provide post-disaster recovery functions, they also occupy huge storage space. Here, we give a simple and feasible storage overhead reduction scheme: nodes with insufficient capacity can delete historical blocks locally, and only keep the latest model and updates of the current round. In this way, the problem of insufficient storage space on some nodes can be solved, while the ability to recover from disasters and block verification is retained on the core nodes. However, the shortcomings of this method are also obvious. The credibility of the blockchain decreases with the deletion of nodes. In a mutually distrusting training community, each node may not use this scheme for security concerns.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Therefore, trusted and reliable third-party storage may be a better solution. The blockchain only maintains the network address where each model or updated file is located and records of modification operations. Other nodes interact with the centralized storage to obtain the latest model or upload updates. This centralized storage will be responsible for disaster recovery backup and distributed file storage services.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Experimental</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Settings and Normal Training</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To demonstrate the effectiveness of the BFLC, we perform it on the real-world federated dataset FEMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. This dataset contains 80,5263 samples and 3550 users for handwritten character image classification tasks and contains 62 different classes (10 digits, 26 lowercase, 26 uppercase). Following the instruction of the dataset, we simulate 900 devices in the training community, where the local datasets are unbalanced in number and not independent in distribution. After the active nodes are randomly selected, we perform the local training and aggregate via memory. We employed a blockchain system named FISCO <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/fisco-bcos</span></span></span> with PBFT consensus on an Intel Core CPU i9-9900X with a clock rate of 3.50 GHz with 10 cores and 2 threads per core. The SC layer was developed using the Solidity programming language. The learning model is written with Python 3.7.6 and Tensorflow 1.14.0 and is executed on Geforce RTX 2080Ti GPUs.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.3" class="ltx_p">We compare the BFLC with the basic FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> framework and the stand-alone training framework as the baseline. Each framework performs the classic image classification model AlexNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> as the global model and fixed a set of model hyper-parameters to ensure fairness. In terms of the experimental settings, we defined the proportion of active nodes in each round as <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mi id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><ci id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">k</annotation></semantics></math>%, among which 40% will be elected as committee members in the next round for BFLC. The proportion of training nodes for Basic FL is also <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><mi id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">k</annotation></semantics></math>%. Meanwhile, stand-alone training will leverage the whole dataset. Under the conditions of different <math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mi id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><ci id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">k</annotation></semantics></math> values, we recorded their performance in Table <a href="#S4.T1" title="TABLE I ‣ IV-C Malicious Nodes ‣ IV Discussion ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.5" class="ltx_p">As can be seen in Table <a href="#S4.T1" title="TABLE I ‣ IV-C Malicious Nodes ‣ IV Discussion ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, with the increase in the proportion of active nodes, the performance of BFLC keeps approaching the effect of the basic FL framework and only has a slight loss compared to the stand-alone training with the intact dataset. We should mention that the BFLC can significantly reduce the consumption of consensus through the committee consensus mechanism. For instance, if the number of training nodes is <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mi id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><ci id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">P</annotation></semantics></math> and the size of the committee is <math id="S5.SS1.p3.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S5.SS1.p3.2.m2.1a"><mi id="S5.SS1.p3.2.m2.1.1" xref="S5.SS1.p3.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.m2.1b"><ci id="S5.SS1.p3.2.m2.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.m2.1c">Q</annotation></semantics></math>, then the active nodes are <math id="S5.SS1.p3.3.m3.1" class="ltx_Math" alttext="P+Q" display="inline"><semantics id="S5.SS1.p3.3.m3.1a"><mrow id="S5.SS1.p3.3.m3.1.1" xref="S5.SS1.p3.3.m3.1.1.cmml"><mi id="S5.SS1.p3.3.m3.1.1.2" xref="S5.SS1.p3.3.m3.1.1.2.cmml">P</mi><mo id="S5.SS1.p3.3.m3.1.1.1" xref="S5.SS1.p3.3.m3.1.1.1.cmml">+</mo><mi id="S5.SS1.p3.3.m3.1.1.3" xref="S5.SS1.p3.3.m3.1.1.3.cmml">Q</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.3.m3.1b"><apply id="S5.SS1.p3.3.m3.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1"><plus id="S5.SS1.p3.3.m3.1.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1.1"></plus><ci id="S5.SS1.p3.3.m3.1.1.2.cmml" xref="S5.SS1.p3.3.m3.1.1.2">𝑃</ci><ci id="S5.SS1.p3.3.m3.1.1.3.cmml" xref="S5.SS1.p3.3.m3.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.3.m3.1c">P+Q</annotation></semantics></math>. For BFLC, the amount of calculation per round of consensus can be expressed as <math id="S5.SS1.p3.4.m4.1" class="ltx_Math" alttext="P\times Q" display="inline"><semantics id="S5.SS1.p3.4.m4.1a"><mrow id="S5.SS1.p3.4.m4.1.1" xref="S5.SS1.p3.4.m4.1.1.cmml"><mi id="S5.SS1.p3.4.m4.1.1.2" xref="S5.SS1.p3.4.m4.1.1.2.cmml">P</mi><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p3.4.m4.1.1.1" xref="S5.SS1.p3.4.m4.1.1.1.cmml">×</mo><mi id="S5.SS1.p3.4.m4.1.1.3" xref="S5.SS1.p3.4.m4.1.1.3.cmml">Q</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.4.m4.1b"><apply id="S5.SS1.p3.4.m4.1.1.cmml" xref="S5.SS1.p3.4.m4.1.1"><times id="S5.SS1.p3.4.m4.1.1.1.cmml" xref="S5.SS1.p3.4.m4.1.1.1"></times><ci id="S5.SS1.p3.4.m4.1.1.2.cmml" xref="S5.SS1.p3.4.m4.1.1.2">𝑃</ci><ci id="S5.SS1.p3.4.m4.1.1.3.cmml" xref="S5.SS1.p3.4.m4.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.4.m4.1c">P\times Q</annotation></semantics></math>, while the broadcasting approach is <math id="S5.SS1.p3.5.m5.1" class="ltx_Math" alttext="(P+Q)^{2}" display="inline"><semantics id="S5.SS1.p3.5.m5.1a"><msup id="S5.SS1.p3.5.m5.1.1" xref="S5.SS1.p3.5.m5.1.1.cmml"><mrow id="S5.SS1.p3.5.m5.1.1.1.1" xref="S5.SS1.p3.5.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.SS1.p3.5.m5.1.1.1.1.2" xref="S5.SS1.p3.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS1.p3.5.m5.1.1.1.1.1" xref="S5.SS1.p3.5.m5.1.1.1.1.1.cmml"><mi id="S5.SS1.p3.5.m5.1.1.1.1.1.2" xref="S5.SS1.p3.5.m5.1.1.1.1.1.2.cmml">P</mi><mo id="S5.SS1.p3.5.m5.1.1.1.1.1.1" xref="S5.SS1.p3.5.m5.1.1.1.1.1.1.cmml">+</mo><mi id="S5.SS1.p3.5.m5.1.1.1.1.1.3" xref="S5.SS1.p3.5.m5.1.1.1.1.1.3.cmml">Q</mi></mrow><mo stretchy="false" id="S5.SS1.p3.5.m5.1.1.1.1.3" xref="S5.SS1.p3.5.m5.1.1.1.1.1.cmml">)</mo></mrow><mn id="S5.SS1.p3.5.m5.1.1.3" xref="S5.SS1.p3.5.m5.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.5.m5.1b"><apply id="S5.SS1.p3.5.m5.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p3.5.m5.1.1.2.cmml" xref="S5.SS1.p3.5.m5.1.1">superscript</csymbol><apply id="S5.SS1.p3.5.m5.1.1.1.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1.1.1"><plus id="S5.SS1.p3.5.m5.1.1.1.1.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1.1.1.1.1"></plus><ci id="S5.SS1.p3.5.m5.1.1.1.1.1.2.cmml" xref="S5.SS1.p3.5.m5.1.1.1.1.1.2">𝑃</ci><ci id="S5.SS1.p3.5.m5.1.1.1.1.1.3.cmml" xref="S5.SS1.p3.5.m5.1.1.1.1.1.3">𝑄</ci></apply><cn type="integer" id="S5.SS1.p3.5.m5.1.1.3.cmml" xref="S5.SS1.p3.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.5.m5.1c">(P+Q)^{2}</annotation></semantics></math>. Compared with stand-alone training, BFLC also has the privacy data protection function of federated learning and does not require a trusted central server to manage, which significantly reduces the risk of privacy leakage.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Under Malicious Attack</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The malicious nodes in the training community will generate harmful updates, which will significantly reduce the performance of the global model if being integrated. In this sub-section, we simulate malicious node attacks to demonstrate how the proposed BFLC, basic FL, and CwMed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> will be affected under different malicious proportions among active nodes. We assume that the attack mode of the malicious node is random perturbation with a pointwise Gaussian random noise.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The basic FL will not perform any defense measures, and model updates generated by randomly selected active nodes will be integrated. CwMed constructs a global gradient, where each entry is the median of entries in the local gradients with the same coordinate. BFLC relies on the committee consensus mentioned above to resist the attack. Each update will obtain a score from the committee (i.e., the median local prediction accuracy).</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">In order to enhance the effectiveness of the attack, we assume that malicious nodes are collusion, that is, members of the malicious committee will give random high scores (for example, 90% 1̃00%) to the malicious updates. The proportion of active nodes is fixed as 10%, and 20% of them will be elected as the committee in the next round. As shown in Figure <a href="#S5.F4" title="Figure 4 ‣ V-B Under Malicious Attack ‣ V Experimental ‣ A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the BFLC can resist much higher malicious nodes proportion than the compared methods. This indicates the effectiveness of BFLC with the help of the committee mechanism.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2004.00773/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="218" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Performance of methods under malicious attacks.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The security of federated learning is facing increasing challenges. Malicious FL training nodes would damage the global model, while a malicious central server can also leak the nodes’ private data. Based on a trusted blockchain system, we propose BFLC, which is a decentralized, federated learning framework exploiting the committee consensus. Such the committee consensus can effectively avoid the influence of malicious central servers or malicious nodes. In the experiment section, we verified the effectiveness of the BFLC framework by adopting the real-world dataset, which can obtain a global model similar to the centralized training in a federated learning framework. We also discussed the scalability of BFLC, which has broad research prospects in security, data storage, and incentive mechanisms.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Acknowledgement</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">The work described in this paper was supported by the National Key Research and Development Program (2016YFB1000101), the National Natural Science Foundation of China (11801595, 61722214), the Natural Science Foundation of Guangdong (2018A030310076, 2019A1515011043) and the CCF-Tencent Open Fund WeBank Special Funding.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Konecný, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving communication
efficiency,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1610.05492, 2016. [Online]. Available:
http://arxiv.org/abs/1610.05492

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P. Ramanan, K. Nakayama, and R. Sharma, “BAFFLE : Blockchain based
aggregator free federated learning,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1909.07452, 2019.
[Online]. Available: http://arxiv.org/abs/1909.07452

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S. Zhou, H. Huang, W. Chen, Z. Zheng, and S. Guo, “PIRATE: A
blockchain-based secure framework of distributed machine learning in 5g
networks,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1912.07860, 2019. [Online]. Available:
http://arxiv.org/abs/1912.07860

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
X. Chen, J. Ji, C. Luo, W. Liao, and P. Li, “When machine learning
meets blockchain: A decentralized, privacy-preserving and secure design,” in
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Big Data (Big Data)</em>, Dec 2018,
pp. 1178–1187.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
I. Hegedüs, G. Danner, and M. Jelasity, “Gossip learning as a
decentralized alternative to federated learning,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Distributed
Applications and Interoperable Systems - 19th IFIP WG 6.1 International
Conference, DAIS 2019, Held as Part of the 14th International Federated
Conference on Distributed Computing Techniques, DisCoTec 2019, Kongens
Lyngby, Denmark, June 17-21, 2019, Proceedings</em>, 2019, pp. 74–90. [Online].
Available: https://doi.org/10.1007/978-3-030-22496-7_5

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C. Hu, J. Jiang, and Z. Wang, “Decentralized federated learning: A segmented
gossip approach,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1908.07782, 2019. [Online].
Available: http://arxiv.org/abs/1908.07782

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
B. Podgorelec, M. Turkanovic, and S. Karakatic, “A machine learning-based
method for automated blockchain transaction signing including personalized
anomaly detection,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20, no. 1, p. 147, 2020. [Online].
Available: https://doi.org/10.3390/s20010147

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. J. Kim and C. S. Hong, “Blockchain-based node-aware dynamic weighting
methods for improving federated learning performance,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">20th
Asia-Pacific Network Operations and Management Symposium, APNOMS 2019,
Matsue, Japan, September 18-20, 2019</em>.   IEEE, 2019, pp. 1–4. [Online]. Available:
https://doi.org/10.23919/APNOMS.2019.8893114

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
U. Majeed and C. S. Hong, “Flchain: Federated learning via mec-enabled
blockchain network,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">20th Asia-Pacific Network Operations and
Management Symposium, APNOMS 2019, Matsue, Japan, September 18-20,
2019</em>.   IEEE, 2019, pp. 1–4.
[Online]. Available: https://doi.org/10.23919/APNOMS.2019.8892848

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu, “Flchain: A blockchain for
auditable federated learning with trust and incentive,” in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">5th
International Conference on Big Data Computing and Communications, BIGCOM
2019, QingDao, China, August 9-11, 2019</em>.   IEEE, 2019, pp. 151–159. [Online]. Available:
https://doi.org/10.1109/BIGCOM.2019.00030

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R. Shokri and V. Shmatikov, “Privacy-preserving deep learning,” in
<em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security, Denver, CO, USA, October 12-16, 2015</em>, I. Ray,
N. Li, and C. Kruegel, Eds.   ACM,
2015, pp. 1310–1321. [Online]. Available:
https://doi.org/10.1145/2810103.2813687

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics, AISTATS 2017, 20-22 April 2017,
Fort Lauderdale, FL, USA</em>, ser. Proceedings of Machine Learning Research,
A. Singh and X. J. Zhu, Eds., vol. 54.   PMLR, 2017, pp. 1273–1282. [Online]. Available:
http://proceedings.mlr.press/v54/mcmahan17a.html

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. Caldas, P. Wu, T. Li, J. Konecný, H. B. McMahan, V. Smith, and
A. Talwalkar, “LEAF: A benchmark for federated settings,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/1812.01097, 2018. [Online]. Available:
http://arxiv.org/abs/1812.01097

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with
deep convolutional neural networks,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol. 60, no. 6,
pp. 84–90, 2017. [Online]. Available:
http://doi.acm.org/10.1145/3065386

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D. Yin, Y. Chen, K. Ramchandran, and P. L. Bartlett, “Byzantine-robust
distributed learning: Towards optimal statistical rates,” in
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 35th International Conference on Machine Learning,
ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018</em>,
ser. Proceedings of Machine Learning Research, J. G. Dy and A. Krause, Eds.,
vol. 80.   PMLR, 2018, pp. 5636–5645.
[Online]. Available: http://proceedings.mlr.press/v80/yin18a.html

</span>
</li>
</ul>
</section>
<figure id="tab1" class="ltx_float biography">
<table id="tab1.1" class="ltx_tabular">
<tr id="tab1.1.1" class="ltx_tr">
<td id="tab1.1.1.1" class="ltx_td">
<span id="tab1.1.1.1.1" class="ltx_inline-block">
<span id="tab1.1.1.1.1.1" class="ltx_p"><span id="tab1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Yuzheng Li</span> 
received the B.S. degrees from the Sun Yat-sen University, Guangdong, China, in 2018. He is currently pursuing an M.S. degree with the School of Data and Computer Science, Sun Yat-sen University. His current research interests include federated learning, blockchain, statistical machine learning, multi-view learning, and optimization.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab2" class="ltx_float biography">
<table id="tab2.1" class="ltx_tabular">
<tr id="tab2.1.1" class="ltx_tr">
<td id="tab2.1.1.1" class="ltx_td">
<span id="tab2.1.1.1.1" class="ltx_inline-block">
<span id="tab2.1.1.1.1.1" class="ltx_p"><span id="tab2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Chuan Chen</span> 
received the B.S. degree from Sun Yat-sen University, Guangzhou, China, in 2012, and the Ph.D. degree from Hong Kong Baptist University, Hong Kong, in 2016. He is currently an Associate Research Fellow with the School of Data and Computer Science, Sun Yat-sen University. His current research interests include blockchain, machine learning, numerical linear algebra, and numerical optimization.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab3" class="ltx_float biography">
<table id="tab3.1" class="ltx_tabular">
<tr id="tab3.1.1" class="ltx_tr">
<td id="tab3.1.1.1" class="ltx_td">
<span id="tab3.1.1.1.1" class="ltx_inline-block">
<span id="tab3.1.1.1.1.1" class="ltx_p"><span id="tab3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Nan Liu</span> 
received the B.S. degree from the Sun Yat-sen University, Guangzhou, China, in 2019. He is currently pursuing an M.S. degree with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China. His research interests include federated learning, blockchain, and network representation learning.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab4" class="ltx_float biography">
<table id="tab4.1" class="ltx_tabular">
<tr id="tab4.1.1" class="ltx_tr">
<td id="tab4.1.1.1" class="ltx_td">
<span id="tab4.1.1.1.1" class="ltx_inline-block">
<span id="tab4.1.1.1.1.1" class="ltx_p"><span id="tab4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Huawei Huang</span> 
received his Ph.D. in Computer Science and Engineering from the University of Aizu, Japan. He is currently an associate professor with the School of Data and Computer Science, Sun Yat-Sen University, China. His research interests mainly include distributed learning and blockchain. He has served as a visiting scholar with the Hong Kong Polytechnic University (2017-2018); a post-doctoral research fellow of JSPS (2016-2018); and an assistant professor with Kyoto University, Japan (2018-2019).</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab5" class="ltx_float biography">
<table id="tab5.1" class="ltx_tabular">
<tr id="tab5.1.1" class="ltx_tr">
<td id="tab5.1.1.1" class="ltx_td">
<span id="tab5.1.1.1.1" class="ltx_inline-block">
<span id="tab5.1.1.1.1.1" class="ltx_p"><span id="tab5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Zibing Zheng</span> 
received his PhD degree from the Chinese University of Hong Kong in 2011. He is currently a professor in the School of Data and Computer Science at Sun Yat-sen University, China. He has published over 120 international journal and conference papers, including three ESI highly cited papers. According to Google Scholar, his papers have more than 9,100 citations, with an II-index of 46. His research interests include blockchain. services computing, software engi­neering, and financial big data.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab6" class="ltx_float biography">
<table id="tab6.1" class="ltx_tabular">
<tr id="tab6.1.1" class="ltx_tr">
<td id="tab6.1.1.1" class="ltx_td">
<span id="tab6.1.1.1.1" class="ltx_inline-block">
<span id="tab6.1.1.1.1.1" class="ltx_p"><span id="tab6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Qiang Yan</span> 
is currently the Blockchain Scientist at WeBank. He received his Ph.D. degree in Information Systems from Singapore Management University in 2013. Before joining WeBank, he was the tech lead of the privacy infrastructure team at Google Switzerland. His research interests include applied security and privacy for blockchain, AI, mobile systems, social networks and more, human factors in security system design, and applied cryptography.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2004.00772" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2004.00773" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2004.00773">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2004.00773" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2004.00774" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 07:41:53 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
