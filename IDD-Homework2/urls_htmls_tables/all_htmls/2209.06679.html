<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2209.06679] Rule-adhering synthetic data - the lingua franca of learning</title><meta property="og:description" content="AI-generated synthetic data allows to distill the general patterns of existing data, that can then be shared safely as granular-level representative, yet novel data samples within the original semantics. In this work w…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Rule-adhering synthetic data - the lingua franca of learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Rule-adhering synthetic data - the lingua franca of learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2209.06679">

<!--Generated on Wed Mar 13 21:51:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Rule-adhering synthetic data - the lingua franca of learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Michael Platzer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:michael.platzer@mostly.ai">michael.platzer@mostly.ai</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">MOSTLY AI</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Vienna</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">Austria</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ivona Krchova
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:ivona.krchova@mostly.ai">ivona.krchova@mostly.ai</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">MOSTLY AI</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Vienna</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">Austria</span>
</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id7.id1" class="ltx_p">AI-generated synthetic data allows to distill the general patterns of existing data, that can then be shared safely as granular-level representative, yet novel data samples within the original semantics. In this work we explore approaches of incorporating domain expertise into the data synthesis, to have the statistical properties as well as pre-existing domain knowledge of rules be represented. The resulting synthetic data generator, that can be probed for any number of new samples, can then serve as a common source of intelligence, as a lingua franca of learning, consumable by humans and machines alike. We demonstrate the concept for a publicly available data set, and evaluate its benefits via descriptive analysis as well as a downstream ML model.</p>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2022</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>; Nov 02, 2022; New York, NY</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Motivation</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">AI has progressed over the past decades from symbolic AI towards a far more capable subsymbolic AI. Whereas the former feeds upon existing domain knowledge on rules and associations, the latter is taught to learn these ”on its own” from existing data. The increase in data, in compute and in model capacity have led to significant breakthroughs, and already allow to exceed human performance on a wide variety of tasks. Analogously, synthetic data has drastically advanced over the past couple of years. While rule-based fake data generators can create an arbitrary number of records, these will only represent the limited knowledge of an expert, that encodes the underlying rules. On the other hand, generative deep neural networks allow to simulate statistically representative, highly realistic, yet truly novel records in a fully automated fashion<cite class="ltx_cite ltx_citemacro_citep">(Karras et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2020</a>; Platzer and Reutterer, <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>. This new breed of AI-powered synthetic data generators is built to distill the insights of existing data, to detect rules and associations that generalize beyond the individual record, to then encode the retained information in the form of new data samples. And with the synthetic data being represented with the same semantics as the original data, this intelligence can be consumed, processed and learned from by people of all backgrounds (policy makers, business managers, data scientists, end users, advocacy groups, etc.). E.g., a fictional record that represents the case of a 38-year old single mother with 3 children, who earns a minimum salary while she pays back an outstanding housing loan of $120k, can easily be reasoned upon with and without an education in statistics. Thus, synthetic data can serve as a <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">lingua franca</span>, as a common language, of learning, for humans as well as for machines alike, as it allows to share the patterns and the diversity of a population via an unlimited number of representative samples, all without infringing anyone’s privacy.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">A key emerging trend in AI is the marriage of symbolic and subsymbolic AI into a hybrid neurosymbolic AI, that makes best use of both approaches, by learning from existing data as well as from existing domain expertise. It is motivated by the need to become more data efficient, and to generalize well into sparse areas of the data space. In particular, for rare yet high impact cases, like fraud, defects or accidents, practitioners seek to gain more confidence in spotting and understanding these. In a similar vein, we demonstrate with this paper the concept of <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">rule-adhering synthetic data</span>. AI-generated synthetic data that can both learn from data as well as from rules, and can thus provide insights and confidence with respect to otherwise sparsely populated data regions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Concept</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.3" class="ltx_p">Domain expertise can take various forms, ranging from exact relations (<math id="S2.p1.1.m1.1" class="ltx_Math" alttext="a+b=c" display="inline"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mrow id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml"><mi id="S2.p1.1.m1.1.1.2.2" xref="S2.p1.1.m1.1.1.2.2.cmml">a</mi><mo id="S2.p1.1.m1.1.1.2.1" xref="S2.p1.1.m1.1.1.2.1.cmml">+</mo><mi id="S2.p1.1.m1.1.1.2.3" xref="S2.p1.1.m1.1.1.2.3.cmml">b</mi></mrow><mo id="S2.p1.1.m1.1.1.1" xref="S2.p1.1.m1.1.1.1.cmml">=</mo><mi id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><eq id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1"></eq><apply id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2"><plus id="S2.p1.1.m1.1.1.2.1.cmml" xref="S2.p1.1.m1.1.1.2.1"></plus><ci id="S2.p1.1.m1.1.1.2.2.cmml" xref="S2.p1.1.m1.1.1.2.2">𝑎</ci><ci id="S2.p1.1.m1.1.1.2.3.cmml" xref="S2.p1.1.m1.1.1.2.3">𝑏</ci></apply><ci id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">a+b=c</annotation></semantics></math>), to constraints (<math id="S2.p1.2.m2.1" class="ltx_Math" alttext="\texttt{deathYear}&gt;=\texttt{birthYear}" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2a.cmml">deathYear</mtext><mo lspace="0.278em" rspace="0.278em" id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">&gt;=</mo><mtext class="ltx_mathvariant_monospace" id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3a.cmml">birthYear</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><geq id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></geq><ci id="S2.p1.2.m2.1.1.2a.cmml" xref="S2.p1.2.m2.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">deathYear</mtext></ci><ci id="S2.p1.2.m2.1.1.3a.cmml" xref="S2.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">birthYear</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\texttt{deathYear}&gt;=\texttt{birthYear}</annotation></semantics></math>), to priors (<math id="S2.p1.3.m3.2" class="ltx_Math" alttext="x\sim N(0,1)" display="inline"><semantics id="S2.p1.3.m3.2a"><mrow id="S2.p1.3.m3.2.3" xref="S2.p1.3.m3.2.3.cmml"><mi id="S2.p1.3.m3.2.3.2" xref="S2.p1.3.m3.2.3.2.cmml">x</mi><mo id="S2.p1.3.m3.2.3.1" xref="S2.p1.3.m3.2.3.1.cmml">∼</mo><mrow id="S2.p1.3.m3.2.3.3" xref="S2.p1.3.m3.2.3.3.cmml"><mi id="S2.p1.3.m3.2.3.3.2" xref="S2.p1.3.m3.2.3.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.p1.3.m3.2.3.3.1" xref="S2.p1.3.m3.2.3.3.1.cmml">​</mo><mrow id="S2.p1.3.m3.2.3.3.3.2" xref="S2.p1.3.m3.2.3.3.3.1.cmml"><mo stretchy="false" id="S2.p1.3.m3.2.3.3.3.2.1" xref="S2.p1.3.m3.2.3.3.3.1.cmml">(</mo><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">0</mn><mo id="S2.p1.3.m3.2.3.3.3.2.2" xref="S2.p1.3.m3.2.3.3.3.1.cmml">,</mo><mn id="S2.p1.3.m3.2.2" xref="S2.p1.3.m3.2.2.cmml">1</mn><mo stretchy="false" id="S2.p1.3.m3.2.3.3.3.2.3" xref="S2.p1.3.m3.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.2b"><apply id="S2.p1.3.m3.2.3.cmml" xref="S2.p1.3.m3.2.3"><csymbol cd="latexml" id="S2.p1.3.m3.2.3.1.cmml" xref="S2.p1.3.m3.2.3.1">similar-to</csymbol><ci id="S2.p1.3.m3.2.3.2.cmml" xref="S2.p1.3.m3.2.3.2">𝑥</ci><apply id="S2.p1.3.m3.2.3.3.cmml" xref="S2.p1.3.m3.2.3.3"><times id="S2.p1.3.m3.2.3.3.1.cmml" xref="S2.p1.3.m3.2.3.3.1"></times><ci id="S2.p1.3.m3.2.3.3.2.cmml" xref="S2.p1.3.m3.2.3.3.2">𝑁</ci><interval closure="open" id="S2.p1.3.m3.2.3.3.3.1.cmml" xref="S2.p1.3.m3.2.3.3.3.2"><cn type="integer" id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">0</cn><cn type="integer" id="S2.p1.3.m3.2.2.cmml" xref="S2.p1.3.m3.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.2c">x\sim N(0,1)</annotation></semantics></math>), and so forth. In this work we focus on hard constraints for categorical attributes, where a domain expert knows that certain combinations of attribute values are impossible to occur. Given sufficient amount of training data, a machine learning model is expected to pick up the non-occurrence of such combinations, and thus assign already a low probability to it. However, without any additional information, neither a human nor the learning algorithm can conclude whether a given combination is indeed impossible, or just so rare, that it hasn’t yet been observed in the training data.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In order to incorporate the knowledge on impossible combinations into synthetic data, we pursue two approaches:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Rules for training: add a rule-specific training loss component to penalize assigning any non-zero probability to invalid areas of the data space<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>See <cite class="ltx_cite ltx_citemacro_citep">(Seo et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> or <cite class="ltx_cite ltx_citemacro_citep">(Tiwald et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite> for models, where additional loss components are being added to the training objective.</span></span></span>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Rules for sampling: set the probability of invalid areas of the data space to zero during the sampling phase<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>See <cite class="ltx_cite ltx_citemacro_citep">(Holtzman et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> for an example, where probabilities of a generative model are being manipulated during sampling.</span></span></span>.</p>
</div>
</li>
</ol>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">While the former impacts the learning of the generative model, the latter only applies to the sampling from an already trained model. On the other hand, while the former reduces the likelihood of invalid records, which itself depends on the relative weight of the additional loss component, it is only the latter that strictly rules these out.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">We explore both approaches, as well as a combination of these. We do so by extending the underlying model of a commercial solution provider for structured synthetic data<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>MOSTLY AI, <a target="_blank" href="https://mostly.ai/" title="" class="ltx_ref ltx_href">https://mostly.ai/</a></span></span></span>. All generated data sets, as well as the corresponding analysis, are made available at <a target="_blank" href="https://github.com/mostly-ai/paper-rule-adherence" title="" class="ltx_ref ltx_href">https://github.com/mostly-ai/paper-rule-adherence</a>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Demonstration</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To demonstrate the aforementioned approaches we will generate rule-adhering synthetic versions of the <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">Census Income</span>, also known as <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">adult</span>, data set, that is obtained from the UCI Machine Learning repository <cite class="ltx_cite ltx_citemacro_citep">(Dua and Graff, <a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite>. This is a widely studied, tabular data set, consisting of 48,842 records across a range of mixed-type variables. Figure <a href="#S3.F1" title="Figure 1 ‣ 3. Demonstration ‣ Rule-adhering synthetic data - the lingua franca of learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows a selection of attributes for a random sample of records.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2209.06679/assets/adult_sample.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="320" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Sample records for the Census Income data set</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Exploring the data set reveals a handful of rules / constraints, that seem to be in place:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">If the <span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">education</span> level is either <span id="S3.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">Doctorate</span> or <span id="S3.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">Prof-school</span>, then the person is at least 25 years old.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">If the relationship status is either <span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Husband</span> or <span id="S3.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">Wife</span>, then the marital status is always <span id="S3.I1.i2.p1.1.3" class="ltx_text ltx_font_italic">Married-civ-spouse</span>. On the other hand, if the marital status is <span id="S3.I1.i2.p1.1.4" class="ltx_text ltx_font_italic">Married-civ-spouse</span>, then the relationship status cannot be <span id="S3.I1.i2.p1.1.5" class="ltx_text ltx_font_italic">Unmarried</span>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">The attributes <span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">education</span> and <span id="S3.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">education-num</span> exhibit a strict 1:1 relationship and thus represent identical information.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">If <span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">relationship</span> is <span id="S3.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">Wife</span>, then the person is <span id="S3.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">female</span>, if it is <span id="S3.I1.i4.p1.1.4" class="ltx_text ltx_font_italic">Husband</span> then the <span id="S3.I1.i4.p1.1.5" class="ltx_text ltx_font_italic">sex</span> is <span id="S3.I1.i4.p1.1.6" class="ltx_text ltx_font_italic">male<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><span id="footnote4.5" class="ltx_text ltx_font_upright">Actually, this ”rule” is violated in 4 cases within the original data set. Hence, male wives and female husbands are seemingly possible, yet very very rare. Whether they then occur or not, then highly depends on the size of the actual sample that is being made available.</span></span></span></span></span>.</p>
</div>
</li>
</ol>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Let’s consider that rules (1), (2), (3) and (4) are all valid, and shall be respected within the generated synthetic data. Let’s further assume that we only have access to a small subset of 2,000 records. In order to share the knowledge of this data as well as the existing rules, we proceed with training a generative model on top of these samples, to then create 100,000 novel, rule-adhering synthetic records. For comparison, we do this once by incorporating rules into the learning phase, once into the sampling phase, and once by combining both of the approaches at the same time. In addition, we compare this to a synthetic data set, that is being generated without any explicit knowledge of these four rules.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2209.06679/assets/adult_age.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="490" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Rule (1) for <span id="S3.F2.3.1" class="ltx_text ltx_font_italic">age</span> vs. <span id="S3.F2.4.2" class="ltx_text ltx_font_italic">education</span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2209.06679/assets/adult_relationship.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="490" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Rule (2) for <span id="S3.F3.3.1" class="ltx_text ltx_font_italic">marital-status</span> vs. <span id="S3.F3.4.2" class="ltx_text ltx_font_italic">relationship</span></figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2209.06679/assets/adult_education.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="490" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Rule (3) for <span id="S3.F4.3.1" class="ltx_text ltx_font_italic">education</span> vs. <span id="S3.F4.4.2" class="ltx_text ltx_font_italic">education-num</span></figcaption>
</figure>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2209.06679/assets/adult_gender.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="490" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Rule (4) for <span id="S3.F5.3.1" class="ltx_text ltx_font_italic">relationship</span> vs. <span id="S3.F5.4.2" class="ltx_text ltx_font_italic">sex</span></figcaption>
</figure>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">Figures <a href="#S3.F2" title="Figure 2 ‣ 3. Demonstration ‣ Rule-adhering synthetic data - the lingua franca of learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#S3.F3" title="Figure 3 ‣ 3. Demonstration ‣ Rule-adhering synthetic data - the lingua franca of learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S3.F4" title="Figure 4 ‣ 3. Demonstration ‣ Rule-adhering synthetic data - the lingua franca of learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#S3.F5" title="Figure 5 ‣ 3. Demonstration ‣ Rule-adhering synthetic data - the lingua franca of learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> display the resulting contingency tables across these experiments for each of the corresponding four rules. As one can see, the synthetic data, that doesn’t explicitly know about the rules already successfully picks up and retains the signal that these combinations (highlighted in red) are rare. The average share, measured across 10 independent repeats of the experiments, of invalid records for each of the four rules is (1) 0.1%, (2) 1.6%, (3) 0.07% and (4) 0.06%. Adding the additional loss components during training, then indeed further reduces the likelihood of such invalid records to occur to (1) 0.01%, (2) 0.8%, (3) 0.02% and (4) 0.003%. Alternatively, if we enforce the rules during sampling, by setting the probabilities of invalid combinations to zero, we can effectively yield perfectly rule-adhering synthetic data. Given the much larger amount of 100k synthetic records that is being generated, these rule-adhering data sets allow any downstream consumers to infer with much greater confidence that these rules are indeed valid, when compared to an analysis that is purely informed by the original data sample of 2,000 records.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Let’s also assess the impact of replacing original data with synthetic data on a downstream machine learning task. For that, we pursue a train-synthetic-test-real (<span id="S3.p5.1.1" class="ltx_text ltx_font_italic">TSTR</span>) evaluation scheme <cite class="ltx_cite ltx_citemacro_citep">(Esteban et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite>, and measure model performance on the remaining 46,842 holdout records, that were not part of the 2,000 sampled records, and thus also not used for the data synthesis. We then train a gradient boosting classifier<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>This model class was selected, as it provided the strongest out-of-the-box performance among the available sklearn models <cite class="ltx_cite ltx_citemacro_citep">(Pedregosa et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2011</a>)</cite> for the given task.</span></span></span> to predict whether a person has a high <span id="S3.p5.1.2" class="ltx_text ltx_font_italic">income</span> or not. The corresponding AUCs across 10 separate runs are reported in figure <a href="#S3.F6" title="Figure 6 ‣ 3. Demonstration ‣ Rule-adhering synthetic data - the lingua franca of learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. As we can see, the 100,000 synthetic samples, that do not explicitly consider the rules, already yield a higher predictive performance than the original data set of 2,000 sample. Thus, for the given scenario, the generative model is a stronger learner, and can teach the downstream model by providing a large amount of diverse, yet representative synthetic samples. The incorporation of rules then does neither harm nor improve the results with respect to the learning task. We assume that this is due to the small share of invalid records in the first place, and secondly, that the predictive task at hand likely does not depend on the rule-related signals.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2209.06679/assets/adult_aucs.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Model performance on the (original) holdout data</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Conclusions</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We have demonstrated the concept of rule-adhering synthetic data, and shown that it is possible to incorporate pre-existing knowledge on invalid combinations into the synthesis process. For the selected data set and the four presented rules, the rule adherence is significantly improved by adding rule-specific loss components to the training phase. Further, the rules can be perfectly satisfied by considering these during the sampling phase. The theoretically unlimited amount of rule-adhering synthetic data can then be used for any downstream data consumers, humans as well as algorithms alike, to learn the statistical information of the original data, as well as the rules by domain experts. We hope that these findings motivate further research and explorations of use cases for <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">rule-adhering synthetic data</span>, as it shows promise to serve as a <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">lingua franca</span> of learning.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann,
Nick Ryder, Melanie Subbiah,
Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
et al<span id="bib.bib2.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.4.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 33 (2020),
1877–1901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua and Graff (2017)</span>
<span class="ltx_bibblock">
Dheeru Dua and Casey
Graff. 2017.

</span>
<span class="ltx_bibblock">UCI Machine Learning Repository.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://archive.ics.uci.edu/ml" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://archive.ics.uci.edu/ml</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esteban et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Cristóbal Esteban,
Stephanie L Hyland, and Gunnar
Rätsch. 2017.

</span>
<span class="ltx_bibblock">Real-valued (medical) time series generation with
recurrent conditional gans.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.02633</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holtzman et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ari Holtzman, Jan Buys,
Li Du, Maxwell Forbes, and
Yejin Choi. 2019.

</span>
<span class="ltx_bibblock">The curious case of neural text degeneration.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.09751</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Tero Karras, Timo Aila,
Samuli Laine, and Jaakko Lehtinen.
2017.

</span>
<span class="ltx_bibblock">Progressive growing of gans for improved quality,
stability, and variation.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.10196</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedregosa et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Fabian Pedregosa, Gaël
Varoquaux, Alexandre Gramfort, Vincent
Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter
Prettenhofer, Ron Weiss, Vincent
Dubourg, et al<span id="bib.bib7.3.1" class="ltx_text">.</span> 2011.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine learning in Python.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.4.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>
12, Oct (2011),
2825–2830.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Platzer and Reutterer (2021)</span>
<span class="ltx_bibblock">
Michael Platzer and
Thomas Reutterer. 2021.

</span>
<span class="ltx_bibblock">Holdout-based empirical assessment of mixed-type
synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Frontiers in big Data</em>
(2021), 43.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seo et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sungyong Seo, Sercan
Arik, Jinsung Yoon, Xiang Zhang,
Kihyuk Sohn, and Tomas Pfister.
2021.

</span>
<span class="ltx_bibblock">Controlling neural networks with rule
representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021),
11196–11207.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiwald et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Paul Tiwald, Alexandra
Ebert, and Daniel T Soukup.
2021.

</span>
<span class="ltx_bibblock">Representative &amp; fair synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.03007</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2209.06678" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2209.06679" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2209.06679">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2209.06679" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2209.06680" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 21:51:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
