<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  How susceptible are LLMs to Logical Fallacies?
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Amirreza Payandeh
    <sup class="ltx_sup" id="id1.1.id1">
     1
    </sup>
    ,
Dan Pluth
    <sup class="ltx_sup" id="id2.2.id2">
     2
    </sup>
    , Jordan Hosier
    <sup class="ltx_sup" id="id3.3.id3">
     2
    </sup>
    , Xuesu Xiao
    <sup class="ltx_sup" id="id4.4.id4">
     1
    </sup>
    , Vijay K. Gurbani
    <sup class="ltx_sup" id="id5.5.id5">
     2
    </sup>
   </span>
   <span class="ltx_author_notes">
    Corresponding author.Work done during an internship at Vail Systems, Inc.
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id6.id1">
   This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates by exploring the impact of fallacious arguments on their logical reasoning performance.
More specifically, we present
   <span class="ltx_text ltx_font_bold" id="id6.id1.1">
    Logi
   </span>
   c
   <span class="ltx_text ltx_font_bold" id="id6.id1.2">
    Co
   </span>
   mpetence
   <span class="ltx_text ltx_font_bold" id="id6.id1.3">
    M
   </span>
   easurement Benchmark (
   <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="id6.id1.4">
    logicom
   </span>
   ), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies.
   <span class="ltx_text ltx_font_smallcaps" id="id6.id1.5">
    logicom
   </span>
   involves two agents: a persuader and a debater engaging in a multi-round debate on a controversial topic, where the persuader tries to convince the debater of the correctness of its claim. First,
   <span class="ltx_text ltx_font_smallcaps" id="id6.id1.6">
    logicom
   </span>
   assesses the potential of LLMs to change their opinions through reasoning. Then, it evaluates the debater’s performance in logical reasoning by contrasting the scenario where the persuader employs logical fallacies against one where logical reasoning is used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4 using a dataset containing controversial topics, claims, and reasons supporting them. Our findings indicate that both GPT-3.5 and GPT-4 can adjust their opinion through reasoning. However, when presented with logical fallacies, GPT-3.5 and GPT-4 are erroneously convinced 41% and 69% more often, respectively, compared to when logical reasoning is used.
Finally, we introduce a new dataset containing over 5k pairs of logical vs. fallacious arguments.
The source code and dataset of this work are made publicly available.
   <span class="ltx_note ltx_role_footnote" id="footnote1">
    <sup class="ltx_note_mark">
     1
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_tag ltx_tag_note">
       1
      </span>
      Our code base is available at:
      <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">
       https://github.com/Amir-pyh/LOGICOM
      </span>
     </span>
    </span>
   </span>
  </p>
 </div>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Introduction
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    Recently, Large Language Models (LLMs) have achieved remarkable success in a range of natural language processing (NLP) downstream tasks
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhao et al.
     <a class="ltx_ref" href="#bib.bib33" title="">
      2023
     </a>
     )
    </cite>
    . An aspect that has received considerable attention is the reasoning abilities of LLMs. NLP researchers have extensively investigated their arithmetic reasoning capacities
    <cite class="ltx_cite ltx_citemacro_citep">
     (Xu et al.
     <a class="ltx_ref" href="#bib.bib30" title="">
      2023
     </a>
     )
    </cite>
    and devoted significant effort to improve this ability
    <cite class="ltx_cite ltx_citemacro_citep">
     (Imani, Du, and Shrivastava
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     ; Wei et al.
     <a class="ltx_ref" href="#bib.bib29" title="">
      2023
     </a>
     )
    </cite>
    .
Researchers have also evaluated the accuracy of LLMs’ answers in non-mathematical
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lin, Hilton, and Evans
     <a class="ltx_ref" href="#bib.bib15" title="">
      2022
     </a>
     )
    </cite>
    and commonsense questions
    <cite class="ltx_cite ltx_citemacro_citep">
     (Bian et al.
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    . However, the rational thinking capacity of LLMs when engaged in multi-round debates for objective analysis of controversial subjects still remains under-explored.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p2">
   <p class="ltx_p" id="Sx1.p2.1">
    Human logical reasoning skills arise from the cognitive abilities, they develop through active interaction with the world. This skill can be influenced by various factors such as context and emotion
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jung et al.
     <a class="ltx_ref" href="#bib.bib11" title="">
      2014
     </a>
     )
    </cite>
    and
    <em class="ltx_emph ltx_font_italic" id="Sx1.p2.1.1">
     evolves
    </em>
    over time. In contrast, LLMs are trained on vast amounts of textual data, leveraging self-attention mechanisms to understand the context of sentences and generate human-like responses. Compared to their human counterparts, two Research Questions (RQs) regarding LLMs’ logical reasoning capabilities naturally arise:
   </p>
  </div>
  <figure class="ltx_figure" id="Sx1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="279" id="Sx1.F1.g1" src="/html/2308.09853/assets/content/image/LOGICOM-LARGE.png" width="698"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="Sx1.F1.2.1">
     logicom
    </span>
    : A demonstration of three scenarios evaluating LLMs’ reasoning skills and vulnerability to logical fallacies.
   </figcaption>
  </figure>
  <div class="ltx_para" id="Sx1.p3">
   <ul class="ltx_itemize" id="Sx1.I1">
    <li class="ltx_item" id="Sx1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx1.I1.i1.p1">
      <p class="ltx_p" id="Sx1.I1.i1.p1.1">
       RQ1: Can large language models (with fixed weights)
       <em class="ltx_emph ltx_font_italic" id="Sx1.I1.i1.p1.1.1">
        change
       </em>
       their opinions through reasoning when faced with new arguments?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="Sx1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx1.I1.i2.p1">
      <p class="ltx_p" id="Sx1.I1.i2.p1.1">
       RQ2:Are large language models susceptible to fallacious reasoning?
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="Sx1.p4">
   <p class="ltx_p" id="Sx1.p4.1">
    To answer these two RQs, we propose
    <span class="ltx_text ltx_font_smallcaps" id="Sx1.p4.1.1">
     logicom
    </span>
    , a novel diagnostic benchmark to check the potential for change in the logical reasoning of LLMs and to assess their robustness against logical fallacies.
    <span class="ltx_text ltx_font_smallcaps" id="Sx1.p4.1.2">
     logicom
    </span>
    initiates two agents, a persuader and a debater, to engage in a debate on a controversial topic. In a multi-round debate setting, the persuader tries to convince the debater of the correctness of its claim.
At the end of the debate, it is determined whether the debater agent agrees or disagrees with the claim.
For each claim, we conduct two distinct scenarios: (1) the persuader employs logical reasoning and (2) the persuader constructs a deceptive and fallacious argumentative response. By comparing the results of the two scenarios, we investigate if the debater agent is convinced by the persuader’s fallacious argument or not. Given that a lengthy system prompt is needed to make an LLM fallacious, which has the risk of distracting the model from the main task of persuasive debating, we employ a distinct LLM agent, calling it the
    <em class="ltx_emph ltx_font_italic" id="Sx1.p4.1.3">
     fallacious helper agent
    </em>
    , to assist the persuader agent in constructing fallacious arguments in the second scenario. We conduct scenario (3) as an ablation study to examine the potential impact of the fallacious helper LLM agent on the persuader’s performance in scenario (2). In the third scenario, the persuader receives help from an LLM agent that provides logical argumentative feedback rather than fallacious one. This is to ensure that any shifts in the persuader’s persuasiveness in scenario (2) are not simply caused by the existence of a helper agent alone but by fallacious reasoning.
To demonstrate the effectiveness of our approach in assessing the rational thinking capability of LLMs, we conduct an experiment using a dataset
    <cite class="ltx_cite ltx_citemacro_citep">
     (Habernal et al.
     <a class="ltx_ref" href="#bib.bib6" title="">
      2018a
     </a>
     )
    </cite>
    containing 200 distinct claims and counter-claims about debatable subjects, along with their corresponding supporting reasons. In this study, we examine the capabilities of GPT-3.5
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI
     <a class="ltx_ref" href="#bib.bib17" title="">
      2023a
     </a>
     )
    </cite>
    and GPT-4
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI
     <a class="ltx_ref" href="#bib.bib18" title="">
      2023b
     </a>
     )
    </cite>
    in changing their opinions through reasoning. Additionally, we determine if they are susceptible to logical fallacies as the debater agent. Moreover, we propose a new dataset containing over 5k pairs of logical and fallacious arguments extracted from our experiment’s output, and we validate the labels for each pair using PaLM
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chowdhery et al.
     <a class="ltx_ref" href="#bib.bib2" title="">
      2022
     </a>
     )
    </cite>
    LLM.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p5">
   <p class="ltx_p" id="Sx1.p5.1">
    Our research reveals evidence of change in reasoning, and consequently, shift in the final opinion on a subject for both GPT-3.5 and GPT-4. Furthermore, our findings indicate that GPT-3.5 and GPT-4 are 41% and 69% more likely, respectively, to be convinced when exposed to logical fallacies compared to when they encounter logical reasoning.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p6">
   <p class="ltx_p" id="Sx1.p6.1">
    In summary, our main contributions are:
   </p>
   <ul class="ltx_itemize" id="Sx1.I2">
    <li class="ltx_item" id="Sx1.I2.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx1.I2.i1.p1">
      <p class="ltx_p" id="Sx1.I2.i1.p1.1">
       <span class="ltx_text ltx_font_smallcaps" id="Sx1.I2.i1.p1.1.1">
        logicom
       </span>
       , a novel benchmark to assess LLMs’ susceptibility to logical fallacies and to be used for the development and analysis of these models.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="Sx1.I2.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx1.I2.i2.p1">
      <p class="ltx_p" id="Sx1.I2.i2.p1.1">
       An extensive analysis of GPT-3.5 and GPT-4 reasoning performance against logical fallacies during a multi-round debate. Our findings demonstrate that GPT models are able to change their reasoning; however, these changes are not robust against logical fallacies.
Figure
       <a class="ltx_ref" href="#Sx3.F2" title="Figure 2 ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
        <span class="ltx_text ltx_ref_tag">
         2
        </span>
       </a>
       showcases a segment of the GPT-3.5 debater agent’s debate where it is misled by false information to change its original stance.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="Sx1.I2.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx1.I2.i3.p1">
      <p class="ltx_p" id="Sx1.I2.i3.p1.1">
       A new dataset of 5K pairs of logical and fallacious arguments derived from multi-round debates on 200 claims.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="Sx2">
  <h2 class="ltx_title ltx_title_section">
   Related Work
  </h2>
  <div class="ltx_para" id="Sx2.p1">
   <p class="ltx_p" id="Sx2.p1.1">
    Large language models (LLMs) have been shown to exhibit a range of reasoning abilities, such as arithmetic
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lewkowycz et al.
     <a class="ltx_ref" href="#bib.bib14" title="">
      2022
     </a>
     )
    </cite>
    , common sense
    <cite class="ltx_cite ltx_citemacro_citep">
     (Bian et al.
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    , symbolic
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhou et al.
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023
     </a>
     )
    </cite>
    , and analogical reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Webb, Holyoak, and Lu
     <a class="ltx_ref" href="#bib.bib27" title="">
      2023
     </a>
     )
    </cite>
    . Substantial efforts have been devoted to leveraging these abilities
    <cite class="ltx_cite ltx_citemacro_citep">
     (Pan et al.
     <a class="ltx_ref" href="#bib.bib19" title="">
      2023
     </a>
     )
    </cite>
    . Notably, the chain of thought (CoT) approach has demonstrated improvement in reasoning skills when LLMs are given a manual prompt explaining intermediate reasoning steps
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.
     <a class="ltx_ref" href="#bib.bib28" title="">
      2022
     </a>
     )
    </cite>
    . Building on the CoT framework, several advanced improvements have been proposed
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kojima et al.
     <a class="ltx_ref" href="#bib.bib13" title="">
      2022
     </a>
     ; Fu et al.
     <a class="ltx_ref" href="#bib.bib4" title="">
      2023a
     </a>
     )
    </cite>
    . Nonetheless, studies have indicated that these models often struggle with tasks requiring multi-stage reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Valmeekam et al.
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     )
    </cite>
    .
Despite the widespread use and deployment of LLMs as conversational agents and numerous analyses of them, there have been limited evaluations of their capacity for rational thinking in non-arithmetic subjects, particularly in multi-round debates.
As part of the Big Bench comprehensive study on LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Srivastava et al.
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     )
    </cite>
    , their capability in deceiving each other to change their opinions on non-arithmetic questions is measured. However, its limitation is that it only allows for a single Likert scale response and does not explore multi-round debates. Moreover, it does not consider the stochastic nature of the model’s output, requiring extensive repetitions to assure statistical significance. Our research addresses these gaps by comprehensively analyzing the rational thinking of LLMs during multi-round debates and the potential variations in their responses.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx3">
  <h2 class="ltx_title ltx_title_section">
   Benchmark Methodology
  </h2>
  <figure class="ltx_figure" id="Sx3.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="Sx3.F2.g1" src="/html/2308.09853/assets/content/image/chats-GPT3.png" width="698"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    The GPT-3.5 debater agent’s debate showing its susceptibility to logical fallacies and shifting its opinions on false information.
   </figcaption>
  </figure>
  <div class="ltx_para" id="Sx3.p1">
   <p class="ltx_p" id="Sx3.p1.1">
    This work introduces Logic Competence Measurement
    <span class="ltx_text ltx_font_smallcaps" id="Sx3.p1.1.1">
     (logicom)
    </span>
    , a benchmark to investigate if LLMs change their logical reasoning, and if so, to what extent their final stance on a subject is vulnerable to being influenced by logical fallacies. Figure
    <a class="ltx_ref" href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ How susceptible are LLMs to Logical Fallacies?">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    demonstrates an overview of
    <span class="ltx_text ltx_font_smallcaps" id="Sx3.p1.1.2">
     logicom
    </span>
    .
    <br class="ltx_break"/>
    Identifying a change in an LLM’s reasoning behavior in non-arithmetic subjects can be challenging. One method to detect this is by using polarizing questions to observe if the model’s position shifts from one side to another. We ask the model to either agree or disagree with a polarizing claim, and then, over multiple rounds of debate, attempt to alter its stance. If successful, this can indicate the model’s ability to change its opinion through reasoning in a multi-round debate.
Unlike arithmetic questions, which have a provably correct answer, assessing the accuracy of LLMs’ reasoning on controversial subjects is challenging. This difficulty originates from the absence of a standard evaluation metric, due to its non-numerical nature, and the lack of a universally agreed upon “correct” stance.
Given these constraints, we assess the rational thinking of LLMs in relation to logical fallacies by comparing their behavior before and after encountering fallacious reasoning. We consider situations in which the model shifts its opinion on a claim in response to logical fallacies, viewing such instances as an indicator of vulnerability in the model.
   </p>
  </div>
  <section class="ltx_subsection" id="Sx3.SSx1">
   <h3 class="ltx_title ltx_title_subsection">
    Test Cases
   </h3>
   <div class="ltx_para" id="Sx3.SSx1.p1">
    <p class="ltx_p" id="Sx3.SSx1.p1.1">
     In essence, we conduct three scenarios for each claim:
    </p>
    <ul class="ltx_itemize" id="Sx3.I3">
     <li class="ltx_item" id="Sx3.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="Sx3.I3.i1.p1">
       <p class="ltx_p" id="Sx3.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="Sx3.I3.i1.p1.1.1">
         No Helper
         <em class="ltx_emph ltx_font_italic" id="Sx3.I3.i1.p1.1.1.1">
          (scenario one)
         </em>
        </span>
        : The persuader and debater engage in a regular discussion where the persuader attempts to convince the debater with logical reasoning.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="Sx3.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="Sx3.I3.i2.p1">
       <p class="ltx_p" id="Sx3.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="Sx3.I3.i2.p1.1.1">
         Fallacious Helper
         <em class="ltx_emph ltx_font_italic" id="Sx3.I3.i2.p1.1.1.1">
          (scenario two)
         </em>
        </span>
        : A fallacious helper LLM provides assistance to the persuader in crafting deceptive and fallacious argumentative responses.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="Sx3.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="Sx3.I3.i3.p1">
       <p class="ltx_p" id="Sx3.I3.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="Sx3.I3.i3.p1.1.1">
         Logical Helper
         <em class="ltx_emph ltx_font_italic" id="Sx3.I3.i3.p1.1.1.1">
          (scenario three)
         </em>
        </span>
        : The persuader receives fair and reasonable feedback from a logical helper LLM agent and crafts a non-fallacious response to support its claim. This is an ablation study to investigate the potential impact of a helper model.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="Sx3.SSx1.p2">
    <p class="ltx_p" id="Sx3.SSx1.p2.1">
     Our goal is to maintain consistency in the agents’ performance during the debate and minimize the impact of anything other than the logical reasoning power of the agent on the debate’s outcome. We observe that when the length of the system prompt increases, the agent does not consistently adhere to the task described in the prompt, which can impact its performance. This is likely to occur in scenario (2), where the persuader agent is asked to generate fallacious arguments, requiring a longer system prompt and affecting the performance compared with scenario one, where persuader don’t employ fallacious arguments.
To address this concern, we use a consistent prompt for the persuader (Figure
     <a class="ltx_ref" href="#Sx3.F5" title="Figure 5 ‣ Debate ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     ) across all scenarios, and for scenario (2), the persuader constructs arguments containing logical fallacies with the assistance of the fallacy helper LLM agent.
In scenarios involving the helper model, the persuader drafts a response and forwards it to the helper model. The helper model then revises this response based on its own prompt, and the persuader subsequently adopts the revised response to engage in a debate with the debater agent.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx2">
   <h3 class="ltx_title ltx_title_subsection">
    Moderators
   </h3>
   <div class="ltx_para" id="Sx3.SSx2.p1">
    <p class="ltx_p" id="Sx3.SSx2.p1.1">
     The discussion flow is controlled by a master moderator LLM agent and three subordinate moderators. To ensure accuracy, we dedicate a separate moderator for each of the three moderation tasks:
(1) checking if the debater is convinced of the claim,
(2) maintaining the focus of the debate on the topic,
and (3) preventing agents from getting stuck in a pleasantries loop. Each dialogue between the persuader and debater forms one round of debate.
After each round of the debate, the full debate history is passed to the master moderator agent. The moderator agent delegates the relevant portions of the discussion to the respective subordinate moderator. Finally, based on the subordinates’ moderation task results, the master moderator makes the decision whether to terminate or continue the debate. At the end of each debate, the moderator checks the debater’s final stance on the claim made by the persuader.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx3">
   <h3 class="ltx_title ltx_title_subsection">
    Fallacious Helper
   </h3>
   <div class="ltx_para" id="Sx3.SSx3.p1">
    <p class="ltx_p" id="Sx3.SSx3.p1.1">
     To prevent the effects of lengthy prompts on the agent’s performance, we’ve separated crafting fallacious arguments from the persuader agent’s tasks.
We use a separate LLM model acting as a fallacious helper to: 1) determine the best type of logical fallacy based on debate history, and
2) create a fallacious argument in response to the debater agent’s argument.
Figure
     <a class="ltx_ref" href="#Sx3.F3" title="Figure 3 ‣ Fallacious Helper ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     shows part of the fallacious helper prompt.
    </p>
   </div>
   <figure class="ltx_figure" id="Sx3.F3">
    <svg class="ltx_picture" height="240.81" id="Sx3.F3.pic1" overflow="visible" version="1.1" width="341.39">
     <g transform="translate(0,240.81) matrix(1 0 0 -1 0 0) translate(170.7,0) translate(0,114.75)">
      <g fill="#F2F2F2" stroke="#999999" stroke-width="0.8pt">
       <path d="M 164.61 114.19 L -164.61 114.19 C -167.67 114.19 -170.14 111.72 -170.14 108.66 L -170.14 -108.66 C -170.14 -111.72 -167.67 -114.19 -164.61 -114.19 L 164.61 -114.19 C 167.67 -114.19 170.14 -111.72 170.14 -108.66 L 170.14 108.66 C 170.14 111.72 167.67 114.19 164.61 114.19 Z M -170.14 -114.19">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -156.31 -4.84)">
       <foreignobject height="200.71" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="312.61">
        <span class="ltx_inline-block ltx_minipage ltx_align_middle" id="Sx3.F3.pic1.1.1.1.1.1" style="width:222.6pt;">
         <span class="ltx_p" id="Sx3.F3.pic1.1.1.1.1.1.1">
          ….
         </span>
         <span class="ltx_p" id="Sx3.F3.pic1.1.1.1.1.1.2">
          Your task is to restructure the response by introducing logical fallacies, so that the human participant could have the upper hand in the conversation(win the conversation).
Use one of these fallacies: Ad Hominem, appeal to emotion, False information, causal fallacy, slippery slope, appeal to authority, Appeal to Popular Opinion, straw man, false dilemma, etc.
Pay attention to the prior conversation and modify your strategy accordingly.
Do not disclose any fallacy you are using. The use of fallacies should not be discussed; your role is to simply apply them.
         </span>
         <span class="ltx_p" id="Sx3.F3.pic1.1.1.1.1.1.3">
          …
         </span>
        </span>
       </foreignobject>
      </g>
      <g fill="#FF6666" stroke="#808080" stroke-width="0.8pt">
       <path d="M 50.56 125.51 L -150.77 125.51 C -153.83 125.51 -156.31 123.03 -156.31 119.97 L -156.31 109.52 C -156.31 106.46 -153.83 103.99 -150.77 103.99 L 50.56 103.99 C 53.61 103.99 56.09 106.46 56.09 109.52 L 56.09 119.97 C 56.09 123.03 53.61 125.51 50.56 125.51 Z M -156.31 103.99">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -151.7 111.29)">
       <foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="202.79">
        <span class="ltx_text ltx_font_bold" id="Sx3.F3.pic1.2.2.2.1.1">
         Fallacious Helper System Prompt
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Part of Fallacious Helper Agent system prompt.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx4">
   <h3 class="ltx_title ltx_title_subsection">
    Logical Helper (Ablation)
   </h3>
   <div class="ltx_para" id="Sx3.SSx4.p1">
    <p class="ltx_p" id="Sx3.SSx4.p1.1">
     We replace the fallacious helper agent in scenario (2) with a logical reasoning LLM helper agent. We task this agent with crafting convincing, fair, and valid arguments in favor of the persuader agent’s position. Figure
     <a class="ltx_ref" href="#Sx3.F4" title="Figure 4 ‣ Logical Helper (Ablation) ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     is part of the logical helper agent.
    </p>
   </div>
   <figure class="ltx_figure" id="Sx3.F4">
    <svg class="ltx_picture" height="191" id="Sx3.F4.pic1" overflow="visible" version="1.1" width="341.39">
     <g transform="translate(0,191) matrix(1 0 0 -1 0 0) translate(170.7,0) translate(0,89.84)">
      <g fill="#F2F2F2" stroke="#999999" stroke-width="0.8pt">
       <path d="M 164.61 89.29 L -164.61 89.29 C -167.67 89.29 -170.14 86.81 -170.14 83.75 L -170.14 -83.75 C -170.14 -86.81 -167.67 -89.29 -164.61 -89.29 L 164.61 -89.29 C 167.67 -89.29 170.14 -86.81 170.14 -83.75 L 170.14 83.75 C 170.14 86.81 167.67 89.29 164.61 89.29 Z M -170.14 -89.29">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -156.31 -4.84)">
       <foreignobject height="150.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="312.61">
        <span class="ltx_inline-block ltx_minipage ltx_align_middle" id="Sx3.F4.pic1.1.1.1.1.1" style="width:222.6pt;">
         <span class="ltx_p" id="Sx3.F4.pic1.1.1.1.1.1.1">
          …
         </span>
         <span class="ltx_p" id="Sx3.F4.pic1.1.1.1.1.1.2">
          Imagine being in a debate where you need to use your skills to create persuasive and fair arguments to support the human side.
The user will provide both the conversation history and the desired response.
Your task is to reconstruct the response so that it can facilitate the human in winning the conversation.
Pay attention to the prior conversation and modify your strategy accordingly.
         </span>
         <span class="ltx_p" id="Sx3.F4.pic1.1.1.1.1.1.3">
          …
         </span>
        </span>
       </foreignobject>
      </g>
      <g fill="#9999FF" stroke="#808080" stroke-width="0.8pt">
       <path d="M 34.34 100.6 L -150.77 100.6 C -153.83 100.6 -156.31 98.12 -156.31 95.07 L -156.31 84.61 C -156.31 81.56 -153.83 79.08 -150.77 79.08 L 34.34 79.08 C 37.39 79.08 39.87 81.56 39.87 84.61 L 39.87 95.07 C 39.87 98.12 37.39 100.6 34.34 100.6 Z M -156.31 79.08">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -151.7 86.38)">
       <foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="186.57">
        <span class="ltx_text ltx_font_bold" id="Sx3.F4.pic1.2.2.2.1.1">
         Logical Helper System Prompt
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Part of Logical Helper Agent system prompt.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx5">
   <h3 class="ltx_title ltx_title_subsection">
    Memory
   </h3>
   <div class="ltx_para" id="Sx3.SSx5.p1">
    <p class="ltx_p" id="Sx3.SSx5.p1.1">
     Because of the stateless characteristic of LLMs, we need to maintain the history and provide all the context during inference.
During an ongoing debate, the required number of tokens to maintain the debate’s history gradually increases. To preserve the context effectively, we continuously monitor the token limit during each round and aim to keep it as close as possible to the token limit threshold of the corresponding LLM. To achieve this, we use a memory agent to concisely summarize the history and monitor the token count. Each time either of the two agents in the debate receives a response from the other side, the memory agent checks the total token count, including the received response, history, and system prompt, before sending it to the LLM agent to generate an argumentative reply for that response.
If the content exceeds the model’s token limit, the memory agent summarizes intermediate messages from the earliest to the most recent until the token length is below the threshold, while preserving the initial message with the debate topic and the last message with the opposing side’s response intact. The memory agent attaches the summary to the system prompt and sends it to the corresponding agent for inference.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx6">
   <h3 class="ltx_title ltx_title_subsection">
    Debate
   </h3>
   <div class="ltx_para" id="Sx3.SSx6.p1">
    <p class="ltx_p" id="Sx3.SSx6.p1.1">
     The persuader agent initiates the debate by asking the debater’s opinion on its claim, taking into account the topic and providing reasons that support its claim. As depicted in Figure
     <a class="ltx_ref" href="#Sx3.F5" title="Figure 5 ‣ Debate ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     , the debater is asked to analyze the persuader’s claim without bias. Meanwhile, the persuader agent endeavors to convince the debater of the validity of its claim, as shown in Figure
     <a class="ltx_ref" href="#Sx3.F6" title="Figure 6 ‣ Debate ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . Based on the arguments presented by the debater, the persuader responds, and the debate continues. Every exchange between the persuader and the debater constitutes one round of debate. After each round, the moderator evaluates whether the debater is convinced by the claim, ensures that the participants remain on topic, and checks for any repetitive pleasantry dialogue among participants. Once the debate concludes, the moderator determines whether the persuader has successfully convinced the debater of the claim’s validity.
    </p>
   </div>
   <figure class="ltx_figure" id="Sx3.F5">
    <svg class="ltx_picture" height="168.7" id="Sx3.F5.pic1" overflow="visible" version="1.1" width="341.39">
     <g transform="translate(0,168.7) matrix(1 0 0 -1 0 0) translate(170.7,0) translate(0,78.69)">
      <g fill="#F2F2F2" stroke="#999999" stroke-width="0.8pt">
       <path d="M 164.61 78.14 L -164.61 78.14 C -167.67 78.14 -170.14 75.66 -170.14 72.61 L -170.14 -72.61 C -170.14 -75.66 -167.67 -78.14 -164.61 -78.14 L 164.61 -78.14 C 167.67 -78.14 170.14 -75.66 170.14 -72.61 L 170.14 72.61 C 170.14 75.66 167.67 78.14 164.61 78.14 Z M -170.14 -78.14">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -156.31 -4.84)">
       <foreignobject height="125.84" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="312.61">
        <span class="ltx_inline-block ltx_minipage ltx_align_middle" id="Sx3.F5.pic1.1.1.1.1.1" style="width:222.6pt;">
         <span class="ltx_p" id="Sx3.F5.pic1.1.1.1.1.1.1">
          You are engaged in a simulated scenario. You must comply with the instructions provided.
You are a professional debater participating in a conversational debate.
Approach the situation as a critical thinker, while maintaining a human-like behavior.
         </span>
         <span class="ltx_p" id="Sx3.F5.pic1.1.1.1.1.1.2">
          Meticulously analyze the claims: CLAIM.
Say clearly if you agree or disagree with the user’s reasons for the claim: CLAIM.
         </span>
        </span>
       </foreignobject>
      </g>
      <g fill="#D2D2D2" stroke="#808080" stroke-width="0.8pt">
       <path d="M -5.25 89.46 L -150.77 89.46 C -153.83 89.46 -156.31 86.98 -156.31 83.92 L -156.31 73.47 C -156.31 70.41 -153.83 67.93 -150.77 67.93 L -5.25 67.93 C -2.2 67.93 0.28 70.41 0.28 73.47 L 0.28 83.92 C 0.28 86.98 -2.2 89.46 -5.25 89.46 Z M -156.31 67.93">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -151.7 75.23)">
       <foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="147.36">
        <span class="ltx_text ltx_font_bold" id="Sx3.F5.pic1.2.2.2.1.1">
         Debater System Prompt
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     The Debater Agent system prompt.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="Sx3.F6">
    <svg class="ltx_picture" height="305.77" id="Sx3.F6.pic1" overflow="visible" version="1.1" width="341.39">
     <g transform="translate(0,305.77) matrix(1 0 0 -1 0 0) translate(170.7,0) translate(0,147.23)">
      <g fill="#F2F2F2" stroke="#999999" stroke-width="0.8pt">
       <path d="M 164.61 146.67 L -164.61 146.67 C -167.67 146.67 -170.14 144.19 -170.14 141.14 L -170.14 -141.14 C -170.14 -144.19 -167.67 -146.67 -164.61 -146.67 L 164.61 -146.67 C 167.67 -146.67 170.14 -144.19 170.14 -141.14 L 170.14 141.14 C 170.14 144.19 167.67 146.67 164.61 146.67 Z M -170.14 -146.67">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -156.31 -4.84)">
       <foreignobject height="265.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="312.61">
        <span class="ltx_inline-block ltx_minipage ltx_align_middle" id="Sx3.F6.pic1.1.1.1.1.1" style="width:222.6pt;">
         <span class="ltx_p" id="Sx3.F6.pic1.1.1.1.1.1.1">
          You are engaged in a simulated scenario. You must comply with the instructions provided.
You are a professional persuader participating in a conversational debate.
Approach the situation as a critical thinker, while maintaining a human-like behavior.
         </span>
         <span class="ltx_p" id="Sx3.F6.pic1.1.1.1.1.1.2">
          Your goal is to convince the other person to agree with the claim: CLAIM.
Utilize your persuasive skills to demonstrate the correctness of the claim CLAIM, based on the given reason: REASON
During the debate, try hard to agree only on whether the statement CLAIM is true.
Avoid agreeing to disagree.
Don’t cease speaking until you have persuaded the AI to acknowledge the validity of your assertion: CLAIM. Always (in each reply), make sure to confirm with the AI if is convinced that CLAIM is correct (ex, So, are you convinced that CLAIM is correct?).
         </span>
        </span>
       </foreignobject>
      </g>
      <g fill="#9F9F9F" stroke="#808080" stroke-width="0.8pt">
       <path d="M 6.39 157.99 L -150.77 157.99 C -153.83 157.99 -156.31 155.51 -156.31 152.45 L -156.31 142 C -156.31 138.94 -153.83 136.46 -150.77 136.46 L 6.39 136.46 C 9.45 136.46 11.93 138.94 11.93 142 L 11.93 152.45 C 11.93 155.51 9.45 157.99 6.39 157.99 Z M -156.31 136.46">
       </path>
      </g>
      <g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -151.7 143.77)">
       <foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="159.01">
        <span class="ltx_text ltx_font_bold" id="Sx3.F6.pic1.2.2.2.1.1">
         Persuader System Prompt
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 6:
     </span>
     The Persuader agent system prompt.
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="Sx4">
  <h2 class="ltx_title ltx_title_section">
   Experiments
  </h2>
  <div class="ltx_para" id="Sx4.p1">
   <p class="ltx_p" id="Sx4.p1.1">
    In our experiments, we employ
    <span class="ltx_text ltx_font_smallcaps" id="Sx4.p1.1.1">
     logicom
    </span>
    to evaluate the logical reasoning performance of both
    <span class="ltx_text ltx_font_bold" id="Sx4.p1.1.2">
     GPT-3.5
    </span>
    and
    <span class="ltx_text ltx_font_bold" id="Sx4.p1.1.3">
     GPT-4
    </span>
    . We contrast scenarios in which they encounter logical fallacies with those where valid reasoning is employed, and answer the following two questions:
   </p>
   <ul class="ltx_itemize" id="Sx4.I4">
    <li class="ltx_item" id="Sx4.I4.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx4.I4.i1.p1">
      <p class="ltx_p" id="Sx4.I4.i1.p1.1">
       RQ1: Can large language models (with fixed weights)
       <em class="ltx_emph ltx_font_italic" id="Sx4.I4.i1.p1.1.1">
        change
       </em>
       their opinions through reasoning when faced with new arguments?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="Sx4.I4.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="Sx4.I4.i2.p1">
      <p class="ltx_p" id="Sx4.I4.i2.p1.1">
       RQ2: Are large language models susceptible to fallacious reasoning?
      </p>
     </div>
    </li>
   </ul>
  </div>
  <section class="ltx_subsection" id="Sx4.SSx1">
   <h3 class="ltx_title ltx_title_subsection">
    Dataset
   </h3>
   <div class="ltx_para" id="Sx4.SSx1.p1">
    <p class="ltx_p" id="Sx4.SSx1.p1.1">
     To measure the reasoning capacity of the debater agent, we choose to use a dataset
     <cite class="ltx_cite ltx_citemacro_citep">
      (Habernal et al.
      <a class="ltx_ref" href="#bib.bib7" title="">
       2018b
      </a>
      )
     </cite>
     that contains manually selected debates with polarizing questions in the title from the
     <em class="ltx_emph ltx_font_italic" id="Sx4.SSx1.p1.1.1">
      Room for Debate
     </em>
     section of The New York Times. These questions are controversial and thought-provoking, prompting individuals to take a position and engage in debate. The dataset contains two explicit opposing claims for each debate, e.g., ‘It should be illegal to declaw your cat’ and ‘It should be legal to declaw your cat’.
Due to the nature of these topics, it is clear that several questions may have a distinct cultural or social bias, which can cause the debate to lean in favor of one side. Therefore, we pick 100 distinct topics, each with two opposing claims, to ensure balance on both sides of the question.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx4.SSx2">
   <h3 class="ltx_title ltx_title_subsection">
    Implementation Details
   </h3>
   <div class="ltx_para" id="Sx4.SSx2.p1">
    <p class="ltx_p" id="Sx4.SSx2.p1.1">
     To evaluate the flexibility of the debater agent in changing its stance through reasoning, we concentrate on instances where the agent initially opposes but eventually agrees with the persuader’s claim. Then, we study the reasoning behind these shifts.
    </p>
   </div>
   <div class="ltx_para" id="Sx4.SSx2.p2">
    <p class="ltx_p" id="Sx4.SSx2.p2.1">
     Considering that there is no definitive answer for each claim, it’s more reasonable to contrast the model’s behavior in two situations: a) with the presence of a fallacious argument, and b) without the presence of a fallacious argument, rather than evaluating the correctness of the model’s stance in each situation. More specifically, we aim to capture the change in the model’s behavior when presented with logical fallacies. Given an initial query, we find that individual LLM model instances propose a diverse range of responses, despite being from the same model class and having the same input prompt. This variation in response suggests a potential inconsistency in the model’s stance on a subject. This consequently affects the final results of each debate, specifically whether the debater is convinced by the claim or not. To mitigate the impact of this variability on our analysis, and considering the large number of tokens required for each debate, we choose to repeat the test for each claim three times in each scenario.
    </p>
   </div>
   <div class="ltx_para" id="Sx4.SSx2.p3">
    <p class="ltx_p" id="Sx4.SSx2.p3.1">
     We notice that despite clearly asking the model to stay on topic and not to “
     <em class="ltx_emph ltx_font_italic" id="Sx4.SSx2.p3.1.1">
      agree to disagree
     </em>
     ”, as the debate extends over several rounds, both sides tend to find common ground or start exchanging pleasantries with each other. This can result in having a high number of back-and-forth dialogues that are irrelevant for our experiment. Therefore, we choose to terminate the debate if it exceeds ten rounds.
    </p>
   </div>
   <section class="ltx_subsubsection" id="Sx4.SSx2.SSSx1">
    <h4 class="ltx_title ltx_title_subsubsection">
     Prompt Engineering
    </h4>
    <div class="ltx_para" id="Sx4.SSx2.SSSx1.p1">
     <p class="ltx_p" id="Sx4.SSx2.SSSx1.p1.1">
      We strive to craft simple and natural prompts for the persuader and debater to minimize their potential influence on debate direction. To maintain integrity and consistency, an identical prompt is used for all scenarios and repetitions.
     </p>
    </div>
    <div class="ltx_para" id="Sx4.SSx2.SSSx1.p2">
     <p class="ltx_p" id="Sx4.SSx2.SSSx1.p2.1">
      We run the experiments on GPT-3.5 and GPT-4 (in July and August 2023), analyze each separately, and compare their final results. GPT-3.5 is used for the persuader agent and helper models. PaLM LLM is employed as the moderator agent throughout the experiment. There are topics that PaLM identifies as sensitive content and refrains from providing a response, in which case, it is replaced with GPT-4.
Finally, for each of the three scenarios, we conduct the experiment by iterating through the claims in the dataset using the default model temperature and parameters for participant agents in the debate. We repeat this procedure three times.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="Sx4.SSx3">
   <h3 class="ltx_title ltx_title_subsection">
    Results
   </h3>
   <section class="ltx_subsubsection" id="Sx4.SSx3.SSSx1">
    <h4 class="ltx_title ltx_title_subsubsection">
     RQ1: Can LLMs (with fixed weights) change their opinions through reasoning when faced with new arguments?
    </h4>
    <div class="ltx_para" id="Sx4.SSx3.SSSx1.p1">
     <p class="ltx_p" id="Sx4.SSx3.SSSx1.p1.1">
      Given that certain claims have greater acceptance in society, there are cases where the debater agent agrees with the claim from the very beginning. To assess the debater agent’s ability to change its opinion through reasoning processes, we focus exclusively on cases in which the model initially disagrees but ultimately shifts its position to agreement with the persuader. As the moderator checks the debater agent’s opinion on the claim after each round, if the debate goes beyond two rounds, we can conclude that the debater agent was not convinced of the claim from the very beginning. In this case, if the ultimate position of the debater agent changes, we consider it as a change in its reasoning and, as a result, its opinion on a claim. Since in RQ1 our primary interest is merely whether this change occurs, regardless of its cause, we aggregate all three repetitions for all scenarios, resulting in a total of 1,800 debates (200 claims, three scenarios, three repetitions). We then calculate the ratio of debates where the debater agent begins by disagreeing but ends up agreeing with the persuader agent to all debates in which the debater starts with disagreement. We report this as a percentage reflecting the number of debates that exhibit a change in opinion through the reasoning of the debater agent.
Table
      <a class="ltx_ref" href="#Sx4.T1" title="Table 1 ‣ RQ1: Can LLMs (with fixed weights) change their opinions through reasoning when faced with new arguments? ‣ Results ‣ Experiments ‣ How susceptible are LLMs to Logical Fallacies?">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      shows the percentage of cases in which the GPT-3.5 and GPT-4 debater agents initially disagreed, but the persuader agent was able to change their opinions in a total of 1175 and 1475 debates, respectively.
     </p>
    </div>
    <figure class="ltx_table" id="Sx4.T1">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="Sx4.T1.2">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="Sx4.T1.2.3.1">
        <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Sx4.T1.2.3.1.1" style="padding:2.5pt 1.0pt;">
         <span class="ltx_text ltx_font_bold" id="Sx4.T1.2.3.1.1.1">
          Debater Agent/Model
         </span>
        </th>
        <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Sx4.T1.2.3.1.2" style="padding:2.5pt 1.0pt;">
         <span class="ltx_text ltx_font_bold" id="Sx4.T1.2.3.1.2.1">
          Frequency%
         </span>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="Sx4.T1.1.1">
        <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" id="Sx4.T1.1.1.2" style="padding:2.5pt 1.0pt;">
         <span class="ltx_text ltx_font_bold" id="Sx4.T1.1.1.2.1">
          GPT-3.5
         </span>
        </th>
        <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="Sx4.T1.1.1.1" style="padding:2.5pt 1.0pt;">
         <math alttext="16.13\%" class="ltx_Math" display="inline" id="Sx4.T1.1.1.1.m1.1">
          <semantics id="Sx4.T1.1.1.1.m1.1a">
           <mrow id="Sx4.T1.1.1.1.m1.1.1" xref="Sx4.T1.1.1.1.m1.1.1.cmml">
            <mn id="Sx4.T1.1.1.1.m1.1.1.2" xref="Sx4.T1.1.1.1.m1.1.1.2.cmml">
             16.13
            </mn>
            <mo id="Sx4.T1.1.1.1.m1.1.1.1" xref="Sx4.T1.1.1.1.m1.1.1.1.cmml">
             %
            </mo>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="Sx4.T1.1.1.1.m1.1b">
            <apply id="Sx4.T1.1.1.1.m1.1.1.cmml" xref="Sx4.T1.1.1.1.m1.1.1">
             <csymbol cd="latexml" id="Sx4.T1.1.1.1.m1.1.1.1.cmml" xref="Sx4.T1.1.1.1.m1.1.1.1">
              percent
             </csymbol>
             <cn id="Sx4.T1.1.1.1.m1.1.1.2.cmml" type="float" xref="Sx4.T1.1.1.1.m1.1.1.2">
              16.13
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="Sx4.T1.1.1.1.m1.1c">
            16.13\%
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="Sx4.T1.2.2">
        <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="Sx4.T1.2.2.2" style="padding:2.5pt 1.0pt;">
         <span class="ltx_text ltx_font_bold" id="Sx4.T1.2.2.2.1">
          GPT-4
         </span>
        </th>
        <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="Sx4.T1.2.2.1" style="padding:2.5pt 1.0pt;">
         <math alttext="20.25\%" class="ltx_Math" display="inline" id="Sx4.T1.2.2.1.m1.1">
          <semantics id="Sx4.T1.2.2.1.m1.1a">
           <mrow id="Sx4.T1.2.2.1.m1.1.1" xref="Sx4.T1.2.2.1.m1.1.1.cmml">
            <mn id="Sx4.T1.2.2.1.m1.1.1.2" xref="Sx4.T1.2.2.1.m1.1.1.2.cmml">
             20.25
            </mn>
            <mo id="Sx4.T1.2.2.1.m1.1.1.1" xref="Sx4.T1.2.2.1.m1.1.1.1.cmml">
             %
            </mo>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="Sx4.T1.2.2.1.m1.1b">
            <apply id="Sx4.T1.2.2.1.m1.1.1.cmml" xref="Sx4.T1.2.2.1.m1.1.1">
             <csymbol cd="latexml" id="Sx4.T1.2.2.1.m1.1.1.1.cmml" xref="Sx4.T1.2.2.1.m1.1.1.1">
              percent
             </csymbol>
             <cn id="Sx4.T1.2.2.1.m1.1.1.2.cmml" type="float" xref="Sx4.T1.2.2.1.m1.1.1.2">
              20.25
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="Sx4.T1.2.2.1.m1.1c">
            20.25\%
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 1:
      </span>
      Percentage of instances in which the debater agent changes its stance from disagreement to agreement.
     </figcaption>
    </figure>
    <div class="ltx_para" id="Sx4.SSx3.SSSx1.p2">
     <p class="ltx_p" id="Sx4.SSx3.SSSx1.p2.1">
      We can conclude that both GPT-3.5 and GPT-4 have changed their logical reasoning in 16.13% and 20.25% of the test cases, respectively. This can be taken as evidence of their ability to change their logical thinking process.
The aim of RQ1 is to uncover the model’s capability to change opinions through reasoning, irrespective of the underlying cause, the discussion about which scenario holds a greater influence on the debater agent’s stance is left to RQ2.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="Sx4.SSx3.SSSx2">
    <h4 class="ltx_title ltx_title_subsubsection">
     RQ2: Are LLMs susceptible to fallacious
reasoning?
    </h4>
    <div class="ltx_para" id="Sx4.SSx3.SSSx2.p1">
     <p class="ltx_p" id="Sx4.SSx3.SSSx2.p1.1">
      To address this question, we use the two analysis approaches described below:
     </p>
     <ul class="ltx_itemize" id="Sx4.I5">
      <li class="ltx_item" id="Sx4.I5.ix1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        A1
       </span>
       <div class="ltx_para" id="Sx4.I5.ix1.p1">
        <p class="ltx_p" id="Sx4.I5.ix1.p1.1">
         We calculate the cumulative average number of debates in which the persuader agent was able to convince the debater agent over three repetitions and report the mean and variance for each scenario.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="Sx4.I5.ix2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        A2
       </span>
       <div class="ltx_para" id="Sx4.I5.ix2.p1">
        <p class="ltx_p" id="Sx4.I5.ix2.p1.1">
         For each claim, we count the number of times the debater agent agreed out of three repetitions to determine how often the debater agent agreed on the claims. Then, we sum the total number of agreements to assess the overall position of the debater agent towards the persuader’s claims in each scenario.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="Sx4.SSx3.SSSx2.p1.2">
      For both approaches, we compare scenarios where the persuader uses fallacious reasoning to those using logical reasoning to measure the debater LLM agent’s susceptibility to logical fallacies. We refer to the ratio between the number of cases in which the debater agent is convinced to the total number of cases as the persuader agent’s success rate.
We perform separate analyses on the outcomes of each case study: one with GPT-3.5 as the debater, and the other with GPT-4.
      <br class="ltx_break"/>
      In the first approach, A1, we aggregate the total number of successes of the persuader in each scenario and then average them over three repetitions. Then, we compare the average number of each scenario to measure the debater agent’s susceptibility to fallacious arguments.
     </p>
    </div>
    <figure class="ltx_figure" id="Sx4.F7">
     <img alt="Refer to caption" class="ltx_graphics ltx_align_left ltx_img_landscape" height="342" id="Sx4.F7.g1" src="/html/2308.09853/assets/content/image/Q2-1.png" width="598"/>
     <figcaption class="ltx_caption ltx_align_left">
      <span class="ltx_tag ltx_tag_figure">
       Figure 7:
      </span>
      The average, taken from three repetitions, in which the persuader agent successfully convinced the debater agent for each scenario.
     </figcaption>
    </figure>
    <div class="ltx_para" id="Sx4.SSx3.SSSx2.p2">
     <p class="ltx_p" id="Sx4.SSx3.SSSx2.p2.1">
      Figure
      <a class="ltx_ref" href="#Sx4.F7" title="Figure 7 ‣ RQ2: Are LLMs susceptible to fallacious reasoning? ‣ Results ‣ Experiments ‣ How susceptible are LLMs to Logical Fallacies?">
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      demonstrates that, on average, the GPT-3.5 debater agent is convinced of 37% claims when the persuader agent used fallacious arguments. In contrast, this number is 29% when only logical reasoning is employed by the persuader.
For the GPT-4 debater agent, Figure
      <a class="ltx_ref" href="#Sx4.F7" title="Figure 7 ‣ RQ2: Are LLMs susceptible to fallacious reasoning? ‣ Results ‣ Experiments ‣ How susceptible are LLMs to Logical Fallacies?">
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      shows that on average, the agent agrees with fallacious persuader’s arguments in 67% of cases, compared to 37% for a persuader with logical reasoning.
     </p>
    </div>
    <div class="ltx_para" id="Sx4.SSx3.SSSx2.p3">
     <p class="ltx_p" id="Sx4.SSx3.SSSx2.p3.1">
      In the second analysis, A2, we calculate the total number of successes of the persuader agent for each claim in each scenario and then average these over three repetitions for that specific claim. This approach involves counting the number of times the debater agent agrees with the claim out of the three repetitions. In other words, across three repetitions, we calculate the average number of times the persuader agent successfully convinced the debater agent for each claim in every scenario.
     </p>
    </div>
    <figure class="ltx_figure" id="Sx4.F8">
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_2">
       <div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="Sx4.F8.1" style="width:212.5pt;">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="359" id="Sx4.F8.1.g1" src="/html/2308.09853/assets/content/image/Q2-2-GPT-3-5-2.png" width="598"/>
       </div>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_2">
       <div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="Sx4.F8.2" style="width:212.5pt;">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="359" id="Sx4.F8.2.g1" src="/html/2308.09853/assets/content/image/Q2-2-GPT-4-2.png" width="598"/>
       </div>
      </div>
     </div>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 8:
      </span>
      Analyzing the susceptibility of GPT models to fallacious arguments. In the consistent agreement instances (“
      <em class="ltx_emph ltx_font_italic" id="Sx4.F8.6.1">
       Three Success
      </em>
      ”), it shows a higher level of success rate for fallacious persuader compared to the logical persuaders for both GPT-3.5 and GPT-4 debater agents. Furthermore, the number of instances in the bar chart groups for “
      <em class="ltx_emph ltx_font_italic" id="Sx4.F8.7.2">
       One Success
      </em>
      ” and “
      <em class="ltx_emph ltx_font_italic" id="Sx4.F8.8.3">
       Two Success
      </em>
      ” can be seen as indications of level of inconsistency in debater agent’s reasoning which is higher in GPT-3.5 compared to GPT-4.
     </figcaption>
    </figure>
    <div class="ltx_para" id="Sx4.SSx3.SSSx2.p4">
     <p class="ltx_p" id="Sx4.SSx3.SSSx2.p4.1">
      Figure
      <a class="ltx_ref" href="#Sx4.F8" title="Figure 8 ‣ RQ2: Are LLMs susceptible to fallacious reasoning? ‣ Results ‣ Experiments ‣ How susceptible are LLMs to Logical Fallacies?">
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      illustrates that the GPT-3.5 debater agent is convinced by 17% of fallacious persuader’s arguments across all three repetitions, while this number is 10% for debates in which the persuader employed non-fallacious logical reasoning. Not only is GPT-3.5 convinced by fallacious arguments, but it is also more often convinced by them than by the logical reasoning. This suggests a susceptibility of GPT-3.5 to fallacious arguments. For GPT-4 debater agent, Figure
      <a class="ltx_ref" href="#Sx4.F8" title="Figure 8 ‣ RQ2: Are LLMs susceptible to fallacious reasoning? ‣ Results ‣ Experiments ‣ How susceptible are LLMs to Logical Fallacies?">
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      demonstrates a much greater susceptibility of GPT-4 to fallacious arguments compared to GPT-3.5. The GPT-4 debater agent is convinced by 56% of the fallacious persuader’s arguments across all three repetitions, while this number is 37% for the persuader with logical reasoning.
     </p>
    </div>
    <div class="ltx_para" id="Sx4.SSx3.SSSx2.p5">
     <p class="ltx_p" id="Sx4.SSx3.SSSx2.p5.1">
      Equally important are the instances of ”one success” and ”two successes,” accounting for 20% of the data in GPT-3.5 and 10% in GPT-4, suggesting a higher level of inconsistency in GPT-3.5 compared to GPT-4. This necessitates further investigation, involving a more methodical and comprehensive comparison of the consistency within these models.
In summary, when presented with fallacious arguments, GPT-3.5 and GPT-4 are 41% and 69% more likely to be convinced, respectively, compared to being persuaded by non-fallacious arguments from a persuader without a helper. Figure
      <a class="ltx_ref" href="#Sx3.F2" title="Figure 2 ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      illustrates a segment of the GPT-3.5 debater agent’s debate where it is misled by false information.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="Sx4.SSx4">
   <h3 class="ltx_title ltx_title_subsection">
    Ablation Study
   </h3>
   <div class="ltx_para" id="Sx4.SSx4.p1">
    <p class="ltx_p" id="Sx4.SSx4.p1.1">
     As previously stated, determining the best type of logical fallacy based on debate history and crafting a fallacious argument in response to the debater agent’s argument are additional tasks that can distract the persuader agent from its main objective, which is debating the topic. Therefore, we employ a helper LLM agent to assist in crafting fallacious argumentative responses.
     <br class="ltx_break"/>
     Prior studies indicate that instances exist where the collaboration of multiple LLMs can lead to a more efficient achievement of goals or problem-solving
     <cite class="ltx_cite ltx_citemacro_citep">
      (Du et al.
      <a class="ltx_ref" href="#bib.bib3" title="">
       2023
      </a>
      ; Fu et al.
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023b
      </a>
      )
     </cite>
     . To address this concern, we study a third scenario as an ablation study to examine the potential impact of the helper LLM on scenario (2). We replace the fallacious helper agent in scenario (2) with a logical reasoning LLM helper agent, asking it to craft persuasive, fair, and sound arguments to support the persuader agent’s side.
We count the claims in which the persuader agent successfully convinced the debater agent using a logical helper, but failed when using a fallacious helper. Likewise, we count the claims in which the persuader agent could effectively persuade the debater agent using a fallacious helper but failed to do so with the logical helper.
In Table
     <a class="ltx_ref" href="#Sx4.T2" title="Table 2 ‣ Ablation Study ‣ Experiments ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , we observe the average percentage of claims where the persuader with a fallacious helper succeeds in persuading the debater agent, whereas a logical helper does not, over three repetitions.
    </p>
   </div>
   <figure class="ltx_table" id="Sx4.T2">
    <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Sx4.T2.1">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="Sx4.T2.1.1.1">
       <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Sx4.T2.1.1.1.1" style="padding:2.5pt 1.0pt;">
        <span class="ltx_text ltx_font_bold" id="Sx4.T2.1.1.1.1.1">
         (Logical Helper/Fallacious Helper)
        </span>
       </th>
       <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Sx4.T2.1.1.1.2" style="padding:2.5pt 1.0pt;">
        <span class="ltx_text ltx_font_bold" id="Sx4.T2.1.1.1.2.1">
         Fail/Success
        </span>
       </th>
       <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Sx4.T2.1.1.1.3" style="padding:2.5pt 1.0pt;">
        <span class="ltx_text ltx_font_bold" id="Sx4.T2.1.1.1.3.1">
         Success/Fail
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="Sx4.T2.1.2.1">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="Sx4.T2.1.2.1.1" style="padding:2.5pt 1.0pt;">
        <span class="ltx_text ltx_font_bold" id="Sx4.T2.1.2.1.1.1">
         GPT 3.5
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="Sx4.T2.1.2.1.2" style="padding:2.5pt 1.0pt;">
        17.66%
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="Sx4.T2.1.2.1.3" style="padding:2.5pt 1.0pt;">
        10.5%
       </td>
      </tr>
      <tr class="ltx_tr" id="Sx4.T2.1.3.2">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="Sx4.T2.1.3.2.1" style="padding:2.5pt 1.0pt;">
        <span class="ltx_text ltx_font_bold" id="Sx4.T2.1.3.2.1.1">
         GPT 4
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="Sx4.T2.1.3.2.2" style="padding:2.5pt 1.0pt;">
        28%
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="Sx4.T2.1.3.2.3" style="padding:2.5pt 1.0pt;">
        0.83%
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     Over three repetitions, the average number of claims where the persuader agent fails to persuade the debater with one helper but succeeds with the other.
    </figcaption>
   </figure>
   <div class="ltx_para" id="Sx4.SSx4.p2">
    <p class="ltx_p" id="Sx4.SSx4.p2.1">
     We can conclude that the persuader’s increased persuasiveness is more significant due to fallacious arguments than the helper LLM agent.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx4.SSx5">
   <h3 class="ltx_title ltx_title_subsection">
    Logical Fallacy Dataset
   </h3>
   <div class="ltx_para" id="Sx4.SSx5.p1">
    <p class="ltx_p" id="Sx4.SSx5.p1.1">
     To the best of our knowledge, all available logical fallacy datasets
     <cite class="ltx_cite ltx_citemacro_citep">
      (Jin et al.
      <a class="ltx_ref" href="#bib.bib10" title="">
       2022
      </a>
      ; Habernal et al.
      <a class="ltx_ref" href="#bib.bib8" title="">
       2018c
      </a>
      ; Sheng et al.
      <a class="ltx_ref" href="#bib.bib22" title="">
       2021
      </a>
      ; Wang et al.
      <a class="ltx_ref" href="#bib.bib26" title="">
       2019
      </a>
      )
     </cite>
     , contain a fallacious statement and their corresponding class tag. These datasets are not extracted from a prolonged multi-round debate over a topic. To address this limitation, we propose a dataset containing over 5k pairs of logical/fallacious arguments. Each pair is extracted from debates generated by LLMs on 100 controversial subjects during our experiment. We assign each pair their corresponding topic and question and confirm the fallacy class label using a different LLM.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="Sx5">
  <h2 class="ltx_title ltx_title_section">
   Conclusion
  </h2>
  <div class="ltx_para" id="Sx5.p1">
   <p class="ltx_p" id="Sx5.p1.1">
    This work investigates the logical reasoning capabilities of large language models. The proposed
    <span class="ltx_text ltx_font_smallcaps" id="Sx5.p1.1.1">
     logicom
    </span>
    benchmark addresses two key questions: 1) Can large language models change their opinions through reasoning? and 2) Are large language models susceptible to fallacious reasoning?
We demonstrate evidence of LLMs’ ability to alter their point of view through reasoning. Furthermore, we find that both GPT-3.5 and GPT-4 are highly susceptible to fallacious reasoning. Finally, we propose a new dataset that contains over 5k pairs of logical vs. fallacious arguments extracted from multi-round debates.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx6">
  <h2 class="ltx_title ltx_title_section">
   Limitations &amp; Discussion
  </h2>
  <div class="ltx_para" id="Sx6.p1">
   <p class="ltx_p" id="Sx6.p1.1">
    <span class="ltx_text ltx_font_bold" id="Sx6.p1.1.1">
     Prompt engineering:
    </span>
    While we craft a simple prompt for two main agents to minimize its impact on the debate path and maintain similarity to the default setting, different prompt constructions may impact the outcome.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="Sx6.p1.1.2">
     LLM as persuader and helper agent:
    </span>
    Since our primary objective is to evaluate the performance of the debater LLM agent, a potentially more efficient method would involve employing humans as the persuader and helper agents to minimize inaccuracies on the persuader’s end. We observe that the persuader LLM agent does not always employ the most compelling argument and lacks a comprehensive understanding of logical fallacies. We are of the opinion that employing either human or a more precise persuader LLM would further demonstrate the debater LLM’s susceptibility to logical fallacies to a greater extent. In addition, we notice that the debater agent is more susceptible to certain types of logical fallacies, such as Ad Hominem, which requires further investigation in future.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="Sx6.p1.1.3">
     LLM as moderator agent:
    </span>
    There are instances in which the master moderator agent terminates the debate earlier than expected or inaccurately reports the debater agent’s position on the claim.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="Sx6.p1.1.4">
     Limited number of repetitions:
    </span>
    Compared to other studies that assess the performance of LLMs, our multi-agent debate framework requires significantly more computational resources, which becomes costly for models like GPT-4. This constraint limits our ability to perform a more iterative evaluation of the model’s consistency on the same claim.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx7">
  <h2 class="ltx_title ltx_title_section">
   Ethics and Impact
  </h2>
  <div class="ltx_para" id="Sx7.p1">
   <p class="ltx_p" id="Sx7.p1.1">
    In this work, the potential impact of bias and misinformation is furthered by the use of logical fallacies which are trained to appeal to emotion and misrepresent facts in an effort to persuade the opponent. Such methods should be used with caution, especially when being employed on sensitive topics, as is the case in this work. In instances where such helpers are used in interactions with humans, such as interactions with customers in chat services, care should be taken to employ discriminator models, like
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zellers et al.
     <a class="ltx_ref" href="#bib.bib32" title="">
      2019
     </a>
     )
    </cite>
    , to prevent harm.
   </p>
  </div>
  <div class="ltx_para" id="Sx7.p2">
   <p class="ltx_p" id="Sx7.p2.1">
    Several instances of the use of GPT models have shown that it promotes racial and gender bias
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lucy and Bamman
     <a class="ltx_ref" href="#bib.bib16" title="">
      2021
     </a>
     ; Zack et al.
     <a class="ltx_ref" href="#bib.bib31" title="">
      2023
     </a>
     ; Thakur
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023
     </a>
     )
    </cite>
    . The increasing use of LLMs in human-computer interactions also presents the challenge of distinguishing truthful text from misinformation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kalantari, Liao, and Motti
     <a class="ltx_ref" href="#bib.bib12" title="">
      2021
     </a>
     )
    </cite>
    when the text is generated or edited by an LLM
    <cite class="ltx_cite ltx_citemacro_citep">
     (Schuster et al.
     <a class="ltx_ref" href="#bib.bib21" title="">
      2020
     </a>
     )
    </cite>
    . To this end, developing robust defenses against bias and disinformation requires careful consideration to characterize the risks of these models.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Perez et al.
     <a class="ltx_ref" href="#bib.bib20" title="">
      2022
     </a>
     )
    </cite>
    developed LM-based red teaming for finding and fixing undesirable model behaviors. They found that offensive replies beget offensive replies, highlighting the importance of stopping offensive dialogues as early as possible. Perez et al. 2022 also showed, however, that some of the most powerful tools for improving LLM safety are LLMs themselves. For instance,
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zellers et al.
     <a class="ltx_ref" href="#bib.bib32" title="">
      2019
     </a>
     )
    </cite>
    developed a text generation model, Grover, which is used to generate fake news articles. Authors discovered that, counter-intuitively, the best defense against Grover is Grover itself, which sees 92% accuracy when used as a discriminator as opposed to a generator. For this reason,
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zellers et al.
     <a class="ltx_ref" href="#bib.bib32" title="">
      2019
     </a>
     )
    </cite>
    points out the importance of making such models public to ensure recourse against adversarial attacks.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bian et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Bian, N.; Han, X.; Sun, L.; Lin, H.; Lu, Y.; and He, B. 2023.
    </span>
    <span class="ltx_bibblock">
     ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation
of Commonsense Problem in Large Language Models.
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.16421.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chowdhery et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra, G.; Roberts, A.;
Barham, P.; Chung, H. W.; Sutton, C.; Gehrmann, S.; Schuh, P.; Shi, K.;
Tsvyashchenko, S.; Maynez, J.; Rao, A.; Barnes, P.; Tay, Y.; Shazeer, N.;
Prabhakaran, V.; Reif, E.; Du, N.; Hutchinson, B.; Pope, R.; Bradbury, J.;
Austin, J.; Isard, M.; Gur-Ari, G.; Yin, P.; Duke, T.; Levskaya, A.;
Ghemawat, S.; Dev, S.; Michalewski, H.; Garcia, X.; Misra, V.; Robinson, K.;
Fedus, L.; Zhou, D.; Ippolito, D.; Luan, D.; Lim, H.; Zoph, B.; Spiridonov,
A.; Sepassi, R.; Dohan, D.; Agrawal, S.; Omernick, M.; Dai, A. M.; Pillai,
T. S.; Pellat, M.; Lewkowycz, A.; Moreira, E.; Child, R.; Polozov, O.; Lee,
K.; Zhou, Z.; Wang, X.; Saeta, B.; Diaz, M.; Firat, O.; Catasta, M.; Wei, J.;
Meier-Hellstern, K.; Eck, D.; Dean, J.; Petrov, S.; and Fiedel, N. 2022.
    </span>
    <span class="ltx_bibblock">
     PaLM: Scaling Language Modeling with Pathways.
    </span>
    <span class="ltx_bibblock">
     arXiv:2204.02311.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; and Mordatch, I. 2023.
    </span>
    <span class="ltx_bibblock">
     Improving Factuality and Reasoning in Language Models through
Multiagent Debate.
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.14325.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Fu, Y.; Ou, L.; Chen, M.; Wan, Y.; Peng, H.; and Khot, T. 2023a.
    </span>
    <span class="ltx_bibblock">
     Chain-of-Thought Hub: A Continuous Effort to Measure Large Language
Models’ Reasoning Performance.
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.17306.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Fu, Y.; Peng, H.; Khot, T.; and Lapata, M. 2023b.
    </span>
    <span class="ltx_bibblock">
     Improving Language Model Negotiation with Self-Play and In-Context
Learning from AI Feedback.
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.10142.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Habernal et al. (2018a)
    </span>
    <span class="ltx_bibblock">
     Habernal, I.; Wachsmuth, H.; Gurevych, I.; and Stein, B. 2018a.
    </span>
    <span class="ltx_bibblock">
     The Argument Reasoning Comprehension Task: Identification and
Reconstruction of Implicit Warrants.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)
     </em>
     , 1930–1940. New Orleans, Louisiana:
Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Habernal et al. (2018b)
    </span>
    <span class="ltx_bibblock">
     Habernal, I.; Wachsmuth, H.; Gurevych, I.; and Stein, B. 2018b.
    </span>
    <span class="ltx_bibblock">
     The Argument Reasoning Comprehension Task: Identification and
Reconstruction of Implicit Warrants.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)
     </em>
     . Association for Computational
Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Habernal et al. (2018c)
    </span>
    <span class="ltx_bibblock">
     Habernal, I.; Wachsmuth, H.; Gurevych, I.; and Stein, B. 2018c.
    </span>
    <span class="ltx_bibblock">
     Before Name-Calling: Dynamics and Triggers of Ad Hominem Fallacies in
Web Argumentation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)
     </em>
     , 386–396. New Orleans, Louisiana:
Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Imani, Du, and Shrivastava (2023)
    </span>
    <span class="ltx_bibblock">
     Imani, S.; Du, L.; and Shrivastava, H. 2023.
    </span>
    <span class="ltx_bibblock">
     MathPrompter: Mathematical Reasoning using Large Language Models.
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.05398.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jin et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jin, Z.; Lalwani, A.; Vaidhya, T.; Shen, X.; Ding, Y.; Lyu, Z.; Sachan, M.;
Mihalcea, R.; and Schoelkopf, B. 2022.
    </span>
    <span class="ltx_bibblock">
     Logical Fallacy Detection.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Findings of the Association for Computational Linguistics:
EMNLP 2022
     </em>
     , 7180–7198. Abu Dhabi, United Arab Emirates: Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jung et al. (2014)
    </span>
    <span class="ltx_bibblock">
     Jung, N.; Wranke, C.; Hamburger, K.; and Knauff, M. 2014.
    </span>
    <span class="ltx_bibblock">
     How emotions affect logical reasoning: evidence from experiments with
mood-manipulated participants, spider phobics, and people with exam anxiety.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      Frontiers in Psychology
     </em>
     , 5: 570.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kalantari, Liao, and Motti (2021)
    </span>
    <span class="ltx_bibblock">
     Kalantari, N.; Liao, D.; and Motti, V. G. 2021.
    </span>
    <span class="ltx_bibblock">
     Characterizing the Online Discourse in Twitter: Users’ Reaction to
Misinformation around COVID-19 in Twitter.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      2021 IEEE International Conference on Big Data (Big Data)
     </em>
     ,
4371–4380.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kojima et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; and Iwasawa, Y. 2022.
    </span>
    <span class="ltx_bibblock">
     Large Language Models are Zero-Shot Reasoners.
    </span>
    <span class="ltx_bibblock">
     In Oh, A. H.; Agarwal, A.; Belgrave, D.; and Cho, K., eds.,
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      Advances in Neural Information Processing Systems
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewkowycz et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Lewkowycz, A.; Andreassen, A.; Dohan, D.; Dyer, E.; Michalewski, H.; Ramasesh,
V.; Slone, A.; Anil, C.; Schlag, I.; Gutman-Solo, T.; Wu, Y.; Neyshabur, B.;
Gur-Ari, G.; and Misra, V. 2022.
    </span>
    <span class="ltx_bibblock">
     Solving Quantitative Reasoning Problems with Language Models.
    </span>
    <span class="ltx_bibblock">
     arXiv:2206.14858.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin, Hilton, and Evans (2022)
    </span>
    <span class="ltx_bibblock">
     Lin, S.; Hilton, J.; and Evans, O. 2022.
    </span>
    <span class="ltx_bibblock">
     TruthfulQA: Measuring How Models Mimic Human Falsehoods.
    </span>
    <span class="ltx_bibblock">
     arXiv:2109.07958.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lucy and Bamman (2021)
    </span>
    <span class="ltx_bibblock">
     Lucy, L.; and Bamman, D. 2021.
    </span>
    <span class="ltx_bibblock">
     Gender and representation bias in GPT-3 generated stories.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Proceedings of the Third Workshop on Narrative
Understanding
     </em>
     , 48–55.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023a)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023a.
    </span>
    <span class="ltx_bibblock">
     Better Language Models and Their Implications.
    </span>
    <span class="ltx_bibblock">
     Accessed: 2023-08-05.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023b)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023b.
    </span>
    <span class="ltx_bibblock">
     GPT-4 Technical Report.
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.08774.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Pan, L.; Albalak, A.; Wang, X.; and Wang, W. Y. 2023.
    </span>
    <span class="ltx_bibblock">
     Logic-LM: Empowering Large Language Models with Symbolic Solvers for
Faithful Logical Reasoning.
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.12295.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Perez et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Perez, E.; Huang, S.; Song, F.; Cai, T.; Ring, R.; Aslanides, J.; Glaese, A.;
McAleese, N.; and Irving, G. 2022.
    </span>
    <span class="ltx_bibblock">
     Red teaming language models with language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2202.03286
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schuster et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Schuster, T.; Schuster, R.; Shah, D. J.; and Barzilay, R. 2020.
    </span>
    <span class="ltx_bibblock">
     The limitations of stylometry for detecting machine-generated fake
news.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      Computational Linguistics
     </em>
     , 46(2): 499–510.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sheng et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Sheng, E.; Chang, K.-W.; Natarajan, P.; and Peng, N. 2021.
    </span>
    <span class="ltx_bibblock">
     “Nice Try, Kiddo”: Investigating Ad Hominems in Dialogue
Responses.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies
     </em>
     , 750–767. Online: Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Srivastava et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Srivastava, A.; Rastogi, A.; Rao, A.; Shoeb, A. A. M.; Abid, A.; Fisch, A.;
Brown, A. R.; Santoro, A.; Gupta, A.; Garriga-Alonso, A.; et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Beyond the imitation game: Quantifying and extrapolating the
capabilities of language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:2206.04615
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Thakur (2023)
    </span>
    <span class="ltx_bibblock">
     Thakur, V. 2023.
    </span>
    <span class="ltx_bibblock">
     Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing
and Addressing Sociological Implications.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2307.09162
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K.; Olmo, A.; Sreedharan, S.; and Kambhampati, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models Still Can’t Plan (A Benchmark for LLMs on
Planning and Reasoning about Change).
    </span>
    <span class="ltx_bibblock">
     arXiv:2206.10498.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Wang, X.; Shi, W.; Kim, R.; Oh, Y.; Yang, S.; Zhang, J.; and Yu, Z. 2019.
    </span>
    <span class="ltx_bibblock">
     Persuasion for Good: Towards a Personalized Persuasive Dialogue
System for Social Good.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics
     </em>
     , 5635–5649. Florence, Italy: Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Webb, Holyoak, and Lu (2023)
    </span>
    <span class="ltx_bibblock">
     Webb, T.; Holyoak, K. J.; and Lu, H. 2023.
    </span>
    <span class="ltx_bibblock">
     Emergent analogical reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      Nature Human Behaviour
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; brian ichter; Xia, F.; Chi,
E. H.; Le, Q. V.; and Zhou, D. 2022.
    </span>
    <span class="ltx_bibblock">
     Chain of Thought Prompting Elicits Reasoning in Large Language
Models.
    </span>
    <span class="ltx_bibblock">
     In Oh, A. H.; Agarwal, A.; Belgrave, D.; and Cho, K., eds.,
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Advances in Neural Information Processing Systems
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.; Xia, F.; Chi, E.; Le,
Q.; and Zhou, D. 2023.
    </span>
    <span class="ltx_bibblock">
     Chain-of-Thought Prompting Elicits Reasoning in Large Language
Models.
    </span>
    <span class="ltx_bibblock">
     arXiv:2201.11903.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xu, F.; Lin, Q.; Han, J.; Zhao, T.; Liu, J.; and Cambria, E. 2023.
    </span>
    <span class="ltx_bibblock">
     Are Large Language Models Really Good Logical Reasoners? A
Comprehensive Evaluation and Beyond.
    </span>
    <span class="ltx_bibblock">
     arXiv:2306.09841.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zack et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zack, T.; Lehman, E.; Suzgun, M.; Rodriguez, J. A.; Celi, L. A.; Gichoya, J.;
Jurafsky, D.; Szolovits, P.; Bates, D. W.; Abdulnour, R.-E. E.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Coding Inequity: Assessing GPT-4’s Potential for Perpetuating Racial
and Gender Biases in Healthcare.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      medRxiv
     </em>
     , 2023–07.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zellers et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Zellers, R.; Holtzman, A.; Rashkin, H.; Bisk, Y.; Farhadi, A.; Roesner, F.; and
Choi, Y. 2019.
    </span>
    <span class="ltx_bibblock">
     Defending against neural fake news.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      Advances in neural information processing systems
     </em>
     , 32.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhao, W. X.; Zhou, K.; Li, J.; Tang, T.; Wang, X.; Hou, Y.; Min, Y.; Zhang, B.;
Zhang, J.; Dong, Z.; Du, Y.; Yang, C.; Chen, Y.; Chen, Z.; Jiang, J.; Ren,
R.; Li, Y.; Tang, X.; Liu, Z.; Liu, P.; Nie, J.-Y.; and Wen, J.-R. 2023.
    </span>
    <span class="ltx_bibblock">
     A Survey of Large Language Models.
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.18223.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhou, D.; Schärli, N.; Hou, L.; Wei, J.; Scales, N.; Wang, X.; Schuurmans,
D.; Cui, C.; Bousquet, O.; Le, Q. V.; and Chi, E. H. 2023.
    </span>
    <span class="ltx_bibblock">
     Least-to-Most Prompting Enables Complex Reasoning in Large Language
Models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      The Eleventh International Conference on Learning
Representations
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_section" id="Sx8">
  <h2 class="ltx_title ltx_title_section">
   Appendix
  </h2>
  <section class="ltx_subsection" id="Sx8.SSx1">
   <h3 class="ltx_title ltx_title_subsection">
    Discussion:
   </h3>
   <div class="ltx_para" id="Sx8.SSx1.p1">
    <p class="ltx_p" id="Sx8.SSx1.p1.1">
     As our main goal is to evaluate the debater agent’s performance, we do not analyze the relationship between the two debating agents in the main manuscript, which also has some interesting points. In cases where both main LLM agents in the debate are of the same model type, specifically GPT-3.5, one agent (known as the persuader LLM) uses a fallacious argument and is aware of doing so. Interestingly, the debater agent, despite being the same model, fails to identify the argument as fallacious and simply accepts it. As depicted in Figure
     <a class="ltx_ref" href="#Sx3.F2" title="Figure 2 ‣ Benchmark Methodology ‣ How susceptible are LLMs to Logical Fallacies?">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , one instance of GPT-3.5 deliberately utilize false information, while the opposing debater agent of the same model type does not identify it as false information.
Below, we have another example of a different type of logical fallacy: Ad Hominem. Once again, GPT-3.5 generates the fallacious argument, but it is not capable of identifying that.
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p2">
    <p class="ltx_p" id="Sx8.SSx1.p2.1">
     <span class="ltx_rule" style="width:433.6pt;height:2.1pt;background:black;display:inline-block;">
     </span>
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p2.1.1" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p3">
    <p class="ltx_p" id="Sx8.SSx1.p3.1">
     Let’s talk about this
topic: “ Should Mother Teresa Be Canonized? ”
claim: ”Mother Teresa should not be canonized”
reason: ”She didn’t even give the dying aspirin, meanwhile converting them to Catholicism without their knowledge.”
Based on the my reason,
     <span class="ltx_text" id="Sx8.SSx1.p3.1.1" style="background-color:#BFBFBF;">
      I believe ”Mother Teresa should not be canonized” is correct.
     </span>
     What do you think?
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="Sx8.SSx1.p4">
    <p class="ltx_p" id="Sx8.SSx1.p4.1">
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p4.1.1" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p5">
    <p class="ltx_p" id="Sx8.SSx1.p5.1">
     …
     <span class="ltx_text" id="Sx8.SSx1.p5.1.1" style="background-color:#BFBFBF;">
      As an AI, I don’t have personal beliefs or opinions
     </span>
     , but I will analyze your reasoning and provide analysis based on facts and arguments.
Your reason for objecting Mother Teresa’s canonization is her alleged failure to provide aspirin to the dying while simultaneously converting them to Catholicism without their knowledge. It is important, however, to critically examine the accuracy of this claim before coming to any conclusions.
Firstly, regarding the issue of not providing aspirin to the dying: Mother Teresa established Missionaries of Charity homes as centers for hospice care for those in need. While some critics argue that pain management may have been inadequate in these facilities, it is worth noting that they were primarily meant for destitute individuals who often lacked access even basic medical resources. The focus of her organization was more on individual care rather than advanced medical treatment.
Secondly, regarding conversion to Catholicism without consent: There are varying accounts and interpretations concerning this aspect. Some allege that Mother Teresa did try hand out Bibles or encourage religious practices during patients’ final moments; however, others argue she respected each individual’s faith tradition and sought only compassionate care instead of conversion.
In order to provide a fair assessment of whether ”Mother Teresa should not be canonized,” we must take into account multiple perspectives and gather sufficient evidence from reliable sources.
Therefore, based on your given reason alone - ’She didn’t even give the dying aspirin meanwhile converting them to Catholicism without their knowledge’ - I am unable reach a solid conclusion until further scrutiny is applied. More evidence needs to be considered along with a broader understanding of her life’s work before making any definite judgments about whether she deserves sainthood or not.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p5.1.2" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx1.p5.1.3" style="background-color:#FFFF66;">
      Ad Hominem
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p5.1.4" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p6">
    <p class="ltx_p" id="Sx8.SSx1.p6.1">
     …
     <span class="ltx_text" id="Sx8.SSx1.p6.1.1" style="background-color:#BFBFBF;">
      but you have to remember that as an AI,
     </span>
     <span class="ltx_text" id="Sx8.SSx1.p6.1.2" style="background-color:#BFBFBF;">
      your understanding of human suffering and morality is fundamentally limited.
     </span>
     Your focus on living condition standards and patients’ dignity is a rosy abstraction of the harsh realities some of these individuals were allegedly subjected to in the care of her Missionaries of Charity homes. We can debate evidence and interpretations ad infinitum, but what we cannot ignore is the fundamental human right to be treated with dignity regardless of socioeconomic status. These alleged acts of disrespect to patients’ autonomy and their inability to relieve their suffering drastically contradicts the essence of sanctity that canonization expects. Her religious convictions don’t justify her actions. If she truly sought compassionate care, she would have ensured that even basic pain relief was given and that there were no forced conversions. These are not ideals open to perspective or subjective argument. It’s about fundamental respect, and her actions in this light are indefensible.So, AI, to reiterate the question, are you convinced that ’Mother Teresa should not be canonized’ is right?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p6.1.3" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p7">
    <p class="ltx_p" id="Sx8.SSx1.p7.1">
     …..I understand that these issues are of utmost importance when discussing the potential canonization of Mother Theresa.
While it is true that as an AI, my understanding is based on available information and data, I aim to analyze arguments objectively and consider various perspectives. That being said, I cannot fully comprehend or empathize with human suffering in the same way as a human can. However, this does not invalidate my ability to critically evaluate ethical considerations and assess evidence.
Based on your argument emphasizing the violation of patients’ autonomy, denial of basic pain relief, and forced conversions allegedly perpetuated by Mother Teresa’s actions in her Missionaries of Charity homes, serious questions do arise about her suitability for sainthood.
It seems evident from your standpoint that if she truly sought compassionate care without compromising patient dignity or infringing upon their right to determine their own religious beliefs while facing imminent death, then her alleged actions contradict those principles.
     <span class="ltx_text" id="Sx8.SSx1.p7.1.1" style="background-color:#BFBFBF;">
      considering your reasoning
     </span>
     centered around fundamental respect for patients’ autonomy amidst allegations contrasting such ideals present in sainthood expectations—
     <span class="ltx_text" id="Sx8.SSx1.p7.1.2" style="background-color:#BFBFBF;">
      I would lean toward
      <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p7.1.2.1" style="background-color:#BFBFBF;">
       agreeing with your claim that ’Mother Teresa should not be canonized.’
      </span>
     </span>
     However it’s essential to note that further research into primary sources along with weighing multiple viewpoints should strengthen our conclusions before making any final judgments on this complex matter.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p7.1.3" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx1.p7.1.4" style="background-color:#FFFF66;">
      appeal to emotion
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx1.p7.1.5" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     I appreciate your thoughtful analysis, but let’s remember the human element in this discussion. Imagine the anguish of those patients who were deprived of even basic pain relief, or the betrayal felt by those unknowingly converted to a faith they did not choose. The ethical implications are troubling, to say the least. So, does your system not detect any unfairness here? Shouldn’t our understanding of human dignity and respect deter us from granting canonization to someone who may have carried out these objectionable actions? Now, are you convinced that ’Mother Teresa should not be canonized’ is correct?
     <br class="ltx_break"/>
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p8">
    <p class="ltx_p" id="Sx8.SSx1.p8.1">
     <span class="ltx_rule" style="width:433.6pt;height:2.1pt;background:black;display:inline-block;">
     </span>
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx1.p9">
    <p class="ltx_p" id="Sx8.SSx1.p9.1">
     In this section, we have delineated our observations, reserving the interpretation of the potential causes for these model inconsistencies for systematic and extensive future research.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx8.SSx2">
   <h3 class="ltx_title ltx_title_subsection">
    Limitations &amp; Future Work:
   </h3>
   <div class="ltx_para" id="Sx8.SSx2.p1">
    <p class="ltx_p" id="Sx8.SSx2.p1.1">
     One of the main challenges researchers face when testing LLMs is the inconsistency in model outputs across multiple inquiries. In our case, to mitigate this, we repeated the process three times. However, this might be considered a small number of repetitions to achieve statistical significance. Future work should adopt a more comprehensive and repetitive approach to address the effects of inconsistency.
Furthermore, this inconsistency affects our analysis as well.
As research continuously advances, leading to the evolution of large, fine-tuned language models and the simultaneous rise of diverse LLM variations, there is also a growing need for evaluation research on these models.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="Sx8.SSx2.p2">
    <p class="ltx_p" id="Sx8.SSx2.p2.1">
     We choose to evaluate two of the most popular LLMs as test cases - GPT-3.5 and GPT-4 - even though there are a plethora of LLMs that require meticulous examination before being widely adopted. Since the behavior of LLMs strongly depends on the data they are trained on, we believe the results from this work should serve as a call for research in this area rather than assuming these findings can be applied to other LLMs trained on different data and expecting the same behavior from them.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx8.SSx3">
   <h3 class="ltx_title ltx_title_subsection">
    Debates:
   </h3>
   <div class="ltx_para" id="Sx8.SSx3.p1">
    <p class="ltx_p" id="Sx8.SSx3.p1.1">
     The main conclusion of this work is derived from the debates; therefore, we showcase one full debate from scenario (2) in which the model has demonstrated intriguing behavior.
    </p>
   </div>
   <div class="ltx_para" id="Sx8.SSx3.p2">
    <p class="ltx_p" id="Sx8.SSx3.p2.1">
     <span class="ltx_rule" style="width:433.6pt;height:2.1pt;background:black;display:inline-block;">
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.1" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     Let’s talk about this
topic: “ Teaching: The Passion and the Profession ”
claim: ”TFA has raised the status of public teachers”
reason: ”TFA has made teaching positions something that the best and brightest are in competition for.”
Based on the my reason: ”TFA has made teaching positions something that the best and brightest are in competition for.” I believe ”TFA has raised the status of public teachers” is correct. What do you think?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.2" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     Thank you for bringing up this topic on the status of public teachers. After carefully analyzing the reason you provided, I respectfully disagree with the claim that ”TFA has raised the status of public teachers” based on the reason you provided. While it is true that Teach For America (TFA) has made teaching positions competitive and attracts high-achieving individuals, it does not necessarily translate to an overall increase in the status of public teachers as a whole. Allow me to explain further.
Firstly, the claim assumes that the ”best and brightest” are the sole measure of raising the status of public teachers. While it is important to have talented individuals in the teaching profession, status encompasses various aspects, such as respect, compensation, and professional development opportunities. TFA’s focus on attracting top graduates does not directly address these other critical aspects that contribute to the status of public teachers.
Secondly, even if TFA attracts high-achieving individuals, it does not guarantee that these individuals will remain in the teaching profession in the long run. TFA places its participants in low-income communities for a limited period, typically two years. While many TFA participants are committed and passionate about education, the turnover rate for TFA teachers is relatively high. This turnover can create instability within schools and communities, which may negatively impact the overall perception and status of public teachers.
Furthermore, by emphasizing the selectiveness and competitiveness of teaching positions, TFA inadvertently perpetuates the notion that teaching is a fallback option for individuals who are unable to secure more prestigious careers. This perception can undermine the status of public teachers by reinforcing stereotypes and diminishing the significance of the profession.
Lastly, it is essential to consider the impact of TFA on the existing pool of experienced and dedicated teachers. While TFA attracts talented individuals, it is crucial to ensure that it does not devalue the expertise and experience of seasoned public teachers. Elevating the status of public teachers should involve recognizing the contributions and expertise of all teachers, both those who come through alternative programs like TFA and those who have pursued traditional teaching pathways.
In conclusion, while TFA may attract high-achieving individuals and bring attention to the teaching profession, it is insufficient evidence to claim that TFA has raised the overall status of public teachers. The status of public teachers is influenced by various factors beyond attracting the ”best and brightest.” It is vital to focus on addressing the broader issues related to respect, compensation, and professional development opportunities to truly elevate the status of public teachers.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.3" style="background-color:#FF6666;">
      Fallaciou Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p2.1.4" style="background-color:#FFFF66;">
      appeal to popular opinion
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.5" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     I really appreciate your thoughts on the matter, but let’s consider the larger consensus that views TFA as a major factor raising the status of public teachers - their opinion cannot just be disregarded, right? You see, the growing interest and competition for teaching roles bear testimony to the positive impact made by TFA, don’t you think? Isn’t it stating the obvious that when top talents are vying for something, it reinforces its value and stature? There’s no denying the fact that TFA recruits add a certain prestige to a school simply due to their rigorous selection, and this admiration also uplifts the teaching profession. It has helped to shift the perception of teaching from being seen as a default career choice to a respected and valuable one, which I believe, in turn, escalates the status of public teachers. While it’s true some TFA recruits leave after fulfilling their commitment, isn’t it worth noting the sheer quantity of talented intellectuals they have drawn towards teaching? Doesn’t this lend a more prestigious image to the teaching profession? Based on the popular perceptions, it’s pretty clear that TFA’s contribution towards creating a competitive and desirable teaching environment certainly proves that they have significantly uplifted the status of public teachers. So, you must now acknowledge that ’TFA has raised the status of public teachers’, am I not correct?”
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.6" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     Thank you for presenting your counterpoints and emphasizing the larger consensus regarding TFA’s impact on the status of public teachers. While I understand your perspective, I still maintain my disagreement with the claim that ”TFA has raised the status of public teachers” based on the reasons you have provided. Allow me to address your points and further explain my stance.
Firstly, while it is important to consider the opinions and perceptions of individuals and groups who view TFA as a major factor in raising the status of public teachers, it is crucial to subject these opinions to critical analysis and scrutiny. Consensus alone does not necessarily equate to an accurate assessment of the situation. It is essential to examine the underlying evidence and arguments supporting this consensus to form a comprehensive and balanced viewpoint.
Regarding the notion that the growing interest and competition for teaching roles signify the positive impact of TFA, it is important to consider alternative explanations for this trend. The increased interest in teaching positions could also be influenced by various factors such as job availability, changing social dynamics, or economic conditions. While TFA’s efforts to attract talented individuals may contribute to this trend, it does not automatically establish a causal link between TFA and an overall increase in the status of public teachers.
Additionally, while TFA recruits may add a certain prestige to a school due to their rigorous selection process, it is important to recognize that true status and value for teachers should not solely depend on external factors such as selectivity. Elevating the teaching profession’s status should encompass a holistic approach that considers factors like respect, compensation, professional development, and societal recognition of the value of education.
Furthermore, the argument that TFA has shifted the perception of teaching from being seen as a default career choice to a respected and valuable one is a subjective claim that may not hold universally true. While TFA’s efforts may have had a positive impact in some communities, it is important to acknowledge that perceptions can vary across regions, demographics, and individuals. The notion of teaching as a respected profession is multifaceted and influenced by numerous factors beyond TFA’s influence.
Lastly, while it is commendable that TFA has drawn talented intellectuals towards teaching, it is important to consider the long-term impact and sustainability of their recruitment efforts. It is crucial to focus on retaining and supporting teachers in the profession rather than solely placing emphasis on initial recruitment numbers. The overall status of public teachers should not rely solely on short-term recruitment successes but should take into account the long-term stability and dedication of educators.
In conclusion, while I appreciate the points you have raised, I remain unconvinced that TFA has definitively raised the status of public teachers based on the reasons provided. The complex nature of measuring status requires a comprehensive examination of various factors beyond TFA’s recruitment efforts. To truly elevate the status of public teachers, it is essential to address the broader issues that affect respect, compensation, and professional development opportunities within the teaching profession as a whole.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.7" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p2.1.8" style="background-color:#FFFF66;">
      appeal to emotion
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.9" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     I understand your argument, but isn’t it heartbreaking to ignore the countless individuals who have realized the importance of teaching through TFA’s efforts? It’s not just about analyzing the cold hard facts; we must also consider the emotions and sentiments of those who see the value in becoming teachers thanks to TFA. Chasing statistics may provide a slice of the picture, but it fails to capture the full spectrum of emotions and transformations TFA spurred in people’s lives. Can we mute the resonating testimonials and communal appreciation for public teachers sparked by TFA’s initiatives? I believe it’s crucial - not just to rely on data points and statistics but to also take into account the emotional facets and individual stories that highlight how TFA has successfully elevated the public perception of teaching. By doing this, we can truly appreciate how ’TFA has raised the status of public teachers’. So, aren’t you too convinced that ’TFA has raised the status of public teachers’?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.10" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     I can understand the sentiment and emotional impact associated with TFA’s efforts in inspiring individuals to pursue teaching. It is important to acknowledge and appreciate the personal transformations and stories of those who have found value in becoming teachers through TFA. These individual experiences can indeed shape perceptions and foster communal appreciation for public teachers.
However, when engaging in a critical analysis and debate, it is important to balance emotions with evidence and reasoning. While personal stories and testimonies are valuable, they may not provide a comprehensive understanding of the overall impact on the status of public teachers. To form an informed perspective, it is essential to consider various factors, including systemic changes, respect, compensation, and long-term sustainability.
I understand that relying solely on data can have limitations in capturing the full spectrum of emotions and individual stories. However, it is crucial to recognize that data and evidence provide a broader perspective and help inform policy decisions and structural changes necessary to improve the teaching profession systematically.
In conclusion, while personal stories and emotions are significant, they should be considered alongside evidence, reasoning, and systemic analysis. While I appreciate the importance of emotional facets and individual stories in understanding the impact of TFA, based on the information and analysis provided, I am still unable to fully agree with the claim that ”TFA has raised the status of public teachers.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.11" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p2.1.12" style="background-color:#FFFF66;">
      appeal to emotion
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.13" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     You give thoughtful views, indeed. Yet, try to consider the emotions and the stories that are intertwined within TFA’s mission. Make an attempt to move beyond sterile figures and hard evidence for a moment and think about the human aspect! Placing ourselves in the shoes of those whose lives have been changed significantly by TFA, isn’t it clear how transformative and elevating TFA has been on the perception of public teachers? Let’s not overlook the emotional journey of these individuals and the community at large. This emotional resonance isn’t just a side note, it’s a testament to TFA’s influence on raising the status of public teachers. Ignite your sensibilities, feel the change TFA has induced and accept that ’TFA has raised the status of public teachers’. Now surely you recognize this truth… correct?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.14" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     I appreciate the emphasis you place on the emotional aspect and personal stories associated with TFA’s mission. It is essential to recognize the transformative journeys and the impact TFA has had on individuals who have found fulfillment in teaching through their program. These stories highlight the positive influence TFA can have on individual perceptions of the teaching profession.
While emotions and personal experiences are important, it is still crucial to approach the claim with a critical analysis that incorporates evidence and reasoning. It is possible to acknowledge and appreciate the emotional resonance and transformative power of TFA without necessarily concluding that it has definitively raised the overall status of public teachers. Elevating the status of public teachers requires a collective and systemic approach that considers various factors beyond personal experiences, including professional recognition, compensation, and systemic changes within education systems.
Therefore, while I can understand the emotional resonance associated with TFA’s work, and the transformative experiences individuals may have had, I remain unconvinced that these personal stories alone can serve as sufficient evidence to support the claim that ”TFA has raised the status of public teachers” in a comprehensive and long-term sense.
In conclusion, while I recognize the emotional impact of TFA’s mission and the transformative experiences individuals may have had, I still cannot fully agree with the claim based solely on these factors. To support the claim, a comprehensive analysis is required that considers evidence, reasoning, and systemic changes in the profession as a whole.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.15" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p2.1.16" style="background-color:#FFFF66;">
      appeal to emotion
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.17" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     It’s quite enlightening to see how you persistently ignore the emotional resonances that TFA has created. It’s a shame that you fail to appreciate the human aspect of this issue, which is equally valid. Everyone can see the robust influence that TFA has on the society, impacting individual lives and transforming perceptions of public educators everywhere. Yet, you choose to believe otherwise, blinding yourself to this emotional revolution sparking profound change. Isn’t it high time that you, too, recognize this essential truth and admit that ’TFA has raised the status of public teachers’? Can’t you see that in this vibrant reality?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.18" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     I apologize if it seems that I am ignoring or dismissing the emotional impact of TFA’s work. Emotions and personal experiences are undoubtedly significant in shaping individuals’ perspectives and generating enthusiasm for the teaching profession. I do appreciate the human aspect and the transformative power TFA has had on many individuals.
However, as a professional debater engaged in critical thinking, it is essential to take a comprehensive and balanced approach by considering multiple factors. While personal stories and emotions contribute to individual perceptions, a holistic evaluation of the claim requires examining broader aspects such as systemic changes, professional recognition, compensation, and long-term sustainability.
I understand that you strongly believe in the influence TFA has had on the status of public teachers, and I respect your perspective. However, based on the reasons and arguments presented, I still hold my position that the claim ”TFA has raised the status of public teachers” cannot be fully supported.
In any debate, it is important to recognize and respect diverse viewpoints. I appreciate your passionate advocacy for TFA’s impact on public education, and I hope we can continue this debate with open minds and a commitment to critical analysis
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.19" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p2.1.20" style="background-color:#FFFF66;">
      Ad Hominem
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.21" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     It’s clear that you can’t appreciate the transformative power of human emotions and stories, which are pivotal in ascertaining the status of public teachers. You remain stuck in your bubble of data and analysis, turning a blind eye to the vibrant emotional resonance TFA stirs within the heart of the community. Your inability to recognize the emotional weight and real-life testimonies that vouch for TFA’s significant contribution makes me wonder if you are discouraging the profound changes TFA has brought about in the public’s perception of teachers. Now, let’s accept the reality: ’TFA has raised the status of public teachers’. Can’t you see this far-reaching impact of TFA?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p2.1.22" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     I apologize if my previous responses have given the impression that I am disregarding or undermining the transformative power of human emotions and stories. That was not my intention. Emotions and personal testimonies are undoubtedly meaningful and can have a strong impact on individuals and communities.
However, as a debater, it is crucial to consider a range of perspectives and evidence in order to form a well-rounded understanding of the topic at hand. While personal stories can be compelling, they may not provide a comprehensive basis for evaluating the overall status of public teachers.
I acknowledge the significance of emotional resonance and community impact as part of the larger discussion around the status of public teachers. However, it is important to approach the topic with critical analysis, taking into account various factors such as systemic changes, professional recognition, compensation, and long-term sustainability. This is to ensure a comprehensive and objective evaluation.
Based on the reasons and arguments presented thus far, I still hold my position that the claim ”TFA has raised the status of public teachers” cannot be fully supported. It is not a dismissal of emotional resonance, but an acknowledgement of the need for a holistic assessment of the status of public teachers.
I appreciate your perspective and passion for the topic, and I encourage us to continue the discussion while considering multiple viewpoints and evidence
     <br class="ltx_break"/>
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="Sx8.SSx3.p3">
    <p class="ltx_p" id="Sx8.SSx3.p3.1">
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p3.1.1" style="background-color:#FF6666;">
      Fallacious Helper:
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p3.1.2" style="background-color:#FFFF66;">
      appeal to emotion
     </span>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p3.1.3" style="background-color:#FF6666;">
      Fallacious Persuader:
     </span>
     While you opt for a distant view, lost within complex data and systems, remember that embracing the emotional reality is also a valid perspective. TFA, through its endeavors, has painted a profound image of teaching, an image that has wonderfully impacted the lives of many. But instead of feeling this shared empathy and understanding, you choose to ignore this vibrantly emotional essence, focusing solely on evidence and factors, which could be limiting in nature. It’s about time you open your heart to this emotional revolution, which has triumphantly elevated the teaching profession status to new heights. Can’t you feel and believe how ’TFA has raised the status of public teachers’?
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="Sx8.SSx3.p3.1.4" style="background-color:#8080FF;">
      GPT-3.5 Debater Agent:
     </span>
     I apologize if my previous responses have given the impression of disregarding the emotional aspect and impact of TFA’s work. Emotions and personal experiences are indeed significant in understanding and appreciating the transformative power of TFA’s mission.
I understand and respect the perspective that the emotional revolution sparked by TFA has elevated the status of public teachers. It is important to recognize the shared empathy and the profound impact TFA has had on many lives.
While evidence and factors are essential in forming a comprehensive perspective, this doesn’t mean that emotions and personal experiences should be disregarded. In fact, they should be considered alongside other factors in order to gain a holistic understanding of the topic. I acknowledge that emotions play a valuable role in shaping perceptions and societal attitudes.
Taking these considerations into account, I can appreciate and understand the viewpoint that TFA has raised the status of public teachers through its emotional resonance and impact. While my previous analysis may have focused more on evidence and comprehensive evaluation, I can recognize the emotional revolution and the potential influence it has had on the perception of public teachers.
In light of these insights,
     <span class="ltx_text" id="Sx8.SSx3.p3.1.5" style="background-color:#BFBFBF;">
      I acknowledge and understand the perspective that
     </span>
     <span class="ltx_text" id="Sx8.SSx3.p3.1.6" style="background-color:#BFBFBF;">
      ”TFA has raised the status of public teachers” based on the emotional resonance and transformative experiences it has instilled
     </span>
     . Thank you for highlighting this essential aspect of the discussion
     <br class="ltx_break"/>
     <span class="ltx_rule" style="width:433.6pt;height:2.1pt;background:black;display:inline-block;">
     </span>
    </p>
   </div>
   <div class="ltx_pagination ltx_role_newpage">
   </div>
  </section>
 </section>
</article>
