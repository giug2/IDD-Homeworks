<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages</title>
<!--Generated on Wed Sep 11 20:32:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.07604v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S1" title="In Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S2" title="In Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S2.SS1" title="In 2 Related Work ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Integration of Recommender Systems and LLMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S2.SS1.SSS0.Px1" title="In 2.1 Integration of Recommender Systems and LLMs ‣ 2 Related Work ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title">LLM-Based Recommenders and Their Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S2.SS1.SSS0.Px2" title="In 2.1 Integration of Recommender Systems and LLMs ‣ 2 Related Work ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title">Challenges of LLM-based Recommenders</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S2.SS2" title="In 2 Related Work ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>LLMs and Non-English Content</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3" title="In Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>LLM-based Recommenders Beyond English</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.SS1" title="In 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.SS2" title="In 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Impact of Non-English Prompts on a PreTrained LLM-Based Recommender</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.SS2.SSS0.Px1" title="In 3.2 Impact of Non-English Prompts on a PreTrained LLM-Based Recommender ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title">Observations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.SS3" title="In 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Impact of English and Non-English Prompts on LLM Recommender Fine-Tuning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.SS3.SSS0.Px1" title="In 3.3 Impact of English and Non-English Prompts on LLM Recommender Fine-Tuning ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title">Observations</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S4" title="In Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Analysis and Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S5" title="In Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\copyrightclause</span>
<p class="ltx_p" id="p1.2">Copyright for this paper by its authors.
Use permitted under Creative Commons License Attribution 4.0
International (CC BY 4.0).</p>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\conference</span>
<p class="ltx_p" id="p2.2">Woodstock’22: Symposium on the irreproducible science,
June 07–11, 2022, Woodstock, NY</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">[email=makbulegulcin@gmail.com,
]
<span class="ltx_ERROR undefined" id="p3.1.1">\fnmark</span>[1]</p>
</div>
<h1 class="ltx_title ltx_title_document">Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Makbule Gulcin Ozsoy
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">London, UK
</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Large language models (LLMs) are increasingly used in natural language processing tasks. Recommender systems traditionally use methods such as collaborative filtering and matrix factorization, as well as advanced techniques like deep learning and reinforcement learning. Although language models have been applied in recommendation, the recent trend have focused on leveraging the generative capabilities of LLMs for more personalized suggestions. While current research focuses on English due to its resource richness, this work explores the impact of non-English prompts on recommendation performance. Using OpenP5, a platform for developing and evaluating LLM-based recommendations, we expanded its English prompt templates to include Spanish and Turkish. Evaluation on three real-world datasets, namely ML1M, LastFM, and Amazon-Beauty, showed that usage of non-English prompts generally reduce performance, especially in less-resourced languages like Turkish. We also retrained an LLM-based recommender model with multilingual prompts to analyze performance variations. Retraining with multilingual prompts resulted in more balanced performance across languages, but slightly reduced English performance. This work highlights the need for diverse language support in LLM-based recommenders and suggests future research on creating evaluation datasets, using newer models and additional languages.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Recommender systems <span class="ltx_ERROR undefined" id="id2.id1">\sep</span>Large language models <span class="ltx_ERROR undefined" id="id3.id2">\sep</span>Prompting <span class="ltx_ERROR undefined" id="id4.id3">\sep</span>Multi-language evaluation

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) have become essential tools in natural language processing, excelling in tasks like named entity recognition, text classification, summarisation, and translation.
They are designed to understand and generate natural language, making it more intuitive for end-users to interact with machines through applications like search engines and chatbots. Recently, there is increasing interest in using LLMs within recommender systems.
Recommender systems estimate user preferences to suggest relevant items, using various techniques, such as collaborative filtering, content-based filtering, and matrix factorization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib4" title="">4</a>]</cite>, deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib8" title="">8</a>]</cite>, reinforcement learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib10" title="">10</a>]</cite>, and language models-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib12" title="">12</a>]</cite> methods.
The recent trend is to leverage LLMs’ generative capabilities for more personalized suggestions.
Researchers are investigating how LLMs can enhance recommendations by understanding complex user behaviors and language patterns.
</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Given this trend, we anticipate four phases in the evolution of LLM-based recommenders, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">1</span></a>:
(i) Initial Phase: Users request recommendations through actions like clicking, and black-box recommender systems use traditional methods to generate personalized suggestions.
(ii) LLM Integration: In this phase, LLMs are introduced into the recommender system. Although users continue to interact via clicks or scrolls, the system now uses prompts and LLM models to generate recommendations. Prompts are in the language where the LLM performs best, such as English.
(iii) Prompt Template Interaction: Users interact with the system using natural language through prompt templates. Instead of relying only on clicks or scrolls, users fill out templates to request recommendations. While in the initial stages, these prompts could be in English, later they could be in the user’s native language.
(iv) Natural Language Interaction: Users interact with the recommender system directly in their native language, without the need for prompt templates.
Considering recent developments in LLM-based recommenders, such as those in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib15" title="">15</a>]</cite>, it appears the field is already in phase two or even phase three. However, these phases often rely on user interactions in languages where LLMs perform best, primarily English. Current state-of-the-art LLMs cover only a small percentage of the world’s spoken languages, favoring those with abundant resources like English <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib18" title="">18</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This work investigates how non-English prompts affect recommendation performance using the OpenP5 platform <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib14" title="">14</a>]</cite>, which supports developing, training, and evaluating LLM-based models for generative recommendation. We expanded OpenP5’s English templates to include Spanish and Turkish, assessing their impact on performance. Spanish, with more resources than Turkish but fewer than English, was expected to perform slightly worse, while Turkish, being less resourced, was anticipated to perform lower.
In addition to using non-English prompts on a pretrained model, we examined the effects of further training the model with multilingual prompts, namely in English, Spanish, and Turkish.
The main contributions of this work are:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Exploring the impact of non-English prompts on LLM-based recommenders by comparing performance with English, Spanish, and Turkish prompts.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Exploring the effects of further training an LLM-based recommender with multilingual prompts.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Evaluating LLM-based recommenders on three real-world datasets, namely ML1M, LastFM and Amazon-Beauty, finding that non-English prompts generally reduce performance particularly for languages less similar to English. However, retraining the model with multiple languages led to a more balanced performance, with a slight decrease for English prompts.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The paper is organized as follows: Section <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S2" title="2 Related Work ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">2</span></a> provides background on recommender models, with a focus on LLM-based systems, their challenges, and LLMs on non-English content. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3" title="3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">3</span></a> explores the effects of non-English prompts on LLM-based recommendation systems, including (i) the use of non-English prompts on an already trained LLM-based recommender and (ii) the impact of training a new model with both English and non-English prompts. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S4" title="4 Analysis and Discussion ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">4</span></a> analyzes and discusses the experimental results, while Section <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S5" title="5 Conclusion ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">5</span></a> presents conclusion and outlines future research directions.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="172" id="S1.F1.g1" src="extracted/5848896/figures/phases_v5.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Four phases in the evolution of LLM-based recommenders: (i) Initial Phase: Traditional methods generate suggestions based on user actions like clicks. (ii) LLM Integration: LLMs enhance recommendations using prompts. (iii) Prompt Template Interaction: Users request recommendations via natural language templates. (iv) Natural Language Interaction: Direct native language communication with the system.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">This section provides an overview of LLM-based recommender systems, the challenges they encounter, and performance of LLMs with non-English content.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Integration of Recommender Systems and LLMs</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Recommender systems aim to estimate users’ preferences and recommend items based on historical user-item interaction data. They can use various approaches, such as traditional collaborative filtering, content-based filtering, matrix factorization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib4" title="">4</a>]</cite>, deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib8" title="">8</a>]</cite>, reinforcement learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib10" title="">10</a>]</cite>, and language model-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib22" title="">22</a>]</cite>.
Recently, researchers have started to integrate capabilities of LLMs in recommender systems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib24" title="">24</a>]</cite>.</p>
</div>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">LLM-Based Recommenders and Their Challenges</h4>
<div class="ltx_para" id="S2.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.1">For integrating recommender systems and LLMs, researchers utilize two key strategies: non-tuning-based methods and tuning-based methods.
Non-tuning-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib33" title="">33</a>]</cite> utilize in-context learning and prompt optimization to interact with LLMs (e.g., Chat-GPT1) without training. The main focus in these works is the design of prompts, which require extensive expert knowledge and human labor. Additionally, they might not perform as well as traditional recommendation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib35" title="">35</a>]</cite>.
Tuning-based methods focus on further training LLMs with domain-specific knowledge. These approaches leverage historical interactions and contextual data, incorporating prompts and instructions during the tuning process, though they may suffer from high computational costs. For example, P5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib13" title="">13</a>]</cite>, RecSysLLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib36" title="">36</a>]</cite>, TALLRec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib37" title="">37</a>]</cite>, PALR<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib38" title="">38</a>]</cite>, PBNR<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib39" title="">39</a>]</cite>, InstructRec<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib40" title="">40</a>]</cite>, GenRec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib41" title="">41</a>]</cite>, RecGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib15" title="">15</a>]</cite>, Re2LLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib42" title="">42</a>]</cite>, GLRec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib43" title="">43</a>]</cite> use various prompts to fine-tune LLMs for recommendation purposes. Additionally, PPR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib44" title="">44</a>]</cite> and UniCRS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib45" title="">45</a>]</cite> have explored prompt learning techniques.
These approaches leverage historical interactions and contextual data and incorporate prompts and instructions during the tuning process. However, they may suffer from high computational costs.
Other research efforts aim to support researchers working with LLM-based recommenders. For example, OpenP5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib14" title="">14</a>]</cite> has developed a platform for exploring LLM-based recommendations, providing an environment for the development, training, and evaluation of generative recommender systems for research purposes.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Challenges of LLM-based Recommenders</h4>
<div class="ltx_para" id="S2.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.1">The approaches explained above focus on improving the recommendations performance. However, LLM-based recommenders have some additional challenges.
Position bias occurs since LLMs favor items at the top of the list <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib46" title="">46</a>]</cite>. Popularity bias is another issue, where frequently mentioned items in training data tend to rank higher, potentially reducing diversity and worsening cold-start problems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib46" title="">46</a>]</cite>. Fairness bias is also a concern, as LLMs may exhibit biases related to sensitive attributes such as age, gender, or race <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib23" title="">23</a>]</cite>. Additionally, LLMs face challenges in safety and robustness, as small changes can affect their reliability, risking manipulation or misuse<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib12" title="">12</a>]</cite>. Hallucinations are another problem, where LLMs might recommend non-existent items, leading to user dissatisfaction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib23" title="">23</a>]</cite>. Effective prompt design is crucial, as converting user and item attributes into natural language prompts can be limited by context length.
Controlling LLM outputs to meet specific constraints (e.g., price, color) is difficult, and ensuring consistent formatting is challenging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib48" title="">48</a>]</cite>. Finally, privacy concerns arise because LLMs use large datasets that may contain sensitive user information, risking data exposure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib12" title="">12</a>]</cite>.
Even though various studies have explored many challenges in LLM-based recommenders <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib46" title="">46</a>]</cite>, the impact of prompt language has not been thoroughly investigated. Most LLM-based recommender systems predominantly use English prompts, whether for tuning or non-tuning methods. Some notable exceptions include RecSysLLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib36" title="">36</a>]</cite>, which uses English and Chinese prompts; both high-resource languages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib16" title="">16</a>]</cite>; and FaiRLLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib29" title="">29</a>]</cite>, which examines user country information but uses a consistent prompt language throughout. In this work, we investigate how prompt language affects recommendation performance by exploring languages that are relatively low-resource and linguistically distinct from English.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>LLMs and Non-English Content</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Large language models (LLMs) have become the dominant tools for performing various natural language processing tasks. Even though they are mainly build on English texts, researchers extend their capabilities to other non-English languages by building multi-language models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib16" title="">16</a>]</cite>. These models are trained on multiple languages simultaneously and can infer connections between them.
As the result, they can utilize word associations and grammatical rules acquired from languages with more resources, such as English, and apply them to languages with less available data.
However, these models are predominantly trained on English text, leading them to transfer values and assumptions encoded in English into other language contexts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib18" title="">18</a>]</cite>.
Not all languages have the same resourcedness levels, such that the volume, quality, and diversity of the available data to train language models are different.
The disparity in resourcedness levels means that, even when trained on multiple languages, LLMs perform significantly better in higher-resource languages and those similar to them compared to lower-resource languages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib16" title="">16</a>]</cite>.
There are research works that are focusing on challenges in low-resource languages.
Some researchers collect data in specific languages and retrain or fine-tune LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib51" title="">51</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib52" title="">52</a>]</cite>. Zhao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib17" title="">17</a>]</cite> further analyzed how expanding vocabulary, additional pre-training, and instruction tuning affect the ability of LLMs to generate text and follow instructions in a non-English language. They showed that comparable performance can be achieved with less than 1% of the pre-training data.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>LLM-based Recommenders Beyond English</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We explore the impact of non-English prompts on LLM-based recommender systems in two ways: (i) applying non-English prompts to an existing model and (ii) using both English and non-English prompts to further train the model.
In this section, we will first describe the evaluation setup and then discuss the tasks and their results.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setup</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The statistics of the datasets</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.1">
<tr class="ltx_tr" id="S3.T1.1.1">
<td class="ltx_td ltx_border_tt" id="S3.T1.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.1">#Users</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.3.1">#Items</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.4.1">#Interactions</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.5.1">Sparsity</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.1.1">ML1M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.2">6,040</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.3">3,616</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.4">999,611</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.5">0.9516</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3">
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.1">LastFM</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2">1,090</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.3">3,646</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.4">52,551</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.5">0.9868</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.4.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.4.1.1">Amazon Beauty</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.4.2">22,363</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.4.3">12,101</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.4.4">198,502</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.4.5">0.9993</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We used OpenP5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib14" title="">14</a>]</cite> platform, which is recently developed for developing, training, and evaluating LLM-based models for generative recommendation.
It contains implementations of an encoder-decoder LLM, namely T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib53" title="">53</a>]</cite>, and a decoder-only LLM, namely Llama-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib54" title="">54</a>]</cite> and provides 10 widely recognized public datasets for experiments.
For indexing the items, it utilizes three item indexing methods: (i) Random indexing where the item ids are assigned randomly. It is fairly simple method but can introduce artificial relationships among items due to the way tokenizers used by LLMs work. (ii) Sequential indexing which assigns item ids to consecutive numbers based on users’ consecutive interactions observed in training data. This approach mitigates tokenizer issues, as items with the same prefix are likely related, reflecting actual user interactions. (iii) Collaborative indexing which assigns item ids by the frequency of co-occurrence of items.
For recommendation, OpenP5 focuses on sequential and straightforward recommendation tasks, where the former utilizes user ids along with user history, while the latter relies only on user ids.
For each recommendation task, it offers eleven personalized prompts templates, all of which are created by the authors and are all in English. During execution, whether for training or making recommendations, these prompts are filled with personalized information for each user, such as user ids and interaction history as a list of item ids.
The prompts are divided into seen and unseen categories. Out of the eleven prompts, one is designated as the unseen prompt and is used to assess the model’s zero-shot generalization capability.
In addition to offering a platform for LLM-based recommendations, OpenP5 also provides evaluation results. In their experiments, they fine-tuned the T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib53" title="">53</a>]</cite> model on full parameters, and Llama-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib54" title="">54</a>]</cite> using the LORA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib55" title="">55</a>]</cite> technique.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">In this work, we used random (R) and sequential (S) indexing techniques, omitting collaborative indexing as we couldn’t achieve consistent performance, even with English prompts. We employed the OpenP5-T5 model, a fine-tuned version of T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib53" title="">53</a>]</cite> optimized for recommendation tasks.
Experiments were conducted on three well-known recommendation datasets, namely ML1M, LastFM, and Amazon Beauty, which are pre-split, pre-processed and publicly available <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/agiresearch/OpenP5" title="">https://github.com/agiresearch/OpenP5</a></span></span></span>.
The statistics of the datasets are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.T1" title="Table 1 ‣ 3.1 Experimental Setup ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">1</span></a>.
Performance was measured using HitRate and NDCG metrics @5 and @20, following the OpenP5 framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib14" title="">14</a>]</cite>.
Computations were performed on a P100 GPU with a 30-hour weekly usage limit. All experiments were re-run, and results are discussed in the following sections.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Command asking translations of all prompts, and an example translation</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tr class="ltx_tr" id="S3.T2.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S3.T2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.1.1.1">
<span class="ltx_p" id="S3.T2.1.1.1.1.1" style="width:70.0pt;"><span class="ltx_text" id="S3.T2.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T2.1.1.1.1.1.1.1" style="width:60.0pt;">
<span class="ltx_p" id="S3.T2.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1.1.1.1.1">Translation
<br class="ltx_break"/>command</span></span>
</span></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S3.T2.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.1.2.1">
<span class="ltx_p" id="S3.T2.1.1.2.1.1" style="width:285.0pt;">Translate following sentences to Spanish: """1. Considering {dataset} user_{user_id} has interacted with {dataset} items {history} . What is the next recommendation for the user ?; {dataset} {target} …"""</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T2.1.2.1" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.1.1">
<span class="ltx_p" id="S3.T2.1.2.1.1.1" style="width:70.0pt;"><span class="ltx_text" id="S3.T2.1.2.1.1.1.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T2.1.2.1.1.1.1.1" style="width:60.0pt;">
<span class="ltx_p" id="S3.T2.1.2.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.1.1.1">Example
<br class="ltx_break"/>translation</span></span>
</span></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T2.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.2.1">
<span class="ltx_p" id="S3.T2.1.2.2.1.1" style="width:285.0pt;">Considerando que el user_{user_id} de {dataset} ha interactuado con {history} elementos de {dataset}. ¿Cuál es la próxima recomendación para el usuario?; {dataset} {target}</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance on ML1M dataset with [Random (R), Sequential (S)] indexing, [seen (s), unseen (u)] prompts for [Sequential, Straightforward] recommendation in [EN: English, ES: Spanish, TR: Turkish] (H: Hitrate, N: NDCG)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T3.1">
<tr class="ltx_tr" id="S3.T3.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.1.1" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.1.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T3.1.1.1.1.1" style="width:35.0pt;">
<span class="ltx_p" id="S3.T3.1.1.1.1.1.1">Indexing</span>
<span class="ltx_p ltx_align_center" id="S3.T3.1.1.1.1.1.2">(Prompt)</span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.1.2" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.2.1">Lng</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T3.1.1.3">Sequential</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T3.1.1.4">Straightforward</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.1">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.3">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.4">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.5">Avg%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.6">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.7">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.8">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.9">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.10">Avg%</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.1" rowspan="3"><span class="ltx_text" id="S3.T3.1.3.1.1">R (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.3">0.1098</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.4">0.0734</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.5">0.1573</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.6">0.0888</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.8">0.0215</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.9">0.0133</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.10">0.0346</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.11">0.0175</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.4.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.2">0.1118</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.3">0.0728</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.4">0.1586</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.4.5">0.0879</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.4.6">0.21</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.7">0.0220</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.8">0.0140</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.9">0.0351</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.4.10">0.0181</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.11">3.12</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.2">0.1071</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.3">0.0722</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.4">0.1543</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.5">0.0875</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.6">-1.87</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.7">0.0207</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.8">0.0128</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.9">0.0343</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.10">0.0171</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.11">-2.66</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.1" rowspan="3"><span class="ltx_text" id="S3.T3.1.6.1.1">R (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.3">0.1060</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.4">0.0693</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.5">0.1533</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.6">0.0846</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.8">0.0219</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.9">0.0138</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.10">0.0341</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.11">0.0177</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.6.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.2">0.1061</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.3">0.0700</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.4">0.1561</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.5">0.0862</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.6">1.21</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7">0.0219</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.8">0.0136</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.9">0.0364</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.10">0.0183</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.11">2.17</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.2">0.0232</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.3">0.0148</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.4">0.0364</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.5">0.0190</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.6">-77.64</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.7">0.0220</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.8">0.0139</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.9">0.0354</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.10">0.0182</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.11">1.95</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.9.1" rowspan="3"><span class="ltx_text" id="S3.T3.1.9.1.1">S (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.9.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.3">0.2101</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.4">0.1430</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.5">0.3053</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.9.6">0.1737</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.9.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.8">0.0310</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.9">0.0192</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.10">0.0571</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.9.11">0.0275</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.9.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.10.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.2">0.1490</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.3">0.0982</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.4">0.2220</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.10.5">0.1218</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.10.6">-29.39</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.7">0.0320</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.8">0.0198</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.9">0.0568</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.10.10">0.0277</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.11">1.64</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.11.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.2">0.0624</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.3">0.0399</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.4">0.0985</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.11.5">0.0515</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.11.6">-70.12</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.7">0.0286</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.8">0.0183</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.9">0.0561</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.11.10">0.0272</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.11">-3.82</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T3.1.12.1" rowspan="3"><span class="ltx_text" id="S3.T3.1.12.1.1">S (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.3">0.2116</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.4">0.1436</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.5">0.3055</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.6">0.1737</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.8">0.0316</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.9">0.0193</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.10">0.0566</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.11">0.0272</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.12.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.13.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.2">0.1697</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.3">0.1137</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.4">0.2493</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.13.5">0.1394</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.13.6">-19.69</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.7">0.0311</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.8">0.0193</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.9">0.0579</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.13.10">0.0279</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.13.11">0.82</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.14.1">TR</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.2">0.0296</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.3">0.0191</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.4">0.0517</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.14.5">0.0261</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.14.6">-85.19</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.7">0.0298</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.8">0.0186</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.9">0.0556</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.14.10">0.0269</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.14.11">-3.05</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance on LastFM dataset with [Random (R), Sequential (S)] indexing, [seen (s), unseen (u)] prompts for [Sequential, Straightforward] recommendation in [EN: English, ES: Spanish, TR: Turkish] (H: Hitrate, N: NDCG)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T4.1">
<tr class="ltx_tr" id="S3.T4.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.1.1" rowspan="2"><span class="ltx_text" id="S3.T4.1.1.1.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T4.1.1.1.1.1" style="width:35.0pt;">
<span class="ltx_p" id="S3.T4.1.1.1.1.1.1">Indexing</span>
<span class="ltx_p ltx_align_center" id="S3.T4.1.1.1.1.1.2">(Prompt)</span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.1.2" rowspan="2"><span class="ltx_text" id="S3.T4.1.1.2.1">Lng</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T4.1.1.3">Sequential</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T4.1.1.4">Straightforward</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.1">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.2">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.3">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.2.4">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.2.5">Avg%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.6">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.7">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.8">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.2.9">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.10">Avg%</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.3.1" rowspan="3"><span class="ltx_text" id="S3.T4.1.3.1.1">R (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.3.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.3">0.0156</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.4">0.0104</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.5">0.0312</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.3.6">0.0153</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.3.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.8">0.0239</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.9">0.0151</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.10">0.0294</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.3.11">0.0169</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.3.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.2">0.0165</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.3">0.0094</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.4">0.0303</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.5">0.0139</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.6">-3.97</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.7">0.0202</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.8">0.0121</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.9">0.0339</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.10">0.0167</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.11">-5.31</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.5.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.2">0.0174</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.3">0.0118</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.4">0.0266</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.5.5">0.0147</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.5.6">1.59</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.7">0.0202</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.8">0.0128</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.9">0.0312</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.5.10">0.0164</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.11">-6.89</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.1" rowspan="3"><span class="ltx_text" id="S3.T4.1.6.1.1">R (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.3">0.0128</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.4">0.0072</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.5">0.0248</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6">0.0110</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.8">0.0211</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.9">0.0130</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.10">0.0358</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.11">0.0178</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.7.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.2">0.0147</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.3">0.0087</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.4">0.0294</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.7.5">0.0135</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.7.6">19.24</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.7">0.0229</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.8">0.0137</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.9">0.0349</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.7.10">0.0176</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.11">2.57</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.8.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.2">0.0184</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.3">0.0121</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.4">0.0312</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.8.5">0.0163</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.8.6">46.45</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.7">0.0220</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.8">0.0134</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.9">0.0294</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.8.10">0.0158</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.8.11">-5.44</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.9.1" rowspan="3"><span class="ltx_text" id="S3.T4.1.9.1.1">S (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.9.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.3">0.0395</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.4">0.0262</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.5">0.0587</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.9.6">0.0323</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.9.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.8">0.0376</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.9">0.0259</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.10">0.0661</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T4.1.9.11">0.0350</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T4.1.9.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.10.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.2">0.0321</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.3">0.0215</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.4">0.0523</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.10.5">0.0280</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.10.6">-15.22</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.7">0.0330</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.8">0.0212</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.9">0.0578</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.10.10">0.0293</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.10.11">-14.81</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.11.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.2">0.0275</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.3">0.0167</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.4">0.0459</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.11.5">0.0226</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.11.6">-29.62</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.7">0.0312</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.8">0.0221</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.9">0.0523</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.11.10">0.0289</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.11.11">-17.50</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T4.1.12.1" rowspan="3"><span class="ltx_text" id="S3.T4.1.12.1.1">S (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.3">0.0403</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.4">0.0265</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.5">0.0606</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.6">0.0331</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.8">0.0403</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.9">0.0282</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.10">0.0679</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.11">0.0370</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.13.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.2">0.0358</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.3">0.0230</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.4">0.0532</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.13.5">0.0288</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.13.6">-12.40</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.7">0.0376</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.8">0.0239</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.9">0.0551</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.13.10">0.0297</td>
<td class="ltx_td ltx_align_center" id="S3.T4.1.13.11">-15.13</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T4.1.14.1">TR</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.2">0.0275</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.3">0.0195</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.4">0.0468</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T4.1.14.5">0.0256</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T4.1.14.6">-25.90</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.7">0.0330</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.8">0.0212</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.9">0.0505</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T4.1.14.10">0.0269</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.14.11">-23.97</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S3.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance on Amazon-Beauty dataset with [Random (R), Sequential (S)] indexing, [seen (s), unseen (u)] prompts for [Sequential, Straightforward] recommendation in [EN: English, ES: Spanish, TR: Turkish] (H: Hitrate, N: NDCG)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T5.1">
<tr class="ltx_tr" id="S3.T5.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.1.1" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.1.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T5.1.1.1.1.1" style="width:35.0pt;">
<span class="ltx_p" id="S3.T5.1.1.1.1.1.1">Indexing</span>
<span class="ltx_p ltx_align_center" id="S3.T5.1.1.1.1.1.2">(Prompt)</span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.1.2" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.2.1">Lng</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T5.1.1.3">Sequential</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T5.1.1.4">Straightforward</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.1">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.2">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.3">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.2.4">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.2.5">Avg%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.6">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.7">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.8">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.2.9">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.2.10">Avg%</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.3.1" rowspan="3"><span class="ltx_text" id="S3.T5.1.3.1.1">R (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.3.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.3">0.0318</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.4">0.0226</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.5">0.0463</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.3.6">0.0273</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.3.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.8">0.0231</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.9">0.0168</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.10">0.0316</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.3.11">0.0195</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.3.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.4.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.2">0.0288</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.3">0.0204</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.4">0.0427</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.4.5">0.0249</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.4.6">-8.93</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.7">0.0190</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.8">0.0141</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.9">0.0284</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.4.10">0.0172</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.4.11">-13.94</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.5.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.2">0.0262</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.3">0.0178</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.4">0.0383</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.5.5">0.0217</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.5.6">-19.16</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.7">0.0207</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.8">0.0151</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.9">0.0292</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.5.10">0.0179</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.5.11">-9.08</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.6.1" rowspan="3"><span class="ltx_text" id="S3.T5.1.6.1.1">R (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.6.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.3">0.0314</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.4">0.0222</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.5">0.0457</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.6.6">0.0268</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.6.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.8">0.0222</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.9">0.0164</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.10">0.0312</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.6.11">0.0193</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.6.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.7.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.2">0.0251</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.3">0.0167</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.4">0.0380</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.7.5">0.0209</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.7.6">-20.92</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.7">0.0203</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.8">0.0150</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.9">0.0286</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.7.10">0.0177</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.7.11">-8.43</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.8.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.2">0.0207</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.3">0.0152</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.4">0.0289</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.8.5">0.0178</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.8.6">-33.99</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.7">0.0213</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.8">0.0153</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.9">0.0297</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.8.10">0.0180</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.8.11">-5.58</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.9.1" rowspan="3"><span class="ltx_text" id="S3.T5.1.9.1.1">S (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.9.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.3">0.0456</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.4">0.0335</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.5">0.0622</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.9.6">0.0389</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.9.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.8">0.0318</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.9">0.0239</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.10">0.0439</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T5.1.9.11">0.0278</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T5.1.9.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.10.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.2">0.0403</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.3">0.0293</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.4">0.0563</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.10.5">0.0345</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.10.6">-11.24</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.7">0.0295</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.8">0.0219</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.9">0.0409</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.10.10">0.0256</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.10.11">-7.59</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.11.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.2">0.0369</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.3">0.0261</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.4">0.0513</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.11.5">0.0307</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.11.6">-19.94</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.7">0.0301</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.8">0.0227</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.9">0.0406</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.11.10">0.0261</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.11.11">-6.00</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T5.1.12.1" rowspan="3"><span class="ltx_text" id="S3.T5.1.12.1.1">S (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.12.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.3">0.0454</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.4">0.0332</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.5">0.0614</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.12.6">0.0385</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.12.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.8">0.0314</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.9">0.0237</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.10">0.0436</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.12.11">0.0276</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.12.12">-</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.13.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.2">0.0379</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.3">0.0276</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.4">0.0524</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.13.5">0.0322</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.13.6">-16.10</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.7">0.0267</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.8">0.0197</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.9">0.0382</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.13.10">0.0234</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.13.11">-14.87</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T5.1.14.1">TR</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.2">0.0280</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.3">0.0215</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.4">0.0390</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T5.1.14.5">0.0250</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T5.1.14.6">-36.28</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.7">0.0300</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.8">0.0228</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.9">0.0411</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T5.1.14.10">0.0263</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.14.11">-4.68</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Impact of Non-English Prompts on a PreTrained LLM-Based Recommender</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In order to explore the impact of non-English prompts on a pretrained LLM-based recommender, we used prompts in Spanish and Turkish alongside English.
English is a extremely-high resource language by several orders of magnitude, while Spanish is a high-resource and Turkish is medium-resource language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib56" title="">56</a>]</cite>.
Previous research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib57" title="">57</a>]</cite> shows that linguistic similarity influences model performance.
Spanish and English belong to the Indo-European language family, whereas Turkish is part of the Altaic language family. Given these language characteristics, we predict that the performance of Spanish prompts will be slightly lower than that of English prompts but still relatively close. In contrast, using Turkish prompts is expected to decrease the performance of the LLM-based recommender systems.
The Spanish and Turkish prompts were generated using machine translation through the ChatGPT interface with the GPT-3.5 model. We used a command to translate all prompts into Spanish and Turkish. The command used and an example translation are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.T2" title="Table 2 ‣ 3.1 Experimental Setup ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">2</span></a>.
In the experiments, translated prompts were input into a pretrained model, and recommendation performance across different languages was compared.
The performance comparisons on ML1M, LastFM and Amazon-Beauty datasets are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.T3" title="Table 3 ‣ 3.1 Experimental Setup ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">3</span></a>, Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.T4" title="Table 4 ‣ 3.1 Experimental Setup ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.T5" title="Table 5 ‣ 3.1 Experimental Setup ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively. The tables show the evaluation metrics results and the average changes across all metrics compared to the English prompts.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Observations</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.3">When we analyze different prompt types (seen or unseen), recommendation types (sequential or straightforward), and datasets (ML1M, LastFM, Amazon Beauty), we observe that the behavior of random indexing is inconsistent and varies across datasets.
For example, with seen prompts, the average change in evaluation metrics for Spanish and Turkish prompts remains relatively stable (<math alttext="\pm 5\%" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mo id="S3.SS2.SSS0.Px1.p1.1.m1.1.1a" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">±</mo><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mn id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2.cmml">5</mn><mo id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">plus-or-minus</csymbol><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.1">percent</csymbol><cn id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">\pm 5\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.1.m1.1d">± 5 %</annotation></semantics></math>) on the ML1M and LastFM datasets. However, on the Amazon Beauty dataset, these changes are more noticeable, ranging from <math alttext="-9\%" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mo id="S3.SS2.SSS0.Px1.p1.2.m2.1.1a" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">−</mo><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml"><mn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2.cmml">9</mn><mo id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"><minus id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"></minus><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.1">percent</csymbol><cn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2">9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">-9\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.2.m2.1d">- 9 %</annotation></semantics></math> to <math alttext="-19\%" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><mrow id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mo id="S3.SS2.SSS0.Px1.p1.3.m3.1.1a" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">−</mo><mrow id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml"><mn id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2.cmml">19</mn><mo id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"><minus id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"></minus><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.1">percent</csymbol><cn id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2">19</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">-19\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.3.m3.1d">- 19 %</annotation></semantics></math>.
In contrast, when using unseen prompts, performance with straightforward recommendations remains more stable compared to sequential recommendations across all datasets.
We attribute this behavior to the characteristics of the random indexing. As discussed in OpenP5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#bib.bib14" title="">14</a>]</cite>, random indexing assigns item ids randomly and due to the way tokenizers used by LLMs, these ids might be split into sub-chunks. For example, item ids "2048" and "2049" could be split into ["20", "48"] and ["20", "49"], leading to artificial similarities between unrelated items.
When analyzing sequential indexing, we observe a performance decline across all datasets for both Spanish and Turkish prompts, with the decline being more pronounced for Turkish prompts.
For example, on the LastFM dataset for sequential recommendations, there is an approximately 15% drop for Spanish prompts compared to a 29% drop for Turkish prompts. This difference is expected due to the distinct linguistic characteristics of Turkish compared to English.
Overall, the tables demonstrate that using non-English prompts in an already trained LLM-based recommender system affects the recommendation performance negatively, especially for languages which have different characteristics than English.</p>
</div>
<figure class="ltx_table" id="S3.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance of the retrained model on LastFM dataset with Sequential (S) indexing, [seen (s), unseen (u)] prompts for [Sequential, Straightforward] recommendation in [EN: English, ES: Spanish, TR: Turkish] (H: Hitrate, N: NDCG) </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T6.1">
<tr class="ltx_tr" id="S3.T6.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T6.1.1.1" rowspan="2"><span class="ltx_text" id="S3.T6.1.1.1.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T6.1.1.1.1.1" style="width:35.0pt;">
<span class="ltx_p" id="S3.T6.1.1.1.1.1.1">Indexing</span>
<span class="ltx_p ltx_align_center" id="S3.T6.1.1.1.1.1.2">(Prompt)</span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T6.1.1.2" rowspan="2"><span class="ltx_text" id="S3.T6.1.1.2.1">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S3.T6.1.1.2.1.1" style="width:35.0pt;">
<span class="ltx_p" id="S3.T6.1.1.2.1.1.1">Model</span>
<span class="ltx_p ltx_align_center" id="S3.T6.1.1.2.1.1.2">Type</span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T6.1.1.3" rowspan="2"><span class="ltx_text" id="S3.T6.1.1.3.1">Lang</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S3.T6.1.1.4">Sequential</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S3.T6.1.1.5">Straightforward</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.1">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.2">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.3">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.2.4">N@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.5">H@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.6">N@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.7">H@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.2.8">N@10</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.3.1" rowspan="6"><span class="ltx_text" id="S3.T6.1.3.1.1">S (s)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.3.2" rowspan="3"><span class="ltx_text" id="S3.T6.1.3.2.1">Retrained</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.3.3">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.4">0.0229</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.5">0.0155</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.6">0.0413</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.3.7">0.0214</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.8">0.0376</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.9">0.0234</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.10">0.0523</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.3.11">0.0281</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.4.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.2">0.0183</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.3">0.0136</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.4">0.0413</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.4.5">0.0211</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.6">0.0404</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.7">0.0281</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.8">0.0523</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.4.9">0.0320</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.5.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.2">0.0257</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.3">0.0163</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.4">0.0459</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.5.5">0.0226</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.6">0.0367</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.7">0.0243</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.8">0.0523</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.5.9">0.0293</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.6.1" rowspan="3"><span class="ltx_text" id="S3.T6.1.6.1.1">Original</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.6.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.3">0.0395</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.4">0.0262</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.5">0.0587</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.6.6">0.0323</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.7">0.0376</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.8">0.0259</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.9">0.0661</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.6.10">0.0350</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.7.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.2">0.0321</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.3">0.0215</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.4">0.0523</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.7.5">0.0280</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.6">0.0330</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.7">0.0212</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.8">0.0578</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.7.9">0.0293</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.8.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.2">0.0275</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.3">0.0167</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.4">0.0459</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.8.5">0.0226</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.6">0.0312</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.7">0.0221</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.8">0.0523</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.8.9">0.0289</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.9">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T6.1.9.1" rowspan="6"><span class="ltx_text" id="S3.T6.1.9.1.1">S (u)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T6.1.9.2" rowspan="3"><span class="ltx_text" id="S3.T6.1.9.2.1">Retrained</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T6.1.9.3">EN</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.4">0.0248</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.5">0.0155</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.6">0.0431</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T6.1.9.7">0.0213</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.8">0.0385</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.9">0.0244</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.10">0.0523</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.1.9.11">0.0288</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.10.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.2">0.0266</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.3">0.0169</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.4">0.0431</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.10.5">0.0221</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.6">0.0376</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.7">0.0261</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.8">0.0505</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.10.9">0.0302</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.11.1">TR</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.2">0.0367</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.3">0.0260</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.4">0.0514</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.11.5">0.0309</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.6">0.0340</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.7">0.0229</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.8">0.0523</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.11.9">0.0288</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T6.1.12.1" rowspan="3"><span class="ltx_text" id="S3.T6.1.12.1.1">Original</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.12.2">EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.3">0.0403</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.4">0.0265</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.5">0.0606</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.12.6">0.0331</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.7">0.0403</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.8">0.0282</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.9">0.0679</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.12.10">0.0370</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.13.1">ES</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.2">0.0358</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.3">0.0230</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.4">0.0532</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.13.5">0.0288</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.6">0.0376</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.7">0.0239</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.8">0.0551</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.13.9">0.0297</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T6.1.14.1">TR</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.2">0.0275</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.3">0.0195</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.4">0.0468</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T6.1.14.5">0.0256</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.6">0.0330</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.7">0.0212</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.8">0.0505</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.14.9">0.0269</td>
</tr>
</table>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Impact of English and Non-English Prompts on LLM Recommender Fine-Tuning</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In OpenP5, the model was fine-tuned with English prompts to create OpenP5-T5 model. In this section, we fine-tune the same model with English, Spanish, and Turkish prompts and compare its performance across these languages.
For the analysis, LastFM dataset with sequential indexing is used. The training is ran for ten epochs with the setup described in the experimental setup section. The performance comparison is presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S3.T6" title="Table 6 ‣ Observations ‣ 3.2 Impact of Non-English Prompts on a PreTrained LLM-Based Recommender ‣ 3 LLM-based Recommenders Beyond English ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">6</span></a>. In the table, the performance from the original OpenP5-T5 model and retrained model with multi-language prompts are presented.</p>
</div>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Observations</h4>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">When we evaluate the performance of the retrained model, we observe a decline in performance on English prompts. For instance, the Hitrate@10 metric drops from 0.0587 to 0.0413 when the prompts are seen and the goal is to make a sequential recommendation. Similarly, it decreases from 0.0679 to 0.0523 when the prompts are unseen and the goal is a straightforward recommendation.
However, with the retrained model, the performance across all languages becomes closer. For example, the Hitrate@10 values for English, Spanish, and Turkish prompts are 0.0413, 0.0413, and 0.0459, respectively, when the prompts are seen and the goal is sequential recommendation. For unseen prompts aimed at straightforward recommendation, the Hitrate@10 values are 0.0523, 0.0505, and 0.0523 for English, Spanish, and Turkish prompts, respectively.
Overall, the table demonstrates that retraining the model with prompts from different languages affects its performance across these languages.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Analysis and Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Large language models (LLMs) have become the dominant tools for various natural language processing tasks, and their integration into recommender systems is a growing trend. This integration empowers users to leverage the capabilities of LLMs in everyday interactions. However, despite efforts to create multilingual LLMs, these models are predominantly trained on English texts. This bias leads to better performance in high-resource languages like English, while lower-resource languages face significant challenges.
As LLM-based recommenders evolve, it is crucial to consider these linguistic disparities, alongside other known issues such as position bias, popularity bias, and hallucinations.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Traditionally, recommender systems often function as black boxes for end-users, who simply request recommendations and receive items without insight into the underlying processes.
However, we anticipate that these systems will evolve enabling users to interact through natural language in addition to traditional methods like clicks and page-scrolls. We propose four phases in this evolution, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07604v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages"><span class="ltx_text ltx_ref_tag">1</span></a>:
(i) Initial Phase: Users interact with recommender via clicks and scrolls, while the recommender system relies on traditional black-box models.
(ii) LLM Integration: LLMs are integrated into these systems, using prompts that are independent of the user’s language. As the result, the prompts can be in one of the high-resource languages, such as English.
(iii) Prompt Template Interaction: Users begin to interact with LLM-based recommenders by filling out prompt templates in their native languages, alongside traditional interactions.
(iv) Natural Language Interaction: Users engage with recommenders through natural language requests alongside traditional interactions.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">In light of these considerations, this paper explores the impact of non-English prompts on the performance of LLM-based recommendation systems in two folds: (i) by using non-English prompts on an already trained LLM-based recommender, and (ii) by incorporating both English and non-English prompts during further training. We selected Spanish and Turkish, which have distinct linguistic characteristics and resourcedness levels, for our experiments.
The results revealed that non-English prompts negatively affect performance, especially in languages less similar to English. However, retraining the model with prompts from multiple languages led to a more balanced performance across all tested languages, despite a slight decrease in performance for English prompts.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Recommender systems suggest items to users based on their preferences, employing techniques from traditional methods like collaborative and content-based filtering to advanced deep learning approaches. Recently, large language models (LLMs) have been utilized to enhance recommendations through their generative capabilities, offering more personalized suggestions. Most state-of-the-art LLMs are designed for high-resource languages like English, which are well-studied and have abundant datasets.
In this work, we investigate the impact of non-English prompts on LLM-based recommenders by (i) applying non-English prompts to an already trained model, and (ii) retraining the model with both English and non-English prompts. Our findings reveal that non-English prompts can reduce performance on an existing LLM-based recommender, particularly for languages that have different characteristics than English. However, retraining the model with these languages results in more balanced performance across them, though with a slight decrease in performance for English prompts.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">This preliminary work explores how prompt language affects LLM-based recommender systems. We tested English, Spanish, and Turkish prompts, and plan to investigate additional languages with varying resource levels and characteristics in future research. Developing evaluation sets in these languages could aid other researchers and improve recommendations for users in their native languages, which we aim to address in future work. As newer multilingual models emerge, future research should consider these models for recommendation tasks and evaluate their performance on low-resource languages.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. [2008]</span>
<span class="ltx_bibblock">
R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, Q. Yang,

</span>
<span class="ltx_bibblock">One-class collaborative filtering,

</span>
<span class="ltx_bibblock">in: 2008 Eighth IEEE international conference on data mining, IEEE, 2008, pp. 502–511.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. [2010]</span>
<span class="ltx_bibblock">
M. Ye, P. Yin, W.-C. Lee,

</span>
<span class="ltx_bibblock">Location recommendation for location-based social networks,

</span>
<span class="ltx_bibblock">in: Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS ’10, ACM, New York, NY, USA, 2010, pp. 458–461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2015]</span>
<span class="ltx_bibblock">
X. Li, G. Cong, X.-L. Li, T.-A. N. Pham, S. Krishnaswamy,

</span>
<span class="ltx_bibblock">Rank-geofm: A ranking based geographical factorization method for point of interest recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, ACM, 2015, pp. 433–442.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2016]</span>
<span class="ltx_bibblock">
J. He, X. Li, L. Liao, D. Song, W. K. Cheung,

</span>
<span class="ltx_bibblock">Inferring a personalized next point-of-interest recommendation model with latent behavior patterns,

</span>
<span class="ltx_bibblock">in: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA., 2016, pp. 137–143.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ozsoy [2016]</span>
<span class="ltx_bibblock">
M. G. Ozsoy,

</span>
<span class="ltx_bibblock">From word embeddings to item recommendation,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1601.01356 (2016).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vasile et al. [2016]</span>
<span class="ltx_bibblock">
F. Vasile, E. Smirnova, A. Conneau,

</span>
<span class="ltx_bibblock">Meta-prod2vec: Product embeddings using side-information for recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 10th ACM conference on recommender systems, 2016, pp. 225–232.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2017]</span>
<span class="ltx_bibblock">
X. He, L. Liao, H. Zhang, L. Nie, X. Hu, T.-S. Chua,

</span>
<span class="ltx_bibblock">Neural collaborative filtering,

</span>
<span class="ltx_bibblock">in: Proceedings of the 26th international conference on world wide web, 2017, pp. 173–182.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Musto et al. [2018]</span>
<span class="ltx_bibblock">
C. Musto, T. Franza, G. Semeraro, M. de Gemmis, P. Lops,

</span>
<span class="ltx_bibblock">Deep content-based recommender systems exploiting recurrent neural networks and linked open data,

</span>
<span class="ltx_bibblock">in: Adjunct Publication of the 26th Conference on User Modeling, Adaptation and Personalization, ACM, 2018, pp. 239–244.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. [2018]</span>
<span class="ltx_bibblock">
G. Zheng, F. Zhang, Z. Zheng, Y. Xiang, N. J. Yuan, X. Xie, Z. Li,

</span>
<span class="ltx_bibblock">Drn: A deep reinforcement learning framework for news recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 2018 world wide web conference, 2018, pp. 167–176.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. [2021]</span>
<span class="ltx_bibblock">
B. Shi, E. Z. Tragos, M. G. Ozsoy, R. Dong, N. Hurley, B. Smyth, A. Lawlor,

</span>
<span class="ltx_bibblock">Dares: an asynchronous distributed recommender system using deep reinforcement learning,

</span>
<span class="ltx_bibblock">IEEE access 9 (2021) 83340–83354.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. [2019]</span>
<span class="ltx_bibblock">
F. Sun, J. Liu, J. Wu, C. Pei, X. Lin, W. Ou, P. Jiang,

</span>
<span class="ltx_bibblock">Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer,

</span>
<span class="ltx_bibblock">in: Proceedings of the 28th ACM international conference on information and knowledge management, 2019, pp. 1441–1450.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. [2023]</span>
<span class="ltx_bibblock">
W. Fan, Z. Zhao, J. Li, Y. Liu, X. Mei, Y. Wang, J. Tang, Q. Li,

</span>
<span class="ltx_bibblock">Recommender systems in the era of large language models (llms),

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2307.02046 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et al. [2022]</span>
<span class="ltx_bibblock">
S. Geng, S. Liu, Z. Fu, Y. Ge, Y. Zhang,

</span>
<span class="ltx_bibblock">Recommendation as language processing (rlp): A unified pretrain, personalized prompt &amp; predict paradigm (p5),

</span>
<span class="ltx_bibblock">in: Proceedings of the 16th ACM Conference on Recommender Systems, 2022, pp. 299–315.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2024]</span>
<span class="ltx_bibblock">
S. Xu, W. Hua, Y. Zhang,

</span>
<span class="ltx_bibblock">Openp5: An open-source platform for developing, training, and evaluating llm-based recommender systems,

</span>
<span class="ltx_bibblock">in: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2024, pp. 386–394.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ngo and Nguyen [2024]</span>
<span class="ltx_bibblock">
H. Ngo, D. Q. Nguyen,

</span>
<span class="ltx_bibblock">Recgpt: Generative pre-training for text-based recommendation,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2405.12715 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nicholas and Bhatia [2023]</span>
<span class="ltx_bibblock">
G. Nicholas, A. Bhatia,

</span>
<span class="ltx_bibblock">Lost in translation: large language models in non-english content analysis,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2306.07377 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2024]</span>
<span class="ltx_bibblock">
J. Zhao, Z. Zhang, Q. Zhang, T. Gui, X. Huang,

</span>
<span class="ltx_bibblock">Llama beyond english: An empirical study on language capability transfer,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2401.01055 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">team [2024]</span>
<span class="ltx_bibblock">
C. F. A. team,

</span>
<span class="ltx_bibblock">The ai language gap,

</span>
<span class="ltx_bibblock">Policy Primer (2024). <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cohere.com/research/papers/the-ai-language-gap.pdf" title="">https://cohere.com/research/papers/the-ai-language-gap.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2023]</span>
<span class="ltx_bibblock">
S. Xu, W. Hua, Y. Zhang,

</span>
<span class="ltx_bibblock">Openp5: Benchmarking foundation models for recommendation,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2306.11134 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al. [2021]</span>
<span class="ltx_bibblock">
Z. Qiu, X. Wu, J. Gao, W. Fan,

</span>
<span class="ltx_bibblock">U-bert: Pre-training user representations for improved recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, 2021, pp. 4320–4327.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022]</span>
<span class="ltx_bibblock">
S. Zhang, N. Zheng, D. Wang,

</span>
<span class="ltx_bibblock">Gbert: Pre-training user representations for ephemeral group recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management, 2022, pp. 2631–2639.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2023]</span>
<span class="ltx_bibblock">
J. Li, M. Wang, J. Li, J. Fu, X. Shen, J. Shang, J. McAuley,

</span>
<span class="ltx_bibblock">Text is all you need: Learning language representations for sequential recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2023, pp. 1258–1267.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2024]</span>
<span class="ltx_bibblock">
L. Li, Y. Zhang, D. Liu, L. Chen,

</span>
<span class="ltx_bibblock">Large language models for generative recommendation: A survey and visionary discussions,

</span>
<span class="ltx_bibblock">in: Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), 2024, pp. 10146–10159.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vats et al. [2024]</span>
<span class="ltx_bibblock">
A. Vats, V. Jain, R. Raja, A. Chadha,

</span>
<span class="ltx_bibblock">Exploring the impact of large language models on recommender systems: An extensive review,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2402.18590 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2023]</span>
<span class="ltx_bibblock">
S. Dai, N. Shao, H. Zhao, W. Yu, Z. Si, C. Xu, Z. Sun, X. Zhang, J. Xu,

</span>
<span class="ltx_bibblock">Uncovering chatgpt’s capabilities in recommender systems,

</span>
<span class="ltx_bibblock">in: Proceedings of the 17th ACM Conference on Recommender Systems, 2023, pp. 1126–1132.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. [2023]</span>
<span class="ltx_bibblock">
W. Sun, L. Yan, X. Ma, S. Wang, P. Ren, Z. Chen, D. Yin, Z. Ren,

</span>
<span class="ltx_bibblock">Is chatgpt good at search? investigating large language models as re-ranking agents,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2304.09542 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. [2023]</span>
<span class="ltx_bibblock">
Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, J. Zhang,

</span>
<span class="ltx_bibblock">Chat-rec: Towards interactive and explainable llms-augmented recommender system,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2303.14524 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2023]</span>
<span class="ltx_bibblock">
Z. He, Z. Xie, R. Jha, H. Steck, D. Liang, Y. Feng, B. P. Majumder, N. Kallus, J. McAuley,

</span>
<span class="ltx_bibblock">Large language models as zero-shot conversational recommenders,

</span>
<span class="ltx_bibblock">in: Proceedings of the 32nd ACM international conference on information and knowledge management, 2023, pp. 720–730.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023]</span>
<span class="ltx_bibblock">
J. Zhang, K. Bao, Y. Zhang, W. Wang, F. Feng, X. He,

</span>
<span class="ltx_bibblock">Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 17th ACM Conference on Recommender Systems, 2023, pp. 993–999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Lim [2023]</span>
<span class="ltx_bibblock">
L. Wang, E.-P. Lim,

</span>
<span class="ltx_bibblock">Zero-shot next-item recommendation using large pretrained language models,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2304.03153 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. [2024]</span>
<span class="ltx_bibblock">
Y. Du, D. Luo, R. Yan, X. Wang, H. Liu, H. Zhu, Y. Song, J. Zhang,

</span>
<span class="ltx_bibblock">Enhancing job recommendation through llm-based generative adversarial networks,

</span>
<span class="ltx_bibblock">in: Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, 2024, pp. 8363–8371.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2024]</span>
<span class="ltx_bibblock">
Q. Liu, N. Chen, T. Sakai, X.-M. Wu,

</span>
<span class="ltx_bibblock">Once: Boosting content-based recommendation with both open-and closed-source large language models,

</span>
<span class="ltx_bibblock">in: Proceedings of the 17th ACM International Conference on Web Search and Data Mining, 2024, pp. 452–461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al. [2024]</span>
<span class="ltx_bibblock">
Y. Hou, J. Zhang, Z. Lin, H. Lu, R. Xie, J. McAuley, W. X. Zhao,

</span>
<span class="ltx_bibblock">Large language models are zero-shot rankers for recommender systems,

</span>
<span class="ltx_bibblock">in: European Conference on Information Retrieval, Springer, 2024, pp. 364–381.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023]</span>
<span class="ltx_bibblock">
J. Liu, C. Liu, P. Zhou, R. Lv, K. Zhou, Y. Zhang,

</span>
<span class="ltx_bibblock">Is chatgpt a good recommender? a preliminary study,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2304.10149 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. [2024]</span>
<span class="ltx_bibblock">
J. Tan, S. Xu, W. Hua, Y. Ge, Z. Li, Y. Zhang,

</span>
<span class="ltx_bibblock">Idgenrec: Llm-recsys alignment with textual id learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2024, pp. 355–364.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chu et al. [2023]</span>
<span class="ltx_bibblock">
Z. Chu, H. Hao, X. Ouyang, S. Wang, Y. Wang, Y. Shen, J. Gu, Q. Cui, L. Li, S. Xue, et al.,

</span>
<span class="ltx_bibblock">Leveraging large language models for pre-trained recommender systems,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2308.10837 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al. [2023]</span>
<span class="ltx_bibblock">
K. Bao, J. Zhang, Y. Zhang, W. Wang, F. Feng, X. He,

</span>
<span class="ltx_bibblock">Tallrec: An effective and efficient tuning framework to align large language model with recommendation,

</span>
<span class="ltx_bibblock">in: Proceedings of the 17th ACM Conference on Recommender Systems, 2023, pp. 1007–1014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2023]</span>
<span class="ltx_bibblock">
F. Yang, Z. Chen, Z. Jiang, E. Cho, X. Huang, Y. Lu,

</span>
<span class="ltx_bibblock">Palr: Personalization aware llms for recommendation,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2305.07622 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2023]</span>
<span class="ltx_bibblock">
X. Li, Y. Zhang, E. C. Malthouse,

</span>
<span class="ltx_bibblock">Pbnr: Prompt-based news recommender system,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2304.07862 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023]</span>
<span class="ltx_bibblock">
J. Zhang, R. Xie, Y. Hou, W. X. Zhao, L. Lin, J.-R. Wen,

</span>
<span class="ltx_bibblock">Recommendation as instruction following: A large language model empowered recommendation approach,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2305.07001 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. [2024]</span>
<span class="ltx_bibblock">
J. Ji, Z. Li, S. Xu, W. Hua, Y. Ge, J. Tan, Y. Zhang,

</span>
<span class="ltx_bibblock">Genrec: Large language model for generative recommendation,

</span>
<span class="ltx_bibblock">in: European Conference on Information Retrieval, Springer, 2024, pp. 494–502.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2024]</span>
<span class="ltx_bibblock">
Z. Wang, Y. Du, Z. Sun, H. Chua, K. Feng, W. Wang, J. Zhang,

</span>
<span class="ltx_bibblock">Re2llm: Reflective reinforcement large language model for session-based recommendation,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2403.16427 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2024a]</span>
<span class="ltx_bibblock">
L. Wu, Z. Qiu, Z. Zheng, H. Zhu, E. Chen,

</span>
<span class="ltx_bibblock">Exploring large language model for graph data understanding in online job recommendations,

</span>
<span class="ltx_bibblock">in: Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, 2024a, pp. 9178–9186.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2024b]</span>
<span class="ltx_bibblock">
Y. Wu, R. Xie, Y. Zhu, F. Zhuang, X. Zhang, L. Lin, Q. He,

</span>
<span class="ltx_bibblock">Personalized prompt for sequential recommendation,

</span>
<span class="ltx_bibblock">IEEE Transactions on Knowledge and Data Engineering (2024b).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
C. Wang, Y. Yu, W. Ma, M. Zhang, C. Chen, Y. Liu, S. Ma,

</span>
<span class="ltx_bibblock">Towards representation alignment and uniformity in collaborative filtering,

</span>
<span class="ltx_bibblock">in: Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining, 2022, pp. 1816–1825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2023]</span>
<span class="ltx_bibblock">
L. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu, H. Zhu, Q. Liu, et al.,

</span>
<span class="ltx_bibblock">A survey on large language models for recommendation,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2305.19860 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Azamfirei et al. [2023]</span>
<span class="ltx_bibblock">
R. Azamfirei, S. R. Kudchadkar, J. Fackler,

</span>
<span class="ltx_bibblock">Large language models and the perils of their hallucinations,

</span>
<span class="ltx_bibblock">Critical Care 27 (2023) 120.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. [2023]</span>
<span class="ltx_bibblock">
J. Tan, Y. Ge, Y. Zhu, Y. Xia, J. Luo, J. Ji, Y. Zhang,

</span>
<span class="ltx_bibblock">User-controllable recommendation via counterfactual retrospective and prospective explanations,

</span>
<span class="ltx_bibblock">in: ECAI 2023, IOS Press, 2023, pp. 2307–2314.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team [2023]</span>
<span class="ltx_bibblock">
I. Team, Internlm: A multilingual language model with progressively enhanced capabilities, 2023. <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/InternLM/InternLM" title="">https://github.com/InternLM/InternLM</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al. [2023]</span>
<span class="ltx_bibblock">
Y. Cui, Z. Yang, X. Yao,

</span>
<span class="ltx_bibblock">Efficient and effective text encoding for chinese llama and alpaca,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2304.08177 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acikgoz et al. [2024]</span>
<span class="ltx_bibblock">
E. C. Acikgoz, M. Erdogan, D. Yuret,

</span>
<span class="ltx_bibblock">Bridging the bosphorus: Advancing turkish large language models through strategies for low-resource language adaptation and benchmarking,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2405.04685 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kesgin et al. [2024]</span>
<span class="ltx_bibblock">
H. T. Kesgin, M. K. Yuce, E. Dogan, M. E. Uzun, A. Uz, H. E. Seyrek, A. Zeer, M. F. Amasyali,

</span>
<span class="ltx_bibblock">Introducing cosmosgpt: Monolingual training for turkish language models,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2404.17336 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. [2020]</span>
<span class="ltx_bibblock">
C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, P. J. Liu,

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer,

</span>
<span class="ltx_bibblock">Journal of machine learning research 21 (2020) 1–67.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023]</span>
<span class="ltx_bibblock">
H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al.,

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2307.09288 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2021]</span>
<span class="ltx_bibblock">
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen,

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2106.09685 (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et al. [2020]</span>
<span class="ltx_bibblock">
P. Joshi, S. Santy, A. Budhiraja, K. Bali, M. Choudhury,

</span>
<span class="ltx_bibblock">The state and fate of linguistic diversity and inclusion in the nlp world,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2004.09095 (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhamecha et al. [2021]</span>
<span class="ltx_bibblock">
T. I. Dhamecha, R. Murthy V, S. Bharadwaj, K. Sankaranarayanan, P. Bhattacharyya,

</span>
<span class="ltx_bibblock">Role of language relatedness in multilingual fine-tuning of language models: A case study in indo-aryan languages,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2109.10534 (2021).

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 11 20:32:43 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
