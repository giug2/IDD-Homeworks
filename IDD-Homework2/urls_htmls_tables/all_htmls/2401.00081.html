<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.00081] 1 Introduction</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="1 Introduction">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="1 Introduction">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.00081">

<!--Generated on Tue Feb 27 06:02:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on today.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\OneAndAHalfSpacedXI</span>
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined" lang="en">\RUNTITLE</span>
<p id="p2.2" class="ltx_p"><span id="p2.2.1" class="ltx_text" lang="en">Synthetic Data Applications in Finance</span></p>
</div>
<div id="p3" class="ltx_para">
<span id="p3.1" class="ltx_ERROR undefined" lang="en">\TITLE</span>
<p id="p3.2" class="ltx_p"><span id="p3.2.1" class="ltx_text" lang="en">Synthetic Data Applications in Finance</span></p>
</div>
<div id="p4" class="ltx_para">
<span id="p4.1" class="ltx_ERROR undefined" lang="en">\ARTICLEAUTHORS</span>
</div>
<div id="p5" class="ltx_para">
<span id="p5.1" class="ltx_ERROR undefined" lang="en">\AUTHOR</span>
<p id="p5.2" class="ltx_p"><span id="p5.2.1" class="ltx_text" lang="en">Vamsi K. Potluru, Daniel Borrajo, Andrea Coletta<span id="p5.2.1.1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>work done while at AI Research</span></span></span>, NiccolÃ² Dalmasso, Yousef El-Laham, Elizabeth Fons, Mohsen Ghassemi, Sriram Gopalakrishnan, Vikesh Gosai, Eleonora KreaÄiÄ‡, Ganapathy Mani, Saheed Obitayo, Deepak Paramanand, Natraj Raman, Mikhail Solonin, 
<br class="ltx_break">Srijan Sood, Svitlana Vyetrenko, Haibei Zhu, Manuela Veloso, Tucker Balch</span></p>
<p id="p5.3" class="ltx_p ltx_align_center" lang="en"><span id="p5.3.1" class="ltx_text">J.P. Morgan AI Research</span></p>
<p id="p5.4" class="ltx_p ltx_align_center" lang="en"><span id="p5.4.1" class="ltx_text">{vamsi.k.potluru, first.last}@jpmchase.com</span></p>
</div>
<div id="p6" class="ltx_para">
<span id="p6.1" class="ltx_ERROR undefined" lang="en">\ABSTRACT</span>
<p id="p6.2" class="ltx_p"><span id="p6.2.1" class="ltx_text" lang="en">Synthetic data has made tremendous strides in various commercial settings including finance, healthcare, and virtual reality.
We present a broad overview of prototypical applications of synthetic data in the financial sector and in particular provide richer details for a few select ones. These cover a wide variety of data modalities including tabular, time-series, event-series, and unstructured arising from both markets and retail financial applications. Since finance is a highly regulated industry, synthetic data is a potential approach for dealing with issues related to privacy, fairness, and explainability. Various metrics are utilized in evaluating the quality and effectiveness of our approaches in these applications. We conclude with open directions in synthetic data in the context of the financial domain.


</span></p>
</div>
<section id="S1" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Synthetic data has been receiving increased attention in the research community and beyond
with the wide-spread popularity of generative models such as DALL-EÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx165" title="" class="ltx_ref">RPG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite> and GPT4Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx145" title="" class="ltx_ref">Ope23</a>]</cite> for the domains of image and text generation, respectively. The use of synthetic data in finance is still in an early phase and typically involves tabular, time-series, and text datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">ADM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>. In this work, we will primarily focus on tabular and time-series synthetic data which have wide applicability in the retail and investment banking applications such as marketing, trading, and anti-money laundering. Also, we will briefly touch upon modalities involving images and text as can be seen in applications such as check fraud and document understanding. The latter has seen tremendous uptick in financial use-cases with the introduction of chatGPT.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Synthetic data applications in finance can be primarily tagged into the following use-cases.</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S1.SS0.SSS0.Px1.1.1" class="ltx_text ltx_font_bold">Data Liberation</span>:</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">Data use and sharing within and outside the financial institutions is highly restrictive due to internal policies designed to protect the important relationship of trust between consumers and financial institutions and to ensure compliance with the various regulatory regimes across the globe. These are mostly concerned about the privacy and legal aspects of the customer data and they in turn lead to limits or bureaucracy for data use. Other risks include leakage of institutional knowledge which could pose a competitive risk for the bankÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx121" title="" class="ltx_ref">LWSF23</a>, <a href="#bib.bibx183" title="" class="ltx_ref">TBV23</a>]</cite>. Certain types of synthetic data may potentially alleviate this issue and thereby speed up the adoption of AI and model development process in the firmÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">ADM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>. There are many criteria for evaluating the quality of synthetic data and one such notion is that of epistemic parityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx161" title="" class="ltx_ref">RHR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> where the findings on the original dataset match those that are found on the synthetic dataset. Other applications include explanations where instead of using samples from the real datasets, we can generate private synthetic dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx154" title="" class="ltx_ref">PSZ22</a>]</cite>.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S1.SS0.SSS0.Px2.1.1" class="ltx_text ltx_font_bold">Augmentation</span>:</h5>

<div id="S1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px2.p1.1" class="ltx_p">We can also utilize synthetic data to augment our training data for improving the performance of downstream classifiers. Intuitively, synthetic data can help robustify our training samples when the generated samples are sufficiently diverse from the original dataset. The benefits of synthetic data in image domains have been clearly establishedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx44" title="" class="ltx_ref">CSK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>. It is an open question as to in which regimes does synthetic data provide a lift for training machine learning (ML) models in tabular regimesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx207" title="" class="ltx_ref">XSC22</a>, <a href="#bib.bibx126" title="" class="ltx_ref">MA23</a>]</cite>. Other applications include fairness, where synthetic data can be utilized to the datasets in such a manner that the downstream fairness metrics are improved while preserving classification performanceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx119" title="" class="ltx_ref">LRD22</a>]</cite>.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S1.SS0.SSS0.Px3.1.1" class="ltx_text ltx_font_bold">Counterfactual Scenarios and Testing</span>:</h5>

<div id="S1.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px3.p1.1" class="ltx_p">Learning machine learning (ML) models which are robust to distributional shifts is a challenging problem and synthetic data offers a way of modeling counterfactual scenarios to benchmark these modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">CELT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>.
Testing robustness of ML systems is a big challenge in operations due to the wider variability of real-world data than the training data that was used to build these production systems (SectionÂ <a href="#S3.SS4.SSS1.Px1" title="Case Study: Stress Testing Software Applications â€£ 3.4.1 Privacy Levels to Guide Synthetic Data Use Cases â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.1</span></a>).</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.2.1.1" class="ltx_tr">
<th id="S1.T1.2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.1.1.1.1.1" class="ltx_p" style="width:111.0pt;">Modalities</span>
</span>
</th>
<th id="S1.T1.2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S1.T1.2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.1.1.2.1.1" class="ltx_p" style="width:150.8pt;">Models</span>
</span>
</th>
<th id="S1.T1.2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S1.T1.2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.1.1.3.1.1" class="ltx_p" style="width:176.4pt;">Applications</span>
</span>
</th>
</tr>
<tr id="S1.T1.2.2.2" class="ltx_tr">
<th id="S1.T1.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.1.1.1" class="ltx_p" style="width:111.0pt;">Tabular</span>
</span>
</th>
<th id="S1.T1.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S1.T1.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.1.1" class="ltx_p" style="width:150.8pt;">CTGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx208" title="" class="ltx_ref">XSCIV19</a>]</cite></span>
</span>
</th>
<th id="S1.T1.2.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S1.T1.2.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.3.1.1" class="ltx_p" style="width:176.4pt;">Fraud, AML (sectionÂ <a href="#S4" title="4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> )</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.2.3.1" class="ltx_tr">
<th id="S1.T1.2.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.3.1.1.1.1" class="ltx_p" style="width:111.0pt;">Event series</span>
</span>
</th>
<td id="S1.T1.2.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.3.1.2.1.1" class="ltx_p" style="width:150.8pt;">HawkesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx220" title="" class="ltx_ref">ZJL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite></span>
</span>
</td>
<td id="S1.T1.2.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.3.1.3.1.1" class="ltx_p" style="width:176.4pt;">Multi-touch attribution (sectionÂ <a href="#S5" title="5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>)</span>
</span>
</td>
</tr>
<tr id="S1.T1.2.4.2" class="ltx_tr">
<th id="S1.T1.2.4.2.1" class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_rr"></th>
<td id="S1.T1.2.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S1.T1.2.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.4.2.2.1.1" class="ltx_p" style="width:150.8pt;">Automated PlanningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx81" title="" class="ltx_ref">GNT04</a>]</cite></span>
</span>
</td>
<td id="S1.T1.2.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S1.T1.2.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.4.2.3.1.1" class="ltx_p" style="width:176.4pt;">Customer Journeys (sectionÂ <a href="#S5" title="5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>)</span>
</span>
</td>
</tr>
<tr id="S1.T1.2.5.3" class="ltx_tr">
<th id="S1.T1.2.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.5.3.1.1.1" class="ltx_p" style="width:111.0pt;">Time series</span>
</span>
</th>
<td id="S1.T1.2.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.5.3.2.1.1" class="ltx_p" style="width:150.8pt;">TimeGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx213" title="" class="ltx_ref">YJvdS19a</a>]</cite></span>
</span>
</td>
<td id="S1.T1.2.5.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.5.3.3.1.1" class="ltx_p" style="width:176.4pt;">Market counterfactuals (sectionÂ <a href="#S6" title="6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>)</span>
</span>
</td>
</tr>
<tr id="S1.T1.2.6.4" class="ltx_tr">
<th id="S1.T1.2.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.6.4.1.1.1" class="ltx_p" style="width:111.0pt;">Discrete time-series</span>
</span>
</th>
<td id="S1.T1.2.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.6.4.2.1.1" class="ltx_p" style="width:150.8pt;">Bayes NetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx169" title="" class="ltx_ref">S<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>10</a>]</cite>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx185" title="" class="ltx_ref">TGG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite></span>
</span>
</td>
<td id="S1.T1.2.6.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.6.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.6.4.3.1.1" class="ltx_p" style="width:176.4pt;">Asset allocation (sectionÂ <a href="#S2" title="2 Background and Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>)</span>
</span>
</td>
</tr>
<tr id="S1.T1.2.7.5" class="ltx_tr">
<th id="S1.T1.2.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.7.5.1.1.1" class="ltx_p" style="width:111.0pt;">Images</span>
</span>
</th>
<td id="S1.T1.2.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.7.5.2.1.1" class="ltx_p" style="width:150.8pt;">ScrabbleGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx67" title="" class="ltx_ref">FAEC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite></span>
</span>
</td>
<td id="S1.T1.2.7.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.7.5.3.1.1" class="ltx_p" style="width:176.4pt;">Check OCR (sectionÂ <a href="#S7.SS1" title="7.1 Handwriting â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.1</span></a> )</span>
</span>
</td>
</tr>
<tr id="S1.T1.2.8.6" class="ltx_tr">
<th id="S1.T1.2.8.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t">
<span id="S1.T1.2.8.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.8.6.1.1.1" class="ltx_p" style="width:111.0pt;">Documents</span>
</span>
</th>
<td id="S1.T1.2.8.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.2.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.8.6.2.1.1" class="ltx_p" style="width:150.8pt;">Bayes NetworkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx167" title="" class="ltx_ref">RSV22</a>]</cite></span>
</span>
</td>
<td id="S1.T1.2.8.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.2.8.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.8.6.3.1.1" class="ltx_p" style="width:176.4pt;">Layout generation (sectionÂ <a href="#S7.SS2.SSS1" title="7.2.1 Layout generation â€£ 7.2 Document generation â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.2.1</span></a>)</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S1.T1.4.2" class="ltx_text" style="font-size:90%;">List of modalities and illustrative applications</span></figcaption>
</figure>
<div id="S1.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S1.SS0.SSS0.Px3.p2.1" class="ltx_p">The paper is structured as follows: we provide a brief review to the various synthetic data generation techniques in the literature (SectionÂ <a href="#S2" title="2 Background and Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). This includes simulation based techniques (SectionÂ <a href="#S2.SS1.SSS1" title="2.1.1 Model-Based Simulation methods â€£ 2.1 Generation techniques â€£ 2 Background and Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1.1</span></a>), various metrics for measuring the quality of the synthetic data as well as publicly available libraries for the generation. Privacy is a huge requirement in many applications and we provide a novel framework for categorizing all synthetic data into six levels (SectionÂ <a href="#S3" title="3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). We then consider data arising from various modalities and tackle them one by one. We start with various applications of synthetic data in the tabular settings (SectionÂ <a href="#S4" title="4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) and follow it up by providing succinct applications for event-series in the case of customer journeys and multi-touch attribution (SectionÂ <a href="#S5" title="5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). Time series is another modality which is widely prevalent in many financial applications and we provide compelling synthetic data use-cases in generation, imputation, constraint satisfaction among others (SectionÂ <a href="#S6" title="6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). Finally, we consider applications in unstructured data such as images and text (SectionÂ <a href="#S7.SS2.SSS1" title="7.2.1 Layout generation â€£ 7.2 Document generation â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.2.1</span></a>) for check processing and document understanding. We conclude with some of the open questions in the field.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Availability of data is a crucial factor for decision making in the finance domain. However, the sensitive nature of information in this domain makes access to shared data difficult. Although synthetic data offers a route to mitigate this limitation, synthetic data per se is not automatically privateÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx100" title="" class="ltx_ref">JSH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>. We devote SectionÂ <a href="#S3" title="3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> to discuss this important issue. In this section, we will provide a high-level overview of the various generation techniques that are available in the literature and the metrics to evaluate the quality of the synthetic data that is generated. Additional modality-specific generation models and metrics will be discussed in greater detail in the corresponding SectionsÂ <a href="#S4" title="4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>Â <a href="#S5" title="5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>Â <a href="#S6" title="6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>,Â <a href="#S7" title="7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Finally, we briefly review some popular packages for generating synthetic data.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Generation techniques</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The classical method (SMOTE) for generating synthetic data for imbalanced datasets is by interpolating between the samplesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">CBHK02</a>]</cite>.
With the recent success of deep learning techniques in various ML tasks, it is no surprise that they work exceedingly well even for generation. In particular, models such as generative adversarial networks (GANs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx84" title="" class="ltx_ref">GPAM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>14b</a>]</cite>, diffusion modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx174" title="" class="ltx_ref">SDWMG15</a>]</cite>, and energy based models (EBMs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx189" title="" class="ltx_ref">TWOH03</a>, <a href="#bib.bibx52" title="" class="ltx_ref">DM19</a>]</cite> have been widely successful in a wide variety of synthetic data generation tasks. They gain their flexibility from the fact that they are universal function approximatorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx93" title="" class="ltx_ref">HSW89</a>]</cite>, as well as their high capacity arising from over-parameterization. GANs have been quite successful for tabularÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx157" title="" class="ltx_ref">PWV16a</a>]</cite>, timeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx213" title="" class="ltx_ref">YJvdS19a</a>]</cite>, and image dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx67" title="" class="ltx_ref">FAEC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>. Recently, diffusion based models have been performing increasingly well in a variety of generation tasks, avoiding some of the training pitfalls associated with GANsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx103" title="" class="ltx_ref">KBRB23</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Financial data can also be generated using simulators, which can be powerful for a multitude of reasons including helping with data privacy concerns, generating rare data, and their ability to incorporate expert knowledge. Simulators can be built by: (1) encoding domain knowledge into modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx32" title="" class="ltx_ref">Cho95</a>]</cite>; (2) learning the model directly from data (eg: deep generative modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx141" title="" class="ltx_ref">OE18</a>]</cite>); or (3) a hybrid method that includes expert knowledge into the model and then fine-tunes the model with data (e.g. with Bayesian NetworksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">AMAF19</a>]</cite>). In this work, when we refer to simulators, we mean a program that rolls out the state of a system (its variables) over time or steps. So, simulation-based methods are mostly pertinent for time series or event-series data in finance.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Model-Based Simulation methods</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">Model-based simulation is a powerful approach for generating synthetic time series data which can leverage domain knowledge of predefined rules, and helpful assumptions for effective simulation Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx72" title="" class="ltx_ref">FHMR88</a>]</cite>. One advantage of using such simulators to generate data is the ability to explicitly represent the underlying mechanism of data generation by incorporating domain knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">ATLO17</a>]</cite>. This allowssimulators to generate data for rare or extreme scenarios Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx168" title="" class="ltx_ref">RT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>09</a>]</cite> that may not be present in the data. Rare events play an important role in financial applicationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx61" title="" class="ltx_ref">EKM13</a>]</cite>. Such simulators also have the advantage of control and reproducibility by design, allowing researchers to replicate data generation, analyze the effect of small parameter changes, and ensure consistency.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.1" class="ltx_p">Model-based simulators are also helpful for generating realistic datasets for downstream ML models in cases where private data cannot be released; this can be due to privacy and or regulatory constraints in financeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx195" title="" class="ltx_ref">VL18</a>]</cite>. With respect to privacy levels, using a simulator can offer us the highest level of data privacy, as the model can be programmed by a domain expert without referencing the data. However, if the model used in a simulator was built referencing (for example) statistical properties or cases from a dataset, then information leakage can occur and the privacy level is reduced.</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p id="S2.SS1.SSS1.p3.1" class="ltx_p">As stated, simulators can be helpful in simulating potential (unseen) scenarios in markets, and also useful for testing various strategies or policies in finance. The effectiveness and realism of simulators will depend on how accurate (fidelity) the model used in the simulator captures the dynamics of the target features. This often involves a trade off between model accuracy and simplicity (affects speed and comprehensibility). A simulator needs not be highly accurate (lower fidelity) to be usefulÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx176" title="" class="ltx_ref">SKB23</a>]</cite>; as the statistician George Box put it, <span id="S2.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_italic">â€Essentially, all models are wrong, but some are usefulâ€</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">BD19</a>]</cite>.</p>
</div>
<div id="S2.SS1.SSS1.p4" class="ltx_para">
<p id="S2.SS1.SSS1.p4.1" class="ltx_p">For generating such synthetic data in finance using model-based simulators, we will discuss a set of approaches that include Markov models, automated planning, and agent-based simulatorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">ATLO17</a>]</cite>.</p>
</div>
<section id="S2.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S2.SS1.SSS1.Px1.1.1" class="ltx_text ltx_font_bold">Using Markov models</span>:</h5>

<div id="S2.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.Px1.p1.1" class="ltx_p">The Markov assumptionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx155" title="" class="ltx_ref">Put14a</a>, <a href="#bib.bibx34" title="" class="ltx_ref">Cin13</a>]</cite> is often used in modeling systems. By this assumption, the successor state of a system is only dependent on the current state of a system. Markov models have been extensively used to model real-world systemsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx199" title="" class="ltx_ref">Whi85</a>, <a href="#bib.bibx22" title="" class="ltx_ref">BVD17</a>]</cite>, including financeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">BR11</a>]</cite>.</p>
</div>
<div id="S2.SS1.SSS1.Px1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.Px1.p2.1" class="ltx_p">A Markov process is one in which the state evolves over time based on the current state alone, based on dynamics defined by the modeler. These processes can be used directly to simulate financial scenarios and generate dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">Bra14</a>, <a href="#bib.bibx94" title="" class="ltx_ref">I<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>08</a>]</cite>. Data can also be generated by including one or more agents and their behavior, or a policy of actions, in the Markov process. Agents would act in the environment (described by the model) to optimize their objectives. The data generated would then be reflective of system dynamics as well as of dynamics that emerge from the policies (actions) of agents in the environment. How these agents behave need not be explicitly modeled, and can be learned after specifying a reward function; this is what defines Markov Decision Processes (MDPs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx156" title="" class="ltx_ref">Put14b</a>]</cite> and their variants. Such models are used in reinforcement learning. In addition to data generation, one can also test (investment) policies on such models and simulate unseen situations by appropriately modifying the model.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/figures/simulator/Markov_model.png" id="S2.F2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="240" height="119" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/figures/abides.png" id="S2.F2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="341" height="104" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;"> (Left) A Markov model in RDDLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx169" title="" class="ltx_ref">S<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>10</a>]</cite>, (Right)
A Multi-Agent Market SimulatorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">BHB19</a>]</cite>. </span></figcaption>
</figure>
<div id="S2.SS1.SSS1.Px1.p3" class="ltx_para">
<p id="S2.SS1.SSS1.Px1.p3.1" class="ltx_p">In order to define Markov models for generating synthetic data, one popular language is the Resource Domain Definition Language (RDDL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx169" title="" class="ltx_ref">S<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>10</a>, <a href="#bib.bibx185" title="" class="ltx_ref">TGG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> which allows one to define MDPs as well as Partially Observable Markov Decision Processes (POMDPs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx109" title="" class="ltx_ref">Kri16</a>]</cite>. POMDPs are a type of MDP that includes the ability to reason about state information that is not fully specified. Using RDDL to define a Markov model involves defining how the dynamics of the environment evolves over time, actions an agent may take, and a reward function. However, if one is interested in generating data purely by simulation using a particular model (a Markov process), and not by including or wanting agent behavior data, then the actions and reward function can be made irrelevant. The RDDL simulator<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>RDDL simulator code: https://github.com/ssanner/rddlsim</span></span></span><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>RDDL simulator in python: https://github.com/ataitler/pyRDDLGym</span></span></span> (which runs an RDDL model) can be run to generate data. If one ignores actions and rewards, an RDDL model is essentially a dynamic Bayes netÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx136" title="" class="ltx_ref">Mur02</a>]</cite> model. InÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx152" title="" class="ltx_ref">PMG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> the authors give an example of using RDDL to model the problem of asset allocation and optimal trade execution.</p>
</div>
</section>
<section id="S2.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S2.SS1.SSS1.Px2.1.1" class="ltx_text ltx_font_bold">Agent-based models</span>:</h5>

<div id="S2.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S2.SS1.SSS1.Px2.p1.1" class="ltx_p">It is often necessary to test trading algorithms against the hypothetical market stress scenarios in order to ensure their robustness before deploying them in real settings. For that purpose, financial price time series are commonly simulated by stochastic processes (for instance, by an Ornstein-Uhlenbeck process as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx36" title="" class="ltx_ref">CK11</a>]</cite>). However, such approaches suffer from an inability to explicitly model interactions among market agents. The knowledge of those interactions is often required to understand scenario nuances. In contrast, agent-based simulation presents a natural bottom-up approach to modeling agent interaction in financial marketsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">BHB19</a>, <a href="#bib.bibx12" title="" class="ltx_ref">AVG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a href="#bib.bibx131" title="" class="ltx_ref">Miz16</a>]</cite>. A schematic example of multi-agent marked simulator, called ABIDES (which stands for Agent-Based Interactive Discrete Event Simulator)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">BHB19</a>]</cite>, is shown in FigureÂ <a href="#S2.F2" title="Figure 2 â€£ Using Markov models: â€£ 2.1.1 Model-Based Simulation methods â€£ 2.1 Generation techniques â€£ 2 Background and Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. To emulate the real market, ABIDES defines a pool of heterogeneous agents (i.e., traders) with different strategies to mimic the real market traders. Multi-agent simulators, such as ABIDES, can be used in a <span id="S2.SS1.SSS1.Px2.p1.1.1" class="ltx_text ltx_font_italic">forward simulation</span> mode - i.e., to test how a trading strategy interacts with the simulated marketÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx192" title="" class="ltx_ref">VBP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>; as well as to generate synthetic series data that contains agent identity/market regime labels. For example, inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">CELT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> the synthetic time series benchmark dataset with volatility regime labels, that was generated using ABIDES, was provided to test the robustness of forecasting algorithms to distributional shifts.</p>
</div>
</section>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Metrics</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In order to evaluate the quality of our synthetic data generators, we consider various metrics utilizing both the real and synthetic samples. They can be mainly divided into three main categories:</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fidelity:</h5>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.1" class="ltx_p">These metrics capture the distributional aspects of the synthetic data with respect to the real samples. Typical metrics include the Kolmogorov-Smirnov (KS) test statistic and Chi-Squared (CS) test which measure for the similarity for continuous and categorical variables (columns) respectively. Other distributional divergence measures include
Jensen-Shannon distance, MMD, and Wasserstein distance. Specialized metrics of distributional similarity such as stylized fact comparison (e.g., similarity of price returns between real and synthetic time series) are used for financial time seriesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx192" title="" class="ltx_ref">VBP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>. Additionally, T-SNE plots provide a common way to visually check the distributional similarity between real and synthetic data in a two dimensional projectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx193" title="" class="ltx_ref">vdMH08</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Utility:</h5>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.1" class="ltx_p">These metrics evaluate the quality of the synthetic data as an effective proxy for real data in classification and regression tasks among others. The various downstream tasks are typically solved
by using XGBoostÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">CG16</a>]</cite>, neural nets, or logistic regression among others. The Training on Synthetic data and Testing on Real data (TSTR) approach allows us to evaluate the usefulness of synthetic data by training a prediction or classification model on synthetic data and testing its performance on a real downstream taskÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx60" title="" class="ltx_ref">EHR17b</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Privacy:</h5>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.2" class="ltx_p">These metrics provide a measure of risk mitigation across the various types of potential attacks on the released synthetic data such as membership inferenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx179" title="" class="ltx_ref">SSS16</a>]</cite>, attribute inferenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx139" title="" class="ltx_ref">NS07</a>]</cite>, and property inference<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx121" title="" class="ltx_ref">LWSF23</a>]</cite>.
Privacy metrics such as <math id="S2.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.1c">k</annotation></semantics></math>-anonymity and <math id="S2.SS2.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\ell" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.2.m2.1a"><mi mathvariant="normal" id="S2.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.cmml">â„“</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.2.m2.1b"><ci id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1">â„“</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.2.m2.1c">\ell</annotation></semantics></math>-diversity, in addition to reidentification scores such as delta-presence and identifiability score attempt to quantify privacy risk.</p>
</div>
<div id="S2.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p2.1" class="ltx_p">Recently, metrics have also been introduced to account for diversity and authenticity of the generated samplesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">ACvdS20</a>]</cite>. We will review additional domain-specific metrics in the corresponding data modality section.
</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Synthetic Data Generation with Python Libraries</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">There are several Python libraries available for synthetic data generation, each with its distinct capabilities and features. This section provides a detailed overview of five of these librariesâ€”SynthCity, SDV, DataSynthesizer, Faker, and Metadata to Dataâ€”and compares them on various metrics. Each library has its own strengths, weaknesses, and unique features. Here, we provide a detailed description of each major Python library for synthetic data generation, including the aforementioned five libraries using common Python libraries like <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">pandas, NumPy</span>, and <span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">scikit-learn</span>. A comparison of these libraries can be found in ExhibitÂ <a href="#S2.T3" title="Table 3 â€£ 2.3 Synthetic Data Generation with Python Libraries â€£ 2 Background and Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">SynthCity</span>: It is tailored for the generation and evaluation of synthetic tabular data. The package has a pluginable architecture, and it encompasses a wide array of reference models, ranging from GAN-based methods to Bayesian Networks, with specialized tools for time series, survival analysis, and privacy-centric synthesis.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">SDV (Synthetic Data Vault)</span>: A Python framework focused on the generation and evaluation of synthetic tabular, multi-table, and time series data. Harnessing a combination of state-of-the-art machine learning models, SDV provides capabilities and data synthesis across diverse use-cases while ensuring that generated datasets closely resemble original data in structure and statistical properties.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">DataSynthesizer</span>: This Python-based tool designed for the creation of synthetic datasets, with an emphasis on preserving data structure while ensuring privacy. Leveraging differential privacy and other techniques, it offers a balance between data utility and privacy, making it an optimal choice for researchers and practitioners concerned with data anonymization.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">TGAN (TableGAN)</span>: A specialized generative adversarial network (GAN) tailored for generating synthetic tabular data. Merging the capabilities of deep learning with the nuances of structured data, TableGAN enables the creation of high-quality synthetic datasets, preserving intricate data patterns and relationships while offering an alternative to traditional data augmentation methods.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Faker</span>: A lightweight library primarily used for creating fake data for testing purposes. It can rapidly generate large volumes of data in a variety of formats. While Faker does support complex data types, it does not provide advanced features like data anonymization, or correlation modeling.</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p"><span id="S2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Metadata to Data (using Python libraries like pandas, NumPy, scikit-learn)</span>: This approach involves generating synthetic data based on the metadata of a given dataset. It uses common Python libraries, making it highly flexible and customizable to specific needs. The functionality of this approach heavily depends on the specific implementation, but it can potentially support all functionalities, including complex data types, correlation modeling, and data anonymization. It also provides the freedom to optimize performance based on the specific requirements and computational resources available.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.T3" class="ltx_table">
<table id="S2.T3.15" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T3.1.1" class="ltx_tr">
<td id="S2.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.1.1" class="ltx_inline-block ltx_nopad ltx_align_top"><svg version="1.1" height="21.76" width="122.05" overflow="visible"><g transform="translate(0,21.76) scale(1,-1)"><path d="M 0,21.76 122.05,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,9.46) scale(1, -1)"><foreignObject width="46.97" height="9.46" overflow="visible">
<span id="S2.T3.1.1.1.1.pic1.1.1" class="ltx_inline-block">
<span id="S2.T3.1.1.1.1.pic1.1.1.1" class="ltx_inline-block ltx_align_left">
<span id="S2.T3.1.1.1.1.pic1.1.1.1.1" class="ltx_p">Criteria</span>
</span>
</span></foreignObject></g></g><g class="ltx_svg_fog" transform="translate(76.81,9.46)"><g transform="translate(0,12.3) scale(1, -1)"><foreignObject width="45.24" height="12.3" overflow="visible">
<span id="S2.T3.1.1.1.1.pic1.2.1" class="ltx_inline-block">
<span id="S2.T3.1.1.1.1.pic1.2.1.1" class="ltx_inline-block ltx_align_right">
<span id="S2.T3.1.1.1.1.pic1.2.1.1.1" class="ltx_p">Library</span>
</span>
</span></foreignObject></g></g></g></svg>
</span>
</td>
<td id="S2.T3.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.2.1.1" class="ltx_p"><span id="S2.T3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">SynthCity</span></span>
</span>
</td>
<td id="S2.T3.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.3.1.1" class="ltx_p"><span id="S2.T3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">SDV</span></span>
</span>
</td>
<td id="S2.T3.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.4.1.1" class="ltx_p"><span id="S2.T3.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Data Synthesizer</span></span>
</span>
</td>
<td id="S2.T3.1.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.5.1.1" class="ltx_p"><span id="S2.T3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">TGAN</span></span>
</span>
</td>
<td id="S2.T3.1.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.6.1.1" class="ltx_p"><span id="S2.T3.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Faker</span></span>
</span>
</td>
<td id="S2.T3.1.1.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.7.1.1" class="ltx_p"><span id="S2.T3.1.1.7.1.1.1" class="ltx_text ltx_font_bold">Metadata to Data</span></span>
</span>
</td>
</tr>
<tr id="S2.T3.5.5" class="ltx_tr">
<td id="S2.T3.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.5.5.5.1.1" class="ltx_p"><span id="S2.T3.5.5.5.1.1.1" class="ltx_text ltx_font_bold">Spatially Aware Data</span></span>
</span>
</td>
<td id="S2.T3.5.5.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.5.5.6.1.1" class="ltx_p"><span id="S2.T3.5.5.6.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.2.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.2.2.1.1.1" class="ltx_p"><math id="S2.T3.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.2.2.1.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.2.2.1.1.1.m1.1.1" xref="S2.T3.2.2.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.2.2.1.1.1.m1.1b"><times id="S2.T3.2.2.1.1.1.m1.1.1.cmml" xref="S2.T3.2.2.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.2.2.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.3.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.3.3.2.1.1" class="ltx_p"><math id="S2.T3.3.3.2.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.3.3.2.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.3.3.2.1.1.m1.1.1" xref="S2.T3.3.3.2.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.3.3.2.1.1.m1.1b"><times id="S2.T3.3.3.2.1.1.m1.1.1.cmml" xref="S2.T3.3.3.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.3.3.2.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.4.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.4.4.3.1.1" class="ltx_p"><math id="S2.T3.4.4.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.4.4.3.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.4.4.3.1.1.m1.1.1" xref="S2.T3.4.4.3.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.4.4.3.1.1.m1.1b"><times id="S2.T3.4.4.3.1.1.m1.1.1.cmml" xref="S2.T3.4.4.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.4.4.3.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.5.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.5.5.4.1.1" class="ltx_p"><math id="S2.T3.5.5.4.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.5.5.4.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.5.5.4.1.1.m1.1.1" xref="S2.T3.5.5.4.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.5.5.4.1.1.m1.1b"><times id="S2.T3.5.5.4.1.1.m1.1.1.cmml" xref="S2.T3.5.5.4.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.5.5.4.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.5.5.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.5.5.7.1.1" class="ltx_p">Variable</span>
</span>
</td>
</tr>
<tr id="S2.T3.8.8" class="ltx_tr">
<td id="S2.T3.8.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.8.8.4.1.1" class="ltx_p"><span id="S2.T3.8.8.4.1.1.1" class="ltx_text ltx_font_bold">Data Anonymization</span></span>
</span>
</td>
<td id="S2.T3.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.6.6.1.1.1" class="ltx_p"><math id="S2.T3.6.6.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.6.6.1.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.6.6.1.1.1.m1.1.1" xref="S2.T3.6.6.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.6.6.1.1.1.m1.1b"><times id="S2.T3.6.6.1.1.1.m1.1.1.cmml" xref="S2.T3.6.6.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.6.6.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.8.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.8.8.5.1.1" class="ltx_p"><span id="S2.T3.8.8.5.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.8.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.8.8.6.1.1" class="ltx_p"><span id="S2.T3.8.8.6.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.7.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.7.7.2.1.1" class="ltx_p"><math id="S2.T3.7.7.2.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.7.7.2.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.7.7.2.1.1.m1.1.1" xref="S2.T3.7.7.2.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.7.7.2.1.1.m1.1b"><times id="S2.T3.7.7.2.1.1.m1.1.1.cmml" xref="S2.T3.7.7.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.7.7.2.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.8.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.8.8.3.1.1" class="ltx_p"><math id="S2.T3.8.8.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.8.8.3.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.8.8.3.1.1.m1.1.1" xref="S2.T3.8.8.3.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.8.8.3.1.1.m1.1b"><times id="S2.T3.8.8.3.1.1.m1.1.1.cmml" xref="S2.T3.8.8.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.8.8.3.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.8.8.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.8.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.8.8.7.1.1" class="ltx_p">Variable</span>
</span>
</td>
</tr>
<tr id="S2.T3.10.10" class="ltx_tr">
<td id="S2.T3.10.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.3.1.1" class="ltx_p"><span id="S2.T3.10.10.3.1.1.1" class="ltx_text ltx_font_bold">Supports Complex Data Types</span></span>
</span>
</td>
<td id="S2.T3.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.9.9.1.1.1" class="ltx_p"><math id="S2.T3.9.9.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.9.9.1.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.9.9.1.1.1.m1.1.1" xref="S2.T3.9.9.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.9.9.1.1.1.m1.1b"><times id="S2.T3.9.9.1.1.1.m1.1.1.cmml" xref="S2.T3.9.9.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.9.9.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.10.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.4.1.1" class="ltx_p"><span id="S2.T3.10.10.4.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.10.10.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.2.1.1" class="ltx_p"><math id="S2.T3.10.10.2.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.10.10.2.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.10.10.2.1.1.m1.1.1" xref="S2.T3.10.10.2.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.10.10.2.1.1.m1.1b"><times id="S2.T3.10.10.2.1.1.m1.1.1.cmml" xref="S2.T3.10.10.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.10.10.2.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.10.10.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.5.1.1" class="ltx_p"><span id="S2.T3.10.10.5.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.10.10.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.10.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.6.1.1" class="ltx_p"><span id="S2.T3.10.10.6.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.10.10.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.10.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.7.1.1" class="ltx_p">Variable</span>
</span>
</td>
</tr>
<tr id="S2.T3.11.11" class="ltx_tr">
<td id="S2.T3.11.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.2.1.1" class="ltx_p"><span id="S2.T3.11.11.2.1.1.1" class="ltx_text ltx_font_bold">Statistical Similarity</span></span>
</span>
</td>
<td id="S2.T3.11.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.3.1.1" class="ltx_p"><span id="S2.T3.11.11.3.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.4.1.1" class="ltx_p"><span id="S2.T3.11.11.4.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.5.1.1" class="ltx_p"><span id="S2.T3.11.11.5.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.11.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.6.1.1" class="ltx_p"><span id="S2.T3.11.11.6.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.1.1.1" class="ltx_p"><math id="S2.T3.11.11.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.11.11.1.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.11.11.1.1.1.m1.1.1" xref="S2.T3.11.11.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.11.11.1.1.1.m1.1b"><times id="S2.T3.11.11.1.1.1.m1.1.1.cmml" xref="S2.T3.11.11.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.11.11.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.11.11.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.11.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.7.1.1" class="ltx_p">Variable</span>
</span>
</td>
</tr>
<tr id="S2.T3.14.14" class="ltx_tr">
<td id="S2.T3.14.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.14.14.4.1.1" class="ltx_p"><span id="S2.T3.14.14.4.1.1.1" class="ltx_text ltx_font_bold">Advanced ML Models</span></span>
</span>
</td>
<td id="S2.T3.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.12.12.1.1.1" class="ltx_p"><math id="S2.T3.12.12.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.12.12.1.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.12.12.1.1.1.m1.1.1" xref="S2.T3.12.12.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.12.12.1.1.1.m1.1b"><times id="S2.T3.12.12.1.1.1.m1.1.1.cmml" xref="S2.T3.12.12.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.12.12.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.14.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.14.14.5.1.1" class="ltx_p"><span id="S2.T3.14.14.5.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.13.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.13.13.2.1.1" class="ltx_p"><math id="S2.T3.13.13.2.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.13.13.2.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.13.13.2.1.1.m1.1.1" xref="S2.T3.13.13.2.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.13.13.2.1.1.m1.1b"><times id="S2.T3.13.13.2.1.1.m1.1.1.cmml" xref="S2.T3.13.13.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.13.13.2.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.14.14.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.14.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.14.14.6.1.1" class="ltx_p"><span id="S2.T3.14.14.6.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.14.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.14.14.3.1.1" class="ltx_p"><math id="S2.T3.14.14.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.14.14.3.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.14.14.3.1.1.m1.1.1" xref="S2.T3.14.14.3.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.14.14.3.1.1.m1.1b"><times id="S2.T3.14.14.3.1.1.m1.1.1.cmml" xref="S2.T3.14.14.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.14.14.3.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.14.14.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.14.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.14.14.7.1.1" class="ltx_p">Variable</span>
</span>
</td>
</tr>
<tr id="S2.T3.15.15" class="ltx_tr">
<td id="S2.T3.15.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.2.1.1" class="ltx_p"><span id="S2.T3.15.15.2.1.1.1" class="ltx_text ltx_font_bold">Correlation Modeling</span></span>
</span>
</td>
<td id="S2.T3.15.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.1.1.1" class="ltx_p"><math id="S2.T3.15.15.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T3.15.15.1.1.1.m1.1a"><mo mathcolor="#FF0000" mathsize="144%" id="S2.T3.15.15.1.1.1.m1.1.1" xref="S2.T3.15.15.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.T3.15.15.1.1.1.m1.1b"><times id="S2.T3.15.15.1.1.1.m1.1.1.cmml" xref="S2.T3.15.15.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.15.15.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.15.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.3.1.1" class="ltx_p"><span id="S2.T3.15.15.3.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.15.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.4.1.1" class="ltx_p"><span id="S2.T3.15.15.4.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.15.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.5.1.1" class="ltx_p"><span id="S2.T3.15.15.5.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
<td id="S2.T3.15.15.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.6.1.1" class="ltx_p">Manual</span>
</span>
</td>
<td id="S2.T3.15.15.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.7.1.1" class="ltx_p"><span id="S2.T3.15.15.7.1.1.1" class="ltx_text" style="font-size:144%;color:#00FF00;">âœ“</span></span>
</span>
</td>
</tr>
<tr id="S2.T3.15.16.1" class="ltx_tr">
<td id="S2.T3.15.16.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="width:79.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.1.1.1" class="ltx_p"><span id="S2.T3.15.16.1.1.1.1.1" class="ltx_text ltx_font_bold">Performance</span></span>
</span>
</td>
<td id="S2.T3.15.16.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.2.1.1" class="ltx_p">High</span>
</span>
</td>
<td id="S2.T3.15.16.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.3.1.1" class="ltx_p">Variable</span>
</span>
</td>
<td id="S2.T3.15.16.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.4.1.1" class="ltx_p">Variable</span>
</span>
</td>
<td id="S2.T3.15.16.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:42.7pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.5.1.1" class="ltx_p">Variable</span>
</span>
</td>
<td id="S2.T3.15.16.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:34.1pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.6.1.1" class="ltx_p">High</span>
</span>
</td>
<td id="S2.T3.15.16.1.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:62.6pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S2.T3.15.16.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.16.1.7.1.1" class="ltx_p">Variable</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T3.17.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S2.T3.18.2" class="ltx_text" style="font-size:90%;">Comparison of Python Libraries for Synthetic Data Generation</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Privacy</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We begin this section by discussing risks posed by data sharing that are specific to the financial domain. We next review privacy attacks studied in machine learning literature. We then discuss the relationship between the privacy risks in the financial domain and the privacy attacks. Finally, we discuss various levels of (privacy) defense that can be applied to the original data or embedded into the synthetic data generation process, and the protection these provide in the context of privacy attacks. We refer to these levels as privacy levels.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Privacy risks in the finance domain</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In financial institutions, data sharing between various lines of businesses within the institution as well as externally is governed by various regulations and internal guidelines that are put in place to protect clientsâ€™ sensitive information and protect firms from MNPI (Material Non-Public Information), litigation, reputation, and competitive risks. In this section, we review some prominent risks and relevant regulations in this space.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fair Credit Reporting Act (FCRA)</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">This act requires that information collected by consumer reporting agencies (e.g. credit bureaus) cannot be provided to anyone who does not have a purpose specified by the FCRA. In particular, it is not enough to only remove from the data fields that identify an individual. In addition, one needs to ensure that the identity cannot be revealed using other data fields, outcome of an algorithm used on the data, and/or publicly available information.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Regulation on Unfair, Deceptive or Abusive Acts or Practices (UDAAP)</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">Sharing and certain uses of identifiable data may be sensitive to consumer or a client, and it thus represents potential UDAAP risks if used or shared in a manner contrary to elections made by, or representations made to, consumers or clients. In particular, in many settings sharing identifiable data is subject to privacy elections made by consumers.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Litigation risks</h5>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.1" class="ltx_p">Inappropriate release of data or functions of data (e.g., models trained on data, insights from data, or synthetic data resembling these datasets) that reveal personally identifying information or statistics (a.k.a. global characteristics) of the data, may pose litigation risks. This is particularly prominent in the context of data sourced from external vendors: use of such data is typically bounded by contracts that precisely define the scope of the use.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Competitive risks</h5>

<div id="S3.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px4.p1.1" class="ltx_p">Publishing data that resembles characteristics of a firmâ€™s client base or industries and publicly traded companies the firm has interest in, may pose competitive, antitrust and increased insider trading risks. This holds even if the published data is synthetic.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Privacy attacks in machine learning literature</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">ML models and their outputs are vulnerable to various privacy attacksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx181" title="" class="ltx_ref">SZZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>. The basic assumption of a privacy attack is the existence of a maliciously intentioned adversary who aims to elicit some private information based on the model output. In this paper, we focus on the model output in the form of synthetic data. Privacy attacks come in various flavors. Each distinct attack is characterized by a set of assumptions; e.g. what information is available to the adversary, what information needs to be protected, what is the goal of the attack, etc. Here, we briefly overview some of the most relevant attacks, in the context of privacy risks in the domain of finance (see TableÂ <a href="#S3.T4" title="Table 4 â€£ Property inference attacks â€£ 3.2 Privacy attacks in machine learning literature â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Membership inference attacks (MIAs)</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">In many cases, the presence of an individualâ€™s data in a dataset by itself can reveal sensitive information. The adversaryâ€™s task in MIAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx179" title="" class="ltx_ref">SSS16</a>]</cite> is to successfully infer whether an individual was present in the training dataset or not, based on the output of a data processing procedure (e.g. an ML classifier or a synthetic data generator). Moreover, an adversary with the knowledge of an individualâ€™s presence in the dataset can further use linkage attacks (reconstruction attacks) to identify sensitive attributes of that individual. For example, if all data columns matching public information of an individual correspond to an entry in the dataset with a given private attribute, the presence of the individual in the dataset reveals that private attribute for that individual. Thus, MIA can be used as a stepping stone to launch other types of attack.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Reconstruction attacks (attribute inference attacks)</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">Reconstruction attacks are characterized by an adversary who is in possession of partial knowledge of a set of features with the aim to recover <span id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">sensitive</span> features or the full data sample. A notable example of an attribute inference attack is the one where an adversary relies on a public set of (non-sensitive) attributes in order to infer values of a sensitive attributeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx139" title="" class="ltx_ref">NS07</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Property inference attacks</h5>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">Property inference represents the ability to extract properties of the original dataset based on the corresponding synthetic data. In general, property inference covers learning of any summary statistic of the original data (e.g. mean value, quantiles, histograms, etc.) under the assumption of the access to synthetic data. Preventing property inference attack necessarily degrades fidelity of the synthetic dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx121" title="" class="ltx_ref">LWSF23</a>]</cite>.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<table id="S3.T4.2" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T4.2.1.1" class="ltx_tr">
<td id="S3.T4.2.1.1.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FCRA</td>
<td id="S3.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">UDAAP</td>
<td id="S3.T4.2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Litigation Risk</td>
<td id="S3.T4.2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Competitive Risk</td>
</tr>
<tr id="S3.T4.2.2.2" class="ltx_tr">
<td id="S3.T4.2.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Membership Inference Attack</td>
<td id="S3.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
</tr>
<tr id="S3.T4.2.3.3" class="ltx_tr">
<td id="S3.T4.2.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Attribute Inference Attack</td>
<td id="S3.T4.2.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
</tr>
<tr id="S3.T4.2.4.4" class="ltx_tr">
<td id="S3.T4.2.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Property Inference Attack</td>
<td id="S3.T4.2.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S3.T4.2.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S3.T4.2.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Applicable</td>
</tr>
<tr id="S3.T4.2.5.5" class="ltx_tr">
<td id="S3.T4.2.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Model Inference Attack</td>
<td id="S3.T4.2.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Applicable</td>
<td id="S3.T4.2.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Applicable</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S3.T4.4.2" class="ltx_text" style="font-size:90%;">Privacy attacks on synthetic data can lead to breach of various regulations in the financial domain</span></figcaption>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Defences against privacy attacks</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this section, we review some defenses against privacy attacks. Note that the list is non exhaustive. Moreover, we propose a novel hierarchy of defenses against privacy attacks we refer to as <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">privacy levels</span>.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Anonymization/PII obscuration</h5>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">There is a wide range of techniques that rely on personal identifiable information (PII) obscuration or anonymization of sensitive fields (e.g. full or partial masking of characters, mapping of categories into codes, etc.). These are however generally prone to linkage attacks, and thus they do not provide formal guarantees against privacy attacksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx139" title="" class="ltx_ref">NS07</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Randomization</h5>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.1" class="ltx_p">Randomization is a data swapping technique that aims to provide plausible deniability by making it impossible for an adversary to infer any information regarding the data with absolute certainty. It involves swapping values of certain (or all) data points between unique individuals in the dataset. Randomization often aims to provide privacy while preserving the utility of the downstream task (or the accuracy of a query from the dataset) to an acceptable degree.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Differential privacy</h5>

<div id="S3.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px3.p1.11" class="ltx_p">Differential privacyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx55" title="" class="ltx_ref">DR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>14</a>, <a href="#bib.bibx1" title="" class="ltx_ref">ABG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> as defence belongs to the family of randomization techniques. It provides theoretical guarantees that a potential adversary with the knowledge of an algorithmâ€™s output (e.g. synthetic data) is not able to distinguish with certainty whether a particular individual was present in the input dataset (e.g. original data). More precisely, let <math id="S3.SS3.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{X}^{n}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.1.m1.1a"><msup id="S3.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml">ğ’³</mi><mi id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml">n</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1.2">ğ’³</ci><ci id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.1.m1.1c">\mathcal{X}^{n}</annotation></semantics></math> represent the universe of datasets consisting of <math id="S3.SS3.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.2.m2.1a"><mi id="S3.SS3.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.2.m2.1b"><ci id="S3.SS3.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.2.m2.1c">n</annotation></semantics></math> entries. We say that two datasets <math id="S3.SS3.SSS0.Px3.p1.3.m3.2" class="ltx_Math" alttext="D,D^{\prime}\in\mathcal{X}^{n}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.3.m3.2a"><mrow id="S3.SS3.SSS0.Px3.p1.3.m3.2.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.cmml"><mrow id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.2.cmml"><mi id="S3.SS3.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS3.SSS0.Px3.p1.3.m3.1.1.cmml">D</mi><mo id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.2.cmml">,</mo><msup id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3.cmml">â€²</mo></msup></mrow><mo id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.2.cmml">âˆˆ</mo><msup id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.2.cmml">ğ’³</mi><mi id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.3.m3.2b"><apply id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2"><in id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.2"></in><list id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1"><ci id="S3.SS3.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.1.1">ğ·</ci><apply id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2">ğ·</ci><ci id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3">â€²</ci></apply></list><apply id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3">superscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.2">ğ’³</ci><ci id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.3.m3.2c">D,D^{\prime}\in\mathcal{X}^{n}</annotation></semantics></math> are <span id="S3.SS3.SSS0.Px3.p1.11.1" class="ltx_text ltx_font_italic">neighbouring</span> if they differ in exactly one data entry, i.e. individual. Let <math id="S3.SS3.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.4.m4.1b"><ci id="S3.SS3.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.4.m4.1c">\mathcal{M}</annotation></semantics></math> represent a mechanism that takes as an input a dataset from <math id="S3.SS3.SSS0.Px3.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{X}^{n}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.5.m5.1a"><msup id="S3.SS3.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2.cmml">ğ’³</mi><mi id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3.cmml">n</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.5.m5.1b"><apply id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2">ğ’³</ci><ci id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.5.m5.1c">\mathcal{X}^{n}</annotation></semantics></math> and provides an output, e.g. a synthetic dataset. We say that <math id="S3.SS3.SSS0.Px3.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.6.m6.1.1" xref="S3.SS3.SSS0.Px3.p1.6.m6.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.6.m6.1b"><ci id="S3.SS3.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.6.m6.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.6.m6.1c">\mathcal{M}</annotation></semantics></math> is <math id="S3.SS3.SSS0.Px3.p1.7.m7.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.7.m7.2a"><mrow id="S3.SS3.SSS0.Px3.p1.7.m7.2.3.2" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.3.1.cmml"><mo stretchy="false" id="S3.SS3.SSS0.Px3.p1.7.m7.2.3.2.1" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.3.1.cmml">(</mo><mi id="S3.SS3.SSS0.Px3.p1.7.m7.1.1" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.cmml">Ïµ</mi><mo id="S3.SS3.SSS0.Px3.p1.7.m7.2.3.2.2" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.3.1.cmml">,</mo><mi id="S3.SS3.SSS0.Px3.p1.7.m7.2.2" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.2.cmml">Î´</mi><mo stretchy="false" id="S3.SS3.SSS0.Px3.p1.7.m7.2.3.2.3" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.7.m7.2b"><interval closure="open" id="S3.SS3.SSS0.Px3.p1.7.m7.2.3.1.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.3.2"><ci id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1">italic-Ïµ</ci><ci id="S3.SS3.SSS0.Px3.p1.7.m7.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.2.2">ğ›¿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.7.m7.2c">(\epsilon,\delta)</annotation></semantics></math>-differentially private if for any two neighbouring datasets <math id="S3.SS3.SSS0.Px3.p1.8.m8.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.8.m8.1a"><mi id="S3.SS3.SSS0.Px3.p1.8.m8.1.1" xref="S3.SS3.SSS0.Px3.p1.8.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.8.m8.1b"><ci id="S3.SS3.SSS0.Px3.p1.8.m8.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.8.m8.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.8.m8.1c">D</annotation></semantics></math> and <math id="S3.SS3.SSS0.Px3.p1.9.m9.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.9.m9.1a"><msup id="S3.SS3.SSS0.Px3.p1.9.m9.1.1" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.9.m9.1b"><apply id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2">ğ·</ci><ci id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.9.m9.1c">D^{\prime}</annotation></semantics></math> and any set <math id="S3.SS3.SSS0.Px3.p1.10.m10.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.10.m10.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.10.m10.1.1" xref="S3.SS3.SSS0.Px3.p1.10.m10.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.10.m10.1b"><ci id="S3.SS3.SSS0.Px3.p1.10.m10.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.10.m10.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.10.m10.1c">\mathcal{C}</annotation></semantics></math> of outcomes of mechanism <math id="S3.SS3.SSS0.Px3.p1.11.m11.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.11.m11.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.11.m11.1.1" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.11.m11.1b"><ci id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.11.m11.1c">\mathcal{M}</annotation></semantics></math> we have</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\mathbb{P}\left(\mathcal{M}(D)\in\mathcal{C}\right)\leq e^{\epsilon}\mathbb{P}\left(\mathcal{M}(D^{\prime})\in\mathcal{C}\right)+\delta." display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml">â„™</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">D</mi><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml">ğ’</mi></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml">â‰¤</mo><mrow id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml"><mrow id="S3.E1.m1.2.2.1.1.2.1" xref="S3.E1.m1.2.2.1.1.2.1.cmml"><msup id="S3.E1.m1.2.2.1.1.2.1.3" xref="S3.E1.m1.2.2.1.1.2.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.1.3.2" xref="S3.E1.m1.2.2.1.1.2.1.3.2.cmml">e</mi><mi id="S3.E1.m1.2.2.1.1.2.1.3.3" xref="S3.E1.m1.2.2.1.1.2.1.3.3.cmml">Ïµ</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.1.2" xref="S3.E1.m1.2.2.1.1.2.1.2.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.2.1.4" xref="S3.E1.m1.2.2.1.1.2.1.4.cmml">â„™</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.1.2a" xref="S3.E1.m1.2.2.1.1.2.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.2.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.2.cmml">D</mi><mo id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.2.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.2.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.3.cmml">ğ’</mi></mrow><mo id="S3.E1.m1.2.2.1.1.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.2.2" xref="S3.E1.m1.2.2.1.1.2.2.cmml">+</mo><mi id="S3.E1.m1.2.2.1.1.2.3" xref="S3.E1.m1.2.2.1.1.2.3.cmml">Î´</mi></mrow></mrow><mo lspace="0em" id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><leq id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3"></leq><apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.2"></times><ci id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3">â„™</ci><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><in id="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1"></in><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2"><times id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1"></times><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.2">â„³</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ·</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3">ğ’</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2"><plus id="S3.E1.m1.2.2.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2"></plus><apply id="S3.E1.m1.2.2.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1"><times id="S3.E1.m1.2.2.1.1.2.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.2"></times><apply id="S3.E1.m1.2.2.1.1.2.1.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.3">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.3.2">ğ‘’</ci><ci id="S3.E1.m1.2.2.1.1.2.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.3.3">italic-Ïµ</ci></apply><ci id="S3.E1.m1.2.2.1.1.2.1.4.cmml" xref="S3.E1.m1.2.2.1.1.2.1.4">â„™</ci><apply id="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1"><in id="S3.E1.m1.2.2.1.1.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.2"></in><apply id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.2"></times><ci id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.3">â„³</ci><apply id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.2">ğ·</ci><ci id="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.1.1.1.1.3">â€²</ci></apply></apply><ci id="S3.E1.m1.2.2.1.1.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.3">ğ’</ci></apply></apply><ci id="S3.E1.m1.2.2.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.3">ğ›¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\mathbb{P}\left(\mathcal{M}(D)\in\mathcal{C}\right)\leq e^{\epsilon}\mathbb{P}\left(\mathcal{M}(D^{\prime})\in\mathcal{C}\right)+\delta.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS3.SSS0.Px3.p2.6" class="ltx_p">For <math id="S3.SS3.SSS0.Px3.p2.1.m1.1" class="ltx_Math" alttext="\delta=0" display="inline"><semantics id="S3.SS3.SSS0.Px3.p2.1.m1.1a"><mrow id="S3.SS3.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.2" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.2.cmml">Î´</mi><mo id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.1" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.3" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p2.1.m1.1b"><apply id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1"><eq id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.1"></eq><ci id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.2">ğ›¿</ci><cn type="integer" id="S3.SS3.SSS0.Px3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p2.1.m1.1c">\delta=0</annotation></semantics></math> and small values of <math id="S3.SS3.SSS0.Px3.p2.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS0.Px3.p2.2.m2.1a"><mi id="S3.SS3.SSS0.Px3.p2.2.m2.1.1" xref="S3.SS3.SSS0.Px3.p2.2.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p2.2.m2.1b"><ci id="S3.SS3.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.2.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p2.2.m2.1c">\epsilon</annotation></semantics></math>, <math id="S3.SS3.SSS0.Px3.p2.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS0.Px3.p2.3.m3.1a"><mi id="S3.SS3.SSS0.Px3.p2.3.m3.1.1" xref="S3.SS3.SSS0.Px3.p2.3.m3.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p2.3.m3.1b"><ci id="S3.SS3.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.3.m3.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p2.3.m3.1c">\epsilon</annotation></semantics></math>-differential privacy guranatees that for any run of the mechanism, any output is almost equally likely to be observed on any neighbouring database. On the other hand, <math id="S3.SS3.SSS0.Px3.p2.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S3.SS3.SSS0.Px3.p2.4.m4.2a"><mrow id="S3.SS3.SSS0.Px3.p2.4.m4.2.3.2" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.3.1.cmml"><mo stretchy="false" id="S3.SS3.SSS0.Px3.p2.4.m4.2.3.2.1" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.3.1.cmml">(</mo><mi id="S3.SS3.SSS0.Px3.p2.4.m4.1.1" xref="S3.SS3.SSS0.Px3.p2.4.m4.1.1.cmml">Ïµ</mi><mo id="S3.SS3.SSS0.Px3.p2.4.m4.2.3.2.2" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.3.1.cmml">,</mo><mi id="S3.SS3.SSS0.Px3.p2.4.m4.2.2" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.2.cmml">Î´</mi><mo stretchy="false" id="S3.SS3.SSS0.Px3.p2.4.m4.2.3.2.3" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p2.4.m4.2b"><interval closure="open" id="S3.SS3.SSS0.Px3.p2.4.m4.2.3.1.cmml" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.3.2"><ci id="S3.SS3.SSS0.Px3.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.4.m4.1.1">italic-Ïµ</ci><ci id="S3.SS3.SSS0.Px3.p2.4.m4.2.2.cmml" xref="S3.SS3.SSS0.Px3.p2.4.m4.2.2">ğ›¿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p2.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-differential privacy guarantees that for all neighbouring datasets the absolute value of privacy loss is bounded by <math id="S3.SS3.SSS0.Px3.p2.5.m5.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS0.Px3.p2.5.m5.1a"><mi id="S3.SS3.SSS0.Px3.p2.5.m5.1.1" xref="S3.SS3.SSS0.Px3.p2.5.m5.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p2.5.m5.1b"><ci id="S3.SS3.SSS0.Px3.p2.5.m5.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.5.m5.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p2.5.m5.1c">\epsilon</annotation></semantics></math>, with probability at least <math id="S3.SS3.SSS0.Px3.p2.6.m6.1" class="ltx_Math" alttext="1-\delta" display="inline"><semantics id="S3.SS3.SSS0.Px3.p2.6.m6.1a"><mrow id="S3.SS3.SSS0.Px3.p2.6.m6.1.1" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.cmml"><mn id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.2" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.1" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.1.cmml">âˆ’</mo><mi id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.3" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.3.cmml">Î´</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p2.6.m6.1b"><apply id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1"><minus id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.2">1</cn><ci id="S3.SS3.SSS0.Px3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p2.6.m6.1.1.3">ğ›¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p2.6.m6.1c">1-\delta</annotation></semantics></math>. We are now ready to introduce our privacy framework.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Privacy levels: synthetic data generation techniques as privacy defenses</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In this section, we propose a six-level privacy defense hierarchy and discuss the privacy attacks, utility implications, and potential privacy guarantees for each level. Each level corresponds to a category of defense mechanisms. This is important when reviewing what individuals and businesses want to do with existing data. In practice, we would look to apply the corresponding privacy level to the specific use case in order to achieve the business goal, with security and speed being the two primary benefits to the business. Note that there is still not a widely accepted definition of synthetic dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx100" title="" class="ltx_ref">JSH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<table id="S3.T5.2" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T5.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1" class="ltx_td ltx_align_center" colspan="6"><math id="S3.T5.1.1.1.m1.1" class="ltx_math_unparsed" alttext="\xrightarrow{\hskip 85.35826pt\text{More privacy}\hskip 85.35826pt}" display="inline"><semantics id="S3.T5.1.1.1.m1.1a"><mover accent="true" id="S3.T5.1.1.1.m1.1.1"><mo stretchy="false" id="S3.T5.1.1.1.m1.1.1.2">â†’</mo><mrow id="S3.T5.1.1.1.m1.1.1.1"><mtext id="S3.T5.1.1.1.m1.1.1.1.1">More privacy</mtext><mspace width="8.54em" id="S3.T5.1.1.1.m1.1.1.1.2"></mspace></mrow></mover><annotation encoding="application/x-tex" id="S3.T5.1.1.1.m1.1b">\xrightarrow{\hskip 85.35826pt\text{More privacy}\hskip 85.35826pt}</annotation></semantics></math></td>
</tr>
<tr id="S3.T5.2.3.1" class="ltx_tr">
<td id="S3.T5.2.3.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Level 1</td>
<td id="S3.T5.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Level 2</td>
<td id="S3.T5.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Level 3</td>
<td id="S3.T5.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Level 4</td>
<td id="S3.T5.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Level 5</td>
<td id="S3.T5.2.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Level 6</td>
</tr>
<tr id="S3.T5.2.4.2" class="ltx_tr">
<td id="S3.T5.2.4.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Obscure PII</td>
<td id="S3.T5.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T5.2.4.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.2.4.2.2.1.1" class="ltx_tr">
<td id="S3.T5.2.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Obscure PII</td>
</tr>
<tr id="S3.T5.2.4.2.2.1.2" class="ltx_tr">
<td id="S3.T5.2.4.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">+</td>
</tr>
<tr id="S3.T5.2.4.2.2.1.3" class="ltx_tr">
<td id="S3.T5.2.4.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">Randomization</td>
</tr>
</table>
</td>
<td id="S3.T5.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T5.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.2.4.2.3.1.1" class="ltx_tr">
<td id="S3.T5.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Generative</td>
</tr>
<tr id="S3.T5.2.4.2.3.1.2" class="ltx_tr">
<td id="S3.T5.2.4.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">modeling</td>
</tr>
</table>
</td>
<td id="S3.T5.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T5.2.4.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.2.4.2.4.1.1" class="ltx_tr">
<td id="S3.T5.2.4.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Generative</td>
</tr>
<tr id="S3.T5.2.4.2.4.1.2" class="ltx_tr">
<td id="S3.T5.2.4.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">modeling</td>
</tr>
<tr id="S3.T5.2.4.2.4.1.3" class="ltx_tr">
<td id="S3.T5.2.4.2.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">+</td>
</tr>
<tr id="S3.T5.2.4.2.4.1.4" class="ltx_tr">
<td id="S3.T5.2.4.2.4.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center">randomization</td>
</tr>
</table>
</td>
<td id="S3.T5.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T5.2.4.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.2.4.2.5.1.1" class="ltx_tr">
<td id="S3.T5.2.4.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Calibrated</td>
</tr>
<tr id="S3.T5.2.4.2.5.1.2" class="ltx_tr">
<td id="S3.T5.2.4.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">simulation</td>
</tr>
</table>
</td>
<td id="S3.T5.2.4.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T5.2.4.2.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.2.4.2.6.1.1" class="ltx_tr">
<td id="S3.T5.2.4.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Uncalibrated</td>
</tr>
<tr id="S3.T5.2.4.2.6.1.2" class="ltx_tr">
<td id="S3.T5.2.4.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Simulation</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T5.2.2" class="ltx_tr">
<td id="S3.T5.2.2.1" class="ltx_td ltx_align_center ltx_border_t" colspan="6"><math id="S3.T5.2.2.1.m1.1" class="ltx_math_unparsed" alttext="\xleftarrow{\hskip 85.35826pt\text{More fidelity}\hskip 85.35826pt}" display="inline"><semantics id="S3.T5.2.2.1.m1.1a"><mover accent="true" id="S3.T5.2.2.1.m1.1.1"><mo stretchy="false" id="S3.T5.2.2.1.m1.1.1.2">â†</mo><mrow id="S3.T5.2.2.1.m1.1.1.1"><mtext id="S3.T5.2.2.1.m1.1.1.1.1">More fidelity</mtext><mspace width="8.54em" id="S3.T5.2.2.1.m1.1.1.1.2"></mspace></mrow></mover><annotation encoding="application/x-tex" id="S3.T5.2.2.1.m1.1b">\xleftarrow{\hskip 85.35826pt\text{More fidelity}\hskip 85.35826pt}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T5.4.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S3.T5.5.2" class="ltx_text" style="font-size:90%;">Categorization of synthetic data approaches based on privacy levels. Higher levels generally provide better privacy guarantees, but are less truthful to the original data.</span></figcaption>
</figure>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2401.00081/assets/x1.png" id="S3.F6.g1" class="ltx_graphics ltx_img_landscape" width="597" height="176" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.3.2" class="ltx_text" style="font-size:90%;">Privacy Level 1: Obscure PII</span></figcaption>
</figure>
<section id="S3.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Level 1: Obscure PII</h5>

<div id="S3.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px1.p1.1" class="ltx_p">Examples of mechanisms at this level include dropping, replacing, masking, or anonymizing of the PII attributes. Since this approach does not modify non-PII attributes in any way, it will not impact the utility of downstream tasks and thus there is no utility degradation. This however represents weak privacy protection as data remains vulnerable to linkage attacks (see FigureÂ <a href="#S3.F6" title="Figure 6 â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> for an illustrative example).</p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2401.00081/assets/x2.png" id="S3.F7.g1" class="ltx_graphics ltx_img_landscape" width="597" height="177" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.3.2" class="ltx_text" style="font-size:90%;">Privacy Level 2: Obscure PII + Randomization</span></figcaption>
</figure>
</section>
<section id="S3.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Level 2: Obscure PII + Randomization</h5>

<div id="S3.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px2.p1.1" class="ltx_p">In addition to obscuring PII columns, we add deliberate noise to other attributes or carefully randomize the algorithm applied to the data (algorithm could be a query from the dataset, train a machine learning algorithm, etc.). Depending on the amount of noise and the downstream task, some degree of utility degradation is expected (see FigureÂ <a href="#S3.F7" title="Figure 7 â€£ Level 1: Obscure PII â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> for an illustrative example).</p>
</div>
<figure id="S3.F8" class="ltx_figure"><img src="/html/2401.00081/assets/x3.png" id="S3.F8.g1" class="ltx_graphics ltx_img_landscape" width="597" height="260" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S3.F8.3.2" class="ltx_text" style="font-size:90%;">Privacy Level 3: Synthetisized Rows</span></figcaption>
</figure>
</section>
<section id="S3.SS4.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Level 3: Generative modeling</h5>

<div id="S3.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px3.p1.1" class="ltx_p">Many ML-based synthetic data generation approaches such as Gaussian copula, GAN copula, etc. fall in this category <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx158" title="" class="ltx_ref">PWV16b</a>, <a href="#bib.bibx84" title="" class="ltx_ref">GPAM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>14b</a>, <a href="#bib.bibx151" title="" class="ltx_ref">PMG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite>. These methods typically do not have strong privacy guarantees (see FigureÂ <a href="#S3.F8" title="Figure 8 â€£ Level 2: Obscure PII + Randomization â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> for an illustrative example).</p>
</div>
<figure id="S3.F9" class="ltx_figure"><img src="/html/2401.00081/assets/x4.png" id="S3.F9.g1" class="ltx_graphics ltx_img_landscape" width="597" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S3.F9.3.2" class="ltx_text" style="font-size:90%;">Privacy Level 4: Synthetisized Rows + Test</span></figcaption>
</figure>
</section>
<section id="S3.SS4.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Level 4: Generative modeling + Randomization</h5>

<div id="S3.SS4.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px4.p1.1" class="ltx_p">Randomizing the synthetic data generation process by adding deliberate noise to the input data (the real data), the synthetic data generation algorithm, or the output (synthetic data). Utility degradation depends on the synthetic data generation approach, the amount of injected noise, and the downstream task. This approach has the potential to achieve strong protection against MIA. In particular, synthetic data generation methods that provide DP guarantees belong to this class <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">ADR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>, <a href="#bib.bibx206" title="" class="ltx_ref">XLW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>, <a href="#bib.bibx214" title="" class="ltx_ref">YJvdS19b</a>]</cite> (see FigureÂ <a href="#S3.F9" title="Figure 9 â€£ Level 3: Generative modeling â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> for an illustrative example).</p>
</div>
<figure id="S3.F10" class="ltx_figure"><img src="/html/2401.00081/assets/x5.png" id="S3.F10.g1" class="ltx_graphics ltx_img_landscape" width="597" height="191" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S3.F10.3.2" class="ltx_text" style="font-size:90%;">Privacy Level 5: Calibrated Simulation</span></figcaption>
</figure>
</section>
<section id="S3.SS4.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Level 5: Simulation-based synthetic data generation calibrated on real data</h5>

<div id="S3.SS4.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px5.p1.1" class="ltx_p">In this approach the data generation model is not trained on real data. In fact, there is no learning in this approach. This approach relies on simulations governed by rules to generate synthetic data. These rules, however, are calibrated such that the generated data follows some statistical properties of the original, real dataset. Utility degradation depends on the downstream task and the simulation framework. This approach generally represents a strong defence, except in the context of PIA attacks, since the simulator is calibrated with respect to statistical properties of the real dataset (see FigureÂ <a href="#S3.F10" title="Figure 10 â€£ Level 4: Generative modeling + Randomization â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> for an illustrative example).</p>
</div>
<figure id="S3.F11" class="ltx_figure"><img src="/html/2401.00081/assets/x6.png" id="S3.F11.g1" class="ltx_graphics ltx_img_landscape" width="597" height="188" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S3.F11.3.2" class="ltx_text" style="font-size:90%;">Privacy Level 6: Uncalibrated Simulation</span></figcaption>
</figure>
</section>
<section id="S3.SS4.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Level 6: Uncalibrated simulation-based synthetic data generation</h5>

<div id="S3.SS4.SSS0.Px6.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px6.p1.1" class="ltx_p">Uncalibrated simulation has no related statistical properties to the original real dataset, meaning that the population-level statistics from the original dataset are not revealed. In general, this method yields a strong privacy guarantee given the severe utility degradation. This method of data creation requires the user to define the metadata of the original data, describing the column names and the values in those columns. Given the uncalibrated nature of this level, different data distributions to that of the original dataset are used, strengthening the defence of the synthetic data. This approach remediates one of the consequences of level 5 generation of defence against PIA attacks, given that the statistical properties of the data are uncalibrated to the real dataset (see FigureÂ <a href="#S3.F11" title="Figure 11 â€£ Level 5: Simulation-based synthetic data generation calibrated on real data â€£ 3.4 Privacy levels: synthetic data generation techniques as privacy defenses â€£ 3 Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> for an illustrative example).</p>
</div>
</section>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Privacy Levels to Guide Synthetic Data Use Cases</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">The creation of these privacy levels has the benefit of being transposed across business use-cases. Levels one and two lend themselves to use cases around sharing data after removing the confidential elements of the original dataset. Levels three and four translate well to improving AI models, be that through augmenting the original data, or testing AI models. Finally, levels five and six can support software engineers in testing applications among others. We will see additional level five synthetic data applications in the time-series SectionÂ <a href="#S6" title="6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> using ABIDES. Level 6 data in particular can be utilized for software testing, proof of concepts, hackathons, stress testing business rules in applications, and data migrations among others.</p>
</div>
<section id="S3.SS4.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Case Study: Stress Testing Software Applications</h5>

<div id="S3.SS4.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px1.p1.1" class="ltx_p">A common challenge in the software engineering space is stress testing applications to better understand performance. For financial systems, market volatility can cause unexpected increases in the volumes traded, when unexpected events occur, such as Brexit or the outbreak of Covid-19, which saw abnormal increases in the volume of trades. To better understand how the supporting technology will function when such events occur, it is important to test these types of scenarios before they occur to ensure stability of these systems. Using production data for testing is not feasible due to privacy concerns.</p>
</div>
<div id="S3.SS4.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS4.SSS1.Px1.p2.1" class="ltx_p">We created level <math id="S3.SS4.SSS1.Px1.p2.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S3.SS4.SSS1.Px1.p2.1.m1.1a"><mn id="S3.SS4.SSS1.Px1.p2.1.m1.1.1" xref="S3.SS4.SSS1.Px1.p2.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.Px1.p2.1.m1.1b"><cn type="integer" id="S3.SS4.SSS1.Px1.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS1.Px1.p2.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.Px1.p2.1.m1.1c">5</annotation></semantics></math> calibrated simulation-based synthetic data to contain similar statistical properties, while removing all records of confidential data in the generated dataset. Millions of rows of data were generated in order to test the application if a sudden spike in trades were to occur. This enabled a streamlined approach to stress testing that had previously not existed.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S4" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Tabular Data</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we focus on one of the most ubiquitous type of financial data, namely tabular data, and in particular synthetic data generation, privacy, fairness and robustness of downstream classifiers.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Generation</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Real-world domains are often described by what we call tabular data, i.e., data that can be structured and organized in a table-like format. Synthetic data generation of these types of datasets is vital as it resolves data scarcity and quality concerns by providing synthetic data that preserves the overall statistical properties and relationships among the attributes of the original dataset (FigureÂ <a href="#S4.F12" title="Figure 12 â€£ 4.1 Generation â€£ 4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>). Synthetic data enables testing new ideas without compromising real data, blending multiple sources, and protecting individual privacy when sharingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx197" title="" class="ltx_ref">VVdB17</a>, <a href="#bib.bibx188" title="" class="ltx_ref">TWB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite>. However, major questions arise from the use of synthetic data. Particularly, is there a major cost that comes with replacing the original training data with the synthetic data we generated? To address this question, the development of a framework to mitigate performance degradation is indispensable.</p>
</div>
<figure id="S4.F12" class="ltx_figure"><img src="/html/2401.00081/assets/x7.png" id="S4.F12.g1" class="ltx_graphics ltx_centering ltx_img_square" width="184" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S4.F12.3.2" class="ltx_text" style="font-size:90%;">TSNE plot showing similarity between original data and synthetic data.</span></figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Recent workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx65" title="" class="ltx_ref">ET08</a>]</cite> shows that there are various approaches to model tabular data distribution: statistical-basedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx125" title="" class="ltx_ref">LZF20</a>]</cite>, machine learning-basedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx42" title="" class="ltx_ref">CR10</a>]</cite>, Bayesian network-basedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx75" title="" class="ltx_ref">GBR21</a>]</cite>, neural network-basedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx151" title="" class="ltx_ref">PMG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite>. Each of these methods for synthetic data generation possesses unique capabilities and features. The appropriate method depends on many factors such as the distribution of the observed data or the objective of generating the synthetic data. For instance, statistical-based approaches prove advantageous when dealing with known marginal distributions. Due to this, reaching consensus on which method we should use for a specific dataset and use-case remains challenging. Recently, a potential solution for model selection was proposed by using Bayesian optimizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx91" title="" class="ltx_ref">HNSOP23</a>]</cite>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">We review three popular neural network-based models namely, TVAE, conditional tabular GAN (CTGAN) and CopulaGAN. Since the original GAN formulationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx84" title="" class="ltx_ref">GPAM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>14b</a>]</cite>, ongoing research has proposed new optimization strategies and modifications to address limitations found on GANs. One of these GAN models, that builds on the success attained by previous architectures, is CTGAN. It uses mode-specific normalization to capture non-Gaussian and multimodal distributionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx208" title="" class="ltx_ref">XSCIV19</a>]</cite>. This model also introduces a conditional generator and training by sampling to deal with challenges imposed by highly imbalanced categorical columns and sparsity of one-hot-encoded vectors, which is a limitation of previous GAN architectures. CopulaGAN is a variation of CTGAN which takes advantage of the cumulative distribution function (CDF)-based transformation. The other neural network approach called TVAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx208" title="" class="ltx_ref">XSCIV19</a>]</cite> is based on variational autoencoders (VAE).
Synthetic data generation can also be achieved by treating each table column as a random variable, modeling a multivariate probability distribution, and sampling from it using statistical-based methods. This approach, known as GaussianCopulaÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx137" title="" class="ltx_ref">MV12</a>]</cite>, is based on copula functions which are mathematical functions that allow us to describe the joint distribution of multiple random variables by analyzing the dependencies among their marginal distributionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx157" title="" class="ltx_ref">PWV16a</a>]</cite>. This is used to model the covariances among features in addition to the distributionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx117" title="" class="ltx_ref">LM22</a>]</cite>. Beyond these approaches, synthetic data can also be synthesized by inferring the domain of each attribute, deriving a description of the distribution of attributes in the dataset and sampling from the probabilistic model in the dataset description. This method is called DataSynthesizer (DS)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx153" title="" class="ltx_ref">PSH17</a>]</cite>.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Optimization Method</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Most of synthetic generation approaches mentioned earlier are â€œunsupervisedâ€ in the sense that they do not take into account the downstream task. Most of the approaches discussed earlier treat the label variable like other covariates. The primary focus of these approaches is to create models that are â€œsimilarâ€ to original datasets. This creates a conflict in some use cases where the primary objective is optimizing for downstream predictions as opposed to achieving similarity to the original data. We propose a novel synthetic data generation framework, Supervised and Composed Generative Optimization Approach for Tabular data (SC-GOAT)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx91" title="" class="ltx_ref">HNSOP23</a>]</cite>, which incorporates a supervised component and optimizes directly on the downstream loss function to address the aforementioned issues. This approach comprises of two steps. In the first step, we incorporate a supervised component customized for the specific downstream task leveraging a Bayesian optimization approach to fine-tune the hyperparameters related to the neural networks. For the second step, we adopt a meta-learning approach to identify the optimal mixture distribution of the existing synthetic data generation approaches. Therefore, the SC-GOAT approach generates synthetic data based on the mixture of multiple synthetic data generation approaches we mentioned earlier.</p>
</div>
<figure id="S4.T13" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T13.2.1.1" class="ltx_text" style="font-size:90%;">Table 13</span>: </span><span id="S4.T13.3.2" class="ltx_text" style="font-size:90%;">Description of data sets.</span></figcaption>
<table id="S4.T13.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T13.4.1.1" class="ltx_tr">
<th id="S4.T13.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Data set</th>
<th id="S4.T13.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Label</th>
<th id="S4.T13.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Observation</th>
<th id="S4.T13.4.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Continuous</th>
<th id="S4.T13.4.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Binary</th>
<th id="S4.T13.4.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Multi-class</th>
<th id="S4.T13.4.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Label = 0</th>
<th id="S4.T13.4.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Label = 1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T13.4.2.1" class="ltx_tr">
<td id="S4.T13.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Credit Balanced</td>
<td id="S4.T13.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t">â€™Classâ€™</td>
<td id="S4.T13.4.2.1.3" class="ltx_td ltx_align_left ltx_border_t">50,000</td>
<td id="S4.T13.4.2.1.4" class="ltx_td ltx_align_left ltx_border_t">30</td>
<td id="S4.T13.4.2.1.5" class="ltx_td ltx_align_left ltx_border_t">1</td>
<td id="S4.T13.4.2.1.6" class="ltx_td ltx_align_left ltx_border_t">0</td>
<td id="S4.T13.4.2.1.7" class="ltx_td ltx_align_left ltx_border_t">66.70%%</td>
<td id="S4.T13.4.2.1.8" class="ltx_td ltx_align_left ltx_border_t">33.3%</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Application: Credit Card Fraud</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this section, we investigate our generative models in terms of the utility of using machine learning for fraud detection.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data:</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">To showcase the usefulness of synthetic tabular data, we use the credit card fraud dataset<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Data available on the Kaggle platform at <a target="_blank" href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud</a></span></span></span>. The dataset contains transactions collected in the span of two days made by European cardholders for the month of September 2013. The dataset is highly imbalanced, containing 492 frauds out of 284807 total transactions, a 0.172% of all transactions. The credit card fraud dataset contains only numerical input variables with a total of 31 features. With respect to confidentiality and privacy, 28 of the features - V1 to V28 are principal components obtained by using PCA. â€™Timeâ€™, â€™Amountâ€™, and â€™Classâ€™ are the only features not to be transformed with PCA. â€™Timeâ€™ contains the seconds elapsed between each transaction and the first transaction in the dataset. â€™Classâ€™ is the target variable which takes the value of 0 for cases of no fraud and 1 for cases of fraud. And â€™Amountâ€™ is the transaction amount. Given the class imbalance ratio of the credit fraud dataset, we processed the dataset by oversampling the minority class with random undersampling of the majority class, leading to a more balanced dataset. This involved duplicating examples in the minority class in order to reach an equal balance between the minority and majority class. We used Synthetic Minority Oversampling Technique (SMOTE)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">CBHK02</a>]</cite>. The dataset descriptions are summarized in TableÂ <a href="#S4.T13" title="Table 13 â€£ 4.1.1 Optimization Method â€£ 4.1 Generation â€£ 4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
<figure id="S4.T14" class="ltx_table">
<table id="S4.T14.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T14.2.1.1" class="ltx_tr">
<th id="S4.T14.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Synthesizer</th>
<th id="S4.T14.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Class Frauds (1)</th>
<th id="S4.T14.2.1.1.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t">Class No Frauds (0)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T14.2.2.1" class="ltx_tr">
<td id="S4.T14.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t">Original</td>
<td id="S4.T14.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t">33.33%</td>
<td id="S4.T14.2.2.1.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">66.67%</td>
</tr>
<tr id="S4.T14.2.3.2" class="ltx_tr">
<td id="S4.T14.2.3.2.1" class="ltx_td ltx_align_center">GaussianCopula</td>
<td id="S4.T14.2.3.2.2" class="ltx_td ltx_align_center">41.9%</td>
<td id="S4.T14.2.3.2.3" class="ltx_td ltx_nopad_r ltx_align_center">58.1%</td>
</tr>
<tr id="S4.T14.2.4.3" class="ltx_tr">
<td id="S4.T14.2.4.3.1" class="ltx_td ltx_align_center">CopulaGAN</td>
<td id="S4.T14.2.4.3.2" class="ltx_td ltx_align_center">74.76%</td>
<td id="S4.T14.2.4.3.3" class="ltx_td ltx_nopad_r ltx_align_center">25.24%</td>
</tr>
<tr id="S4.T14.2.5.4" class="ltx_tr">
<td id="S4.T14.2.5.4.1" class="ltx_td ltx_align_center">CTGAN</td>
<td id="S4.T14.2.5.4.2" class="ltx_td ltx_align_center">74.76%</td>
<td id="S4.T14.2.5.4.3" class="ltx_td ltx_nopad_r ltx_align_center">25.24%</td>
</tr>
<tr id="S4.T14.2.6.5" class="ltx_tr">
<td id="S4.T14.2.6.5.1" class="ltx_td ltx_align_center">TVAE</td>
<td id="S4.T14.2.6.5.2" class="ltx_td ltx_align_center">40.07%</td>
<td id="S4.T14.2.6.5.3" class="ltx_td ltx_nopad_r ltx_align_center">59.93%</td>
</tr>
<tr id="S4.T14.2.7.6" class="ltx_tr">
<td id="S4.T14.2.7.6.1" class="ltx_td ltx_align_center">EmpiricalCopula</td>
<td id="S4.T14.2.7.6.2" class="ltx_td ltx_align_center">33.81%</td>
<td id="S4.T14.2.7.6.3" class="ltx_td ltx_nopad_r ltx_align_center">66.19%</td>
</tr>
<tr id="S4.T14.2.8.7" class="ltx_tr">
<td id="S4.T14.2.8.7.1" class="ltx_td ltx_align_center">DS 0</td>
<td id="S4.T14.2.8.7.2" class="ltx_td ltx_align_center">0.173%</td>
<td id="S4.T14.2.8.7.3" class="ltx_td ltx_nopad_r ltx_align_center">99.83%</td>
</tr>
<tr id="S4.T14.2.9.8" class="ltx_tr">
<td id="S4.T14.2.9.8.1" class="ltx_td ltx_align_center">DS 0.1</td>
<td id="S4.T14.2.9.8.2" class="ltx_td ltx_align_center">45.47%</td>
<td id="S4.T14.2.9.8.3" class="ltx_td ltx_nopad_r ltx_align_center">54.53%</td>
</tr>
<tr id="S4.T14.2.10.9" class="ltx_tr">
<td id="S4.T14.2.10.9.1" class="ltx_td ltx_align_center ltx_border_b">SC-GOAT</td>
<td id="S4.T14.2.10.9.2" class="ltx_td ltx_align_center ltx_border_b">36.10%</td>
<td id="S4.T14.2.10.9.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b">63.90%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T14.3.1.1" class="ltx_text" style="font-size:90%;">Table 14</span>: </span><span id="S4.T14.4.2" class="ltx_text" style="font-size:90%;">Percentage class of synthetic datasets using each model.</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation:</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">To evaluate the synthetic data generated, various benchmarking approaches are available allowing flexibility in adapting the loss function to suit the specific objectives of synthetic data generation. In this paper, we will adopt a downstream approach to evaluate the generative models. We will use our generative models to generate synthetic data from the original dataset, train and test our datasets on fraud detection models, and evaluate this via the AUROC metric. This serves as a well-rounded metric to assess the modelsâ€™ overall performance. From this analysis, we can decide on the best synthetic data generative models, and select the best fraud detection models.</p>
</div>
<figure id="S4.F15" class="ltx_figure"><img src="/html/2401.00081/assets/x8.png" id="S4.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="355" height="240" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F15.2.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="S4.F15.3.2" class="ltx_text" style="font-size:90%;">Utility metrics for fraud detection classifiers. See text for details.</span></figcaption>
</figure>
<figure id="S4.T16" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T16.4.2.1" class="ltx_text" style="font-size:90%;">Table 16</span>: </span><span id="S4.T16.2.1" class="ltx_text" style="font-size:90%;">Average, standard deviation, and one-sided paired t-test for the downstream test AUC score, using XGBoost fitted on the generated data by each method on <math id="S4.T16.2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T16.2.1.m1.1b"><mn id="S4.T16.2.1.m1.1.1" xref="S4.T16.2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T16.2.1.m1.1c"><cn type="integer" id="S4.T16.2.1.m1.1.1.cmml" xref="S4.T16.2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T16.2.1.m1.1d">10</annotation></semantics></math> experimentsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx91" title="" class="ltx_ref">HNSOP23</a>]</cite>.</span></figcaption>
<table id="S4.T16.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T16.5.1.1" class="ltx_tr">
<td id="S4.T16.5.1.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S4.T16.5.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Untuned</th>
<th id="S4.T16.5.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Tuned</th>
</tr>
<tr id="S4.T16.5.2.2" class="ltx_tr">
<th id="S4.T16.5.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Method</th>
<th id="S4.T16.5.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">average</th>
<th id="S4.T16.5.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column">std</th>
<th id="S4.T16.5.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column">test statistic</th>
<th id="S4.T16.5.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column">p-value</th>
<th id="S4.T16.5.2.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column">average</th>
<th id="S4.T16.5.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column">std</th>
<th id="S4.T16.5.2.2.8" class="ltx_td ltx_align_left ltx_th ltx_th_column">test statistic</th>
<th id="S4.T16.5.2.2.9" class="ltx_td ltx_align_left ltx_th ltx_th_column">p-value</th>
</tr>
<tr id="S4.T16.5.3.3" class="ltx_tr">
<td id="S4.T16.5.3.3.1" class="ltx_td ltx_align_left ltx_border_t">Gaussian Copula</td>
<td id="S4.T16.5.3.3.2" class="ltx_td ltx_align_left ltx_border_t">94.45%</td>
<td id="S4.T16.5.3.3.3" class="ltx_td ltx_align_left ltx_border_t">0.01</td>
<td id="S4.T16.5.3.3.4" class="ltx_td ltx_align_left ltx_border_t">14.10</td>
<td id="S4.T16.5.3.3.5" class="ltx_td ltx_align_left ltx_border_t">0</td>
<td id="S4.T16.5.3.3.6" class="ltx_td ltx_align_left ltx_border_t">94.45%</td>
<td id="S4.T16.5.3.3.7" class="ltx_td ltx_align_left ltx_border_t">0.01</td>
<td id="S4.T16.5.3.3.8" class="ltx_td ltx_align_left ltx_border_t">14.31</td>
<td id="S4.T16.5.3.3.9" class="ltx_td ltx_align_left ltx_border_t">0</td>
</tr>
<tr id="S4.T16.5.4.4" class="ltx_tr">
<td id="S4.T16.5.4.4.1" class="ltx_td ltx_align_left">CTGAN</td>
<td id="S4.T16.5.4.4.2" class="ltx_td ltx_align_left">95.34%</td>
<td id="S4.T16.5.4.4.3" class="ltx_td ltx_align_left">0.01</td>
<td id="S4.T16.5.4.4.4" class="ltx_td ltx_align_left">16.21</td>
<td id="S4.T16.5.4.4.5" class="ltx_td ltx_align_left">0</td>
<td id="S4.T16.5.4.4.6" class="ltx_td ltx_align_left">95.93%</td>
<td id="S4.T16.5.4.4.7" class="ltx_td ltx_align_left">0.01</td>
<td id="S4.T16.5.4.4.8" class="ltx_td ltx_align_left">13.15</td>
<td id="S4.T16.5.4.4.9" class="ltx_td ltx_align_left">0</td>
</tr>
<tr id="S4.T16.5.5.5" class="ltx_tr">
<td id="S4.T16.5.5.5.1" class="ltx_td ltx_align_left">CopulaGAN</td>
<td id="S4.T16.5.5.5.2" class="ltx_td ltx_align_left">95.50%</td>
<td id="S4.T16.5.5.5.3" class="ltx_td ltx_align_left">0.01</td>
<td id="S4.T16.5.5.5.4" class="ltx_td ltx_align_left">14.18</td>
<td id="S4.T16.5.5.5.5" class="ltx_td ltx_align_left">0</td>
<td id="S4.T16.5.5.5.6" class="ltx_td ltx_align_left">96.41%</td>
<td id="S4.T16.5.5.5.7" class="ltx_td ltx_align_left">0.01</td>
<td id="S4.T16.5.5.5.8" class="ltx_td ltx_align_left">7.80</td>
<td id="S4.T16.5.5.5.9" class="ltx_td ltx_align_left">0</td>
</tr>
<tr id="S4.T16.5.6.6" class="ltx_tr">
<td id="S4.T16.5.6.6.1" class="ltx_td ltx_align_left">TVAE</td>
<td id="S4.T16.5.6.6.2" class="ltx_td ltx_align_left">98.52%</td>
<td id="S4.T16.5.6.6.3" class="ltx_td ltx_align_left">0.00</td>
<td id="S4.T16.5.6.6.4" class="ltx_td ltx_align_left">0.00</td>
<td id="S4.T16.5.6.6.5" class="ltx_td ltx_align_left">0.5</td>
<td id="S4.T16.5.6.6.6" class="ltx_td ltx_align_left">98.48%</td>
<td id="S4.T16.5.6.6.7" class="ltx_td ltx_align_left">0.00</td>
<td id="S4.T16.5.6.6.8" class="ltx_td ltx_align_left">0.00</td>
<td id="S4.T16.5.6.6.9" class="ltx_td ltx_align_left">0.5</td>
</tr>
<tr id="S4.T16.5.7.7" class="ltx_tr">
<td id="S4.T16.5.7.7.1" class="ltx_td ltx_align_left ltx_border_bb">SC-GOAT</td>
<td id="S4.T16.5.7.7.2" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S4.T16.5.7.7.2.1" class="ltx_text ltx_font_bold">98.52</span>%</td>
<td id="S4.T16.5.7.7.3" class="ltx_td ltx_align_left ltx_border_bb">0.00</td>
<td id="S4.T16.5.7.7.4" class="ltx_td ltx_align_left ltx_border_bb">-</td>
<td id="S4.T16.5.7.7.5" class="ltx_td ltx_align_left ltx_border_bb">-</td>
<td id="S4.T16.5.7.7.6" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S4.T16.5.7.7.6.1" class="ltx_text ltx_font_bold">98.48</span>%</td>
<td id="S4.T16.5.7.7.7" class="ltx_td ltx_align_left ltx_border_bb">0.00</td>
<td id="S4.T16.5.7.7.8" class="ltx_td ltx_align_left ltx_border_bb">-</td>
<td id="S4.T16.5.7.7.9" class="ltx_td ltx_align_left ltx_border_bb">-</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p2.1" class="ltx_p">TableÂ <a href="#S4.T14" title="Table 14 â€£ Data: â€£ 4.2 Application: Credit Card Fraud â€£ 4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> reports the level of balance of various synthetic datasets generated from different approaches without conditional sampling for one experiment. The datasets generated by CTGAN and CopulaGAN synthesize a more imbalanced dataset that is dissimilar from the original dataset. The other approaches, TVAE, GaussianCopula and EmpiricalCopula synthesize datasets that are more similar to the original dataset in terms of class balance. FigureÂ <a href="#S4.F15" title="Figure 15 â€£ Evaluation: â€£ 4.2 Application: Credit Card Fraud â€£ 4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> shows a comparison among the performance of the original data and the synthetic data. This chart shows the AUROC results of different models for the data generated with different approaches. The original dataset performs the best for GAM and decision tree models. CTGAN and TVAE, which happen to be neural-network based generative models, improve the results for XGBoost. Therefore, in the fraud detection scenario, when training data synthesized by neural network approaches, XGBoost performs better at distinguishing between fraudulent and non-fraudulent cases.</p>
</div>
<div id="S4.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p3.1" class="ltx_p">Given the positive results of using the XGBoost model, another experiment was performed solely by training
an XGBoost classifierÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">CG16</a>]</cite> on the training data set and subsequently evaluating its performance on a separate validation data set. TableÂ <a href="#S4.T16" title="Table 16 â€£ Evaluation: â€£ 4.2 Application: Credit Card Fraud â€£ 4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a> shows the AUROC results between the various approaches. The results are reported based on 10 runs of the experiment with 70% of the real data used for training, 20% for validation, and the remaining 10% for testing. The SC-GOATÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx91" title="" class="ltx_ref">HNSOP23</a>]</cite> approach outperforms all other approaches by identifying the optimal mixture distribution of existing synthetic data generation methods.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Privacy</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">As previously discussed, privacy preservation of data in the financial domain is crucial in order to assure compliance with the relevant privacy regulations. A vast body of financial data is presented in tabular format, and thus privacy-preserving generation of synthetic tabular data is a particularly relevant topic in ML for finance.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Privacy considerations in the tabular setting typically assume that the data consists of a number of independent individuals represented by rows of the table, each of which is characterized by a number of attributes contained within the columns of the table. There are various angles of privacy concerns in this setting, and we review the most prominent ones. Often one requires protection of <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">sensitive attributes</span> represented by values within a subset of columnsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx180" title="" class="ltx_ref">SSW11</a>]</cite>. This is relevant not only in the context of publishing the original dataset, but also any output based on the original dataset input (in particular its synthetic data counterpart) that would enable learning of sensitive attributesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx139" title="" class="ltx_ref">NS07</a>]</cite>.
Another usual requirement is to protect global statistics of the datasets, such as quantiles or correlationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx121" title="" class="ltx_ref">LWSF23</a>]</cite>. Finally, most literature on privacy in tabular data quantifies it with respect to its ability to successfully perform MIA, i.e. correctly identify which individuals were present in the original datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx179" title="" class="ltx_ref">SSS16</a>]</cite>. As previously discussed, a de facto standard differential privacy represents a defense against MIA. In the remainder of this section, we review existing approaches for differentially private generation of tabular synthetic data.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">In the space of statistical-based methods for tabular data, differential privacy is typically achieved by employing perturbation with the use of e.g. the Laplace mechanismÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx122" title="" class="ltx_ref">LXJ14</a>, <a href="#bib.bibx7" title="" class="ltx_ref">ADR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>. Marginal-based methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx187" title="" class="ltx_ref">TMH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> rely on low order marginals in order to fit a graphical model, e.g. PrivBayesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx218" title="" class="ltx_ref">ZCP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite> and PrivSynÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx223" title="" class="ltx_ref">ZWL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite>.
Recent work in the area of private synthetic data generation mainly focused on deep generative models which utilize the DP-SGD framework in order to achieve privacyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">ACG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>16</a>]</cite>. Some
prominent examples of this line of work are DPGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx206" title="" class="ltx_ref">XLW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite>, PATEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx146" title="" class="ltx_ref">PAE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>, PATEGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx214" title="" class="ltx_ref">YJvdS19b</a>]</cite>, DPCTGAN and PATECTGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx164" title="" class="ltx_ref">RLP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>.
These approaches however lack interpretability which is of crucial importance in the finance domain. Some recent works that focus on interpretability rely on space partitioning techniques together with noise perturbation in order to achieve differentially-private synthetic dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx108" title="" class="ltx_ref">KNP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>.
We have also explored privacy in diffusion models for tabular dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx201" title="" class="ltx_ref">WKW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite></p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Privacy in Credit Card Fraud Use case</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Our goal is to demonstrate the trade-off between the extent of privacy protection (measured by the scale of noisy perturbation) and the utility of synthetic data in the context of a downstream task. We consider two algorithms that output DP synthetic data based on the original data input: the data-dependent algorithm fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx108" title="" class="ltx_ref">KNP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> which relies on space partitioning and noisy perturbation, and deep learning based DP-MERFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx87" title="" class="ltx_ref">HAP21</a>]</cite>.</p>
</div>
<section id="S4.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset:</h5>

<div id="S4.SS3.SSS1.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.Px1.p1.4" class="ltx_p">We use a credit card fraud dataset (see discussion above), and use all features except time. We use <math id="S4.SS3.SSS1.Px1.p1.1.m1.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S4.SS3.SSS1.Px1.p1.1.m1.1a"><mrow id="S4.SS3.SSS1.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS1.Px1.p1.1.m1.1.1.cmml"><mn id="S4.SS3.SSS1.Px1.p1.1.m1.1.1.2" xref="S4.SS3.SSS1.Px1.p1.1.m1.1.1.2.cmml">80</mn><mo id="S4.SS3.SSS1.Px1.p1.1.m1.1.1.1" xref="S4.SS3.SSS1.Px1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.Px1.p1.1.m1.1b"><apply id="S4.SS3.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS1.Px1.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS1.Px1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS1.Px1.p1.1.m1.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.Px1.p1.1.m1.1c">80\%</annotation></semantics></math> of input data for synthetic data generation, for various privacy budgets <math id="S4.SS3.SSS1.Px1.p1.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.SSS1.Px1.p1.2.m2.1a"><mi id="S4.SS3.SSS1.Px1.p1.2.m2.1.1" xref="S4.SS3.SSS1.Px1.p1.2.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.Px1.p1.2.m2.1b"><ci id="S4.SS3.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS1.Px1.p1.2.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.Px1.p1.2.m2.1c">\epsilon</annotation></semantics></math>. Synthetic data is then used to train <math id="S4.SS3.SSS1.Px1.p1.3.m3.1" class="ltx_Math" alttext="12" display="inline"><semantics id="S4.SS3.SSS1.Px1.p1.3.m3.1a"><mn id="S4.SS3.SSS1.Px1.p1.3.m3.1.1" xref="S4.SS3.SSS1.Px1.p1.3.m3.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.Px1.p1.3.m3.1b"><cn type="integer" id="S4.SS3.SSS1.Px1.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS1.Px1.p1.3.m3.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.Px1.p1.3.m3.1c">12</annotation></semantics></math> classifiers (seeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx108" title="" class="ltx_ref">KNP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> for a detailed setup), which are tested on the remaining <math id="S4.SS3.SSS1.Px1.p1.4.m4.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S4.SS3.SSS1.Px1.p1.4.m4.1a"><mrow id="S4.SS3.SSS1.Px1.p1.4.m4.1.1" xref="S4.SS3.SSS1.Px1.p1.4.m4.1.1.cmml"><mn id="S4.SS3.SSS1.Px1.p1.4.m4.1.1.2" xref="S4.SS3.SSS1.Px1.p1.4.m4.1.1.2.cmml">20</mn><mo id="S4.SS3.SSS1.Px1.p1.4.m4.1.1.1" xref="S4.SS3.SSS1.Px1.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.Px1.p1.4.m4.1b"><apply id="S4.SS3.SSS1.Px1.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS1.Px1.p1.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS3.SSS1.Px1.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS3.SSS1.Px1.p1.4.m4.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.Px1.p1.4.m4.1c">20\%</annotation></semantics></math> of the original input data.</p>
</div>
</section>
<section id="S4.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation:</h5>

<div id="S4.SS3.SSS1.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS1.Px2.p1.1" class="ltx_p">We present degradation of average ROC (area under the receiver operating curve) over <math id="S4.SS3.SSS1.Px2.p1.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS3.SSS1.Px2.p1.1.m1.1a"><mn id="S4.SS3.SSS1.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS1.Px2.p1.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.Px2.p1.1.m1.1b"><cn type="integer" id="S4.SS3.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS1.Px2.p1.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.Px2.p1.1.m1.1c">20</annotation></semantics></math> repetitions. The algorithm introduced inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx108" title="" class="ltx_ref">KNP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> does not outperform DP-MERF in terms of ROC values. This is not surprising as it does not rely on deep generative models. However, their performance degrades slower as privacy increases compared to the DP-MERF (FigureÂ <a href="#S4.F17" title="Figure 17 â€£ Evaluation: â€£ 4.3.1 Privacy in Credit Card Fraud Use case â€£ 4.3 Privacy â€£ 4 Tabular Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>).</p>
</div>
<figure id="S4.F17" class="ltx_figure"><img src="/html/2401.00081/assets/x9.png" id="S4.F17.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="276" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F17.6.3.1" class="ltx_text" style="font-size:90%;">Figure 17</span>: </span><span id="S4.F17.4.2" class="ltx_text" style="font-size:90%;">Comparison of the data- algorithm ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx108" title="" class="ltx_ref">KNP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> and DP-MERFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx87" title="" class="ltx_ref">HAP21</a>]</cite> on a downstream classification task. ROC degradation is represented as a ratio of the ROC corresponding to a specified <math id="S4.F17.3.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.F17.3.1.m1.1b"><mi id="S4.F17.3.1.m1.1.1" xref="S4.F17.3.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S4.F17.3.1.m1.1c"><ci id="S4.F17.3.1.m1.1.1.cmml" xref="S4.F17.3.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F17.3.1.m1.1d">\epsilon</annotation></semantics></math> budget and the ROC for <math id="S4.F17.4.2.m2.1" class="ltx_Math" alttext="\epsilon=10" display="inline"><semantics id="S4.F17.4.2.m2.1b"><mrow id="S4.F17.4.2.m2.1.1" xref="S4.F17.4.2.m2.1.1.cmml"><mi id="S4.F17.4.2.m2.1.1.2" xref="S4.F17.4.2.m2.1.1.2.cmml">Ïµ</mi><mo id="S4.F17.4.2.m2.1.1.1" xref="S4.F17.4.2.m2.1.1.1.cmml">=</mo><mn id="S4.F17.4.2.m2.1.1.3" xref="S4.F17.4.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F17.4.2.m2.1c"><apply id="S4.F17.4.2.m2.1.1.cmml" xref="S4.F17.4.2.m2.1.1"><eq id="S4.F17.4.2.m2.1.1.1.cmml" xref="S4.F17.4.2.m2.1.1.1"></eq><ci id="S4.F17.4.2.m2.1.1.2.cmml" xref="S4.F17.4.2.m2.1.1.2">italic-Ïµ</ci><cn type="integer" id="S4.F17.4.2.m2.1.1.3.cmml" xref="S4.F17.4.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F17.4.2.m2.1d">\epsilon=10</annotation></semantics></math>. </span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Fairness</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">As synthetic data generation is a powerful tool to both augment and correct automatic decision-making tools, more recent developments have explored and analysed the biases inherited in synthetic data and their downstream effects. This is particularly relevant to commercial banking, where machine learning algorithms are directly used for tasks such as auto loans or credit card applications decisions. Most of recent work revolves around diagnosing and improving generative modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx210" title="" class="ltx_ref">XYZW18</a>, <a href="#bib.bibx175" title="" class="ltx_ref">SHCV19</a>, <a href="#bib.bibx209" title="" class="ltx_ref">XWY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>, <a href="#bib.bibx211" title="" class="ltx_ref">XYZW19</a>, <a href="#bib.bibx191" title="" class="ltx_ref">vBKBvdS21</a>, <a href="#bib.bibx119" title="" class="ltx_ref">LRD22</a>]</cite>, while other approaches tackle the problem from a transfer learningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx182" title="" class="ltx_ref">TAC23</a>]</cite> or optimizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx204" title="" class="ltx_ref">XDP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> perspective. We refer the reader toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx133" title="" class="ltx_ref">MMS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite> for a high-level overview.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Robustness</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Recent years saw the surge of interest in utilizing synthetic data in order to improve model robustness.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx43" title="" class="ltx_ref">CRS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite> show that training a classifier with additional unlabelled data from the same distribution improves adversarial robustness, i.e. robustness against adversarial attacks that are launched by manipulating features of the test instances.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx58" title="" class="ltx_ref">DZGZ21</a>]</cite> explore how data from a different domain/distribution affects adversarial robustness in the original domain.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx178" title="" class="ltx_ref">SMH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> investigate how adversarial robustness of a classifier trained on synthetic data from a proxy distribution translates to the robustness on the real data. In comparison to data arising from a related domain/proxy distribution, the advantage of relying on a synthetic data generator trained on real data is that control over the distance between real and synthetic distribution often comes for free as a consequence of theoretical guarantees on the fidelity of the chosen generatorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx83" title="" class="ltx_ref">GPAM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>14a</a>, <a href="#bib.bibx2" title="" class="ltx_ref">ACB17</a>, <a href="#bib.bibx111" title="" class="ltx_ref">LCC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">We have reviewed various aspects of synthetic tabular data and there are many open questions. Some of them include: can we generate high quality synthetic data which match the performance of real datasets, differentially private explanations for customer decisions as opposed to utilizing real data, distinguishing synthetic data from real data. We continue our discussion on tabular data with event series which has an additional temporal component that needs to be taken into account.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Event series data</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">Event series data record sequences of events, including associated time and related features. In general, a sequence of event series data is composed of multiple events of different types, in which the occurrence of any event at time <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">t</annotation></semantics></math> might depend on the history (i.e., the sequence of past events) up to time <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.p1.2.m2.1a"><mi id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><ci id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">t</annotation></semantics></math>. Unlike time series data, in which a continuously occurring phenomenon is sampled at different resolutions, time interval between two events is usually not predetermined, so event series data are asynchronous. Event series data are ubiquitous in many financial domains. In commercial banking, â€œcustomer journeysâ€ log the interactions of customers with the bank. In trading, limit order books record buy or sell orders on a security at a specific price or better. In marketing applications, customer impressions record when a specific ad was served to the customer and whether the customer eventually purchased the advertised product. Outside of financial applications, infectious diseases patternsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx37" title="" class="ltx_ref">CLM22</a>]</cite>, earthquake logsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx143" title="" class="ltx_ref">Oga98</a>]</cite>, social media interactionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx163" title="" class="ltx_ref">RLMX17</a>]</cite>, and crime modelingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx160" title="" class="ltx_ref">RG18</a>]</cite> are among other examples of event series data. Graphs are typically used to model the rich interaction structures between entities such as customersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx116" title="" class="ltx_ref">LLS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> but this makes the generation process much more involved. Diffusion models have been recently explored for the generation of these large-scale graphsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx115" title="" class="ltx_ref">LKPL23</a>]</cite>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.2" class="ltx_p">The literature on modeling sequential data encompasses a broad spectrum of techniques. Traditional approaches include Hidden Markov ModelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">BP66</a>, <a href="#bib.bibx162" title="" class="ltx_ref">RJ86</a>]</cite>, Kalman filtersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx101" title="" class="ltx_ref">Kal60</a>, <a href="#bib.bibx198" title="" class="ltx_ref">WB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>95</a>]</cite>, dynamic Bayesian networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx78" title="" class="ltx_ref">Gha97</a>]</cite> and sequential mining patterns algorithmsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx130" title="" class="ltx_ref">ME10</a>, <a href="#bib.bibx74" title="" class="ltx_ref">FVLK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>. More recently, deep learning approaches such as recurrent neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx92" title="" class="ltx_ref">HS97</a>, <a href="#bib.bibx215" title="" class="ltx_ref">YSHZ19</a>]</cite>, deep autoregressive modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx140" title="" class="ltx_ref">ODZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>16</a>, <a href="#bib.bibx194" title="" class="ltx_ref">VdOKE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>16</a>]</cite> and transformer-based architecturesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx196" title="" class="ltx_ref">VSP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>, <a href="#bib.bibx120" title="" class="ltx_ref">LWLQ22</a>]</cite> have proven highly effective in sequential data prediction. Within this diverse landscape of sequential data models, a powerful set of tools to model the occurrence of events in event series data are temporal point processesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">CI80</a>, <a href="#bib.bibx56" title="" class="ltx_ref">DVJ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>03</a>]</cite>. Temporal point processes model the probability of occurrence of an event of a given type at any time <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">t</annotation></semantics></math> (possibly as a function of the history up to time t). Hawkes processes (self-exciting point processes) are a common class of temporal point processesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx88" title="" class="ltx_ref">Haw71</a>, <a href="#bib.bibx96" title="" class="ltx_ref">IW79</a>, <a href="#bib.bibx159" title="" class="ltx_ref">Rei18</a>]</cite> that model sequential event series in which the occurrence of an event may increase the probability of occurrence of future events. Temporal point processes are particularly useful as, once trained, one can directly generate synthetic event series data with the same dynamics of the training data; one of the most popular algorithms is the thinning algorithmÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx142" title="" class="ltx_ref">Oga81</a>]</cite>, (seeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx57" title="" class="ltx_ref">DZ13</a>]</cite> andÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx205" title="" class="ltx_ref">XFY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite> for more recent simulation-based approaches). Recent works have focused on improving the Hawkes model capacity by estimating the event dynamics more flexibly beyond self-excitation or for different data typesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx123" title="" class="ltx_ref">LXZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>15</a>, <a href="#bib.bibx221" title="" class="ltx_ref">ZLKY19</a>, <a href="#bib.bibx220" title="" class="ltx_ref">ZJL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>, <a href="#bib.bibx150" title="" class="ltx_ref">PH22</a>, <a href="#bib.bibx76" title="" class="ltx_ref">GDL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a href="#bib.bibx219" title="" class="ltx_ref">ZDG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>, while other approaches have focused on the privacy properties of Hawkes processesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx79" title="" class="ltx_ref">GKD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a href="#bib.bibx222" title="" class="ltx_ref">ZLZZ22</a>]</cite>. Additionally, point processes have been extended to incorporate a stochastic process as intensity function (Cox processesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">Cox55</a>]</cite>) or to assume a probability distribution which can be expressed as a functional determinant (determinantal point processesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx127" title="" class="ltx_ref">Mac75</a>]</cite>).
Finally, goodness-of-fit evaluation is usually conducted by looking at the integral of the estimated intensity between out-of-sample events, which is known to follow an exponential distribution with rate <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.p2.2.m2.1a"><mn id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><cn type="integer" id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">1</annotation></semantics></math> under the ground truth intensityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx56" title="" class="ltx_ref">DVJ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>03</a>]</cite>. Other goodness-of-fit approaches include the difference between the empirical and estimated intensityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx205" title="" class="ltx_ref">XFY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite> as well as non-parametric two sample testsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx203" title="" class="ltx_ref">WZZX21</a>]</cite>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Using Automated Planning</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">A way of generating synthetic event series data assumes there is a model of the underlying environment and perform a simulation using the model on different scenarios. The different events that appear in the simulation are converted into data points of the output dataset. An example of such techniqueÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">BV20</a>, <a href="#bib.bibx23" title="" class="ltx_ref">BVS20</a>]</cite> uses classical automated planningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx81" title="" class="ltx_ref">GNT04</a>]</cite>. The assumption is that most data that financial institutions keep on clients, come from clientâ€™s interaction with the bank. Each interaction can be seen as an action that the client executes and that is observable by the bank. Examples are opening accounts, making wire transfers, or withdrawing money from ATMs. At each time step, a clients state can be described in terms of some facts, such as the accounts they opened, the balance on their accounts, or their regular payments (e.g. monthly rent, yearly taxes, utility bills). Also, at each time step, clients have short-term financial goals, such as paying the rent, buying a product, or receiving the payroll from their employer. Given that we can define clientsâ€™ interactions in terms of actions, states and goals, we can use an automated planning framework to randomly generate goals for clients, generate plans that achieve those goals from the current state of clients, and execute the actions in those plans. Each action execution leaves a trace that can be logged into a record of a dataset that defines that interaction. Data generated using this method has been used in several papers for purposes ranging from reasoning on entanglementsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx129" title="" class="ltx_ref">MCV<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> to goal recognitionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx66" title="" class="ltx_ref">EVY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>. In particular, this approach generated datasets that described money laundering activities, fraudulent transactions, or customer journeysÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">BV20</a>]</cite>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">FigureÂ <a href="#S5.F18" title="Figure 18 â€£ 5.1 Using Automated Planning â€£ 5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a> shows an excerpt of a customer journey dataset generated from a simulated trace using planning. Events are usually described by a date-time tag, a label for the executed event, and a client id. The event description includes the channel used by the client, mobile in this case and the corresponding action.</p>
</div>
<figure id="S5.F18" class="ltx_figure">
<table id="S5.F18.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.F18.2.1.1" class="ltx_tr">
<th id="S5.F18.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Date and time</th>
<th id="S5.F18.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Event</th>
<th id="S5.F18.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Customer ID</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.F18.2.2.1" class="ltx_tr">
<td id="S5.F18.2.2.1.1" class="ltx_td ltx_align_left ltx_border_t">2021-05-24 21:22:14</td>
<td id="S5.F18.2.2.1.2" class="ltx_td ltx_align_left ltx_border_t">mobile : logon</td>
<td id="S5.F18.2.2.1.3" class="ltx_td ltx_align_left ltx_border_t">ID-22522</td>
</tr>
<tr id="S5.F18.2.3.2" class="ltx_tr">
<td id="S5.F18.2.3.2.1" class="ltx_td ltx_align_left">2021-05-24 21:25:14</td>
<td id="S5.F18.2.3.2.2" class="ltx_td ltx_align_left">mobile : transaction summary business</td>
<td id="S5.F18.2.3.2.3" class="ltx_td ltx_align_left">ID-22522</td>
</tr>
<tr id="S5.F18.2.4.3" class="ltx_tr">
<td id="S5.F18.2.4.3.1" class="ltx_td ltx_align_left">2021-05-24 21:26:14</td>
<td id="S5.F18.2.4.3.2" class="ltx_td ltx_align_left">mobile : transaction history prepaid account</td>
<td id="S5.F18.2.4.3.3" class="ltx_td ltx_align_left">ID-22522</td>
</tr>
<tr id="S5.F18.2.5.4" class="ltx_tr">
<td id="S5.F18.2.5.4.1" class="ltx_td ltx_align_left">2021-05-24 21:28:14</td>
<td id="S5.F18.2.5.4.2" class="ltx_td ltx_align_left">mobile : ultimate rewards info</td>
<td id="S5.F18.2.5.4.3" class="ltx_td ltx_align_left">ID-22522</td>
</tr>
<tr id="S5.F18.2.6.5" class="ltx_tr">
<td id="S5.F18.2.6.5.1" class="ltx_td ltx_align_left">2021-05-24 21:31:14</td>
<td id="S5.F18.2.6.5.2" class="ltx_td ltx_align_left">mobile : ultimate rewards activity</td>
<td id="S5.F18.2.6.5.3" class="ltx_td ltx_align_left">ID-22522</td>
</tr>
<tr id="S5.F18.2.7.6" class="ltx_tr">
<td id="S5.F18.2.7.6.1" class="ltx_td ltx_align_left ltx_border_b">2021-05-24 21:36:14</td>
<td id="S5.F18.2.7.6.2" class="ltx_td ltx_align_left ltx_border_b">mobile : logoff</td>
<td id="S5.F18.2.7.6.3" class="ltx_td ltx_align_left ltx_border_b">ID-22522</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F18.3.1.1" class="ltx_text" style="font-size:90%;">Figure 18</span>: </span><span id="S5.F18.4.2" class="ltx_text" style="font-size:90%;">Small section of a generated trace of events using AI planning.</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Application: Marketing spending insight via synthetic customer journeys</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In this section, we show how data augmentation with synthetic customer journeys can help downstream tasks related to marketing campaigns. In marketing, customer journeys are composed of the customer interactions with different advertising channels, such as search, social media or television ads. Post mortem spending insight is usually conducted by identifying the importance of different channels in terms of customer conversions, i.e., in terms of the number of customers who purchased the advertised product after seeing the ad. Multi-Touch Attribution (MTA) models measure this importance by assigning credit to each channel to drive future budget allocation. Unlike more traditional approaches, where all the credit was assigned to the last customer touch point, MTA models take into account the entirety of the customer journeys; seeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx216" title="" class="ltx_ref">YSS15</a>, <a href="#bib.bibx6" title="" class="ltx_ref">ADR17</a>, <a href="#bib.bibx8" title="" class="ltx_ref">ADY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite> for examples of MTA models. Temporal point processes can be used to learn the customer journey dynamics, enrich the available training data, and improve the downstream MTA model insights.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.2" class="ltx_p">To showcase the usefulness of synthetic event series data, we use a public MTA dataset<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Data available on the Kaggle platform at <a target="_blank" href="https://www.kaggle.com/code/hughhuyton/multitouch-attribution-modelling/notebook" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/code/hughhuyton/multitouch-attribution-modelling/notebook</a></span></span></span>. The data cover a month-long campaign with the ads channels available in the data being Facebook, Instagram, Paid Search, Online display and Paid Search. We extract <math id="S5.SS2.p2.1.m1.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="S5.SS2.p2.1.m1.2a"><mrow id="S5.SS2.p2.1.m1.2.3.2" xref="S5.SS2.p2.1.m1.2.3.1.cmml"><mn id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">10</mn><mo id="S5.SS2.p2.1.m1.2.3.2.1" xref="S5.SS2.p2.1.m1.2.3.1.cmml">,</mo><mn id="S5.SS2.p2.1.m1.2.2" xref="S5.SS2.p2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.2b"><list id="S5.SS2.p2.1.m1.2.3.1.cmml" xref="S5.SS2.p2.1.m1.2.3.2"><cn type="integer" id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">10</cn><cn type="integer" id="S5.SS2.p2.1.m1.2.2.cmml" xref="S5.SS2.p2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.2c">10,000</annotation></semantics></math> customer journeys with a <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="\sim 7\%" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml"></mi><mo id="S5.SS2.p2.2.m2.1.1.1" xref="S5.SS2.p2.2.m2.1.1.1.cmml">âˆ¼</mo><mrow id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml"><mn id="S5.SS2.p2.2.m2.1.1.3.2" xref="S5.SS2.p2.2.m2.1.1.3.2.cmml">7</mn><mo id="S5.SS2.p2.2.m2.1.1.3.1" xref="S5.SS2.p2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">absent</csymbol><apply id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3"><csymbol cd="latexml" id="S5.SS2.p2.2.m2.1.1.3.1.cmml" xref="S5.SS2.p2.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS2.p2.2.m2.1.1.3.2.cmml" xref="S5.SS2.p2.2.m2.1.1.3.2">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">\sim 7\%</annotation></semantics></math> conversion rate from the campaign, and use a Markov chain MTA modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx104" title="" class="ltx_ref">KBRF18</a>]</cite>. We train an XGBoostÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">CG16</a>]</cite> model trained on features extracted from customer journeys data to predict the customer conversion. An improvement in prediction performance would indicate that synthetic event series data do indeed capture the dynamics within the real data. We use a mixture of 4 Hawkes processes for augmentation, conducting a separate hyper-parameter optimization across the number of mixtures and the decay parameters. FigureÂ <a href="#S5.F19" title="Figure 19 â€£ 5.2 Application: Marketing spending insight via synthetic customer journeys â€£ 5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a> (left) reports the XGBoost model AUC as a function of the percentage of data augmentation used in training (shaded bands indicate one standard deviation computed over 10 runs). We see that the addition of synthetic customer journeys improves the classifier performance, although the increase saturates after 50% augmentation. FigureÂ <a href="#S5.F19" title="Figure 19 â€£ 5.2 Application: Marketing spending insight via synthetic customer journeys â€£ 5 Event series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a> (right) shows the MTA credit assignments when using 50% of the synthetic customer journeys. The synthetic journeys do not radically change the credit assignment, but increase the importance of online video advertisement, which gains credit and ranking.</p>
</div>
<figure id="S5.F19" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/x10.png" id="S5.F19.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="262" height="143" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/x11.png" id="S5.F19.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="193" height="145" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F19.2.1.1" class="ltx_text" style="font-size:90%;">Figure 19</span>: </span><span id="S5.F19.3.2" class="ltx_text" style="font-size:90%;">Data augmentation with synthetic event series data (left) and change in MTA credit assignments when using a combination of both real and synthetic data (right).</span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Time series data</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Synthetic time series (TS) data refers to artificially generated time series data that emulate the statistical properties and patterns observed in the real world. Synthetic time series are useful when only limited number of historical observations are available. They are also needed to simulate specific scenarios (for instance, market crashes). Such data finds utility in the finance domain in multiple ways, including back-testing investment strategies, evaluating trading algorithm performance for robustness, and simulating market stress scenarios for risk management. Additionally, synthetic time series data can be combined with historically observed data to make model training datasets larger as well as to enhance the representation of minority classes in imbalanced datasets â€“ both of which typically lead to better generalization capabilities of machine learning models.
</p>
</div>
<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Approaches to synthetic time-series</h5>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">We can divide the existing methods for synthetic time-series generation and simulation in three major classesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx82" title="" class="ltx_ref">Goo16</a>]</cite>:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Parametric models</span> assume a specific parametric form for the underlying distribution of the data, and they have a fixed number of parameters that are usually estimated from the training data. Once their parameters are estimated, we can generate synthetic samples by sampling directly from the learned distribution. A Gaussian distribution is an example of parametric model, where the mean and variance are the parameters. For time series data, suitable models include probabilistic variants of vector autoregressionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx138" title="" class="ltx_ref">New83</a>]</cite>, or state-space models. In terms of financial time series, stochastic differential equations (SDEs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx148" title="" class="ltx_ref">PEK21</a>, <a href="#bib.bibx97" title="" class="ltx_ref">JB19</a>]</cite> are among the most popular class of models due to their ability to explicitly model time series data as a continuous time stochastic process with an underlying drift (i.e., trend) and diffusion (i.e., noise). Common SDEs employed to model price time series include geometric Brownian motion and the Ornsteinâ€“Uhlenbeck (OU)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx132" title="" class="ltx_ref">MMS09</a>]</cite> process, where the OU process captures the mean-reversion property
typically observed in financial time seriesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">BBDG18</a>]</cite>.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Non-Parametric models</span> do not take any parametric assumptions, i.e., they do not make strong assumptions about the form of the underlying distribution. Instead, these models aim at estimating the data distribution directly from the training samples, often without specifying a set of fixed parameters. Example of non-parametric models are GANsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx82" title="" class="ltx_ref">Goo16</a>]</cite> and VAEsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx53" title="" class="ltx_ref">Doe16</a>]</cite>. Among non-parametric models we can distinguish between: <span id="S6.I1.i2.p1.1.2" class="ltx_text ltx_font_bold">implicit models</span> which do not need to make any assumption on the density function form, but they rather train and sample directly the samples (e.g., GANs); and <span id="S6.I1.i2.p1.1.3" class="ltx_text ltx_font_bold">explicit models</span> which make an explicit assumption on the form of density function from which they sample the synthetic samples (e.g,. VAEs). A recent work using an implicit model is shown in SectionÂ <a href="#S6.SS2" title="6.2 Simulation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>, where a conditional generative network (cGAN) is used to generated synthetic order booksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx39" title="" class="ltx_ref">CMVB22</a>]</cite>.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Agent-based models</span> provide a natural bottom-up approach to model the underlying system dynamics (e.g., traders) and to simulate and generate synthetic markets. Agent-based models have been widely used in the economic literature to replicate complex processes, and perform â€what-ifâ€ studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx112" title="" class="ltx_ref">LeB06</a>]</cite>. In SectionÂ <a href="#S6.SS2" title="6.2 Simulation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a> we discuss ABIDESÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">BHB19</a>]</cite> a state-of-art Multi-Agent Simulator for high-fidelity market data.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S6.SS0.SSS0.Px2.1.1" class="ltx_text ltx_font_bold">Metrics</span>:</h5>

<div id="S6.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p1.1" class="ltx_p">Fidelity and utility metrics described in SectionÂ <a href="#S2.SS2" title="2.2 Metrics â€£ 2 Background and Related Work" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> are widely used for assessing the quality of generic (i.e., not necessarily financial) synthetic time series data. Properties of financial time series that are repeated across a wide range of instruments, venues, and time periods are referred to as stylized factsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx192" title="" class="ltx_ref">VBP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>. For instance, it is a well known fact that the distribution of daily stock price returns shows fat tails and that distribution is time-invariant. Evaluating the stylized facts of generated financial time series such as distributions of asset returns, order volumes, order arrival times, order cancellations, etc., and comparing them to those derived from real historical data allows us to infer the level of fidelity of a time series generation process.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S6.SS0.SSS0.Px3.1.1" class="ltx_text ltx_font_bold">Related Work</span>:</h5>

<div id="S6.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p1.1" class="ltx_p">Realistic time series generation has been previously studied in the literature by using the generative adversarial networks (GANs). In the TimeGAN architectureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx213" title="" class="ltx_ref">YJvdS19a</a>]</cite>, realistic generation of temporal patterns was achieved by jointly optimizing with both supervised and adversarial objectives to learn an embedding space. QuantGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx200" title="" class="ltx_ref">WKKK20</a>]</cite> consists of a generator and discriminator functions represented by temporal convolutional networks, which allows it to synthesize long-range dependencies such as the presence of volatility clusters that are characteristic of financial time series. TimeVAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx49" title="" class="ltx_ref">DFWB21</a>]</cite> was recently proposed as a variational autoencoder alternative to GAN-based time-series generation. GANs and VAEs are typically used for creating statistical replicas of the training data, and not the distributionally new scenarios needed for data augmentation. Recently, neural SDEs have also been proposed for realistic time series generation. Neural SDEs assume that the time series data follow some underlying latent SDE, where the drift and diffusion of the SDE are modelled via a deep neural network.</p>
</div>
<div id="S6.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p2.1" class="ltx_p">Data augmentation is well established in computer vision tasks due to the simplicity of label-preserving geometric image transformation techniques, but it is still not widely used for time series with some early work being discussed in the literatureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx95" title="" class="ltx_ref">IU21</a>, <a href="#bib.bibx202" title="" class="ltx_ref">WSS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>. For example, simple augmentation techniques applied to financial price time series, such as adding noise or time warping, were shown to improve the quality of next day price prediction modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx69" title="" class="ltx_ref">FDZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>, <a href="#bib.bibx70" title="" class="ltx_ref">FDZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite>. However, such transformations were not required to produce realistic synthetic time series.
Furthermore, some augmentation methods might work in certain domain-specific time series, but not in others. For example, if noise is added to a sample, what scale of noise should be used? Given a certain dataset, what set of transformations would work best? Therefore, a major challenge in data augmentation is how to search over the space of possible transformations, which can be prohibitive given the large number of possible transformations and their associated hyperparameters. This issue motivated the investigation of several automated data augmentation algorithmsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx47" title="" class="ltx_ref">CZM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>. Previous methods perform the search by using proxy tasks with small models and training subsetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx114" title="" class="ltx_ref">LKK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>, <a href="#bib.bibx224" title="" class="ltx_ref">ZWZZ20</a>, <a href="#bib.bibx90" title="" class="ltx_ref">HLC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>, which might not give optimal results in the final task. More recently, RandAugmentÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">CZSL20</a>]</cite> proposes to sample augmentations uniformly with the same shared magnitude, where the number of augmentations and magnitude can be tuned with a grid search. A similar approach is proposed for time series inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx68" title="" class="ltx_ref">FDjZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite> where all possible augmentations are weighted with a learnable parameter, while inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx144" title="" class="ltx_ref">OMI22</a>]</cite> a neural network that dynamically selects the best combination of data augmentation methods is proposed, using a feature consistency loss.</p>
</div>
</section>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Generation</h3>

<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Application: Realistic Generation of Financial Time Series</h5>

<figure id="S6.F20" class="ltx_figure">
<p id="S6.F20.2.2" class="ltx_p ltx_minipage ltx_align_middle" style="width:433.6pt;"><span id="S6.F20.1.1.1" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2401.00081/assets/x12.png" id="S6.F20.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="124" height="53" alt="Refer to caption"></span>
Â Â Â Â Â Â Â 
<span id="S6.F20.2.2.2" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2401.00081/assets/x13.png" id="S6.F20.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="252" height="115" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F20.10.4.1" class="ltx_text" style="font-size:90%;">Figure 20</span>: </span><span id="S6.F20.8.3" class="ltx_text" style="font-size:90%;">Diagram of the implicit neural representation (INR) for univariate time series (left). Diagram of HyperTime (right) where each pair of time-coordinate <math id="S6.F20.6.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.F20.6.1.m1.1b"><mi id="S6.F20.6.1.m1.1.1" xref="S6.F20.6.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.F20.6.1.m1.1c"><ci id="S6.F20.6.1.m1.1.1.cmml" xref="S6.F20.6.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F20.6.1.m1.1d">t</annotation></semantics></math> and time series <math id="S6.F20.7.2.m2.1" class="ltx_Math" alttext="f(t)" display="inline"><semantics id="S6.F20.7.2.m2.1b"><mrow id="S6.F20.7.2.m2.1.2" xref="S6.F20.7.2.m2.1.2.cmml"><mi id="S6.F20.7.2.m2.1.2.2" xref="S6.F20.7.2.m2.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.F20.7.2.m2.1.2.1" xref="S6.F20.7.2.m2.1.2.1.cmml">â€‹</mo><mrow id="S6.F20.7.2.m2.1.2.3.2" xref="S6.F20.7.2.m2.1.2.cmml"><mo stretchy="false" id="S6.F20.7.2.m2.1.2.3.2.1" xref="S6.F20.7.2.m2.1.2.cmml">(</mo><mi id="S6.F20.7.2.m2.1.1" xref="S6.F20.7.2.m2.1.1.cmml">t</mi><mo stretchy="false" id="S6.F20.7.2.m2.1.2.3.2.2" xref="S6.F20.7.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.F20.7.2.m2.1c"><apply id="S6.F20.7.2.m2.1.2.cmml" xref="S6.F20.7.2.m2.1.2"><times id="S6.F20.7.2.m2.1.2.1.cmml" xref="S6.F20.7.2.m2.1.2.1"></times><ci id="S6.F20.7.2.m2.1.2.2.cmml" xref="S6.F20.7.2.m2.1.2.2">ğ‘“</ci><ci id="S6.F20.7.2.m2.1.1.cmml" xref="S6.F20.7.2.m2.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F20.7.2.m2.1d">f(t)</annotation></semantics></math> is encoded as an embedding <math id="S6.F20.8.3.m3.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S6.F20.8.3.m3.1b"><mi id="S6.F20.8.3.m3.1.1" xref="S6.F20.8.3.m3.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S6.F20.8.3.m3.1c"><ci id="S6.F20.8.3.m3.1.1.cmml" xref="S6.F20.8.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F20.8.3.m3.1d">Z</annotation></semantics></math> by the Set Encoder. The HyperNet decoder learns to predict INR weights from the embeddings.</span></figcaption>
</figure>
<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.1" class="ltx_p">Time series data often presents unique challenges due to its potentially irregular sampling or presence of missing values. These issues can significantly affect the performance of certain deep learning models, leading to inaccurate predictions or flawed insights. Given the crucial role time series data plays across various scientific and economic domains, researchers have focused on the development and deployment of robust deep learning models capable of accommodating these inconsistencies. In recent years, Implicit Neural Representations (INRs) have gained popularity as an accurate and flexible method to parameterize signals from diverse sources, including images, videos, audio, and 3D scenesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx166" title="" class="ltx_ref">RSGZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>, <a href="#bib.bibx38" title="" class="ltx_ref">CLW21</a>, <a href="#bib.bibx177" title="" class="ltx_ref">SMB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>. Traditional methods primarily use discrete representations like data grids that often grapple with limited spatial resolution and inherent discretization issues. Instead, INRs encode data in terms of continuous functional relationships. Thus, they are are resolution-independent, offering a novel framework for data representation. Furthermore, modifications to INRs, such as SIRENâ€™s periodic activationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx177" title="" class="ltx_ref">SMB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite> and NeRFsâ€™ positional encodingsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx135" title="" class="ltx_ref">MST<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>, have successfully mitigated the spectral bias commonly faced by traditional neural networks. Therefore, the resolution free nature of INRs, in combination with their capacity for accurate spectral reconstruction makes them particularly useful in time series applications, where data irregularities and missing values are prevalent.</p>
</div>
<div id="S6.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p2.1" class="ltx_p">In particular,Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx73" title="" class="ltx_ref">FSEL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> proposes HyperTime that leverages INRs with hypernetworks for time series generation. Given that each time series is represented by an INR, the hypernetwork allows it to learn a prior over the time series dataset, which generates a compressed latent representation of the entire time series dataset. The embeddings can then be interpolated to generate novel time series. The method was evaluated using two quantitative metrics: 1) the predictive score, which measures the <span id="S6.SS1.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">usefulness</span> of the generated data by using a <span id="S6.SS1.SSS0.Px1.p2.1.2" class="ltx_text ltx_font_italic">train on synthetic, test on real</span> (TSRT) approach where a model is trained using the synthetic data to predict the next step in a sequence, and then it is evaluated using the real data; and 2) the <span id="S6.SS1.SSS0.Px1.p2.1.3" class="ltx_text ltx_font_bold">discriminative score</span> which serves as a measurement of <span id="S6.SS1.SSS0.Px1.p2.1.4" class="ltx_text ltx_font_italic">fidelity</span> of the generated data, where the aim is to assess if the synthetic data is indistinguishable from real data. A discriminative model is trained to classify real and fake samples, and then used to test whether the original and generated data are correctly classified. The discriminative score is computed as <math id="S6.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="|\text{Accuracy}-0.5|" display="inline"><semantics id="S6.SS1.SSS0.Px1.p2.1.m1.1a"><mrow id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml"><mo stretchy="false" id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.2" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.2.1.cmml">|</mo><mrow id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.cmml"><mtext id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.2" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.2a.cmml">Accuracy</mtext><mo id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.1" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.3" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.3.cmml">0.5</mn></mrow><mo stretchy="false" id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.3" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p2.1.m1.1b"><apply id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1"><abs id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.2.1.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.2"></abs><apply id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1"><minus id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.1.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.1"></minus><ci id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.2a.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.2"><mtext id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.2.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.2">Accuracy</mtext></ci><cn type="float" id="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.3.cmml" xref="S6.SS1.SSS0.Px1.p2.1.m1.1.1.1.1.3">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p2.1.m1.1c">|\text{Accuracy}-0.5|</annotation></semantics></math>, where a low value means that the classification is challenging, and therefore, the model cannot tell which samples are real and which are generated. Results for multiple lengths of Google stock data are shown in TableÂ <a href="#S6.T21" title="Table 21 â€£ Application: Realistic Generation of Financial Time Series â€£ 6.1 Generation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">21</span></a> where HyperTime outperforms all other benchmarks with regards to the predictive score and shows competitive performance with regards to the discriminative score.</p>
</div>
<figure id="S6.T21" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T21.47.1.1" class="ltx_text" style="font-size:90%;">Table 21</span>: </span><span id="S6.T21.48.2" class="ltx_text" style="font-size:90%;">Performance of regular time series generation in terms of the predictive and discriminative scores.</span></figcaption>
<table id="S6.T21.45" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T21.45.46.1" class="ltx_tr">
<th id="S6.T21.45.46.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;"></th>
<th id="S6.T21.45.46.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">Method</th>
<td id="S6.T21.45.46.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.45.46.1.3.1" class="ltx_text ltx_font_bold">Stock24</span></td>
<td id="S6.T21.45.46.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.45.46.1.4.1" class="ltx_text ltx_font_bold">Stocks72</span></td>
<td id="S6.T21.45.46.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.45.46.1.5.1" class="ltx_text ltx_font_bold">Stock360</span></td>
</tr>
<tr id="S6.T21.45.47.2" class="ltx_tr">
<th id="S6.T21.45.47.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="8">

<span id="S6.T21.45.47.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_top" style="width:2.8pt;">
<span id="S6.T21.45.47.2.1.1.1" class="ltx_p">
<span id="S6.T21.45.47.2.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:5.6pt;height:56.6pt;vertical-align:-25.5pt;"><span class="ltx_transformed_inner" style="width:56.6pt;transform:translate(-25.52pt,0pt) rotate(-90deg) ;">
<span id="S6.T21.45.47.2.1.1.1.1.1" class="ltx_p"><span id="S6.T21.45.47.2.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Predictive Score</span></span>
</span></span></span>
</span>
</th>
<th id="S6.T21.45.47.2.2" class="ltx_td ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></th>
<td id="S6.T21.45.47.2.3" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S6.T21.45.47.2.4" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S6.T21.45.47.2.5" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr id="S6.T21.3.3" class="ltx_tr">
<th id="S6.T21.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">iHT</th>
<td id="S6.T21.1.1.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.1.1.1.1" class="ltx_text ltx_font_bold">.037 <math id="S6.T21.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.1.1.1.1.m1.1a"><mo id="S6.T21.1.1.1.1.m1.1.1" xref="S6.T21.1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T21.1.1.1.1.m1.1.1.cmml" xref="S6.T21.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.1.1.1.1.m1.1c">\pm</annotation></semantics></math> .000</span></td>
<td id="S6.T21.2.2.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.2.2.2.1" class="ltx_text ltx_font_bold">.188 <math id="S6.T21.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.2.2.2.1.m1.1a"><mo id="S6.T21.2.2.2.1.m1.1.1" xref="S6.T21.2.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S6.T21.2.2.2.1.m1.1.1.cmml" xref="S6.T21.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.2.2.2.1.m1.1c">\pm</annotation></semantics></math> .000</span></td>
<td id="S6.T21.3.3.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.3.3.3.1" class="ltx_text ltx_font_bold">.168 <math id="S6.T21.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.3.3.3.1.m1.1a"><mo id="S6.T21.3.3.3.1.m1.1.1" xref="S6.T21.3.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S6.T21.3.3.3.1.m1.1.1.cmml" xref="S6.T21.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.3.3.3.1.m1.1c">\pm</annotation></semantics></math> .000</span></td>
</tr>
<tr id="S6.T21.6.6" class="ltx_tr">
<th id="S6.T21.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">GT-GAN</th>
<td id="S6.T21.4.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">.040 <math id="S6.T21.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.4.4.1.m1.1a"><mo id="S6.T21.4.4.1.m1.1.1" xref="S6.T21.4.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.4.4.1.m1.1b"><csymbol cd="latexml" id="S6.T21.4.4.1.m1.1.1.cmml" xref="S6.T21.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.4.4.1.m1.1c">\pm</annotation></semantics></math> .000</td>
<td id="S6.T21.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">.207 <math id="S6.T21.5.5.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.5.5.2.m1.1a"><mo id="S6.T21.5.5.2.m1.1.1" xref="S6.T21.5.5.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.5.5.2.m1.1b"><csymbol cd="latexml" id="S6.T21.5.5.2.m1.1.1.cmml" xref="S6.T21.5.5.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.5.5.2.m1.1c">\pm</annotation></semantics></math> .000</td>
<td id="S6.T21.6.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">.188 <math id="S6.T21.6.6.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.6.6.3.m1.1a"><mo id="S6.T21.6.6.3.m1.1.1" xref="S6.T21.6.6.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.6.6.3.m1.1b"><csymbol cd="latexml" id="S6.T21.6.6.3.m1.1.1.cmml" xref="S6.T21.6.6.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.6.6.3.m1.1c">\pm</annotation></semantics></math> .000</td>
</tr>
<tr id="S6.T21.9.9" class="ltx_tr">
<th id="S6.T21.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">TimeGAN</th>
<td id="S6.T21.7.7.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.038 <math id="S6.T21.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.7.7.1.m1.1a"><mo id="S6.T21.7.7.1.m1.1.1" xref="S6.T21.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.7.7.1.m1.1b"><csymbol cd="latexml" id="S6.T21.7.7.1.m1.1.1.cmml" xref="S6.T21.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.7.7.1.m1.1c">\pm</annotation></semantics></math> .001</td>
<td id="S6.T21.8.8.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.226 <math id="S6.T21.8.8.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.8.8.2.m1.1a"><mo id="S6.T21.8.8.2.m1.1.1" xref="S6.T21.8.8.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.8.8.2.m1.1b"><csymbol cd="latexml" id="S6.T21.8.8.2.m1.1.1.cmml" xref="S6.T21.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.8.8.2.m1.1c">\pm</annotation></semantics></math> .002</td>
<td id="S6.T21.9.9.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.206 <math id="S6.T21.9.9.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.9.9.3.m1.1a"><mo id="S6.T21.9.9.3.m1.1.1" xref="S6.T21.9.9.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.9.9.3.m1.1b"><csymbol cd="latexml" id="S6.T21.9.9.3.m1.1.1.cmml" xref="S6.T21.9.9.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.9.9.3.m1.1c">\pm</annotation></semantics></math> .000</td>
</tr>
<tr id="S6.T21.12.12" class="ltx_tr">
<th id="S6.T21.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">RCGAN</th>
<td id="S6.T21.10.10.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.040 <math id="S6.T21.10.10.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.10.10.1.m1.1a"><mo id="S6.T21.10.10.1.m1.1.1" xref="S6.T21.10.10.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.10.10.1.m1.1b"><csymbol cd="latexml" id="S6.T21.10.10.1.m1.1.1.cmml" xref="S6.T21.10.10.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.10.10.1.m1.1c">\pm</annotation></semantics></math> .001</td>
<td id="S6.T21.11.11.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.192 <math id="S6.T21.11.11.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.11.11.2.m1.1a"><mo id="S6.T21.11.11.2.m1.1.1" xref="S6.T21.11.11.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.11.11.2.m1.1b"><csymbol cd="latexml" id="S6.T21.11.11.2.m1.1.1.cmml" xref="S6.T21.11.11.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.11.11.2.m1.1c">\pm</annotation></semantics></math> .001</td>
<td id="S6.T21.12.12.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.189 <math id="S6.T21.12.12.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.12.12.3.m1.1a"><mo id="S6.T21.12.12.3.m1.1.1" xref="S6.T21.12.12.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.12.12.3.m1.1b"><csymbol cd="latexml" id="S6.T21.12.12.3.m1.1.1.cmml" xref="S6.T21.12.12.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.12.12.3.m1.1c">\pm</annotation></semantics></math> .000</td>
</tr>
<tr id="S6.T21.15.15" class="ltx_tr">
<th id="S6.T21.15.15.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">DiffTime</th>
<td id="S6.T21.13.13.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.038 <math id="S6.T21.13.13.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.13.13.1.m1.1a"><mo id="S6.T21.13.13.1.m1.1.1" xref="S6.T21.13.13.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.13.13.1.m1.1b"><csymbol cd="latexml" id="S6.T21.13.13.1.m1.1.1.cmml" xref="S6.T21.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.13.13.1.m1.1c">\pm</annotation></semantics></math> .001</td>
<td id="S6.T21.14.14.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.213 <math id="S6.T21.14.14.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.14.14.2.m1.1a"><mo id="S6.T21.14.14.2.m1.1.1" xref="S6.T21.14.14.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.14.14.2.m1.1b"><csymbol cd="latexml" id="S6.T21.14.14.2.m1.1.1.cmml" xref="S6.T21.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.14.14.2.m1.1c">\pm</annotation></semantics></math> .000</td>
<td id="S6.T21.15.15.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.215 <math id="S6.T21.15.15.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.15.15.3.m1.1a"><mo id="S6.T21.15.15.3.m1.1.1" xref="S6.T21.15.15.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.15.15.3.m1.1b"><csymbol cd="latexml" id="S6.T21.15.15.3.m1.1.1.cmml" xref="S6.T21.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.15.15.3.m1.1c">\pm</annotation></semantics></math> .000</td>
</tr>
<tr id="S6.T21.18.18" class="ltx_tr">
<th id="S6.T21.18.18.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">LS4</th>
<td id="S6.T21.16.16.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.103 <math id="S6.T21.16.16.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.16.16.1.m1.1a"><mo id="S6.T21.16.16.1.m1.1.1" xref="S6.T21.16.16.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.16.16.1.m1.1b"><csymbol cd="latexml" id="S6.T21.16.16.1.m1.1.1.cmml" xref="S6.T21.16.16.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.16.16.1.m1.1c">\pm</annotation></semantics></math> .001</td>
<td id="S6.T21.17.17.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.194 <math id="S6.T21.17.17.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.17.17.2.m1.1a"><mo id="S6.T21.17.17.2.m1.1.1" xref="S6.T21.17.17.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.17.17.2.m1.1b"><csymbol cd="latexml" id="S6.T21.17.17.2.m1.1.1.cmml" xref="S6.T21.17.17.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.17.17.2.m1.1c">\pm</annotation></semantics></math> .000</td>
<td id="S6.T21.18.18.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.18.18.3.1" class="ltx_text ltx_font_bold">.168 <math id="S6.T21.18.18.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.18.18.3.1.m1.1a"><mo id="S6.T21.18.18.3.1.m1.1.1" xref="S6.T21.18.18.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.18.18.3.1.m1.1b"><csymbol cd="latexml" id="S6.T21.18.18.3.1.m1.1.1.cmml" xref="S6.T21.18.18.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.18.18.3.1.m1.1c">\pm</annotation></semantics></math> .000</span></td>
</tr>
<tr id="S6.T21.21.21" class="ltx_tr">
<th id="S6.T21.21.21.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">FF</th>
<td id="S6.T21.19.19.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.076 <math id="S6.T21.19.19.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.19.19.1.m1.1a"><mo id="S6.T21.19.19.1.m1.1.1" xref="S6.T21.19.19.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.19.19.1.m1.1b"><csymbol cd="latexml" id="S6.T21.19.19.1.m1.1.1.cmml" xref="S6.T21.19.19.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.19.19.1.m1.1c">\pm</annotation></semantics></math> .001</td>
<td id="S6.T21.20.20.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.191 <math id="S6.T21.20.20.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.20.20.2.m1.1a"><mo id="S6.T21.20.20.2.m1.1.1" xref="S6.T21.20.20.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.20.20.2.m1.1b"><csymbol cd="latexml" id="S6.T21.20.20.2.m1.1.1.cmml" xref="S6.T21.20.20.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.20.20.2.m1.1c">\pm</annotation></semantics></math> .000</td>
<td id="S6.T21.21.21.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.169 <math id="S6.T21.21.21.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.21.21.3.m1.1a"><mo id="S6.T21.21.21.3.m1.1.1" xref="S6.T21.21.21.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.21.21.3.m1.1b"><csymbol cd="latexml" id="S6.T21.21.21.3.m1.1.1.cmml" xref="S6.T21.21.21.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.21.21.3.m1.1c">\pm</annotation></semantics></math> .000</td>
</tr>
<tr id="S6.T21.24.24" class="ltx_tr">
<th id="S6.T21.24.24.4" class="ltx_td ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;"></th>
<th id="S6.T21.24.24.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.24.24.5.1" class="ltx_text" style="background-color:#F2F2F2;">Original</span></th>
<td id="S6.T21.22.22.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.22.22.1.1" class="ltx_text" style="background-color:#F2F2F2;">.036 <math id="S6.T21.22.22.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.22.22.1.1.m1.1a"><mo mathbackground="#F2F2F2" id="S6.T21.22.22.1.1.m1.1.1" xref="S6.T21.22.22.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.22.22.1.1.m1.1b"><csymbol cd="latexml" id="S6.T21.22.22.1.1.m1.1.1.cmml" xref="S6.T21.22.22.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.22.22.1.1.m1.1c">\pm</annotation></semantics></math> .001</span></td>
<td id="S6.T21.23.23.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.23.23.2.1" class="ltx_text" style="background-color:#F2F2F2;">.186 <math id="S6.T21.23.23.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.23.23.2.1.m1.1a"><mo mathbackground="#F2F2F2" id="S6.T21.23.23.2.1.m1.1.1" xref="S6.T21.23.23.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.23.23.2.1.m1.1b"><csymbol cd="latexml" id="S6.T21.23.23.2.1.m1.1.1.cmml" xref="S6.T21.23.23.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.23.23.2.1.m1.1c">\pm</annotation></semantics></math> .001</span></td>
<td id="S6.T21.24.24.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.24.24.3.1" class="ltx_text" style="background-color:#F2F2F2;">.167 <math id="S6.T21.24.24.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.24.24.3.1.m1.1a"><mo mathbackground="#F2F2F2" id="S6.T21.24.24.3.1.m1.1.1" xref="S6.T21.24.24.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.24.24.3.1.m1.1b"><csymbol cd="latexml" id="S6.T21.24.24.3.1.m1.1.1.cmml" xref="S6.T21.24.24.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.24.24.3.1.m1.1c">\pm</annotation></semantics></math> .001</span></td>
</tr>
<tr id="S6.T21.45.48.3" class="ltx_tr">
<th id="S6.T21.45.48.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="7">

<span id="S6.T21.45.48.3.1.1" class="ltx_inline-block ltx_parbox ltx_align_top" style="width:2.8pt;">
<span id="S6.T21.45.48.3.1.1.1" class="ltx_p">
<span id="S6.T21.45.48.3.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:5.5pt;height:72pt;vertical-align:-72.0pt;"><span class="ltx_transformed_inner" style="width:72.0pt;transform:translate(-33.26pt,38.72pt) rotate(-90deg) ;">
<span id="S6.T21.45.48.3.1.1.1.1.1" class="ltx_p"><span id="S6.T21.45.48.3.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Discriminative Score</span></span>
</span></span></span>
</span>
</th>
<th id="S6.T21.45.48.3.2" class="ltx_td ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></th>
<td id="S6.T21.45.48.3.3" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S6.T21.45.48.3.4" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S6.T21.45.48.3.5" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr id="S6.T21.27.27" class="ltx_tr">
<th id="S6.T21.27.27.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">iHT</th>
<td id="S6.T21.25.25.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.25.25.1.1" class="ltx_text ltx_font_bold">.044 <math id="S6.T21.25.25.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.25.25.1.1.m1.1a"><mo id="S6.T21.25.25.1.1.m1.1.1" xref="S6.T21.25.25.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.25.25.1.1.m1.1b"><csymbol cd="latexml" id="S6.T21.25.25.1.1.m1.1.1.cmml" xref="S6.T21.25.25.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.25.25.1.1.m1.1c">\pm</annotation></semantics></math> .011</span></td>
<td id="S6.T21.26.26.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.014 <math id="S6.T21.26.26.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.26.26.2.m1.1a"><mo id="S6.T21.26.26.2.m1.1.1" xref="S6.T21.26.26.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.26.26.2.m1.1b"><csymbol cd="latexml" id="S6.T21.26.26.2.m1.1.1.cmml" xref="S6.T21.26.26.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.26.26.2.m1.1c">\pm</annotation></semantics></math> .009</td>
<td id="S6.T21.27.27.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.018 <math id="S6.T21.27.27.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.27.27.3.m1.1a"><mo id="S6.T21.27.27.3.m1.1.1" xref="S6.T21.27.27.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.27.27.3.m1.1b"><csymbol cd="latexml" id="S6.T21.27.27.3.m1.1.1.cmml" xref="S6.T21.27.27.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.27.27.3.m1.1c">\pm</annotation></semantics></math> .015</td>
</tr>
<tr id="S6.T21.30.30" class="ltx_tr">
<th id="S6.T21.30.30.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">GT-GAN</th>
<td id="S6.T21.28.28.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">.077 <math id="S6.T21.28.28.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.28.28.1.m1.1a"><mo id="S6.T21.28.28.1.m1.1.1" xref="S6.T21.28.28.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.28.28.1.m1.1b"><csymbol cd="latexml" id="S6.T21.28.28.1.m1.1.1.cmml" xref="S6.T21.28.28.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.28.28.1.m1.1c">\pm</annotation></semantics></math> .031</td>
<td id="S6.T21.29.29.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">.058 <math id="S6.T21.29.29.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.29.29.2.m1.1a"><mo id="S6.T21.29.29.2.m1.1.1" xref="S6.T21.29.29.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.29.29.2.m1.1b"><csymbol cd="latexml" id="S6.T21.29.29.2.m1.1.1.cmml" xref="S6.T21.29.29.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.29.29.2.m1.1c">\pm</annotation></semantics></math> .017</td>
<td id="S6.T21.30.30.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">.085 <math id="S6.T21.30.30.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.30.30.3.m1.1a"><mo id="S6.T21.30.30.3.m1.1.1" xref="S6.T21.30.30.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.30.30.3.m1.1b"><csymbol cd="latexml" id="S6.T21.30.30.3.m1.1.1.cmml" xref="S6.T21.30.30.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.30.30.3.m1.1c">\pm</annotation></semantics></math> .064</td>
</tr>
<tr id="S6.T21.33.33" class="ltx_tr">
<th id="S6.T21.33.33.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">TimeGAN</th>
<td id="S6.T21.31.31.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.102 <math id="S6.T21.31.31.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.31.31.1.m1.1a"><mo id="S6.T21.31.31.1.m1.1.1" xref="S6.T21.31.31.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.31.31.1.m1.1b"><csymbol cd="latexml" id="S6.T21.31.31.1.m1.1.1.cmml" xref="S6.T21.31.31.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.31.31.1.m1.1c">\pm</annotation></semantics></math> .021</td>
<td id="S6.T21.32.32.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.073 <math id="S6.T21.32.32.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.32.32.2.m1.1a"><mo id="S6.T21.32.32.2.m1.1.1" xref="S6.T21.32.32.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.32.32.2.m1.1b"><csymbol cd="latexml" id="S6.T21.32.32.2.m1.1.1.cmml" xref="S6.T21.32.32.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.32.32.2.m1.1c">\pm</annotation></semantics></math> .047</td>
<td id="S6.T21.33.33.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.042 <math id="S6.T21.33.33.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.33.33.3.m1.1a"><mo id="S6.T21.33.33.3.m1.1.1" xref="S6.T21.33.33.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.33.33.3.m1.1b"><csymbol cd="latexml" id="S6.T21.33.33.3.m1.1.1.cmml" xref="S6.T21.33.33.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.33.33.3.m1.1c">\pm</annotation></semantics></math> .074</td>
</tr>
<tr id="S6.T21.36.36" class="ltx_tr">
<th id="S6.T21.36.36.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">RCGAN</th>
<td id="S6.T21.34.34.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.196 <math id="S6.T21.34.34.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.34.34.1.m1.1a"><mo id="S6.T21.34.34.1.m1.1.1" xref="S6.T21.34.34.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.34.34.1.m1.1b"><csymbol cd="latexml" id="S6.T21.34.34.1.m1.1.1.cmml" xref="S6.T21.34.34.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.34.34.1.m1.1c">\pm</annotation></semantics></math> .027</td>
<td id="S6.T21.35.35.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.35.35.2.1" class="ltx_text ltx_font_bold">.012 <math id="S6.T21.35.35.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.35.35.2.1.m1.1a"><mo id="S6.T21.35.35.2.1.m1.1.1" xref="S6.T21.35.35.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.35.35.2.1.m1.1b"><csymbol cd="latexml" id="S6.T21.35.35.2.1.m1.1.1.cmml" xref="S6.T21.35.35.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.35.35.2.1.m1.1c">\pm</annotation></semantics></math> .09</span></td>
<td id="S6.T21.36.36.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S6.T21.36.36.3.1" class="ltx_text ltx_font_bold">.014 <math id="S6.T21.36.36.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.36.36.3.1.m1.1a"><mo id="S6.T21.36.36.3.1.m1.1.1" xref="S6.T21.36.36.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.36.36.3.1.m1.1b"><csymbol cd="latexml" id="S6.T21.36.36.3.1.m1.1.1.cmml" xref="S6.T21.36.36.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.36.36.3.1.m1.1c">\pm</annotation></semantics></math> .007</span></td>
</tr>
<tr id="S6.T21.39.39" class="ltx_tr">
<th id="S6.T21.39.39.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">DiffTime</th>
<td id="S6.T21.37.37.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.097 <math id="S6.T21.37.37.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.37.37.1.m1.1a"><mo id="S6.T21.37.37.1.m1.1.1" xref="S6.T21.37.37.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.37.37.1.m1.1b"><csymbol cd="latexml" id="S6.T21.37.37.1.m1.1.1.cmml" xref="S6.T21.37.37.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.37.37.1.m1.1c">\pm</annotation></semantics></math> .016</td>
<td id="S6.T21.38.38.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.097 <math id="S6.T21.38.38.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.38.38.2.m1.1a"><mo id="S6.T21.38.38.2.m1.1.1" xref="S6.T21.38.38.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.38.38.2.m1.1b"><csymbol cd="latexml" id="S6.T21.38.38.2.m1.1.1.cmml" xref="S6.T21.38.38.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.38.38.2.m1.1c">\pm</annotation></semantics></math> .012</td>
<td id="S6.T21.39.39.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.101 <math id="S6.T21.39.39.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.39.39.3.m1.1a"><mo id="S6.T21.39.39.3.m1.1.1" xref="S6.T21.39.39.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.39.39.3.m1.1b"><csymbol cd="latexml" id="S6.T21.39.39.3.m1.1.1.cmml" xref="S6.T21.39.39.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.39.39.3.m1.1c">\pm</annotation></semantics></math> .018</td>
</tr>
<tr id="S6.T21.42.42" class="ltx_tr">
<th id="S6.T21.42.42.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.5pt;padding-bottom:0.5pt;">LS4</th>
<td id="S6.T21.40.40.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.363 <math id="S6.T21.40.40.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.40.40.1.m1.1a"><mo id="S6.T21.40.40.1.m1.1.1" xref="S6.T21.40.40.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.40.40.1.m1.1b"><csymbol cd="latexml" id="S6.T21.40.40.1.m1.1.1.cmml" xref="S6.T21.40.40.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.40.40.1.m1.1c">\pm</annotation></semantics></math> .027</td>
<td id="S6.T21.41.41.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.089 <math id="S6.T21.41.41.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.41.41.2.m1.1a"><mo id="S6.T21.41.41.2.m1.1.1" xref="S6.T21.41.41.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.41.41.2.m1.1b"><csymbol cd="latexml" id="S6.T21.41.41.2.m1.1.1.cmml" xref="S6.T21.41.41.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.41.41.2.m1.1c">\pm</annotation></semantics></math> .081</td>
<td id="S6.T21.42.42.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">.088 <math id="S6.T21.42.42.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.42.42.3.m1.1a"><mo id="S6.T21.42.42.3.m1.1.1" xref="S6.T21.42.42.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.42.42.3.m1.1b"><csymbol cd="latexml" id="S6.T21.42.42.3.m1.1.1.cmml" xref="S6.T21.42.42.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.42.42.3.m1.1c">\pm</annotation></semantics></math> .081</td>
</tr>
<tr id="S6.T21.45.45" class="ltx_tr">
<th id="S6.T21.45.45.4" class="ltx_td ltx_th ltx_th_row ltx_border_bb" style="padding-top:0.5pt;padding-bottom:0.5pt;"></th>
<th id="S6.T21.45.45.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-top:0.5pt;padding-bottom:0.5pt;">FF</th>
<td id="S6.T21.43.43.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.5pt;padding-bottom:0.5pt;">.349 <math id="S6.T21.43.43.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.43.43.1.m1.1a"><mo id="S6.T21.43.43.1.m1.1.1" xref="S6.T21.43.43.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.43.43.1.m1.1b"><csymbol cd="latexml" id="S6.T21.43.43.1.m1.1.1.cmml" xref="S6.T21.43.43.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.43.43.1.m1.1c">\pm</annotation></semantics></math> .113</td>
<td id="S6.T21.44.44.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.5pt;padding-bottom:0.5pt;">.016 <math id="S6.T21.44.44.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.44.44.2.m1.1a"><mo id="S6.T21.44.44.2.m1.1.1" xref="S6.T21.44.44.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.44.44.2.m1.1b"><csymbol cd="latexml" id="S6.T21.44.44.2.m1.1.1.cmml" xref="S6.T21.44.44.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.44.44.2.m1.1c">\pm</annotation></semantics></math> .018</td>
<td id="S6.T21.45.45.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.5pt;padding-bottom:0.5pt;">.015 <math id="S6.T21.45.45.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T21.45.45.3.m1.1a"><mo id="S6.T21.45.45.3.m1.1.1" xref="S6.T21.45.45.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T21.45.45.3.m1.1b"><csymbol cd="latexml" id="S6.T21.45.45.3.m1.1.1.cmml" xref="S6.T21.45.45.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T21.45.45.3.m1.1c">\pm</annotation></semantics></math> .014</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Application: Imputation of Financial Time Series</h5>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.1" class="ltx_p">Addressing time series imputation is crucial across different domains including finance, climate modelling, and healthcare, given the potentially vast differences in the type of data under study.
Classic strategies, such as averaging and regression, are generally too simplistic and fail to sufficiently encapsulate the underlying behavior. Although modern methods, like iterative imputation and maximum likelihood procedures, allow for a higher degree of algorithmic complexity and performance improvement, the assumptions they often make can introduce biases that are detrimental to intricate cases (refer toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx98" title="" class="ltx_ref">JCL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> orÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx46" title="" class="ltx_ref">CWL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite> for examples). Inspired by the success ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx73" title="" class="ltx_ref">FSEL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> to generate time series that can be irregularly sampled,Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">BFELV23</a>]</cite> proposes Modulated Auto-Decoding SIREN (MADS) for multivariate time series imputation. MADS utilises the capabilities of SIRENs for high fidelity reconstruction of signals and irregular data handling and combines the SIREN parameterizations with hypernetworks in order to learn a prior over the space of time series. Experimental results across three real-world time series datasets from different domains are shown in TableÂ <a href="#S6.T22" title="Table 22 â€£ Application: Imputation of Financial Time Series â€£ 6.1 Generation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">22</span></a>, where MADS shows best performance in the majority of the datasets. Interestingly, in all cases, the best performance is achieved by INR-based methods. For details of the performance metrics and additional results, we refer to the original paperÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">BFELV23</a>]</cite>.</p>
</div>
<figure id="S6.T22" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S6.T22.4.1.1" class="ltx_text" style="font-size:90%;">Table 22</span>: </span><span id="S6.T22.5.2" class="ltx_text" style="font-size:90%;">Experimental results for time series imputation. Results are averaged over five runs, with the standard deviation shown in parenthesis (bold indicates best performance).</span></figcaption>
<div id="S6.T22.2" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:222.2pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-135.3pt,69.2pt) scale(0.61569333671898,0.61569333671898) ;">
<table id="S6.T22.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T22.2.2.2" class="ltx_tr">
<th id="S6.T22.2.2.2.3" class="ltx_td ltx_th ltx_th_row ltx_border_tt" colspan="2"></th>
<td id="S6.T22.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T22.2.2.2.4.1" class="ltx_text ltx_font_italic">Air Quality</span></td>
<td id="S6.T22.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T22.1.1.1.1.1" class="ltx_text ltx_font_italic">HAR (<math id="S6.T22.1.1.1.1.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S6.T22.1.1.1.1.1.m1.1a"><mrow id="S6.T22.1.1.1.1.1.m1.1.1" xref="S6.T22.1.1.1.1.1.m1.1.1.cmml"><mn id="S6.T22.1.1.1.1.1.m1.1.1.2" xref="S6.T22.1.1.1.1.1.m1.1.1.2.cmml">30</mn><mo id="S6.T22.1.1.1.1.1.m1.1.1.1" xref="S6.T22.1.1.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T22.1.1.1.1.1.m1.1b"><apply id="S6.T22.1.1.1.1.1.m1.1.1.cmml" xref="S6.T22.1.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T22.1.1.1.1.1.m1.1.1.1.cmml" xref="S6.T22.1.1.1.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T22.1.1.1.1.1.m1.1.1.2.cmml" xref="S6.T22.1.1.1.1.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T22.1.1.1.1.1.m1.1c">30\%</annotation></semantics></math>)</span></td>
<td id="S6.T22.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T22.2.2.2.2.1" class="ltx_text ltx_font_italic">HAR (<math id="S6.T22.2.2.2.2.1.m1.1" class="ltx_Math" alttext="70\%" display="inline"><semantics id="S6.T22.2.2.2.2.1.m1.1a"><mrow id="S6.T22.2.2.2.2.1.m1.1.1" xref="S6.T22.2.2.2.2.1.m1.1.1.cmml"><mn id="S6.T22.2.2.2.2.1.m1.1.1.2" xref="S6.T22.2.2.2.2.1.m1.1.1.2.cmml">70</mn><mo id="S6.T22.2.2.2.2.1.m1.1.1.1" xref="S6.T22.2.2.2.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T22.2.2.2.2.1.m1.1b"><apply id="S6.T22.2.2.2.2.1.m1.1.1.cmml" xref="S6.T22.2.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="S6.T22.2.2.2.2.1.m1.1.1.1.cmml" xref="S6.T22.2.2.2.2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T22.2.2.2.2.1.m1.1.1.2.cmml" xref="S6.T22.2.2.2.2.1.m1.1.1.2">70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T22.2.2.2.2.1.m1.1c">70\%</annotation></semantics></math>)</span></td>
<td id="S6.T22.2.2.2.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T22.2.2.2.5.1" class="ltx_text ltx_font_italic">PhysioNet</span></td>
</tr>
<tr id="S6.T22.2.2.3.1" class="ltx_tr">
<th id="S6.T22.2.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Family</th>
<th id="S6.T22.2.2.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Method</th>
<td id="S6.T22.2.2.3.1.3" class="ltx_td ltx_align_center">MSE</td>
<td id="S6.T22.2.2.3.1.4" class="ltx_td ltx_align_center">Max MSE</td>
<td id="S6.T22.2.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r">W2</td>
<td id="S6.T22.2.2.3.1.6" class="ltx_td ltx_align_center">MSE</td>
<td id="S6.T22.2.2.3.1.7" class="ltx_td ltx_align_center">Max MSE</td>
<td id="S6.T22.2.2.3.1.8" class="ltx_td ltx_align_center ltx_border_r">W2</td>
<td id="S6.T22.2.2.3.1.9" class="ltx_td ltx_align_center">MSE</td>
<td id="S6.T22.2.2.3.1.10" class="ltx_td ltx_align_center">Max MSE</td>
<td id="S6.T22.2.2.3.1.11" class="ltx_td ltx_align_center ltx_border_r">W2</td>
<td id="S6.T22.2.2.3.1.12" class="ltx_td ltx_align_center">MSE</td>
<td id="S6.T22.2.2.3.1.13" class="ltx_td ltx_align_center">Max MSE</td>
<td id="S6.T22.2.2.3.1.14" class="ltx_td ltx_align_center">W2</td>
</tr>
<tr id="S6.T22.2.2.4.2" class="ltx_tr">
<th id="S6.T22.2.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T22.2.2.4.2.1.1" class="ltx_text">Classic</span></th>
<th id="S6.T22.2.2.4.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mean</th>
<td id="S6.T22.2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_t">0.091</td>
<td id="S6.T22.2.2.4.2.4" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
<td id="S6.T22.2.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.260</td>
<td id="S6.T22.2.2.4.2.6" class="ltx_td ltx_align_center ltx_border_t">0.027</td>
<td id="S6.T22.2.2.4.2.7" class="ltx_td ltx_align_center ltx_border_t">0.332</td>
<td id="S6.T22.2.2.4.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.078</td>
<td id="S6.T22.2.2.4.2.9" class="ltx_td ltx_align_center ltx_border_t">0.028</td>
<td id="S6.T22.2.2.4.2.10" class="ltx_td ltx_align_center ltx_border_t">0.358</td>
<td id="S6.T22.2.2.4.2.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.182</td>
<td id="S6.T22.2.2.4.2.12" class="ltx_td ltx_align_center ltx_border_t">0.024</td>
<td id="S6.T22.2.2.4.2.13" class="ltx_td ltx_align_center ltx_border_t">0.386</td>
<td id="S6.T22.2.2.4.2.14" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T22.2.2.4.2.14.1" class="ltx_text ltx_font_bold">0.029</span></td>
</tr>
<tr id="S6.T22.2.2.5.3" class="ltx_tr">
<th id="S6.T22.2.2.5.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.5.3.2" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.5.3.3" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r">(0.000)</td>
<td id="S6.T22.2.2.5.3.5" class="ltx_td ltx_align_center">(0.001)</td>
<td id="S6.T22.2.2.5.3.6" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.5.3.7" class="ltx_td ltx_align_center ltx_border_r">(0.001)</td>
<td id="S6.T22.2.2.5.3.8" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.5.3.9" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.5.3.10" class="ltx_td ltx_align_center ltx_border_r">(0.004)</td>
<td id="S6.T22.2.2.5.3.11" class="ltx_td ltx_align_center">(0.001)</td>
<td id="S6.T22.2.2.5.3.12" class="ltx_td ltx_align_center">(0.018)</td>
<td id="S6.T22.2.2.5.3.13" class="ltx_td ltx_align_center">(0.001)</td>
</tr>
<tr id="S6.T22.2.2.6.4" class="ltx_tr">
<th id="S6.T22.2.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Median</th>
<td id="S6.T22.2.2.6.4.2" class="ltx_td ltx_align_center">0.091</td>
<td id="S6.T22.2.2.6.4.3" class="ltx_td ltx_align_center">0.480</td>
<td id="S6.T22.2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r">0.260</td>
<td id="S6.T22.2.2.6.4.5" class="ltx_td ltx_align_center">0.029</td>
<td id="S6.T22.2.2.6.4.6" class="ltx_td ltx_align_center">0.332</td>
<td id="S6.T22.2.2.6.4.7" class="ltx_td ltx_align_center ltx_border_r">0.215</td>
<td id="S6.T22.2.2.6.4.8" class="ltx_td ltx_align_center">0.029</td>
<td id="S6.T22.2.2.6.4.9" class="ltx_td ltx_align_center">0.362</td>
<td id="S6.T22.2.2.6.4.10" class="ltx_td ltx_align_center ltx_border_r">0.180</td>
<td id="S6.T22.2.2.6.4.11" class="ltx_td ltx_align_center">0.026</td>
<td id="S6.T22.2.2.6.4.12" class="ltx_td ltx_align_center">0.428</td>
<td id="S6.T22.2.2.6.4.13" class="ltx_td ltx_align_center">0.086</td>
</tr>
<tr id="S6.T22.2.2.7.5" class="ltx_tr">
<th id="S6.T22.2.2.7.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.7.5.2" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.7.5.3" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.7.5.4" class="ltx_td ltx_align_center ltx_border_r">(0.000)</td>
<td id="S6.T22.2.2.7.5.5" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.7.5.6" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.7.5.7" class="ltx_td ltx_align_center ltx_border_r">(0.305)</td>
<td id="S6.T22.2.2.7.5.8" class="ltx_td ltx_align_center">(0.000)</td>
<td id="S6.T22.2.2.7.5.9" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.7.5.10" class="ltx_td ltx_align_center ltx_border_r">(0.000)</td>
<td id="S6.T22.2.2.7.5.11" class="ltx_td ltx_align_center">(0.001)</td>
<td id="S6.T22.2.2.7.5.12" class="ltx_td ltx_align_center">(0.022)</td>
<td id="S6.T22.2.2.7.5.13" class="ltx_td ltx_align_center">(0.125)</td>
</tr>
<tr id="S6.T22.2.2.8.6" class="ltx_tr">
<th id="S6.T22.2.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="6"><span id="S6.T22.2.2.8.6.1.1" class="ltx_text">Deep learning</span></th>
<th id="S6.T22.2.2.8.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">BRITS</th>
<td id="S6.T22.2.2.8.6.3" class="ltx_td ltx_align_center ltx_border_t">0.224</td>
<td id="S6.T22.2.2.8.6.4" class="ltx_td ltx_align_center ltx_border_t">0.880</td>
<td id="S6.T22.2.2.8.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.388</td>
<td id="S6.T22.2.2.8.6.6" class="ltx_td ltx_align_center ltx_border_t">0.308</td>
<td id="S6.T22.2.2.8.6.7" class="ltx_td ltx_align_center ltx_border_t">0.952</td>
<td id="S6.T22.2.2.8.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.284</td>
<td id="S6.T22.2.2.8.6.9" class="ltx_td ltx_align_center ltx_border_t">0.312</td>
<td id="S6.T22.2.2.8.6.10" class="ltx_td ltx_align_center ltx_border_t">0.988</td>
<td id="S6.T22.2.2.8.6.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.666</td>
<td id="S6.T22.2.2.8.6.12" class="ltx_td ltx_align_center ltx_border_t">0.522</td>
<td id="S6.T22.2.2.8.6.13" class="ltx_td ltx_align_center ltx_border_t">0.986</td>
<td id="S6.T22.2.2.8.6.14" class="ltx_td ltx_align_center ltx_border_t">0.144</td>
</tr>
<tr id="S6.T22.2.2.9.7" class="ltx_tr">
<th id="S6.T22.2.2.9.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.9.7.2" class="ltx_td ltx_align_center">(0.015)</td>
<td id="S6.T22.2.2.9.7.3" class="ltx_td ltx_align_center">(0.016)</td>
<td id="S6.T22.2.2.9.7.4" class="ltx_td ltx_align_center ltx_border_r">(0.022)</td>
<td id="S6.T22.2.2.9.7.5" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.9.7.6" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.9.7.7" class="ltx_td ltx_align_center ltx_border_r">(0.005)</td>
<td id="S6.T22.2.2.9.7.8" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.9.7.9" class="ltx_td ltx_align_center">(0.004)</td>
<td id="S6.T22.2.2.9.7.10" class="ltx_td ltx_align_center ltx_border_r">(0.005)</td>
<td id="S6.T22.2.2.9.7.11" class="ltx_td ltx_align_center">(0.011)</td>
<td id="S6.T22.2.2.9.7.12" class="ltx_td ltx_align_center">(0.011)</td>
<td id="S6.T22.2.2.9.7.13" class="ltx_td ltx_align_center">(0.005)</td>
</tr>
<tr id="S6.T22.2.2.10.8" class="ltx_tr">
<th id="S6.T22.2.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CSDI</th>
<td id="S6.T22.2.2.10.8.2" class="ltx_td ltx_align_center">0.075</td>
<td id="S6.T22.2.2.10.8.3" class="ltx_td ltx_align_center">0.844</td>
<td id="S6.T22.2.2.10.8.4" class="ltx_td ltx_align_center ltx_border_r">1.220</td>
<td id="S6.T22.2.2.10.8.5" class="ltx_td ltx_align_center">0.010</td>
<td id="S6.T22.2.2.10.8.6" class="ltx_td ltx_align_center">0.280</td>
<td id="S6.T22.2.2.10.8.7" class="ltx_td ltx_align_center ltx_border_r">0.122</td>
<td id="S6.T22.2.2.10.8.8" class="ltx_td ltx_align_center">0.020</td>
<td id="S6.T22.2.2.10.8.9" class="ltx_td ltx_align_center">0.436</td>
<td id="S6.T22.2.2.10.8.10" class="ltx_td ltx_align_center ltx_border_r">0.168</td>
<td id="S6.T22.2.2.10.8.11" class="ltx_td ltx_align_center">0.037</td>
<td id="S6.T22.2.2.10.8.12" class="ltx_td ltx_align_center">0.506</td>
<td id="S6.T22.2.2.10.8.13" class="ltx_td ltx_align_center">0.422</td>
</tr>
<tr id="S6.T22.2.2.11.9" class="ltx_tr">
<th id="S6.T22.2.2.11.9.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.11.9.2" class="ltx_td ltx_align_center">(0.012)</td>
<td id="S6.T22.2.2.11.9.3" class="ltx_td ltx_align_center">(0.015)</td>
<td id="S6.T22.2.2.11.9.4" class="ltx_td ltx_align_center ltx_border_r">(0.045)</td>
<td id="S6.T22.2.2.11.9.5" class="ltx_td ltx_align_center">(0.002)</td>
<td id="S6.T22.2.2.11.9.6" class="ltx_td ltx_align_center">(0.021)</td>
<td id="S6.T22.2.2.11.9.7" class="ltx_td ltx_align_center ltx_border_r">(0.017)</td>
<td id="S6.T22.2.2.11.9.8" class="ltx_td ltx_align_center">(0.006)</td>
<td id="S6.T22.2.2.11.9.9" class="ltx_td ltx_align_center">(0.056)</td>
<td id="S6.T22.2.2.11.9.10" class="ltx_td ltx_align_center ltx_border_r">(0.031)</td>
<td id="S6.T22.2.2.11.9.11" class="ltx_td ltx_align_center">(0.005)</td>
<td id="S6.T22.2.2.11.9.12" class="ltx_td ltx_align_center">(0.035)</td>
<td id="S6.T22.2.2.11.9.13" class="ltx_td ltx_align_center">(0.029)</td>
</tr>
<tr id="S6.T22.2.2.12.10" class="ltx_tr">
<th id="S6.T22.2.2.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">GP-VAE</th>
<td id="S6.T22.2.2.12.10.2" class="ltx_td ltx_align_center">0.083</td>
<td id="S6.T22.2.2.12.10.3" class="ltx_td ltx_align_center">0.772</td>
<td id="S6.T22.2.2.12.10.4" class="ltx_td ltx_align_center ltx_border_r">0.764</td>
<td id="S6.T22.2.2.12.10.5" class="ltx_td ltx_align_center">0.035</td>
<td id="S6.T22.2.2.12.10.6" class="ltx_td ltx_align_center">0.374</td>
<td id="S6.T22.2.2.12.10.7" class="ltx_td ltx_align_center ltx_border_r">0.280</td>
<td id="S6.T22.2.2.12.10.8" class="ltx_td ltx_align_center">0.038</td>
<td id="S6.T22.2.2.12.10.9" class="ltx_td ltx_align_center">0.416</td>
<td id="S6.T22.2.2.12.10.10" class="ltx_td ltx_align_center ltx_border_r">0.302</td>
<td id="S6.T22.2.2.12.10.11" class="ltx_td ltx_align_center">0.024</td>
<td id="S6.T22.2.2.12.10.12" class="ltx_td ltx_align_center">0.386</td>
<td id="S6.T22.2.2.12.10.13" class="ltx_td ltx_align_center">0.352</td>
</tr>
<tr id="S6.T22.2.2.13.11" class="ltx_tr">
<th id="S6.T22.2.2.13.11.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.13.11.2" class="ltx_td ltx_align_center">(0.003)</td>
<td id="S6.T22.2.2.13.11.3" class="ltx_td ltx_align_center">(0.013)</td>
<td id="S6.T22.2.2.13.11.4" class="ltx_td ltx_align_center ltx_border_r">(0.015)</td>
<td id="S6.T22.2.2.13.11.5" class="ltx_td ltx_align_center">(0.007)</td>
<td id="S6.T22.2.2.13.11.6" class="ltx_td ltx_align_center">(0.027)</td>
<td id="S6.T22.2.2.13.11.7" class="ltx_td ltx_align_center ltx_border_r">(0.020)</td>
<td id="S6.T22.2.2.13.11.8" class="ltx_td ltx_align_center">(0.007)</td>
<td id="S6.T22.2.2.13.11.9" class="ltx_td ltx_align_center">(0.025)</td>
<td id="S6.T22.2.2.13.11.10" class="ltx_td ltx_align_center ltx_border_r">(0.026)</td>
<td id="S6.T22.2.2.13.11.11" class="ltx_td ltx_align_center">(0.001)</td>
<td id="S6.T22.2.2.13.11.12" class="ltx_td ltx_align_center">(0.019)</td>
<td id="S6.T22.2.2.13.11.13" class="ltx_td ltx_align_center">(0.013)</td>
</tr>
<tr id="S6.T22.2.2.14.12" class="ltx_tr">
<th id="S6.T22.2.2.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="7"><span id="S6.T22.2.2.14.12.1.1" class="ltx_text">INR</span></th>
<th id="S6.T22.2.2.14.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">SIREN+</th>
<td id="S6.T22.2.2.14.12.3" class="ltx_td ltx_align_center ltx_border_t">0.085</td>
<td id="S6.T22.2.2.14.12.4" class="ltx_td ltx_align_center ltx_border_t">0.504</td>
<td id="S6.T22.2.2.14.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.226</td>
<td id="S6.T22.2.2.14.12.6" class="ltx_td ltx_align_center ltx_border_t">0.007</td>
<td id="S6.T22.2.2.14.12.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T22.2.2.14.12.7.1" class="ltx_text ltx_font_bold">0.178</span></td>
<td id="S6.T22.2.2.14.12.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.106</td>
<td id="S6.T22.2.2.14.12.9" class="ltx_td ltx_align_center ltx_border_t">0.008</td>
<td id="S6.T22.2.2.14.12.10" class="ltx_td ltx_align_center ltx_border_t">0.270</td>
<td id="S6.T22.2.2.14.12.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.123</td>
<td id="S6.T22.2.2.14.12.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T22.2.2.14.12.12.1" class="ltx_text ltx_font_bold">0.017</span></td>
<td id="S6.T22.2.2.14.12.13" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T22.2.2.14.12.13.1" class="ltx_text ltx_font_bold">0.368</span></td>
<td id="S6.T22.2.2.14.12.14" class="ltx_td ltx_align_center ltx_border_t">0.270</td>
</tr>
<tr id="S6.T22.2.2.15.13" class="ltx_tr">
<th id="S6.T22.2.2.15.13.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.15.13.2" class="ltx_td ltx_align_center">(0.009)</td>
<td id="S6.T22.2.2.15.13.3" class="ltx_td ltx_align_center">(0.034)</td>
<td id="S6.T22.2.2.15.13.4" class="ltx_td ltx_align_center ltx_border_r">(0.030)</td>
<td id="S6.T22.2.2.15.13.5" class="ltx_td ltx_align_center">(0.002)</td>
<td id="S6.T22.2.2.15.13.6" class="ltx_td ltx_align_center">(0.090)</td>
<td id="S6.T22.2.2.15.13.7" class="ltx_td ltx_align_center ltx_border_r">(0.018)</td>
<td id="S6.T22.2.2.15.13.8" class="ltx_td ltx_align_center">(0.003)</td>
<td id="S6.T22.2.2.15.13.9" class="ltx_td ltx_align_center">(0.023)</td>
<td id="S6.T22.2.2.15.13.10" class="ltx_td ltx_align_center ltx_border_r">(0.035)</td>
<td id="S6.T22.2.2.15.13.11" class="ltx_td ltx_align_center">(0.001)</td>
<td id="S6.T22.2.2.15.13.12" class="ltx_td ltx_align_center">(0.019)</td>
<td id="S6.T22.2.2.15.13.13" class="ltx_td ltx_align_center">(0.014)</td>
</tr>
<tr id="S6.T22.2.2.16.14" class="ltx_tr">
<th id="S6.T22.2.2.16.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HN+SIREN</th>
<td id="S6.T22.2.2.16.14.2" class="ltx_td ltx_align_center">0.077</td>
<td id="S6.T22.2.2.16.14.3" class="ltx_td ltx_align_center">0.516</td>
<td id="S6.T22.2.2.16.14.4" class="ltx_td ltx_align_center ltx_border_r">0.210</td>
<td id="S6.T22.2.2.16.14.5" class="ltx_td ltx_align_center">0.010</td>
<td id="S6.T22.2.2.16.14.6" class="ltx_td ltx_align_center">0.266</td>
<td id="S6.T22.2.2.16.14.7" class="ltx_td ltx_align_center ltx_border_r">0.119</td>
<td id="S6.T22.2.2.16.14.8" class="ltx_td ltx_align_center">0.013</td>
<td id="S6.T22.2.2.16.14.9" class="ltx_td ltx_align_center">0.354</td>
<td id="S6.T22.2.2.16.14.10" class="ltx_td ltx_align_center ltx_border_r">0.138</td>
<td id="S6.T22.2.2.16.14.11" class="ltx_td ltx_align_center">0.024</td>
<td id="S6.T22.2.2.16.14.12" class="ltx_td ltx_align_center">0.418</td>
<td id="S6.T22.2.2.16.14.13" class="ltx_td ltx_align_center">0.332</td>
</tr>
<tr id="S6.T22.2.2.17.15" class="ltx_tr">
<th id="S6.T22.2.2.17.15.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.17.15.2" class="ltx_td ltx_align_center">(0.009)</td>
<td id="S6.T22.2.2.17.15.3" class="ltx_td ltx_align_center">(0.011)</td>
<td id="S6.T22.2.2.17.15.4" class="ltx_td ltx_align_center ltx_border_r">(0.029)</td>
<td id="S6.T22.2.2.17.15.5" class="ltx_td ltx_align_center">(0.005)</td>
<td id="S6.T22.2.2.17.15.6" class="ltx_td ltx_align_center">(0.077)</td>
<td id="S6.T22.2.2.17.15.7" class="ltx_td ltx_align_center ltx_border_r">(0.035)</td>
<td id="S6.T22.2.2.17.15.8" class="ltx_td ltx_align_center">(0.006)</td>
<td id="S6.T22.2.2.17.15.9" class="ltx_td ltx_align_center">(0.070)</td>
<td id="S6.T22.2.2.17.15.10" class="ltx_td ltx_align_center ltx_border_r">(0.043)</td>
<td id="S6.T22.2.2.17.15.11" class="ltx_td ltx_align_center">(0.002)</td>
<td id="S6.T22.2.2.17.15.12" class="ltx_td ltx_align_center">(0.026)</td>
<td id="S6.T22.2.2.17.15.13" class="ltx_td ltx_align_center">(0.023)</td>
</tr>
<tr id="S6.T22.2.2.18.16" class="ltx_tr">
<th id="S6.T22.2.2.18.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mod-SIREN</th>
<td id="S6.T22.2.2.18.16.2" class="ltx_td ltx_align_center"><span id="S6.T22.2.2.18.16.2.1" class="ltx_text ltx_font_bold">0.070</span></td>
<td id="S6.T22.2.2.18.16.3" class="ltx_td ltx_align_center">0.480</td>
<td id="S6.T22.2.2.18.16.4" class="ltx_td ltx_align_center ltx_border_r">0.214</td>
<td id="S6.T22.2.2.18.16.5" class="ltx_td ltx_align_center">0.007</td>
<td id="S6.T22.2.2.18.16.6" class="ltx_td ltx_align_center">0.210</td>
<td id="S6.T22.2.2.18.16.7" class="ltx_td ltx_align_center ltx_border_r">0.100</td>
<td id="S6.T22.2.2.18.16.8" class="ltx_td ltx_align_center">0.010</td>
<td id="S6.T22.2.2.18.16.9" class="ltx_td ltx_align_center">0.276</td>
<td id="S6.T22.2.2.18.16.10" class="ltx_td ltx_align_center ltx_border_r">0.121</td>
<td id="S6.T22.2.2.18.16.11" class="ltx_td ltx_align_center">0.018</td>
<td id="S6.T22.2.2.18.16.12" class="ltx_td ltx_align_center">0.378</td>
<td id="S6.T22.2.2.18.16.13" class="ltx_td ltx_align_center">0.286</td>
</tr>
<tr id="S6.T22.2.2.19.17" class="ltx_tr">
<th id="S6.T22.2.2.19.17.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T22.2.2.19.17.2" class="ltx_td ltx_align_center">(0.007)</td>
<td id="S6.T22.2.2.19.17.3" class="ltx_td ltx_align_center">(0.016)</td>
<td id="S6.T22.2.2.19.17.4" class="ltx_td ltx_align_center ltx_border_r">(0.036)</td>
<td id="S6.T22.2.2.19.17.5" class="ltx_td ltx_align_center">(0.002)</td>
<td id="S6.T22.2.2.19.17.6" class="ltx_td ltx_align_center">(0.010)</td>
<td id="S6.T22.2.2.19.17.7" class="ltx_td ltx_align_center ltx_border_r">(0.016)</td>
<td id="S6.T22.2.2.19.17.8" class="ltx_td ltx_align_center">(0.010)</td>
<td id="S6.T22.2.2.19.17.9" class="ltx_td ltx_align_center">(0.047)</td>
<td id="S6.T22.2.2.19.17.10" class="ltx_td ltx_align_center ltx_border_r">(0.072)</td>
<td id="S6.T22.2.2.19.17.11" class="ltx_td ltx_align_center">(0.002)</td>
<td id="S6.T22.2.2.19.17.12" class="ltx_td ltx_align_center">(0.029)</td>
<td id="S6.T22.2.2.19.17.13" class="ltx_td ltx_align_center">(0.023)</td>
</tr>
<tr id="S6.T22.2.2.20.18" class="ltx_tr">
<th id="S6.T22.2.2.20.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MADS</th>
<td id="S6.T22.2.2.20.18.2" class="ltx_td ltx_align_center">0.072</td>
<td id="S6.T22.2.2.20.18.3" class="ltx_td ltx_align_center"><span id="S6.T22.2.2.20.18.3.1" class="ltx_text ltx_font_bold">0.458</span></td>
<td id="S6.T22.2.2.20.18.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T22.2.2.20.18.4.1" class="ltx_text ltx_font_bold">0.202</span></td>
<td id="S6.T22.2.2.20.18.5" class="ltx_td ltx_align_center"><span id="S6.T22.2.2.20.18.5.1" class="ltx_text ltx_font_bold">0.005</span></td>
<td id="S6.T22.2.2.20.18.6" class="ltx_td ltx_align_center">0.186</td>
<td id="S6.T22.2.2.20.18.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T22.2.2.20.18.7.1" class="ltx_text ltx_font_bold">0.072</span></td>
<td id="S6.T22.2.2.20.18.8" class="ltx_td ltx_align_center"><span id="S6.T22.2.2.20.18.8.1" class="ltx_text ltx_font_bold">0.006</span></td>
<td id="S6.T22.2.2.20.18.9" class="ltx_td ltx_align_center"><span id="S6.T22.2.2.20.18.9.1" class="ltx_text ltx_font_bold">0.252</span></td>
<td id="S6.T22.2.2.20.18.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T22.2.2.20.18.10.1" class="ltx_text ltx_font_bold">0.082</span></td>
<td id="S6.T22.2.2.20.18.11" class="ltx_td ltx_align_center">0.018</td>
<td id="S6.T22.2.2.20.18.12" class="ltx_td ltx_align_center">0.372</td>
<td id="S6.T22.2.2.20.18.13" class="ltx_td ltx_align_center">0.276</td>
</tr>
<tr id="S6.T22.2.2.21.19" class="ltx_tr">
<th id="S6.T22.2.2.21.19.1" class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_r"></th>
<th id="S6.T22.2.2.21.19.2" class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_r"></th>
<td id="S6.T22.2.2.21.19.3" class="ltx_td ltx_align_center ltx_border_bb">(0.012)</td>
<td id="S6.T22.2.2.21.19.4" class="ltx_td ltx_align_center ltx_border_bb">(0.016)</td>
<td id="S6.T22.2.2.21.19.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">(0.028)</td>
<td id="S6.T22.2.2.21.19.6" class="ltx_td ltx_align_center ltx_border_bb">(0.000)</td>
<td id="S6.T22.2.2.21.19.7" class="ltx_td ltx_align_center ltx_border_bb">(0.005)</td>
<td id="S6.T22.2.2.21.19.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">(0.003)</td>
<td id="S6.T22.2.2.21.19.9" class="ltx_td ltx_align_center ltx_border_bb">(0.001)</td>
<td id="S6.T22.2.2.21.19.10" class="ltx_td ltx_align_center ltx_border_bb">(0.011)</td>
<td id="S6.T22.2.2.21.19.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">(0.005)</td>
<td id="S6.T22.2.2.21.19.12" class="ltx_td ltx_align_center ltx_border_bb">(0.001)</td>
<td id="S6.T22.2.2.21.19.13" class="ltx_td ltx_align_center ltx_border_bb">(0.018)</td>
<td id="S6.T22.2.2.21.19.14" class="ltx_td ltx_align_center ltx_border_bb">(0.013)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Application: Constrained Market Scenarios Generation </h5>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">Synthetic time-series are extremely useful to test hypotheses and algorithms before employing them in real settings, especially for unseen and counterfactual scenarios. For instance, the US Federal Reserve publishes synthetic market stress scenarios given by the constrained time series for financial institutions to assess their performance in hypothetical recessionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx71" title="" class="ltx_ref">fed</a>]</cite>. We refer to the constrained time-series generation problem as the problem of generating synthetic time-series that are statistically similar to historical times series while matching some input constraintsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx50" title="" class="ltx_ref">DLAG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>, <a href="#bib.bibx212" title="" class="ltx_ref">XZF<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>, <a href="#bib.bibx86" title="" class="ltx_ref">GSLO<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>.</p>
</div>
<div id="S6.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p2.1" class="ltx_p">Existing work that employs deep generative models attempts to capture the statistical data properties and temporal dynamics of time-series, neglecting additional requirements, such as input constraints. These constraints are often introduced by re-training the existing generative models, and penalizing them proportionally to the mass they allocate to invalid dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx186" title="" class="ltx_ref">TK21</a>, <a href="#bib.bibx50" title="" class="ltx_ref">DLAG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>, <a href="#bib.bibx86" title="" class="ltx_ref">GSLO<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>, <a href="#bib.bibx212" title="" class="ltx_ref">XZF<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite>. Other works consider unconstrained generative models to generate synthetic markets while rejecting and re-sampling time-series that do not match the constraintsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx158" title="" class="ltx_ref">PWV16b</a>]</cite>.</p>
</div>
<figure id="S6.F23" class="ltx_figure">
<div id="S6.F23.2" class="ltx_block">
<figure id="S6.F23.sf1" class="ltx_figure ltx_align_center"><img src="/html/2401.00081/assets/figures/time/constrained/uncond.png" id="S6.F23.sf1.g1" class="ltx_graphics ltx_img_landscape" width="120" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F23.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F23.sf1.3.2" class="ltx_text" style="font-size:90%;">Unconstrained</span></figcaption>
</figure>
<figure id="S6.F23.sf2" class="ltx_figure ltx_align_center"><img src="/html/2401.00081/assets/figures/time/constrained/soft.png" id="S6.F23.sf2.g1" class="ltx_graphics ltx_img_landscape" width="120" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F23.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F23.sf2.3.2" class="ltx_text" style="font-size:90%;">Trend</span></figcaption>
</figure>
<figure id="S6.F23.sf3" class="ltx_figure ltx_align_center"><img src="/html/2401.00081/assets/figures/time/constrained/close_value.png" id="S6.F23.sf3.g1" class="ltx_graphics ltx_img_landscape" width="120" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F23.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S6.F23.sf3.3.2" class="ltx_text" style="font-size:90%;">Fixed value</span></figcaption>
</figure>
<figure id="S6.F23.sf4" class="ltx_figure ltx_align_center"><img src="/html/2401.00081/assets/figures/time/constrained/global_min.png" id="S6.F23.sf4.g1" class="ltx_graphics ltx_img_landscape" width="120" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F23.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S6.F23.sf4.3.2" class="ltx_text" style="font-size:90%;">Global min</span></figcaption>
</figure>
<figure id="S6.F23.sf5" class="ltx_figure ltx_align_center"><img src="/html/2401.00081/assets/figures/time/constrained/multi_variate.png" id="S6.F23.sf5.g1" class="ltx_graphics ltx_img_landscape" width="120" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F23.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S6.F23.sf5.3.2" class="ltx_text" style="font-size:90%;">Multivariate</span></figcaption>
</figure>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F23.5.1.1" class="ltx_text" style="font-size:90%;">Figure 23</span>: </span><span id="S6.F23.6.2" class="ltx_text" style="font-size:90%;">An example of synthetic stock market time-series under different constraints: (a) unconstrained generation; (b) a time-series following a trend constraint; (c) the final value of the TS has to hold a specific value; (d) the global minimum must be at a given time point; (e) multi-variate TS where the <span id="S6.F23.6.2.1" class="ltx_text ltx_font_italic">High</span> and <span id="S6.F23.6.2.2" class="ltx_text ltx_font_italic">Low</span> dimensions have the maximum and minimum values, respectively.
</span></figcaption>
</figure>
<div id="S6.SS1.SSS0.Px3.p3" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p3.1" class="ltx_p">A formal definition of constrained time-series generation is introduced inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">CGBV23</a>]</cite>. This work divides the constraints in <span id="S6.SS1.SSS0.Px3.p3.1.1" class="ltx_text ltx_font_italic">Soft</span> and <span id="S6.SS1.SSS0.Px3.p3.1.2" class="ltx_text ltx_font_italic">Hard</span> constraints, and additionally it divides them between <span id="S6.SS1.SSS0.Px3.p3.1.3" class="ltx_text ltx_font_italic">Global</span> and <span id="S6.SS1.SSS0.Px3.p3.1.4" class="ltx_text ltx_font_italic">Local</span> constraints. <span id="S6.SS1.SSS0.Px3.p3.1.5" class="ltx_text ltx_font_italic">Soft</span> constraints optimize the time-series to minimize a constraint score (i.e., minimize the distance between the time-series and the constraint), and do not require sample rejection. <span id="S6.SS1.SSS0.Px3.p3.1.6" class="ltx_text ltx_font_italic">Hard</span> constraints require the time-series to exactly match the input-constraints, and a time-series can be rejected if it does not respect a constraint.
Additional, <span id="S6.SS1.SSS0.Px3.p3.1.7" class="ltx_text ltx_font_italic">Global</span> constraints compare across all the points in the time-series, while <span id="S6.SS1.SSS0.Px3.p3.1.8" class="ltx_text ltx_font_italic">Local</span> constraints focus on specific sub-sections of the input time-series.
This work proposes four different approaches to tackle the constrained generative problem. It starts from a constrained-optimization (COP) framework, and then it proposes three different variant of denoising diffusion models.
The COP framework provides to the user the possibility to specify any constraints, and generate synthetic time-series starting from random noise or existing time-series. This method explicitly includes also all the statistical data properties as constraints, e.g., auto-correlation and returns for financial time-series.
Thus, it enables the users to constrain the time-series and also to control their statistical properties.
Instead, the diffusion models learn the statistical data properties directly from input data, and they can integrate additional constraints during training or inference. In particular, one promising diffusion model, called <span id="S6.SS1.SSS0.Px3.p3.1.9" class="ltx_text ltx_font_italic">Guided-DiffTime</span>, shows the ability to incorporate any differentiable constraints into the sampling procedure. This model does not require to be re-trained when incorporating new constraints. The proposed approach outperform existing state-of-art benchmarks under different quantitative and qualitative metrics.</p>
</div>
<div id="S6.SS1.SSS0.Px3.p4" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p4.1" class="ltx_p">FigureÂ <a href="#S6.F23" title="Figure 23 â€£ Application: Constrained Market Scenarios Generation â€£ 6.1 Generation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">23</span></a> shows an example of generated time series from the work inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">CGBV23</a>]</cite>. The figure shows the model ability to generate multiple different scenarios which can be used to further study and test investment strategies, and perform stress tests. To evaluate the model performance upon different constraints, the authors introduce several new metrics: the <span id="S6.SS1.SSS0.Px3.p4.1.1" class="ltx_text ltx_font_bold">L2 distance</span> which measures how much the synthetic data follows a trend <span id="S6.SS1.SSS0.Px3.p4.1.2" class="ltx_text ltx_font_italic">soft</span>-constraint by evaluating the distance between the TS and the trend constraint using L2 norm; the <span id="S6.SS1.SSS0.Px3.p4.1.3" class="ltx_text ltx_font_bold">satisfaction rate</span> which measures the percentage of time a synthetic TS meets the input <span id="S6.SS1.SSS0.Px3.p4.1.4" class="ltx_text ltx_font_italic">hard</span>-constraints; and the <span id="S6.SS1.SSS0.Px3.p4.1.5" class="ltx_text ltx_font_bold">inference time</span> and <span id="S6.SS1.SSS0.Px3.p4.1.6" class="ltx_text ltx_font_bold">fine-tuning time</span>, which measure the average time required to generate a new valid sample, and the time required to enforce constraints over invalid samples by fine-tuning them. The proposed approaches establish a new state-of-art performance on constrained time-series generation. We report the performance for the trend soft-constraint in TableÂ <a href="#S6.T24" title="Table 24 â€£ Application: Constrained Market Scenarios Generation â€£ 6.1 Generation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">24</span></a>, while additional results can be found in the original paperÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">CGBV23</a>]</cite>.</p>
</div>
<figure id="S6.T24" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T24.2.1.1" class="ltx_text" style="font-size:90%;">Table 24</span>: </span><span id="S6.T24.3.2" class="ltx_text" style="font-size:90%;">Soft Constraints (Trend) Time-Series Generation (Bold indicates best performance).</span></figcaption>
<div id="S6.T24.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:260.2pt;height:80.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-44.7pt,13.8pt) scale(0.744122917541588,0.744122917541588) ;">
<table id="S6.T24.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T24.4.1.1.1" class="ltx_tr">
<th id="S6.T24.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Algo</th>
<th id="S6.T24.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Discr-Score</th>
<th id="S6.T24.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Pred-Score</th>
<th id="S6.T24.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Inference-Time</th>
<th id="S6.T24.4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">L2 Distance</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T24.4.1.2.1" class="ltx_tr">
<th id="S6.T24.4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">COP (Ours)</th>
<td id="S6.T24.4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T24.4.1.2.1.2.1" class="ltx_text ltx_font_bold">0.01Â±0.01</span></td>
<td id="S6.T24.4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T24.4.1.2.1.3.1" class="ltx_text ltx_font_bold">0.20Â±0.00</span></td>
<td id="S6.T24.4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.73Â±0.05</td>
<td id="S6.T24.4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T24.4.1.2.1.5.1" class="ltx_text ltx_font_bold">0.015Â±0</span></td>
</tr>
<tr id="S6.T24.4.1.3.2" class="ltx_tr">
<th id="S6.T24.4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">DiffTime (Ours)</th>
<td id="S6.T24.4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T24.4.1.3.2.2.1" class="ltx_text ltx_font_bold">0.01Â±0.01</span></td>
<td id="S6.T24.4.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T24.4.1.3.2.3.1" class="ltx_text ltx_font_bold">0.20Â±0.00</span></td>
<td id="S6.T24.4.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">0.02Â±0.00</td>
<td id="S6.T24.4.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r">0.018Â±0</td>
</tr>
<tr id="S6.T24.4.1.4.3" class="ltx_tr">
<th id="S6.T24.4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">GT-GAN</th>
<td id="S6.T24.4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">0.04Â±0.03</td>
<td id="S6.T24.4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">0.22Â±0.00</td>
<td id="S6.T24.4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T24.4.1.4.3.4.1" class="ltx_text ltx_font_bold">0.00Â±0.00</span></td>
<td id="S6.T24.4.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r">1.378Â±2</td>
</tr>
<tr id="S6.T24.4.1.5.4" class="ltx_tr">
<th id="S6.T24.4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">TimeGAN</th>
<td id="S6.T24.4.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">0.02Â±0.02</td>
<td id="S6.T24.4.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T24.4.1.5.4.3.1" class="ltx_text ltx_font_bold">0.20Â±0.00</span></td>
<td id="S6.T24.4.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T24.4.1.5.4.4.1" class="ltx_text ltx_font_bold">0.00Â±0.00</span></td>
<td id="S6.T24.4.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r">0.073Â±0</td>
</tr>
<tr id="S6.T24.4.1.6.5" class="ltx_tr">
<th id="S6.T24.4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">RCGAN</th>
<td id="S6.T24.4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.02Â±0.01</td>
<td id="S6.T24.4.1.6.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T24.4.1.6.5.3.1" class="ltx_text ltx_font_bold">0.20Â±0.00</span></td>
<td id="S6.T24.4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T24.4.1.6.5.4.1" class="ltx_text ltx_font_bold">0.00Â±0.00</span></td>
<td id="S6.T24.4.1.6.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.071Â±0</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S6.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Application: Stylized Generation of Financial Time Series</h5>

<div id="S6.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p1.1" class="ltx_p">When it comes to generating realistic financial time series data, traditional generative models and simulation approaches often struggle to produce accurate representations of real-world market dynamics. Mainly, they fail to satisfy specific statistical properties, known as stylized facts, which are essential for accurately modeling financial phenomena. Stylized facts encompass various characteristics observed in financial time series, such as volatility clustering, fat-tailed distributions, and long-range dependencies. Ensuring that generative models and simulations satisfy all stylized facts simultaneously can be a challenging and computationally intensive task.</p>
</div>
<div id="S6.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p2.1" class="ltx_p">To overcome the limitations of traditional generative models and simulations, style transfer techniques have been proposed to enhance the realism of financial time series dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx63" title="" class="ltx_ref">ELV22</a>]</cite>. Style transfer, a concept originally developed in the field of computer vision, involves modifying the style or appearance of an image while preserving its content. In the context of financial time series, style transfer techniques can be employed to enhance synthetic data by imbuing it with specific stylized facts observed in real financial markets. By transferring the statistical characteristics and patterns from real financial time series to synthetic data, style transfer can bridge the gap between simulated and real-world data, resulting in more realistic representations of financial dynamics. This approach offers a promising avenue for creating reliable financial simulations that not only capture the overall structure and trends but also satisfy critical stylized facts.</p>
</div>
<div id="S6.SS1.SSS0.Px4.p3" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p3.1" class="ltx_p">Specifically, inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx63" title="" class="ltx_ref">ELV22</a>]</cite>, a style transfer technique called <em id="S6.SS1.SSS0.Px4.p3.1.1" class="ltx_emph ltx_font_italic">StyleTime</em> was introduced so to stylize synthetic time series data with statistical properties of real time series data. The technique was evaluated along three different dimensions:</p>
<ol id="S6.I2" class="ltx_enumerate">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p"><em id="S6.I2.i1.p1.1.1" class="ltx_emph ltx_font_italic">Fidelity</em>: Synthetic data fidelity is quantified using precision/recall metrics fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx170" title="" class="ltx_ref">SBL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite> and by using the TSTR frameworkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx59" title="" class="ltx_ref">EHR17a</a>]</cite> to assess the predictive utility of the synthetic time series.</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p"><em id="S6.I2.i2.p1.1.1" class="ltx_emph ltx_font_italic">Predictive utility</em>: Stylized synthetic data is used to augment a historical time series (training) dataset and the predictive utility is measured by evaluating the percentage of improvement in time series forecasting in terms of MAE.</p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S6.I2.i3.p1" class="ltx_para">
<p id="S6.I2.i3.p1.2" class="ltx_p"><em id="S6.I2.i3.p1.2.1" class="ltx_emph ltx_font_italic">Authenticity</em>: An authenticity score, proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">AvBSvdS21</a>]</cite>, is used as a means to assess similarity of the generated synthetic data from the original training data. A low authenticity score (<math id="S6.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="A=0" display="inline"><semantics id="S6.I2.i3.p1.1.m1.1a"><mrow id="S6.I2.i3.p1.1.m1.1.1" xref="S6.I2.i3.p1.1.m1.1.1.cmml"><mi id="S6.I2.i3.p1.1.m1.1.1.2" xref="S6.I2.i3.p1.1.m1.1.1.2.cmml">A</mi><mo id="S6.I2.i3.p1.1.m1.1.1.1" xref="S6.I2.i3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S6.I2.i3.p1.1.m1.1.1.3" xref="S6.I2.i3.p1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i3.p1.1.m1.1b"><apply id="S6.I2.i3.p1.1.m1.1.1.cmml" xref="S6.I2.i3.p1.1.m1.1.1"><eq id="S6.I2.i3.p1.1.m1.1.1.1.cmml" xref="S6.I2.i3.p1.1.m1.1.1.1"></eq><ci id="S6.I2.i3.p1.1.m1.1.1.2.cmml" xref="S6.I2.i3.p1.1.m1.1.1.2">ğ´</ci><cn type="integer" id="S6.I2.i3.p1.1.m1.1.1.3.cmml" xref="S6.I2.i3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i3.p1.1.m1.1c">A=0</annotation></semantics></math>) means that the synthetic data is an exact replica of the training data, while a high authenticity score <math id="S6.I2.i3.p1.2.m2.1" class="ltx_Math" alttext="(A=1)" display="inline"><semantics id="S6.I2.i3.p1.2.m2.1a"><mrow id="S6.I2.i3.p1.2.m2.1.1.1" xref="S6.I2.i3.p1.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S6.I2.i3.p1.2.m2.1.1.1.2" xref="S6.I2.i3.p1.2.m2.1.1.1.1.cmml">(</mo><mrow id="S6.I2.i3.p1.2.m2.1.1.1.1" xref="S6.I2.i3.p1.2.m2.1.1.1.1.cmml"><mi id="S6.I2.i3.p1.2.m2.1.1.1.1.2" xref="S6.I2.i3.p1.2.m2.1.1.1.1.2.cmml">A</mi><mo id="S6.I2.i3.p1.2.m2.1.1.1.1.1" xref="S6.I2.i3.p1.2.m2.1.1.1.1.1.cmml">=</mo><mn id="S6.I2.i3.p1.2.m2.1.1.1.1.3" xref="S6.I2.i3.p1.2.m2.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S6.I2.i3.p1.2.m2.1.1.1.3" xref="S6.I2.i3.p1.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i3.p1.2.m2.1b"><apply id="S6.I2.i3.p1.2.m2.1.1.1.1.cmml" xref="S6.I2.i3.p1.2.m2.1.1.1"><eq id="S6.I2.i3.p1.2.m2.1.1.1.1.1.cmml" xref="S6.I2.i3.p1.2.m2.1.1.1.1.1"></eq><ci id="S6.I2.i3.p1.2.m2.1.1.1.1.2.cmml" xref="S6.I2.i3.p1.2.m2.1.1.1.1.2">ğ´</ci><cn type="integer" id="S6.I2.i3.p1.2.m2.1.1.1.1.3.cmml" xref="S6.I2.i3.p1.2.m2.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i3.p1.2.m2.1c">(A=1)</annotation></semantics></math> means that the synthetic data differs a lot from the original training samples.</p>
</div>
</li>
</ol>
<p id="S6.SS1.SSS0.Px4.p3.2" class="ltx_p">Results inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx63" title="" class="ltx_ref">ELV22</a>]</cite> indicate that by stylizing synthetic time series data with the statistical properties of historical data, we can see improvement across all of these metrics. We repeat the results for Google stock data here for completeness in TableÂ <a href="#S6.T25" title="Table 25 â€£ Application: Stylized Generation of Financial Time Series â€£ 6.1 Generation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">25</span></a>.</p>
</div>
<figure id="S6.T25" class="ltx_table">
<div id="S6.T25.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:77pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.5pt,6.5pt) scale(0.85606258421988,0.85606258421988) ;">
<table id="S6.T25.12.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T25.12.12.13.1" class="ltx_tr">
<th id="S6.T25.12.12.13.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S6.T25.12.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2"><span id="S6.T25.12.12.13.1.2.1" class="ltx_text ltx_font_bold">Fidelity</span></th>
<th id="S6.T25.12.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T25.12.12.13.1.3.1" class="ltx_text ltx_font_bold">Predictive Utility</span></th>
<th id="S6.T25.12.12.13.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T25.12.12.13.1.4.1" class="ltx_text ltx_font_bold">Authenticity</span></th>
</tr>
<tr id="S6.T25.12.12.14.2" class="ltx_tr">
<th id="S6.T25.12.12.14.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S6.T25.12.12.14.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T25.12.12.14.2.2.1" class="ltx_text ltx_font_italic">F-Score</span></th>
<th id="S6.T25.12.12.14.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T25.12.12.14.2.3.1" class="ltx_text ltx_font_italic">TSTR MAE</span></th>
<th id="S6.T25.12.12.14.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T25.12.12.14.2.4.1" class="ltx_text ltx_font_italic">Augmentation MAE</span></th>
<th id="S6.T25.12.12.14.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T25.12.12.14.2.5.1" class="ltx_text ltx_font_italic">Authenticity Score</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T25.4.4.4" class="ltx_tr">
<th id="S6.T25.4.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S6.T25.4.4.4.5.1" class="ltx_text ltx_font_bold">Fourier Flows</span></th>
<td id="S6.T25.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.1.1.1.1.m1.1" class="ltx_Math" alttext="0.9813\pm 0.0010" display="inline"><semantics id="S6.T25.1.1.1.1.m1.1a"><mrow id="S6.T25.1.1.1.1.m1.1.1" xref="S6.T25.1.1.1.1.m1.1.1.cmml"><mn id="S6.T25.1.1.1.1.m1.1.1.2" xref="S6.T25.1.1.1.1.m1.1.1.2.cmml">0.9813</mn><mo id="S6.T25.1.1.1.1.m1.1.1.1" xref="S6.T25.1.1.1.1.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.1.1.1.1.m1.1.1.3" xref="S6.T25.1.1.1.1.m1.1.1.3.cmml">0.0010</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.1.1.1.1.m1.1b"><apply id="S6.T25.1.1.1.1.m1.1.1.cmml" xref="S6.T25.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T25.1.1.1.1.m1.1.1.1.cmml" xref="S6.T25.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.1.1.1.1.m1.1.1.2.cmml" xref="S6.T25.1.1.1.1.m1.1.1.2">0.9813</cn><cn type="float" id="S6.T25.1.1.1.1.m1.1.1.3.cmml" xref="S6.T25.1.1.1.1.m1.1.1.3">0.0010</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.1.1.1.1.m1.1c">0.9813\pm 0.0010</annotation></semantics></math></td>
<td id="S6.T25.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.2.2.2.2.m1.1" class="ltx_Math" alttext="0.0079\pm 0.0022" display="inline"><semantics id="S6.T25.2.2.2.2.m1.1a"><mrow id="S6.T25.2.2.2.2.m1.1.1" xref="S6.T25.2.2.2.2.m1.1.1.cmml"><mn id="S6.T25.2.2.2.2.m1.1.1.2" xref="S6.T25.2.2.2.2.m1.1.1.2.cmml">0.0079</mn><mo id="S6.T25.2.2.2.2.m1.1.1.1" xref="S6.T25.2.2.2.2.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.2.2.2.2.m1.1.1.3" xref="S6.T25.2.2.2.2.m1.1.1.3.cmml">0.0022</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.2.2.2.2.m1.1b"><apply id="S6.T25.2.2.2.2.m1.1.1.cmml" xref="S6.T25.2.2.2.2.m1.1.1"><csymbol cd="latexml" id="S6.T25.2.2.2.2.m1.1.1.1.cmml" xref="S6.T25.2.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.2.2.2.2.m1.1.1.2.cmml" xref="S6.T25.2.2.2.2.m1.1.1.2">0.0079</cn><cn type="float" id="S6.T25.2.2.2.2.m1.1.1.3.cmml" xref="S6.T25.2.2.2.2.m1.1.1.3">0.0022</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.2.2.2.2.m1.1c">0.0079\pm 0.0022</annotation></semantics></math></td>
<td id="S6.T25.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.3.3.3.3.m1.1" class="ltx_Math" alttext="0.0057\pm 0.0011" display="inline"><semantics id="S6.T25.3.3.3.3.m1.1a"><mrow id="S6.T25.3.3.3.3.m1.1.1" xref="S6.T25.3.3.3.3.m1.1.1.cmml"><mn id="S6.T25.3.3.3.3.m1.1.1.2" xref="S6.T25.3.3.3.3.m1.1.1.2.cmml">0.0057</mn><mo id="S6.T25.3.3.3.3.m1.1.1.1" xref="S6.T25.3.3.3.3.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.3.3.3.3.m1.1.1.3" xref="S6.T25.3.3.3.3.m1.1.1.3.cmml">0.0011</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.3.3.3.3.m1.1b"><apply id="S6.T25.3.3.3.3.m1.1.1.cmml" xref="S6.T25.3.3.3.3.m1.1.1"><csymbol cd="latexml" id="S6.T25.3.3.3.3.m1.1.1.1.cmml" xref="S6.T25.3.3.3.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.3.3.3.3.m1.1.1.2.cmml" xref="S6.T25.3.3.3.3.m1.1.1.2">0.0057</cn><cn type="float" id="S6.T25.3.3.3.3.m1.1.1.3.cmml" xref="S6.T25.3.3.3.3.m1.1.1.3">0.0011</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.3.3.3.3.m1.1c">0.0057\pm 0.0011</annotation></semantics></math></td>
<td id="S6.T25.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.4.4.4.4.m1.1" class="ltx_Math" alttext="0.9760\pm 0.0025" display="inline"><semantics id="S6.T25.4.4.4.4.m1.1a"><mrow id="S6.T25.4.4.4.4.m1.1.1" xref="S6.T25.4.4.4.4.m1.1.1.cmml"><mn id="S6.T25.4.4.4.4.m1.1.1.2" xref="S6.T25.4.4.4.4.m1.1.1.2.cmml">0.9760</mn><mo id="S6.T25.4.4.4.4.m1.1.1.1" xref="S6.T25.4.4.4.4.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.4.4.4.4.m1.1.1.3" xref="S6.T25.4.4.4.4.m1.1.1.3.cmml">0.0025</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.4.4.4.4.m1.1b"><apply id="S6.T25.4.4.4.4.m1.1.1.cmml" xref="S6.T25.4.4.4.4.m1.1.1"><csymbol cd="latexml" id="S6.T25.4.4.4.4.m1.1.1.1.cmml" xref="S6.T25.4.4.4.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.4.4.4.4.m1.1.1.2.cmml" xref="S6.T25.4.4.4.4.m1.1.1.2">0.9760</cn><cn type="float" id="S6.T25.4.4.4.4.m1.1.1.3.cmml" xref="S6.T25.4.4.4.4.m1.1.1.3">0.0025</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.4.4.4.4.m1.1c">0.9760\pm 0.0025</annotation></semantics></math></td>
</tr>
<tr id="S6.T25.8.8.8" class="ltx_tr">
<th id="S6.T25.8.8.8.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S6.T25.8.8.8.5.1" class="ltx_text ltx_font_bold">Stylized Data (Perturbed)</span></th>
<td id="S6.T25.5.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.5.5.5.1.m1.1" class="ltx_Math" alttext="{\bf 0.9971}\pm{\bf 0.0002}" display="inline"><semantics id="S6.T25.5.5.5.1.m1.1a"><mrow id="S6.T25.5.5.5.1.m1.1.1" xref="S6.T25.5.5.5.1.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.5.5.5.1.m1.1.1.2" xref="S6.T25.5.5.5.1.m1.1.1.2.cmml">0.9971</mn><mo id="S6.T25.5.5.5.1.m1.1.1.1" xref="S6.T25.5.5.5.1.m1.1.1.1.cmml">Â±</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.5.5.5.1.m1.1.1.3" xref="S6.T25.5.5.5.1.m1.1.1.3.cmml">0.0002</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.5.5.5.1.m1.1b"><apply id="S6.T25.5.5.5.1.m1.1.1.cmml" xref="S6.T25.5.5.5.1.m1.1.1"><csymbol cd="latexml" id="S6.T25.5.5.5.1.m1.1.1.1.cmml" xref="S6.T25.5.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.5.5.5.1.m1.1.1.2.cmml" xref="S6.T25.5.5.5.1.m1.1.1.2">0.9971</cn><cn type="float" id="S6.T25.5.5.5.1.m1.1.1.3.cmml" xref="S6.T25.5.5.5.1.m1.1.1.3">0.0002</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.5.5.5.1.m1.1c">{\bf 0.9971}\pm{\bf 0.0002}</annotation></semantics></math></td>
<td id="S6.T25.6.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.6.6.6.2.m1.1" class="ltx_Math" alttext="{\bf 0.0057}\pm{\bf 0.0010}" display="inline"><semantics id="S6.T25.6.6.6.2.m1.1a"><mrow id="S6.T25.6.6.6.2.m1.1.1" xref="S6.T25.6.6.6.2.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.6.6.6.2.m1.1.1.2" xref="S6.T25.6.6.6.2.m1.1.1.2.cmml">0.0057</mn><mo id="S6.T25.6.6.6.2.m1.1.1.1" xref="S6.T25.6.6.6.2.m1.1.1.1.cmml">Â±</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.6.6.6.2.m1.1.1.3" xref="S6.T25.6.6.6.2.m1.1.1.3.cmml">0.0010</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.6.6.6.2.m1.1b"><apply id="S6.T25.6.6.6.2.m1.1.1.cmml" xref="S6.T25.6.6.6.2.m1.1.1"><csymbol cd="latexml" id="S6.T25.6.6.6.2.m1.1.1.1.cmml" xref="S6.T25.6.6.6.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.6.6.6.2.m1.1.1.2.cmml" xref="S6.T25.6.6.6.2.m1.1.1.2">0.0057</cn><cn type="float" id="S6.T25.6.6.6.2.m1.1.1.3.cmml" xref="S6.T25.6.6.6.2.m1.1.1.3">0.0010</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.6.6.6.2.m1.1c">{\bf 0.0057}\pm{\bf 0.0010}</annotation></semantics></math></td>
<td id="S6.T25.7.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.7.7.7.3.m1.1" class="ltx_Math" alttext="{\bf 0.0054}\pm{\bf 0.0004}" display="inline"><semantics id="S6.T25.7.7.7.3.m1.1a"><mrow id="S6.T25.7.7.7.3.m1.1.1" xref="S6.T25.7.7.7.3.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.7.7.7.3.m1.1.1.2" xref="S6.T25.7.7.7.3.m1.1.1.2.cmml">0.0054</mn><mo id="S6.T25.7.7.7.3.m1.1.1.1" xref="S6.T25.7.7.7.3.m1.1.1.1.cmml">Â±</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.7.7.7.3.m1.1.1.3" xref="S6.T25.7.7.7.3.m1.1.1.3.cmml">0.0004</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.7.7.7.3.m1.1b"><apply id="S6.T25.7.7.7.3.m1.1.1.cmml" xref="S6.T25.7.7.7.3.m1.1.1"><csymbol cd="latexml" id="S6.T25.7.7.7.3.m1.1.1.1.cmml" xref="S6.T25.7.7.7.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.7.7.7.3.m1.1.1.2.cmml" xref="S6.T25.7.7.7.3.m1.1.1.2">0.0054</cn><cn type="float" id="S6.T25.7.7.7.3.m1.1.1.3.cmml" xref="S6.T25.7.7.7.3.m1.1.1.3">0.0004</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.7.7.7.3.m1.1c">{\bf 0.0054}\pm{\bf 0.0004}</annotation></semantics></math></td>
<td id="S6.T25.8.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S6.T25.8.8.8.4.m1.1" class="ltx_Math" alttext="{\bf 0.9943}\pm{\bf 0.0017}" display="inline"><semantics id="S6.T25.8.8.8.4.m1.1a"><mrow id="S6.T25.8.8.8.4.m1.1.1" xref="S6.T25.8.8.8.4.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.8.8.8.4.m1.1.1.2" xref="S6.T25.8.8.8.4.m1.1.1.2.cmml">0.9943</mn><mo id="S6.T25.8.8.8.4.m1.1.1.1" xref="S6.T25.8.8.8.4.m1.1.1.1.cmml">Â±</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S6.T25.8.8.8.4.m1.1.1.3" xref="S6.T25.8.8.8.4.m1.1.1.3.cmml">0.0017</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.8.8.8.4.m1.1b"><apply id="S6.T25.8.8.8.4.m1.1.1.cmml" xref="S6.T25.8.8.8.4.m1.1.1"><csymbol cd="latexml" id="S6.T25.8.8.8.4.m1.1.1.1.cmml" xref="S6.T25.8.8.8.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.8.8.8.4.m1.1.1.2.cmml" xref="S6.T25.8.8.8.4.m1.1.1.2">0.9943</cn><cn type="float" id="S6.T25.8.8.8.4.m1.1.1.3.cmml" xref="S6.T25.8.8.8.4.m1.1.1.3">0.0017</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.8.8.8.4.m1.1c">{\bf 0.9943}\pm{\bf 0.0017}</annotation></semantics></math></td>
</tr>
<tr id="S6.T25.12.12.12" class="ltx_tr">
<th id="S6.T25.12.12.12.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S6.T25.12.12.12.5.1" class="ltx_text ltx_font_bold">Stylized Data (Fourier Flows)</span></th>
<td id="S6.T25.9.9.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T25.9.9.9.1.m1.1" class="ltx_Math" alttext="0.9827\pm 0.0099" display="inline"><semantics id="S6.T25.9.9.9.1.m1.1a"><mrow id="S6.T25.9.9.9.1.m1.1.1" xref="S6.T25.9.9.9.1.m1.1.1.cmml"><mn id="S6.T25.9.9.9.1.m1.1.1.2" xref="S6.T25.9.9.9.1.m1.1.1.2.cmml">0.9827</mn><mo id="S6.T25.9.9.9.1.m1.1.1.1" xref="S6.T25.9.9.9.1.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.9.9.9.1.m1.1.1.3" xref="S6.T25.9.9.9.1.m1.1.1.3.cmml">0.0099</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.9.9.9.1.m1.1b"><apply id="S6.T25.9.9.9.1.m1.1.1.cmml" xref="S6.T25.9.9.9.1.m1.1.1"><csymbol cd="latexml" id="S6.T25.9.9.9.1.m1.1.1.1.cmml" xref="S6.T25.9.9.9.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.9.9.9.1.m1.1.1.2.cmml" xref="S6.T25.9.9.9.1.m1.1.1.2">0.9827</cn><cn type="float" id="S6.T25.9.9.9.1.m1.1.1.3.cmml" xref="S6.T25.9.9.9.1.m1.1.1.3">0.0099</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.9.9.9.1.m1.1c">0.9827\pm 0.0099</annotation></semantics></math></td>
<td id="S6.T25.10.10.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T25.10.10.10.2.m1.1" class="ltx_Math" alttext="0.0089\pm 0.0022" display="inline"><semantics id="S6.T25.10.10.10.2.m1.1a"><mrow id="S6.T25.10.10.10.2.m1.1.1" xref="S6.T25.10.10.10.2.m1.1.1.cmml"><mn id="S6.T25.10.10.10.2.m1.1.1.2" xref="S6.T25.10.10.10.2.m1.1.1.2.cmml">0.0089</mn><mo id="S6.T25.10.10.10.2.m1.1.1.1" xref="S6.T25.10.10.10.2.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.10.10.10.2.m1.1.1.3" xref="S6.T25.10.10.10.2.m1.1.1.3.cmml">0.0022</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.10.10.10.2.m1.1b"><apply id="S6.T25.10.10.10.2.m1.1.1.cmml" xref="S6.T25.10.10.10.2.m1.1.1"><csymbol cd="latexml" id="S6.T25.10.10.10.2.m1.1.1.1.cmml" xref="S6.T25.10.10.10.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.10.10.10.2.m1.1.1.2.cmml" xref="S6.T25.10.10.10.2.m1.1.1.2">0.0089</cn><cn type="float" id="S6.T25.10.10.10.2.m1.1.1.3.cmml" xref="S6.T25.10.10.10.2.m1.1.1.3">0.0022</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.10.10.10.2.m1.1c">0.0089\pm 0.0022</annotation></semantics></math></td>
<td id="S6.T25.11.11.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T25.11.11.11.3.m1.1" class="ltx_Math" alttext="0.0058\pm 0.0013" display="inline"><semantics id="S6.T25.11.11.11.3.m1.1a"><mrow id="S6.T25.11.11.11.3.m1.1.1" xref="S6.T25.11.11.11.3.m1.1.1.cmml"><mn id="S6.T25.11.11.11.3.m1.1.1.2" xref="S6.T25.11.11.11.3.m1.1.1.2.cmml">0.0058</mn><mo id="S6.T25.11.11.11.3.m1.1.1.1" xref="S6.T25.11.11.11.3.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.11.11.11.3.m1.1.1.3" xref="S6.T25.11.11.11.3.m1.1.1.3.cmml">0.0013</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.11.11.11.3.m1.1b"><apply id="S6.T25.11.11.11.3.m1.1.1.cmml" xref="S6.T25.11.11.11.3.m1.1.1"><csymbol cd="latexml" id="S6.T25.11.11.11.3.m1.1.1.1.cmml" xref="S6.T25.11.11.11.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.11.11.11.3.m1.1.1.2.cmml" xref="S6.T25.11.11.11.3.m1.1.1.2">0.0058</cn><cn type="float" id="S6.T25.11.11.11.3.m1.1.1.3.cmml" xref="S6.T25.11.11.11.3.m1.1.1.3">0.0013</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.11.11.11.3.m1.1c">0.0058\pm 0.0013</annotation></semantics></math></td>
<td id="S6.T25.12.12.12.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T25.12.12.12.4.m1.1" class="ltx_Math" alttext="0.9879\pm 0.0013" display="inline"><semantics id="S6.T25.12.12.12.4.m1.1a"><mrow id="S6.T25.12.12.12.4.m1.1.1" xref="S6.T25.12.12.12.4.m1.1.1.cmml"><mn id="S6.T25.12.12.12.4.m1.1.1.2" xref="S6.T25.12.12.12.4.m1.1.1.2.cmml">0.9879</mn><mo id="S6.T25.12.12.12.4.m1.1.1.1" xref="S6.T25.12.12.12.4.m1.1.1.1.cmml">Â±</mo><mn id="S6.T25.12.12.12.4.m1.1.1.3" xref="S6.T25.12.12.12.4.m1.1.1.3.cmml">0.0013</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T25.12.12.12.4.m1.1b"><apply id="S6.T25.12.12.12.4.m1.1.1.cmml" xref="S6.T25.12.12.12.4.m1.1.1"><csymbol cd="latexml" id="S6.T25.12.12.12.4.m1.1.1.1.cmml" xref="S6.T25.12.12.12.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T25.12.12.12.4.m1.1.1.2.cmml" xref="S6.T25.12.12.12.4.m1.1.1.2">0.9879</cn><cn type="float" id="S6.T25.12.12.12.4.m1.1.1.3.cmml" xref="S6.T25.12.12.12.4.m1.1.1.3">0.0013</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T25.12.12.12.4.m1.1c">0.9879\pm 0.0013</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T25.14.1.1" class="ltx_text" style="font-size:90%;">Table 25</span>: </span><span id="S6.T25.15.2" class="ltx_text" style="font-size:90%;">Experimental results across fidelity, predictive utility, and authenticity metrics for stylized synthetic time series data for the Google stock. These results are extracted fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx63" title="" class="ltx_ref">ELV22</a>]</cite>; for more insight on how the experiments were conducted and comparison to other benchmarks please reference the original paper. </span></figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Discussion: Uncertainty Quantification in Time Series Augmentation Methods</h5>

<div id="S6.SS1.SSS0.Px5.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px5.p1.1" class="ltx_p">Machine learning models that quantify uncertainty are of paramount importance for financial time series. In particular, uncertainty quantification in time series forecasting applications allows one to reason about the volatility of time series, the probability of extreme events (heavy-tailed phenomena), and the occurrence of a distributional shift. As previously mentioned, a major use-case for synthetic time series data is data augmentation for improving the generalization of supervised learning models, particularly for deep learning models. In most data augmentation formulations, the focus is on devising a data augmentation technique to improve the average predictive performance of a model (e.g., augmenting samples to the training dataset that would reduce the mean-squared error of the model on the test dataset). There are many candidate probabilistic deep learning techniques that can account for predictive uncertainty in supervised learning settings (e.g., variational inferenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx85" title="" class="ltx_ref">Gra11</a>]</cite>, Monte Carlo dropoutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx77" title="" class="ltx_ref">GG16</a>]</cite>, deep ensemblesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx118" title="" class="ltx_ref">LPB17</a>]</cite>, deep Gaussian mixture ensemblesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx62" title="" class="ltx_ref">ELDFV23</a>]</cite>). However, there has been little effort on studying the impact of data augmentation on uncertainty estimates produced by these techniques. For example, does augmentation of synthetic data impact the modelâ€™s ability to reliably account for rare events (i.e., change the tail behavior of predictive model) or reliably detect out-of-distribution inputs (i.e., underestimation of epistemic uncertainty)? Recent works for large-language models have revealed that repetitive training on synthetic examples (based on the distribution of training data) can cause the model to effectively lose its ability to account for heavy-tailed phenomena. An important line of research to consider is making synthetic data augmentation robust, so that important statistical properties of an uncertainty quantifying modelâ€™s predictive distribution remain intact after data augmentation.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Simulation</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">An extremely useful application of synthetic time series concerns the simulation of financial markets. Simulated markets can be used to train and test investment strategies, representing an invaluable alternative to historical market data.
Different from historical data, simulation can provide more variability of the market scenarios reducing possible â€time-period biasâ€ (i.e., overfitting to a particular history that was encountered). Synthetic data can be used to simulate counterfactual market scenarios, where test strategies and algorithms before approaching the real market. Similarly, simulated markets can test the robustness of various deep learning approaches upon temporal covariate shifts. Finally, simulated markets can also react to the presence of any investment strategies, providing a realistic price impact for exogenous ordersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">CJSV23</a>, <a href="#bib.bibx39" title="" class="ltx_ref">CMVB22</a>]</cite>.</p>
</div>
<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Introduction to Multi-Agent Simulation: ABIDES</h5>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p1.1" class="ltx_p">Agent-Based Interactive Discrete Event Simulation environment (ABIDES) serves as an advanced multi-agent system (MAS) specifically for simulating complex financial marketsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">BHB19</a>, <a href="#bib.bibx25" title="" class="ltx_ref">Byr19</a>, <a href="#bib.bibx17" title="" class="ltx_ref">BML<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>. ABIDES offers a highly configurable messaging system as its core engine, enabling individual agents, each representing a market participant, to communicate via routed messages with controlled latency and nanosecond resolution. The system replicates the dynamics of continuous double-auction trading, resembling real-world markets like NASDAQ. A distinguishing feature of ABIDES is its capability to assign a unique trading strategy to each agent, ranging from standard rule-based strategies to sophisticated reinforcement learning-based approaches.</p>
</div>
<div id="S6.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p2.1" class="ltx_p">ABIDESâ€™ architecture permits an in-depth exploration of market dynamics with various agents. Specifically, the exchange agent is designed to handle all transactions, processing buy and sell orders from other market participants. Upon receipt, the exchange agent matches and executes orders, updating the status of the order book. This allows agents to monitor the fluctuations in stock prices and observe the evolution of the order book. ABIDES also facilitates the configuration of an exogenous time series representing the â€œfundamentalâ€ price for each stock, based on the mean-reverting Ornstein-Uhlenbeck process, reflecting the perception of the real worldÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx190" title="" class="ltx_ref">UO30</a>]</cite>. FigureÂ <a href="#S6.F26" title="Figure 26 â€£ Introduction to Multi-Agent Simulation: ABIDES â€£ 6.2 Simulation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">26</span></a> shows the synthetic market generated through ABIDES (orange lines) compared to actual intra-day price on two separate days in history. In such scenarios ABIDES uses 100 interacting background agents, calibrated according to common strategies. We can observe that the price history closely resembles the day in history, with similar statistical properties.</p>
</div>
<figure id="S6.F26" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F26.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.00081/assets/figures/time/background_a9_IBM.png" id="S6.F26.sf1.g1" class="ltx_graphics ltx_img_landscape" width="250" height="187" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F26.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F26.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.00081/assets/figures/time/background_a9_MSFT.png" id="S6.F26.sf2.g1" class="ltx_graphics ltx_img_landscape" width="250" height="187" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F26.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F26.2.1.1" class="ltx_text" style="font-size:90%;">Figure 26</span>: </span><span id="S6.F26.3.2" class="ltx_text" style="font-size:90%;">ABIDES Simulated trades versus historical trades on two days.</span></figcaption>
</figure>
</section>
<section id="S6.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Application: Orderbook market simulation</h5>

<div id="S6.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p1.1" class="ltx_p">Orderbook market simulation offers a novel alternative to the traditional backtesting, as it provides an interactive environment which allows us to study the market response (e.g., price impactÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">BBDG18</a>]</cite>) to any experimental trading strategy. Moreover, orderbook simulation can be used to generate thousand of synthetic markets, with more variability and without sensitive contents.</p>
</div>
<figure id="S6.F27" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/figures/time/abides_impact.png" id="S6.F27.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="269" height="202" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/figures/time/cgan_impact.png" id="S6.F27.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="252" height="189" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F27.2.1.1" class="ltx_text" style="font-size:90%;">Figure 27</span>: </span><span id="S6.F27.3.2" class="ltx_text" style="font-size:90%;">Example of price impact with an without an Experimental trading agent. For both the multi-agent simulator ABIDES (left) and the Conditional Generative Adversarial Network (right), the simulation changes and the price goes up after the experimental agent places multiple buy orders.</span></figcaption>
</figure>
<div id="S6.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p2.1" class="ltx_p">Another recent approach uses conditional generative models for order book simulationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx172" title="" class="ltx_ref">SC23</a>, <a href="#bib.bibx39" title="" class="ltx_ref">CMVB22</a>, <a href="#bib.bibx147" title="" class="ltx_ref">PCCK22</a>, <a href="#bib.bibx41" title="" class="ltx_ref">CPC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>, <a href="#bib.bibx131" title="" class="ltx_ref">Miz16</a>]</cite>. This approach has drawn recent attention thanks to its high performance and ease of use. In fact, one major limitation of multi-agent simulators is their difficult calibration: to obtain realistic simulations, we need to identify the correct number of agents and their strategies.
Instead, deep generative models can learn the different tradersâ€™ behaviors directly from real market data-setsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx45" title="" class="ltx_ref">CVB23</a>]</cite>. In particular, recent work considers the whole market as a unique â€world agentâ€, which can be learnt from the anonymous historical data as a deep conditional generative model, and subsequently used to simulate realistic interactions of experimental trading agent with the marketÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx41" title="" class="ltx_ref">CPC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>, <a href="#bib.bibx39" title="" class="ltx_ref">CMVB22</a>]</cite>. The synthetic generation can be conditioned upon the incoming orders of the exogenous investment strategy, and the generated time-series exhibit realistic price impact.</p>
</div>
<div id="S6.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p3.1" class="ltx_p">As results, these simulation environments enable further development of the investment strategies, providing an invaluable instrument to train, test and pursue â€what ifâ€ studies. In FigureÂ <a href="#S6.F27" title="Figure 27 â€£ Application: Orderbook market simulation â€£ 6.2 Simulation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">27</span></a> we show an example of price impact that can be simulated using financial simulation. We consider exogenous trading strategies that place buy orders, and we show the price series generated using ABIDES (right chart) and the one generated using a deep generative model (left chart). This â€what ifâ€ market simulation analysis cannot be implemented in market replay or in a real financial system as the two situations (i.e., the exogenous orders arriving or not) are mutually exclusive.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Application: Benchmarking Forecasting Algorithms to Distributional Shifts</h5>

<div id="S6.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px3.p1.1" class="ltx_p">Agent-based models are a common technique for simulating complex systems. For example, as previously mentioned, ABIDES can be used to simulate equities markets and provide intraday limit-order book data as a result of trading agents interacting with an exchange agent. One of the useful properties of simulation techniques such as ABIDES is that they can provide synthetic data to benchmark the performance of machine learning algorithms under different conditions that are not encountered in historical data.</p>
</div>
<div id="S6.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS2.SSS0.Px3.p2.1" class="ltx_p">For example, inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">CELT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>, ABIDES is utilized to simulate intraday limit-order book data under different market shock conditions. Using the simulated data, a test can easily be run to test the robustness of various deep learning approaches to temporal covariate shift on the task of midprice forecasting. The finding of the paper was that state-of-art techniques, such as DeepLOBÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx225" title="" class="ltx_ref">ZZR19</a>]</cite>, were not robust to distributional and performed much better on unshocked market scenarios. Results for this experiment were conducted inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">CELT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>, but we repeat them here for convenience in TableÂ <a href="#S6.T28" title="Table 28 â€£ Application: Benchmarking Forecasting Algorithms to Distributional Shifts â€£ 6.2 Simulation â€£ 6 Time series data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">28</span></a>.</p>
</div>
<figure id="S6.T28" class="ltx_table">
<table id="S6.T28.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T28.9.10.1" class="ltx_tr">
<th id="S6.T28.9.10.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S6.T28.9.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T28.9.10.1.2.1" class="ltx_text" style="font-size:90%;">No Shock</span></th>
<th id="S6.T28.9.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T28.9.10.1.3.1" class="ltx_text" style="font-size:90%;">Small Shock</span></th>
<th id="S6.T28.9.10.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T28.9.10.1.4.1" class="ltx_text" style="font-size:90%;">Large Shock</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T28.3.3" class="ltx_tr">
<th id="S6.T28.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S6.T28.3.3.4.1" class="ltx_text" style="font-size:90%;">AdaRNN</span></th>
<td id="S6.T28.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S6.T28.1.1.1.1" class="ltx_text" style="font-size:90%;">1.02 </span><math id="S6.T28.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.1.1.1.m1.1a"><mo mathsize="90%" id="S6.T28.1.1.1.m1.1.1" xref="S6.T28.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T28.1.1.1.m1.1.1.cmml" xref="S6.T28.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.1.1.1.2" class="ltx_text" style="font-size:90%;"> 2.24e-4</span>
</td>
<td id="S6.T28.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S6.T28.2.2.2.1" class="ltx_text" style="font-size:90%;">1.00 </span><math id="S6.T28.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.2.2.2.m1.1a"><mo mathsize="90%" id="S6.T28.2.2.2.m1.1.1" xref="S6.T28.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.2.2.2.m1.1b"><csymbol cd="latexml" id="S6.T28.2.2.2.m1.1.1.cmml" xref="S6.T28.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.2.2.2.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.2.2.2.2" class="ltx_text" style="font-size:90%;"> 8.07e-5</span>
</td>
<td id="S6.T28.3.3.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S6.T28.3.3.3.1" class="ltx_text" style="font-size:90%;">0.99 </span><math id="S6.T28.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.3.3.3.m1.1a"><mo mathsize="90%" id="S6.T28.3.3.3.m1.1.1" xref="S6.T28.3.3.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.3.3.3.m1.1b"><csymbol cd="latexml" id="S6.T28.3.3.3.m1.1.1.cmml" xref="S6.T28.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.3.3.3.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.3.3.3.2" class="ltx_text" style="font-size:90%;">3.58e-5</span>
</td>
</tr>
<tr id="S6.T28.6.6" class="ltx_tr">
<th id="S6.T28.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S6.T28.6.6.4.1" class="ltx_text" style="font-size:90%;">Transformer</span></th>
<td id="S6.T28.4.4.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S6.T28.4.4.1.1" class="ltx_text" style="font-size:90%;">0.87 </span><math id="S6.T28.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.4.4.1.m1.1a"><mo mathsize="90%" id="S6.T28.4.4.1.m1.1.1" xref="S6.T28.4.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.4.4.1.m1.1b"><csymbol cd="latexml" id="S6.T28.4.4.1.m1.1.1.cmml" xref="S6.T28.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.4.4.1.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.4.4.1.2" class="ltx_text" style="font-size:90%;"> 1.98e-3</span>
</td>
<td id="S6.T28.5.5.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S6.T28.5.5.2.1" class="ltx_text" style="font-size:90%;">1.02 </span><math id="S6.T28.5.5.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.5.5.2.m1.1a"><mo mathsize="90%" id="S6.T28.5.5.2.m1.1.1" xref="S6.T28.5.5.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.5.5.2.m1.1b"><csymbol cd="latexml" id="S6.T28.5.5.2.m1.1.1.cmml" xref="S6.T28.5.5.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.5.5.2.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.5.5.2.2" class="ltx_text" style="font-size:90%;"> 6.29e-3</span>
</td>
<td id="S6.T28.6.6.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S6.T28.6.6.3.1" class="ltx_text" style="font-size:90%;">1.08 </span><math id="S6.T28.6.6.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.6.6.3.m1.1a"><mo mathsize="90%" id="S6.T28.6.6.3.m1.1.1" xref="S6.T28.6.6.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.6.6.3.m1.1b"><csymbol cd="latexml" id="S6.T28.6.6.3.m1.1.1.cmml" xref="S6.T28.6.6.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.6.6.3.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.6.6.3.2" class="ltx_text" style="font-size:90%;"> 0.01</span>
</td>
</tr>
<tr id="S6.T28.9.9" class="ltx_tr">
<th id="S6.T28.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S6.T28.9.9.4.1" class="ltx_text" style="font-size:90%;">DeepLOB</span></th>
<td id="S6.T28.7.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S6.T28.7.7.1.1" class="ltx_text" style="font-size:90%;">0.66 </span><math id="S6.T28.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.7.7.1.m1.1a"><mo mathsize="90%" id="S6.T28.7.7.1.m1.1.1" xref="S6.T28.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.7.7.1.m1.1b"><csymbol cd="latexml" id="S6.T28.7.7.1.m1.1.1.cmml" xref="S6.T28.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.7.7.1.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.7.7.1.2" class="ltx_text" style="font-size:90%;"> 0.11</span>
</td>
<td id="S6.T28.8.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S6.T28.8.8.2.1" class="ltx_text" style="font-size:90%;">1.08 </span><math id="S6.T28.8.8.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.8.8.2.m1.1a"><mo mathsize="90%" id="S6.T28.8.8.2.m1.1.1" xref="S6.T28.8.8.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.8.8.2.m1.1b"><csymbol cd="latexml" id="S6.T28.8.8.2.m1.1.1.cmml" xref="S6.T28.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.8.8.2.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.8.8.2.2" class="ltx_text" style="font-size:90%;"> 0.07</span>
</td>
<td id="S6.T28.9.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S6.T28.9.9.3.1" class="ltx_text" style="font-size:90%;">2.25 </span><math id="S6.T28.9.9.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T28.9.9.3.m1.1a"><mo mathsize="90%" id="S6.T28.9.9.3.m1.1.1" xref="S6.T28.9.9.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S6.T28.9.9.3.m1.1b"><csymbol cd="latexml" id="S6.T28.9.9.3.m1.1.1.cmml" xref="S6.T28.9.9.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T28.9.9.3.m1.1c">\pm</annotation></semantics></math><span id="S6.T28.9.9.3.2" class="ltx_text" style="font-size:90%;"> 0.15</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 28: </span>Forecasting model performance in terms of RMSE on the synthetic LOB dataset generated from ABIDES.</figcaption>
</figure>
<div id="S6.SS2.SSS0.Px3.p3" class="ltx_para">
<p id="S6.SS2.SSS0.Px3.p3.1" class="ltx_p">We have discussed various aspects of synthetic time-series and their myriad applications to the financial domain. Our discussion on the various modalities concludes with the next section on unstructured data.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Unstructured data</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Many applications in a financial institution involve data arising from text, images, and documents. In particular, we focus on two applications from checks and client communications.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Handwriting</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">Optical Character Recognition (OCR) tasks transcribe images containing text (possibly handwritten) to machine-encoded text. OCR has multiple applications in automated data entry and information extraction, e.g., scanning of forms, checks, and documents. Commercial solutions are based on Convolutional Recurrent Neural Networks (CRNN)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx89" title="" class="ltx_ref">Heg22</a>, <a href="#bib.bibx171" title="" class="ltx_ref">SBY16</a>]</cite>. These models are typically trained in a supervised fashion, with datasets consisting of <span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">&lt;image, ground_truth_text&gt;</span> pairs. However, OCR datasets â€“ particularly those of handwritten text â€“ can be noisy with incorrect annotations and artefacts in the images. Additionally, multiple types of data within the firm are sensitive, and cannot be used to train models (e.g., PII considerations with addresses), causing downstream performance degradation. Synthetic Data offers a way of augmenting these datasets so as to possibly boost the performance of OCR models.</p>
</div>
<figure id="S7.F29" class="ltx_figure"><img src="/html/2401.00081/assets/x14.png" id="S7.F29.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="272" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F29.2.1.1" class="ltx_text" style="font-size:90%;">Figure 29</span>: </span><span id="S7.F29.3.2" class="ltx_text" style="font-size:90%;">Content and Style Dimensions of Handwriting Data: augmenting by filling in missing styles (left) and augmenting by filling in missing content (right) (adapated fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">CBC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>. </span></figcaption>
</figure>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">Handwriting data have two dimensions that are of particular interest: content, and style. Contents refers to the text contained in the image. Textual contents can be often be grouped into categories like numerals, words, alphanumeric, etc. Style refers to the manner in which the text is written, e.g., cursive or bold, along with author-specific intricacies. When generating synthetic handwriting data, we must decide which dimensions we wish to augment along â€“ introduce new contents, capture novel handwriting styles, or both (see FigureÂ <a href="#S7.F29" title="Figure 29 â€£ 7.1 Handwriting â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">29</span></a> for a schematic example).</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">OCR models can be hard to train because of challenges with datasets of handwritten text. These datasets can suffer from label noise (incorrect labels), and image noise (artefacts, cropping)Additionally, missing data is the strongest pain point, as models cannot be trained on datasets containing PII (e.g., addresses of customers). This causes low performance in production. We wish to investigate if augmentation with synthetic data is a feasible solution for addressing the aforementioned problems. Particularly, we focus on two settings:</p>
</div>
<div id="S7.SS1.p4" class="ltx_para">
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p"><span id="S7.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Intra-set Augmentation</span>: Can we use synthetic data to improve performance with only style augmentation? No new contents is added to the training set;</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.2" class="ltx_p"><span id="S7.I1.i2.p1.2.1" class="ltx_text ltx_font_italic">Inter-set Augmentation</span>: Can we use synthetic data to improve performance with both contents and style augmentation, particularly when the base dataset contents greatly differs from the test set (e.g., real base dataset <math id="S7.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S7.I1.i2.p1.1.m1.1a"><mo id="S7.I1.i2.p1.1.m1.1.1" xref="S7.I1.i2.p1.1.m1.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="S7.I1.i2.p1.1.m1.1b"><in id="S7.I1.i2.p1.1.m1.1.1.cmml" xref="S7.I1.i2.p1.1.m1.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i2.p1.1.m1.1c">\in</annotation></semantics></math> words, deployment data <math id="S7.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S7.I1.i2.p1.2.m2.1a"><mo id="S7.I1.i2.p1.2.m2.1.1" xref="S7.I1.i2.p1.2.m2.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="S7.I1.i2.p1.2.m2.1b"><in id="S7.I1.i2.p1.2.m2.1.1.cmml" xref="S7.I1.i2.p1.2.m2.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i2.p1.2.m2.1c">\in</annotation></semantics></math> numerals)?</p>
</div>
</li>
</ul>
</div>
<div id="S7.SS1.p5" class="ltx_para">
<p id="S7.SS1.p5.1" class="ltx_p">Prior work has explored deep learning based approaches for generating synthetic handwritten textÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx67" title="" class="ltx_ref">FAEC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>, <a href="#bib.bibx44" title="" class="ltx_ref">CSK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite>. We will explore font-based generation as a viable alternative for improving classification performance in data scarce regimes.</p>
</div>
<section id="S7.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.1.1 </span>Font-based Augmentation</h4>

<div id="S7.SS1.SSS1.p1" class="ltx_para">
<p id="S7.SS1.SSS1.p1.1" class="ltx_p">We built a font-based text generator that uses computer fonts in conjunction with various image transformations to create synthetic handwriting data. The five image transformations we consider are rotation, elastic distortion, Gaussian blur, masking with white patches, and masking with black patches. The strength of these transformations can be varied, and they can be combined to modify a source image.</p>
</div>
<div id="S7.SS1.SSS1.p2" class="ltx_para">
<p id="S7.SS1.SSS1.p2.1" class="ltx_p">The generator starts by selecting a font style from a set of fifteen options and produces an image using the input text. Next, it samples strength levels for the individual transformations and then applies them to combine random transformation.</p>
</div>
<div id="S7.SS1.SSS1.p3" class="ltx_para">
<p id="S7.SS1.SSS1.p3.9" class="ltx_p"><span id="S7.SS1.SSS1.p3.9.1" class="ltx_text ltx_font_bold">Dataset details:</span> The base dataset consists of <math id="S7.SS1.SSS1.p3.1.m1.2" class="ltx_Math" alttext="\sim 34,000" display="inline"><semantics id="S7.SS1.SSS1.p3.1.m1.2a"><mrow id="S7.SS1.SSS1.p3.1.m1.2.3" xref="S7.SS1.SSS1.p3.1.m1.2.3.cmml"><mi id="S7.SS1.SSS1.p3.1.m1.2.3.2" xref="S7.SS1.SSS1.p3.1.m1.2.3.2.cmml"></mi><mo id="S7.SS1.SSS1.p3.1.m1.2.3.1" xref="S7.SS1.SSS1.p3.1.m1.2.3.1.cmml">âˆ¼</mo><mrow id="S7.SS1.SSS1.p3.1.m1.2.3.3.2" xref="S7.SS1.SSS1.p3.1.m1.2.3.3.1.cmml"><mn id="S7.SS1.SSS1.p3.1.m1.1.1" xref="S7.SS1.SSS1.p3.1.m1.1.1.cmml">34</mn><mo id="S7.SS1.SSS1.p3.1.m1.2.3.3.2.1" xref="S7.SS1.SSS1.p3.1.m1.2.3.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.1.m1.2.2" xref="S7.SS1.SSS1.p3.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.1.m1.2b"><apply id="S7.SS1.SSS1.p3.1.m1.2.3.cmml" xref="S7.SS1.SSS1.p3.1.m1.2.3"><csymbol cd="latexml" id="S7.SS1.SSS1.p3.1.m1.2.3.1.cmml" xref="S7.SS1.SSS1.p3.1.m1.2.3.1">similar-to</csymbol><csymbol cd="latexml" id="S7.SS1.SSS1.p3.1.m1.2.3.2.cmml" xref="S7.SS1.SSS1.p3.1.m1.2.3.2">absent</csymbol><list id="S7.SS1.SSS1.p3.1.m1.2.3.3.1.cmml" xref="S7.SS1.SSS1.p3.1.m1.2.3.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S7.SS1.SSS1.p3.1.m1.1.1">34</cn><cn type="integer" id="S7.SS1.SSS1.p3.1.m1.2.2.cmml" xref="S7.SS1.SSS1.p3.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.1.m1.2c">\sim 34,000</annotation></semantics></math> images, which we split into a training set of <math id="S7.SS1.SSS1.p3.2.m2.2" class="ltx_Math" alttext="\sim 26,500" display="inline"><semantics id="S7.SS1.SSS1.p3.2.m2.2a"><mrow id="S7.SS1.SSS1.p3.2.m2.2.3" xref="S7.SS1.SSS1.p3.2.m2.2.3.cmml"><mi id="S7.SS1.SSS1.p3.2.m2.2.3.2" xref="S7.SS1.SSS1.p3.2.m2.2.3.2.cmml"></mi><mo id="S7.SS1.SSS1.p3.2.m2.2.3.1" xref="S7.SS1.SSS1.p3.2.m2.2.3.1.cmml">âˆ¼</mo><mrow id="S7.SS1.SSS1.p3.2.m2.2.3.3.2" xref="S7.SS1.SSS1.p3.2.m2.2.3.3.1.cmml"><mn id="S7.SS1.SSS1.p3.2.m2.1.1" xref="S7.SS1.SSS1.p3.2.m2.1.1.cmml">26</mn><mo id="S7.SS1.SSS1.p3.2.m2.2.3.3.2.1" xref="S7.SS1.SSS1.p3.2.m2.2.3.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.2.m2.2.2" xref="S7.SS1.SSS1.p3.2.m2.2.2.cmml">500</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.2.m2.2b"><apply id="S7.SS1.SSS1.p3.2.m2.2.3.cmml" xref="S7.SS1.SSS1.p3.2.m2.2.3"><csymbol cd="latexml" id="S7.SS1.SSS1.p3.2.m2.2.3.1.cmml" xref="S7.SS1.SSS1.p3.2.m2.2.3.1">similar-to</csymbol><csymbol cd="latexml" id="S7.SS1.SSS1.p3.2.m2.2.3.2.cmml" xref="S7.SS1.SSS1.p3.2.m2.2.3.2">absent</csymbol><list id="S7.SS1.SSS1.p3.2.m2.2.3.3.1.cmml" xref="S7.SS1.SSS1.p3.2.m2.2.3.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S7.SS1.SSS1.p3.2.m2.1.1">26</cn><cn type="integer" id="S7.SS1.SSS1.p3.2.m2.2.2.cmml" xref="S7.SS1.SSS1.p3.2.m2.2.2">500</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.2.m2.2c">\sim 26,500</annotation></semantics></math> images, a validation set of <math id="S7.SS1.SSS1.p3.3.m3.2" class="ltx_Math" alttext="\sim 5,000" display="inline"><semantics id="S7.SS1.SSS1.p3.3.m3.2a"><mrow id="S7.SS1.SSS1.p3.3.m3.2.3" xref="S7.SS1.SSS1.p3.3.m3.2.3.cmml"><mi id="S7.SS1.SSS1.p3.3.m3.2.3.2" xref="S7.SS1.SSS1.p3.3.m3.2.3.2.cmml"></mi><mo id="S7.SS1.SSS1.p3.3.m3.2.3.1" xref="S7.SS1.SSS1.p3.3.m3.2.3.1.cmml">âˆ¼</mo><mrow id="S7.SS1.SSS1.p3.3.m3.2.3.3.2" xref="S7.SS1.SSS1.p3.3.m3.2.3.3.1.cmml"><mn id="S7.SS1.SSS1.p3.3.m3.1.1" xref="S7.SS1.SSS1.p3.3.m3.1.1.cmml">5</mn><mo id="S7.SS1.SSS1.p3.3.m3.2.3.3.2.1" xref="S7.SS1.SSS1.p3.3.m3.2.3.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.3.m3.2.2" xref="S7.SS1.SSS1.p3.3.m3.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.3.m3.2b"><apply id="S7.SS1.SSS1.p3.3.m3.2.3.cmml" xref="S7.SS1.SSS1.p3.3.m3.2.3"><csymbol cd="latexml" id="S7.SS1.SSS1.p3.3.m3.2.3.1.cmml" xref="S7.SS1.SSS1.p3.3.m3.2.3.1">similar-to</csymbol><csymbol cd="latexml" id="S7.SS1.SSS1.p3.3.m3.2.3.2.cmml" xref="S7.SS1.SSS1.p3.3.m3.2.3.2">absent</csymbol><list id="S7.SS1.SSS1.p3.3.m3.2.3.3.1.cmml" xref="S7.SS1.SSS1.p3.3.m3.2.3.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.3.m3.1.1.cmml" xref="S7.SS1.SSS1.p3.3.m3.1.1">5</cn><cn type="integer" id="S7.SS1.SSS1.p3.3.m3.2.2.cmml" xref="S7.SS1.SSS1.p3.3.m3.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.3.m3.2c">\sim 5,000</annotation></semantics></math> images, and an additional holdout set of <math id="S7.SS1.SSS1.p3.4.m4.2" class="ltx_Math" alttext="2,500" display="inline"><semantics id="S7.SS1.SSS1.p3.4.m4.2a"><mrow id="S7.SS1.SSS1.p3.4.m4.2.3.2" xref="S7.SS1.SSS1.p3.4.m4.2.3.1.cmml"><mn id="S7.SS1.SSS1.p3.4.m4.1.1" xref="S7.SS1.SSS1.p3.4.m4.1.1.cmml">2</mn><mo id="S7.SS1.SSS1.p3.4.m4.2.3.2.1" xref="S7.SS1.SSS1.p3.4.m4.2.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.4.m4.2.2" xref="S7.SS1.SSS1.p3.4.m4.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.4.m4.2b"><list id="S7.SS1.SSS1.p3.4.m4.2.3.1.cmml" xref="S7.SS1.SSS1.p3.4.m4.2.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.4.m4.1.1.cmml" xref="S7.SS1.SSS1.p3.4.m4.1.1">2</cn><cn type="integer" id="S7.SS1.SSS1.p3.4.m4.2.2.cmml" xref="S7.SS1.SSS1.p3.4.m4.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.4.m4.2c">2,500</annotation></semantics></math> images. Of the <math id="S7.SS1.SSS1.p3.5.m5.2" class="ltx_Math" alttext="34,000" display="inline"><semantics id="S7.SS1.SSS1.p3.5.m5.2a"><mrow id="S7.SS1.SSS1.p3.5.m5.2.3.2" xref="S7.SS1.SSS1.p3.5.m5.2.3.1.cmml"><mn id="S7.SS1.SSS1.p3.5.m5.1.1" xref="S7.SS1.SSS1.p3.5.m5.1.1.cmml">34</mn><mo id="S7.SS1.SSS1.p3.5.m5.2.3.2.1" xref="S7.SS1.SSS1.p3.5.m5.2.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.5.m5.2.2" xref="S7.SS1.SSS1.p3.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.5.m5.2b"><list id="S7.SS1.SSS1.p3.5.m5.2.3.1.cmml" xref="S7.SS1.SSS1.p3.5.m5.2.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.5.m5.1.1.cmml" xref="S7.SS1.SSS1.p3.5.m5.1.1">34</cn><cn type="integer" id="S7.SS1.SSS1.p3.5.m5.2.2.cmml" xref="S7.SS1.SSS1.p3.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.5.m5.2c">34,000</annotation></semantics></math> images, approximately <math id="S7.SS1.SSS1.p3.6.m6.2" class="ltx_Math" alttext="20,000" display="inline"><semantics id="S7.SS1.SSS1.p3.6.m6.2a"><mrow id="S7.SS1.SSS1.p3.6.m6.2.3.2" xref="S7.SS1.SSS1.p3.6.m6.2.3.1.cmml"><mn id="S7.SS1.SSS1.p3.6.m6.1.1" xref="S7.SS1.SSS1.p3.6.m6.1.1.cmml">20</mn><mo id="S7.SS1.SSS1.p3.6.m6.2.3.2.1" xref="S7.SS1.SSS1.p3.6.m6.2.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.6.m6.2.2" xref="S7.SS1.SSS1.p3.6.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.6.m6.2b"><list id="S7.SS1.SSS1.p3.6.m6.2.3.1.cmml" xref="S7.SS1.SSS1.p3.6.m6.2.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.6.m6.1.1.cmml" xref="S7.SS1.SSS1.p3.6.m6.1.1">20</cn><cn type="integer" id="S7.SS1.SSS1.p3.6.m6.2.2.cmml" xref="S7.SS1.SSS1.p3.6.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.6.m6.2c">20,000</annotation></semantics></math> are images of words (names, places etc.), with <math id="S7.SS1.SSS1.p3.7.m7.2" class="ltx_Math" alttext="\sim 5,300" display="inline"><semantics id="S7.SS1.SSS1.p3.7.m7.2a"><mrow id="S7.SS1.SSS1.p3.7.m7.2.3" xref="S7.SS1.SSS1.p3.7.m7.2.3.cmml"><mi id="S7.SS1.SSS1.p3.7.m7.2.3.2" xref="S7.SS1.SSS1.p3.7.m7.2.3.2.cmml"></mi><mo id="S7.SS1.SSS1.p3.7.m7.2.3.1" xref="S7.SS1.SSS1.p3.7.m7.2.3.1.cmml">âˆ¼</mo><mrow id="S7.SS1.SSS1.p3.7.m7.2.3.3.2" xref="S7.SS1.SSS1.p3.7.m7.2.3.3.1.cmml"><mn id="S7.SS1.SSS1.p3.7.m7.1.1" xref="S7.SS1.SSS1.p3.7.m7.1.1.cmml">5</mn><mo id="S7.SS1.SSS1.p3.7.m7.2.3.3.2.1" xref="S7.SS1.SSS1.p3.7.m7.2.3.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.7.m7.2.2" xref="S7.SS1.SSS1.p3.7.m7.2.2.cmml">300</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.7.m7.2b"><apply id="S7.SS1.SSS1.p3.7.m7.2.3.cmml" xref="S7.SS1.SSS1.p3.7.m7.2.3"><csymbol cd="latexml" id="S7.SS1.SSS1.p3.7.m7.2.3.1.cmml" xref="S7.SS1.SSS1.p3.7.m7.2.3.1">similar-to</csymbol><csymbol cd="latexml" id="S7.SS1.SSS1.p3.7.m7.2.3.2.cmml" xref="S7.SS1.SSS1.p3.7.m7.2.3.2">absent</csymbol><list id="S7.SS1.SSS1.p3.7.m7.2.3.3.1.cmml" xref="S7.SS1.SSS1.p3.7.m7.2.3.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.7.m7.1.1.cmml" xref="S7.SS1.SSS1.p3.7.m7.1.1">5</cn><cn type="integer" id="S7.SS1.SSS1.p3.7.m7.2.2.cmml" xref="S7.SS1.SSS1.p3.7.m7.2.2">300</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.7.m7.2c">\sim 5,300</annotation></semantics></math> unique labels. The remaining <math id="S7.SS1.SSS1.p3.8.m8.2" class="ltx_Math" alttext="\sim 14,000" display="inline"><semantics id="S7.SS1.SSS1.p3.8.m8.2a"><mrow id="S7.SS1.SSS1.p3.8.m8.2.3" xref="S7.SS1.SSS1.p3.8.m8.2.3.cmml"><mi id="S7.SS1.SSS1.p3.8.m8.2.3.2" xref="S7.SS1.SSS1.p3.8.m8.2.3.2.cmml"></mi><mo id="S7.SS1.SSS1.p3.8.m8.2.3.1" xref="S7.SS1.SSS1.p3.8.m8.2.3.1.cmml">âˆ¼</mo><mrow id="S7.SS1.SSS1.p3.8.m8.2.3.3.2" xref="S7.SS1.SSS1.p3.8.m8.2.3.3.1.cmml"><mn id="S7.SS1.SSS1.p3.8.m8.1.1" xref="S7.SS1.SSS1.p3.8.m8.1.1.cmml">14</mn><mo id="S7.SS1.SSS1.p3.8.m8.2.3.3.2.1" xref="S7.SS1.SSS1.p3.8.m8.2.3.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.8.m8.2.2" xref="S7.SS1.SSS1.p3.8.m8.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.8.m8.2b"><apply id="S7.SS1.SSS1.p3.8.m8.2.3.cmml" xref="S7.SS1.SSS1.p3.8.m8.2.3"><csymbol cd="latexml" id="S7.SS1.SSS1.p3.8.m8.2.3.1.cmml" xref="S7.SS1.SSS1.p3.8.m8.2.3.1">similar-to</csymbol><csymbol cd="latexml" id="S7.SS1.SSS1.p3.8.m8.2.3.2.cmml" xref="S7.SS1.SSS1.p3.8.m8.2.3.2">absent</csymbol><list id="S7.SS1.SSS1.p3.8.m8.2.3.3.1.cmml" xref="S7.SS1.SSS1.p3.8.m8.2.3.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.8.m8.1.1.cmml" xref="S7.SS1.SSS1.p3.8.m8.1.1">14</cn><cn type="integer" id="S7.SS1.SSS1.p3.8.m8.2.2.cmml" xref="S7.SS1.SSS1.p3.8.m8.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.8.m8.2c">\sim 14,000</annotation></semantics></math> are images containing numerals (dates, numeric amounts etc.) with <math id="S7.SS1.SSS1.p3.9.m9.2" class="ltx_Math" alttext="\sim 3,500" display="inline"><semantics id="S7.SS1.SSS1.p3.9.m9.2a"><mrow id="S7.SS1.SSS1.p3.9.m9.2.3" xref="S7.SS1.SSS1.p3.9.m9.2.3.cmml"><mi id="S7.SS1.SSS1.p3.9.m9.2.3.2" xref="S7.SS1.SSS1.p3.9.m9.2.3.2.cmml"></mi><mo id="S7.SS1.SSS1.p3.9.m9.2.3.1" xref="S7.SS1.SSS1.p3.9.m9.2.3.1.cmml">âˆ¼</mo><mrow id="S7.SS1.SSS1.p3.9.m9.2.3.3.2" xref="S7.SS1.SSS1.p3.9.m9.2.3.3.1.cmml"><mn id="S7.SS1.SSS1.p3.9.m9.1.1" xref="S7.SS1.SSS1.p3.9.m9.1.1.cmml">3</mn><mo id="S7.SS1.SSS1.p3.9.m9.2.3.3.2.1" xref="S7.SS1.SSS1.p3.9.m9.2.3.3.1.cmml">,</mo><mn id="S7.SS1.SSS1.p3.9.m9.2.2" xref="S7.SS1.SSS1.p3.9.m9.2.2.cmml">500</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p3.9.m9.2b"><apply id="S7.SS1.SSS1.p3.9.m9.2.3.cmml" xref="S7.SS1.SSS1.p3.9.m9.2.3"><csymbol cd="latexml" id="S7.SS1.SSS1.p3.9.m9.2.3.1.cmml" xref="S7.SS1.SSS1.p3.9.m9.2.3.1">similar-to</csymbol><csymbol cd="latexml" id="S7.SS1.SSS1.p3.9.m9.2.3.2.cmml" xref="S7.SS1.SSS1.p3.9.m9.2.3.2">absent</csymbol><list id="S7.SS1.SSS1.p3.9.m9.2.3.3.1.cmml" xref="S7.SS1.SSS1.p3.9.m9.2.3.3.2"><cn type="integer" id="S7.SS1.SSS1.p3.9.m9.1.1.cmml" xref="S7.SS1.SSS1.p3.9.m9.1.1">3</cn><cn type="integer" id="S7.SS1.SSS1.p3.9.m9.2.2.cmml" xref="S7.SS1.SSS1.p3.9.m9.2.2">500</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p3.9.m9.2c">\sim 3,500</annotation></semantics></math> unique labels.</p>
</div>
<div id="S7.SS1.SSS1.p4" class="ltx_para">
<p id="S7.SS1.SSS1.p4.1" class="ltx_p"><span id="S7.SS1.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Experiment Procedure:</span> The experiment is conducted using the following steps:</p>
</div>
<div id="S7.SS1.SSS1.p5" class="ltx_para">
<ol id="S7.I2" class="ltx_enumerate">
<li id="S7.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S7.I2.i1.p1" class="ltx_para">
<p id="S7.I2.i1.p1.1" class="ltx_p">Create dataset with a preset number of real examples (= R) plus X% new examples coming from augmentation.
For instance, if R = <math id="S7.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="7000" display="inline"><semantics id="S7.I2.i1.p1.1.m1.1a"><mn id="S7.I2.i1.p1.1.m1.1.1" xref="S7.I2.i1.p1.1.m1.1.1.cmml">7000</mn><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.1.m1.1b"><cn type="integer" id="S7.I2.i1.p1.1.m1.1.1.cmml" xref="S7.I2.i1.p1.1.m1.1.1">7000</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.1.m1.1c">7000</annotation></semantics></math> and augmentation level X = 50%, the dataset would comprise 7,000 real examples, and 3,500 synthetic ones.</p>
</div>
</li>
<li id="S7.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S7.I2.i2.p1" class="ltx_para">
<p id="S7.I2.i2.p1.1" class="ltx_p">Train OCR model using curated dataset. The OCR model selected is a Convolutional Neural network with 18 million parameters.</p>
</div>
</li>
<li id="S7.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S7.I2.i3.p1" class="ltx_para">
<p id="S7.I2.i3.p1.1" class="ltx_p">Test on holdout test set, and measure Character Error Rate (CER)</p>
</div>
</li>
</ol>
<p id="S7.SS1.SSS1.p5.1" class="ltx_p">The CER metric is based on the Levenshtein Edit Distance that computes the number of operations required to transform one string into another. It correlates with the percentage of characters in the ground-truth text that were incorrectly transcribed.
Lower CER values are better, as they indicate lower error. Note that we can have CER <math id="S7.SS1.SSS1.p5.1.m1.1" class="ltx_Math" alttext="&gt;1.0" display="inline"><semantics id="S7.SS1.SSS1.p5.1.m1.1a"><mrow id="S7.SS1.SSS1.p5.1.m1.1.1" xref="S7.SS1.SSS1.p5.1.m1.1.1.cmml"><mi id="S7.SS1.SSS1.p5.1.m1.1.1.2" xref="S7.SS1.SSS1.p5.1.m1.1.1.2.cmml"></mi><mo id="S7.SS1.SSS1.p5.1.m1.1.1.1" xref="S7.SS1.SSS1.p5.1.m1.1.1.1.cmml">&gt;</mo><mn id="S7.SS1.SSS1.p5.1.m1.1.1.3" xref="S7.SS1.SSS1.p5.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p5.1.m1.1b"><apply id="S7.SS1.SSS1.p5.1.m1.1.1.cmml" xref="S7.SS1.SSS1.p5.1.m1.1.1"><gt id="S7.SS1.SSS1.p5.1.m1.1.1.1.cmml" xref="S7.SS1.SSS1.p5.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S7.SS1.SSS1.p5.1.m1.1.1.2.cmml" xref="S7.SS1.SSS1.p5.1.m1.1.1.2">absent</csymbol><cn type="float" id="S7.SS1.SSS1.p5.1.m1.1.1.3.cmml" xref="S7.SS1.SSS1.p5.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p5.1.m1.1c">&gt;1.0</annotation></semantics></math> in cases where the prediction is longer than the ground truth.</p>
</div>
<div id="S7.SS1.SSS1.p6" class="ltx_para">
<p id="S7.SS1.SSS1.p6.1" class="ltx_p"><span id="S7.SS1.SSS1.p6.1.1" class="ltx_text ltx_font_bold">Results:</span> As previously stated, we investigate two scenarios:</p>
</div>
<div id="S7.SS1.SSS1.p7" class="ltx_para">
<ol id="S7.I3" class="ltx_enumerate">
<li id="S7.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S7.I3.i1.p1" class="ltx_para">
<p id="S7.I3.i1.p1.7" class="ltx_p"><span id="S7.I3.i1.p1.7.1" class="ltx_text ltx_font_italic">Intra-set Augmentation</span>: We would like to study if we can use synthetic data to improve performance with only style augmentation. In this case, no new contents is added to the training set. Instead, contents for the synthetic examples is sampled from the set of ground-truth labels of the training set. The first experiment was performed with the real dataset size <math id="S7.I3.i1.p1.1.m1.2" class="ltx_Math" alttext="R=7,000" display="inline"><semantics id="S7.I3.i1.p1.1.m1.2a"><mrow id="S7.I3.i1.p1.1.m1.2.3" xref="S7.I3.i1.p1.1.m1.2.3.cmml"><mi id="S7.I3.i1.p1.1.m1.2.3.2" xref="S7.I3.i1.p1.1.m1.2.3.2.cmml">R</mi><mo id="S7.I3.i1.p1.1.m1.2.3.1" xref="S7.I3.i1.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S7.I3.i1.p1.1.m1.2.3.3.2" xref="S7.I3.i1.p1.1.m1.2.3.3.1.cmml"><mn id="S7.I3.i1.p1.1.m1.1.1" xref="S7.I3.i1.p1.1.m1.1.1.cmml">7</mn><mo id="S7.I3.i1.p1.1.m1.2.3.3.2.1" xref="S7.I3.i1.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S7.I3.i1.p1.1.m1.2.2" xref="S7.I3.i1.p1.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.1.m1.2b"><apply id="S7.I3.i1.p1.1.m1.2.3.cmml" xref="S7.I3.i1.p1.1.m1.2.3"><eq id="S7.I3.i1.p1.1.m1.2.3.1.cmml" xref="S7.I3.i1.p1.1.m1.2.3.1"></eq><ci id="S7.I3.i1.p1.1.m1.2.3.2.cmml" xref="S7.I3.i1.p1.1.m1.2.3.2">ğ‘…</ci><list id="S7.I3.i1.p1.1.m1.2.3.3.1.cmml" xref="S7.I3.i1.p1.1.m1.2.3.3.2"><cn type="integer" id="S7.I3.i1.p1.1.m1.1.1.cmml" xref="S7.I3.i1.p1.1.m1.1.1">7</cn><cn type="integer" id="S7.I3.i1.p1.1.m1.2.2.cmml" xref="S7.I3.i1.p1.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.1.m1.2c">R=7,000</annotation></semantics></math> samples. This was to demonstrate the effects of the augmentation when the real dataset is of a limited size. We observed that augmenting with synthetic data improved model performance. As shown in FigureÂ <a href="#S7.F30" title="Figure 30 â€£ item 1 â€£ 7.1.1 Font-based Augmentation â€£ 7.1 Handwriting â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">30</span></a>, the highest level of improvement (<math id="S7.I3.i1.p1.2.m2.1" class="ltx_Math" alttext="26.11\%" display="inline"><semantics id="S7.I3.i1.p1.2.m2.1a"><mrow id="S7.I3.i1.p1.2.m2.1.1" xref="S7.I3.i1.p1.2.m2.1.1.cmml"><mn id="S7.I3.i1.p1.2.m2.1.1.2" xref="S7.I3.i1.p1.2.m2.1.1.2.cmml">26.11</mn><mo id="S7.I3.i1.p1.2.m2.1.1.1" xref="S7.I3.i1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.2.m2.1b"><apply id="S7.I3.i1.p1.2.m2.1.1.cmml" xref="S7.I3.i1.p1.2.m2.1.1"><csymbol cd="latexml" id="S7.I3.i1.p1.2.m2.1.1.1.cmml" xref="S7.I3.i1.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S7.I3.i1.p1.2.m2.1.1.2.cmml" xref="S7.I3.i1.p1.2.m2.1.1.2">26.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.2.m2.1c">26.11\%</annotation></semantics></math>) was achieved with <math id="S7.I3.i1.p1.3.m3.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S7.I3.i1.p1.3.m3.1a"><mrow id="S7.I3.i1.p1.3.m3.1.1" xref="S7.I3.i1.p1.3.m3.1.1.cmml"><mn id="S7.I3.i1.p1.3.m3.1.1.2" xref="S7.I3.i1.p1.3.m3.1.1.2.cmml">100</mn><mo id="S7.I3.i1.p1.3.m3.1.1.1" xref="S7.I3.i1.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.3.m3.1b"><apply id="S7.I3.i1.p1.3.m3.1.1.cmml" xref="S7.I3.i1.p1.3.m3.1.1"><csymbol cd="latexml" id="S7.I3.i1.p1.3.m3.1.1.1.cmml" xref="S7.I3.i1.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S7.I3.i1.p1.3.m3.1.1.2.cmml" xref="S7.I3.i1.p1.3.m3.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.3.m3.1c">100\%</annotation></semantics></math> augmentation; further augmentation degraded performance from this level, although still a marked improvement from the <math id="S7.I3.i1.p1.4.m4.1" class="ltx_Math" alttext="0\%" display="inline"><semantics id="S7.I3.i1.p1.4.m4.1a"><mrow id="S7.I3.i1.p1.4.m4.1.1" xref="S7.I3.i1.p1.4.m4.1.1.cmml"><mn id="S7.I3.i1.p1.4.m4.1.1.2" xref="S7.I3.i1.p1.4.m4.1.1.2.cmml">0</mn><mo id="S7.I3.i1.p1.4.m4.1.1.1" xref="S7.I3.i1.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.4.m4.1b"><apply id="S7.I3.i1.p1.4.m4.1.1.cmml" xref="S7.I3.i1.p1.4.m4.1.1"><csymbol cd="latexml" id="S7.I3.i1.p1.4.m4.1.1.1.cmml" xref="S7.I3.i1.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S7.I3.i1.p1.4.m4.1.1.2.cmml" xref="S7.I3.i1.p1.4.m4.1.1.2">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.4.m4.1c">0\%</annotation></semantics></math> baseline. The second experiment was performed with the real dataset size <math id="S7.I3.i1.p1.5.m5.2" class="ltx_Math" alttext="R=21,000" display="inline"><semantics id="S7.I3.i1.p1.5.m5.2a"><mrow id="S7.I3.i1.p1.5.m5.2.3" xref="S7.I3.i1.p1.5.m5.2.3.cmml"><mi id="S7.I3.i1.p1.5.m5.2.3.2" xref="S7.I3.i1.p1.5.m5.2.3.2.cmml">R</mi><mo id="S7.I3.i1.p1.5.m5.2.3.1" xref="S7.I3.i1.p1.5.m5.2.3.1.cmml">=</mo><mrow id="S7.I3.i1.p1.5.m5.2.3.3.2" xref="S7.I3.i1.p1.5.m5.2.3.3.1.cmml"><mn id="S7.I3.i1.p1.5.m5.1.1" xref="S7.I3.i1.p1.5.m5.1.1.cmml">21</mn><mo id="S7.I3.i1.p1.5.m5.2.3.3.2.1" xref="S7.I3.i1.p1.5.m5.2.3.3.1.cmml">,</mo><mn id="S7.I3.i1.p1.5.m5.2.2" xref="S7.I3.i1.p1.5.m5.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.5.m5.2b"><apply id="S7.I3.i1.p1.5.m5.2.3.cmml" xref="S7.I3.i1.p1.5.m5.2.3"><eq id="S7.I3.i1.p1.5.m5.2.3.1.cmml" xref="S7.I3.i1.p1.5.m5.2.3.1"></eq><ci id="S7.I3.i1.p1.5.m5.2.3.2.cmml" xref="S7.I3.i1.p1.5.m5.2.3.2">ğ‘…</ci><list id="S7.I3.i1.p1.5.m5.2.3.3.1.cmml" xref="S7.I3.i1.p1.5.m5.2.3.3.2"><cn type="integer" id="S7.I3.i1.p1.5.m5.1.1.cmml" xref="S7.I3.i1.p1.5.m5.1.1">21</cn><cn type="integer" id="S7.I3.i1.p1.5.m5.2.2.cmml" xref="S7.I3.i1.p1.5.m5.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.5.m5.2c">R=21,000</annotation></semantics></math> samples. This represents a realistic setting in OCR training, and helps us gauge whether synthetic data can help boost performance in such scenarios. Similar to the previous experiment, FigureÂ <a href="#S7.F30" title="Figure 30 â€£ item 1 â€£ 7.1.1 Font-based Augmentation â€£ 7.1 Handwriting â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">30</span></a> shows that synthetic data augmentation improved model performance, with the most improvement (<math id="S7.I3.i1.p1.6.m6.1" class="ltx_Math" alttext="18.92\%" display="inline"><semantics id="S7.I3.i1.p1.6.m6.1a"><mrow id="S7.I3.i1.p1.6.m6.1.1" xref="S7.I3.i1.p1.6.m6.1.1.cmml"><mn id="S7.I3.i1.p1.6.m6.1.1.2" xref="S7.I3.i1.p1.6.m6.1.1.2.cmml">18.92</mn><mo id="S7.I3.i1.p1.6.m6.1.1.1" xref="S7.I3.i1.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.6.m6.1b"><apply id="S7.I3.i1.p1.6.m6.1.1.cmml" xref="S7.I3.i1.p1.6.m6.1.1"><csymbol cd="latexml" id="S7.I3.i1.p1.6.m6.1.1.1.cmml" xref="S7.I3.i1.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S7.I3.i1.p1.6.m6.1.1.2.cmml" xref="S7.I3.i1.p1.6.m6.1.1.2">18.92</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.6.m6.1c">18.92\%</annotation></semantics></math>) observed at <math id="S7.I3.i1.p1.7.m7.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S7.I3.i1.p1.7.m7.1a"><mrow id="S7.I3.i1.p1.7.m7.1.1" xref="S7.I3.i1.p1.7.m7.1.1.cmml"><mn id="S7.I3.i1.p1.7.m7.1.1.2" xref="S7.I3.i1.p1.7.m7.1.1.2.cmml">100</mn><mo id="S7.I3.i1.p1.7.m7.1.1.1" xref="S7.I3.i1.p1.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.7.m7.1b"><apply id="S7.I3.i1.p1.7.m7.1.1.cmml" xref="S7.I3.i1.p1.7.m7.1.1"><csymbol cd="latexml" id="S7.I3.i1.p1.7.m7.1.1.1.cmml" xref="S7.I3.i1.p1.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S7.I3.i1.p1.7.m7.1.1.2.cmml" xref="S7.I3.i1.p1.7.m7.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.7.m7.1c">100\%</annotation></semantics></math> augmentation. Further augmentation resulted in a plateau.</p>
</div>
<figure id="S7.F30" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/x15.png" id="S7.F30.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="312" height="218" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2401.00081/assets/x16.png" id="S7.F30.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="312" height="216" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F30.14.7.1" class="ltx_text" style="font-size:90%;">Figure 30</span>: </span><span id="S7.F30.12.6" class="ltx_text" style="font-size:90%;">Results of synthetic data augmentation with real dataset size of <math id="S7.F30.7.1.m1.2" class="ltx_Math" alttext="7,000" display="inline"><semantics id="S7.F30.7.1.m1.2b"><mrow id="S7.F30.7.1.m1.2.3.2" xref="S7.F30.7.1.m1.2.3.1.cmml"><mn id="S7.F30.7.1.m1.1.1" xref="S7.F30.7.1.m1.1.1.cmml">7</mn><mo id="S7.F30.7.1.m1.2.3.2.1" xref="S7.F30.7.1.m1.2.3.1.cmml">,</mo><mn id="S7.F30.7.1.m1.2.2" xref="S7.F30.7.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.F30.7.1.m1.2c"><list id="S7.F30.7.1.m1.2.3.1.cmml" xref="S7.F30.7.1.m1.2.3.2"><cn type="integer" id="S7.F30.7.1.m1.1.1.cmml" xref="S7.F30.7.1.m1.1.1">7</cn><cn type="integer" id="S7.F30.7.1.m1.2.2.cmml" xref="S7.F30.7.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.F30.7.1.m1.2d">7,000</annotation></semantics></math> samples. We observe a <math id="S7.F30.8.2.m2.1" class="ltx_Math" alttext="26.11\%" display="inline"><semantics id="S7.F30.8.2.m2.1b"><mrow id="S7.F30.8.2.m2.1.1" xref="S7.F30.8.2.m2.1.1.cmml"><mn id="S7.F30.8.2.m2.1.1.2" xref="S7.F30.8.2.m2.1.1.2.cmml">26.11</mn><mo id="S7.F30.8.2.m2.1.1.1" xref="S7.F30.8.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.F30.8.2.m2.1c"><apply id="S7.F30.8.2.m2.1.1.cmml" xref="S7.F30.8.2.m2.1.1"><csymbol cd="latexml" id="S7.F30.8.2.m2.1.1.1.cmml" xref="S7.F30.8.2.m2.1.1.1">percent</csymbol><cn type="float" id="S7.F30.8.2.m2.1.1.2.cmml" xref="S7.F30.8.2.m2.1.1.2">26.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F30.8.2.m2.1d">26.11\%</annotation></semantics></math> improvement with <math id="S7.F30.9.3.m3.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S7.F30.9.3.m3.1b"><mrow id="S7.F30.9.3.m3.1.1" xref="S7.F30.9.3.m3.1.1.cmml"><mn id="S7.F30.9.3.m3.1.1.2" xref="S7.F30.9.3.m3.1.1.2.cmml">100</mn><mo id="S7.F30.9.3.m3.1.1.1" xref="S7.F30.9.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.F30.9.3.m3.1c"><apply id="S7.F30.9.3.m3.1.1.cmml" xref="S7.F30.9.3.m3.1.1"><csymbol cd="latexml" id="S7.F30.9.3.m3.1.1.1.cmml" xref="S7.F30.9.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S7.F30.9.3.m3.1.1.2.cmml" xref="S7.F30.9.3.m3.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F30.9.3.m3.1d">100\%</annotation></semantics></math> augmentation. Results of synthetic data augmentation with real dataset size of <math id="S7.F30.10.4.m4.2" class="ltx_Math" alttext="21,000" display="inline"><semantics id="S7.F30.10.4.m4.2b"><mrow id="S7.F30.10.4.m4.2.3.2" xref="S7.F30.10.4.m4.2.3.1.cmml"><mn id="S7.F30.10.4.m4.1.1" xref="S7.F30.10.4.m4.1.1.cmml">21</mn><mo id="S7.F30.10.4.m4.2.3.2.1" xref="S7.F30.10.4.m4.2.3.1.cmml">,</mo><mn id="S7.F30.10.4.m4.2.2" xref="S7.F30.10.4.m4.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.F30.10.4.m4.2c"><list id="S7.F30.10.4.m4.2.3.1.cmml" xref="S7.F30.10.4.m4.2.3.2"><cn type="integer" id="S7.F30.10.4.m4.1.1.cmml" xref="S7.F30.10.4.m4.1.1">21</cn><cn type="integer" id="S7.F30.10.4.m4.2.2.cmml" xref="S7.F30.10.4.m4.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.F30.10.4.m4.2d">21,000</annotation></semantics></math> samples. We observe a <math id="S7.F30.11.5.m5.1" class="ltx_Math" alttext="18.92\%" display="inline"><semantics id="S7.F30.11.5.m5.1b"><mrow id="S7.F30.11.5.m5.1.1" xref="S7.F30.11.5.m5.1.1.cmml"><mn id="S7.F30.11.5.m5.1.1.2" xref="S7.F30.11.5.m5.1.1.2.cmml">18.92</mn><mo id="S7.F30.11.5.m5.1.1.1" xref="S7.F30.11.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.F30.11.5.m5.1c"><apply id="S7.F30.11.5.m5.1.1.cmml" xref="S7.F30.11.5.m5.1.1"><csymbol cd="latexml" id="S7.F30.11.5.m5.1.1.1.cmml" xref="S7.F30.11.5.m5.1.1.1">percent</csymbol><cn type="float" id="S7.F30.11.5.m5.1.1.2.cmml" xref="S7.F30.11.5.m5.1.1.2">18.92</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F30.11.5.m5.1d">18.92\%</annotation></semantics></math> improvement with <math id="S7.F30.12.6.m6.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S7.F30.12.6.m6.1b"><mrow id="S7.F30.12.6.m6.1.1" xref="S7.F30.12.6.m6.1.1.cmml"><mn id="S7.F30.12.6.m6.1.1.2" xref="S7.F30.12.6.m6.1.1.2.cmml">100</mn><mo id="S7.F30.12.6.m6.1.1.1" xref="S7.F30.12.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.F30.12.6.m6.1c"><apply id="S7.F30.12.6.m6.1.1.cmml" xref="S7.F30.12.6.m6.1.1"><csymbol cd="latexml" id="S7.F30.12.6.m6.1.1.1.cmml" xref="S7.F30.12.6.m6.1.1.1">percent</csymbol><cn type="integer" id="S7.F30.12.6.m6.1.1.2.cmml" xref="S7.F30.12.6.m6.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F30.12.6.m6.1d">100\%</annotation></semantics></math> augmentation.</span></figcaption>
</figure>
</li>
<li id="S7.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S7.I3.i2.p1" class="ltx_para">
<p id="S7.I3.i2.p1.5" class="ltx_p"><span id="S7.I3.i2.p1.5.1" class="ltx_text ltx_font_italic">Inter-set Augmentation</span>: Now, we want to analyze if we can use synthetic data to improve performance with both contents and style augmentation, particularly when the training set contents greatly differs from and with potentially little to no overlap with the test set (e.g., real base dataset <math id="S7.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S7.I3.i2.p1.1.m1.1a"><mo id="S7.I3.i2.p1.1.m1.1.1" xref="S7.I3.i2.p1.1.m1.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="S7.I3.i2.p1.1.m1.1b"><in id="S7.I3.i2.p1.1.m1.1.1.cmml" xref="S7.I3.i2.p1.1.m1.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i2.p1.1.m1.1c">\in</annotation></semantics></math> words, deployment data <math id="S7.I3.i2.p1.2.m2.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S7.I3.i2.p1.2.m2.1a"><mo id="S7.I3.i2.p1.2.m2.1.1" xref="S7.I3.i2.p1.2.m2.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="S7.I3.i2.p1.2.m2.1b"><in id="S7.I3.i2.p1.2.m2.1.1.cmml" xref="S7.I3.i2.p1.2.m2.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i2.p1.2.m2.1c">\in</annotation></semantics></math> numerals). This experiment is akin to test the OCR model in cases of dataset shift, i.e., when the distribution of the test set greatly differs from the training set. In this experiment, the real data comprises only words (names, places etc.), whereas the OCR model will be tested on a dataset comprising of numerals (dates, amounts etc.). Therefore, the synthetic data introduces samples with numeric contents to gauge if this helps the model perform inference on the test set. This mimics a real-world contents gap scenario, where the training set consists of words and numerals in independent samples (the dataset described previously), whereas the deployment dataset consists of addresses (alphanumeric data). It is not possible to train the model directly on addresses due to data privacy considerations related to PII (Personally Identifiable Information). As in the first experiment, we observed that augmenting with synthetic data improved model performance (FigureÂ <a href="#S7.F31" title="Figure 31 â€£ item 2 â€£ 7.1.1 Font-based Augmentation â€£ 7.1 Handwriting â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">31</span></a>). The highest level of improvement (<math id="S7.I3.i2.p1.3.m3.1" class="ltx_Math" alttext="40.68\%" display="inline"><semantics id="S7.I3.i2.p1.3.m3.1a"><mrow id="S7.I3.i2.p1.3.m3.1.1" xref="S7.I3.i2.p1.3.m3.1.1.cmml"><mn id="S7.I3.i2.p1.3.m3.1.1.2" xref="S7.I3.i2.p1.3.m3.1.1.2.cmml">40.68</mn><mo id="S7.I3.i2.p1.3.m3.1.1.1" xref="S7.I3.i2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i2.p1.3.m3.1b"><apply id="S7.I3.i2.p1.3.m3.1.1.cmml" xref="S7.I3.i2.p1.3.m3.1.1"><csymbol cd="latexml" id="S7.I3.i2.p1.3.m3.1.1.1.cmml" xref="S7.I3.i2.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S7.I3.i2.p1.3.m3.1.1.2.cmml" xref="S7.I3.i2.p1.3.m3.1.1.2">40.68</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i2.p1.3.m3.1c">40.68\%</annotation></semantics></math>) was achieved with <math id="S7.I3.i2.p1.4.m4.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S7.I3.i2.p1.4.m4.1a"><mrow id="S7.I3.i2.p1.4.m4.1.1" xref="S7.I3.i2.p1.4.m4.1.1.cmml"><mn id="S7.I3.i2.p1.4.m4.1.1.2" xref="S7.I3.i2.p1.4.m4.1.1.2.cmml">100</mn><mo id="S7.I3.i2.p1.4.m4.1.1.1" xref="S7.I3.i2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i2.p1.4.m4.1b"><apply id="S7.I3.i2.p1.4.m4.1.1.cmml" xref="S7.I3.i2.p1.4.m4.1.1"><csymbol cd="latexml" id="S7.I3.i2.p1.4.m4.1.1.1.cmml" xref="S7.I3.i2.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S7.I3.i2.p1.4.m4.1.1.2.cmml" xref="S7.I3.i2.p1.4.m4.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i2.p1.4.m4.1c">100\%</annotation></semantics></math> augmentation, with further augmentation degrading performance. The baseline in this experiment was set to be the OCR model trained with <math id="S7.I3.i2.p1.5.m5.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S7.I3.i2.p1.5.m5.1a"><mrow id="S7.I3.i2.p1.5.m5.1.1" xref="S7.I3.i2.p1.5.m5.1.1.cmml"><mn id="S7.I3.i2.p1.5.m5.1.1.2" xref="S7.I3.i2.p1.5.m5.1.1.2.cmml">1</mn><mo id="S7.I3.i2.p1.5.m5.1.1.1" xref="S7.I3.i2.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.I3.i2.p1.5.m5.1b"><apply id="S7.I3.i2.p1.5.m5.1.1.cmml" xref="S7.I3.i2.p1.5.m5.1.1"><csymbol cd="latexml" id="S7.I3.i2.p1.5.m5.1.1.1.cmml" xref="S7.I3.i2.p1.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S7.I3.i2.p1.5.m5.1.1.2.cmml" xref="S7.I3.i2.p1.5.m5.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i2.p1.5.m5.1c">1\%</annotation></semantics></math> synthetic data augmentation. With no data augmentation, the OCR model implementation would indeed not compile on a test set with unrecognized and previously unseen characters.</p>
</div>
<figure id="S7.F31" class="ltx_figure"><img src="/html/2401.00081/assets/x17.png" id="S7.F31.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="565" height="407" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F31.8.4.1" class="ltx_text" style="font-size:90%;">Figure 31</span>: </span><span id="S7.F31.6.3" class="ltx_text" style="font-size:90%;">Results of synthetic data augmentation in a contents gap scenario with real dataset size of <math id="S7.F31.4.1.m1.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="S7.F31.4.1.m1.2b"><mrow id="S7.F31.4.1.m1.2.3.2" xref="S7.F31.4.1.m1.2.3.1.cmml"><mn id="S7.F31.4.1.m1.1.1" xref="S7.F31.4.1.m1.1.1.cmml">10</mn><mo id="S7.F31.4.1.m1.2.3.2.1" xref="S7.F31.4.1.m1.2.3.1.cmml">,</mo><mn id="S7.F31.4.1.m1.2.2" xref="S7.F31.4.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.F31.4.1.m1.2c"><list id="S7.F31.4.1.m1.2.3.1.cmml" xref="S7.F31.4.1.m1.2.3.2"><cn type="integer" id="S7.F31.4.1.m1.1.1.cmml" xref="S7.F31.4.1.m1.1.1">10</cn><cn type="integer" id="S7.F31.4.1.m1.2.2.cmml" xref="S7.F31.4.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.F31.4.1.m1.2d">10,000</annotation></semantics></math> samples. We observe a <math id="S7.F31.5.2.m2.1" class="ltx_Math" alttext="40.68\%" display="inline"><semantics id="S7.F31.5.2.m2.1b"><mrow id="S7.F31.5.2.m2.1.1" xref="S7.F31.5.2.m2.1.1.cmml"><mn id="S7.F31.5.2.m2.1.1.2" xref="S7.F31.5.2.m2.1.1.2.cmml">40.68</mn><mo id="S7.F31.5.2.m2.1.1.1" xref="S7.F31.5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.F31.5.2.m2.1c"><apply id="S7.F31.5.2.m2.1.1.cmml" xref="S7.F31.5.2.m2.1.1"><csymbol cd="latexml" id="S7.F31.5.2.m2.1.1.1.cmml" xref="S7.F31.5.2.m2.1.1.1">percent</csymbol><cn type="float" id="S7.F31.5.2.m2.1.1.2.cmml" xref="S7.F31.5.2.m2.1.1.2">40.68</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F31.5.2.m2.1d">40.68\%</annotation></semantics></math> improvement with <math id="S7.F31.6.3.m3.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S7.F31.6.3.m3.1b"><mrow id="S7.F31.6.3.m3.1.1" xref="S7.F31.6.3.m3.1.1.cmml"><mn id="S7.F31.6.3.m3.1.1.2" xref="S7.F31.6.3.m3.1.1.2.cmml">100</mn><mo id="S7.F31.6.3.m3.1.1.1" xref="S7.F31.6.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.F31.6.3.m3.1c"><apply id="S7.F31.6.3.m3.1.1.cmml" xref="S7.F31.6.3.m3.1.1"><csymbol cd="latexml" id="S7.F31.6.3.m3.1.1.1.cmml" xref="S7.F31.6.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S7.F31.6.3.m3.1.1.2.cmml" xref="S7.F31.6.3.m3.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F31.6.3.m3.1d">100\%</annotation></semantics></math> augmentation.</span></figcaption>
</figure>
</li>
</ol>
</div>
</section>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Document generation</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Financial documents such as prospectus, credit reports, purchase orders, sustainability disclosures, income statements, invoices etc., are presented in a range of visual styles and encompass a diverse set of semantics.
Machine interpretation of such documents demands numerous instances, typically with ground-truth examples included. However, curating these documents is challenging especially if they are proprietary or governed by copyright and licensing restrictions. Furthermore, annotation exercises at scale tend to be resource intensive. Synthetically generated documents provide a plausible alternative to explicit collection of documents and manual annotation with massive quantities of automatically annotated documents being cheaply produced on demand.</p>
</div>
<section id="S7.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.1 </span>Layout generation</h4>

<div id="S7.SS2.SSS1.p1" class="ltx_para">
<p id="S7.SS2.SSS1.p1.1" class="ltx_p">A financial document contains various elements such as headers, sections, tables, figures and fields that are organized in a logical fashion to ensure the document is visually appealing and easy to read. Comprehending this layout structure is critical to understanding the document and involves training a visual layout recognition system using a sizable number of documents labelled with their corresponding gold layout structure. Synthetic document generation can produce visually distinct layouts, introduce new layout categories and inherently capture the labels and extents of the layout elements during the construction process, leading to automatic inclusion of ground-truth labels for the various layouts.</p>
</div>
<div id="S7.SS2.SSS1.p2" class="ltx_para">
<p id="S7.SS2.SSS1.p2.1" class="ltx_p">A simple approach for generating documents that appear dissimilar to the original is to perturb the various style attributes of an existing documentÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx64" title="" class="ltx_ref">ERCS19</a>]</cite>. This technique though is only feasible for non-binary document formats like HTML, CSS, or LaTeX, and it is limited by a narrow range of variations. Deep generative models for layout generation using self-attention Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx80" title="" class="ltx_ref">GLA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite>, adversarial training Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx124" title="" class="ltx_ref">LYH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>, autoencoder structuresÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx99" title="" class="ltx_ref">JDH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite> and semi-automatic annotation Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx149" title="" class="ltx_ref">PGM23</a>]</cite> have been proposed. However, these methods tend to require initial annotations to warm up, cannot generate new primitives and suffer from image quality issues. Instead of deep neural models,Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx167" title="" class="ltx_ref">RSV22</a>]</cite> proposes a Bayesian Network approach to generate realistic synthetic documents, which allows creating graphical units from scratch, does not require seed documents, and is interpretable. Their solution treats every primitive unit, style attribute and logical element of a document as a random variable and represents the dependencies between these random variables using conditional probability distributions. Figure Â <a href="#S7.F32" title="Figure 32 â€£ 7.2.1 Layout generation â€£ 7.2 Document generation â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">32</span></a> shows an example synthetic form generated using this approach.</p>
</div>
<figure id="S7.SS2.SSS1.2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S7.SS2.SSS1.2.2" class="ltx_tabular ltx_figure_panel ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S7.SS2.SSS1.2.2.2" class="ltx_tr">
<td id="S7.SS2.SSS1.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2401.00081/assets/x18.png" id="S7.SS2.SSS1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="325" height="213" alt="[Uncaptioned image]"></td>
<td id="S7.SS2.SSS1.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2401.00081/assets/x19.png" id="S7.SS2.SSS1.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="325" height="223" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S7.F32" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S7.F32.4.1.1" class="ltx_text" style="font-size:90%;">Figure 32</span>: </span><span id="S7.F32.5.2" class="ltx_text" style="font-size:90%;">Machine generated synthetic documentsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx167" title="" class="ltx_ref">RSV22</a>]</cite>. <em id="S7.F32.5.2.1" class="ltx_emph ltx_font_italic">left</em>: A synthetic form. <em id="S7.F32.5.2.2" class="ltx_emph ltx_font_italic">right</em>: A synthetic report annotated with layout categories such as headers, titles, or tables.</span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S7.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.2 </span>Diagram generation</h4>

<div id="S7.SS2.SSS2.p1" class="ltx_para">
<p id="S7.SS2.SSS2.p1.1" class="ltx_p">Visual diagrams that depict enterprise ownerships, management hierarchies, supply chain networks and start-up activities are often embedded inside a financial document. These diagrams illustrate complex ideas, relationships and incidents in a compact manner. An automatic question-answering system that explores these diagrams would offer considerable benefits to a business expert. However, developing such a system for <em id="S7.SS2.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">visually rich document understanding</em> demands the collection of enough diagrams, a challenging task given their proprietary nature.</p>
</div>
<div id="S7.SS2.SSS2.p2" class="ltx_para">
<p id="S7.SS2.SSS2.p2.1" class="ltx_p">Synthetic diagrams that faithfully reflect the properties of their real-world counterparts offer a viable option. While there have been previous efforts to curate plotsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx107" title="" class="ltx_ref">KMA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>, infographicsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx128" title="" class="ltx_ref">MBT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> , flowchartsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx184" title="" class="ltx_ref">TFB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> and scientific diagrams Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx110" title="" class="ltx_ref">KSK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>16</a>]</cite>, they do not pertain to the finance domain. Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">BWM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> proposes an algorithmic approach for generating synthetic diagrams applicable to various businesses. Given the underlying graph structures of real-world diagrams, they treat a graph adjacency matrix as an image, and employ an image generative model to produce new samples of these graphs. The graphs are then rendered by applying different style attributes to produce new synthetic diagrams. The availability of the underlying graph structure also facilitates the population of template question and answers, which can be used to perform complex reasoning over the diagrams. FigureÂ <a href="#S7.F33" title="Figure 33 â€£ 7.2.2 Diagram generation â€£ 7.2 Document generation â€£ 7 Unstructured data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">33</span></a> provides a sample synthetic diagram of a company ownership structure.</p>
</div>
<figure id="S7.SS2.SSS2.1" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S7.SS2.SSS2.1.1" class="ltx_tabular ltx_figure_panel ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S7.SS2.SSS2.1.1.1" class="ltx_tr">
<td id="S7.SS2.SSS2.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2401.00081/assets/figures/doclayout/diag_11.png" id="S7.SS2.SSS2.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="277" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S7.SS2.SSS2.1.1.2.1" class="ltx_tr">
<td id="S7.SS2.SSS2.1.1.2.1.1" class="ltx_td ltx_align_center">Question: Who is the ultimate parent of Sunsystem X?</td>
</tr>
<tr id="S7.SS2.SSS2.1.1.3.2" class="ltx_tr">
<td id="S7.SS2.SSS2.1.1.3.2.1" class="ltx_td ltx_align_center">Answer: Styrenics Wood Steward Sa De Cv</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S7.F33" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S7.F33.2.1.1" class="ltx_text" style="font-size:90%;">Figure 33</span>: </span><span id="S7.F33.3.2" class="ltx_text" style="font-size:90%;">Synthetic enterprise ownership diagram, along with gold question and answer pair. The diagrams can be used for training a visually rich document understanding systemÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">BWM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>. </span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S7.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.3 </span>Text generation</h4>

<div id="S7.SS2.SSS3.p1" class="ltx_para">
<p id="S7.SS2.SSS3.p1.1" class="ltx_p">Identifying the financial entities in a document or finance specific sentiment analysisÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx173" title="" class="ltx_ref">SCE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> and question answeringÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx28" title="" class="ltx_ref">CCS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite> require the availability of annotated text. Since labelled data is scarce, it is common to augment manually annotated examples with synthetically generated text. Typical approaches for text augmentation include word substitutions, back translation, summarization and paraphrasing, where a given text is converted into its equivalent form using a language modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx113" title="" class="ltx_ref">LHC22</a>]</cite>. Recent approaches such as AugGPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">DLL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> exploit large language models for conditional text generation and can achieve comparable or even better performance than task tuned models by using a small number of demonstrations. All the above methods largely aim to preserve the semantics of the original text while altering the lexical structure and can be applied to produce synthetic financial documents that are faithful to the original facts yet diverse in surface realizations.</p>
</div>
<div id="S7.SS2.SSS3.p2" class="ltx_para">
<p id="S7.SS2.SSS3.p2.1" class="ltx_p">It is also useful to generate text that diverges in semantics from the original. For instance, let a synthetic document reflect a <em id="S7.SS2.SSS3.p2.1.1" class="ltx_emph ltx_font_italic">bearish</em> sentiment in contrast to the <em id="S7.SS2.SSS3.p2.1.2" class="ltx_emph ltx_font_italic">bullish</em> sentiment expressed in the original. Such documents can simulate different scenarios in the financial markets and help train robust models. While the counterfactual text generation techniques in Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx134" title="" class="ltx_ref">MPPS21</a>, <a href="#bib.bibx54" title="" class="ltx_ref">DPHZ22</a>]</cite> are not specific to finance, they provide a generic mechanism to develop documents that demonstrate an alternative outcome. Besides modifying the facts, the text generation process may also employ privacy enhancing techniques to create synthetic documents without any personally identifiable informationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx217" title="" class="ltx_ref">ZC22</a>]</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S8" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion and Open Challenges</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">We have shown the application of synthetic data on a wide range of applications in the finance industry including fraud, customer acquisition, distributional shifts in markets, realistic time-series generation with constraints, and OCR models for checks. We expect with the increasing success of chatGPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx145" title="" class="ltx_ref">Ope23</a>]</cite> in various domains that they will have a wide spread impact in financial applications.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">Evaluating the quality of generated data (e.g. do we have task agnostic accurate metrics for assessing the preservation of and diversity in semantics, perception, structure, statistical properties, anomalies etc.),
transferability of the techniques across datasets and generalization to different tasks, explanation of what differs between a synthetic and original, Multimodal synthetic data (rather than data mode specific methods), availability of original representative data (e.g. companies with proprietary data hold advantage), and bias enhancement will increasingly play a role in the quality of synthetic data benchmarks.
Distinguishing synthetic data from real is a very pertinent question and will be increasingly an important problem as we have seen with rise of DeepfakesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx106" title="" class="ltx_ref">KLMK20</a>]</cite>. WatermarkingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx105" title="" class="ltx_ref">KGW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite> and other related cryptographic techniques such as digital signaturesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx102" title="" class="ltx_ref">Kat10</a>]</cite> will increasingly play a role for solving these kind of problems.
The use of synthetic data in financial applications is still in its infancy and we expect further open problems to arise with a wider adoption and deployments in real-world use cases.</p>
</div>
<section id="S8.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="S8.SS0.SSS0.Px1.1.1" class="ltx_text ltx_font_bold">Disclaimer</span>:</h5>

<div id="S8.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px1.p1.1" class="ltx_p">This paper was prepared for informational purposes by the Artificial Intelligence Research group of JPMorgan Chase &amp; Co. and its affiliates (â€œJP Morganâ€), and is not a product of the Research Department of JP Morgan. JP Morgan makes no representation and warranty whatsoever and disclaims all liability, for the completeness, accuracy or reliability of the information contained herein. This document is not intended as investment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale of any security, financial instrument, financial product or service, or to be used in any way for evaluating the merits of participating in any transaction, and shall not constitute a solicitation under any jurisdiction or to any person, if such solicitation under such jurisdiction or to such person would be unlawful.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ABG<sup id="bib.bibx1.4.4.1" class="ltx_sup"><span id="bib.bibx1.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Raman Arora, Raef Bassily, TomÃ¡s GonzÃ¡lez, CristÃ³balÂ A GuzmÃ¡n,
Michael Menart, and Enayat Ullah.

</span>
<span class="ltx_bibblock">Faster rates of convergence to stationary points in differentially
private optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx1.7.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
1060â€“1092. PMLR, 2023.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ACB17]</span>
<span class="ltx_bibblock">
Martin Arjovsky, Soumith Chintala, and LÃ©on Bottou.

</span>
<span class="ltx_bibblock">Wasserstein generative adversarial networks.

</span>
<span class="ltx_bibblock">In Doina Precup and YeeÂ Whye Teh, editors, <span id="bib.bibx2.1.1" class="ltx_text ltx_font_italic">Proceedings of the
34th International Conference on Machine Learning</span>, volumeÂ 70 of <span id="bib.bibx2.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pages 214â€“223. PMLR, 06â€“11 Aug
2017.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ACG<sup id="bib.bibx3.4.4.1" class="ltx_sup"><span id="bib.bibx3.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>16]</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H.Â Brendan McMahan, Ilya Mironov, Kunal
Talwar, and LiÂ Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx3.7.1" class="ltx_text ltx_font_italic">Proceedings of the 2016 ACM SIGSAC Conference on Computer
and Communications Security</span>. ACM, oct 2016.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ACvdS20]</span>
<span class="ltx_bibblock">
Ahmed Alaa, AlexÂ James Chan, and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">Generative time-series modeling with fourier flows.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx4.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2020.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ADM<sup id="bib.bibx5.4.4.1" class="ltx_sup"><span id="bib.bibx5.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
SamuelÂ A Assefa, Danial Dervovic, Mahmoud Mahfouz, RobertÂ E Tillman, Prashant
Reddy, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Generating synthetic data in finance: opportunities, challenges and
pitfalls.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx5.7.1" class="ltx_text ltx_font_italic">Proceedings of the First ACM International Conference on AI
in Finance</span>, pages 1â€“8, 2020.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ADR17]</span>
<span class="ltx_bibblock">
Vibhanshu Abhishek, Stylianos Despotakis, and RÂ Ravi.

</span>
<span class="ltx_bibblock">Multi-channel attribution: The blind spot of online advertising.

</span>
<span class="ltx_bibblock"><span id="bib.bibx6.1.1" class="ltx_text ltx_font_italic">Available at SSRN 2959778</span>, 2017.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ADR<sup id="bib.bibx7.4.4.1" class="ltx_sup"><span id="bib.bibx7.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
HassanÂ Jameel Asghar, Ming Ding, Thierry Rakotoarivelo, Sirine Mrabet, and
MohamedÂ Ali Kaafar.

</span>
<span class="ltx_bibblock">Differentially private release of high-dimensional datasets using the
gaussian copula, 2019.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ADY<sup id="bib.bibx8.4.4.1" class="ltx_sup"><span id="bib.bibx8.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
SaiÂ Kumar Arava, Chen Dong, Zhenyu Yan, Abhishek Pani, etÂ al.

</span>
<span class="ltx_bibblock">Deep neural net with attention for multi-channel multi-touch
attribution.

</span>
<span class="ltx_bibblock"><span id="bib.bibx8.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1809.02230</span>, 2018.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AMAF19]</span>
<span class="ltx_bibblock">
ShaheenÂ A Abdulkareem, YaseenÂ T Mustafa, Ellen-Wien Augustijn, and Tatiana
Filatova.

</span>
<span class="ltx_bibblock">Bayesian networks for spatial learning: a workflow on using limited
survey data for intelligent learning in spatial agent-based models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx9.1.1" class="ltx_text ltx_font_italic">Geoinformatica</span>, 23:243â€“268, 2019.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ATLO17]</span>
<span class="ltx_bibblock">
Sameera Abar, GeorgiosÂ K Theodoropoulos, Pierre Lemarinier, and GregoryÂ MP
Oâ€™Hare.

</span>
<span class="ltx_bibblock">Agent based modelling and simulation tools: A review of the
state-of-art software.

</span>
<span class="ltx_bibblock"><span id="bib.bibx10.1.1" class="ltx_text ltx_font_italic">Computer Science Review</span>, 24:13â€“33, 2017.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AvBSvdS21]</span>
<span class="ltx_bibblock">
AhmedÂ M Alaa, Boris van Breugel, Evgeny Saveliev, and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">How faithful is your synthetic data? sample-level metrics for
evaluating and auditing generative models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.08921</span>, 2021.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AVG<sup id="bib.bibx12.4.4.1" class="ltx_sup"><span id="bib.bibx12.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Leo Ardon, Jared Vann, Deepeka Garg, Tom Spooner, and Sumitra Ganesh.

</span>
<span class="ltx_bibblock">Phantomâ€“an rl-driven framework for agent-based modeling of complex
economic systems and markets.

</span>
<span class="ltx_bibblock"><span id="bib.bibx12.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.06012</span>, 2022.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BBDG18]</span>
<span class="ltx_bibblock">
Jean-Philippe Bouchaud, Julius Bonart, Jonathan Donier, and Martin Gould.

</span>
<span class="ltx_bibblock"><span id="bib.bibx13.1.1" class="ltx_text ltx_font_italic">Trades, quotes and prices: financial markets under the
microscope</span>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 2018.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BD19]</span>
<span class="ltx_bibblock">
GeorgeÂ EP Box and NormanÂ R Draper.

</span>
<span class="ltx_bibblock">Essentially, all models are wrong, but some are useful.

</span>
<span class="ltx_bibblock"><span id="bib.bibx14.1.1" class="ltx_text ltx_font_italic">Statistician</span>, 3(28):2013, 1919.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BFELV23]</span>
<span class="ltx_bibblock">
Thomas Bamford, Elizabeth Fons, Yousef El-Laham, and Svitlana Vyetrenko.

</span>
<span class="ltx_bibblock">Mads: Modulated auto-decoding siren for time series imputation.

</span>
<span class="ltx_bibblock"><span id="bib.bibx15.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, abs/2307.00868, 2023.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BHB19]</span>
<span class="ltx_bibblock">
David Byrd, Maria Hybinette, and TuckerÂ Hybinette Balch.

</span>
<span class="ltx_bibblock">Abides: Towards high-fidelity market simulation for AI research.

</span>
<span class="ltx_bibblock"><span id="bib.bibx16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.12066</span>, 2019.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BML<sup id="bib.bibx17.4.4.1" class="ltx_sup"><span id="bib.bibx17.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
TuckerÂ Hybinette Balch, Mahmoud Mahfouz, Joshua Lockhart, Maria Hybinette, and
David Byrd.

</span>
<span class="ltx_bibblock">How to evaluate trading strategies: Single agent market replay or
multiple agent interactive simulation?

</span>
<span class="ltx_bibblock"><span id="bib.bibx17.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1906.12010</span>, 2019.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BP66]</span>
<span class="ltx_bibblock">
LeonardÂ E Baum and Ted Petrie.

</span>
<span class="ltx_bibblock">Statistical inference for probabilistic functions of finite state
markov chains.

</span>
<span class="ltx_bibblock"><span id="bib.bibx18.1.1" class="ltx_text ltx_font_italic">The annals of mathematical statistics</span>, 37(6):1554â€“1563, 1966.

</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BR11]</span>
<span class="ltx_bibblock">
Nicole BÃ¤uerle and Ulrich Rieder.

</span>
<span class="ltx_bibblock"><span id="bib.bibx19.1.1" class="ltx_text ltx_font_italic">Markov decision processes with applications to finance</span>.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 2011.

</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Bra14]</span>
<span class="ltx_bibblock">
Paolo Brandimarte.

</span>
<span class="ltx_bibblock"><span id="bib.bibx20.1.1" class="ltx_text ltx_font_italic">Handbook in Monte Carlo simulation: applications in financial
engineering, risk management, and economics</span>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2014.

</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BV20]</span>
<span class="ltx_bibblock">
Daniel Borrajo and Manuela Veloso.

</span>
<span class="ltx_bibblock">Domain-independent generation and classification of behavior traces.

</span>
<span class="ltx_bibblock"><span id="bib.bibx21.1.1" class="ltx_text ltx_font_italic">arXiv e-prints</span>, abs/2011.02918, 2020.

</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BVD17]</span>
<span class="ltx_bibblock">
RichardÂ J Boucherie and NicoÂ M VanÂ Dijk.

</span>
<span class="ltx_bibblock"><span id="bib.bibx22.1.1" class="ltx_text ltx_font_italic">Markov decision processes in practice</span>, volume 248.

</span>
<span class="ltx_bibblock">Springer, 2017.

</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BVS20]</span>
<span class="ltx_bibblock">
Daniel Borrajo, Manuela Veloso, and Sameena Shah.

</span>
<span class="ltx_bibblock">Simulating and classifying behavior in adversarial environments based
on action-state traces: An application to money laundering.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx23.1.1" class="ltx_text ltx_font_italic">Proceedings of the First ACM International Conference on AI
in Finance</span>, New York (EEUU), 2020.

</span>
<span class="ltx_bibblock">Also in: https://arxiv.org/abs/2011.01826.

</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BWM<sup id="bib.bibx24.4.4.1" class="ltx_sup"><span id="bib.bibx24.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Petr Babkin, William Watson, Zhiqiang Ma, Lucas Cecchi, Natraj Raman, Armineh
Nourbakhsh, and Sameena Shah.

</span>
<span class="ltx_bibblock">Bizgraphqa: A dataset for image-based inference over graph-structured
diagrams from business domains.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx24.7.1" class="ltx_text ltx_font_italic">Proceedings of the 46th International ACM SIGIR Conference on
Research and Development in Information Retrieval</span>, 2023.

</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Byr19]</span>
<span class="ltx_bibblock">
David Byrd.

</span>
<span class="ltx_bibblock">Explaining agent-based financial market simulation.

</span>
<span class="ltx_bibblock"><span id="bib.bibx25.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1909.11650, 2019.

</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CBC<sup id="bib.bibx26.4.4.1" class="ltx_sup"><span id="bib.bibx26.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Jen-HaoÂ Rick Chang, Martin Bresler, Youssouf Chherawala, Adrien Delaye, Thomas
Deselaers, Ryan Dixon, and Oncel Tuzel.

</span>
<span class="ltx_bibblock">Data incubationâ€”synthesizing missing data for handwriting
recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx26.7.1" class="ltx_text ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</span>, pages 4188â€“4192. IEEE, 2022.

</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CBHK02]</span>
<span class="ltx_bibblock">
NiteshÂ V Chawla, KevinÂ W Bowyer, LawrenceÂ O Hall, and WÂ Philip Kegelmeyer.

</span>
<span class="ltx_bibblock">Smote: synthetic minority over-sampling technique.

</span>
<span class="ltx_bibblock"><span id="bib.bibx27.1.1" class="ltx_text ltx_font_italic">Journal of artificial intelligence research</span>, 16:321â€“357, 2002.

</span>
</li>
<li id="bib.bibx28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CCS<sup id="bib.bibx28.4.4.1" class="ltx_sup"><span id="bib.bibx28.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan
Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, etÂ al.

</span>
<span class="ltx_bibblock">Finqa: A dataset of numerical reasoning over financial data.

</span>
<span class="ltx_bibblock">2021.

</span>
</li>
<li id="bib.bibx29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CELT<sup id="bib.bibx29.4.4.1" class="ltx_sup"><span id="bib.bibx29.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Defu Cao, Yousef El-Laham, Loc Trinh, Svitlana Vyetrenko, and Yan Liu.

</span>
<span class="ltx_bibblock">Dslob: A synthetic limit order book dataset for benchmarking
forecasting algorithms under distributional shift, 2022.

</span>
</li>
<li id="bib.bibx30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CG16]</span>
<span class="ltx_bibblock">
Tianqi Chen and Carlos Guestrin.

</span>
<span class="ltx_bibblock">Xgboost: A scalable tree boosting system.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx30.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22nd acm sigkdd international conference
on knowledge discovery and data mining</span>, pages 785â€“794, 2016.

</span>
</li>
<li id="bib.bibx31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CGBV23]</span>
<span class="ltx_bibblock">
Andrea Coletta, Sriram Gopalakrishan, Daniel Borrajo, and Svitlana Vyetrenko.

</span>
<span class="ltx_bibblock">On the constrained time-series generation problem.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx31.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2023.

</span>
</li>
<li id="bib.bibx32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Cho95]</span>
<span class="ltx_bibblock">
DÂ Chorafas.

</span>
<span class="ltx_bibblock"><span id="bib.bibx32.1.1" class="ltx_text ltx_font_italic">Financial models and simulation</span>.

</span>
<span class="ltx_bibblock">Springer, 1995.

</span>
</li>
<li id="bib.bibx33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CI80]</span>
<span class="ltx_bibblock">
DavidÂ Roxbee Cox and Valerie Isham.

</span>
<span class="ltx_bibblock"><span id="bib.bibx33.1.1" class="ltx_text ltx_font_italic">Point processes</span>, volumeÂ 12.

</span>
<span class="ltx_bibblock">CRC Press, 1980.

</span>
</li>
<li id="bib.bibx34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Cin13]</span>
<span class="ltx_bibblock">
Erhan Cinlar.

</span>
<span class="ltx_bibblock"><span id="bib.bibx34.1.1" class="ltx_text ltx_font_italic">Introduction to stochastic processes</span>.

</span>
<span class="ltx_bibblock">Courier Corporation, 2013.

</span>
</li>
<li id="bib.bibx35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CJSV23]</span>
<span class="ltx_bibblock">
Andrea Coletta, Joseph Jerome, Rahul Savani, and Svitlana Vyetrenko.

</span>
<span class="ltx_bibblock">Conditional generators for limit order book environments:
Explainability, challenges, and robustness.

</span>
<span class="ltx_bibblock"><span id="bib.bibx35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.12806</span>, 2023.

</span>
</li>
<li id="bib.bibx36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CK11]</span>
<span class="ltx_bibblock">
Tanmoy Chakraborty and Michael Kearns.

</span>
<span class="ltx_bibblock">Market making and mean reversion.

</span>
<span class="ltx_bibblock">pages 307â€“314, 06 2011.

</span>
</li>
<li id="bib.bibx37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CLM22]</span>
<span class="ltx_bibblock">
Wen-Hao Chiang, Xueying Liu, and George Mohler.

</span>
<span class="ltx_bibblock">Hawkes process modeling of covid-19 with mobility leading indicators
and spatial covariates.

</span>
<span class="ltx_bibblock"><span id="bib.bibx37.1.1" class="ltx_text ltx_font_italic">International journal of forecasting</span>, 38(2):505â€“520, 2022.

</span>
</li>
<li id="bib.bibx38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CLW21]</span>
<span class="ltx_bibblock">
Yinbo Chen, Sifei Liu, and Xiaolong Wang.

</span>
<span class="ltx_bibblock">Learning continuous image representation with local implicit image
function.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx38.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 8628â€“8638, 2021.

</span>
</li>
<li id="bib.bibx39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CMVB22]</span>
<span class="ltx_bibblock">
Andrea Coletta, Aymeric Moulin, Svitlana Vyetrenko, and Tucker Balch.

</span>
<span class="ltx_bibblock">Learning to simulate realistic limit order book markets from data as
a world agent.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx39.1.1" class="ltx_text ltx_font_italic">Proceedings of the Third ACM International Conference on AI
in Finance</span>, pages 428â€“436, 2022.

</span>
</li>
<li id="bib.bibx40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Cox55]</span>
<span class="ltx_bibblock">
DavidÂ R Cox.

</span>
<span class="ltx_bibblock">Some statistical methods connected with series of events.

</span>
<span class="ltx_bibblock"><span id="bib.bibx40.1.1" class="ltx_text ltx_font_italic">Journal of the Royal Statistical Society: Series B
(Methodological)</span>, 17(2):129â€“157, 1955.

</span>
</li>
<li id="bib.bibx41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CPC<sup id="bib.bibx41.4.4.1" class="ltx_sup"><span id="bib.bibx41.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Andrea Coletta, Matteo Prata, Michele Conti, Emanuele Mercanti, Novella
Bartolini, Aymeric Moulin, Svitlana Vyetrenko, and Tucker Balch.

</span>
<span class="ltx_bibblock">Towards realistic market simulations: a generative adversarial
networks approach.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx41.7.1" class="ltx_text ltx_font_italic">Proceedings of the Second ACM International Conference on AI
in Finance</span>, pages 1â€“9, 2021.

</span>
</li>
<li id="bib.bibx42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CR10]</span>
<span class="ltx_bibblock">
Gregory Caiola and JeromeÂ P Reiter.

</span>
<span class="ltx_bibblock">Random forests for generating partially synthetic, categorical data.

</span>
<span class="ltx_bibblock"><span id="bib.bibx42.1.1" class="ltx_text ltx_font_italic">Trans. Data Priv.</span>, 3(1):27â€“42, 2010.

</span>
</li>
<li id="bib.bibx43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CRS<sup id="bib.bibx43.4.4.1" class="ltx_sup"><span id="bib.bibx43.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, JohnÂ C Duchi, and PercyÂ S
Liang.

</span>
<span class="ltx_bibblock">Unlabeled data improves adversarial robustness.

</span>
<span class="ltx_bibblock">In H.Â Wallach, H.Â Larochelle, A.Â Beygelzimer, F.Â d'AlchÃ©-Buc, E.Â Fox, and R.Â Garnett, editors, <span id="bib.bibx43.7.1" class="ltx_text ltx_font_italic">Advances in Neural
Information Processing Systems</span>, volumeÂ 32. Curran Associates, Inc., 2019.

</span>
</li>
<li id="bib.bibx44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CSK<sup id="bib.bibx44.4.4.1" class="ltx_sup"><span id="bib.bibx44.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Jen-HaoÂ Rick Chang, Ashish Shrivastava, Hema Koppula, Xiaoshuai Zhang, and
Oncel Tuzel.

</span>
<span class="ltx_bibblock">Style equalization: Unsupervised learning of controllable generative
sequence models.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx44.7.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
2917â€“2937. PMLR, 2022.

</span>
</li>
<li id="bib.bibx45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CVB23]</span>
<span class="ltx_bibblock">
Andrea Coletta, Svitlana Vyetrenko, and Tucker Balch.

</span>
<span class="ltx_bibblock">K-shap: Policy clustering algorithm for anonymous state-action pairs.

</span>
<span class="ltx_bibblock"><span id="bib.bibx45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.11996</span>, 2023.

</span>
</li>
<li id="bib.bibx46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CWL<sup id="bib.bibx46.4.4.1" class="ltx_sup"><span id="bib.bibx46.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li, and Yitan Li.

</span>
<span class="ltx_bibblock">Brits: Bidirectional recurrent imputation for time series.

</span>
<span class="ltx_bibblock">In S.Â Bengio, H.Â Wallach, H.Â Larochelle, K.Â Grauman, N.Â Cesa-Bianchi,
and R.Â Garnett, editors, <span id="bib.bibx46.7.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing
Systems</span>, volumeÂ 31. Curran Associates, Inc., 2018.

</span>
</li>
<li id="bib.bibx47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CZM<sup id="bib.bibx47.4.4.1" class="ltx_sup"><span id="bib.bibx47.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
EkinÂ D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and QuocÂ V. Le.

</span>
<span class="ltx_bibblock">Autoaugment: Learning augmentation strategies from data.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx47.7.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, June 2019.

</span>
</li>
<li id="bib.bibx48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CZSL20]</span>
<span class="ltx_bibblock">
EkinÂ D. Cubuk, Barret Zoph, Jonathon Shlens, and QuocÂ V. Le.

</span>
<span class="ltx_bibblock">Randaugment: Practical automated data augmentation with a reduced
search space.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx48.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR) Workshops</span>, June 2020.

</span>
</li>
<li id="bib.bibx49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DFWB21]</span>
<span class="ltx_bibblock">
Abhyuday Desai, Cynthia Freeman, Zuhui Wang, and Ian Beaver.

</span>
<span class="ltx_bibblock">Timevae: A variational auto-encoder for multivariate time series
generation.

</span>
<span class="ltx_bibblock"><span id="bib.bibx49.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2111.08095</span>, 2021.

</span>
</li>
<li id="bib.bibx50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DLAG<sup id="bib.bibx50.4.4.1" class="ltx_sup"><span id="bib.bibx50.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Luca DiÂ Liello, Pierfrancesco Ardino, Jacopo Gobbi, Paolo Morettin, Stefano
Teso, and Andrea Passerini.

</span>
<span class="ltx_bibblock">Efficient generation of structured objects with constrained
adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx50.7.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>,
33:14663â€“14674, 2020.

</span>
</li>
<li id="bib.bibx51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DLL<sup id="bib.bibx51.4.4.1" class="ltx_sup"><span id="bib.bibx51.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Huang, Zihao Wu, Lin Zhao,
Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu, etÂ al.

</span>
<span class="ltx_bibblock">Chataug: Leveraging chatgpt for text data augmentation.

</span>
<span class="ltx_bibblock"><span id="bib.bibx51.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.13007</span>, 2023.

</span>
</li>
<li id="bib.bibx52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DM19]</span>
<span class="ltx_bibblock">
Yilun Du and Igor Mordatch.

</span>
<span class="ltx_bibblock">Implicit generation and modeling with energy based models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx52.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 32, 2019.

</span>
</li>
<li id="bib.bibx53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Doe16]</span>
<span class="ltx_bibblock">
Carl Doersch.

</span>
<span class="ltx_bibblock">Tutorial on variational autoencoders.

</span>
<span class="ltx_bibblock"><span id="bib.bibx53.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1606.05908</span>, 2016.

</span>
</li>
<li id="bib.bibx54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DPHZ22]</span>
<span class="ltx_bibblock">
Tanay Dixit, Bhargavi Paranjape, Hannaneh Hajishirzi, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">CORE: A retrieve-then-edit framework for counterfactual data
generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx54.1.1" class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2022</span>, pages 2964â€“2984, Abu Dhabi, United Arab Emirates, December
2022. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bibx55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DR<sup id="bib.bibx55.4.4.1" class="ltx_sup"><span id="bib.bibx55.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>14]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Aaron Roth, etÂ al.

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bibx55.7.1" class="ltx_text ltx_font_italic">Found. Trends Theor. Comput. Sci.</span>, 9(3-4):211â€“407, 2014.

</span>
</li>
<li id="bib.bibx56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DVJ<sup id="bib.bibx56.4.4.1" class="ltx_sup"><span id="bib.bibx56.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>03]</span>
<span class="ltx_bibblock">
DarylÂ J Daley, David Vere-Jones, etÂ al.

</span>
<span class="ltx_bibblock"><span id="bib.bibx56.7.1" class="ltx_text ltx_font_italic">An introduction to the theory of point processes: volume I:
elementary theory and methods</span>.

</span>
<span class="ltx_bibblock">Springer, 2003.

</span>
</li>
<li id="bib.bibx57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DZ13]</span>
<span class="ltx_bibblock">
Angelos Dassios and Hongbiao Zhao.

</span>
<span class="ltx_bibblock">Exact simulation of Hawkes process with exponentially decaying
intensity.

</span>
<span class="ltx_bibblock"><span id="bib.bibx57.1.1" class="ltx_text ltx_font_italic">Electronic Communications in Probability</span>, 18(none):1 â€“ 13,
2013.

</span>
</li>
<li id="bib.bibx58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DZGZ21]</span>
<span class="ltx_bibblock">
Zhun Deng, Linjun Zhang, Amirata Ghorbani, and James Zou.

</span>
<span class="ltx_bibblock">Improving adversarial robustness via unlabeled out-of-domain data.

</span>
<span class="ltx_bibblock">In Arindam Banerjee and Kenji Fukumizu, editors, <span id="bib.bibx58.1.1" class="ltx_text ltx_font_italic">Proceedings of
The 24th International Conference on Artificial Intelligence and Statistics</span>,
volume 130 of <span id="bib.bibx58.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pages
2845â€“2853. PMLR, 13â€“15 Apr 2021.

</span>
</li>
<li id="bib.bibx59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[EHR17a]</span>
<span class="ltx_bibblock">
CristÃ³bal Esteban, StephanieÂ L Hyland, and Gunnar RÃ¤tsch.

</span>
<span class="ltx_bibblock">Real-valued (medical) time series generation with recurrent
conditional gans.

</span>
<span class="ltx_bibblock"><span id="bib.bibx59.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1706.02633</span>, 2017.

</span>
</li>
<li id="bib.bibx60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[EHR17b]</span>
<span class="ltx_bibblock">
CristÃ³bal Esteban, StephanieÂ L. Hyland, and Gunnar RÃ¤tsch.

</span>
<span class="ltx_bibblock">Real-valued (medical) time series generation with recurrent
conditional gans, 2017.

</span>
</li>
<li id="bib.bibx61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[EKM13]</span>
<span class="ltx_bibblock">
Paul Embrechts, Claudia KlÃ¼ppelberg, and Thomas Mikosch.

</span>
<span class="ltx_bibblock"><span id="bib.bibx61.1.1" class="ltx_text ltx_font_italic">Modelling extremal events: for insurance and finance</span>,
volumeÂ 33.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 2013.

</span>
</li>
<li id="bib.bibx62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ELDFV23]</span>
<span class="ltx_bibblock">
Yousef El-Laham, NiccolÃ² Dalmasso, Elizabeth Fons, and Svitlana Vyetrenko.

</span>
<span class="ltx_bibblock">Deep gaussian mixture ensembles.

</span>
<span class="ltx_bibblock"><span id="bib.bibx62.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.07235</span>, 2023.

</span>
</li>
<li id="bib.bibx63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ELV22]</span>
<span class="ltx_bibblock">
Yousef El-Laham and Svitlana Vyetrenko.

</span>
<span class="ltx_bibblock">Styletime: Style transfer for synthetic time series generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx63.1.1" class="ltx_text ltx_font_italic">Proceedings of the Third ACM International Conference on AI
in Finance</span>, pages 489â€“496, 2022.

</span>
</li>
<li id="bib.bibx64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ERCS19]</span>
<span class="ltx_bibblock">
David Etter, Stephen Rawls, Cameron Carpenter, and Gregory Sell.

</span>
<span class="ltx_bibblock">A synthetic recipe for ocr.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx64.1.1" class="ltx_text ltx_font_italic">2019 International Conference on Document Analysis and
Recognition (ICDAR)</span>, pages 864â€“869. IEEE, 2019.

</span>
</li>
<li id="bib.bibx65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ET08]</span>
<span class="ltx_bibblock">
Josh Eno and CraigÂ W Thompson.

</span>
<span class="ltx_bibblock">Generating synthetic data to match data mining patterns.

</span>
<span class="ltx_bibblock"><span id="bib.bibx65.1.1" class="ltx_text ltx_font_italic">IEEE Internet Computing</span>, 12(3):78â€“82, 2008.

</span>
</li>
<li id="bib.bibx66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[EVY<sup id="bib.bibx66.4.4.1" class="ltx_sup"><span id="bib.bibx66.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Andrew Estornell, StylianosÂ Loukas Vasileiou, William Yeoh, Daniel Borrajo, and
Rui Silva.

</span>
<span class="ltx_bibblock">Predicting customer goals in financial institution services: A
data-driven LSTM approach.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx66.7.1" class="ltx_text ltx_font_italic">ICAPS Planning for Financial Services Workshop</span>, 2023.

</span>
</li>
<li id="bib.bibx67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FAEC<sup id="bib.bibx67.4.4.1" class="ltx_sup"><span id="bib.bibx67.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Sharon Fogel, Hadar Averbuch-Elor, Sarel Cohen, Shai Mazor, and Roee Litman.

</span>
<span class="ltx_bibblock">Scrabblegan: Semi-supervised varying length handwritten text
generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx67.7.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span>, pages 4324â€“4333, 2020.

</span>
</li>
<li id="bib.bibx68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FDjZ<sup id="bib.bibx68.4.4.1" class="ltx_sup"><span id="bib.bibx68.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Elizabeth Fons, Paula Dawson, Xiao jun Zeng, John Keane, and Alexandros
Iosifidis.

</span>
<span class="ltx_bibblock">Adaptive weighting scheme for automatic time-series data
augmentation, 2021.

</span>
</li>
<li id="bib.bibx69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FDZ<sup id="bib.bibx69.4.4.1" class="ltx_sup"><span id="bib.bibx69.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, and Alexandros
Iosifidis.

</span>
<span class="ltx_bibblock">Evaluating data augmentation for financial time series
classification.

</span>
<span class="ltx_bibblock"><span id="bib.bibx69.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2010.15111</span>, 2020.

</span>
</li>
<li id="bib.bibx70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FDZ<sup id="bib.bibx70.4.4.1" class="ltx_sup"><span id="bib.bibx70.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, and Alexandros
Iosifidis.

</span>
<span class="ltx_bibblock">Augmenting transferred representations for stock classification.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx70.7.1" class="ltx_text ltx_font_italic">ICASSP 2021 - 2021 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 3915â€“3919, 2021.

</span>
</li>
<li id="bib.bibx71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[fed]</span>
<span class="ltx_bibblock">
https://www.federalreserve.gov/publications/2023-stress-test-scenarios.htm.

</span>
</li>
<li id="bib.bibx72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FHMR88]</span>
<span class="ltx_bibblock">
Mark Fox, Nizwer Husain, Malcolm McRoberts, and YVÂ Reddy.

</span>
<span class="ltx_bibblock"><span id="bib.bibx72.1.1" class="ltx_text ltx_font_italic">Knowledge based simulation: an artificial intelligence approach
to system modeling and automating the simulation life cycle</span>.

</span>
<span class="ltx_bibblock">Carnegie Mellon University, the Robotics Institute, 1988.

</span>
</li>
<li id="bib.bibx73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FSEL<sup id="bib.bibx73.4.4.1" class="ltx_sup"><span id="bib.bibx73.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Elizabeth Fons, Alejandro Sztrajman, Yousef El-Laham, Alexandros Iosifidis, and
Svitlana Vyetrenko.

</span>
<span class="ltx_bibblock">Hypertime: Implicit neural representation for time series.

</span>
<span class="ltx_bibblock"><span id="bib.bibx73.7.1" class="ltx_text ltx_font_italic">ArXiv</span>, abs/2208.05836, 2022.

</span>
</li>
<li id="bib.bibx74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[FVLK<sup id="bib.bibx74.4.4.1" class="ltx_sup"><span id="bib.bibx74.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Philippe Fournier-Viger, Jerry Chun-Wei Lin, RageÂ Uday Kiran, YunÂ Sing Koh, and
Rincy Thomas.

</span>
<span class="ltx_bibblock">A survey of sequential pattern mining.

</span>
<span class="ltx_bibblock"><span id="bib.bibx74.7.1" class="ltx_text ltx_font_italic">Data Science and Pattern Recognition</span>, 1(1):54â€“77, 2017.

</span>
</li>
<li id="bib.bibx75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GBR21]</span>
<span class="ltx_bibblock">
Grigoriy Gogoshin, Sergio Branciamore, and AndreiÂ S Rodin.

</span>
<span class="ltx_bibblock">Synthetic data generation with probabilistic bayesian networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx75.1.1" class="ltx_text ltx_font_italic">Mathematical biosciences and engineering: MBE</span>, 18(6):8603,
2021.

</span>
</li>
<li id="bib.bibx76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GDL<sup id="bib.bibx76.4.4.1" class="ltx_sup"><span id="bib.bibx76.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Mohsen Ghassemi, NiccolÃ² Dalmasso, Simran Lamba, Vamsi Potluru, Tucker Balch,
Sameena Shah, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Online learning for mixture of multivariate hawkes processes.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx76.7.1" class="ltx_text ltx_font_italic">Proceedings of the Third ACM International Conference on AI
in Finance</span>, ICAIF â€™22, page 506â€“513, New York, NY, USA, 2022. Association
for Computing Machinery.

</span>
</li>
<li id="bib.bibx77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GG16]</span>
<span class="ltx_bibblock">
Yarin Gal and Zoubin Ghahramani.

</span>
<span class="ltx_bibblock">Dropout as a bayesian approximation: Representing model uncertainty
in deep learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx77.1.1" class="ltx_text ltx_font_italic">international conference on machine learning</span>, pages
1050â€“1059. PMLR, 2016.

</span>
</li>
<li id="bib.bibx78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Gha97]</span>
<span class="ltx_bibblock">
Zoubin Ghahramani.

</span>
<span class="ltx_bibblock">Learning dynamic bayesian networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx78.1.1" class="ltx_text ltx_font_italic">International School on Neural Networks, Initiated by IIASS and
EMFCSC</span>, pages 168â€“197, 1997.

</span>
</li>
<li id="bib.bibx79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GKD<sup id="bib.bibx79.4.4.1" class="ltx_sup"><span id="bib.bibx79.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Mohsen Ghassemi, Eleonora KreaÄiÄ‡, NiccolÃ² Dalmasso, VamsiÂ K. Potluru,
Tucker Balch, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Differentially private learning of hawkes processes.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li id="bib.bibx80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GLA<sup id="bib.bibx80.4.4.1" class="ltx_sup"><span id="bib.bibx80.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Kamal Gupta, Justin Lazarow, Alessandro Achille, LarryÂ S Davis, Vijay
Mahadevan, and Abhinav Shrivastava.

</span>
<span class="ltx_bibblock">Layouttransformer: Layout generation and completion with
self-attention.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx80.7.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span>, pages 1004â€“1014, 2021.

</span>
</li>
<li id="bib.bibx81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GNT04]</span>
<span class="ltx_bibblock">
Malik Ghallab, Dana Nau, and Paolo Traverso.

</span>
<span class="ltx_bibblock"><span id="bib.bibx81.1.1" class="ltx_text ltx_font_italic">Automated Planning. Theory &amp; Practice</span>.

</span>
<span class="ltx_bibblock">Morgan Kaufmann, 2004.

</span>
</li>
<li id="bib.bibx82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Goo16]</span>
<span class="ltx_bibblock">
Ian Goodfellow.

</span>
<span class="ltx_bibblock">Nips 2016 tutorial: Generative adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx82.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1701.00160</span>, 2016.

</span>
</li>
<li id="bib.bibx83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GPAM<sup id="bib.bibx83.4.4.1" class="ltx_sup"><span id="bib.bibx83.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>14a]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial nets.

</span>
<span class="ltx_bibblock">In Z.Â Ghahramani, M.Â Welling, C.Â Cortes, N.Â Lawrence, and K.Q.
Weinberger, editors, <span id="bib.bibx83.7.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
volumeÂ 27. Curran Associates, Inc., 2014.

</span>
</li>
<li id="bib.bibx84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GPAM<sup id="bib.bibx84.4.4.1" class="ltx_sup"><span id="bib.bibx84.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>14b]</span>
<span class="ltx_bibblock">
IanÂ J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David
Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks, 2014.

</span>
</li>
<li id="bib.bibx85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Gra11]</span>
<span class="ltx_bibblock">
Alex Graves.

</span>
<span class="ltx_bibblock">Practical variational inference for neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx85.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 24, 2011.

</span>
</li>
<li id="bib.bibx86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GSLO<sup id="bib.bibx86.4.4.1" class="ltx_sup"><span id="bib.bibx86.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
GabrielÂ Lima Guimaraes, Benjamin Sanchez-Lengeling, Carlos Outeiral, Pedro
LuisÂ Cunha Farias, and AlÃ¡n Aspuru-Guzik.

</span>
<span class="ltx_bibblock">Objective-reinforced generative adversarial networks (organ) for
sequence generation models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx86.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1705.10843</span>, 2017.

</span>
</li>
<li id="bib.bibx87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HAP21]</span>
<span class="ltx_bibblock">
Frederik Harder, Kamil Adamczewski, and Mijung Park.

</span>
<span class="ltx_bibblock">Dp-merf: Differentially private mean embeddings with random features
for practical privacy-preserving data generation, 2021.

</span>
</li>
<li id="bib.bibx88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Haw71]</span>
<span class="ltx_bibblock">
AlanÂ G Hawkes.

</span>
<span class="ltx_bibblock">Spectra of some self-exciting and mutually exciting point processes.

</span>
<span class="ltx_bibblock"><span id="bib.bibx88.1.1" class="ltx_text ltx_font_italic">Biometrika</span>, 58(1):83â€“90, 1971.

</span>
</li>
<li id="bib.bibx89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Heg22]</span>
<span class="ltx_bibblock">
Thomas Hegghammer.

</span>
<span class="ltx_bibblock">Ocr with tesseract, amazon textract, and google document ai: a
benchmarking experiment.

</span>
<span class="ltx_bibblock"><span id="bib.bibx89.1.1" class="ltx_text ltx_font_italic">Journal of Computational Social Science</span>, 5(1):861â€“882, 2022.

</span>
</li>
<li id="bib.bibx90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HLC<sup id="bib.bibx90.4.4.1" class="ltx_sup"><span id="bib.bibx90.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Daniel Ho, Eric Liang, XiÂ Chen, Ion Stoica, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Population based augmentation: Efficient learning of augmentation
policy schedules.

</span>
<span class="ltx_bibblock">In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, <span id="bib.bibx90.7.1" class="ltx_text ltx_font_italic">Proceedings of the 36th International Conference on Machine Learning</span>,
volumeÂ 97 of <span id="bib.bibx90.8.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pages
2731â€“2741. PMLR, 09â€“15 Jun 2019.

</span>
</li>
<li id="bib.bibx91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HNSOP23]</span>
<span class="ltx_bibblock">
Fadi Hamad, Shinpei Nakamura-Sakai, Saheed Obitayo, and Vamsi Potluru.

</span>
<span class="ltx_bibblock">A supervised generative optimization approach for tabular data.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx91.1.1" class="ltx_text ltx_font_italic">4th ACM International Conference on AI in Finance</span>, pages
10â€“18, 2023.

</span>
</li>
<li id="bib.bibx92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HS97]</span>
<span class="ltx_bibblock">
Sepp Hochreiter and JÃ¼rgen Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><span id="bib.bibx92.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 9(8):1735â€“1780, 1997.

</span>
</li>
<li id="bib.bibx93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HSW89]</span>
<span class="ltx_bibblock">
Kurt Hornik, Maxwell Stinchcombe, and Halbert White.

</span>
<span class="ltx_bibblock">Multilayer feedforward networks are universal approximators.

</span>
<span class="ltx_bibblock"><span id="bib.bibx93.1.1" class="ltx_text ltx_font_italic">Neural networks</span>, 2(5):359â€“366, 1989.

</span>
</li>
<li id="bib.bibx94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[I<sup id="bib.bibx94.4.4.1" class="ltx_sup"><span id="bib.bibx94.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>08]</span>
<span class="ltx_bibblock">
StefanoÂ M Iacus etÂ al.

</span>
<span class="ltx_bibblock"><span id="bib.bibx94.7.1" class="ltx_text ltx_font_italic">Simulation and inference for stochastic differential equations:
with R examples</span>, volume 486.

</span>
<span class="ltx_bibblock">Springer, 2008.

</span>
</li>
<li id="bib.bibx95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[IU21]</span>
<span class="ltx_bibblock">
BrianÂ Kenji Iwana and Seiichi Uchida.

</span>
<span class="ltx_bibblock">An empirical survey of data augmentation for time series
classification with neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx95.1.1" class="ltx_text ltx_font_italic">PLOS ONE</span>, 16(7):e0254841, Jul 2021.

</span>
</li>
<li id="bib.bibx96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[IW79]</span>
<span class="ltx_bibblock">
Valerie Isham and Mark Westcott.

</span>
<span class="ltx_bibblock">A self-correcting point process.

</span>
<span class="ltx_bibblock"><span id="bib.bibx96.1.1" class="ltx_text ltx_font_italic">Stochastic processes and their applications</span>, 8(3):335â€“347,
1979.

</span>
</li>
<li id="bib.bibx97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JB19]</span>
<span class="ltx_bibblock">
Junteng Jia and AustinÂ R Benson.

</span>
<span class="ltx_bibblock">Neural jump stochastic differential equations.

</span>
<span class="ltx_bibblock"><span id="bib.bibx97.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 32, 2019.

</span>
</li>
<li id="bib.bibx98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JCL<sup id="bib.bibx98.4.4.1" class="ltx_sup"><span id="bib.bibx98.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Daniel Jarrett, Bogdan Cebere, Tennison Liu, Alicia Curth, and Mihaela vanÂ der
Schaar.

</span>
<span class="ltx_bibblock">Hyperimpute: Generalized iterative imputation with automatic model
selection.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li id="bib.bibx99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JDH<sup id="bib.bibx99.4.4.1" class="ltx_sup"><span id="bib.bibx99.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
AkashÂ Abdu Jyothi, Thibaut Durand, Jiawei He, Leonid Sigal, and Greg Mori.

</span>
<span class="ltx_bibblock">Layoutvae: Stochastic scene layout generation from a label set.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx99.7.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span>, pages 9895â€“9904, 2019.

</span>
</li>
<li id="bib.bibx100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JSH<sup id="bib.bibx100.4.4.1" class="ltx_sup"><span id="bib.bibx100.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
James Jordon, Lukasz Szpruch, Florimond Houssiau, Mirko Bottarelli, Giovanni
Cherubin, Carsten Maple, SamuelÂ N. Cohen, and Adrian Weller.

</span>
<span class="ltx_bibblock">Synthetic data â€“ what, why and how?, 2022.

</span>
</li>
<li id="bib.bibx101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Kal60]</span>
<span class="ltx_bibblock">
RudolphÂ Emil Kalman.

</span>
<span class="ltx_bibblock">A new approach to linear filtering and prediction problems.

</span>
<span class="ltx_bibblock"><span id="bib.bibx101.1.1" class="ltx_text ltx_font_italic">Transactions of the ASMEâ€“Journal of Basic Engineering</span>,
82(Series D):35â€“45, 1960.

</span>
</li>
<li id="bib.bibx102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Kat10]</span>
<span class="ltx_bibblock">
Jonathan Katz.

</span>
<span class="ltx_bibblock"><span id="bib.bibx102.1.1" class="ltx_text ltx_font_italic">Digital signatures</span>, volumeÂ 1.

</span>
<span class="ltx_bibblock">Springer, 2010.

</span>
</li>
<li id="bib.bibx103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KBRB23]</span>
<span class="ltx_bibblock">
Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko.

</span>
<span class="ltx_bibblock">Tabddpm: Modelling tabular data with diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx103.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
17564â€“17579. PMLR, 2023.

</span>
</li>
<li id="bib.bibx104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KBRF18]</span>
<span class="ltx_bibblock">
LukÃ¡Å¡ KakalejÄÃ­k, Jozef Bucko, PAÂ Resende, and Martina
Ferencova.

</span>
<span class="ltx_bibblock">Multichannel marketing attribution using markov chains.

</span>
<span class="ltx_bibblock"><span id="bib.bibx104.1.1" class="ltx_text ltx_font_italic">Journal of Applied Management and Investments</span>, 7(1):49â€“60,
2018.

</span>
</li>
<li id="bib.bibx105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KGW<sup id="bib.bibx105.4.4.1" class="ltx_sup"><span id="bib.bibx105.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom
Goldstein.

</span>
<span class="ltx_bibblock">A watermark for large language models.

</span>
<span class="ltx_bibblock">In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt,
Sivan Sabato, and Jonathan Scarlett, editors, <span id="bib.bibx105.7.1" class="ltx_text ltx_font_italic">Proceedings of the 40th
International Conference on Machine Learning</span>, volume 202 of <span id="bib.bibx105.8.2" class="ltx_text ltx_font_italic">Proceedings
of Machine Learning Research</span>, pages 17061â€“17084. PMLR, 23â€“29 Jul 2023.

</span>
</li>
<li id="bib.bibx106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KLMK20]</span>
<span class="ltx_bibblock">
Jan Kietzmann, LindaÂ W Lee, IanÂ P McCarthy, and TimÂ C Kietzmann.

</span>
<span class="ltx_bibblock">Deepfakes: Trick or treat?

</span>
<span class="ltx_bibblock"><span id="bib.bibx106.1.1" class="ltx_text ltx_font_italic">Business Horizons</span>, 63(2):135â€“146, 2020.

</span>
</li>
<li id="bib.bibx107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KMA<sup id="bib.bibx107.4.4.1" class="ltx_sup"><span id="bib.bibx107.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
SamiraÂ Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Ãkos
KÃ¡dÃ¡r, Adam Trischler, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Figureqa: An annotated figure dataset for visual reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bibx107.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1710.07300</span>, 2017.

</span>
</li>
<li id="bib.bibx108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KNP<sup id="bib.bibx108.4.4.1" class="ltx_sup"><span id="bib.bibx108.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Eleonora KreaÄiÄ‡, Navid Nouri, VamsiÂ K. Potluru, Tucker Balch, and
Manuela Veloso.

</span>
<span class="ltx_bibblock">Differentially private synthetic data using KD-trees.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx108.7.1" class="ltx_text ltx_font_italic">The 39th Conference on Uncertainty in Artificial
Intelligence</span>, 2023.

</span>
</li>
<li id="bib.bibx109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Kri16]</span>
<span class="ltx_bibblock">
Vikram Krishnamurthy.

</span>
<span class="ltx_bibblock"><span id="bib.bibx109.1.1" class="ltx_text ltx_font_italic">Partially observed Markov decision processes</span>.

</span>
<span class="ltx_bibblock">Cambridge university press, 2016.

</span>
</li>
<li id="bib.bibx110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KSK<sup id="bib.bibx110.4.4.1" class="ltx_sup"><span id="bib.bibx110.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>16]</span>
<span class="ltx_bibblock">
Aniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi,
and Ali Farhadi.

</span>
<span class="ltx_bibblock">A diagram is worth a dozen images.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx110.7.1" class="ltx_text ltx_font_italic">Computer Visionâ€“ECCV 2016: 14th European Conference,
Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part IV 14</span>,
pages 235â€“251. Springer, 2016.

</span>
</li>
<li id="bib.bibx111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LCC<sup id="bib.bibx111.4.4.1" class="ltx_sup"><span id="bib.bibx111.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Chun-Liang Li, Wei-Cheng Chang, YuÂ Cheng, Yiming Yang, and BarnabÃ¡s
PÃ³czos.

</span>
<span class="ltx_bibblock">MMD GAN: towards deeper understanding of moment matching network.

</span>
<span class="ltx_bibblock">In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, HannaÂ M. Wallach,
Rob Fergus, S.Â V.Â N. Vishwanathan, and Roman Garnett, editors, <span id="bib.bibx111.7.1" class="ltx_text ltx_font_italic">Advances
in Neural Information Processing Systems 30: Annual Conference on Neural
Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
USA</span>, pages 2203â€“2213, 2017.

</span>
</li>
<li id="bib.bibx112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LeB06]</span>
<span class="ltx_bibblock">
Blake LeBaron.

</span>
<span class="ltx_bibblock">Agent-based computational finance.

</span>
<span class="ltx_bibblock"><span id="bib.bibx112.1.1" class="ltx_text ltx_font_italic">Handbook of computational economics</span>, 2:1187â€“1233, 2006.

</span>
</li>
<li id="bib.bibx113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LHC22]</span>
<span class="ltx_bibblock">
Bohan Li, Yutai Hou, and Wanxiang Che.

</span>
<span class="ltx_bibblock">Data augmentation approaches in natural language processing: A
survey.

</span>
<span class="ltx_bibblock"><span id="bib.bibx113.1.1" class="ltx_text ltx_font_italic">AI Open</span>, 3:71â€“90, 2022.

</span>
</li>
<li id="bib.bibx114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LKK<sup id="bib.bibx114.4.4.1" class="ltx_sup"><span id="bib.bibx114.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, and Sungwoong Kim.

</span>
<span class="ltx_bibblock">Fast autoaugment.

</span>
<span class="ltx_bibblock">In H.Â Wallach, H.Â Larochelle, A.Â Beygelzimer, F.Â d'AlchÃ©-Buc, E.Â Fox, and R.Â Garnett, editors, <span id="bib.bibx114.7.1" class="ltx_text ltx_font_italic">Advances in Neural
Information Processing Systems</span>, volumeÂ 32, pages 6665â€“6675. Curran
Associates, Inc., 2019.

</span>
</li>
<li id="bib.bibx115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LKPL23]</span>
<span class="ltx_bibblock">
Mufei Li, Eleonora KreaÄiÄ‡, VamsiÂ K Potluru, and Pan Li.

</span>
<span class="ltx_bibblock">Graphmaker: Can diffusion models generate large attributed graphs?

</span>
<span class="ltx_bibblock"><span id="bib.bibx115.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.13833</span>, 2023.

</span>
</li>
<li id="bib.bibx116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LLS<sup id="bib.bibx116.4.4.1" class="ltx_sup"><span id="bib.bibx116.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Antonio Longa, Veronica Lachi, Gabriele Santin, Monica Bianchini, Bruno Lepri,
Pietro Lio, franco scarselli, and Andrea Passerini.

</span>
<span class="ltx_bibblock">Graph neural networks for temporal graphs: State of the art, open
challenges, and opportunities.

</span>
<span class="ltx_bibblock"><span id="bib.bibx116.7.1" class="ltx_text ltx_font_italic">Transactions on Machine Learning Research</span>, 2023.

</span>
</li>
<li id="bib.bibx117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LM22]</span>
<span class="ltx_bibblock">
Majlinda Llugiqi and Rudolf Mayer.

</span>
<span class="ltx_bibblock">An empirical analysis of synthetic-data-based anomaly detection.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx117.1.1" class="ltx_text ltx_font_italic">International Cross-Domain Conference for Machine Learning
and Knowledge Extraction</span>, pages 306â€“327. Springer, 2022.

</span>
</li>
<li id="bib.bibx118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LPB17]</span>
<span class="ltx_bibblock">
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.

</span>
<span class="ltx_bibblock">Simple and scalable predictive uncertainty estimation using deep
ensembles.

</span>
<span class="ltx_bibblock"><span id="bib.bibx118.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li id="bib.bibx119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LRD22]</span>
<span class="ltx_bibblock">
Jie Li, Yongli Ren, and KeÂ Deng.

</span>
<span class="ltx_bibblock">Fairgan: Gans-based fairness-aware learning for recommendations with
implicit feedback.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx119.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Web Conference 2022</span>, pages 297â€“307,
2022.

</span>
</li>
<li id="bib.bibx120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LWLQ22]</span>
<span class="ltx_bibblock">
Tianyang Lin, Yuxin Wang, Xiangyang Liu, and Xipeng Qiu.

</span>
<span class="ltx_bibblock">A survey of transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bibx120.1.1" class="ltx_text ltx_font_italic">AI Open</span>, 2022.

</span>
</li>
<li id="bib.bibx121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LWSF23]</span>
<span class="ltx_bibblock">
Zinan Lin, Shuaiqi Wang, Vyas Sekar, and Giulia Fanti.

</span>
<span class="ltx_bibblock">Summary statistic privacy in data sharing, 2023.

</span>
</li>
<li id="bib.bibx122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LXJ14]</span>
<span class="ltx_bibblock">
Haoran Li, LiÂ Xiong, and Xiaoqian Jiang.

</span>
<span class="ltx_bibblock">Differentially private synthesization of multi-dimensional data using
copula functions.

</span>
<span class="ltx_bibblock"><span id="bib.bibx122.1.1" class="ltx_text ltx_font_italic">Advances in database technology : proceedings. International
Conference on Extending Database Technology</span>, 2014:475â€“486, 2014.

</span>
</li>
<li id="bib.bibx123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LXZ<sup id="bib.bibx123.4.4.1" class="ltx_sup"><span id="bib.bibx123.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>15]</span>
<span class="ltx_bibblock">
Dixin Luo, Hongteng Xu, YiÂ Zhen, Xia Ning, Hongyuan Zha, Xiaokang Yang, and
Wenjun Zhang.

</span>
<span class="ltx_bibblock">Multi-task multi-dimensional hawkes processes for modeling event
sequences.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx123.7.1" class="ltx_text ltx_font_italic">Proceedings of the 24th International Conference on
Artificial Intelligence</span>, IJCAIâ€™15, page 3685â€“3691, 2015.

</span>
</li>
<li id="bib.bibx124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LYH<sup id="bib.bibx124.4.4.1" class="ltx_sup"><span id="bib.bibx124.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Jianan Li, Jimei Yang, Aaron Hertzmann, Jianming Zhang, and Tingfa Xu.

</span>
<span class="ltx_bibblock">Layoutgan: Synthesizing graphic layouts with vector-wireframe
adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx124.7.1" class="ltx_text ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>,
43(7):2388â€“2399, 2020.

</span>
</li>
<li id="bib.bibx125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LZF20]</span>
<span class="ltx_bibblock">
Zheng Li, Yue Zhao, and Jialin Fu.

</span>
<span class="ltx_bibblock">Sync: A copula based framework for generating synthetic data from
aggregated sources.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx125.1.1" class="ltx_text ltx_font_italic">2020 International Conference on Data Mining Workshops
(ICDMW)</span>, pages 571â€“578. IEEE, 2020.

</span>
</li>
<li id="bib.bibx126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MA23]</span>
<span class="ltx_bibblock">
Dionysis Manousakas and SergÃ¼l AydÃ¶re.

</span>
<span class="ltx_bibblock">On the usefulness of synthetic tabular data generation, 2023.

</span>
</li>
<li id="bib.bibx127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Mac75]</span>
<span class="ltx_bibblock">
Odile Macchi.

</span>
<span class="ltx_bibblock">The coincidence approach to stochastic point processes.

</span>
<span class="ltx_bibblock"><span id="bib.bibx127.1.1" class="ltx_text ltx_font_italic">Advances in Applied Probability</span>, 7(1):83â€“122, 1975.

</span>
</li>
<li id="bib.bibx128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MBT<sup id="bib.bibx128.4.4.1" class="ltx_sup"><span id="bib.bibx128.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Minesh Mathew, Viraj Bagal, RubÃ¨n Tito, Dimosthenis Karatzas, Ernest
Valveny, and CVÂ Jawahar.

</span>
<span class="ltx_bibblock">Infographicvqa.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx128.7.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Winter Conference on Applications
of Computer Vision</span>, pages 1697â€“1706, 2022.

</span>
</li>
<li id="bib.bibx129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MCV<sup id="bib.bibx129.4.4.1" class="ltx_sup"><span id="bib.bibx129.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Jing Ma, Chen Chen, Anil Vullikanti, Ritwick Mishra, GregoryÂ R Madden, Daniel
Borrajo, and Jundong Li.

</span>
<span class="ltx_bibblock">A look into causal effects under entangled treatment in graphs:
Investigating the impact of contact on MRSA infection.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx129.7.1" class="ltx_text ltx_font_italic">KDD Conference. Applied Data Science Track</span>, 2023.

</span>
</li>
<li id="bib.bibx130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ME10]</span>
<span class="ltx_bibblock">
NizarÂ R Mabroukeh and ChristieÂ I Ezeife.

</span>
<span class="ltx_bibblock">A taxonomy of sequential pattern mining algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bibx130.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys (CSUR)</span>, 43(1):1â€“41, 2010.

</span>
</li>
<li id="bib.bibx131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Miz16]</span>
<span class="ltx_bibblock">
Takanobu Mizuta.

</span>
<span class="ltx_bibblock">A brief review of recent artificial market simulation (agent-based
model) studies for financial market regulations and/or rules.

</span>
<span class="ltx_bibblock"><span id="bib.bibx131.1.1" class="ltx_text ltx_font_italic">Available at SSRN 2710495</span>, 2016.

</span>
</li>
<li id="bib.bibx132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MMS09]</span>
<span class="ltx_bibblock">
RossÂ A Maller, Gernot MÃ¼ller, and Alex Szimayer.

</span>
<span class="ltx_bibblock">Ornsteinâ€“uhlenbeck processes and extensions.

</span>
<span class="ltx_bibblock"><span id="bib.bibx132.1.1" class="ltx_text ltx_font_italic">Handbook of financial time series</span>, pages 421â€“437, 2009.

</span>
</li>
<li id="bib.bibx133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MMS<sup id="bib.bibx133.4.4.1" class="ltx_sup"><span id="bib.bibx133.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan.

</span>
<span class="ltx_bibblock">A survey on bias and fairness in machine learning.

</span>
<span class="ltx_bibblock"><span id="bib.bibx133.7.1" class="ltx_text ltx_font_italic">ACM computing surveys (CSUR)</span>, 54(6):1â€“35, 2021.

</span>
</li>
<li id="bib.bibx134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MPPS21]</span>
<span class="ltx_bibblock">
Nishtha Madaan, Inkit Padhi, Naveen Panwar, and Diptikalyan Saha.

</span>
<span class="ltx_bibblock">Generate your counterfactuals: Towards controlled counterfactual
generation for text.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx134.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</span>, volumeÂ 35, pages 13516â€“13524, 2021.

</span>
</li>
<li id="bib.bibx135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MST<sup id="bib.bibx135.4.4.1" class="ltx_sup"><span id="bib.bibx135.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Ben Mildenhall, PratulÂ P. Srinivasan, Matthew Tancik, JonathanÂ T. Barron, Ravi
Ramamoorthi, and Ren Ng.

</span>
<span class="ltx_bibblock">Nerf: Representing scenes as neural radiance fields for view
synthesis.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx135.7.1" class="ltx_text ltx_font_italic">ECCV</span>, 2020.

</span>
</li>
<li id="bib.bibx136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Mur02]</span>
<span class="ltx_bibblock">
KevinÂ Patrick Murphy.

</span>
<span class="ltx_bibblock"><span id="bib.bibx136.1.1" class="ltx_text ltx_font_italic">Dynamic bayesian networks: representation, inference and
learning</span>.

</span>
<span class="ltx_bibblock">University of California, Berkeley, 2002.

</span>
</li>
<li id="bib.bibx137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MV12]</span>
<span class="ltx_bibblock">
Guido Masarotto and Cristiano Varin.

</span>
<span class="ltx_bibblock">Gaussian copula marginal regression.

</span>
<span class="ltx_bibblock">2012.

</span>
</li>
<li id="bib.bibx138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[New83]</span>
<span class="ltx_bibblock">
Paul Newbold.

</span>
<span class="ltx_bibblock">Arima model building and the time series analysis approach to
forecasting.

</span>
<span class="ltx_bibblock"><span id="bib.bibx138.1.1" class="ltx_text ltx_font_italic">Journal of forecasting</span>, 2(1):23â€“35, 1983.

</span>
</li>
<li id="bib.bibx139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[NS07]</span>
<span class="ltx_bibblock">
Arvind Narayanan and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">How to break anonymity of the netflix prize dataset, 2007.

</span>
</li>
<li id="bib.bibx140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ODZ<sup id="bib.bibx140.4.4.1" class="ltx_sup"><span id="bib.bibx140.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>16]</span>
<span class="ltx_bibblock">
Aaron vanÂ den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.

</span>
<span class="ltx_bibblock">Wavenet: A generative model for raw audio.

</span>
<span class="ltx_bibblock"><span id="bib.bibx140.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1609.03499</span>, 2016.

</span>
</li>
<li id="bib.bibx141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[OE18]</span>
<span class="ltx_bibblock">
Achraf Oussidi and Azeddine Elhassouny.

</span>
<span class="ltx_bibblock">Deep generative models: Survey.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx141.1.1" class="ltx_text ltx_font_italic">2018 International conference on intelligent systems and
computer vision (ISCV)</span>, pages 1â€“8. IEEE, 2018.

</span>
</li>
<li id="bib.bibx142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Oga81]</span>
<span class="ltx_bibblock">
Yosihiko Ogata.

</span>
<span class="ltx_bibblock">On lewisâ€™ simulation method for point processes.

</span>
<span class="ltx_bibblock"><span id="bib.bibx142.1.1" class="ltx_text ltx_font_italic">IEEE transactions on information theory</span>, 27(1):23â€“31, 1981.

</span>
</li>
<li id="bib.bibx143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Oga98]</span>
<span class="ltx_bibblock">
Yosihiko Ogata.

</span>
<span class="ltx_bibblock">Space-time point-process models for earthquake occurrences.

</span>
<span class="ltx_bibblock"><span id="bib.bibx143.1.1" class="ltx_text ltx_font_italic">Annals of the Institute of Statistical Mathematics</span>,
50:379â€“402, 1998.

</span>
</li>
<li id="bib.bibx144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[OMI22]</span>
<span class="ltx_bibblock">
D.Â Oba, S.Â Matsuo, and B.Â Iwana.

</span>
<span class="ltx_bibblock">Dynamic data augmentation with gating networks for time series
recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx144.1.1" class="ltx_text ltx_font_italic">2022 26th International Conference on Pattern Recognition
(ICPR)</span>, pages 3034â€“3040, Los Alamitos, CA, USA, aug 2022. IEEE Computer
Society.

</span>
</li>
<li id="bib.bibx145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ope23]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023.

</span>
</li>
<li id="bib.bibx146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PAE<sup id="bib.bibx146.4.4.1" class="ltx_sup"><span id="bib.bibx146.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Nicolas Papernot, MartÃ­n Abadi, Ulfar Erlingsson, Ian Goodfellow, and Kunal
Talwar.

</span>
<span class="ltx_bibblock">Semi-supervised knowledge transfer for deep learning from private
training data, 2017.

</span>
</li>
<li id="bib.bibx147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PCCK22]</span>
<span class="ltx_bibblock">
Felix Prenzel, Rama Cont, Mihai Cucuringu, and Jonathan Kochems.

</span>
<span class="ltx_bibblock">Dynamic calibration of order flow models with generative adversarial
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx147.1.1" class="ltx_text ltx_font_italic">Proceedings of the Third ACM International Conference on AI
in Finance</span>, pages 446â€“453, 2022.

</span>
</li>
<li id="bib.bibx148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PEK21]</span>
<span class="ltx_bibblock">
AnnieÂ E Paine, VincentÂ E Elfving, and Oleksandr Kyriienko.

</span>
<span class="ltx_bibblock">Quantum quantile mechanics: solving stochastic differential equations
for generating time-series.

</span>
<span class="ltx_bibblock"><span id="bib.bibx148.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2108.03190</span>, 2021.

</span>
</li>
<li id="bib.bibx149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PGM23]</span>
<span class="ltx_bibblock">
Lorenzo Pisaneschi, Andrea Gemelli, and Simone Marinai.

</span>
<span class="ltx_bibblock">Automatic generation of scientific papers for data augmentation in
document layout analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bibx149.1.1" class="ltx_text ltx_font_italic">Pattern Recognition Letters</span>, 167:38â€“44, 2023.

</span>
</li>
<li id="bib.bibx150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PH22]</span>
<span class="ltx_bibblock">
FrancescoÂ Sanna Passino and NicholasÂ A Heard.

</span>
<span class="ltx_bibblock">Mutually exciting point process graphs for modeling dynamic networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx150.1.1" class="ltx_text ltx_font_italic">Journal of Computational and Graphical Statistics</span>, pages 1â€“15,
2022.

</span>
</li>
<li id="bib.bibx151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PMG<sup id="bib.bibx151.4.4.1" class="ltx_sup"><span id="bib.bibx151.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Noseong Park, Mahmoud Mohammadi, Kshitij Gorde, Sushil Jajodia, Hongkyu Park,
and Youngmin Kim.

</span>
<span class="ltx_bibblock">Data synthesis based on generative adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx151.7.1" class="ltx_text ltx_font_italic">Proceedings of the VLDB Endowment</span>, 11(10):1071â€“1083, jun
2018.

</span>
</li>
<li id="bib.bibx152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PMG<sup id="bib.bibx152.4.4.1" class="ltx_sup"><span id="bib.bibx152.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Sunandita Patra, Mahmoud Mahfouz, Sriram Gopalakrishnan, Daniele Magazzeni, and
Manuela Veloso.

</span>
<span class="ltx_bibblock">Finrddl: Can ai planning be used for quantitative finance problems?

</span>
<span class="ltx_bibblock"><span id="bib.bibx152.7.1" class="ltx_text ltx_font_italic">FinPlan 2023</span>, 2023.

</span>
</li>
<li id="bib.bibx153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PSH17]</span>
<span class="ltx_bibblock">
Haoyue Ping, Julia Stoyanovich, and Bill Howe.

</span>
<span class="ltx_bibblock">Datasynthesizer: Privacy-preserving synthetic datasets.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx153.1.1" class="ltx_text ltx_font_italic">Proceedings of the 29th International Conference on
Scientific and Statistical Database Management</span>, pages 1â€“5, 2017.

</span>
</li>
<li id="bib.bibx154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PSZ22]</span>
<span class="ltx_bibblock">
Neel Patel, Reza Shokri, and Yair Zick.

</span>
<span class="ltx_bibblock">Model explanations with differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx154.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 ACM Conference on Fairness,
Accountability, and Transparency</span>, pages 1895â€“1904, 2022.

</span>
</li>
<li id="bib.bibx155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Put14a]</span>
<span class="ltx_bibblock">
MartinÂ L Puterman.

</span>
<span class="ltx_bibblock"><span id="bib.bibx155.1.1" class="ltx_text ltx_font_italic">Markov decision processes: discrete stochastic dynamic
programming</span>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2014.

</span>
</li>
<li id="bib.bibx156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Put14b]</span>
<span class="ltx_bibblock">
MartinÂ L Puterman.

</span>
<span class="ltx_bibblock"><span id="bib.bibx156.1.1" class="ltx_text ltx_font_italic">Markov decision processes: discrete stochastic dynamic
programming</span>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2014.

</span>
</li>
<li id="bib.bibx157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PWV16a]</span>
<span class="ltx_bibblock">
Neha Patki, Roy Wedge, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">The synthetic data vault.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx157.1.1" class="ltx_text ltx_font_italic">2016 IEEE International Conference on Data Science and
Advanced Analytics (DSAA)</span>, pages 399â€“410. IEEE, 2016.

</span>
</li>
<li id="bib.bibx158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PWV16b]</span>
<span class="ltx_bibblock">
Neha Patki, Roy Wedge, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">The synthetic data vault.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx158.1.1" class="ltx_text ltx_font_italic">2016 IEEE International Conference on Data Science and
Advanced Analytics (DSAA)</span>, pages 399â€“410, 2016.

</span>
</li>
<li id="bib.bibx159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Rei18]</span>
<span class="ltx_bibblock">
Alex Reinhart.

</span>
<span class="ltx_bibblock">A review of self-exciting spatio-temporal point processes and their
applications.

</span>
<span class="ltx_bibblock"><span id="bib.bibx159.1.1" class="ltx_text ltx_font_italic">Statistical Science</span>, 33(3):299â€“318, 2018.

</span>
</li>
<li id="bib.bibx160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RG18]</span>
<span class="ltx_bibblock">
Alex Reinhart and Joel Greenhouse.

</span>
<span class="ltx_bibblock">Self-exciting point processes with spatial covariates.

</span>
<span class="ltx_bibblock"><span id="bib.bibx160.1.1" class="ltx_text ltx_font_italic">Journal of the Royal Statistical Society. Series C (Applied
Statistics)</span>, 67(5):1305â€“1329, 2018.

</span>
</li>
<li id="bib.bibx161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RHR<sup id="bib.bibx161.4.4.1" class="ltx_sup"><span id="bib.bibx161.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Lucas Rosenblatt, Anastasia Holovenko, Taras Rumezhak, Andrii Stadnik, Bernease
Herman, Julia Stoyanovich, and Bill Howe.

</span>
<span class="ltx_bibblock">Epistemic parity: Reproducibility as an evaluation metric for
differential privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bibx161.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2208.12700</span>, 2022.

</span>
</li>
<li id="bib.bibx162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RJ86]</span>
<span class="ltx_bibblock">
Lawrence Rabiner and Biinghwang Juang.

</span>
<span class="ltx_bibblock">An introduction to hidden markov models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx162.1.1" class="ltx_text ltx_font_italic">ieee assp magazine</span>, 3(1):4â€“16, 1986.

</span>
</li>
<li id="bib.bibx163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RLMX17]</span>
<span class="ltx_bibblock">
Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, and Lexing Xie.

</span>
<span class="ltx_bibblock">Hawkes processes for events in social media.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx163.1.1" class="ltx_text ltx_font_italic">Frontiers of multimedia research</span>, pages 191â€“218. 2017.

</span>
</li>
<li id="bib.bibx164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RLP<sup id="bib.bibx164.4.4.1" class="ltx_sup"><span id="bib.bibx164.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Lucas Rosenblatt, Xiaoyan Liu, Samira Pouyanfar, Eduardo deÂ Leon, Anuj Desai,
and Joshua Allen.

</span>
<span class="ltx_bibblock">Differentially private synthetic data: Applied evaluations and
enhancements, 2020.

</span>
</li>
<li id="bib.bibx165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RPG<sup id="bib.bibx165.4.4.1" class="ltx_sup"><span id="bib.bibx165.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
Radford, Mark Chen, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Zero-shot text-to-image generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx165.7.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
8821â€“8831. PMLR, 2021.

</span>
</li>
<li id="bib.bibx166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RSGZ<sup id="bib.bibx166.4.4.1" class="ltx_sup"><span id="bib.bibx166.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Tamar RottÂ Shaham, Michael Gharbi, Richard Zhang, Eli Shechtman, and Tomer
Michaeli.

</span>
<span class="ltx_bibblock">Spatially-adaptive pixelwise networks for fast image translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx166.7.1" class="ltx_text ltx_font_italic">Computer Vision and Pattern Recognition (CVPR)</span>, 2021.

</span>
</li>
<li id="bib.bibx167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RSV22]</span>
<span class="ltx_bibblock">
Natraj Raman, Sameena Shah, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Synthetic document generator for annotation-free layout recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bibx167.1.1" class="ltx_text ltx_font_italic">Pattern Recognition</span>, 128:108660, 2022.

</span>
</li>
<li id="bib.bibx168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RT<sup id="bib.bibx168.4.4.1" class="ltx_sup"><span id="bib.bibx168.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>09]</span>
<span class="ltx_bibblock">
Gerardo Rubino, Bruno Tuffin, etÂ al.

</span>
<span class="ltx_bibblock"><span id="bib.bibx168.7.1" class="ltx_text ltx_font_italic">Rare event simulation using Monte Carlo methods</span>, volumeÂ 73.

</span>
<span class="ltx_bibblock">Wiley Online Library, 2009.

</span>
</li>
<li id="bib.bibx169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[S<sup id="bib.bibx169.4.4.1" class="ltx_sup"><span id="bib.bibx169.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>10]</span>
<span class="ltx_bibblock">
Scott Sanner etÂ al.

</span>
<span class="ltx_bibblock">Relational dynamic influence diagram language (rddl): Language
description.

</span>
<span class="ltx_bibblock"><span id="bib.bibx169.7.1" class="ltx_text ltx_font_italic">Unpublished ms. Australian National University</span>, 32:27, 2010.

</span>
</li>
<li id="bib.bibx170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SBL<sup id="bib.bibx170.4.4.1" class="ltx_sup"><span id="bib.bibx170.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
MehdiÂ SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain
Gelly.

</span>
<span class="ltx_bibblock">Assessing generative models via precision and recall.

</span>
<span class="ltx_bibblock"><span id="bib.bibx170.7.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 31, 2018.

</span>
</li>
<li id="bib.bibx171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SBY16]</span>
<span class="ltx_bibblock">
Baoguang Shi, Xiang Bai, and Cong Yao.

</span>
<span class="ltx_bibblock">An end-to-end trainable neural network for image-based sequence
recognition and its application to scene text recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bibx171.1.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>,
39(11):2298â€“2304, 2016.

</span>
</li>
<li id="bib.bibx172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SC23]</span>
<span class="ltx_bibblock">
Zijian Shi and John Cartlidge.

</span>
<span class="ltx_bibblock">Neural stochastic agent-based limit order book simulation: A hybrid
methodology.

</span>
<span class="ltx_bibblock"><span id="bib.bibx172.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.00080</span>, 2023.

</span>
</li>
<li id="bib.bibx173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SCE<sup id="bib.bibx173.4.4.1" class="ltx_sup"><span id="bib.bibx173.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Raj Shah, Kunal Chawla, Dheeraj Eidnani, Agam Shah, Wendi Du, Sudheer Chava,
Natraj Raman, Charese Smiley, Jiaao Chen, and Diyi Yang.

</span>
<span class="ltx_bibblock">When flue meets flang: Benchmarks and large pretrained language model
for financial domain.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx173.7.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing</span>, pages 2322â€“2335, 2022.

</span>
</li>
<li id="bib.bibx174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SDWMG15]</span>
<span class="ltx_bibblock">
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.

</span>
<span class="ltx_bibblock">Deep unsupervised learning using nonequilibrium thermodynamics.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx174.1.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages
2256â€“2265. PMLR, 2015.

</span>
</li>
<li id="bib.bibx175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SHCV19]</span>
<span class="ltx_bibblock">
Prasanna Sattigeri, SamuelÂ C Hoffman, Vijil Chenthamarakshan, and KushÂ R
Varshney.

</span>
<span class="ltx_bibblock">Fairness gan: Generating datasets with fairness properties using a
generative adversarial network.

</span>
<span class="ltx_bibblock"><span id="bib.bibx175.1.1" class="ltx_text ltx_font_italic">IBM Journal of Research and Development</span>, 63(4/5):3â€“1, 2019.

</span>
</li>
<li id="bib.bibx176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SKB23]</span>
<span class="ltx_bibblock">
Zahra Shahrooei, MykelÂ J Kochenderfer, and Ali Baheri.

</span>
<span class="ltx_bibblock">Falsification of learning-based controllers through multi-fidelity
bayesian optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx176.1.1" class="ltx_text ltx_font_italic">2023 European Control Conference (ECC)</span>, pages 1â€“6. IEEE,
2023.

</span>
</li>
<li id="bib.bibx177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SMB<sup id="bib.bibx177.4.4.1" class="ltx_sup"><span id="bib.bibx177.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Vincent Sitzmann, JulienÂ N.P. Martel, AlexanderÂ W. Bergman, DavidÂ B. Lindell,
and Gordon Wetzstein.

</span>
<span class="ltx_bibblock">Implicit neural representations with periodic activation functions.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx177.7.1" class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2020.

</span>
</li>
<li id="bib.bibx178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SMH<sup id="bib.bibx178.4.4.1" class="ltx_sup"><span id="bib.bibx178.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung
Chiang, and Prateek Mittal.

</span>
<span class="ltx_bibblock">Robust learning meets generative models: Can proxy distributions
improve adversarial robustness?

</span>
<span class="ltx_bibblock">In <span id="bib.bibx178.7.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li id="bib.bibx179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SSS16]</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx179.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1610.05820, 2016.

</span>
</li>
<li id="bib.bibx180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SSW11]</span>
<span class="ltx_bibblock">
Xiaoxun Sun, Lili Sun, and Hua Wang.

</span>
<span class="ltx_bibblock">Extended k-anonymity models against sensitive attribute disclosure.

</span>
<span class="ltx_bibblock"><span id="bib.bibx180.1.1" class="ltx_text ltx_font_italic">Computer Communications</span>, 34(4):526â€“535, 2011.

</span>
<span class="ltx_bibblock">Special issue: Building Secure Parallel and Distributed Networks and
Systems.

</span>
</li>
<li id="bib.bibx181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SZZ<sup id="bib.bibx181.4.4.1" class="ltx_sup"><span id="bib.bibx181.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Hui Sun, Tianqing Zhu, Zhiqiu Zhang, Dawei Jin, Ping Xiong, and Wanlei Zhou.

</span>
<span class="ltx_bibblock">Adversarial attacks against deep generative models on data: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bibx181.7.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>,
35(4):3367â€“3388, apr 2023.

</span>
</li>
<li id="bib.bibx182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TAC23]</span>
<span class="ltx_bibblock">
ChristopherÂ TH Teo, Milad Abdollahzadeh, and Ngai-Man Cheung.

</span>
<span class="ltx_bibblock">Fair generative models via transfer learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx182.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</span>, volumeÂ 37, pages 2429â€“2437, 2023.

</span>
</li>
<li id="bib.bibx183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TBV23]</span>
<span class="ltx_bibblock">
RobertÂ E Tillman, Tucker Balch, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Privacy-preserving energy-based generative models for marginal
distribution protection.

</span>
<span class="ltx_bibblock"><span id="bib.bibx183.1.1" class="ltx_text ltx_font_italic">Transactions on Machine Learning Research</span>, 2023.

</span>
</li>
<li id="bib.bibx184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TFB<sup id="bib.bibx184.4.4.1" class="ltx_sup"><span id="bib.bibx184.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Simon Tannert, Marcelo Feighelstein, Jasmina Bogojeska, Joseph Shtok, Assaf
Arbelle4Â Peter Staar, and Anika Schumann3 Jonas Kuhn1Â Leonid Karlinsky.

</span>
<span class="ltx_bibblock">Flowchartqa: The first large-scale benchmark for reasoning over
flowcharts.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx184.7.1" class="ltx_text ltx_font_italic">The 3rd Workshop on Document Intelligence. KDD</span>, 2022.

</span>
</li>
<li id="bib.bibx185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TGG<sup id="bib.bibx185.4.4.1" class="ltx_sup"><span id="bib.bibx185.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Ayal Taitler, Michael Gimelfarb, Sriram Gopalakrishnan, Martin Mladenov,
Xiaotian Liu, and Scott Sanner.

</span>
<span class="ltx_bibblock">pyrddlgym: From rddl to gym environments.

</span>
<span class="ltx_bibblock"><span id="bib.bibx185.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.05939</span>, 2022.

</span>
</li>
<li id="bib.bibx186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TK21]</span>
<span class="ltx_bibblock">
Naoya Takeishi and Yoshinobu Kawahara.

</span>
<span class="ltx_bibblock">Knowledge-based regularization in generative modeling.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx186.1.1" class="ltx_text ltx_font_italic">Proceedings of the Twenty-Ninth International Conference on
International Joint Conferences on Artificial Intelligence</span>, pages
2390â€“2396, 2021.

</span>
</li>
<li id="bib.bibx187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TMH<sup id="bib.bibx187.4.4.1" class="ltx_sup"><span id="bib.bibx187.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Yuchao Tao, Ryan McKenna, Michael Hay, Ashwin Machanavajjhala, and Gerome
Miklau.

</span>
<span class="ltx_bibblock">Benchmarking differentially private synthetic data generation
algorithms, 2022.

</span>
</li>
<li id="bib.bibx188" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TWB<sup id="bib.bibx188.4.4.1" class="ltx_sup"><span id="bib.bibx188.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
UthaiponÂ Tao Tantipongpipat, Chris Waites, Digvijay Boob, AmareshÂ Ankit Siva,
and Rachel Cummings.

</span>
<span class="ltx_bibblock">Differentially private synthetic mixed-type data generation for
unsupervised learning.

</span>
<span class="ltx_bibblock"><span id="bib.bibx188.7.1" class="ltx_text ltx_font_italic">Intelligent Decision Technologies</span>, 15(4):779â€“807, 2021.

</span>
</li>
<li id="bib.bibx189" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TWOH03]</span>
<span class="ltx_bibblock">
YeeÂ Whye Teh, Max Welling, Simon Osindero, and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Energy-based models for sparse overcomplete representations.

</span>
<span class="ltx_bibblock"><span id="bib.bibx189.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 4(Dec):1235â€“1260, 2003.

</span>
</li>
<li id="bib.bibx190" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[UO30]</span>
<span class="ltx_bibblock">
GeorgeÂ E Uhlenbeck and LeonardÂ S Ornstein.

</span>
<span class="ltx_bibblock">On the theory of the brownian motion.

</span>
<span class="ltx_bibblock"><span id="bib.bibx190.1.1" class="ltx_text ltx_font_italic">Physical Review</span>, 36(5):823, 1930.

</span>
</li>
<li id="bib.bibx191" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[vBKBvdS21]</span>
<span class="ltx_bibblock">
Boris van Breugel, Trent Kyono, Jeroen Berrevoets, and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">Decaf: Generating fair synthetic data using causally-aware generative
networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx191.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
34:22221â€“22233, 2021.

</span>
</li>
<li id="bib.bibx192" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VBP<sup id="bib.bibx192.4.4.1" class="ltx_sup"><span id="bib.bibx192.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Svitlana Vyetrenko, David Byrd, Nick Petosa, Mahmoud Mahfouz, Danial Dervovic,
Manuela Veloso, and TuckerÂ Hybinette Balch.

</span>
<span class="ltx_bibblock">Get real: Realism metrics for robust limit order book market
simulations, 2019.

</span>
</li>
<li id="bib.bibx193" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[vdMH08]</span>
<span class="ltx_bibblock">
Laurens vanÂ der Maaten and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Visualizing data using t-sne.

</span>
<span class="ltx_bibblock"><span id="bib.bibx193.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 9(86):2579â€“2605, 2008.

</span>
</li>
<li id="bib.bibx194" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VdOKE<sup id="bib.bibx194.4.4.1" class="ltx_sup"><span id="bib.bibx194.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>16]</span>
<span class="ltx_bibblock">
Aaron VanÂ den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
Graves, etÂ al.

</span>
<span class="ltx_bibblock">Conditional image generation with pixelcnn decoders.

</span>
<span class="ltx_bibblock"><span id="bib.bibx194.7.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 29, 2016.

</span>
</li>
<li id="bib.bibx195" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VL18]</span>
<span class="ltx_bibblock">
Rory VanÂ Loo.

</span>
<span class="ltx_bibblock">Technology regulation by default: Platforms, privacy, and the cfpb.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li id="bib.bibx196" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VSP<sup id="bib.bibx196.4.4.1" class="ltx_sup"><span id="bib.bibx196.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span id="bib.bibx196.7.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li id="bib.bibx197" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VVdB17]</span>
<span class="ltx_bibblock">
Paul Voigt and Axel VonÂ dem Bussche.

</span>
<span class="ltx_bibblock">The eu general data protection regulation (gdpr).

</span>
<span class="ltx_bibblock"><span id="bib.bibx197.1.1" class="ltx_text ltx_font_italic">A Practical Guide, 1st Ed., Cham: Springer International
Publishing</span>, 10(3152676):10â€“5555, 2017.

</span>
</li>
<li id="bib.bibx198" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[WB<sup id="bib.bibx198.4.4.1" class="ltx_sup"><span id="bib.bibx198.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>95]</span>
<span class="ltx_bibblock">
Greg Welch, Gary Bishop, etÂ al.

</span>
<span class="ltx_bibblock">An introduction to the kalman filter.

</span>
<span class="ltx_bibblock">1995.

</span>
</li>
<li id="bib.bibx199" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Whi85]</span>
<span class="ltx_bibblock">
DouglasÂ J White.

</span>
<span class="ltx_bibblock">Real applications of markov decision processes.

</span>
<span class="ltx_bibblock"><span id="bib.bibx199.1.1" class="ltx_text ltx_font_italic">Interfaces</span>, 15(6):73â€“83, 1985.

</span>
</li>
<li id="bib.bibx200" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[WKKK20]</span>
<span class="ltx_bibblock">
Magnus Wiese, Robert Knobloch, Ralf Korn, and Peter Kretschmer.

</span>
<span class="ltx_bibblock">Quant gans: deep generation of financial time series.

</span>
<span class="ltx_bibblock"><span id="bib.bibx200.1.1" class="ltx_text ltx_font_italic">Quantitative Finance</span>, page 1â€“22, Apr 2020.

</span>
</li>
<li id="bib.bibx201" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[WKW<sup id="bib.bibx201.4.4.1" class="ltx_sup"><span id="bib.bibx201.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Rongzhe Wei, Eleonora KreaÄiÄ‡, Haoyu Wang, Haoteng Yin, Eli Chien,
VamsiÂ K Potluru, and Pan Li.

</span>
<span class="ltx_bibblock">On the inherent privacy properties of discrete denoising diffusion
models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx201.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.15524</span>, 2023.

</span>
</li>
<li id="bib.bibx202" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[WSS<sup id="bib.bibx202.4.4.1" class="ltx_sup"><span id="bib.bibx202.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Qingsong Wen, Liang Sun, Xiaomin Song, Jing Gao, Xue Wang, and Huan Xu.

</span>
<span class="ltx_bibblock">Time series data augmentation for deep learning: A survey.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx202.7.1" class="ltx_text ltx_font_italic">International Joint Conference on Artificial Intelligence</span>,
2020.

</span>
</li>
<li id="bib.bibx203" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[WZZX21]</span>
<span class="ltx_bibblock">
Song Wei, Shixiang Zhu, Minghe Zhang, and Yao Xie.

</span>
<span class="ltx_bibblock">Goodness-of-fit test for mismatched self-exciting processes.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx203.1.1" class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</span>, pages 1243â€“1251. PMLR, 2021.

</span>
</li>
<li id="bib.bibx204" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XDP<sup id="bib.bibx204.4.4.1" class="ltx_sup"><span id="bib.bibx204.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Zikai Xiong, NiccolÃ² Dalmasso, VamsiÂ K. Potluru, Tucker Balch, and Manuela
Veloso.

</span>
<span class="ltx_bibblock">Fair wasserstein coresets, 2023.

</span>
</li>
<li id="bib.bibx205" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XFY<sup id="bib.bibx205.4.4.1" class="ltx_sup"><span id="bib.bibx205.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Shuai Xiao, Mehrdad Farajtabar, Xiaojing Ye, Junchi Yan, LeÂ Song, and Hongyuan
Zha.

</span>
<span class="ltx_bibblock">Wasserstein learning of deep generative point process models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx205.7.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li id="bib.bibx206" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XLW<sup id="bib.bibx206.4.4.1" class="ltx_sup"><span id="bib.bibx206.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou.

</span>
<span class="ltx_bibblock">Differentially private generative adversarial network, 2018.

</span>
</li>
<li id="bib.bibx207" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XSC22]</span>
<span class="ltx_bibblock">
Yue Xing, Qifan Song, and Guang Cheng.

</span>
<span class="ltx_bibblock">Why do artificially generated data help adversarial robustness.

</span>
<span class="ltx_bibblock"><span id="bib.bibx207.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 35:954â€“966,
2022.

</span>
</li>
<li id="bib.bibx208" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XSCIV19]</span>
<span class="ltx_bibblock">
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">Modeling tabular data using conditional gan.

</span>
<span class="ltx_bibblock"><span id="bib.bibx208.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 32, 2019.

</span>
</li>
<li id="bib.bibx209" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XWY<sup id="bib.bibx209.4.4.1" class="ltx_sup"><span id="bib.bibx209.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Depeng Xu, Yongkai Wu, Shuhan Yuan, LuÂ Zhang, and Xintao Wu.

</span>
<span class="ltx_bibblock">Achieving causal fairness through generative adversarial networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx209.7.1" class="ltx_text ltx_font_italic">Proceedings of the Twenty-Eighth International Joint
Conference on Artificial Intelligence</span>, 2019.

</span>
</li>
<li id="bib.bibx210" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XYZW18]</span>
<span class="ltx_bibblock">
Depeng Xu, Shuhan Yuan, LuÂ Zhang, and Xintao Wu.

</span>
<span class="ltx_bibblock">Fairgan: Fairness-aware generative adversarial networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx210.1.1" class="ltx_text ltx_font_italic">2018 IEEE International Conference on Big Data (Big Data)</span>,
pages 570â€“575. IEEE, 2018.

</span>
</li>
<li id="bib.bibx211" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XYZW19]</span>
<span class="ltx_bibblock">
Depeng Xu, Shuhan Yuan, LuÂ Zhang, and Xintao Wu.

</span>
<span class="ltx_bibblock">Fairgan+: Achieving fair data generation and classification through
generative adversarial nets.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx211.1.1" class="ltx_text ltx_font_italic">2019 IEEE International Conference on Big Data (Big Data)</span>,
pages 1401â€“1406. IEEE, 2019.

</span>
</li>
<li id="bib.bibx212" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XZF<sup id="bib.bibx212.4.4.1" class="ltx_sup"><span id="bib.bibx212.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Broeck.

</span>
<span class="ltx_bibblock">A semantic loss function for deep learning with symbolic knowledge.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx212.7.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages
5502â€“5511. PMLR, 2018.

</span>
</li>
<li id="bib.bibx213" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YJvdS19a]</span>
<span class="ltx_bibblock">
Jinsung Yoon, Daniel Jarrett, and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">Time-series generative adversarial networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx213.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2019.

</span>
</li>
<li id="bib.bibx214" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YJvdS19b]</span>
<span class="ltx_bibblock">
Jinsung Yoon, James Jordon, and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">PATE-GAN: Generating synthetic data with differential privacy
guarantees.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx214.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2019.

</span>
</li>
<li id="bib.bibx215" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YSHZ19]</span>
<span class="ltx_bibblock">
Yong Yu, Xiaosheng Si, Changhua Hu, and Jianxun Zhang.

</span>
<span class="ltx_bibblock">A review of recurrent neural networks: Lstm cells and network
architectures.

</span>
<span class="ltx_bibblock"><span id="bib.bibx215.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 31(7):1235â€“1270, 2019.

</span>
</li>
<li id="bib.bibx216" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YSS15]</span>
<span class="ltx_bibblock">
MeghanathÂ Macha Yadagiri, ShivÂ Kumar Saini, and Ritwik Sinha.

</span>
<span class="ltx_bibblock">A non-parametric approach to the multi-channel attribution problem.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx216.1.1" class="ltx_text ltx_font_italic">Web Information Systems Engineeringâ€“WISE 2015: 16th
International Conference, Miami, FL, USA, November 1-3, 2015, Proceedings,
Part I 16</span>, pages 338â€“352. Springer, 2015.

</span>
</li>
<li id="bib.bibx217" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZC22]</span>
<span class="ltx_bibblock">
Ying Zhao and Jinjun Chen.

</span>
<span class="ltx_bibblock">A survey on differential privacy for unstructured data content.

</span>
<span class="ltx_bibblock"><span id="bib.bibx217.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys (CSUR)</span>, 54(10s):1â€“28, 2022.

</span>
</li>
<li id="bib.bibx218" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZCP<sup id="bib.bibx218.4.4.1" class="ltx_sup"><span id="bib.bibx218.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Jun Zhang, Graham Cormode, Cecilia Procopiuc, Divesh Srivastava, and Xiaokui
Xiao.

</span>
<span class="ltx_bibblock">Privbayes: Private data release via bayesian networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx218.7.1" class="ltx_text ltx_font_italic">ACM Transactions on Database Systems</span>, 42:1â€“41, 10 2017.

</span>
</li>
<li id="bib.bibx219" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZDG<sup id="bib.bibx219.4.4.1" class="ltx_sup"><span id="bib.bibx219.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Renbo Zhao, NiccolÃ² Dalmasso, Mohsen Ghassemi, VamsiÂ K Potluru, Tucker
Balch, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Fast learning of multidimensional hawkes processes via frank-wolfe.

</span>
<span class="ltx_bibblock"><span id="bib.bibx219.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.06081</span>, 2022.

</span>
</li>
<li id="bib.bibx220" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZJL<sup id="bib.bibx220.4.4.1" class="ltx_sup"><span id="bib.bibx220.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, and Hongyuan Zha.

</span>
<span class="ltx_bibblock">Transformer Hawkes process.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx220.7.1" class="ltx_text ltx_font_italic">Proceedings of the 37th International Conference on Machine
Learning</span>, volume 119 of <span id="bib.bibx220.8.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>,
pages 11692â€“11702. PMLR, 13â€“18 Jul 2020.

</span>
</li>
<li id="bib.bibx221" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZLKY19]</span>
<span class="ltx_bibblock">
Qiang Zhang, Aldo Lipani, Omer Kirnap, and Emine Yilmaz.

</span>
<span class="ltx_bibblock">Self-attentive hawkes processes.

</span>
<span class="ltx_bibblock"><span id="bib.bibx221.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.07561</span>, 2019.

</span>
</li>
<li id="bib.bibx222" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZLZZ22]</span>
<span class="ltx_bibblock">
Simiao Zuo, Tianyi Liu, Tuo Zhao, and Hongyuan Zha.

</span>
<span class="ltx_bibblock">Differentially private estimation of hawkes process.

</span>
<span class="ltx_bibblock"><span id="bib.bibx222.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2209.07303</span>, 2022.

</span>
</li>
<li id="bib.bibx223" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZWL<sup id="bib.bibx223.4.4.1" class="ltx_sup"><span id="bib.bibx223.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes, Shibo He,
Jiming Chen, and Yang Zhang.

</span>
<span class="ltx_bibblock">PrivSyn: Differentially private data synthesis.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx223.7.1" class="ltx_text ltx_font_italic">30th USENIX Security Symposium (USENIX Security 21)</span>, pages
929â€“946. USENIX Association, August 2021.

</span>
</li>
<li id="bib.bibx224" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZWZZ20]</span>
<span class="ltx_bibblock">
Xinyu Zhang, Qiang Wang, Jian Zhang, and Zhao Zhong.

</span>
<span class="ltx_bibblock">Adversarial autoaugment.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx224.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2020.

</span>
</li>
<li id="bib.bibx225" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZZR19]</span>
<span class="ltx_bibblock">
Zihao Zhang, Stefan Zohren, and Stephen Roberts.

</span>
<span class="ltx_bibblock">Deeplob: Deep convolutional neural networks for limit order books.

</span>
<span class="ltx_bibblock"><span id="bib.bibx225.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Signal Processing</span>, 67(11):3001â€“3012,
2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.00080" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.00081" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.00081">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.00081" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.00082" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 06:02:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
