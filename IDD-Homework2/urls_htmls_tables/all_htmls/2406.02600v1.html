<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Data Quality in Edge Machine Learning: A State-of-the-Art Survey</title>
<!--Generated on Sat Jun  1 23:04:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %\institute{% .-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="abb:ai,  " lang="en" name="keywords"/>
<base href="/html/2406.02600v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S1" title="In Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S2" title="In Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S2.SS0.SSS0.Px1" title="In 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">Notations and conventions</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S2.SS1" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Edge machine learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S3" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data quality for machine learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S4" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Statistical independence</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S4.SS1" title="In 4 Statistical independence ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Machine learning on dependent data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S4.SS2" title="In 4 Statistical independence ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Dependent data in federated learning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Attribute skew</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1" title="In 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Practical solutions and empirical evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS1" title="In 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Data-based methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS1.Px1" title="In 5.1.1 Data-based methods ‣ 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">Data sharing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS1.Px2" title="In 5.1.1 Data-based methods ‣ 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">Data augmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS1.Px3" title="In 5.1.1 Data-based methods ‣ 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">Data selection</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS2" title="In 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Algorithm-based methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS2.Px1" title="In 5.1.2 Algorithm-based methods ‣ 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">Meta-learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS1.SSS2.Px2" title="In 5.1.2 Algorithm-based methods ‣ 5.1 Practical solutions and empirical evaluation ‣ 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">Multitask learning</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S5.SS2" title="In 5 Attribute skew ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Theoretical analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S6" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Label noise</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S7" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Fairness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S8" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Privacy protection</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S8.SS1" title="In 8 Privacy protection ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>What models reveal about their training data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S8.SS1.SSS1" title="In 8.1 What models reveal about their training data ‣ 8 Privacy protection ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1.1 </span>Limitations of encryption-based defenses</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S9" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Reputation, trust, and security</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S9.SS0.SSS1" title="In 9 Reputation, trust, and security ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.0.1 </span>Impossibility results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S10" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Conclusion and future research directions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S10.SS1" title="In 10 Conclusion and future research directions ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1 </span>Directions for further research</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_bibliography"><a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib" title="In Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_title">References</span></a></li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Data Quality in Edge Machine Learning: A State-of-the-Art Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohammed D. Belgoumri
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohamed Reda Bouadjenek
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sunil Aryal
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hakim Hacid
</span></span>
</div>
<div class="ltx_dates">(Received: / Accepted:)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Data-driven <span class="ltx_ERROR undefined" id="id1.id1.1">\glsxtrfull</span>abb:ai systems trained using <span class="ltx_ERROR undefined" id="id1.id1.2">\glsxtrfull</span>abb:ml are shaping an ever-increasing (in size and importance) portion of our lives, including, but not limited to, recommendation systems, autonomous driving technologies, healthcare diagnostics, financial services, and personalized marketing.
On the one hand, the outsized influence of these systems imposes a high standard of quality, particularly in the data used to train them.
On the other hand, establishing and maintaining standards of <span class="ltx_ERROR undefined" id="id1.id1.3">\glsxtrfull</span>abb:dq becomes more challenging due to the proliferation of Edge Computing and Internet of Things devices, along with their increasing adoption for training and deploying <span class="ltx_ERROR undefined" id="id1.id1.4">\glsxtrshort</span>abb:ml models.
The nature of the edge environment–characterized by limited resources, decentralized data storage, and processing–exacerbates data-related issues, making them more frequent, severe, and difficult to detect and mitigate.
From these observations, it follows that <span class="ltx_ERROR undefined" id="id1.id1.5">\glsxtrshort</span>abb:dq research for edge <span class="ltx_ERROR undefined" id="id1.id1.6">\glsxtrshort</span>abb:ml is a critical and urgent exploration track for the safety and robust usefulness of present and future <span class="ltx_ERROR undefined" id="id1.id1.7">\glsxtrshort</span>abb:ai systems.
Despite this fact, <span class="ltx_ERROR undefined" id="id1.id1.8">\glsxtrshort</span>abb:dq research for edge <span class="ltx_ERROR undefined" id="id1.id1.9">\glsxtrshort</span>abb:ml is still in its infancy.
The literature on this subject remains fragmented and scattered across different research communities, with no comprehensive survey to date.
Hence, this paper aims to fill this gap by providing a global view of the existing literature from multiple disciplines that can be grouped under the umbrella of <span class="ltx_ERROR undefined" id="id1.id1.10">\glsxtrshort</span>abb:dq for edge <span class="ltx_ERROR undefined" id="id1.id1.11">\glsxtrshort</span>abb:ml.
Specifically, we present a tentative definition of data quality in Edge computing, which we use to establish a set of <span class="ltx_ERROR undefined" id="id1.id1.12">\glsxtrshort</span>abb:dq dimensions.
We explore each dimension in detail, including existing solutions for mitigation.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>
<span class="ltx_ERROR undefined" id="id2.id1">\Glsxtrlong</span>abb:ai, <span class="ltx_ERROR undefined" id="id3.id2">\Glsxtrlong</span>abb:ml, <span class="ltx_ERROR undefined" id="id4.id3">\Glsxtrlong</span>abb:ec, <span class="ltx_ERROR undefined" id="id5.id4">\Glsxtrlong</span>abb:dq.
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The recent surge in both the scale and prevalence of <span class="ltx_ERROR undefined" id="S1.p1.1.1">\gls</span>abb:ai systems <cite class="ltx_cite ltx_citemacro_cite">Murshed et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib1" title="">2022</a>)</cite> has led to a significant increase in data and computational demands.
Consequently, the traditional model of solely relying on cloud computing for training and inference is reaching its limits <cite class="ltx_cite ltx_citemacro_cite">Singh and Gill (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib2" title="">2023</a>)</cite>.
Combined with emerging concerns about data privacy and security, and recent advances in <span class="ltx_ERROR undefined" id="S1.p1.1.2">\gls</span>abb:ec, this has led to a paradigm shift in the field of <span class="ltx_ERROR undefined" id="S1.p1.1.3">\gls</span>abb:ml.
A new approach has emerged, which advocates for performing as much of the <span class="ltx_ERROR undefined" id="S1.p1.1.4">\gls</span>abb:ml workload as possible close to the data source (on the so-called edge of the network), offloading only the most computationally intensive tasks to the cloud <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib3" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In doing so, edge <span class="ltx_ERROR undefined" id="S1.p2.1.1">\gls</span>abb:ml promises several benefits over centralized <span class="ltx_ERROR undefined" id="S1.p2.1.2">\gls</span>abb:ml.
One major such benefit is the reduction of the volume and frequency of data transfers,
thereby reducing latency, network bandwidth consumption, and the risk of data breaches <cite class="ltx_cite ltx_citemacro_cite">Singh and Gill (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib2" title="">2023</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib3" title="">2020</a>)</cite>.
Moreover, the distributed nature of the edge naturally precludes a single point of failure,
making the system more resilient and fault-tolerant <cite class="ltx_cite ltx_citemacro_cite">Taik et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib4" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">However, edge <span class="ltx_ERROR undefined" id="S1.p3.1.1">\gls</span>abb:ml, at least in its current form,
is not universally superior to centralized <span class="ltx_ERROR undefined" id="S1.p3.1.2">\gls</span>abb:ml.
While it does address many of the latter’s shortcomings,
it also introduces challenges of its own.
Chief among these challenges is the question of <span class="ltx_ERROR undefined" id="S1.p3.1.3">\gls</span>abb:dq.
Broadly speaking, <span class="ltx_ERROR undefined" id="S1.p3.1.4">\gls</span>abb:dq refers to the fitness of data for a given purpose <cite class="ltx_cite ltx_citemacro_cite">Mahanti (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib5" title="">2019</a>); Hassenstein and Vanella (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib6" title="">2022</a>)</cite>.
Already a major concern in centralized <span class="ltx_ERROR undefined" id="S1.p3.1.5">\gls</span>abb:ml <cite class="ltx_cite ltx_citemacro_cite">Camacho et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib7" title="">2023</a>)</cite>,
<span class="ltx_ERROR undefined" id="S1.p3.1.6">\gls</span>abb:dq is even more relevant in the context of edge <span class="ltx_ERROR undefined" id="S1.p3.1.7">\gls</span>abb:ml,
where resource constraints and the distributed nature of the system
conspire to make data faults more frequent, more severe, and harder to detect and correct.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Owing to the critical role <span class="ltx_ERROR undefined" id="S1.p4.1.1">\gls</span>abb:dq plays
in the successful training and deployment of <span class="ltx_ERROR undefined" id="S1.p4.1.2">\gls</span>abb:ml models on the edge,
many researchers have begun to investigate the topic,
producing a large and growing corpus of literature on the subject.
However, due to the multidisciplinary nature of <span class="ltx_ERROR undefined" id="S1.p4.1.3">\gls</span>abb:dq,
and the lack of an established, unified, and widely accepted framework for studying it,
the literature is fragmented,
with little communication or collaboration
between researchers from relevant but different fields.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.T1.2" style="width:433.6pt;height:218.9pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-265.5pt,133.8pt) scale(0.44949,0.44949) ;">
<p class="ltx_p" id="S1.T1.2.1"><span class="ltx_text" id="S1.T1.2.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S1.T1.2.1.1.1" style="width:964.7pt;height:487pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S1.T1.2.1.1.1.1"><span class="ltx_text" id="S1.T1.2.1.1.1.1.1">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S1.T1.2.1.1.1.1.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S1.T1.2.1.1.1.1.1.1.1.1.1"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S1.T1.2.1.1.1.1.1.1.1.1.2"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S1.T1.2.1.1.1.1.1.1.1.1.3"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S1.T1.2.1.1.1.1.1.1.1.1.4"></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_6" id="S1.T1.2.1.1.1.1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S1.T1.2.1.1.1.1.1.1.1.1.5.1">Data quality</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.2.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S1.T1.2.1.1.1.1.1.1.2.2.1.1">Survey</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S1.T1.2.1.1.1.1.1.1.2.2.2.1">Year</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S1.T1.2.1.1.1.1.1.1.2.2.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.2.2.3.1">\stackanchor</span><span class="ltx_text ltx_font_bold" id="S1.T1.2.1.1.1.1.1.1.2.2.3.2">Federatedlearning</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S1.T1.2.1.1.1.1.1.1.2.2.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.2.2.4.1">\stackanchor</span><span class="ltx_text ltx_font_bold" id="S1.T1.2.1.1.1.1.1.1.2.2.4.2">Edgecomputing</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.2.2.5"><em class="ltx_emph ltx_font_italic" id="S1.T1.2.1.1.1.1.1.1.2.2.5.1">Independence</em></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.2.2.6"><em class="ltx_emph ltx_font_italic" id="S1.T1.2.1.1.1.1.1.1.2.2.6.1">Attribute skew</em></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.2.2.7"><em class="ltx_emph ltx_font_italic" id="S1.T1.2.1.1.1.1.1.1.2.2.7.1">Label noise</em></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.2.2.8"><em class="ltx_emph ltx_font_italic" id="S1.T1.2.1.1.1.1.1.1.2.2.8.1">Fairness</em></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.2.2.9"><em class="ltx_emph ltx_font_italic" id="S1.T1.2.1.1.1.1.1.1.2.2.9.1">Privacy</em></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.2.2.10"><em class="ltx_emph ltx_font_italic" id="S1.T1.2.1.1.1.1.1.1.2.2.10.1">Trust</em></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.3.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.1"><cite class="ltx_cite ltx_citemacro_citet">Sidi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib8" title="">2012</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.2">2012</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.1.1.1.1.1.1.3.1.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.3.1.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.4.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.4.2.1"><cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib3" title="">2020</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.4.2.2">2020</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.4.2.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.4.2.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.5.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.5.3.1"><cite class="ltx_cite ltx_citemacro_citet">Han et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib9" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.5.3.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.5.3.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.5.3.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.6.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.6.4.1"><cite class="ltx_cite ltx_citemacro_citet">Jere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib10" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.6.4.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.6.4.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.6.4.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.7.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.7.5.1"><cite class="ltx_cite ltx_citemacro_citet">Xia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib11" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.7.5.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.7.5.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.7.5.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.8.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.8.6.1"><cite class="ltx_cite ltx_citemacro_citet">Yin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib12" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.8.6.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.8.6.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.8.6.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.9.7">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.9.7.1"><cite class="ltx_cite ltx_citemacro_citet">Ferraguig et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib13" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.9.7.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.9.7.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.9.7.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.10.8">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.10.8.1"><cite class="ltx_cite ltx_citemacro_citet">Truong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib14" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.10.8.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.10.8.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.10.8.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.11.9">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.11.9.1"><cite class="ltx_cite ltx_citemacro_citet">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib15" title="">2021</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.11.9.2">2021</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.11.9.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.11.9.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.12.10">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.12.10.1"><cite class="ltx_cite ltx_citemacro_citet">Abreha et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib16" title="">2022</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.12.10.2">2022</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.12.10.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.12.10.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.13.11">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.13.11.1"><cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib17" title="">2022</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.13.11.2">2022</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.13.11.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.13.11.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.14.12">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.14.12.1"><cite class="ltx_cite ltx_citemacro_citet">Mehrabi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib18" title="">2022</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.14.12.2">2022</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.14.12.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.14.12.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.15.13">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.15.13.1"><cite class="ltx_cite ltx_citemacro_citet">Murshed et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib1" title="">2022</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.15.13.2">2022</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.15.13.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.15.13.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.16.14">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.16.14.1"><cite class="ltx_cite ltx_citemacro_citet">Xia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib19" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.16.14.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.16.14.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.16.14.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.17.15">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.17.15.1"><cite class="ltx_cite ltx_citemacro_citet">Shi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib20" title="">2022</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.17.15.2">2022</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.17.15.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.17.15.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.18.16">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.18.16.1"><cite class="ltx_cite ltx_citemacro_citet">Rodríguez-Barroso et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib21" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.18.16.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.18.16.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.18.16.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.19.17">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.19.17.1"><cite class="ltx_cite ltx_citemacro_citet">Abyane et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib22" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.19.17.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.19.17.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.19.17.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.20.18">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.20.18.1"><cite class="ltx_cite ltx_citemacro_citet">Whang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib23" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.20.18.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.20.18.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.20.18.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.21.19">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.21.19.1"><cite class="ltx_cite ltx_citemacro_citet">Gallegos et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib24" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.21.19.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.21.19.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.21.19.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.22.20">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.22.20.1"><cite class="ltx_cite ltx_citemacro_citet">Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib25" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.22.20.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.9.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.22.20.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.22.20.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.23.21">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.23.21.1"><cite class="ltx_cite ltx_citemacro_citet">Gong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib26" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.23.21.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.3.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.23.21.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.23.21.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.24.22">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.24.22.1"><cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib27" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.24.22.2">2023</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.8.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.24.22.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.24.22.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.25.23">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.25.23.1"><cite class="ltx_cite ltx_citemacro_citet">Rafi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib28" title="">2024</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.25.23.2">2024</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.4.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.25.23.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.25.23.10.1">\xmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.26.24">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.26.24.1"><cite class="ltx_cite ltx_citemacro_citet">Sánchez Sánchez et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib29" title="">2024</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.2.1.1.1.1.1.1.26.24.2">2024</span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.5.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.6.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.7.1">\xmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center" id="S1.T1.2.1.1.1.1.1.1.26.24.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.26.24.10.1">\cmark</span></span></span>
<span class="ltx_tr" id="S1.T1.2.1.1.1.1.1.1.27.25">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.1">Our survey</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.2">2024</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.3"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.3.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.4"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.4.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.5"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.5.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.6"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.6.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.7"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.7.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.8"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.8.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.9"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.9.1">\cmark</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.2.1.1.1.1.1.1.27.25.10"><span class="ltx_ERROR undefined" id="S1.T1.2.1.1.1.1.1.1.27.25.10.1">\cmark</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S1.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S1.T1.4.2" style="font-size:90%;">Comparison of this survey to other surveys.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Simultaneously a symptom and a partial cause of this fragmentation,
is the lack of a survey of the state of the art
on <span class="ltx_ERROR undefined" id="S1.p5.1.1">\gls</span>abb:dq in edge <span class="ltx_ERROR undefined" id="S1.p5.1.2">\gls</span>abb:ml.
While a few comprehensive surveys have been published covering <span class="ltx_ERROR undefined" id="S1.p5.1.3">\gls</span>abb:dq
in the general contexts of both
<span class="ltx_ERROR undefined" id="S1.p5.1.4">\gls</span>abb:ml <cite class="ltx_cite ltx_citemacro_cite">Gong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib30" title="">2019</a>)</cite>,
and <span class="ltx_ERROR undefined" id="S1.p5.1.5">\gls</span>abb:ec <cite class="ltx_cite ltx_citemacro_cite">Karkouch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib31" title="">2016</a>)</cite>,
to the best of our knowledge,
none exists that addresses it for the edge <span class="ltx_ERROR undefined" id="S1.p5.1.6">\gls</span>abb:ml case.
Instead, there is a plethora of surveys,
each focusing on a different aspect of <span class="ltx_ERROR undefined" id="S1.p5.1.7">\gls</span>abb:ml data quality,
many of which do address the specific case of edge <span class="ltx_ERROR undefined" id="S1.p5.1.8">\gls</span>abb:ml.
<span class="ltx_ERROR undefined" id="S1.p5.1.9">\Cref</span>tab:comparison_to_other_surveys provides a list of such surveys,
along with the aspects of <span class="ltx_ERROR undefined" id="S1.p5.1.10">\gls</span>abb:dq they cover.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this survey, we aim to provide a broad and comprehensive overview
of the state of the art on <span class="ltx_ERROR undefined" id="S1.p6.1.1">\gls</span>abb:dq in edge <span class="ltx_ERROR undefined" id="S1.p6.1.2">\gls</span>abb:ml,
gathering works from the different <span class="ltx_ERROR undefined" id="S1.p6.1.3">\gls</span>abb:ml research areas,
such as noise-resilience, fairness, privacy, and Byzantine fault tolerance
under the unifying umbrella of <span class="ltx_ERROR undefined" id="S1.p6.1.4">\gls</span>abb:dq.
To this end, we establish a guiding principle for defining <span class="ltx_ERROR undefined" id="S1.p6.1.5">\gls</span>abb:dq
based on the formulation of <span class="ltx_ERROR undefined" id="S1.p6.1.6">\gls</span>abb:ml as an optimization problem.
We use this principle, along with theoretical sufficient conditions
for the convergence of <span class="ltx_ERROR undefined" id="S1.p6.1.7">\gls</span>abb:ml algorithms,
to devise a list of <span class="ltx_ERROR undefined" id="S1.p6.1.8">\gls</span>abb:dq dimensions.
For each dimension, we provide a detailed discussion of existing works,
including common definitions, the faults that can occur and the taxonomy thereof,
the proposed solutions,
and, where applicable, the ways in which the dimension has been studied
in the context of edge <span class="ltx_ERROR undefined" id="S1.p6.1.9">\gls</span>abb:ml.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The remainder of this paper is organized as follows.
<span class="ltx_ERROR undefined" id="S1.p7.1.1">\Cref</span>sec:background provides preliminary background information on edge <span class="ltx_ERROR undefined" id="S1.p7.1.2">\gls</span>abb:ml,
including a general discussion of <span class="ltx_ERROR undefined" id="S1.p7.1.3">\glsxtrlong</span>abb:ml,
a brief overview of the edge environment,
and the algorithms used to perform <span class="ltx_ERROR undefined" id="S1.p7.1.4">\gls</span>abb:ml on the edge,
with particular focus on <span class="ltx_ERROR undefined" id="S1.p7.1.5">\glsxtrlong</span>abb:fl.
<span class="ltx_ERROR undefined" id="S1.p7.1.6">\Cref</span>sec:data_quality is dedicated to <span class="ltx_ERROR undefined" id="S1.p7.1.7">\gls</span>abb:dq in <span class="ltx_ERROR undefined" id="S1.p7.1.8">\gls</span>abb:ml,
its definition, dimensions, and the families of solutions proposed to ensure it.
<span class="ltx_ERROR undefined" id="S1.p7.1.9">\Crefrange</span>sec:independencesec:trust address one <span class="ltx_ERROR undefined" id="S1.p7.1.10">\gls</span>abb:dq dimension each,
providing definitions, possible faults, proposed solutions (if any),
all in the context of edge <span class="ltx_ERROR undefined" id="S1.p7.1.11">\gls</span>abb:ml (where literature permits).
Finally, <span class="ltx_ERROR undefined" id="S1.p7.1.12">\Cref</span>sec:conclusion concludes the paper
with a summary of the main findings and a discussion of future research directions.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Straightforwardly, edge <span class="ltx_ERROR undefined" id="S2.p1.1.1">\gls</span>abb:ml can be defined as
performing some or all of the computation involved in
<span class="ltx_ERROR undefined" id="S2.p1.1.2">\gls</span>abb:ml training and inference on edge devices <cite class="ltx_cite ltx_citemacro_cite">Singh and Gill (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib2" title="">2023</a>)</cite>.
Therefore, understanding edge <span class="ltx_ERROR undefined" id="S2.p1.1.3">\gls</span>abb:ml requires understanding
<span class="ltx_ERROR undefined" id="S2.p1.1.4">\glsxtrlong</span>abb:ml, <span class="ltx_ERROR undefined" id="S2.p1.1.5">\glsxtrlong</span>abb:ec, and the ways in which they interact.
This section discusses these three topics in order,
starting with a general overview of <span class="ltx_ERROR undefined" id="S2.p1.1.6">\gls</span>abb:ml,
followed by a brief discussion of <span class="ltx_ERROR undefined" id="S2.p1.1.7">\gls</span>abb:ec,
and finally, the algorithms used for <span class="ltx_ERROR undefined" id="S2.p1.1.8">\gls</span>abb:ml on the edge.</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Notations and conventions</h5>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Throughout this document, we will make use of the notations presented in <span class="ltx_ERROR undefined" id="S2.SS0.SSS0.Px1.p1.1.1">\Cref</span>tab:notations.
When we consider probabilities, expectations, or random variables on some space,
we implicitly assume a suitable <math alttext="\sigma-" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">σ</mi><mo id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">limit-from</csymbol><ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2">𝜎</ci><minus id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">\sigma-</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.1.m1.1d">italic_σ -</annotation></semantics></math>algebra and probability measure on that space.</p>
</div>
<figure class="ltx_table" id="S2.SS0.SSS0.Px1.27">
<div class="ltx_block" id="S2.SS0.SSS0.Px1.27.27">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.SS0.SSS0.Px1.27.27.27">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.27.27.27.28.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.SS0.SSS0.Px1.27.27.27.28.1.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.27.27.27.28.1.1.1">Notation</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.SS0.SSS0.Px1.27.27.27.28.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.27.27.27.28.1.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.27.27.27.28.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.27.27.27.28.1.2.1.1.1">Significance</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S2.SS0.SSS0.Px1.1.1.1.1.1"><math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.1.1.1.1.1.m1.1d">caligraphic_X</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.SS0.SSS0.Px1.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.1.1.1.1.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.1.1.1.1.2.1.1">Input space</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.2.2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.2.2.2.2.1"><math alttext="\mathcal{Y},\tilde{\mathcal{Y}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2"><semantics id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2a"><mrow id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.3.2" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.1.1" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.1.1.cmml">𝒴</mi><mo id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.3.2.1" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.3.1.cmml">,</mo><mover accent="true" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.2" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.2.cmml">𝒴</mi><mo id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.1" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.1.cmml">~</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2b"><list id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.3.2"><ci id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.1.1">𝒴</ci><apply id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.cmml" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2"><ci id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.1">~</ci><ci id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2.2.2">𝒴</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2c">\mathcal{Y},\tilde{\mathcal{Y}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.2.2.2.2.1.m1.2d">caligraphic_Y , over~ start_ARG caligraphic_Y end_ARG</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.2.2.2.2.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.2.2.2.2.2.1.1">Output space, and noisy output space respectively</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.3.3.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.3.3.3.3.1"><math alttext="\mathcal{H}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1.1" xref="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1.1.cmml">ℋ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1.1">ℋ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1c">\mathcal{H}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.3.3.3.3.1.m1.1d">caligraphic_H</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.3.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.3.3.3.3.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.3.3.3.3.2.1.1">Hypothesis class</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.4.4.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.4.4.4.4.1"><math alttext="\Theta" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1.1" mathvariant="normal" xref="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1c">\Theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.4.4.4.4.1.m1.1d">roman_Θ</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.4.4.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.4.4.4.4.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.4.4.4.4.2.1.1">Parameter space</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.6.6.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.5.5.5.5.1"><math alttext="\mathcal{R},\mathcal{R}_{i}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2"><semantics id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2a"><mrow id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.1.1" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.1.1.cmml">ℛ</mi><mo id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.2" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.2.cmml">,</mo><msub id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.2" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.2.cmml">ℛ</mi><mi id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.3" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2b"><list id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1"><ci id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.1.1">ℛ</ci><apply id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.2">ℛ</ci><ci id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2.2.1.1.3">𝑖</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2c">\mathcal{R},\mathcal{R}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.5.5.5.5.1.m1.2d">caligraphic_R , caligraphic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.6.6.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.6.6.6.6.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1">Global true risk, local true risk of client <math alttext="i" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.6.6.6.6.2.1.1.m1.1d">italic_i</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.8.8.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.7.7.7.7.1"><math alttext="\hat{\mathcal{R}}_{\xi}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1a"><msub id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.cmml"><mover accent="true" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.2.cmml">ℛ</mi><mo id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.1" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.3.cmml">ξ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1">subscript</csymbol><apply id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2"><ci id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.1">^</ci><ci id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.2.2">ℛ</ci></apply><ci id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1.1.3">𝜉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1c">\hat{\mathcal{R}}_{\xi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.7.7.7.7.1.m1.1d">over^ start_ARG caligraphic_R end_ARG start_POSTSUBSCRIPT italic_ξ end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.8.8.8.8.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.8.8.8.8.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1">Empirical risk with respect to <math alttext="\xi" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1.1.cmml">ξ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1.1">𝜉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1c">\xi</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.8.8.8.8.2.1.1.m1.1d">italic_ξ</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.10.10.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.9.9.9.9.1"><math alttext="\theta^{\ast}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1a"><msup id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.2.cmml">θ</mi><mo id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.2">𝜃</ci><ci id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1.1.3">∗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1c">\theta^{\ast}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.9.9.9.9.1.m1.1d">italic_θ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.10.10.10.10.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1">Bayes-optimal model (minimizer of <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.10.10.10.10.2.1.1.m1.1d">caligraphic_R</annotation></semantics></math>)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.12.12.12.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.11.11.11.11.1"><math alttext="\hat{\theta}_{\xi}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1a"><msub id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.cmml"><mover accent="true" id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.2.cmml">θ</mi><mo id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.1" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.3.cmml">ξ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1">subscript</csymbol><apply id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2"><ci id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.1">^</ci><ci id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.2.2">𝜃</ci></apply><ci id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1.1.3">𝜉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1c">\hat{\theta}_{\xi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.11.11.11.11.1.m1.1d">over^ start_ARG italic_θ end_ARG start_POSTSUBSCRIPT italic_ξ end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.12.12.12.12.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1">Minimizer of <math alttext="\hat{\mathcal{R}}_{\xi}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1a"><msub id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.cmml"><mover accent="true" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.2.cmml">ℛ</mi><mo id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.1" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.3.cmml">ξ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1">subscript</csymbol><apply id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2"><ci id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.1">^</ci><ci id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.2.2">ℛ</ci></apply><ci id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1.1.3">𝜉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1c">\hat{\mathcal{R}}_{\xi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.12.12.12.12.2.1.1.m1.1d">over^ start_ARG caligraphic_R end_ARG start_POSTSUBSCRIPT italic_ξ end_POSTSUBSCRIPT</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.15.15.15.15">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.13.13.13.13.1"><math alttext="\theta^{(t)},\theta_{i}^{(t)}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4"><semantics id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4a"><mrow id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.3.cmml"><msup id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.2" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.2.cmml">θ</mi><mrow id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.3" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.cmml"><mo id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.3.1" stretchy="false" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.cmml">(</mo><mi id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.1" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.1.cmml">t</mi><mo id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.3.2" stretchy="false" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.3" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.3.cmml">,</mo><msubsup id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.2" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.2.cmml">θ</mi><mi id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.3" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.3.cmml">i</mi><mrow id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.3" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.cmml"><mo id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.3.1" stretchy="false" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.cmml">(</mo><mi id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.1" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.1.cmml">t</mi><mo id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.3.2" stretchy="false" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.cmml">)</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4b"><list id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.3.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2"><apply id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.3.3.1.1.2">𝜃</ci><ci id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.1.1.1.1">𝑡</ci></apply><apply id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2">superscript</csymbol><apply id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.2">𝜃</ci><ci id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4.4.2.2.2.3">𝑖</ci></apply><ci id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.2.2.1.1">𝑡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4c">\theta^{(t)},\theta_{i}^{(t)}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.13.13.13.13.1.m1.4d">italic_θ start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.15.15.15.15.3">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.15.15.15.15.3.2">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2">Global model (resp. <math alttext="i^{\mathrm{th}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1a"><msup id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.2.cmml">i</mi><mi id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.3.cmml">th</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.2">𝑖</ci><ci id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1c">i^{\mathrm{th}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.14.14.14.14.2.1.1.m1.1d">italic_i start_POSTSUPERSCRIPT roman_th end_POSTSUPERSCRIPT</annotation></semantics></math> local model) at round <math alttext="t" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1a"><mi id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1b"><ci id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.15.15.15.15.3.2.2.m2.1d">italic_t</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.18.18.18.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.16.16.16.16.1"><math alttext="A\independent B" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1a"><mrow id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.2.cmml">A</mi><mo id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.1" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.1.cmml">⁢</mo><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3b.cmml"><mtext id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3a" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3b.cmml">\independent</mtext></merror><mo id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.1a" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.1.cmml">⁢</mo><mi id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.4" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.4.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1"><times id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.1"></times><ci id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.2">𝐴</ci><ci id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3b.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3"><mtext id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3a.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.3">\independent</mtext></merror></ci><ci id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.4.cmml" xref="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1.1.4">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1c">A\independent B</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.16.16.16.16.1.m1.1d">italic_A italic_B</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.18.18.18.18.3">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.18.18.18.18.3.2">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2"><math alttext="A" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.17.17.17.17.2.1.1.m1.1d">italic_A</annotation></semantics></math> is independent of <math alttext="B" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1a"><mi id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1b"><ci id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.18.18.18.18.3.2.2.m2.1d">italic_B</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.22.22.22.22">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.19.19.19.19.1"><math alttext="A\independent B\mid C" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1a"><mrow id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.cmml"><mrow id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.2.cmml">A</mi><mo id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.1" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.1.cmml">⁢</mo><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3b.cmml"><mtext id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3a" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3b.cmml">\independent</mtext></merror><mo id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.1a" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.4" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.4.cmml">B</mi></mrow><mo id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.1" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.1.cmml">∣</mo><mi id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.1">conditional</csymbol><apply id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2"><times id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.1"></times><ci id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.2">𝐴</ci><ci id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3b.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3"><mtext id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3a.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.3">\independent</mtext></merror></ci><ci id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.4.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.2.4">𝐵</ci></apply><ci id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1c">A\independent B\mid C</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.19.19.19.19.1.m1.1d">italic_A italic_B ∣ italic_C</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.22.22.22.22.4">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.22.22.22.22.4.3">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3"><math alttext="A" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.20.20.20.20.2.1.1.m1.1d">italic_A</annotation></semantics></math> is independent of <math alttext="B" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1a"><mi id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1b"><ci id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.21.21.21.21.3.2.2.m2.1d">italic_B</annotation></semantics></math> given <math alttext="C" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1"><semantics id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1a"><mi id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1.1" xref="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1b"><ci id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.22.22.22.22.4.3.3.m3.1d">italic_C</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.24.24.24.24">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.SS0.SSS0.Px1.23.23.23.23.1"><math alttext="[n]" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1a"><mrow id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.2" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.1.cmml"><mo id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.1.1.cmml">[</mo><mi id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.1" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.1.cmml">n</mi><mo id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.2.2" stretchy="false" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.2"><csymbol cd="latexml" id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.2.2.1">delimited-[]</csymbol><ci id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1c">[n]</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.23.23.23.23.1.m1.1d">[ italic_n ]</annotation></semantics></math></th>
<td class="ltx_td ltx_align_justify" id="S2.SS0.SSS0.Px1.24.24.24.24.2">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.24.24.24.24.2.1">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1">The set <math alttext="\{1,2,\ldots,n\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4"><semantics id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4a"><mrow id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml"><mo id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml">{</mo><mn id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.1.1.cmml">1</mn><mo id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2.2" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml">,</mo><mn id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.2.2" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.2.2.cmml">2</mn><mo id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2.3" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.3.3" mathvariant="normal" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.3.3.cmml">…</mi><mo id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2.4" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.4" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.4.cmml">n</mi><mo id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2.5" stretchy="false" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4b"><set id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.1.cmml" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.5.2"><cn id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.1.1">1</cn><cn id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.2.2.cmml" type="integer" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.2.2">2</cn><ci id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.3.3.cmml" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.3.3">…</ci><ci id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.4.cmml" xref="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4.4">𝑛</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4c">\{1,2,\ldots,n\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.24.24.24.24.2.1.1.m1.4d">{ 1 , 2 , … , italic_n }</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.SS0.SSS0.Px1.27.27.27.27">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S2.SS0.SSS0.Px1.25.25.25.25.1"><math alttext="\triangle^{n}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1a"><msup id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.2" mathvariant="normal" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.2.cmml">△</mi><mi id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.3.cmml">n</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.2">△</ci><ci id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1c">\triangle^{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.25.25.25.25.1.m1.1d">△ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_bb" id="S2.SS0.SSS0.Px1.27.27.27.27.3">
<span class="ltx_inline-block ltx_align_top" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2">
<span class="ltx_p" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2">The simplex of <math alttext="\reals^{n}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1a"><msup id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2b.cmml"><mtext id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2a" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2b.cmml">\reals</mtext></merror><mi id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.3.cmml">n</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2b.cmml" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2"><mtext id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2a.cmml" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.2">\reals</mtext></merror></ci><ci id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1c">\reals^{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.26.26.26.26.2.1.1.m1.1d">start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, i.e., <math alttext="\left\{\alpha\in\positive{\reals}^{n}\middle|\lpnorm[1]{\alpha}=1\right\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3"><semantics id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3a"><mrow id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.3.cmml"><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.3" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.3.1.cmml">{</mo><mrow id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.2.cmml">α</mi><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.1" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.1.cmml">∈</mo><mrow id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2b.cmml"><mtext id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2a" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2b.cmml">\positive</mtext></merror><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.1" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.1.cmml">⁢</mo><msup id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2b.cmml"><mtext id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2a" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2b.cmml">\reals</mtext></merror><mi id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.3" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.3.cmml">n</mi></msup></mrow></mrow><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.4" lspace="0em" rspace="0em" stretchy="true" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.3.1.cmml">|</mo><mrow id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.cmml"><mrow id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2b.cmml"><mtext id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2a" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2b.cmml">\lpnorm</mtext></merror><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.1" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.1.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.2" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.1.cmml"><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.1.1.cmml">[</mo><mn id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.1.1.cmml">1</mn><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.2.2" stretchy="false" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.1.1.cmml">]</mo></mrow><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.1a" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.1.cmml">⁢</mo><mi id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.4" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.4.cmml">α</mi></mrow><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.1" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.3" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.3.cmml">1</mn></mrow><mo id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.5" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3b"><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.3.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2"><csymbol cd="latexml" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.3">conditional-set</csymbol><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1"><in id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.1"></in><ci id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.2">𝛼</ci><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3"><times id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.1"></times><ci id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2b.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2"><mtext id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2a.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.2">\positive</mtext></merror></ci><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2b.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2"><mtext id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2a.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.2">\reals</mtext></merror></ci><ci id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.3.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.2.2.1.1.3.3.3">𝑛</ci></apply></apply></apply><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2"><eq id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.1"></eq><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2"><times id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.1"></times><ci id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2b.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2"><mtext id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2a.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.2">\lpnorm</mtext></merror></ci><apply id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.2"><csymbol cd="latexml" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.1.1.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.3.2.1">delimited-[]</csymbol><cn id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.1.1">1</cn></apply><ci id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.4.cmml" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.2.4">𝛼</ci></apply><cn id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3.3.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3c">\left\{\alpha\in\positive{\reals}^{n}\middle|\lpnorm[1]{\alpha}=1\right\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.27.27.27.27.3.2.2.m2.3d">{ italic_α ∈ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT | [ 1 ] italic_α = 1 }</annotation></semantics></math></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_block"><span class="ltx_text" id="S2.SS0.SSS0.Px1.27.27.28.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S2.SS0.SSS0.Px1.27.27.29.2" style="font-size:90%;">Notations used in this document.</span></figcaption>
<section class="ltx_subsection ltx_centering" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Edge machine learning</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Having introduced both <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.1">\glsxtrlong</span>abb:ml in <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.2">\Cref</span>sub:general_notions_of_ml
and <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.3">\glsxtrlong</span>abb:ec in <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.4">\Cref</span>sub:edge_computing,
we dedicate this section to discussing their combination.
We are particularly interested in <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.5">\gls</span>abb:dl on the edge,
since <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.6">\glspl</span>abb:dnn are both very popular, and easy to parallelize.
In all generality, the process of training a <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.7">\gls</span>abb:ml models on the edge
is depicted in <span class="ltx_ERROR undefined" id="S2.SS1.p1.1.8">\Cref</span>fig:edge_ml_process.
End devices collect data from their environment,
optionally preprocessing or temporally storing it,
before sending it to an edge node.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="205" id="S2.F1.1.g1" src="x1.png" width="664"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.4.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.5.2" style="font-size:90%;">An end-to-end <span class="ltx_ERROR undefined" id="S2.F1.5.2.1">\glsfmtshort</span>abb:ml training process on the edge.</span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The edge node aggregates, processes, and stores the data,
before training its local model on it,
possibly invoking the server for orchestration or heavy computations.
The server manages the training process
and performs the computations delegated to it by the edge nodes.
During each step of this process,
edge nodes can respond to client inference requests
using their current local model.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">The number of proposed techniques to train <span class="ltx_ERROR undefined" id="S2.SS1.p3.1.1">\gls</span>abb:ml models on the edge
is beyond what can be covered in a single section.
Therefore, we focus on two of the most popular techniques:
distributed learning and federated learning,
directing the reader’s attention to <cite class="ltx_cite ltx_citemacro_cite">Khouas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib40" title="">2024</a>)</cite>
for a review of other techniques.</p>
</div>
</section>
<section class="ltx_section ltx_centering" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data quality for machine learning</h2>
<div class="ltx_para" id="S3.p1">
<span class="ltx_ERROR undefined" id="S3.p1.1">\Glsxtrfull</span>
<p class="ltx_p" id="S3.p1.2">abb:dq is the central focus of this survey.
It is an extremely broad topic, not only in <span class="ltx_ERROR undefined" id="S3.p1.2.1">\gls</span>abb:ml but also in
data science, data engineering, database management, information systems,
and multiple other adjacent disciplines,
as evidenced by the numerous works on the subject <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib45" title="">2023</a>); Gupta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib46" title="">2021</a>); Olson (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib47" title="">2003</a>); Mahanti (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib5" title="">2019</a>); Renggli et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib48" title="">2021</a>); Camacho et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib7" title="">2023</a>); Gudivada et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib49" title="">2017</a>)</cite>
and the equally numerous approaches these works take to study it.
In this section, we explore <span class="ltx_ERROR undefined" id="S3.p1.2.2">\gls</span>abb:dq for <span class="ltx_ERROR undefined" id="S3.p1.2.3">\gls</span>abb:ml data
as it is covered in the existing literature,
with particular focus on the questions of:

<span class="ltx_inline-enumerate" id="S3.I1">
<span class="ltx_inline-item" id="S3.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="S3.I1.i1.1">what is data quality? (i.e., how it is defined),
</span></span>
<span class="ltx_inline-item" id="S3.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="S3.I1.i2.1">what characterizes a good dataset? (data quality dimensions), and
</span></span>
<span class="ltx_inline-item" id="S3.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="S3.I1.i3.1">how is data quality ensured? (existing solutions).
</span></span>
</span>
As such, this section is divided into three parts,
each corresponding to one of the above questions (in order).</p>
</div>
</section>
<section class="ltx_section ltx_centering" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Statistical independence</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The so-called <span class="ltx_ERROR undefined" id="S4.p1.1.1">\gls</span>abb:iid assumption is the bedrock
for much of the classical theory (and practice) of <span class="ltx_ERROR undefined" id="S4.p1.1.2">\gls</span>abb:ml
 <cite class="ltx_cite ltx_citemacro_cite">Vapnik (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib38" title="">2010</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib67" title="">2023</a>)</cite>.
While convenient for theoretical analysis,
the <span class="ltx_ERROR undefined" id="S4.p1.1.3">\gls</span>abb:iid assumption is not a realistic model of real-world data <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib67" title="">2023</a>)</cite>,
an observation that is even more salient in <span class="ltx_ERROR undefined" id="S4.p1.1.4">\gls</span>abb:fl on the edge <cite class="ltx_cite ltx_citemacro_cite">Xia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib11" title="">2021</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib68" title="">2021</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib69" title="">2020</a>)</cite>.
In general, the <span class="ltx_ERROR undefined" id="S4.p1.1.5">\gls</span>abb:iid assumption can fail in two ways,
the data can be either

<span class="ltx_inline-enumerate" id="S4.I1">
<span class="ltx_inline-item" id="S4.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <em class="ltx_emph ltx_font_italic" id="S4.I1.i1.1">dependent</em><span class="ltx_text" id="S4.I1.i1.2">, or
</span></span>
<span class="ltx_inline-item" id="S4.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="S4.I1.i2.1">it can fail to be equidistributed according to
the true distribution <math alttext="\Pr_{(X,Y)}" class="ltx_Math" display="inline" id="S4.I1.i2.1.m1.2"><semantics id="S4.I1.i2.1.m1.2a"><msub id="S4.I1.i2.1.m1.2.3" xref="S4.I1.i2.1.m1.2.3.cmml"><mi id="S4.I1.i2.1.m1.2.3.2" xref="S4.I1.i2.1.m1.2.3.2.cmml">Pr</mi><mrow id="S4.I1.i2.1.m1.2.2.2.4" xref="S4.I1.i2.1.m1.2.2.2.3.cmml"><mo id="S4.I1.i2.1.m1.2.2.2.4.1" stretchy="false" xref="S4.I1.i2.1.m1.2.2.2.3.cmml">(</mo><mi id="S4.I1.i2.1.m1.1.1.1.1" xref="S4.I1.i2.1.m1.1.1.1.1.cmml">X</mi><mo id="S4.I1.i2.1.m1.2.2.2.4.2" xref="S4.I1.i2.1.m1.2.2.2.3.cmml">,</mo><mi id="S4.I1.i2.1.m1.2.2.2.2" xref="S4.I1.i2.1.m1.2.2.2.2.cmml">Y</mi><mo id="S4.I1.i2.1.m1.2.2.2.4.3" stretchy="false" xref="S4.I1.i2.1.m1.2.2.2.3.cmml">)</mo></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i2.1.m1.2b"><apply id="S4.I1.i2.1.m1.2.3.cmml" xref="S4.I1.i2.1.m1.2.3"><csymbol cd="ambiguous" id="S4.I1.i2.1.m1.2.3.1.cmml" xref="S4.I1.i2.1.m1.2.3">subscript</csymbol><ci id="S4.I1.i2.1.m1.2.3.2.cmml" xref="S4.I1.i2.1.m1.2.3.2">Pr</ci><interval closure="open" id="S4.I1.i2.1.m1.2.2.2.3.cmml" xref="S4.I1.i2.1.m1.2.2.2.4"><ci id="S4.I1.i2.1.m1.1.1.1.1.cmml" xref="S4.I1.i2.1.m1.1.1.1.1">𝑋</ci><ci id="S4.I1.i2.1.m1.2.2.2.2.cmml" xref="S4.I1.i2.1.m1.2.2.2.2">𝑌</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.1.m1.2c">\Pr_{(X,Y)}</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i2.1.m1.2d">roman_Pr start_POSTSUBSCRIPT ( italic_X , italic_Y ) end_POSTSUBSCRIPT</annotation></semantics></math>.
</span></span>
</span>
In this section, we discuss the first of these two issues,
leaving the second for <span class="ltx_ERROR undefined" id="S4.p1.1.6">\Cref</span>sec:equidistribution,sec:noise.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Machine learning on dependent data</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The majority of works in the literature on learning from dependent data <cite class="ltx_cite ltx_citemacro_cite">Zou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib70" title="">2009</a>); Guo and Shi (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib71" title="">2011</a>); Zimin (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib72" title="">2018</a>); Roy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib73" title="">2021</a>)</cite>
relies on the theory of stochastic processes.
The typical approach is to replace the independence part
of the <span class="ltx_ERROR undefined" id="S4.SS1.p1.1.1">\gls</span>abb:iid assumption with a weaker condition like <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.2">mixing</em> <cite class="ltx_cite ltx_citemacro_cite">Guo and Shi (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib71" title="">2011</a>)</cite>.
This is sometimes accompanied by a strengthening
of the <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.3">identically distributed</em> part to a <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.4">stationarity condition</em> <cite class="ltx_cite ltx_citemacro_cite">Roy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib73" title="">2021</a>); Dundar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib74" title="">????</a>)</cite>.
The alternate set of assumptions is then used to derive generalization bounds
analogous to those available in the <span class="ltx_ERROR undefined" id="S4.SS1.p1.1.5">\gls</span>abb:iid case.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Notable deviations from this approach include the work of
<cite class="ltx_cite ltx_citemacro_citet">Lauer (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib75" title="">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Dundar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib74" title="">????</a>)</cite>.
The former presents derivations of classical generalization bounds
such as those based on the <span class="ltx_ERROR undefined" id="S4.SS1.p2.1.1">\gls</span>abb:vc dimension <cite class="ltx_cite ltx_citemacro_cite">Vapnik (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib33" title="">1998</a>)</cite>,
or the Rademacher complexity of the hypothesis class,
without assuming independence, nor replacing it with another condition.
The latter on the other hand, takes a more practical approach,
leveraging (actual or assumed) information about the structure of the dependence
to train linear classifiers on dependent data.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Dependent data in federated learning</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The problem of data dependence in <span class="ltx_ERROR undefined" id="S4.SS2.p1.1.1">\gls</span>abb:fl on edge devices remains largely unexplored.
In our review of the literature, we could not find any edge or <span class="ltx_ERROR undefined" id="S4.SS2.p1.1.2">\gls</span>abb:fl-specific works
that address the issue of dependent data.
This is not indicative of a general lack of interest in
the effect of <span class="ltx_ERROR undefined" id="S4.SS2.p1.1.3">\gls</span>abb:iid violations on <span class="ltx_ERROR undefined" id="S4.SS2.p1.1.4">\gls</span>abb:fl,
which is one of the most active areas of research in the field,
even more so in the case of edge <span class="ltx_ERROR undefined" id="S4.SS2.p1.1.5">\gls</span>abb:fl <cite class="ltx_cite ltx_citemacro_cite">Xia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib11" title="">2021</a>)</cite>.
Most of these works, however, disregard the question of dependence,
in favor of focusing on distribution mismatch <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib68" title="">2021</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib69" title="">2020</a>); Lee (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib76" title="">2023</a>)</cite>.
The absence of works on dependent data in <span class="ltx_ERROR undefined" id="S4.SS2.p1.1.6">\gls</span>abb:fl,
coupled with the localized nature of the edge environment,
which can lead to strong dependence between the data points
of one device or a set of similar devices,
and the difficulty of detecting such dependence due to privacy constraints,
suggests that this is a promising direction for future research.</p>
</div>
</section>
</section>
<section class="ltx_section ltx_centering" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Attribute skew</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.2">The second (and arguably the most important) component
of the <span class="ltx_ERROR undefined" id="S5.p1.2.1">\gls</span>abb:iid assumption is for all random pairs in the sample
to be drawn from the true distribution.
If this is not the case, the empirical risk is not guaranteed to converge to the true risk,
negating guarantees on the consistency of <span class="ltx_ERROR undefined" id="S5.p1.2.2">\gls</span>abb:erm.
This can be due to a mismatch in the marginal distribution <math alttext="\Pr_{X}" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><msub id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">Pr</mi><mi id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">X</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1">subscript</csymbol><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">Pr</ci><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\Pr_{X}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">roman_Pr start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT</annotation></semantics></math>
or the conditional distribution <math alttext="\Pr_{Y\mid X}" class="ltx_Math" display="inline" id="S5.p1.2.m2.1"><semantics id="S5.p1.2.m2.1a"><msub id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mi id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">Pr</mi><mrow id="S5.p1.2.m2.1.1.3" xref="S5.p1.2.m2.1.1.3.cmml"><mi id="S5.p1.2.m2.1.1.3.2" xref="S5.p1.2.m2.1.1.3.2.cmml">Y</mi><mo id="S5.p1.2.m2.1.1.3.1" xref="S5.p1.2.m2.1.1.3.1.cmml">∣</mo><mi id="S5.p1.2.m2.1.1.3.3" xref="S5.p1.2.m2.1.1.3.3.cmml">X</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.cmml" xref="S5.p1.2.m2.1.1">subscript</csymbol><ci id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2">Pr</ci><apply id="S5.p1.2.m2.1.1.3.cmml" xref="S5.p1.2.m2.1.1.3"><csymbol cd="latexml" id="S5.p1.2.m2.1.1.3.1.cmml" xref="S5.p1.2.m2.1.1.3.1">conditional</csymbol><ci id="S5.p1.2.m2.1.1.3.2.cmml" xref="S5.p1.2.m2.1.1.3.2">𝑌</ci><ci id="S5.p1.2.m2.1.1.3.3.cmml" xref="S5.p1.2.m2.1.1.3.3">𝑋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\Pr_{Y\mid X}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.1d">roman_Pr start_POSTSUBSCRIPT italic_Y ∣ italic_X end_POSTSUBSCRIPT</annotation></semantics></math>.
In this section, we will discuss the first of these two possibilities,
discussing the second in the next section.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">When multiple edge devices participate in <span class="ltx_ERROR undefined" id="S5.p2.1.1">\gls</span>abb:fl,
their local datasets are often heterogeneous <cite class="ltx_cite ltx_citemacro_cite">Abreha et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib16" title="">2022</a>)</cite>.
For example, two wearable devices owned by people of different ages
and physical activity levels are extremely unlikely to have similarly distributed datasets.
Therefore, aggregating models trained on these datasets
will not necessarily yield an unbiased estimate of the model trained on their union <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib77" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Addressing this issue is one of the most active areas of research in <span class="ltx_ERROR undefined" id="S5.p3.1.1">\gls</span>abb:fl.
The corpus of literature on the topic is expansive, diverse, and rapidly growing,
covering a wide range of topics from theoretical guarantees <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib69" title="">2020</a>); Lee (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib76" title="">2023</a>)</cite>
to practical solutions <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib68" title="">2021</a>); Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib77" title="">2018</a>)</cite>,
and empirical evaluation thereof <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib78" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib79" title="">b</a>)</cite>.
In this section, we provide a representative sample of the work in this area,
directing the reader’s attention to the surveys by <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib15" title="">2021</a>); Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib80" title="">2022</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib81" title="">2024</a>)</cite>
for a more comprehensive overview.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Practical solutions and empirical evaluation</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Multiple authors have proposed, implemented, and tested novel algorithms
for performing <span class="ltx_ERROR undefined" id="S5.SS1.p1.1.1">\gls</span>abb:fl on the edge with non-<span class="ltx_ERROR undefined" id="S5.SS1.p1.1.2">\gls</span>abb:iid data.
Different surveys of the literature <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib15" title="">2021</a>); Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib80" title="">2022</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib81" title="">2024</a>)</cite>
introduced different categorizations of these methods.
Two recurring categories are data-based and algorithm-based methods,
corresponding roughly to preprocessing and in-processing methods in our taxonomy.
Both categories contain a variety of methods,
a subset of which we will discuss in this section.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Data-based methods</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">The motivating intuition behind data-based methods is that
modifying the local datasets to make them more homogeneous
will lead to better performance when training a global model.
Three main approaches to achieving this have been proposed:
data selection, data augmentation, and data selection <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib15" title="">2021</a>); Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib80" title="">2022</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S5.SS1.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Data sharing</h5>
<div class="ltx_para" id="S5.SS1.SSS1.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.Px1.p1.5"><cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib77" title="">2018</a>)</cite> observed that the accuracy of models
trained through <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px1.p1.5.1">\gls</span>abb:fl can decrease by up to <math alttext="55\%" class="ltx_Math" display="inline" id="S5.SS1.SSS1.Px1.p1.1.m1.1"><semantics id="S5.SS1.SSS1.Px1.p1.1.m1.1a"><mrow id="S5.SS1.SSS1.Px1.p1.1.m1.1.1" xref="S5.SS1.SSS1.Px1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.SSS1.Px1.p1.1.m1.1.1.2" xref="S5.SS1.SSS1.Px1.p1.1.m1.1.1.2.cmml">55</mn><mo id="S5.SS1.SSS1.Px1.p1.1.m1.1.1.1" xref="S5.SS1.SSS1.Px1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.Px1.p1.1.m1.1b"><apply id="S5.SS1.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS1.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.SS1.SSS1.Px1.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS1.SSS1.Px1.p1.1.m1.1.1.2">55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.Px1.p1.1.m1.1c">55\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.Px1.p1.1.m1.1d">55 %</annotation></semantics></math> if the data is not <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px1.p1.5.2">\gls</span>abb:iid.
To address this concern, they propose maintaining a small global shared dataset on the server,
a portion of which is shared with each edge device to augment their local datasets.
They find that a shared dataset as small as <math alttext="5\%" class="ltx_Math" display="inline" id="S5.SS1.SSS1.Px1.p1.2.m2.1"><semantics id="S5.SS1.SSS1.Px1.p1.2.m2.1a"><mrow id="S5.SS1.SSS1.Px1.p1.2.m2.1.1" xref="S5.SS1.SSS1.Px1.p1.2.m2.1.1.cmml"><mn id="S5.SS1.SSS1.Px1.p1.2.m2.1.1.2" xref="S5.SS1.SSS1.Px1.p1.2.m2.1.1.2.cmml">5</mn><mo id="S5.SS1.SSS1.Px1.p1.2.m2.1.1.1" xref="S5.SS1.SSS1.Px1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.Px1.p1.2.m2.1b"><apply id="S5.SS1.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.2.m2.1.1"><csymbol cd="latexml" id="S5.SS1.SSS1.Px1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.2.m2.1.1.1">percent</csymbol><cn id="S5.SS1.SSS1.Px1.p1.2.m2.1.1.2.cmml" type="integer" xref="S5.SS1.SSS1.Px1.p1.2.m2.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.Px1.p1.2.m2.1c">5\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.Px1.p1.2.m2.1d">5 %</annotation></semantics></math> of the total data
can improve the accuracy by as much as <math alttext="30\%" class="ltx_Math" display="inline" id="S5.SS1.SSS1.Px1.p1.3.m3.1"><semantics id="S5.SS1.SSS1.Px1.p1.3.m3.1a"><mrow id="S5.SS1.SSS1.Px1.p1.3.m3.1.1" xref="S5.SS1.SSS1.Px1.p1.3.m3.1.1.cmml"><mn id="S5.SS1.SSS1.Px1.p1.3.m3.1.1.2" xref="S5.SS1.SSS1.Px1.p1.3.m3.1.1.2.cmml">30</mn><mo id="S5.SS1.SSS1.Px1.p1.3.m3.1.1.1" xref="S5.SS1.SSS1.Px1.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.Px1.p1.3.m3.1b"><apply id="S5.SS1.SSS1.Px1.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.SS1.SSS1.Px1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.3.m3.1.1.1">percent</csymbol><cn id="S5.SS1.SSS1.Px1.p1.3.m3.1.1.2.cmml" type="integer" xref="S5.SS1.SSS1.Px1.p1.3.m3.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.Px1.p1.3.m3.1c">30\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.Px1.p1.3.m3.1d">30 %</annotation></semantics></math>.
Later work by <cite class="ltx_cite ltx_citemacro_citet">Yoshida et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib82" title="">2020</a>)</cite> combine this
approach with data selection to achieve <math alttext="13.5\%" class="ltx_Math" display="inline" id="S5.SS1.SSS1.Px1.p1.4.m4.1"><semantics id="S5.SS1.SSS1.Px1.p1.4.m4.1a"><mrow id="S5.SS1.SSS1.Px1.p1.4.m4.1.1" xref="S5.SS1.SSS1.Px1.p1.4.m4.1.1.cmml"><mn id="S5.SS1.SSS1.Px1.p1.4.m4.1.1.2" xref="S5.SS1.SSS1.Px1.p1.4.m4.1.1.2.cmml">13.5</mn><mo id="S5.SS1.SSS1.Px1.p1.4.m4.1.1.1" xref="S5.SS1.SSS1.Px1.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.Px1.p1.4.m4.1b"><apply id="S5.SS1.SSS1.Px1.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.4.m4.1.1"><csymbol cd="latexml" id="S5.SS1.SSS1.Px1.p1.4.m4.1.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.4.m4.1.1.1">percent</csymbol><cn id="S5.SS1.SSS1.Px1.p1.4.m4.1.1.2.cmml" type="float" xref="S5.SS1.SSS1.Px1.p1.4.m4.1.1.2">13.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.Px1.p1.4.m4.1c">13.5\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.Px1.p1.4.m4.1d">13.5 %</annotation></semantics></math> higher accuracy still.
<cite class="ltx_cite ltx_citemacro_citet">Tian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib83" title="">2021</a>)</cite> applied this approach
to asynchronous edge <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px1.p1.5.3">\gls</span>abb:fl using a shared dataset size of <math alttext="5-10\%" class="ltx_Math" display="inline" id="S5.SS1.SSS1.Px1.p1.5.m5.1"><semantics id="S5.SS1.SSS1.Px1.p1.5.m5.1a"><mrow id="S5.SS1.SSS1.Px1.p1.5.m5.1.1" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.cmml"><mn id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.2" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.2.cmml">5</mn><mo id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.1" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.1.cmml">−</mo><mrow id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.cmml"><mn id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.2" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.2.cmml">10</mn><mo id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.1" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.Px1.p1.5.m5.1b"><apply id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1"><minus id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.1.cmml" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.1"></minus><cn id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.2.cmml" type="integer" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.2">5</cn><apply id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.cmml" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3"><csymbol cd="latexml" id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.1.cmml" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.1">percent</csymbol><cn id="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.2.cmml" type="integer" xref="S5.SS1.SSS1.Px1.p1.5.m5.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.Px1.p1.5.m5.1c">5-10\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.Px1.p1.5.m5.1d">5 - 10 %</annotation></semantics></math>,
improving both the accuracy and the convergence speed of the model.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Data augmentation</h5>
<div class="ltx_para" id="S5.SS1.SSS1.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS1.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Abay et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib84" title="">2020</a>)</cite> tackle the problem of non-<span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px2.p1.1.1">\gls</span>abb:iid data
by augmenting the local datasets to match the global distribution.
More concretely, the server uses client-reported statistics on the label distribution
which it uses to coordinate the clients to generate augmentations for rare classes.
<cite class="ltx_cite ltx_citemacro_citet">Jeong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib85" title="">2023</a>)</cite>
on the other hand, propose an approach based on a <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px2.p1.1.2">\gls</span>abb:gan
trained by the server on shared data,
which it distributes to the clients for local data augmentation.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Data selection</h5>
<div class="ltx_para" id="S5.SS1.SSS1.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS1.Px3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Rai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib86" title="">2022</a>)</cite> propose a client selection algorithm
based on a single metric called the <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.Px3.p1.1.1">irrelevance score</em>, which measures,
among other things, deviation from being <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px3.p1.1.2">\gls</span>abb:iid.
<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib87" title="">2020</a>)</cite> on the other hand,
propose a <math alttext="q-" class="ltx_Math" display="inline" id="S5.SS1.SSS1.Px3.p1.1.m1.1"><semantics id="S5.SS1.SSS1.Px3.p1.1.m1.1a"><mrow id="S5.SS1.SSS1.Px3.p1.1.m1.1.1" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS1.Px3.p1.1.m1.1.1.2" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1.2.cmml">q</mi><mo id="S5.SS1.SSS1.Px3.p1.1.m1.1.1.3" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.Px3.p1.1.m1.1b"><apply id="S5.SS1.SSS1.Px3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS1.Px3.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1">limit-from</csymbol><ci id="S5.SS1.SSS1.Px3.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1.2">𝑞</ci><minus id="S5.SS1.SSS1.Px3.p1.1.m1.1.1.3.cmml" xref="S5.SS1.SSS1.Px3.p1.1.m1.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.Px3.p1.1.m1.1c">q-</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.Px3.p1.1.m1.1d">italic_q -</annotation></semantics></math>learning based client selection approach to increase convergence speed
with non-<span class="ltx_ERROR undefined" id="S5.SS1.SSS1.Px3.p1.1.3">\gls</span>abb:iid data.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Algorithm-based methods</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">Algorithm-based methods are in-processing methods that amend the training algorithm
to make it more robust to non-<span class="ltx_ERROR undefined" id="S5.SS1.SSS2.p1.1.1">\gls</span>abb:iid data.
Due to the complex and multi-component nature of the <span class="ltx_ERROR undefined" id="S5.SS1.SSS2.p1.1.2">\gls</span>abb:fl training process,
these methods are more varied and technically sophisticated than data-based methods.</p>
</div>
<section class="ltx_paragraph" id="S5.SS1.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Meta-learning</h5>
<div class="ltx_para" id="S5.SS1.SSS2.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS2.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib88" title="">2023</a>)</cite> propose a model agnostic meta-learning approach <cite class="ltx_cite ltx_citemacro_citet">Finn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib89" title="">2017</a>)</cite>
to simultaneously improve personalization and convergence speed.
Another work by <cite class="ltx_cite ltx_citemacro_citet">Li and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib90" title="">2022</a>)</cite>
applies meta-learning to spatial and temporal data which is innately non-<span class="ltx_ERROR undefined" id="S5.SS1.SSS2.Px1.p1.1.1">\gls</span>abb:iid.
In a different vein, <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib91" title="">2021</a>)</cite>
propose a meta-algorithm based on the primal-dual algorithm.
Their method produces strong convergence guarantees
even with non-<span class="ltx_ERROR undefined" id="S5.SS1.SSS2.Px1.p1.1.2">\gls</span>abb:iid data and non-convex objectives.
Furthermore, it achieves optimal communication efficiency,
requiring only <math alttext="\bigO(1)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.Px1.p1.1.m1.1"><semantics id="S5.SS1.SSS2.Px1.p1.1.m1.1a"><mrow id="S5.SS1.SSS2.Px1.p1.1.m1.1.2" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.cmml"><merror class="ltx_ERROR undefined undefined" id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2b.cmml"><mtext id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2a" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2b.cmml">\bigO</mtext></merror><mo id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.1" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.3.2" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.cmml"><mo id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.cmml">(</mo><mn id="S5.SS1.SSS2.Px1.p1.1.m1.1.1" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.1.cmml">1</mn><mo id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.Px1.p1.1.m1.1b"><apply id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.cmml" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2"><times id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.1.cmml" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.1"></times><ci id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2b.cmml" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2"><merror class="ltx_ERROR undefined undefined" id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2.cmml" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2"><mtext id="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2a.cmml" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.2.2">\bigO</mtext></merror></ci><cn id="S5.SS1.SSS2.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS1.SSS2.Px1.p1.1.m1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.Px1.p1.1.m1.1c">\bigO(1)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.Px1.p1.1.m1.1d">( 1 )</annotation></semantics></math> communication rounds in the <span class="ltx_ERROR undefined" id="S5.SS1.SSS2.Px1.p1.1.3">\gls</span>abb:iid case.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Multitask learning</h5>
<div class="ltx_para" id="S5.SS1.SSS2.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.Px2.p1.1">Personalization can be cast as a multitask learning problem <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib15" title="">2021</a>)</cite>.
Works that have addressed <span class="ltx_ERROR undefined" id="S5.SS1.SSS2.Px2.p1.1.1">\gls</span>abb:fl on the edge with non-<span class="ltx_ERROR undefined" id="S5.SS1.SSS2.Px2.p1.1.2">\gls</span>abb:iid data
from this perspective include <cite class="ltx_cite ltx_citemacro_cite">Smith et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib92" title="">2017</a>)</cite>,
which considers each edge device as a separate task,
<cite class="ltx_cite ltx_citemacro_cite">Corinzia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib93" title="">2021</a>)</cite>,
which treats the edge system as a Bayesian network,
to handle strong <span class="ltx_ERROR undefined" id="S5.SS1.SSS2.Px2.p1.1.3">\gls</span>abb:iid violations,
and <cite class="ltx_cite ltx_citemacro_cite">Sattler et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib94" title="">2021</a>)</cite>,
which leverages the geometry of the loss function to
combine subsets of clients into clusters with better overall distributions.</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Theoretical analysis</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The majority of literature on theoretical <span class="ltx_ERROR undefined" id="S5.SS2.p1.1.1">\gls</span>abb:fl with non-<span class="ltx_ERROR undefined" id="S5.SS2.p1.1.2">\gls</span>abb:iid
data focuses on convergence.
For example, <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib69" title="">2020</a>)</cite>
prove convergence theorems and rates for <span class="ltx_ERROR undefined" id="S5.SS2.p1.1.3">\gls</span>abb:fedavg with non-<span class="ltx_ERROR undefined" id="S5.SS2.p1.1.4">\gls</span>abb:iid data
under certain conditions on the smoothness and convexity of the loss function,
and the boundedness of the gradients.
<cite class="ltx_cite ltx_citemacro_citet">Lee (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib76" title="">2023</a>)</cite> also provide convergence guarantees
for federated regression assuming similar rather than identical local distributions.</p>
</div>
</section>
</section>
<section class="ltx_section ltx_centering" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Label noise</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Label noise, or <em class="ltx_emph ltx_font_italic" id="S6.p1.1.1">labeling error</em>, is a term used to qualify
any situation where the label present in a dataset is different from the target <cite class="ltx_cite ltx_citemacro_cite">Frenay and Verleysen (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib95" title="">2014</a>)</cite>.
This can be due to human error,
communication and storage defects <cite class="ltx_cite ltx_citemacro_cite">Baccour et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib96" title="">2022</a>)</cite>
(very common on the edge),
and deliberate mislabeling <cite class="ltx_cite ltx_citemacro_cite">Frenay and Verleysen (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib95" title="">2014</a>); Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib97" title="">2023</a>)</cite>.
It is not difficult to see how the presence of noise can be problematic,
particularly for highly expressive models such as <span class="ltx_ERROR undefined" id="S6.p1.1.2">\glspl</span>abb:dnn,
which are susceptible to overfitting.</p>
</div>
</section>
<section class="ltx_section ltx_centering" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Fairness</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Fairness is a critical ethical consideration in the design
of any decision-making process (automated or otherwise) that affects humans.
In the context of edge <span class="ltx_ERROR undefined" id="S7.p1.1.1">\gls</span>abb:fl,
we can distinguish between two types of fairness <cite class="ltx_cite ltx_citemacro_cite">Vucinich and Zhu (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib127" title="">2023</a>)</cite>,
broadly corresponding to the traditional notions
of <em class="ltx_emph ltx_font_italic" id="S7.p1.1.2">outcome fairness</em> and <em class="ltx_emph ltx_font_italic" id="S7.p1.1.3">process fairness</em> <cite class="ltx_cite ltx_citemacro_cite">Grgić-Hlača et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib128" title="">2018</a>)</cite>
from the literature on algorithmic fairness.
We refer to them as social fairness and cooperative fairness, respectively.
The latter is of particular interest in the context of <span class="ltx_ERROR undefined" id="S7.p1.1.4">\gls</span>abb:fl,
given its procedural divergence from traditional <span class="ltx_ERROR undefined" id="S7.p1.1.5">\gls</span>abb:ml.
While social fairness is concerned with the model making fair predictions,
cooperative fairness is concerned with the training process producing a fair model.</p>
</div>
</section>
<section class="ltx_section ltx_centering" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Privacy protection</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">Privacy is one of the main selling points of <span class="ltx_ERROR undefined" id="S8.p1.1.1">\gls</span>abb:fl.
By abolishing the need to share data, conventional wisdom says,
<span class="ltx_ERROR undefined" id="S8.p1.1.2">\gls</span>abb:fl guarantees data privacy.
However, this guarantee rings hollow in the face of numerous privacy attacks <cite class="ltx_cite ltx_citemacro_cite">Carlini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib154" title="">2021</a>); Pasquini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib155" title="">2022</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib156" title="">2023</a>); Balle et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib157" title="">2022</a>)</cite>.
While it is true that <span class="ltx_ERROR undefined" id="S8.p1.1.3">\gls</span>abb:fl blocks traditional avenues of data theft
that rely on compromising a central server or intercepting data in transit,
it leaves open other attack angles that rely on what is shared:
model updates, the final model parameters, or, failing that, the model’s predictions <cite class="ltx_cite ltx_citemacro_cite">Shokri et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib158" title="">2017</a>); Carlini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib154" title="">2021</a>)</cite>.
This state of affairs jeopardizes the privacy of individuals
whose data is used in edge <span class="ltx_ERROR undefined" id="S8.p1.1.4">\gls</span>abb:fl systems,
and poses significant ethical and legal risks
to the organizations that deploy them <cite class="ltx_cite ltx_citemacro_cite">Truong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib14" title="">2021</a>)</cite>.
In this section, we explore privacy threats to edge <span class="ltx_ERROR undefined" id="S8.p1.1.5">\gls</span>abb:fl,
proposed defenses, and their limitations.</p>
</div>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1 </span>What models reveal about their training data</h3>
<div class="ltx_para" id="S8.SS1.p1">
<p class="ltx_p" id="S8.SS1.p1.1">The thesis that <span class="ltx_ERROR undefined" id="S8.SS1.p1.1.1">\gls</span>abb:fl guarantees privacy is based on
the simplistic assumption that data is private unless explicitly shared,
a consequence of which is that sharing a model trained on data does not compromise its privacy.
This assumption is patently false, as the model’s parameters contain —at the very least—
information on the data distribution, otherwise the model would not be useful.
The relevant question is therefore not whether the model contains private information,
but rather

<span class="ltx_inline-enumerate" id="S8.I1">
<span class="ltx_inline-item" id="S8.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(a)</span> <span class="ltx_text" id="S8.I1.i1.1">how much information it contains,
</span></span>
<span class="ltx_inline-item" id="S8.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(b)</span> <span class="ltx_text" id="S8.I1.i2.1">and how much of that information can be extracted.
</span></span>
</span></p>
</div>
<div class="ltx_para" id="S8.SS1.p2">
<p class="ltx_p" id="S8.SS1.p2.1">Even this view, however, underestimates models’ information leakage.
While classical <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.1">\gls</span>abb:ml wisdom, embodied by the bias-variance trade-off,
dictates that <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.2">\glspl</span>abb:nn must have as many parameters as necessary
to fit training data, but no more to avoid overfitting,
recent research has shown that they can be largely overparameterized,
yet have excellent generalization performance.
In fact, a neural network with zero empirical risk
(i.e., one that interpolates training data)
can have lower risk than one that slightly underfits the data <cite class="ltx_cite ltx_citemacro_cite">Belkin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib159" title="">2019</a>); Belkin (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib160" title="">2021</a>)</cite>.
Due to this phenomenon, usually referred to as <em class="ltx_emph ltx_font_italic" id="S8.SS1.p2.1.3">double descent</em>,
large modern <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.4">\glspl</span>abb:dnn tend to operate in the so-called <em class="ltx_emph ltx_font_italic" id="S8.SS1.p2.1.5">interpolation regime</em>.
That is to say, not only do <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.6">\glspl</span>abb:nn contain information about the training data,
in many cases, they contain <em class="ltx_emph ltx_font_italic" id="S8.SS1.p2.1.7">all</em> the information about it.
This implies a worst-case answer to question <a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S8.I1.i1" title="item (a) ‣ 8.1 What models reveal about their training data ‣ 8 Privacy protection ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_tag">(a)</span></a>,
leaving question <a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#S8.I1.i2" title="item (b) ‣ 8.1 What models reveal about their training data ‣ 8 Privacy protection ‣ Notations and conventions ‣ 2 Background ‣ Data Quality in Edge Machine Learning: A State-of-the-Art Survey"><span class="ltx_text ltx_ref_tag">(b)</span></a>
as the only hope for defending the privacy of <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.8">\gls</span>abb:fl.
Unfortunately, the answer to this question is also pessimistic.
As we demonstrate in <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.9">\Cref</span>sub:privacy:attacks,
it is possible to extract a significant amount of information about the training data
from surprisingly little information about the model <cite class="ltx_cite ltx_citemacro_cite">Jere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib10" title="">2021</a>); Rodríguez-Barroso et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib21" title="">2023</a>)</cite>.
Vanilla <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.10">\gls</span>abb:fl is in this sense no more private than centralized <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.11">\gls</span>abb:ml.
As such, modifications to <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.12">\gls</span>abb:fl are necessary to ensure privacy.</p>
</div>
<section class="ltx_subsubsection" id="S8.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.1 </span>Limitations of encryption-based defenses</h4>
<div class="ltx_para" id="S8.SS1.SSS1.p1">
<p class="ltx_p" id="S8.SS1.SSS1.p1.1">Perturbation-based privacy-preserving edge <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p1.1.1">\gls</span>abb:fl
suffers from an inherent trade-off between privacy and accuracy <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib191" title="">2021</a>)</cite>.
Encryption-based defenses, on the other hand, appear to have no such trade-off
because they preserve <math alttext="100\%" class="ltx_Math" display="inline" id="S8.SS1.SSS1.p1.1.m1.1"><semantics id="S8.SS1.SSS1.p1.1.m1.1a"><mrow id="S8.SS1.SSS1.p1.1.m1.1.1" xref="S8.SS1.SSS1.p1.1.m1.1.1.cmml"><mn id="S8.SS1.SSS1.p1.1.m1.1.1.2" xref="S8.SS1.SSS1.p1.1.m1.1.1.2.cmml">100</mn><mo id="S8.SS1.SSS1.p1.1.m1.1.1.1" xref="S8.SS1.SSS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.SS1.SSS1.p1.1.m1.1b"><apply id="S8.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S8.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S8.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S8.SS1.SSS1.p1.1.m1.1.1.1">percent</csymbol><cn id="S8.SS1.SSS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S8.SS1.SSS1.p1.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS1.SSS1.p1.1.m1.1c">100\%</annotation><annotation encoding="application/x-llamapun" id="S8.SS1.SSS1.p1.1.m1.1d">100 %</annotation></semantics></math> of the transmitted information.
From this observation, two conclusions can be drawn.
Either

<span class="ltx_inline-enumerate" id="S8.I2">
<span class="ltx_inline-item" id="S8.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(1)</span> <span class="ltx_text" id="S8.I2.i1.1">encryption-based defenses are inherently superior to perturbation-based defenses, or
</span></span>
<span class="ltx_inline-item" id="S8.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(2)</span> <span class="ltx_text" id="S8.I2.i2.1">encryption-based defenses are not as effective as they appear.
</span></span>
</span></p>
</div>
<div class="ltx_para" id="S8.SS1.SSS1.p2">
<p class="ltx_p" id="S8.SS1.SSS1.p2.1">In the case of <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.1">\gls</span>abb:he, the latter conclusion is more likely.
As a matter of fact, the model learned by the server under <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.2">\gls</span>abb:he
is theoretically identical to the one learned under vanilla <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.3">\gls</span>abb:fl.
The only difference is that individual updates are not shared.
This implies that all the black-box attacks enumerated in <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.4">\Cref</span>sub:privacy:attacks,
as well as the attacks on the final model parameters,
are still possible against an edge <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.5">\gls</span>abb:fl system secured with <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.6">\gls</span>abb:he.
As for <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.7">\gls</span>abb:smc, successful attacks against secure aggregation
have been demonstrated in the literature <cite class="ltx_cite ltx_citemacro_cite">Pasquini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib155" title="">2022</a>)</cite>,
supporting the second conclusion in this case as well.
This pessimistic analysis is made rigorous by <cite class="ltx_cite ltx_citemacro_cite">El-Mhamdi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib192" title="">2023</a>)</cite>,
where the authors prove the existence of a trade-off
between model accuracy and differential privacy,
which becomes less favorable as the heterogeneity of the data increases.
As a result, the <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p2.1.8">only</em> way to ensure <span class="ltx_ERROR undefined" id="S8.SS1.SSS1.p2.1.9">\gls</span>abb:dp,
is to sacrifice model accuracy.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section ltx_centering" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Reputation, trust, and security</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">As established in <span class="ltx_ERROR undefined" id="S9.p1.1.1">\Cref</span>sec:data_quality, rather than being an intrinsic property of the data,
<span class="ltx_ERROR undefined" id="S9.p1.1.2">\gls</span>abb:dq is strongly dependent on extrinsic and contextual factors.
Having introduced two such factors,
namely fairness and privacy in <span class="ltx_ERROR undefined" id="S9.p1.1.3">\Cref</span>sec:fairness,sec:privacy,
we now turn our attention to a third one: trustworthiness.
Instead of being a property of the data,
trustworthiness is a property of the data <em class="ltx_emph ltx_font_italic" id="S9.p1.1.4">source</em>,
it allows for different treatments of identical data points depending on their provenance.
Despite the extrinsic nature of trustworthiness,
it is a ubiquitous dimension in the <span class="ltx_ERROR undefined" id="S9.p1.1.5">\gls</span>abb:dq literature <cite class="ltx_cite ltx_citemacro_cite">Restuccia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib193" title="">2017</a>); Hassenstein and Vanella (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib6" title="">2022</a>); Wang and Strong (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib194" title="">1996</a>); Sidi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib8" title="">2012</a>)</cite>.
It is even more salient for <span class="ltx_ERROR undefined" id="S9.p1.1.6">\gls</span>abb:fl on the edge,
where the data is private, and the clients are potentially anonymous.
This section is dedicated to the study of untrusted clients in <span class="ltx_ERROR undefined" id="S9.p1.1.7">\gls</span>abb:fl
(also known as <em class="ltx_emph ltx_font_italic" id="S9.p1.1.8">Byzantine clients</em> for reasons that will become clear),
and the defenses that can be deployed against them.</p>
</div>
<section class="ltx_subsubsection" id="S9.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">9.0.1 </span>Impossibility results</h4>
<div class="ltx_para" id="S9.SS0.SSS1.p1">
<p class="ltx_p" id="S9.SS0.SSS1.p1.1">Despite the plethora of defense strategies we have enumerated
(which represent a vanishingly small fraction of the literature),
the problem of ensuring Byzantine fault tolerance on the edge is far from solved.
<cite class="ltx_cite ltx_citemacro_citet">El-Mhamdi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib192" title="">2023</a>)</cite> have shown that securing <span class="ltx_ERROR undefined" id="S9.SS0.SSS1.p1.1.1">\gls</span>abb:fl
against poisoning attacks is impossible if the datasets of honest clients are heterogeneous.
They manage this by leveraging an equivalence result between robust mean estimation
and robust <span class="ltx_ERROR undefined" id="S9.SS0.SSS1.p1.1.2">\gls</span>abb:fl <cite class="ltx_cite ltx_citemacro_cite">El-Mhamdi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib203" title="">2021</a>)</cite>,
which they combine with a proof of impossibility for robust mean estimation to conclude.
Given existing results on the possibility of Byzantine-robust <span class="ltx_ERROR undefined" id="S9.SS0.SSS1.p1.1.3">\gls</span>abb:fl
with homogeneous honest clients <cite class="ltx_cite ltx_citemacro_cite">Karimireddy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib226" title="">2021</a>); El-Mhamdi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib203" title="">2021</a>)</cite>,
<cite class="ltx_cite ltx_citemacro_citet">El-Mhamdi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib192" title="">2023</a>)</cite> conclude that heterogeneity is the key obstacle.</p>
</div>
</section>
</section>
<section class="ltx_section ltx_centering" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Conclusion and future research directions</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">In this survey, we discussed the problems data can pose for <span class="ltx_ERROR undefined" id="S10.p1.1.1">\gls</span>abb:ml on the edge.
Starting with a general formulation of the learning problem in terms of <span class="ltx_ERROR undefined" id="S10.p1.1.2">\gls</span>abb:erm
and <span class="ltx_ERROR undefined" id="S10.p1.1.3">\gls</span>abb:ferm, we introduced a characterization of data quality in terms of
six dimensions justified by the statistical properties
of the learning problem and social/ethical considerations.
For each of these dimensions, we discussed, to the extent literature permits,
the challenges they pose, the methods to address them, and the limitations of these methods.
In doing this, we remained focused on the specific challenges
that arise in the context of <span class="ltx_ERROR undefined" id="S10.p1.1.4">\gls</span>abb:fl on the edge
and the solutions that are tailored to this context.
We conclude by discussing some open problems and potential avenues for future exploration.</p>
</div>
<section class="ltx_subsection" id="S10.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">10.1 </span>Directions for further research</h3>
<div class="ltx_para" id="S10.SS1.p1">
<p class="ltx_p" id="S10.SS1.p1.1">Multiple <span class="ltx_ERROR undefined" id="S10.SS1.p1.1.1">\gls</span>abb:dq-related questions remain unanswered,
even more so in the context of <span class="ltx_ERROR undefined" id="S10.SS1.p1.1.2">\gls</span>abb:fl.
These include:</p>
<ol class="ltx_enumerate" id="S10.I1">
<li class="ltx_item" id="S10.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S10.I1.i1.p1">
<p class="ltx_p" id="S10.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S10.I1.i1.p1.1.1">Other data quality considerations.</span>
The list of dimensions discussed in this survey is not exhaustive.
This is particularly true of extrinsic dimensions
but is also true of intrinsic dimensions,
which can be subdivided into more specific categories.
Examples of subtleties that have not been discussed include:</p>
<ol class="ltx_enumerate" id="S10.I1.i1.I1">
<li class="ltx_item" id="S10.I1.i1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span>
<div class="ltx_para" id="S10.I1.i1.I1.i1.p1">
<p class="ltx_p" id="S10.I1.i1.I1.i1.p1.1">Shortcuts <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib227" title="">2023</a>); Geirhos et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib228" title="">2020</a>)</cite>,
a special form of bias in the conditional distribution.</p>
</div>
</li>
<li class="ltx_item" id="S10.I1.i1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span>
<div class="ltx_para" id="S10.I1.i1.I1.i2.p1">
<p class="ltx_p" id="S10.I1.i1.I1.i2.p1.1">Temporal and spatial dependencies <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib229" title="">2023</a>); Li and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib90" title="">2022</a>)</cite>, which often lead to dependent and attribute skewed data.</p>
</div>
</li>
<li class="ltx_item" id="S10.I1.i1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span>
<div class="ltx_para" id="S10.I1.i1.I1.i3.p1">
<p class="ltx_p" id="S10.I1.i1.I1.i3.p1.1">Missing data <cite class="ltx_cite ltx_citemacro_cite">Guastella et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib230" title="">2021</a>); You et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib56" title="">2020</a>)</cite>,
which can reduce the effective sample size and introduce bias.</p>
</div>
</li>
<li class="ltx_item" id="S10.I1.i1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span>
<div class="ltx_para" id="S10.I1.i1.I1.i4.p1">
<p class="ltx_p" id="S10.I1.i1.I1.i4.p1.1">The interplay between <span class="ltx_ERROR undefined" id="S10.I1.i1.I1.i4.p1.1.1">\gls</span>abb:dq dimensions.
The dimensions discussed in this survey are not orthogonal.
Many of them are correlated, while others are in conflict,
and it is not always clear which is the case.
For example, some works suggest that differential privacy
and social fairness are equivalent <cite class="ltx_cite ltx_citemacro_cite">Dwork et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib136" title="">2012</a>)</cite>,
while others find a trade-off between them <cite class="ltx_cite ltx_citemacro_cite">Rafi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib28" title="">2024</a>)</cite>.
Other dimensions that can be related include:
cooperative fairness, noise resilience, and Byzantine fault tolerance.</p>
</div>
</li>
</ol>
</div>
</li>
<li class="ltx_item" id="S10.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S10.I1.i2.p1">
<p class="ltx_p" id="S10.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S10.I1.i2.p1.1.1">Understanding the effect of data quality on the learning process.</span>
While <span class="ltx_ERROR undefined" id="S10.I1.i2.p1.1.2">\gls</span>abb:dq’s influence on the learning process
is both intuitive and empirically validated, it is not yet well understood.
Despite attempts to rigorously study it both theoretically <cite class="ltx_cite ltx_citemacro_cite">Izzo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib231" title="">2023</a>)</cite>
and experimentally <cite class="ltx_cite ltx_citemacro_cite">Qi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib232" title="">2021</a>)</cite>,
a unified theory of data quality does not yet exist for <span class="ltx_ERROR undefined" id="S10.I1.i2.p1.1.3">\gls</span>abb:ml,
let alone for <span class="ltx_ERROR undefined" id="S10.I1.i2.p1.1.4">\gls</span>abb:fl.
Characterizing the relationship between data
and different aspects of the learning process
such as the loss landscape, convergence and convergence rate,
quality of the local minima, and generalization error,
as well as the changes this relationship undergoes in the distributed setting,
is an important, fertile, and largely underexplored area of research.
If pursued, this line of research has the potential to facilitate
the establishment of universally accepted definitions of data quality,
and motivate sound practices for its assessment and improvement.</p>
</div>
</li>
<li class="ltx_item" id="S10.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S10.I1.i3.p1">
<span class="ltx_ERROR undefined" id="S10.I1.i3.p1.1">\gls</span>
<p class="ltx_p" id="S10.I1.i3.p1.2"><span class="ltx_text ltx_font_bold" id="S10.I1.i3.p1.2.1">abb:dq-robust learning algorithms.</span>
Most existing methods for addressing <span class="ltx_ERROR undefined" id="S10.I1.i3.p1.2.2">\gls</span>abb:dq issues rely on in-processing.
This trend is likely to continue in the future,
as learning algorithms are the most complex, sophisticated, and flexible
components of the <span class="ltx_ERROR undefined" id="S10.I1.i3.p1.2.3">\gls</span>abb:ml pipeline.
While researchers exert very little control over the data collection process,
the learning algorithm is completely under their control.
Focusing on this component is also motivated by our observation of biological learning,
which can extract useful models from noisy, biased, dependent, and untrusted data.
Problems that lie in this space include <span class="ltx_ERROR undefined" id="S10.I1.i3.p1.2.4">\gls</span>abb:ood,
where methods like <span class="ltx_ERROR undefined" id="S10.I1.i3.p1.2.5">\gls</span>abb:dro and <span class="ltx_ERROR undefined" id="S10.I1.i3.p1.2.6">\gls</span>abb:irm have already been proposed
 <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.02600v1#bib.bib233" title="">2022</a>)</cite>, algorithmic robustness,
and algorithmic stability.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_bibliography ltx_centering" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Murshed et al. (2022)</span>
<span class="ltx_bibblock">
M. G. S. Murshed, C. Murphy, D. Hou, N. Khan, G. Ananthanarayanan, F. Hussain,

</span>
<span class="ltx_bibblock">Machine Learning at the Network Edge: A Survey,

</span>
<span class="ltx_bibblock">ACM Computing Surveys 54 (2022) 1–37. <span class="ltx_text ltx_font_typewriter" id="bib.bib1.1.1">arXiv:1908.00080</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh and Gill (2023)</span>
<span class="ltx_bibblock">
R. Singh, S. S. Gill,

</span>
<span class="ltx_bibblock">Edge AI: A survey,

</span>
<span class="ltx_bibblock">Internet of Things and Cyber-Physical Systems 3 (2023) 71–92.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence, Springer, Singapore, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taik et al. (2021)</span>
<span class="ltx_bibblock">
A. Taik, H. Moudoud, S. Cherkaoui,

</span>
<span class="ltx_bibblock">Data-Quality Based Scheduling for Federated Edge Learning,

</span>
<span class="ltx_bibblock">in: 2021 IEEE 46th Conference on Local Computer Networks (LCN), 2021, pp. 17–23. <span class="ltx_text ltx_font_typewriter" id="bib.bib4.1.1">arXiv:2201.11247</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mahanti (2019)</span>
<span class="ltx_bibblock">
R. Mahanti, Data Quality: Dimensions, Measurement, Strategy, Management, and Governance, ASQ Quality Press, Milwaukee, Wisconsin, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hassenstein and Vanella (2022)</span>
<span class="ltx_bibblock">
M. J. Hassenstein, P. Vanella,

</span>
<span class="ltx_bibblock">Data Quality—Concepts and Problems,

</span>
<span class="ltx_bibblock">Encyclopedia 2 (2022) 498–510.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Camacho et al. (2023)</span>
<span class="ltx_bibblock">
J. Camacho, K. Wasielewska, P. Espinosa, M. Fuentes-García,

</span>
<span class="ltx_bibblock">Quality In / Quality Out: Data quality more relevant than model choice in anomaly detection with the UGR’16,

</span>
<span class="ltx_bibblock">in: NOMS 2023-2023 IEEE/IFIP Network Operations and  Management Symposium, 2023, pp. 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sidi et al. (2012)</span>
<span class="ltx_bibblock">
F. Sidi, P. H. Shariat Panahy, L. S. Affendey, M. A. Jabar, H. Ibrahim, A. Mustapha,

</span>
<span class="ltx_bibblock">Data quality: A survey of data quality dimensions,

</span>
<span class="ltx_bibblock">in: 2012 International Conference on Information Retrieval &amp; Knowledge Management, 2012, pp. 300–304.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2021)</span>
<span class="ltx_bibblock">
B. Han, Q. Yao, T. Liu, G. Niu, I. W. Tsang, J. T. Kwok, M. Sugiyama, A Survey of Label-noise Representation Learning: Past,  Present and Future, 2021. <span class="ltx_text ltx_font_typewriter" id="bib.bib9.1.1">arXiv:2011.04406</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jere et al. (2021)</span>
<span class="ltx_bibblock">
M. S. Jere, T. Farnan, F. Koushanfar,

</span>
<span class="ltx_bibblock">A Taxonomy of Attacks on Federated Learning,

</span>
<span class="ltx_bibblock">IEEE Security &amp; Privacy 19 (2021) 20–28.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2021)</span>
<span class="ltx_bibblock">
Q. Xia, W. Ye, Z. Tao, J. Wu, Q. Li,

</span>
<span class="ltx_bibblock">A survey of federated learning for edge computing: Research problems and solutions,

</span>
<span class="ltx_bibblock">High-Confidence Computing 1 (2021) 100008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2021)</span>
<span class="ltx_bibblock">
X. Yin, Y. Zhu, J. Hu,

</span>
<span class="ltx_bibblock">A Comprehensive Survey of Privacy-preserving Federated Learning : A Taxonomy, Review, and Future Directions,

</span>
<span class="ltx_bibblock">ACM Computing Surveys 54 (2021) 131:1–131:36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferraguig et al. (2021)</span>
<span class="ltx_bibblock">
L. Ferraguig, Y. Djebrouni, S. Bouchenak, V. Marangozova,

</span>
<span class="ltx_bibblock">Survey of Bias Mitigation in Federated Learning,

</span>
<span class="ltx_bibblock">in: Conférence Francophone d’informatique En Parallélisme , Architecture et Système, Lyon (virtuel), France, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truong et al. (2021)</span>
<span class="ltx_bibblock">
N. Truong, K. Sun, S. Wang, F. Guitton, Y. Guo,

</span>
<span class="ltx_bibblock">Privacy preservation in federated learning: An insightful survey from the GDPR perspective,

</span>
<span class="ltx_bibblock">Computers &amp; Security 110 (2021) 102402.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
H. Zhu, J. Xu, S. Liu, Y. Jin,

</span>
<span class="ltx_bibblock">Federated learning on non-IID data: A survey,

</span>
<span class="ltx_bibblock">Neurocomputing 465 (2021) 371–390.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abreha et al. (2022)</span>
<span class="ltx_bibblock">
H. G. Abreha, M. Hayajneh, M. A. Serhani,

</span>
<span class="ltx_bibblock">Federated Learning in Edge Computing: A Systematic Survey,

</span>
<span class="ltx_bibblock">Sensors 22 (2022) 450.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
P. Liu, X. Xu, W. Wang,

</span>
<span class="ltx_bibblock">Threats, attacks and defenses to federated learning: Issues, taxonomy and perspectives,

</span>
<span class="ltx_bibblock">Cybersecurity 5 (2022) 4.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrabi et al. (2022)</span>
<span class="ltx_bibblock">
N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, A. Galstyan,

</span>
<span class="ltx_bibblock">A Survey on Bias and Fairness in Machine Learning,

</span>
<span class="ltx_bibblock">ACM Computing Surveys 54 (2022) 1–35.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2023)</span>
<span class="ltx_bibblock">
G. Xia, J. Chen, C. Yu, J. Ma,

</span>
<span class="ltx_bibblock">Poisoning Attacks in Federated Learning: A Survey,

</span>
<span class="ltx_bibblock">IEEE Access 11 (2023) 10708–10722.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2022)</span>
<span class="ltx_bibblock">
J. Shi, W. Wan, S. Hu, J. Lu, L. Yu Zhang,

</span>
<span class="ltx_bibblock">Challenges and Approaches for Mitigating Byzantine Attacks in Federated Learning,

</span>
<span class="ltx_bibblock">in: 2022 IEEE International Conference on Trust, Security and Privacy in Computing and Communications ( TrustCom), 2022, pp. 139–146.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rodríguez-Barroso et al. (2023)</span>
<span class="ltx_bibblock">
N. Rodríguez-Barroso, D. Jiménez-López, M. V. Luzón, F. Herrera, E. Martínez-C ámara,

</span>
<span class="ltx_bibblock">Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges,

</span>
<span class="ltx_bibblock">Information Fusion 90 (2023) 148–173.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abyane et al. (2023)</span>
<span class="ltx_bibblock">
A. E. Abyane, D. Zhu, R. Souza, L. Ma, H. Hemmati,

</span>
<span class="ltx_bibblock">Towards understanding quality challenges of the federated learning for neural networks: A first look from the lens of robustness,

</span>
<span class="ltx_bibblock">Empirical Software Engineering 28 (2023) 44.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whang et al. (2023)</span>
<span class="ltx_bibblock">
S. E. Whang, Y. Roh, H. Song, J.-G. Lee,

</span>
<span class="ltx_bibblock">Data collection and quality challenges in deep learning: A data-centric AI perspective,

</span>
<span class="ltx_bibblock">The VLDB Journal 32 (2023) 791–813.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallegos et al. (2023)</span>
<span class="ltx_bibblock">
I. O. Gallegos, R. A. Rossi, J. Barrow, M. M. Tanjim, S. Kim, F. Dernoncourt, T. Yu, R. Zhang, N. K. Ahmed, Bias and Fairness in Large Language Models: A Survey, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib24.1.1">arXiv:2309.00770</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2023)</span>
<span class="ltx_bibblock">
N. Lee, Y. Bang, H. Lovenia, S. Cahyawijaya, W. Dai, P. Fung, Survey of Social Bias in Vision-Language Models, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib25.1.1">arXiv:2309.14381</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al. (2023)</span>
<span class="ltx_bibblock">
Y. Gong, G. Liu, Y. Xue, R. Li, L. Meng,

</span>
<span class="ltx_bibblock">A survey on dataset quality in machine learning,

</span>
<span class="ltx_bibblock">Information and Software Technology 162 (2023) 107268.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
J. Wang, A. Pal, Q. Yang, K. Kant, K. Zhu, S. Guo,

</span>
<span class="ltx_bibblock">Collaborative Machine Learning: Schemes, Robustness, and Privacy,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems 34 (2023) 9625–9642.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafi et al. (2024)</span>
<span class="ltx_bibblock">
T. H. Rafi, F. A. Noor, T. Hussain, D.-K. Chae,

</span>
<span class="ltx_bibblock">Fairness and privacy preserving in federated learning: A survey,

</span>
<span class="ltx_bibblock">Information Fusion 105 (2024) 102198.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sánchez Sánchez et al. (2024)</span>
<span class="ltx_bibblock">
P. M. Sánchez Sánchez, A. Huertas Celdrán, N. Xie, G. Bovet, G. Martínez Pérez, B. Stiller,

</span>
<span class="ltx_bibblock">FederatedTrust: A solution for trustworthy federated learning,

</span>
<span class="ltx_bibblock">Future Generation Computer Systems 152 (2024) 83–98.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al. (2019)</span>
<span class="ltx_bibblock">
Z. Gong, P. Zhong, W. Hu,

</span>
<span class="ltx_bibblock">Diversity in Machine Learning,

</span>
<span class="ltx_bibblock">IEEE Access 7 (2019) 64323–64350.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karkouch et al. (2016)</span>
<span class="ltx_bibblock">
A. Karkouch, H. Mousannif, H. Al Moatassime, T. Noel,

</span>
<span class="ltx_bibblock">Data quality in internet of things: A state-of-the-art survey,

</span>
<span class="ltx_bibblock">Journal of Network and Computer Applications 73 (2016) 57–81.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulkarni and Harman (2011)</span>
<span class="ltx_bibblock">
S. Kulkarni, G. Harman, An Elementary Introduction to Statistical Learning Theory, Wiley Series in Probability and Statistics, Wiley, Hoboken, N.J, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vapnik (1998)</span>
<span class="ltx_bibblock">
V. N. Vapnik, Statistical Learning Theory, Adaptive and Learning Systems for Signal Processing, Communications, and Control, Wiley, New York, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abu-Mostafa et al. (2012)</span>
<span class="ltx_bibblock">
Y. S. Abu-Mostafa, M. Magdon-Ismail, H.-T. Lin, Learning from Data: A Short Course, AMLbook.com, S.l., 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grohs (2023)</span>
<span class="ltx_bibblock">
P. Grohs, Mathematical Aspects of Deep Learning, Cambridge University Press, Cambridge, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raschka et al. (2022)</span>
<span class="ltx_bibblock">
S. Raschka, Y. Liu, V. Mirjalili, D. Dzhulgakov, Machine Learning with PyTorch and Scikit-Learn: Develop Machine Learning and Deep Learning Models with Python, Expert Insight, Packt, Birmingham Mumbai, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vapnik (1991)</span>
<span class="ltx_bibblock">
V. Vapnik,

</span>
<span class="ltx_bibblock">Principles of Risk Minimization for Learning Theory,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 4, Morgan-Kaufmann, 1991, pp. 831–838.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vapnik (2010)</span>
<span class="ltx_bibblock">
V. N. Vapnik, The Nature of Statistical Learning Theory, Statistics for Engineering and Information Science, second edition ed., Springer, New York, NY, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2019)</span>
<span class="ltx_bibblock">
Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, J. Zhang,

</span>
<span class="ltx_bibblock">Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing,

</span>
<span class="ltx_bibblock">Proceedings of the IEEE 107 (2019) 1738–1762.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khouas et al. (2024)</span>
<span class="ltx_bibblock">
A. R. Khouas, M. R. Bouadjenek, H. Hacid, S. Aryal, Training Machine Learning models at the Edge: A Survey, 2024. <span class="ltx_text ltx_font_typewriter" id="bib.bib40.1.1">arXiv:2403.02619</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dehghani and Yazdanparast (2023)</span>
<span class="ltx_bibblock">
M. Dehghani, Z. Yazdanparast,

</span>
<span class="ltx_bibblock">From distributed machine to distributed deep learning: A comprehensive survey,

</span>
<span class="ltx_bibblock">Journal of Big Data 10 (2023) 158.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al. (2020)</span>
<span class="ltx_bibblock">
L. Lyu, X. Xu, Q. Wang, H. Yu,

</span>
<span class="ltx_bibblock">Collaborative Fairness in Federated Learning,

</span>
<span class="ltx_bibblock">in: Q. Yang, L. Fan, H. Yu (Eds.), Federated Learning: Privacy and Incentive, Springer International Publishing, Cham, 2020, pp. 189–204.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y Arcas,

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from  Decentralized Data,

</span>
<span class="ltx_bibblock">in: Proceedings of the 20th International Conference on  Artificial Intelligence and Statistics, PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naik and Naik (2024)</span>
<span class="ltx_bibblock">
D. Naik, N. Naik,

</span>
<span class="ltx_bibblock">An Introduction to Federated Learning: Working, Types , Benefits and Limitations,

</span>
<span class="ltx_bibblock">in: N. Naik, P. Jenkins, P. Grace, L. Yang, S. Prajapat (Eds.), Advances in Computational Intelligence Systems, Springer Nature Switzerland, Cham, 2024, pp. 3–17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
S. Xu, Y. Yao, F. Xu, T. Gu, J. Xu, X. Ma,

</span>
<span class="ltx_bibblock">Data Quality Matters: A Case Study of Obsolete Comment Detection,

</span>
<span class="ltx_bibblock">in: 2023 IEEE/ACM 45th International Conference on  Software Engineering (ICSE), 2023, pp. 781–793.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2021)</span>
<span class="ltx_bibblock">
N. Gupta, S. Mujumdar, H. Patel, S. Masuda, N. Panwar, S. Bandyopadhyay, S. Mehta, S. Guttula, S. Afzal, R. Sharma Mittal, V. Munigala,

</span>
<span class="ltx_bibblock">Data Quality for Machine Learning Tasks,

</span>
<span class="ltx_bibblock">in: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining, KDD ’21, Association for Computing Machinery, New York, NY, USA, 2021, pp. 4040–4041.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olson (2003)</span>
<span class="ltx_bibblock">
J. E. Olson, Data Quality: The Accuracy Dimension, Morgan Kaufmann, San Francisco, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Renggli et al. (2021)</span>
<span class="ltx_bibblock">
C. Renggli, L. Rimanic, N. M. Gürel, B. Karlaš, W. Wu, C. Zhang, A Data Quality-Driven View of MLOps, 2021. <span class="ltx_text ltx_font_typewriter" id="bib.bib48.1.1">arXiv:2102.07750</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gudivada et al. (2017)</span>
<span class="ltx_bibblock">
V. N. Gudivada, A. Apon, J. Ding,

</span>
<span class="ltx_bibblock">Data Quality Considerations for Big Data and Machine Learning: Going Beyond Data Cleaning and Transformations (2017).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hagendorff (2021)</span>
<span class="ltx_bibblock">
T. Hagendorff,

</span>
<span class="ltx_bibblock">Linking Human And Machine Behavior: A New Approach to  Evaluate Training Data Quality for Beneficial Machine Learning,

</span>
<span class="ltx_bibblock">Minds and Machines 31 (2021) 563–593.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Budach et al. (2022)</span>
<span class="ltx_bibblock">
L. Budach, M. Feuerpfeil, N. Ihde, A. Nathansen, N. Noack, H. Patzlaff, F. Naumann, H. Harmouch, The Effects of Data Quality on Machine Learning Performance , 2022. <span class="ltx_text ltx_font_typewriter" id="bib.bib51.1.1">arXiv:2207.14529</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Danilov et al. (2023)</span>
<span class="ltx_bibblock">
G. Danilov, K. Kotik, M. Shifrin, Y. Strunina, T. Pronkina, T. Tsukanova, V. Nepomnyashiy, N. Konovalov, V. Danilov, A. Potapov,

</span>
<span class="ltx_bibblock">Data Quality Estimation Via Model Performance: Machine Learning  as a Validation Tool,

</span>
<span class="ltx_bibblock">in: Healthcare Transformation with Informatics and  Artificial Intelligence, IOS Press, 2023, pp. 369–372.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Newey and McFadden (1994)</span>
<span class="ltx_bibblock">
W. K. Newey, D. McFadden,

</span>
<span class="ltx_bibblock">Chapter 36 Large sample estimation and hypothesis testing,

</span>
<span class="ltx_bibblock">in: Handbook of Econometrics, volume 4, Elsevier, 1994, pp. 2111–2245.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramírez-Gallego et al. (2017)</span>
<span class="ltx_bibblock">
S. Ramírez-Gallego, B. Krawczyk, S. García, M. Woźniak, F. Herrera,

</span>
<span class="ltx_bibblock">A survey on data preprocessing for data stream mining: Current status and future directions,

</span>
<span class="ltx_bibblock">Neurocomputing 239 (2017) 39–57.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Werner de Vargas et al. (2023)</span>
<span class="ltx_bibblock">
V. Werner de Vargas, J. A. Schneider Aranda, R.  dos Santos Costa, P. R. da Silva Pereira, J. L. Victória Barbosa,

</span>
<span class="ltx_bibblock">Imbalanced data preprocessing techniques for machine learning: A systematic mapping study,

</span>
<span class="ltx_bibblock">Knowledge and Information Systems 65 (2023) 31–57.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">You et al. (2020)</span>
<span class="ltx_bibblock">
J. You, X. Ma, Y. Ding, M. J. Kochenderfer, J. Leskovec,

</span>
<span class="ltx_bibblock">Handling Missing Data with Graph Representation Learning,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 33, Curran Associates, Inc., 2020, pp. 19075–19087.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Sabuncu (2018)</span>
<span class="ltx_bibblock">
Z. Zhang, M. Sabuncu,

</span>
<span class="ltx_bibblock">Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 31, Curran Associates, Inc., 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2022)</span>
<span class="ltx_bibblock">
F. Lin, X. Fang, Z. Gao,

</span>
<span class="ltx_bibblock">Distributionally Robust Optimization: A review on theory and applications,

</span>
<span class="ltx_bibblock">Numerical Algebra, Control and Optimization 12 (Mon Feb 28 19:00:00 EST 2022) 159–212.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou and Wang (2024)</span>
<span class="ltx_bibblock">
X. Zhou, X. Wang,

</span>
<span class="ltx_bibblock">Federated Label-Noise Learning with Local Diversity Product Regularization,

</span>
<span class="ltx_bibblock">Proceedings of the AAAI Conference on Artificial Intelligence 38 (2024) 17141–17149.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goldberger and Ben-Reuven (2022)</span>
<span class="ltx_bibblock">
J. Goldberger, E. Ben-Reuven,

</span>
<span class="ltx_bibblock">Training deep neural-networks using a noise adaptation layer,

</span>
<span class="ltx_bibblock">in: International Conference on Learning Representations, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zafar et al. (2017)</span>
<span class="ltx_bibblock">
M. B. Zafar, I. Valera, M. G. Rogriguez, K. P. Gummadi,

</span>
<span class="ltx_bibblock">Fairness Constraints: Mechanisms for Fair Classification,

</span>
<span class="ltx_bibblock">in: Proceedings of the 20th International Conference on  Artificial Intelligence and Statistics, PMLR, 2017, pp. 962–970.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
A. Li, L. Zhang, J. Tan, Y. Qin, J. Wang, X.-Y. Li,

</span>
<span class="ltx_bibblock">Sample-level Data Selection for Federated Learning,

</span>
<span class="ltx_bibblock">in: IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, IEEE, Vancouver, BC, Canada, 2021, pp. 1–10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El-Mhamdi et al. (2023)</span>
<span class="ltx_bibblock">
E.-M. El-Mhamdi, S. Farhadkhani, R. Guerraoui, L.-N. Hoang,

</span>
<span class="ltx_bibblock">On the Strategyproofness of the Geometric Median,

</span>
<span class="ltx_bibblock">in: Proceedings of The 26th International Conference on  Artificial Intelligence and Statistics, PMLR, 2023, pp. 2603–2640.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bolukbasi et al. (2016)</span>
<span class="ltx_bibblock">
T. Bolukbasi, K.-W. Chang, J. Y. Zou, V. Saligrama, A. T. Kalai,

</span>
<span class="ltx_bibblock">Man is to Computer Programmer as Woman is to Homemaker?  Debiasing Word Embeddings,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 29, Curran Associates, Inc., 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt et al. (2016)</span>
<span class="ltx_bibblock">
M. Hardt, E. Price, E. Price, N. Srebro,

</span>
<span class="ltx_bibblock">Equality of Opportunity in Supervised Learning,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 29, Curran Associates, Inc., 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petersen et al. (2021)</span>
<span class="ltx_bibblock">
F. Petersen, D. Mukherjee, Y. Sun, M. Yurochkin,

</span>
<span class="ltx_bibblock">Post-processing for Individual Fairness,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 34, Curran Associates, Inc., 2021, pp. 25944–25955.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
J. Liu, Z. Shen, Y. He, X. Zhang, R. Xu, H. Yu, P. Cui, Towards Out-Of-Distribution Generalization: A Survey, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib67.1.1">arXiv:2108.13624</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
H. Wang, L. Muñoz-González, D. Eklund, S. Raza,

</span>
<span class="ltx_bibblock">Non-IID data re-balancing at IoT edge with peer-to-peer federated learning for anomaly detection,

</span>
<span class="ltx_bibblock">in: Proceedings of the 14th ACM Conference on Security and  Privacy in Wireless and Mobile Networks, WiSec ’21, Association for Computing Machinery, New York, NY, USA, 2021, pp. 153–163.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
X. Li, K. Huang, W. Yang, S. Wang, Z. Zhang, On the Convergence of FedAvg on Non-IID Data, 2020. <span class="ltx_text ltx_font_typewriter" id="bib.bib69.1.1">arXiv:1907.02189</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et al. (2009)</span>
<span class="ltx_bibblock">
B. Zou, L. Li, Z. Xu,

</span>
<span class="ltx_bibblock">The generalization performance of ERM algorithm with strongly mixing observations,

</span>
<span class="ltx_bibblock">Machine Learning 75 (2009) 275–295.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo and Shi (2011)</span>
<span class="ltx_bibblock">
Z.-C. Guo, L. Shi,

</span>
<span class="ltx_bibblock">Classification with non-i.i.d. sampling,

</span>
<span class="ltx_bibblock">Mathematical and Computer Modelling 54 (2011) 1347–1364.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zimin (2018)</span>
<span class="ltx_bibblock">
A. Zimin, Learning from Dependent Data, Thesis, Institute of Science and Technology Austria, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et al. (2021)</span>
<span class="ltx_bibblock">
A. Roy, K. Balasubramanian, M. A. Erdogdu,

</span>
<span class="ltx_bibblock">On Empirical Risk Minimization with Dependent and  Heavy-Tailed Data,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 34, Curran Associates, Inc., 2021, pp. 8913–8926.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dundar et al. (????)</span>
<span class="ltx_bibblock">
M. Dundar, B. Krishnapuram, J. Bi, R. B. Rao,

</span>
<span class="ltx_bibblock">Learning Classifiers When The Training Data Is Not IID,

</span>
<span class="ltx_bibblock">in: International Joint Conference on Artificial Intelligence, ????

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lauer (2023)</span>
<span class="ltx_bibblock">
F. Lauer, Uniform Risk Bounds for Learning with Dependent Data Sequences, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib75.1.1">arXiv:2303.11650</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee (2023)</span>
<span class="ltx_bibblock">
H. Lee,

</span>
<span class="ltx_bibblock">Towards Convergence in Federated Learning via Non-IID Analysis in a Distributed Solar Energy Grid,

</span>
<span class="ltx_bibblock">Electronics 12 (2023) 1580.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2018)</span>
<span class="ltx_bibblock">
Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, V. Chandra,

</span>
<span class="ltx_bibblock">Federated Learning with Non-IID Data (2018). <span class="ltx_text ltx_font_typewriter" id="bib.bib77.1.1">arXiv:1806.00582</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Y. Wang, Q. Shi, T.-H. Chang,

</span>
<span class="ltx_bibblock">Why Batch Normalization Damage Federated Learning on Non-IID Data?,

</span>
<span class="ltx_bibblock">IEEE transactions on neural networks and learning systems PP (2023a).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Y. Wang, Q. Shi, T.-H. Chang,

</span>
<span class="ltx_bibblock">Batch Normalization Damages Federated Learning on NON-IID Data : Analysis and Remedy,

</span>
<span class="ltx_bibblock">in: ICASSP 2023 - 2023 IEEE International Conference on  Acoustics, Speech and Signal Processing (ICASSP), 2023b, pp. 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2022)</span>
<span class="ltx_bibblock">
X. Ma, J. Zhu, Z. Lin, S. Chen, Y. Qin,

</span>
<span class="ltx_bibblock">A state-of-the-art survey on solving non-IID data in Federated Learning,

</span>
<span class="ltx_bibblock">Future Generation Computer Systems 135 (2022) 244–258.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2024)</span>
<span class="ltx_bibblock">
Z. Lu, H. Pan, Y. Dai, X. Si, Y. Zhang,

</span>
<span class="ltx_bibblock">Federated Learning With Non-IID Data: A Survey,

</span>
<span class="ltx_bibblock">IEEE Internet of Things Journal (2024) 1–1.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoshida et al. (2020)</span>
<span class="ltx_bibblock">
N. Yoshida, T. Nishio, M. Morikura, K. Yamamoto, R. Yonetani,

</span>
<span class="ltx_bibblock">Hybrid-FL for Wireless Networks: Cooperative Learning Mechanism Using Non-IID Data,

</span>
<span class="ltx_bibblock">in: ICC 2020 - 2020 IEEE International Conference on  Communications (ICC), 2020, pp. 1–7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2021)</span>
<span class="ltx_bibblock">
P. Tian, Z. Chen, W. Yu, W. Liao,

</span>
<span class="ltx_bibblock">Towards asynchronous federated learning based threat detection: A DC-Adam approach,

</span>
<span class="ltx_bibblock">Computers &amp; Security 108 (2021) 102344.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abay et al. (2020)</span>
<span class="ltx_bibblock">
A. Abay, Y. Zhou, N. Baracaldo, S. Rajamoni, E. Chuba, H. Ludwig, Mitigating Bias in Federated Learning, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong et al. (2023)</span>
<span class="ltx_bibblock">
E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, S.-L. Kim, Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib85.1.1">arXiv:1811.11479</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rai et al. (2022)</span>
<span class="ltx_bibblock">
S. Rai, A. Kumari, D. K. Prasad,

</span>
<span class="ltx_bibblock">Client Selection in Federated Learning under Imperfections  in Environment,

</span>
<span class="ltx_bibblock">AI 3 (2022) 124–145.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
H. Wang, Z. Kaplan, D. Niu, B. Li,

</span>
<span class="ltx_bibblock">Optimizing Federated Learning on Non-IID Data with  Reinforcement Learning,

</span>
<span class="ltx_bibblock">in: IEEE INFOCOM 2020 - IEEE Conference on Computer Communications, 2020, pp. 1698–1707.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Y. Jiang, J. Konečný, K. Rush, S. Kannan, Improving Federated Learning Personalization via Model Agnostic Meta Learning, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib88.1.1">arXiv:1909.12488</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Finn et al. (2017)</span>
<span class="ltx_bibblock">
C. Finn, P. Abbeel, S. Levine,

</span>
<span class="ltx_bibblock">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks,

</span>
<span class="ltx_bibblock">in: Proceedings of the 34th International Conference on Machine Learning, PMLR, 2017, pp. 1126–1135.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang (2022)</span>
<span class="ltx_bibblock">
W. Li, S. Wang,

</span>
<span class="ltx_bibblock">Federated meta-learning for spatial-temporal prediction,

</span>
<span class="ltx_bibblock">Neural Computing and Applications 34 (2022) 10355–10374.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2021)</span>
<span class="ltx_bibblock">
X. Zhang, M. Hong, S. Dhople, W. Yin, Y. Liu,

</span>
<span class="ltx_bibblock">FedPD: A Federated Learning Framework With Adaptivity to  Non-IID Data,

</span>
<span class="ltx_bibblock">IEEE Transactions on Signal Processing 69 (2021) 6055–6070.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. (2017)</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, A. S. Talwalkar,

</span>
<span class="ltx_bibblock">Federated Multi-Task Learning,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 30, Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corinzia et al. (2021)</span>
<span class="ltx_bibblock">
L. Corinzia, A. Beuret, J. M. Buhmann, Variational Federated Multi-Task Learning, 2021. <span class="ltx_text ltx_font_typewriter" id="bib.bib93.1.1">arXiv:1906.06268</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al. (2021)</span>
<span class="ltx_bibblock">
F. Sattler, K.-R. Müller, W. Samek,

</span>
<span class="ltx_bibblock">Clustered Federated Learning: Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems 32 (2021) 3710–3722.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frenay and Verleysen (2014)</span>
<span class="ltx_bibblock">
B. Frenay, M. Verleysen,

</span>
<span class="ltx_bibblock">Classification in the Presence of Label Noise: A Survey,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems 25 (2014) 845–869.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baccour et al. (2022)</span>
<span class="ltx_bibblock">
E. Baccour, N. Mhaisen, A. A. Abdellatif, A. Erbad, A. Mohamed, M. Hamdi, M. Guizani,

</span>
<span class="ltx_bibblock">Pervasive AI for IoT applications: A Survey on  Resource-efficient Distributed Artificial Intelligence,

</span>
<span class="ltx_bibblock">IEEE Communications Surveys &amp; Tutorials 24 (2022) 2366–2418. <span class="ltx_text ltx_font_typewriter" id="bib.bib96.1.1">arXiv:2105.01798</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2023)</span>
<span class="ltx_bibblock">
H. Song, M. Kim, D. Park, Y. Shin, J.-G. Lee,

</span>
<span class="ltx_bibblock">Learning From Noisy Labels With Deep Neural Networks: A Survey ,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems 34 (2023) 8135–8153.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2023)</span>
<span class="ltx_bibblock">
W. Wan, X. Wang, M. Xie, S. Huang, S. Chen, S. Li, Unlocking the Power of Open Set : A New Perspective for  Open-set Noisy Label Learning, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib98.1.1">arXiv:2305.04203</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albert et al. (2022)</span>
<span class="ltx_bibblock">
P. Albert, D. Ortego, E. Arazo, N. E. O’Connor, K. McGuinness,

</span>
<span class="ltx_bibblock">Addressing Out-of-Distribution Label Noise in Webly-Labelled Data,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF Winter Conference on  Applications of Computer Vision, 2022, pp. 392–401.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Algan and Ulusoy (2020)</span>
<span class="ltx_bibblock">
G. Algan, İ. Ulusoy, Label Noise Types and Their Effects on Deep Learning, 2020. <span class="ltx_text ltx_font_typewriter" id="bib.bib100.1.1">arXiv:2003.10471</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shanthini et al. (2019)</span>
<span class="ltx_bibblock">
A. Shanthini, G. Vinodhini, R. M. Chandrasekaran, P. Supraja,

</span>
<span class="ltx_bibblock">A taxonomy on impact of label noise and feature noise using machine learning techniques,

</span>
<span class="ltx_bibblock">Soft Computing 23 (2019) 8597–8607.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2022)</span>
<span class="ltx_bibblock">
X. Liang, X. Liu, L. Yao,

</span>
<span class="ltx_bibblock">Review–A Survey of Learning from Noisy Labels,

</span>
<span class="ltx_bibblock">ECS Sensors Plus 1 (2022) 021401.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Algan and Ulusoy (2021)</span>
<span class="ltx_bibblock">
G. Algan, I. Ulusoy,

</span>
<span class="ltx_bibblock">Image classification with deep learning in the presence of noisy labels: A survey,

</span>
<span class="ltx_bibblock">Knowledge-Based Systems 215 (2021) 106771.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barry et al. (2023)</span>
<span class="ltx_bibblock">
A. Barry, L. Han, G. Demartini,

</span>
<span class="ltx_bibblock">On the Impact of Data Quality on Image Classification Fairness,

</span>
<span class="ltx_bibblock">in: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’23, Association for Computing Machinery, New York, NY, USA, 2023, pp. 2225–2229.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. (2021)</span>
<span class="ltx_bibblock">
Z. Zeng, Y. Liu, W. Tang, F. Chen,

</span>
<span class="ltx_bibblock">Noise Is Useful: Exploiting Data Diversity for Edge Intelligence,

</span>
<span class="ltx_bibblock">IEEE Wireless Communications Letters 10 (2021) 957–961.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng (2012)</span>
<span class="ltx_bibblock">
L. Deng,

</span>
<span class="ltx_bibblock">The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web],

</span>
<span class="ltx_bibblock">IEEE Signal Processing Magazine 29 (2012) 141–142.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jafarigol and Trafalis (2023)</span>
<span class="ltx_bibblock">
E. Jafarigol, T. Trafalis, The Paradox of Noise: An Empirical Study of  Noise-Infusion Mechanisms to Improve Generalization, Stability , and Privacy in Federated Learning, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib107.1.1">arXiv:2311.05790</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky (????)</span>
<span class="ltx_bibblock">
A. Krizhevsky,

</span>
<span class="ltx_bibblock">Learning Multiple Layers of Features from Tiny Images (????).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao (2019)</span>
<span class="ltx_bibblock">
J. Yao, Deep Learning with Noisy Supervision, Thesis, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tuor et al. (2021)</span>
<span class="ltx_bibblock">
T. Tuor, S. Wang, B. J. Ko, C. Liu, K. K. Leung,

</span>
<span class="ltx_bibblock">Overcoming Noisy and Irrelevant Data in Federated Learning ,

</span>
<span class="ltx_bibblock">in: 2020 25th International Conference on Pattern Recognition (ICPR), 2021, pp. 5020–5027.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2022)</span>
<span class="ltx_bibblock">
M. Yang, H. Qian, X. Wang, Y. Zhou, H. Zhu,

</span>
<span class="ltx_bibblock">Client Selection for Federated Learning With Label Noise,

</span>
<span class="ltx_bibblock">IEEE Transactions on Vehicular Technology 71 (2022) 2193–2197.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. (2024)</span>
<span class="ltx_bibblock">
X. Ji, Z. Zhu, W. Xi, O. Gadyatskaya, Z. Song, Y. Cai, Y. Liu,

</span>
<span class="ltx_bibblock">FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning,

</span>
<span class="ltx_bibblock">Proceedings of the AAAI Conference on Artificial Intelligence 38 (2024) 12830–12838.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tam et al. (2023)</span>
<span class="ltx_bibblock">
K. Tam, L. Li, B. Han, C. Xu, H. Fu,

</span>
<span class="ltx_bibblock">Federated Noisy Client Learning,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems (2023) 1–14.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gamberger et al. (1996)</span>
<span class="ltx_bibblock">
D. Gamberger, N. Lavrač, S. Džeroski,

</span>
<span class="ltx_bibblock">Noise elimination in inductive concept learning: A case study in medical diagnosis,

</span>
<span class="ltx_bibblock">in: S. Arikawa, A. K. Sharma (Eds.), Algorithmic Learning Theory, Springer, Berlin, Heidelberg, 1996, pp. 199–212.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pleiss et al. (2020)</span>
<span class="ltx_bibblock">
G. Pleiss, T. Zhang, E. Elenberg, K. Q. Weinberger,

</span>
<span class="ltx_bibblock">Identifying Mislabeled Data using the Area Under the Margin Ranking,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 33, Curran Associates, Inc., 2020, pp. 17044–17056.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gamberger et al. (1999)</span>
<span class="ltx_bibblock">
D. Gamberger, N. Lavrac, C. Groselj,

</span>
<span class="ltx_bibblock">Experiments with noise ltering in a medical domain,

</span>
<span class="ltx_bibblock">in: Proceedings of the Sixteenth International Conference on  Machine Learning {(<span class="ltx_text ltx_phantom" id="bib.bib116.1.1"><span style="visibility:hidden">}</span></span>ICML<span class="ltx_text ltx_phantom" id="bib.bib116.2.2"><span style="visibility:hidden">{</span></span>} 1999),  Bled, Slovenia, June 27 - 30, 1999, Morgan Kaufmann, 1999, pp. 143–151.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brodley and Friedl (1999)</span>
<span class="ltx_bibblock">
C. E. Brodley, M. A. Friedl,

</span>
<span class="ltx_bibblock">Identifying Mislabeled Training Data,

</span>
<span class="ltx_bibblock">Journal of Artificial Intelligence Research 11 (1999) 131–167.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2003)</span>
<span class="ltx_bibblock">
X. Zhu, X. Wu, Q. Chen,

</span>
<span class="ltx_bibblock">Eliminating Class Noise in Large Datasets,

</span>
<span class="ltx_bibblock">in: Proceedings, Twentieth International Conference on Machine Learning, volume 2, 2003, pp. 920–927.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2021)</span>
<span class="ltx_bibblock">
L. Ma, Q. Pei, L. Zhou, H. Zhu, L. Wang, Y. Ji,

</span>
<span class="ltx_bibblock">Federated Data Cleaning: Collaborative and  Privacy-Preserving Data Cleaning for Edge Intelligence,

</span>
<span class="ltx_bibblock">IEEE Internet of Things Journal 8 (2021) 6757–6770.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Azadi et al. (2016)</span>
<span class="ltx_bibblock">
S. Azadi, J. Feng, S. Jegelka, T. Darrell, Auxiliary Image Regularization for Deep CNNs with Noisy Labels, 2016. <span class="ltx_text ltx_font_typewriter" id="bib.bib120.1.1">arXiv:1511.07069</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
R. Yu, H. Zhu, K. Li, L. Hong, R. Zhang, N. Ye, S.-L. Huang, X. He,

</span>
<span class="ltx_bibblock">Regularization Penalty Optimization for Addressing Data Quality Variance in OoD Algorithms,

</span>
<span class="ltx_bibblock">Proceedings of the AAAI Conference on Artificial Intelligence 36 (2022) 8945–8953.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Tao (2016)</span>
<span class="ltx_bibblock">
T. Liu, D. Tao,

</span>
<span class="ltx_bibblock">Classification with Noisy Labels by Importance Reweighting,

</span>
<span class="ltx_bibblock">IEEE Transactions on Pattern Analysis and Machine Intelligence 38 (2016) 447–461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
L. Chen, F. Ang, Y. Chen, W. Wang,

</span>
<span class="ltx_bibblock">Robust Federated Learning With Noisy Labeled Data Through Loss Function Correction,

</span>
<span class="ltx_bibblock">IEEE Transactions on Network Science and Engineering 10 (2023) 1501–1511.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manwani and Sastry (2013)</span>
<span class="ltx_bibblock">
N. Manwani, P. S. Sastry,

</span>
<span class="ltx_bibblock">Noise Tolerance Under Risk Minimization,

</span>
<span class="ltx_bibblock">IEEE Transactions on Cybernetics 43 (2013) 1146–1151.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Lyu (2020)</span>
<span class="ltx_bibblock">
X. Xu, L. Lyu, A Reputation Mechanism Is All You Need: Collaborative Fairness  and Adversarial Robustness in Federated Learning, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Y. Chen, X. Yang, X. Qin, H. Yu, P. Chan, Z. Shen,

</span>
<span class="ltx_bibblock">Dealing with Label Quality Disparity in Federated Learning,

</span>
<span class="ltx_bibblock">in: Q. Yang, L. Fan, H. Yu (Eds.), Federated Learning: Privacy and Incentive, Springer International Publishing, Cham, 2020, pp. 108–121.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vucinich and Zhu (2023)</span>
<span class="ltx_bibblock">
S. Vucinich, Q. Zhu,

</span>
<span class="ltx_bibblock">The Current State and Challenges of Fairness in  Federated Learning,

</span>
<span class="ltx_bibblock">IEEE Access 11 (2023) 80903–80914.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grgić-Hlača et al. (2018)</span>
<span class="ltx_bibblock">
N. Grgić-Hlača, M. Zafar, K. Gummadi, A. Weller,

</span>
<span class="ltx_bibblock">Beyond distributive fairness in algorithmic decision making:  Feature selection for procedurally fair learning,

</span>
<span class="ltx_bibblock">in: 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, 2018, pp. 51–60.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weerts et al. (2023)</span>
<span class="ltx_bibblock">
H. Weerts, M. Dudík, R. Edgar, A. Jalali, R. Lutz, M. Madaio,

</span>
<span class="ltx_bibblock">Fairlearn: Assessing and Improving Fairness of AI Systems,

</span>
<span class="ltx_bibblock">Journal of Machine Learning Research 24 (2023) 1–8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castelnovo et al. (2022)</span>
<span class="ltx_bibblock">
A. Castelnovo, R. Crupi, G. Greco, D. Regoli, I. G. Penco, A. C. Cosentini,

</span>
<span class="ltx_bibblock">A clarification of the nuances in the fairness metrics landscape,

</span>
<span class="ltx_bibblock">Scientific Reports 12 (2022) 4209.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Verma and Rubin (2018)</span>
<span class="ltx_bibblock">
S. Verma, J. Rubin,

</span>
<span class="ltx_bibblock">Fairness definitions explained,

</span>
<span class="ltx_bibblock">in: Proceedings of the International Workshop on Software Fairness, ACM, Gothenburg Sweden, 2018, pp. 1–7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. (2018)</span>
<span class="ltx_bibblock">
A. Agarwal, A. Beygelzimer, M. Dudik, J. Langford, H. Wallach,

</span>
<span class="ltx_bibblock">A Reductions Approach to Fair Classification,

</span>
<span class="ltx_bibblock">in: Proceedings of the 35th International Conference on Machine Learning, PMLR, 2018, pp. 60–69.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corbett-Davies et al. (2017)</span>
<span class="ltx_bibblock">
S. Corbett-Davies, E. Pierson, A. Feller, S. Goel, A. Huq,

</span>
<span class="ltx_bibblock">Algorithmic Decision Making and the Cost of Fairness,

</span>
<span class="ltx_bibblock">in: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’17, Association for Computing Machinery, New York, NY, USA, 2017, pp. 797–806.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donini et al. (2018)</span>
<span class="ltx_bibblock">
M. Donini, L. Oneto, S. Ben-David, J. S.  Shawe-Taylor, M. Pontil,

</span>
<span class="ltx_bibblock">Empirical Risk Minimization Under Fairness Constraints,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 31, Curran Associates, Inc., 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grgic-Hlaca et al. (2016)</span>
<span class="ltx_bibblock">
N. Grgic-Hlaca, M. B. Zafar, K. Gummadi, A. Weller,

</span>
<span class="ltx_bibblock">The Case for Process Fairness in Learning: Feature Selection for Fair Decision Making,

</span>
<span class="ltx_bibblock">2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al. (2012)</span>
<span class="ltx_bibblock">
C. Dwork, M. Hardt, T. Pitassi, O. Reingold, R. Zemel,

</span>
<span class="ltx_bibblock">Fairness through awareness,

</span>
<span class="ltx_bibblock">in: Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ITCS ’12, Association for Computing Machinery, New York, NY, USA, 2012, pp. 214–226.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kusner et al. (2017)</span>
<span class="ltx_bibblock">
M. J. Kusner, J. Loftus, C. Russell, R. Silva,

</span>
<span class="ltx_bibblock">Counterfactual Fairness,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 30, Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kearns et al. (2018)</span>
<span class="ltx_bibblock">
M. Kearns, S. Neel, A. Roth, Z. S. Wu,

</span>
<span class="ltx_bibblock">Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness,

</span>
<span class="ltx_bibblock">in: Proceedings of the 35th International Conference on Machine Learning, PMLR, 2018, pp. 2564–2572.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kearns et al. (2019)</span>
<span class="ltx_bibblock">
M. Kearns, S. Neel, A. Roth, Z. S. Wu,

</span>
<span class="ltx_bibblock">An Empirical Study of Rich Subgroup Fairness for Machine Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the Conference on Fairness,  Accountability, and Transparency, FAT* ’19, Association for Computing Machinery, New York, NY, USA, 2019, pp. 100–109.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al. (2020)</span>
<span class="ltx_bibblock">
L. Lyu, J. Yu, K. Nandakumar, Y. Li, X. Ma, J. Jin, H. Yu, K. S. Ng,

</span>
<span class="ltx_bibblock">Towards Fair and Privacy-Preserving Federated Deep Models,

</span>
<span class="ltx_bibblock">IEEE Transactions on Parallel and Distributed Systems 31 (2020) 2524–2541.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donahue and Kleinberg (2023)</span>
<span class="ltx_bibblock">
K. Donahue, J. Kleinberg,

</span>
<span class="ltx_bibblock">Fairness in model-sharing games,

</span>
<span class="ltx_bibblock">in: Proceedings of the ACM Web Conference 2023, WWW ’23, Association for Computing Machinery, New York, NY, USA, 2023, pp. 3775–3783.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ray Chaudhury et al. (2022)</span>
<span class="ltx_bibblock">
B. Ray Chaudhury, L. Li, M. Kang, B. Li, R. Mehta,

</span>
<span class="ltx_bibblock">Fairness in Federated Learning via Core-Stability,

</span>
<span class="ltx_bibblock">Advances in Neural Information Processing Systems 35 (2022) 5738–5750.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohri et al. (2019)</span>
<span class="ltx_bibblock">
M. Mohri, G. Sivek, A. T. Suresh,

</span>
<span class="ltx_bibblock">Agnostic Federated Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 36th International Conference on Machine Learning, PMLR, 2019, pp. 4615–4625.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
F. Zhang, K. Kuang, Y. Liu, L. Chen, C. Wu, F. Wu, J. Lu, Y. Shao, J. Xiao, Unified Group Fairness on Federated Learning, 2022. <span class="ltx_text ltx_font_typewriter" id="bib.bib144.1.1">arXiv:2111.04986</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al. (2020)</span>
<span class="ltx_bibblock">
L. Lyu, Y. Li, K. Nandakumar, J. Yu, X. Ma,

</span>
<span class="ltx_bibblock">How to Democratise and Protect AI: Fair and  Differentially Private Decentralised Deep Learning,

</span>
<span class="ltx_bibblock">IEEE Transactions on Dependable and Secure Computing (2020) 1–1.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shapley and Shubik (1969)</span>
<span class="ltx_bibblock">
L. S. Shapley, M. Shubik,

</span>
<span class="ltx_bibblock">On market games,

</span>
<span class="ltx_bibblock">Journal of Economic Theory 1 (1969) 9–25.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brunet et al. (2019)</span>
<span class="ltx_bibblock">
M.-E. Brunet, C. Alkalay-Houlihan, A. Anderson, R. Zemel,

</span>
<span class="ltx_bibblock">Understanding the Origins of Bias in Word Embeddings,

</span>
<span class="ltx_bibblock">in: Proceedings of the 36th International Conference on Machine Learning, PMLR, 2019, pp. 803–811.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Calmon et al. (2017)</span>
<span class="ltx_bibblock">
F. Calmon, D. Wei, B. Vinzamuri, K. Natesan Ramamurthy, K. R. Varshney,

</span>
<span class="ltx_bibblock">Optimized Pre-Processing for Discrimination Prevention,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 30, Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abhishek and Abdelaziz (2023)</span>
<span class="ltx_bibblock">
K. Abhishek, M. Abdelaziz, Machine Learning for Imbalanced Data: Tackle Imbalanced Datasets Using Machine Learning and Deep Learning Techniques, [first edition] ed., Packt Publishing Ltd., Birmingham, UK, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al. (2019)</span>
<span class="ltx_bibblock">
M. Duan, D. Liu, X. Chen, Y. Tan, J. Ren, L. Qiao, L. Liang,

</span>
<span class="ltx_bibblock">Astraea: Self-Balancing Federated Learning for Improving Classification Accuracy of Mobile Deep Learning Applications,

</span>
<span class="ltx_bibblock">in: 2019 IEEE 37th International Conference on Computer Design (ICCD), IEEE, Abu Dhabi, United Arab Emirates, 2019, pp. 246–254.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamishima et al. (2012)</span>
<span class="ltx_bibblock">
T. Kamishima, S. Akaho, H. Asoh, J. Sakuma,

</span>
<span class="ltx_bibblock">Fairness-Aware Classifier with Prejudice Remover Regularizer,

</span>
<span class="ltx_bibblock">in: P. A. Flach, T. De Bie, N. Cristianini (Eds.), Machine Learning and Knowledge Discovery in Databases, Springer, Berlin, Heidelberg, 2012, pp. 35–50.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ezzeldin et al. (2023)</span>
<span class="ltx_bibblock">
Y. H. Ezzeldin, S. Yan, C. He, E. Ferrara, A. S. Avestimehr,

</span>
<span class="ltx_bibblock">FairFed: Enabling Group Fairness in Federated Learning,

</span>
<span class="ltx_bibblock">Proceedings of the AAAI Conference on Artificial Intelligence 37 (2023) 7494–7502.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2023)</span>
<span class="ltx_bibblock">
Y. Shi, H. Yu, C. Leung,

</span>
<span class="ltx_bibblock">Towards Fairness-Aware Federated Learning,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems (2023) 1–17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2021)</span>
<span class="ltx_bibblock">
N. Carlini, F. Tramèr, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee, A. Roberts, T. Brown, D. Song, Ú. Erlingsson, A. Oprea, C. Raffel,

</span>
<span class="ltx_bibblock">Extracting Training Data from Large Language Models,

</span>
<span class="ltx_bibblock">in: 30th USENIX Security Symposium (USENIX Security 21), 2021, pp. 2633–2650.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasquini et al. (2022)</span>
<span class="ltx_bibblock">
D. Pasquini, D. Francati, G. Ateniese,

</span>
<span class="ltx_bibblock">Eluding Secure Aggregation in Federated Learning via Model Inconsistency,

</span>
<span class="ltx_bibblock">in: Proceedings of the ACM Conference on Computer and  Communications Security, 2022, pp. 2429–2443.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Y. Li, H. Yan, T. Huang, Z. Pan, J. Lai, X. Zhang, K. Chen, J. Li,

</span>
<span class="ltx_bibblock">Model architecture level privacy leakage in neural networks,

</span>
<span class="ltx_bibblock">Science China Information Sciences 67 (2023) 132101.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balle et al. (2022)</span>
<span class="ltx_bibblock">
B. Balle, G. Cherubin, J. Hayes,

</span>
<span class="ltx_bibblock">Reconstructing Training Data with Informed Adversaries,

</span>
<span class="ltx_bibblock">in: 2022 IEEE Symposium on Security and Privacy (SP), IEEE, San Francisco, CA, USA, 2022, pp. 1138–1156.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al. (2017)</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, V. Shmatikov,

</span>
<span class="ltx_bibblock">Membership Inference Attacks Against Machine Learning Models,

</span>
<span class="ltx_bibblock">in: 2017 IEEE Symposium on Security and Privacy (SP), 2017, pp. 3–18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belkin et al. (2019)</span>
<span class="ltx_bibblock">
M. Belkin, D. Hsu, S. Ma, S. Mandal,

</span>
<span class="ltx_bibblock">Reconciling modern machine-learning practice and the classical bias–variance trade-off,

</span>
<span class="ltx_bibblock">Proceedings of the National Academy of Sciences of the United States of America 116 (2019) 15849–15854.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belkin (2021)</span>
<span class="ltx_bibblock">
M. Belkin,

</span>
<span class="ltx_bibblock">Fit without fear: Remarkable mathematical phenomena of deep learning through the prism of interpolation,

</span>
<span class="ltx_bibblock">Acta Numerica 30 (2021) 203–248.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mothukuri et al. (2021)</span>
<span class="ltx_bibblock">
V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha, G. Srivastava,

</span>
<span class="ltx_bibblock">A survey on security and privacy of federated learning,

</span>
<span class="ltx_bibblock">Future Generation Computer Systems 115 (2021) 619–640.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulynych et al. (2022)</span>
<span class="ltx_bibblock">
B. Kulynych, M. Yaghini, G. Cherubin, M. Veale, C. Troncoso,

</span>
<span class="ltx_bibblock">Disparate Vulnerability to Membership Inference Attacks,

</span>
<span class="ltx_bibblock">Proceedings on Privacy Enhancing Technologies (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
H. Hu, Z. Salcic, L. Sun, G. Dobbie, P. S. Yu, X. Zhang,

</span>
<span class="ltx_bibblock">Membership Inference Attacks on Machine Learning: A Survey ,

</span>
<span class="ltx_bibblock">ACM Computing Surveys 54 (2022) 1–37.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Z. Wang, Y. Huang, M. Song, L. Wu, F. Xue, K. Ren,

</span>
<span class="ltx_bibblock">Poisoning-Assisted Property Inference Attack Against Federated Learning,

</span>
<span class="ltx_bibblock">IEEE Transactions on Dependable and Secure Computing 20 (2023) 3328–3340.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis et al. (2019)</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, V. Shmatikov,

</span>
<span class="ltx_bibblock">Exploiting Unintended Feature Leakage in Collaborative Learning ,

</span>
<span class="ltx_bibblock">in: 2019 IEEE Symposium on Security and Privacy (SP), IEEE, San Francisco, CA, USA, 2019, pp. 691–706.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023)</span>
<span class="ltx_bibblock">
H. Kim, Y. Cho, Y. Lee, H. Bae, Y. Paek,

</span>
<span class="ltx_bibblock">Exploring Clustered Federated Learning’s Vulnerability against Property Inference Attack,

</span>
<span class="ltx_bibblock">in: Proceedings of the 26th International Symposium on Research  in Attacks, Intrusions and Defenses, RAID ’23, Association for Computing Machinery, New York, NY, USA, 2023, pp. 236–249.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mahloujifar et al. (2022)</span>
<span class="ltx_bibblock">
S. Mahloujifar, E. Ghosh, M. Chase,

</span>
<span class="ltx_bibblock">Property Inference from Poisoning,

</span>
<span class="ltx_bibblock">in: 2022 IEEE Symposium on Security and Privacy (SP), 2022, pp. 1120–1137.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hitaj et al. (2017)</span>
<span class="ltx_bibblock">
B. Hitaj, G. Ateniese, F. Perez-Cruz,

</span>
<span class="ltx_bibblock">Deep Models Under the GAN: Information Leakage from  Collaborative Deep Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS ’17, Association for Computing Machinery, New York, NY, USA, 2017, pp. 603–618.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2019)</span>
<span class="ltx_bibblock">
Z. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, H. Qi,

</span>
<span class="ltx_bibblock">Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning,

</span>
<span class="ltx_bibblock">in: IEEE INFOCOM 2019 - IEEE Conference on Computer Communications, 2019, pp. 2512–2520.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib170">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El Mestari et al. (2024)</span>
<span class="ltx_bibblock">
S. Z. El Mestari, G. Lenzini, H. Demirci,

</span>
<span class="ltx_bibblock">Preserving data privacy in machine learning systems,

</span>
<span class="ltx_bibblock">Computers &amp; Security 137 (2024) 103605.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib171">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al. (2021)</span>
<span class="ltx_bibblock">
K. Mo, X. Liu, T. Huang, A. Yan,

</span>
<span class="ltx_bibblock">Querying little is enough: Model inversion attack via latent information,

</span>
<span class="ltx_bibblock">International Journal of Intelligent Systems 36 (2021) 681–690.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib172">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinur and Nissim (2003)</span>
<span class="ltx_bibblock">
I. Dinur, K. Nissim,

</span>
<span class="ltx_bibblock">Revealing information while preserving privacy,

</span>
<span class="ltx_bibblock">in: Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS ’03, Association for Computing Machinery, New York, NY, USA, 2003, pp. 202–210.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib173">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Han (2020)</span>
<span class="ltx_bibblock">
L. Zhu, S. Han,

</span>
<span class="ltx_bibblock">Deep Leakage from Gradients,

</span>
<span class="ltx_bibblock">in: Q. Yang, L. Fan, H. Yu (Eds.), Federated Learning: Privacy and Incentive, Springer International Publishing, Cham, 2020, pp. 17–31.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib174">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2019)</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, S. Han,

</span>
<span class="ltx_bibblock">Deep Leakage from Gradients,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 32, Curran Associates, Inc., 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib175">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haim et al. (2022)</span>
<span class="ltx_bibblock">
N. Haim, G. Vardi, G. Yehudai, O. Shamir, M. Irani,

</span>
<span class="ltx_bibblock">Reconstructing Training Data From Trained Neural Networks,

</span>
<span class="ltx_bibblock">Advances in Neural Information Processing Systems 35 (2022) 22911–22924.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib176">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buzaglo et al. (2023)</span>
<span class="ltx_bibblock">
G. Buzaglo, N. Haim, G. Yehudai, G. Vardi, Y. Oz, Y. Nikankin, M. Irani,

</span>
<span class="ltx_bibblock">Deconstructing Data Reconstruction: Multiclass, Weight Decay and General Losses,

</span>
<span class="ltx_bibblock">Advances in Neural Information Processing Systems 36 (2023) 51515–51535.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib177">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Z. Wang, J. Lee, Q. Lei,

</span>
<span class="ltx_bibblock">Reconstructing Training Data from Model Gradient, Provably ,

</span>
<span class="ltx_bibblock">in: Proceedings of The 26th International Conference on  Artificial Intelligence and Statistics, PMLR, 2023, pp. 6595–6612.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib178">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2023)</span>
<span class="ltx_bibblock">
N. Carlini, J. Hayes, M. Nasr, M. Jagielski, V. Sehwag, F. Tramèr, B. Balle, D. Ippolito, E. Wallace,

</span>
<span class="ltx_bibblock">Extracting Training Data from Diffusion Models,

</span>
<span class="ltx_bibblock">in: 32nd USENIX Security Symposium (USENIX Security 23), 2023, pp. 5253–5270.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib179">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morris et al. (2023)</span>
<span class="ltx_bibblock">
J. Morris, V. Kuleshov, V. Shmatikov, A. Rush,

</span>
<span class="ltx_bibblock">Text Embeddings Reveal (Almost) As Much As Text,

</span>
<span class="ltx_bibblock">in: H. Bouamor, J. Pino, K. Bali (Eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Singapore, 2023, pp. 12448–12460.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib180">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilad-Bachrach et al. (2016)</span>
<span class="ltx_bibblock">
R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, J. Wernsing,

</span>
<span class="ltx_bibblock">CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy,

</span>
<span class="ltx_bibblock">in: Proceedings of The 33rd International Conference on  Machine Learning, PMLR, 2016, pp. 201–210.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib181">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et al. (2014)</span>
<span class="ltx_bibblock">
X. Yi, R. Paulet, E. Bertino,

</span>
<span class="ltx_bibblock">Homomorphic Encryption,

</span>
<span class="ltx_bibblock">in: X. Yi, R. Paulet, E. Bertino (Eds.), Homomorphic Encryption and Applications, Springer International Publishing, Cham, 2014, pp. 27–46.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib182">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phong et al. (2018)</span>
<span class="ltx_bibblock">
L. T. Phong, Y. Aono, T. Hayashi, L. Wang, S. Moriai,

</span>
<span class="ltx_bibblock">Privacy-Preserving Deep Learning via Additively Homomorphic Encryption,

</span>
<span class="ltx_bibblock">IEEE Transactions on Information Forensics and Security 13 (2018) 1333–1345.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib183">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
J. Zhang, B. Chen, S. Yu, H. Deng,

</span>
<span class="ltx_bibblock">PEFL: A Privacy-Enhanced Federated Learning Scheme for Big Data Analytics,

</span>
<span class="ltx_bibblock">2019, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib184">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. (2020)</span>
<span class="ltx_bibblock">
M. Hao, H. Li, X. Luo, G. Xu, H. Yang, S. Liu,

</span>
<span class="ltx_bibblock">Efficient and Privacy-Enhanced Federated Learning for  Industrial Artificial Intelligence,

</span>
<span class="ltx_bibblock">IEEE Transactions on Industrial Informatics 16 (2020) 6532–6542.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib185">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
C. Zhang, S. Li, J. Xia, W. Wang, F. Yan, Y. Liu,

</span>
<span class="ltx_bibblock">{<span class="ltx_text ltx_phantom" id="bib.bib185.1.1"><span style="visibility:hidden">}</span></span>BatchCrypt<span class="ltx_text ltx_phantom" id="bib.bib185.2.2"><span style="visibility:hidden">{</span></span>}: Efficient Homomorphic Encryption for {<span class="ltx_text ltx_phantom" id="bib.bib185.3.3"><span style="visibility:hidden">}</span></span>Cross-Silo<span class="ltx_text ltx_phantom" id="bib.bib185.4.4"><span style="visibility:hidden">{</span></span>} Federated Learning,

</span>
<span class="ltx_bibblock">in: 2020 USENIX Annual Technical Conference (USENIX ATC 20), 2020, pp. 493–506.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib186">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lindell (2021)</span>
<span class="ltx_bibblock">
Y. Lindell,

</span>
<span class="ltx_bibblock">Secure multiparty computation,

</span>
<span class="ltx_bibblock">Communications of the ACM 64 (2021) 86–96.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib187">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. (2017)</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, K. Seth,

</span>
<span class="ltx_bibblock">Practical Secure Aggregation for Privacy-Preserving Machine Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, ACM, Dallas Texas USA, 2017, pp. 1175–1191.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib188">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork (2008)</span>
<span class="ltx_bibblock">
C. Dwork,

</span>
<span class="ltx_bibblock">Differential Privacy: A Survey of Results,

</span>
<span class="ltx_bibblock">in: M. Agrawal, D. Du, Z. Duan, A. Li (Eds.), Theory and Applications of Models of Computation, Springer, Berlin, Heidelberg, 2008, pp. 1–19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib189">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouadrhiri and Abdelhadi (2022)</span>
<span class="ltx_bibblock">
A. E. Ouadrhiri, A. Abdelhadi,

</span>
<span class="ltx_bibblock">Differential Privacy for Deep and Federated Learning: A Survey,

</span>
<span class="ltx_bibblock">IEEE Access 10 (2022) 22359–22380.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib190">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. (2021)</span>
<span class="ltx_bibblock">
N. Agarwal, P. Kairouz, Z. Liu,

</span>
<span class="ltx_bibblock">The Skellam Mechanism for Differentially Private Federated Learning,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 34, Curran Associates, Inc., 2021, pp. 5052–5064.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib191">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2021)</span>
<span class="ltx_bibblock">
M. Kim, O. Günlü, R. F. Schaefer,

</span>
<span class="ltx_bibblock">Federated Learning with Local Differential Privacy:  Trade-Offs Between Privacy, Utility, and Communication,

</span>
<span class="ltx_bibblock">in: ICASSP 2021 - 2021 IEEE International Conference on  Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 2650–2654.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib192">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El-Mhamdi et al. (2023)</span>
<span class="ltx_bibblock">
E.-M. El-Mhamdi, S. Farhadkhani, R. Guerraoui, N. Gupta, L.-N. Hoang, R. Pinot, S. Rouault, J. Stephan, On the Impossible Safety of Large AI Models, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib192.1.1">arXiv:2209.15259</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib193">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Restuccia et al. (2017)</span>
<span class="ltx_bibblock">
F. Restuccia, N. Ghosh, S. Bhattacharjee, S. K. Das, T. Melodia,

</span>
<span class="ltx_bibblock">Quality of Information in Mobile Crowdsensing: Survey and Research Challenges,

</span>
<span class="ltx_bibblock">ACM Transactions on Sensor Networks 13 (2017) 34:1–34:43.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib194">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Strong (1996)</span>
<span class="ltx_bibblock">
R. Y. Wang, D. M. Strong,

</span>
<span class="ltx_bibblock">Beyond Accuracy: What Data Quality Means to Data Consumers ,

</span>
<span class="ltx_bibblock">Journal of Management Information Systems 12 (1996) 5–33. <span class="ltx_text ltx_font_typewriter" id="bib.bib194.1.1">arXiv:40398176</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib195">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamport et al. (1982)</span>
<span class="ltx_bibblock">
L. Lamport, R. Shostak, M. Pease,

</span>
<span class="ltx_bibblock">The Byzantine Generals Problem,

</span>
<span class="ltx_bibblock">ACM Transactions on Programming Languages and Systems 4 (1982) 382–401.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib196">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su and Vaidya (2016)</span>
<span class="ltx_bibblock">
L. Su, N. H. Vaidya,

</span>
<span class="ltx_bibblock">Robust Multi-agent Optimization: Coping with Byzantine Agents with Input Redundancy,

</span>
<span class="ltx_bibblock">in: B. Bonakdarpour, F. Petit (Eds.), Stabilization, Safety, and Security of Distributed Systems, Springer International Publishing, Cham, 2016, pp. 368–382.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib197">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard et al. (2017)</span>
<span class="ltx_bibblock">
P. Blanchard, E. M. El Mhamdi, R. Guerraoui, J. Stainer,

</span>
<span class="ltx_bibblock">Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 30, Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib198">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. (2023)</span>
<span class="ltx_bibblock">
G. Yan, H. Wang, X. Yuan, J. Li,

</span>
<span class="ltx_bibblock">DeFL: Defending against Model Poisoning Attacks in  Federated Learning via Critical Learning Periods Awareness,

</span>
<span class="ltx_bibblock">Proceedings of the AAAI Conference on Artificial Intelligence 37 (2023) 10711–10719.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib199">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El-Mhamdi et al. (2020)</span>
<span class="ltx_bibblock">
E.-M. El-Mhamdi, R. Guerraoui, A. Guirguis, L. N. Hoang, S. Rouault,

</span>
<span class="ltx_bibblock">Genuinely Distributed Byzantine Machine Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 39th Symposium on Principles of  Distributed Computing, ACM, Virtual Event Italy, 2020, pp. 355–364.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib200">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shejwalkar and Houmansadr (2021)</span>
<span class="ltx_bibblock">
V. Shejwalkar, A. Houmansadr,

</span>
<span class="ltx_bibblock">Manipulating the Byzantine: Optimizing Model Poisoning Attacks  and Defenses for Federated Learning,

</span>
<span class="ltx_bibblock">in: Proceedings 2021 Network and Distributed System Security Symposium, Internet Society, Virtual, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib201">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. (2020)</span>
<span class="ltx_bibblock">
M. Fang, X. Cao, J. Jia, N. Z. Gong,

</span>
<span class="ltx_bibblock">Local model poisoning attacks to byzantine-robust federated learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 29th USENIX Conference on Security Symposium, SEC’20, USENIX Association, USA, 2020, pp. 1623–1640.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib202">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Farhadkhani et al. (2022)</span>
<span class="ltx_bibblock">
S. Farhadkhani, R. Guerraoui, L. N. Hoang, O. Villemaud,

</span>
<span class="ltx_bibblock">An Equivalence Between Data Poisoning and Byzantine Gradient Attacks,

</span>
<span class="ltx_bibblock">in: Proceedings of the 39th International Conference on Machine Learning, PMLR, 2022, pp. 6284–6323.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib203">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El-Mhamdi et al. (2021)</span>
<span class="ltx_bibblock">
E. M. El-Mhamdi, S. Farhadkhani, R. Guerraoui, A. Guirguis, L.-N. Hoang, S. b. Rouault,

</span>
<span class="ltx_bibblock">Collaborative Learning in the Jungle (Decentralized,  Byzantine, Heterogeneous, Asynchronous and Nonconvex Learning),

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 34, Curran Associates, Inc., 2021, pp. 25044–25057.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib204">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2018)</span>
<span class="ltx_bibblock">
C. Xie, O. Koyejo, I. Gupta, Generalized Byzantine-tolerant SGD, 2018. <span class="ltx_text ltx_font_typewriter" id="bib.bib204.1.1">arXiv:1802.10116</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib205">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2019)</span>
<span class="ltx_bibblock">
L. Li, W. Xu, T. Chen, G. B. Giannakis, Q. Ling,

</span>
<span class="ltx_bibblock">RSA: Byzantine-Robust Stochastic Aggregation Methods for  Distributed Learning from Heterogeneous Datasets,

</span>
<span class="ltx_bibblock">Proceedings of the AAAI Conference on Artificial Intelligence 33 (2019) 1544–1551.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib206">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al. (2020)</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, V. Shmatikov,

</span>
<span class="ltx_bibblock">How To Backdoor Federated Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the Twenty Third International Conference on  Artificial Intelligence and Statistics, PMLR, 2020, pp. 2938–2948.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib207">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
X. Chen, C. Liu, B. Li, K. Lu, D. Song, Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning, 2017. <span class="ltx_text ltx_font_typewriter" id="bib.bib207.1.1">arXiv:1712.05526</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib208">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolpegin et al. (2020)</span>
<span class="ltx_bibblock">
V. Tolpegin, S. Truex, M. E. Gursoy, L. Liu,

</span>
<span class="ltx_bibblock">Data Poisoning Attacks Against Federated Learning Systems,

</span>
<span class="ltx_bibblock">in: L. Chen, N. Li, K. Liang, S. Schneider (Eds.), Computer Security – ESORICS 2020, Springer International Publishing, Cham, 2020, pp. 480–501.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib209">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shafahi et al. (2018)</span>
<span class="ltx_bibblock">
A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras, T. Goldstein,

</span>
<span class="ltx_bibblock">Poison Frogs! Targeted Clean-Label Poisoning Attacks on  Neural Networks,

</span>
<span class="ltx_bibblock">in: Advances in Neural Information Processing Systems, volume 31, Curran Associates, Inc., 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib210">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2021)</span>
<span class="ltx_bibblock">
J. Zhang, B. Chen, X. Cheng, H. T. T. Binh, S. Yu,

</span>
<span class="ltx_bibblock">PoisonGAN: Generative Poisoning Attacks Against Federated Learning in Edge Computing Systems,

</span>
<span class="ltx_bibblock">IEEE Internet of Things Journal 8 (2021) 3310–3322.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib211">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
J. Zhang, J. Chen, D. Wu, B. Chen, S. Yu,

</span>
<span class="ltx_bibblock">Poisoning Attack in Federated Learning using Generative Adversarial Nets,

</span>
<span class="ltx_bibblock">in: 2019 18th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering ( TrustCom/BigDataSE), 2019, pp. 374–380.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib212">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shejwalkar et al. (2022)</span>
<span class="ltx_bibblock">
V. Shejwalkar, A. Houmansadr, P. Kairouz, D. Ramage,

</span>
<span class="ltx_bibblock">Back to the Drawing Board: A Critical Evaluation of  Poisoning Attacks on Production Federated Learning,

</span>
<span class="ltx_bibblock">in: 2022 IEEE Symposium on Security and Privacy (SP), 2022, pp. 1354–1371.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib213">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2021)</span>
<span class="ltx_bibblock">
Y. Wu, H. Chen, X. Wang, C. Liu, P. Nguyen, Y. Yesha,

</span>
<span class="ltx_bibblock">Tolerating Adversarial Attacks and Byzantine Faults in  Distributed Machine Learning,

</span>
<span class="ltx_bibblock">in: 2021 IEEE International Conference on Big Data (Big Data), 2021, pp. 3380–3389.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib214">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Damaskinos et al. (2018)</span>
<span class="ltx_bibblock">
G. Damaskinos, E. M. E. Mhamdi, R. Guerraoui, R. Patra, M. Taziki,

</span>
<span class="ltx_bibblock">Asynchronous Byzantine Machine Learning (the case of SGD),

</span>
<span class="ltx_bibblock">in: Proceedings of the 35th International Conference on Machine Learning, PMLR, 2018, pp. 1145–1154.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib215">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mhamdi et al. (2018)</span>
<span class="ltx_bibblock">
E. M. E. Mhamdi, R. Guerraoui, S. Rouault,

</span>
<span class="ltx_bibblock">The Hidden Vulnerability of Distributed Learning in  Byzantium,

</span>
<span class="ltx_bibblock">in: Proceedings of the 35th International Conference on Machine Learning, PMLR, 2018, pp. 3521–3530.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib216">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minsker (2015)</span>
<span class="ltx_bibblock">
S. Minsker,

</span>
<span class="ltx_bibblock">Geometric median and robust estimation in Banach spaces,

</span>
<span class="ltx_bibblock">Bernoulli 21 (2015) 2308–2335.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib217">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2018)</span>
<span class="ltx_bibblock">
D. Yin, Y. Chen, R. Kannan, P. Bartlett,

</span>
<span class="ltx_bibblock">Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,

</span>
<span class="ltx_bibblock">in: Proceedings of the 35th International Conference on Machine Learning, PMLR, 2018, pp. 5650–5659.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib218">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2019)</span>
<span class="ltx_bibblock">
Q. Xia, Z. Tao, Z. Hao, Q. Li,

</span>
<span class="ltx_bibblock">FABA: An Algorithm for Fast Aggregation against  Byzantine Attacks in Distributed Neural Networks,

</span>
<span class="ltx_bibblock">IJCAI (2019).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib219">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Z. Wu, T. Chen, Q. Ling,

</span>
<span class="ltx_bibblock">Byzantine-Resilient Decentralized Stochastic Optimization With Robust Aggregation Rules,

</span>
<span class="ltx_bibblock">IEEE Transactions on Signal Processing 71 (2023) 3179–3195.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib220">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et al. (2020)</span>
<span class="ltx_bibblock">
C. Fung, C. J. M. Yoon, I. Beschastnikh, Mitigating Sybils in Federated Learning Poisoning, 2020. <span class="ltx_text ltx_font_typewriter" id="bib.bib220.1.1">arXiv:1808.04866</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib221">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. (2019)</span>
<span class="ltx_bibblock">
D. Cao, S. Chang, Z. Lin, G. Liu, D. Sun,

</span>
<span class="ltx_bibblock">Understanding Distributed Poisoning Attack in Federated Learning,

</span>
<span class="ltx_bibblock">in: 2019 IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS), IEEE, Tianjin, China, 2019, pp. 233–239.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib222">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Byabazaire et al. (2020)</span>
<span class="ltx_bibblock">
J. Byabazaire, G. O’Hare, D. Delaney,

</span>
<span class="ltx_bibblock">Using Trust as a Measure to Derive Data Quality in Data Shared IoT Deployments,

</span>
<span class="ltx_bibblock">in: 2020 29th International Conference on Computer Communications and Networks (ICCCN), 2020, pp. 1–9.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib223">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chuprov et al. (2020)</span>
<span class="ltx_bibblock">
S. Chuprov, I. Viksnin, I. Kim, L. Reznikand, I. Khokhlov,

</span>
<span class="ltx_bibblock">Reputation and Trust Models with Data Quality Metrics for  Improving Autonomous Vehicles Traffic Security and Safety,

</span>
<span class="ltx_bibblock">in: 2020 IEEE Systems Security Symposium (SSS), 2020, pp. 1–8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib224">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2021)</span>
<span class="ltx_bibblock">
H. Jia, M. Yaghini, C. A. Choquette-Choo, N. Dullerud, A. Thudi, V. Chandrasekaran, N. Papernot,

</span>
<span class="ltx_bibblock">Proof-of-Learning: Definitions and Practice,

</span>
<span class="ltx_bibblock">in: 2021 IEEE Symposium on Security and Privacy (SP), 2021, pp. 1039–1056.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib225">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garg et al. (2023)</span>
<span class="ltx_bibblock">
S. Garg, A. Goel, S. Jha, S. Mahloujifar, M. Mahmoody, G.-V. Policharla, M. Wang,

</span>
<span class="ltx_bibblock">Experimenting with Zero-Knowledge Proofs of Training,

</span>
<span class="ltx_bibblock">in: Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security, ACM, Copenhagen Denmark, 2023, pp. 1880–1894.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib226">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al. (2021)</span>
<span class="ltx_bibblock">
S. P. Karimireddy, L. He, M. Jaggi,

</span>
<span class="ltx_bibblock">Learning from History for Byzantine Robust Optimization,

</span>
<span class="ltx_bibblock">in: Proceedings of the 38th International Conference on Machine Learning, PMLR, 2021, pp. 5311–5319.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib227">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
S. Wu, S. Chen, C. Xie, X. Huang, One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks, 2023. <span class="ltx_text ltx_font_typewriter" id="bib.bib227.1.1">arXiv:2205.12141</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib228">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geirhos et al. (2020)</span>
<span class="ltx_bibblock">
R. Geirhos, t. link will open in a new tab Link to external site, J. Jörn-Henrik, C. Michaelis, t. link will open in a new tab Link to external site, R. Zemel, B. Wieland, B. Matthias, F. A. Wichmann, t. link will open in a new tab Link to external site,

</span>
<span class="ltx_bibblock">Shortcut learning in deep neural networks,

</span>
<span class="ltx_bibblock">Nature Machine Intelligence 2 (2020) 665–673.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib229">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
L. Wang, J. Liu, Q. He,

</span>
<span class="ltx_bibblock">Concept Drift-Based Checkpoint-Restart for Edge Services Rejuvenation,

</span>
<span class="ltx_bibblock">IEEE Transactions on Services Computing 16 (2023) 1713–1725.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib230">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guastella et al. (2021)</span>
<span class="ltx_bibblock">
D. A. Guastella, G. Marcillaud, C. Valenti,

</span>
<span class="ltx_bibblock">Edge-Based Missing Data Imputation in Large-Scale Environments ,

</span>
<span class="ltx_bibblock">Information 12 (2021) 195.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib231">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izzo et al. (2023)</span>
<span class="ltx_bibblock">
Z. Izzo, L. Ying, J. Zou, S. Chatterjee, Theory and Algorithms for Data-Centric Machine Learning, Ph.D. thesis, Stanford University, Stanford, California, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib232">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al. (2021)</span>
<span class="ltx_bibblock">
Z. Qi, H. Wang, J. Li, H. Gao, Impacts of Dirty Data: And Experimental Evaluation, 2021. <span class="ltx_text ltx_font_typewriter" id="bib.bib232.1.1">arXiv:1803.06071</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib233">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2022)</span>
<span class="ltx_bibblock">
X. Zhou, Y. Lin, R. Pi, W. Zhang, R. Xu, P. Cui, T. Zhang,

</span>
<span class="ltx_bibblock">Model Agnostic Sample Reweighting for Out-of-Distribution Learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 39th International Conference on Machine Learning, PMLR, 2022, pp. 27203–27221.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_centering ltx_role_newpage"></div>
</div>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Jun  1 23:04:36 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
