<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.00635] Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data</title><meta property="og:description" content="AI-based data synthesis has seen rapid progress over the last several years, and is increasingly recognized for its promise to enable privacy-respecting high-fidelity data sharing. However, adequately evaluating the quâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.00635">

<!--Generated on Sun Mar 17 01:05:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Michael Platzer 
<br class="ltx_break">MOSTLY AI 
<br class="ltx_break">Vienna, Austria 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">michael.platzer@mostly.ai</span> 
<br class="ltx_break">&amp;Thomas Reutterer 
<br class="ltx_break">Vienna University of Economics and Business 
<br class="ltx_break">Vienna, Austria 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">thomas.reutterer@wu.ac.at</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">AI-based data synthesis has seen rapid progress over the last several years, and is increasingly recognized for its promise to enable privacy-respecting high-fidelity data sharing. However, adequately evaluating the quality of generated synthetic datasets is still an open challenge. We introduce and demonstrate a holdout-based empirical assessment framework for quantifying the fidelity as well as the privacy risk of synthetic data solutions for mixed-type tabular data. Measuring fidelity is based on statistical distances of lower-dimensional marginal distributions, which provide a model-free and easy-to-communicate empirical metric for the representativeness of a synthetic dataset. Privacy risk is assessed by calculating the individual-level distances to closest record with respect to the training data. By showing that the synthetic samples are just as close to the training as to the holdout data, we yield strong evidence that the synthesizer indeed learned to generalize patterns and is independent of individual training records. We demonstrate the presented framework for seven distinct synthetic data solutions across four mixed-type datasets and compare these to more traditional statistical disclosure techniques. The results highlight the need to systematically assess the fidelity just as well as the privacy of these emerging class of synthetic data generators.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Self-supervised generative AI has made significant progress over the past years, with algorithms capable of creating â€œshockinglyâ€ realistic synthetic data across a range of domains. Demonstrations like are particularly impressive within domains of unstructured data, like images <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2017</a>)</cite> and text <cite class="ltx_cite ltx_citemacro_citep">(Brown etÂ al., <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>. These samples demonstrate that it is becoming increasingly difficult for us humans, as well as for machines, to discriminate actual from machine-generated fake data. While less prominent, similar progress is made within structured data domains, such as synthesizing medical health records <cite class="ltx_cite ltx_citemacro_citep">(Choi etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Krauland etÂ al., <a href="#bib.bib21" title="" class="ltx_ref">2020</a>; Goncalves etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>, census data <cite class="ltx_cite ltx_citemacro_citep">(Freiman etÂ al., <a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite>, human genoms <cite class="ltx_cite ltx_citemacro_citep">(Yelmen etÂ al., <a href="#bib.bib36" title="" class="ltx_ref">2021</a>)</cite>, website traffic <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al., <a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> or financial transactions <cite class="ltx_cite ltx_citemacro_citep">(Assefa, <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. These advances are particularly remarkable considering that they do not build upon our own human understanding of the world, but â€œmerelyâ€ require a flexible, scalable self-supervised learning algorithm that teaches itself to create novel records based on a sufficient amount of training data.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Given this new capability to generate arbitrary amounts of new data, many applications arise and provide rich opportunities. These range from automated content creation <cite class="ltx_cite ltx_citemacro_citep">(Shu etÂ al., <a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite>, test data generation <cite class="ltx_cite ltx_citemacro_citep">(PopiÄ‡ etÂ al., <a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite>, world simulations for accelerated learning <cite class="ltx_cite ltx_citemacro_citep">(Ha &amp; Schmidhuber, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>, to general-purpose privacy-safe data sharing <cite class="ltx_cite ltx_citemacro_citep">(Surendra &amp; MohanH, <a href="#bib.bib32" title="" class="ltx_ref">2017</a>; Howe etÂ al., <a href="#bib.bib18" title="" class="ltx_ref">2017</a>; Bellovin etÂ al., <a href="#bib.bib4" title="" class="ltx_ref">2019</a>; Hittmeir etÂ al., <a href="#bib.bib15" title="" class="ltx_ref">2019</a>; Li etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">We focus on the data sharing use cases, where data owners seek to provide highly accurate, yet truly anonymous statistical representations of datasets. AI-based approaches for generating synthetic data provide a promising novel tool box for data stewards in the field of statistical disclosure control (SDC) <cite class="ltx_cite ltx_citemacro_citep">(Drechsler, <a href="#bib.bib7" title="" class="ltx_ref">2011</a>)</cite>, but just as more traditional methodologies also share the fundamental need to balance data utility against disclosure risk. One can maximize utility by releasing the full original dataset, but would thereby expose the privacy of all contained data subjects. On the other hand, one can easily minimize the risk by releasing no data at all, which naturally yields zero utility. It is this privacy-utility trade-off that we seek to quantify for mixed-type synthetic data by introducing the empirical assessment framework proposed in this paper. After briefly discussing the background we present the building blocks of the proposed framework in section <a href="#S3" title="3 Framework â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This will then allow us to compare the performance of generative models from the rapidly growing field of synthetic data approaches against each other, as well as against alternative SDC techniques in section <a href="#S4" title="4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">The field of generative AI gained strong momentum ever since the introduction of Generative Adversarial Networks <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow etÂ al., <a href="#bib.bib13" title="" class="ltx_ref">2014</a>)</cite> and its application to image synthesis. This seminal and widely cited paper assessed synthetic data quality by fitting Gaussian Parzen windows to the generated samples in order to estimate the log-likelihood of holdout samples. At that time the authors already called out for further research to assess synthetic data, as they highlighted the limitations of Parzen window estimates for higher dimensional domains, which are then also further confirmed by <cite class="ltx_cite ltx_citemacro_cite">Theis etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2015</a>)</cite>. In addition to quantitative assessments, nearly all of the research advances for image synthesis also present non-cherry picked synthetic samples as an indicator for quality (see e.g., <cite class="ltx_cite ltx_citemacro_citet">Karras etÂ al. <a href="#bib.bib20" title="" class="ltx_ref">2017</a>; Liu &amp; Tuzel <a href="#bib.bib24" title="" class="ltx_ref">2016</a>; Radford etÂ al. <a href="#bib.bib30" title="" class="ltx_ref">2015</a></cite>). While these allow to visually judge plausibility of the generated data, they do not allow to capture a generatorâ€™s ability to faithfully represent the full variety and richness of a dataset, i.e. its dataset-level statistics. On the contrary, by overly focusing on â€œrealisticâ€ sample records in the assessment, one will potentially favor generators that bias towards conservative, safe-bet samples, at the cost of diversity and representativeness.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Temperature-based sampling <cite class="ltx_cite ltx_citemacro_citep">(Ackley etÂ al., <a href="#bib.bib1" title="" class="ltx_ref">1985</a>)</cite>, top-k sampling <cite class="ltx_cite ltx_citemacro_citep">(Fan etÂ al., <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>, and nucleus sampling <cite class="ltx_cite ltx_citemacro_citep">(Holtzman etÂ al., <a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite> are all techniques to make such trade-offs explicitly, and are commonly applied for synthetic text generation.</span></span></span></p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">For structured data a popular and intuitive approach is to visually compare histograms and correlation plots (see e.g., <cite class="ltx_cite ltx_citemacro_citet">Lu etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2019</a>; Howe etÂ al. <a href="#bib.bib18" title="" class="ltx_ref">2017</a></cite>). While this does allow to capture representativeness, it typically is being applied to only a small subset of statistics, and misses out on systematically quantifying any discrepancies thereof.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">A popular assessment technique common to both structured as well as unstructured domains is to train a supervised machine learning task on the generated synthetic data and see how its predictive accuracy fairs against the same model being trained on real data <cite class="ltx_cite ltx_citemacro_citep">(Jordon etÂ al., <a href="#bib.bib19" title="" class="ltx_ref">2018</a>; Xu etÂ al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>. By validating against an actual holdout dataset, that is not used for the data synthesis itself, one gets an indication for the information loss for a specific relationship within the data incurred due to the synthesis. If the chosen predictive task is difficult enough and a capable downstream machine learning model is used, this can indeed yield a strong measure. However, results will depend on both of these assumptions, and will vary even for the same dataset from predicted target to predicted target, as it tests only for a singular relationship within the high dimensional data distribution. And more importantly, the measure again does not allow statements regarding the overall statistical representativeness. Any accidentally introduced bias, any artefacts, any misrepresentations within the generated data might remain unnoticed. Yet, all of these are of particular importance when a data owner seeks to disseminate granular-level information with highest possible accuracy, without needing to restrict or even to know the downstream application.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">No accuracy assessment of a synthetic data solution can be complete, if it does not include some measurement of its ability to produce truly novel samples, rather than merely memorizing and recreating actual data. Closely related, users of synthetic data solutions seek to establish the privacy of a generated dataset. I.e. whether the synthetic dataset is considered to be anonymous, non-personal data in a legal sense. With data protection regulations varying from country to country, and industry to industry, any ultimate assessment requires legal expertise and can only be done with respect to a given regulation. However, there are a growing number of technical definitions and assessments of privacy being introduced, that serve practitioners well to make the legal case. Two commonly used concepts within the context of synthetic data are empirical attribute disclosure assessments <cite class="ltx_cite ltx_citemacro_citep">(Hittmeir etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>; Taub etÂ al., <a href="#bib.bib33" title="" class="ltx_ref">2018</a>)</cite>, and Differential Privacy <cite class="ltx_cite ltx_citemacro_citep">(Dwork etÂ al., <a href="#bib.bib9" title="" class="ltx_ref">2006</a>)</cite>. Both of these have proven to be useful in establishing trust in the safety of synthetic data, yet come with their own challenges in practice. While the former requires computationally intensive, case-specific repeated synthetization re-runs that can become infeasible to perform on a continuous base, the latter requires the inspection of the algorithms as well as their actual implementations for these to be validated. We seek to contribute to the growing list of privacy concepts by proposing an easy-to-compute holdout-based empirical assessment, that does not rely on knowledge of the underlying synthetization process.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Framework</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Fidelity</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">We start out by motivating our introduced fidelity measure by visualizing selected distributions and cross-tabulations for the â€˜adultâ€˜ dataset, which we will use later in our empirical demonstration study. Figure <a href="#S3.F1" title="Figure 1 â€£ 3.1 Fidelity â€£ 3 Framework â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> exhibits the distribution of four selected numeric attributes and shows the wide variety of shapes that can occur in real-world datasets. For example, the numeric attribute â€˜ageâ€˜ ranges from 17 and 90, with a small cluster of subjects that are exactly 90 years old, while hardly any subject is between 85 and 89 years old. The Numeric attribute â€˜fnlwgtâ€˜ spans a much wider range, with nearly all observed values being unique within the dataset. Thus these values need to be binned to visualize the shape of the variableâ€™s distribution. Attribute â€˜hours-per-weekâ€˜ is characterized by specific outstanding integer values, while â€˜capital-gainâ€˜ is dominated by zeros with only a few exceptions that themselves can range up to 100â€™000. We would want to see synthesizers faithfully retain any of these different types and shapes of univariate distributional patterns and thus need a fidelity measure that can capture any discrepancies thereof.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2104.00635/assets/fig3-adult-univariate.png" id="S3.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="287" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Selected univariate marginal distributions for dataset â€˜adultâ€˜</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.4" class="ltx_p">However, synthetic data shall not only be representative for the distribution of individual attributes, but for all multivariate combinations and relationships among the set of attributes. For example, figure <a href="#S3.F2" title="Figure 2 â€£ 3.1 Fidelity â€£ 3 Framework â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> displays three selected bivariate distributions for the dataset â€˜adultâ€˜, each with distinct patterns and insights that are to be retained and assessed. The challenge for deriving a metric that accommodates these interdependencies in an adequate way is that the number of relationships to investigate grows quickly with the number of attributes. More specifically, a dataset with <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">m</annotation></semantics></math> attributes results in <math id="S3.SS1.p2.2.m2.2" class="ltx_Math" alttext="\binom{m}{k}" display="inline"><semantics id="S3.SS1.p2.2.m2.2a"><mrow id="S3.SS1.p2.2.m2.2.2.4" xref="S3.SS1.p2.2.m2.2.2.3.cmml"><mo id="S3.SS1.p2.2.m2.2.2.4.1" xref="S3.SS1.p2.2.m2.2.2.3.1.cmml">(</mo><mfrac linethickness="0pt" id="S3.SS1.p2.2.m2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.3.cmml"><mi id="S3.SS1.p2.2.m2.1.1.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml">m</mi><mi id="S3.SS1.p2.2.m2.2.2.2.2.2.1" xref="S3.SS1.p2.2.m2.2.2.2.2.2.1.cmml">k</mi></mfrac><mo id="S3.SS1.p2.2.m2.2.2.4.2" xref="S3.SS1.p2.2.m2.2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><apply id="S3.SS1.p2.2.m2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.4"><csymbol cd="latexml" id="S3.SS1.p2.2.m2.2.2.3.1.cmml" xref="S3.SS1.p2.2.m2.2.2.4.1">binomial</csymbol><ci id="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1">ğ‘š</ci><ci id="S3.SS1.p2.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.2.1">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">\binom{m}{k}</annotation></semantics></math> combinations of <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">k</annotation></semantics></math>-way interactions. For example, for 50 attributes this yields 1â€™225 two-way, and 19â€™600 three-way interactions. Ideally, we would want to compare the full joint empirical distributions (<math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="m=k" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">m</mi><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">=</mo><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><eq id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></eq><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">ğ‘š</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">m=k</annotation></semantics></math>) between the actual and synthetic data, but that is, except for the most trivial cases, infeasible in practice. The curse of dimensionality <cite class="ltx_cite ltx_citemacro_citep">(Bellman, <a href="#bib.bib3" title="" class="ltx_ref">1966</a>)</cite> strikes here again; i.e., the number of cross-combinations of attribute values grows exponentially as more attributes are considered, resulting in the available data becoming too sparse in a high-dimensional data space. While binning and grouping of attribute values mitigates the issue for the lower-level interactions, this fundamental principle cannot be defeated for deeper levels. Thus we propose as a practical, model- and assumption-free approach to empirically measure the fidelity of a synthetic dataset with respect to a target dataset by averaging across the total variation distances<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The total variation distance equals half the <math id="footnote2.m1.1" class="ltx_Math" alttext="L_{1}" display="inline"><semantics id="footnote2.m1.1b"><msub id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml"><mi id="footnote2.m1.1.1.2" xref="footnote2.m1.1.1.2.cmml">L</mi><mn id="footnote2.m1.1.1.3" xref="footnote2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><apply id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1"><csymbol cd="ambiguous" id="footnote2.m1.1.1.1.cmml" xref="footnote2.m1.1.1">subscript</csymbol><ci id="footnote2.m1.1.1.2.cmml" xref="footnote2.m1.1.1.2">ğ¿</ci><cn type="integer" id="footnote2.m1.1.1.3.cmml" xref="footnote2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">L_{1}</annotation></semantics></math>-distance for the discretized distributions at hand. We explored other distance measures for empirical distributions, like the maximum absolute error, euclidean distances, the Jensen-Shannon distance or the Hellinger distance, but they yielded practically identical rankings for the empirical benchmarks. However, the TVD is easy to communicate, easy to reason about and has exhibited in our experiments a low sensitivity with respect to sampling noise.</span></span></span> (TVD) of the corresponding discretized, lower-level empirical marginal distributions.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2104.00635/assets/fig4-adult-bivariate.png" id="S3.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="318" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Selected bivariate marginal distributions for dataset â€˜adultâ€˜</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.12" class="ltx_p">The construction of our proposed fidelity metric proceeds as follows: Letâ€™s consider a random split of the available records into a training dataset <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">T</annotation></semantics></math> and a holdout dataset <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ğ»</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">H</annotation></semantics></math>. We only expose the training data <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">T</annotation></semantics></math> to a synthesizer which yields a synthetic dataset <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">S</annotation></semantics></math> of arbitrary size <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="n_{S}" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">n</mi><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">ğ‘›</ci><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">n_{S}</annotation></semantics></math>. Further, letâ€™s transform each of the attributes of these datasets into categorical variables, that have a fixed upper bound <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">c</annotation></semantics></math> for their cardinality. For those categorical variables that have cardinality <math id="S3.SS1.p3.7.m7.1" class="ltx_Math" alttext="c_{j}&gt;c" display="inline"><semantics id="S3.SS1.p3.7.m7.1a"><mrow id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml"><msub id="S3.SS1.p3.7.m7.1.1.2" xref="S3.SS1.p3.7.m7.1.1.2.cmml"><mi id="S3.SS1.p3.7.m7.1.1.2.2" xref="S3.SS1.p3.7.m7.1.1.2.2.cmml">c</mi><mi id="S3.SS1.p3.7.m7.1.1.2.3" xref="S3.SS1.p3.7.m7.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.p3.7.m7.1.1.1" xref="S3.SS1.p3.7.m7.1.1.1.cmml">&gt;</mo><mi id="S3.SS1.p3.7.m7.1.1.3" xref="S3.SS1.p3.7.m7.1.1.3.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><apply id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1"><gt id="S3.SS1.p3.7.m7.1.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1.1"></gt><apply id="S3.SS1.p3.7.m7.1.1.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.1.1.2.1.cmml" xref="S3.SS1.p3.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.7.m7.1.1.2.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p3.7.m7.1.1.2.3.cmml" xref="S3.SS1.p3.7.m7.1.1.2.3">ğ‘—</ci></apply><ci id="S3.SS1.p3.7.m7.1.1.3.cmml" xref="S3.SS1.p3.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">c_{j}&gt;c</annotation></semantics></math>, we lump together the <math id="S3.SS1.p3.8.m8.1" class="ltx_Math" alttext="(c_{j}-c+1)" display="inline"><semantics id="S3.SS1.p3.8.m8.1a"><mrow id="S3.SS1.p3.8.m8.1.1.1" xref="S3.SS1.p3.8.m8.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p3.8.m8.1.1.1.2" xref="S3.SS1.p3.8.m8.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p3.8.m8.1.1.1.1" xref="S3.SS1.p3.8.m8.1.1.1.1.cmml"><mrow id="S3.SS1.p3.8.m8.1.1.1.1.2" xref="S3.SS1.p3.8.m8.1.1.1.1.2.cmml"><msub id="S3.SS1.p3.8.m8.1.1.1.1.2.2" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2.cmml"><mi id="S3.SS1.p3.8.m8.1.1.1.1.2.2.2" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2.2.cmml">c</mi><mi id="S3.SS1.p3.8.m8.1.1.1.1.2.2.3" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2.3.cmml">j</mi></msub><mo id="S3.SS1.p3.8.m8.1.1.1.1.2.1" xref="S3.SS1.p3.8.m8.1.1.1.1.2.1.cmml">âˆ’</mo><mi id="S3.SS1.p3.8.m8.1.1.1.1.2.3" xref="S3.SS1.p3.8.m8.1.1.1.1.2.3.cmml">c</mi></mrow><mo id="S3.SS1.p3.8.m8.1.1.1.1.1" xref="S3.SS1.p3.8.m8.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.8.m8.1.1.1.1.3" xref="S3.SS1.p3.8.m8.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS1.p3.8.m8.1.1.1.3" xref="S3.SS1.p3.8.m8.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><apply id="S3.SS1.p3.8.m8.1.1.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1.1"><plus id="S3.SS1.p3.8.m8.1.1.1.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.1"></plus><apply id="S3.SS1.p3.8.m8.1.1.1.1.2.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2"><minus id="S3.SS1.p3.8.m8.1.1.1.1.2.1.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2.1"></minus><apply id="S3.SS1.p3.8.m8.1.1.1.1.2.2.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p3.8.m8.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2.2">ğ‘</ci><ci id="S3.SS1.p3.8.m8.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2.2.3">ğ‘—</ci></apply><ci id="S3.SS1.p3.8.m8.1.1.1.1.2.3.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S3.SS1.p3.8.m8.1.1.1.1.3.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">(c_{j}-c+1)</annotation></semantics></math> least frequent values into a single group. For numeric variables we apply quantile binning, i.e., cut the range of values into a maximum of <math id="S3.SS1.p3.9.m9.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p3.9.m9.1a"><mi id="S3.SS1.p3.9.m9.1.1" xref="S3.SS1.p3.9.m9.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m9.1b"><ci id="S3.SS1.p3.9.m9.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m9.1c">c</annotation></semantics></math> ranges, based on their <math id="S3.SS1.p3.10.m10.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p3.10.m10.1a"><mi id="S3.SS1.p3.10.m10.1.1" xref="S3.SS1.p3.10.m10.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.10.m10.1b"><ci id="S3.SS1.p3.10.m10.1.1.cmml" xref="S3.SS1.p3.10.m10.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.10.m10.1c">c</annotation></semantics></math> quantiles. Any date or datetime variable is to be converted first into a numeric representation before applying the same transformation as suggested above. Any missing values are treated as yet another categorical value, thus can increase cardinality to <math id="S3.SS1.p3.11.m11.1" class="ltx_Math" alttext="c+1" display="inline"><semantics id="S3.SS1.p3.11.m11.1a"><mrow id="S3.SS1.p3.11.m11.1.1" xref="S3.SS1.p3.11.m11.1.1.cmml"><mi id="S3.SS1.p3.11.m11.1.1.2" xref="S3.SS1.p3.11.m11.1.1.2.cmml">c</mi><mo id="S3.SS1.p3.11.m11.1.1.1" xref="S3.SS1.p3.11.m11.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.11.m11.1.1.3" xref="S3.SS1.p3.11.m11.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.11.m11.1b"><apply id="S3.SS1.p3.11.m11.1.1.cmml" xref="S3.SS1.p3.11.m11.1.1"><plus id="S3.SS1.p3.11.m11.1.1.1.cmml" xref="S3.SS1.p3.11.m11.1.1.1"></plus><ci id="S3.SS1.p3.11.m11.1.1.2.cmml" xref="S3.SS1.p3.11.m11.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS1.p3.11.m11.1.1.3.cmml" xref="S3.SS1.p3.11.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.11.m11.1c">c+1</annotation></semantics></math> for those variables that contain missing values. Note, that the required statistics for the discretization, i.e., the list of least frequent values as well as the quantiles, are to be determined based on the training dataset <math id="S3.SS1.p3.12.m12.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p3.12.m12.1a"><mi id="S3.SS1.p3.12.m12.1.1" xref="S3.SS1.p3.12.m12.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.12.m12.1b"><ci id="S3.SS1.p3.12.m12.1.1.cmml" xref="S3.SS1.p3.12.m12.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.12.m12.1c">T</annotation></semantics></math> alone, and then reused for the discretization of the other datasets.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.11" class="ltx_p">We then proceed in calculating relative frequencies for all <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">k</annotation></semantics></math>-way interactions for the discretized <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">m</annotation></semantics></math> attributes and do so for both the training dataset <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">T</annotation></semantics></math> and the synthetic dataset <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mi id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">S</annotation></semantics></math>. For each <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><mi id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><ci id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">k</annotation></semantics></math>-way interaction we calculate the TVD between the two corresponding empirical marginal distributions and then average across all <math id="S3.SS1.p4.6.m6.2" class="ltx_Math" alttext="\binom{m}{k}" display="inline"><semantics id="S3.SS1.p4.6.m6.2a"><mrow id="S3.SS1.p4.6.m6.2.2.4" xref="S3.SS1.p4.6.m6.2.2.3.cmml"><mo id="S3.SS1.p4.6.m6.2.2.4.1" xref="S3.SS1.p4.6.m6.2.2.3.1.cmml">(</mo><mfrac linethickness="0pt" id="S3.SS1.p4.6.m6.2.2.2.2" xref="S3.SS1.p4.6.m6.2.2.3.cmml"><mi id="S3.SS1.p4.6.m6.1.1.1.1.1.1" xref="S3.SS1.p4.6.m6.1.1.1.1.1.1.cmml">m</mi><mi id="S3.SS1.p4.6.m6.2.2.2.2.2.1" xref="S3.SS1.p4.6.m6.2.2.2.2.2.1.cmml">k</mi></mfrac><mo id="S3.SS1.p4.6.m6.2.2.4.2" xref="S3.SS1.p4.6.m6.2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.2b"><apply id="S3.SS1.p4.6.m6.2.2.3.cmml" xref="S3.SS1.p4.6.m6.2.2.4"><csymbol cd="latexml" id="S3.SS1.p4.6.m6.2.2.3.1.cmml" xref="S3.SS1.p4.6.m6.2.2.4.1">binomial</csymbol><ci id="S3.SS1.p4.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1.1.1.1.1">ğ‘š</ci><ci id="S3.SS1.p4.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS1.p4.6.m6.2.2.2.2.2.1">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.2c">\binom{m}{k}</annotation></semantics></math> combinations. This yields a measure <math id="S3.SS1.p4.7.m7.2" class="ltx_Math" alttext="F^{k}(T,S)" display="inline"><semantics id="S3.SS1.p4.7.m7.2a"><mrow id="S3.SS1.p4.7.m7.2.3" xref="S3.SS1.p4.7.m7.2.3.cmml"><msup id="S3.SS1.p4.7.m7.2.3.2" xref="S3.SS1.p4.7.m7.2.3.2.cmml"><mi id="S3.SS1.p4.7.m7.2.3.2.2" xref="S3.SS1.p4.7.m7.2.3.2.2.cmml">F</mi><mi id="S3.SS1.p4.7.m7.2.3.2.3" xref="S3.SS1.p4.7.m7.2.3.2.3.cmml">k</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p4.7.m7.2.3.1" xref="S3.SS1.p4.7.m7.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p4.7.m7.2.3.3.2" xref="S3.SS1.p4.7.m7.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p4.7.m7.2.3.3.2.1" xref="S3.SS1.p4.7.m7.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p4.7.m7.1.1" xref="S3.SS1.p4.7.m7.1.1.cmml">T</mi><mo id="S3.SS1.p4.7.m7.2.3.3.2.2" xref="S3.SS1.p4.7.m7.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p4.7.m7.2.2" xref="S3.SS1.p4.7.m7.2.2.cmml">S</mi><mo stretchy="false" id="S3.SS1.p4.7.m7.2.3.3.2.3" xref="S3.SS1.p4.7.m7.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.2b"><apply id="S3.SS1.p4.7.m7.2.3.cmml" xref="S3.SS1.p4.7.m7.2.3"><times id="S3.SS1.p4.7.m7.2.3.1.cmml" xref="S3.SS1.p4.7.m7.2.3.1"></times><apply id="S3.SS1.p4.7.m7.2.3.2.cmml" xref="S3.SS1.p4.7.m7.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m7.2.3.2.1.cmml" xref="S3.SS1.p4.7.m7.2.3.2">superscript</csymbol><ci id="S3.SS1.p4.7.m7.2.3.2.2.cmml" xref="S3.SS1.p4.7.m7.2.3.2.2">ğ¹</ci><ci id="S3.SS1.p4.7.m7.2.3.2.3.cmml" xref="S3.SS1.p4.7.m7.2.3.2.3">ğ‘˜</ci></apply><interval closure="open" id="S3.SS1.p4.7.m7.2.3.3.1.cmml" xref="S3.SS1.p4.7.m7.2.3.3.2"><ci id="S3.SS1.p4.7.m7.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1">ğ‘‡</ci><ci id="S3.SS1.p4.7.m7.2.2.cmml" xref="S3.SS1.p4.7.m7.2.2">ğ‘†</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.2c">F^{k}(T,S)</annotation></semantics></math>, which quantifies the fidelity of dataset <math id="S3.SS1.p4.8.m8.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p4.8.m8.1a"><mi id="S3.SS1.p4.8.m8.1.1" xref="S3.SS1.p4.8.m8.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m8.1b"><ci id="S3.SS1.p4.8.m8.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m8.1c">S</annotation></semantics></math> with respect to dataset <math id="S3.SS1.p4.9.m9.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p4.9.m9.1a"><mi id="S3.SS1.p4.9.m9.1.1" xref="S3.SS1.p4.9.m9.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.9.m9.1b"><ci id="S3.SS1.p4.9.m9.1.1.cmml" xref="S3.SS1.p4.9.m9.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.9.m9.1c">T</annotation></semantics></math>. In order to help gauge how much information is lost due to the synthetization and how much discrepancies is expected due to sampling noise we shall compare <math id="S3.SS1.p4.10.m10.2" class="ltx_Math" alttext="F^{k}(T,S)" display="inline"><semantics id="S3.SS1.p4.10.m10.2a"><mrow id="S3.SS1.p4.10.m10.2.3" xref="S3.SS1.p4.10.m10.2.3.cmml"><msup id="S3.SS1.p4.10.m10.2.3.2" xref="S3.SS1.p4.10.m10.2.3.2.cmml"><mi id="S3.SS1.p4.10.m10.2.3.2.2" xref="S3.SS1.p4.10.m10.2.3.2.2.cmml">F</mi><mi id="S3.SS1.p4.10.m10.2.3.2.3" xref="S3.SS1.p4.10.m10.2.3.2.3.cmml">k</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p4.10.m10.2.3.1" xref="S3.SS1.p4.10.m10.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p4.10.m10.2.3.3.2" xref="S3.SS1.p4.10.m10.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p4.10.m10.2.3.3.2.1" xref="S3.SS1.p4.10.m10.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p4.10.m10.1.1" xref="S3.SS1.p4.10.m10.1.1.cmml">T</mi><mo id="S3.SS1.p4.10.m10.2.3.3.2.2" xref="S3.SS1.p4.10.m10.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p4.10.m10.2.2" xref="S3.SS1.p4.10.m10.2.2.cmml">S</mi><mo stretchy="false" id="S3.SS1.p4.10.m10.2.3.3.2.3" xref="S3.SS1.p4.10.m10.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.10.m10.2b"><apply id="S3.SS1.p4.10.m10.2.3.cmml" xref="S3.SS1.p4.10.m10.2.3"><times id="S3.SS1.p4.10.m10.2.3.1.cmml" xref="S3.SS1.p4.10.m10.2.3.1"></times><apply id="S3.SS1.p4.10.m10.2.3.2.cmml" xref="S3.SS1.p4.10.m10.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.10.m10.2.3.2.1.cmml" xref="S3.SS1.p4.10.m10.2.3.2">superscript</csymbol><ci id="S3.SS1.p4.10.m10.2.3.2.2.cmml" xref="S3.SS1.p4.10.m10.2.3.2.2">ğ¹</ci><ci id="S3.SS1.p4.10.m10.2.3.2.3.cmml" xref="S3.SS1.p4.10.m10.2.3.2.3">ğ‘˜</ci></apply><interval closure="open" id="S3.SS1.p4.10.m10.2.3.3.1.cmml" xref="S3.SS1.p4.10.m10.2.3.3.2"><ci id="S3.SS1.p4.10.m10.1.1.cmml" xref="S3.SS1.p4.10.m10.1.1">ğ‘‡</ci><ci id="S3.SS1.p4.10.m10.2.2.cmml" xref="S3.SS1.p4.10.m10.2.2">ğ‘†</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.10.m10.2c">F^{k}(T,S)</annotation></semantics></math> with <math id="S3.SS1.p4.11.m11.2" class="ltx_Math" alttext="F^{k}(T,H)" display="inline"><semantics id="S3.SS1.p4.11.m11.2a"><mrow id="S3.SS1.p4.11.m11.2.3" xref="S3.SS1.p4.11.m11.2.3.cmml"><msup id="S3.SS1.p4.11.m11.2.3.2" xref="S3.SS1.p4.11.m11.2.3.2.cmml"><mi id="S3.SS1.p4.11.m11.2.3.2.2" xref="S3.SS1.p4.11.m11.2.3.2.2.cmml">F</mi><mi id="S3.SS1.p4.11.m11.2.3.2.3" xref="S3.SS1.p4.11.m11.2.3.2.3.cmml">k</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p4.11.m11.2.3.1" xref="S3.SS1.p4.11.m11.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p4.11.m11.2.3.3.2" xref="S3.SS1.p4.11.m11.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p4.11.m11.2.3.3.2.1" xref="S3.SS1.p4.11.m11.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p4.11.m11.1.1" xref="S3.SS1.p4.11.m11.1.1.cmml">T</mi><mo id="S3.SS1.p4.11.m11.2.3.3.2.2" xref="S3.SS1.p4.11.m11.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p4.11.m11.2.2" xref="S3.SS1.p4.11.m11.2.2.cmml">H</mi><mo stretchy="false" id="S3.SS1.p4.11.m11.2.3.3.2.3" xref="S3.SS1.p4.11.m11.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.11.m11.2b"><apply id="S3.SS1.p4.11.m11.2.3.cmml" xref="S3.SS1.p4.11.m11.2.3"><times id="S3.SS1.p4.11.m11.2.3.1.cmml" xref="S3.SS1.p4.11.m11.2.3.1"></times><apply id="S3.SS1.p4.11.m11.2.3.2.cmml" xref="S3.SS1.p4.11.m11.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.11.m11.2.3.2.1.cmml" xref="S3.SS1.p4.11.m11.2.3.2">superscript</csymbol><ci id="S3.SS1.p4.11.m11.2.3.2.2.cmml" xref="S3.SS1.p4.11.m11.2.3.2.2">ğ¹</ci><ci id="S3.SS1.p4.11.m11.2.3.2.3.cmml" xref="S3.SS1.p4.11.m11.2.3.2.3">ğ‘˜</ci></apply><interval closure="open" id="S3.SS1.p4.11.m11.2.3.3.1.cmml" xref="S3.SS1.p4.11.m11.2.3.3.2"><ci id="S3.SS1.p4.11.m11.1.1.cmml" xref="S3.SS1.p4.11.m11.1.1">ğ‘‡</ci><ci id="S3.SS1.p4.11.m11.2.2.cmml" xref="S3.SS1.p4.11.m11.2.2">ğ»</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.11.m11.2c">F^{k}(T,H)</annotation></semantics></math>. The fidelity measure of the holdout with respect to the training data thus serves us as a reference for what we aim for when retaining statistics, that generalize beyond the individuals.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Privacy</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">While fidelity is assessed at the dataset-level, we need to look at individual-level distances for making the case that none of the training subjects is exposed by any of the generated synthetic records.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">A simplistic approach is to check for identical matches, i.e., records from the training set that are also contained in the synthetic set. However, the occurrence of identical matches is neither a required nor a sufficient condition for detecting a leakage of privacy. Just as any dataset can contain duplicate records, we shall expect a similar relative occurrence within a representative synthetic dataset. Further, and analogous to that metaphorical monkey typing the complete works of William Shakespeare by hitting random keys on a typewriter for an infinite time (also known as the â€˜infinite monkey theoremâ€˜), even an uninformed random data generator will eventually end up generating any data record. More importantly, these identical matches must not be removed from the synthetic output, as such a rejection filter actually leaks privacy, since it would reveal the presence of a specific record in the training data by it being absent from a sufficiently large generated synthetic dataset.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p">The concept of identical matches is commonly generalized towards measuring the distance to closest records (DCR) <cite class="ltx_cite ltx_citemacro_citep">(Park etÂ al., <a href="#bib.bib28" title="" class="ltx_ref">2018</a>; Lu etÂ al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>. These are the individual-level distances of synthetic records with respect to their corresponding nearest neighboring records from the training dataset. The distance measure itself is interchangeable, whereas we opt for the Hamming distance applied to the discretized dataset as an easy-to-compute, easy-to-reason distance metric. However, the very same framework can be just as well applied on top of alternative distance metrics, including ones based on more meaningful learned representations of domain-specific embedding spaces. A DCR of 0 corresponds to an identical match. But as argued above, also that metric in itself does not reveal anything regarding the leakage of individual-level information, but is rather a statistic of the data distribution we seek to retain. Therefore, to provide meaning and to facilitate interpretation the measured DCRs need to be put into the context of their expected value, which can be estimated based on an actual holdout dataset.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2104.00635/assets/fig5-split.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Construction of the holdout-based privacy risk measure</figcaption>
</figure>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p">As illustrated in figure <a href="#S3.F3" title="Figure 3 â€£ 3.2 Privacy â€£ 3 Framework â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we therefore propose to calculate for each synthetic record its DCR with respect to the training data as well as with respect to an equally sized holdout dataset. The <span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_italic">share of records</span> that are then closer to a training than to a holdout record serves us as our proposed privacy risk measure. Any ties are to be distributed equally between these two datasets. If that resulting share is then close to 50%, we gain empirical evidence of the training and holdout data being interchangeable with respect to the synthetic data<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Note, that as the holdout records are randomly sampled and never exposed to the synthesizer, the synthesizer can not systematically generate subjects that are closer to these than to the training records. I.e., the presented privacy metric can not be undermined by mixing â€too closeâ€ with â€too far awayâ€ records in an attempt to achieve a balanced share.</span></span></span>. This in turn allows to make a strong case for plausible deniability for any individual, as the synthetic data records do not allow to conjecture whether an individual was or was not contained in the training dataset. Even for cases of a strong resemblance of a particular record with a real-world subject, it can be argued that such a resemblance can occur for unseen subjects just as well. Thus, one can deduce that â€œany resemblance to persons living or dead is purely coincidentalâ€.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">To demonstrate the usefulness of the presented framework for assessing fidelity and privacy of synthetic data solutions, we apply it to four publicly available, mixed-type tabular datasets from the UCI Machine Learning repository <cite class="ltx_cite ltx_citemacro_citep">(Dua &amp; Graff, <a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite> and synthesize them using seven publicly available data synthesizers.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p">The four datasets include:</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">adult: 48â€™842 records with 15 attributes (6 numerical, 9 categorical)</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">bank-marketing: 45â€™211 records with 17 attributes (7 numerical, 10 categorical)</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">credit-default: 30â€™000 records with 24 attributes (20 numerical, 4 categorical)</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S4.I1.i4.p1.1" class="ltx_p">online-shoppers: 12â€™330 records with 18 attributes (4 numerical, 14 categorical)</p>
</div>
</li>
</ul>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.1" class="ltx_p">The seven tested generative models comprise four generators contained as part of MITâ€™s Synthetic Data Vault (SDV) library <cite class="ltx_cite ltx_citemacro_citep">(Montanez etÂ al., <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite>, the synthpop R package <cite class="ltx_cite ltx_citemacro_citep">(Nowok etÂ al., <a href="#bib.bib27" title="" class="ltx_ref">2016</a>)</cite>, an open-sourced generator by Gretel (<a target="_blank" href="https://gretel.ai/" title="" class="ltx_ref ltx_href">gretel.ai</a>), plus one closed-source solution by MOSTLY AI (<a target="_blank" href="https://mostly.ai/" title="" class="ltx_ref ltx_href">mostly.ai</a>), who provide a freely available community edition online.</p>
</div>
<div id="S4.p5" class="ltx_para ltx_noindent">
<p id="S4.p5.1" class="ltx_p">Each of the four datasets is randomly split into an equally sized training and holdout dataset. The seven generative models are fitted to the training data to then generate 50â€™000 synthetic records for each dataset. All synthesizers are run with their default settings unchanged, i.e., no parameter tuning is being performed.</p>
</div>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p id="S4.p6.1" class="ltx_p">To provide further context to the results, we also generate additional datasets by perturbating the training data with a varying degree of noise. In doing so, we draw 50â€™000 records with replacement from the dataset and then decide for each value of each record with a given probability (ranging from 10% up to 90%) whether to keep it or to replace it with a value from a different record. This approach adds noise to existing records, yet retains the univariate marginal distributions. With more noise being added, one expects privacy to be increasingly protected, while also more statistical relations to be distorted.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2104.00635/assets/fig6-adult-univariate-bench.png" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="298" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Selected univariate marginal distributions for dataset â€˜adultâ€˜ across generators</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2104.00635/assets/fig7-adult-bivariate-bench.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="265" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span> Selected bivariate marginal distribution for dataset â€˜adultâ€˜ across generators</figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2104.00635/assets/fig8-adult-threeway-bench.png" id="S4.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="354" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Selected three-way marginal distribution for dataset â€˜adultâ€˜ across generators</figcaption>
</figure>
<div id="S4.p7" class="ltx_para ltx_noindent">
<p id="S4.p7.1" class="ltx_p">Figures <a href="#S4.F4" title="Figure 4 â€£ 4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, <a href="#S4.F5" title="Figure 5 â€£ 4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S4.F6" title="Figure 6 â€£ 4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> visualize the resulting distributions of selected univariate, bivariate and three-way attribute interactions for the â€˜adultâ€˜ dataset across the various generated datasets. While the visual inspection already allows to spot some qualitative differences with respect to representativeness of the training data, it is the corresponding TVD metric that provides us with a quantitative summary statistic. The reported TVD for the holdout data then serves as a reference, as the derived distributions shall not be systematically closer to the training than what is expected from the holdout. And with 15 univariate, 105 bivariate and 455 three-way interactions for dataset â€˜adultâ€˜ to be investigated, the proposed summary statistics of averaging across these yield a condensed but informative fidelity assessment of synthetic data. Figure <a href="#S4.F7" title="Figure 7 â€£ 4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> reports the proposed fidelity measures across all four datasets and generative methods.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>For the fidelity assessment we chose for <math id="footnote4.m1.1" class="ltx_Math" alttext="c=100" display="inline"><semantics id="footnote4.m1.1b"><mrow id="footnote4.m1.1.1" xref="footnote4.m1.1.1.cmml"><mi id="footnote4.m1.1.1.2" xref="footnote4.m1.1.1.2.cmml">c</mi><mo id="footnote4.m1.1.1.1" xref="footnote4.m1.1.1.1.cmml">=</mo><mn id="footnote4.m1.1.1.3" xref="footnote4.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m1.1c"><apply id="footnote4.m1.1.1.cmml" xref="footnote4.m1.1.1"><eq id="footnote4.m1.1.1.1.cmml" xref="footnote4.m1.1.1.1"></eq><ci id="footnote4.m1.1.1.2.cmml" xref="footnote4.m1.1.1.2">ğ‘</ci><cn type="integer" id="footnote4.m1.1.1.3.cmml" xref="footnote4.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m1.1d">c=100</annotation></semantics></math> for discretizing the univariate distributions, <math id="footnote4.m2.1" class="ltx_Math" alttext="c=10" display="inline"><semantics id="footnote4.m2.1b"><mrow id="footnote4.m2.1.1" xref="footnote4.m2.1.1.cmml"><mi id="footnote4.m2.1.1.2" xref="footnote4.m2.1.1.2.cmml">c</mi><mo id="footnote4.m2.1.1.1" xref="footnote4.m2.1.1.1.cmml">=</mo><mn id="footnote4.m2.1.1.3" xref="footnote4.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m2.1c"><apply id="footnote4.m2.1.1.cmml" xref="footnote4.m2.1.1"><eq id="footnote4.m2.1.1.1.cmml" xref="footnote4.m2.1.1.1"></eq><ci id="footnote4.m2.1.1.2.cmml" xref="footnote4.m2.1.1.2">ğ‘</ci><cn type="integer" id="footnote4.m2.1.1.3.cmml" xref="footnote4.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m2.1d">c=10</annotation></semantics></math> for the bivariate combinations, and <math id="footnote4.m3.1" class="ltx_Math" alttext="c=5" display="inline"><semantics id="footnote4.m3.1b"><mrow id="footnote4.m3.1.1" xref="footnote4.m3.1.1.cmml"><mi id="footnote4.m3.1.1.2" xref="footnote4.m3.1.1.2.cmml">c</mi><mo id="footnote4.m3.1.1.1" xref="footnote4.m3.1.1.1.cmml">=</mo><mn id="footnote4.m3.1.1.3" xref="footnote4.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m3.1c"><apply id="footnote4.m3.1.1.cmml" xref="footnote4.m3.1.1"><eq id="footnote4.m3.1.1.1.cmml" xref="footnote4.m3.1.1.1"></eq><ci id="footnote4.m3.1.1.2.cmml" xref="footnote4.m3.1.1.2">ğ‘</ci><cn type="integer" id="footnote4.m3.1.1.3.cmml" xref="footnote4.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m3.1d">c=5</annotation></semantics></math> for the 3-way interactions. Experiments have shown that rankings among synthesizers remain relatively robust with respect to the cardinality of the categorical variable <math id="footnote4.m4.1" class="ltx_Math" alttext="c" display="inline"><semantics id="footnote4.m4.1b"><mi id="footnote4.m4.1.1" xref="footnote4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="footnote4.m4.1c"><ci id="footnote4.m4.1.1.cmml" xref="footnote4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m4.1d">c</annotation></semantics></math>.</span></span></span></p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2104.00635/assets/fig9-fidelity.png" id="S4.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="242" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Fidelity measures of the presented empirical study</figcaption>
</figure>
<div id="S4.p8" class="ltx_para ltx_noindent">
<p id="S4.p8.1" class="ltx_p">It is interesting to note that the rankings with respect to fidelity among synthesizers are relatively consistent across all datasets, showing that these metrics indeed serve as general-purpose measures for the quality of a synthesizer. The reported numbers for the perturbated datasets exhibit the expected relationship between noise level and fidelity. Among the benchmarked synthesizers â€˜synthpopâ€˜ and â€˜MOSTLYâ€˜ exhibit the highest fidelity score with the caveat that the former is systematically too close to the training data compared to what is expected based on the holdout.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2104.00635/assets/fig10-privacy.png" id="S4.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="530" height="267" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Privacy measures of the presented empirical study</figcaption>
</figure>
<div id="S4.p9" class="ltx_para ltx_noindent">
<p id="S4.p9.1" class="ltx_p">Figure <a href="#S4.F8" title="Figure 8 â€£ 4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> on the other hand contains the results for the proposed privacy risk measures. For each dataset and synthesizer the share of synthetic records that is closer to a training record than to a holdout record is being reported. In addition, the average DCRs are displayed, once with respect to the training and once with respect to the holdout. With the notable exception of â€™synthpopâ€™ all of the presented synthesizers exhibit near identical DCR distributions for training as well as for holdout records. This indicates that no individual-level information of the training subjects has been exposed beyond what is attainable from the underlying distribution and thus makes a strong case for the generated data preserving the privacy of the training subjects. In contrast, the reported numbers for the perturbated datasets reveal a severe exposure of the training subjects, even as a high amount of noise is being added. Only at a level where most of the utility of these datasets is being destroyed, the privacy measures start to align with the holdout dataset.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2104.00635/assets/fig11-tradeoff.png" id="S4.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="530" height="464" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Trade-off between privacy and fidelity for the presented empirical study</figcaption>
</figure>
<div id="S4.p10" class="ltx_para ltx_noindent">
<p id="S4.p10.1" class="ltx_p">Based on these results we can further visualize the uncovered empirical relationship between privacy and fidelity. The x-axes in Figure <a href="#S4.F9" title="Figure 9 â€£ 4 Results â€£ Holdout-Based Fidelity and Privacy Assessment of Mixed-Type Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> represent the three-way fidelity measure in relation to its corresponding value for the holdout dataset, i.e., <math id="S4.p10.1.m1.4" class="ltx_Math" alttext="F^{3}(T,S)/F^{3}(T,H)" display="inline"><semantics id="S4.p10.1.m1.4a"><mrow id="S4.p10.1.m1.4.5" xref="S4.p10.1.m1.4.5.cmml"><mrow id="S4.p10.1.m1.4.5.2" xref="S4.p10.1.m1.4.5.2.cmml"><mrow id="S4.p10.1.m1.4.5.2.2" xref="S4.p10.1.m1.4.5.2.2.cmml"><msup id="S4.p10.1.m1.4.5.2.2.2" xref="S4.p10.1.m1.4.5.2.2.2.cmml"><mi id="S4.p10.1.m1.4.5.2.2.2.2" xref="S4.p10.1.m1.4.5.2.2.2.2.cmml">F</mi><mn id="S4.p10.1.m1.4.5.2.2.2.3" xref="S4.p10.1.m1.4.5.2.2.2.3.cmml">3</mn></msup><mo lspace="0em" rspace="0em" id="S4.p10.1.m1.4.5.2.2.1" xref="S4.p10.1.m1.4.5.2.2.1.cmml">â€‹</mo><mrow id="S4.p10.1.m1.4.5.2.2.3.2" xref="S4.p10.1.m1.4.5.2.2.3.1.cmml"><mo stretchy="false" id="S4.p10.1.m1.4.5.2.2.3.2.1" xref="S4.p10.1.m1.4.5.2.2.3.1.cmml">(</mo><mi id="S4.p10.1.m1.1.1" xref="S4.p10.1.m1.1.1.cmml">T</mi><mo id="S4.p10.1.m1.4.5.2.2.3.2.2" xref="S4.p10.1.m1.4.5.2.2.3.1.cmml">,</mo><mi id="S4.p10.1.m1.2.2" xref="S4.p10.1.m1.2.2.cmml">S</mi><mo stretchy="false" id="S4.p10.1.m1.4.5.2.2.3.2.3" xref="S4.p10.1.m1.4.5.2.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.p10.1.m1.4.5.2.1" xref="S4.p10.1.m1.4.5.2.1.cmml">/</mo><msup id="S4.p10.1.m1.4.5.2.3" xref="S4.p10.1.m1.4.5.2.3.cmml"><mi id="S4.p10.1.m1.4.5.2.3.2" xref="S4.p10.1.m1.4.5.2.3.2.cmml">F</mi><mn id="S4.p10.1.m1.4.5.2.3.3" xref="S4.p10.1.m1.4.5.2.3.3.cmml">3</mn></msup></mrow><mo lspace="0em" rspace="0em" id="S4.p10.1.m1.4.5.1" xref="S4.p10.1.m1.4.5.1.cmml">â€‹</mo><mrow id="S4.p10.1.m1.4.5.3.2" xref="S4.p10.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S4.p10.1.m1.4.5.3.2.1" xref="S4.p10.1.m1.4.5.3.1.cmml">(</mo><mi id="S4.p10.1.m1.3.3" xref="S4.p10.1.m1.3.3.cmml">T</mi><mo id="S4.p10.1.m1.4.5.3.2.2" xref="S4.p10.1.m1.4.5.3.1.cmml">,</mo><mi id="S4.p10.1.m1.4.4" xref="S4.p10.1.m1.4.4.cmml">H</mi><mo stretchy="false" id="S4.p10.1.m1.4.5.3.2.3" xref="S4.p10.1.m1.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p10.1.m1.4b"><apply id="S4.p10.1.m1.4.5.cmml" xref="S4.p10.1.m1.4.5"><times id="S4.p10.1.m1.4.5.1.cmml" xref="S4.p10.1.m1.4.5.1"></times><apply id="S4.p10.1.m1.4.5.2.cmml" xref="S4.p10.1.m1.4.5.2"><divide id="S4.p10.1.m1.4.5.2.1.cmml" xref="S4.p10.1.m1.4.5.2.1"></divide><apply id="S4.p10.1.m1.4.5.2.2.cmml" xref="S4.p10.1.m1.4.5.2.2"><times id="S4.p10.1.m1.4.5.2.2.1.cmml" xref="S4.p10.1.m1.4.5.2.2.1"></times><apply id="S4.p10.1.m1.4.5.2.2.2.cmml" xref="S4.p10.1.m1.4.5.2.2.2"><csymbol cd="ambiguous" id="S4.p10.1.m1.4.5.2.2.2.1.cmml" xref="S4.p10.1.m1.4.5.2.2.2">superscript</csymbol><ci id="S4.p10.1.m1.4.5.2.2.2.2.cmml" xref="S4.p10.1.m1.4.5.2.2.2.2">ğ¹</ci><cn type="integer" id="S4.p10.1.m1.4.5.2.2.2.3.cmml" xref="S4.p10.1.m1.4.5.2.2.2.3">3</cn></apply><interval closure="open" id="S4.p10.1.m1.4.5.2.2.3.1.cmml" xref="S4.p10.1.m1.4.5.2.2.3.2"><ci id="S4.p10.1.m1.1.1.cmml" xref="S4.p10.1.m1.1.1">ğ‘‡</ci><ci id="S4.p10.1.m1.2.2.cmml" xref="S4.p10.1.m1.2.2">ğ‘†</ci></interval></apply><apply id="S4.p10.1.m1.4.5.2.3.cmml" xref="S4.p10.1.m1.4.5.2.3"><csymbol cd="ambiguous" id="S4.p10.1.m1.4.5.2.3.1.cmml" xref="S4.p10.1.m1.4.5.2.3">superscript</csymbol><ci id="S4.p10.1.m1.4.5.2.3.2.cmml" xref="S4.p10.1.m1.4.5.2.3.2">ğ¹</ci><cn type="integer" id="S4.p10.1.m1.4.5.2.3.3.cmml" xref="S4.p10.1.m1.4.5.2.3.3">3</cn></apply></apply><interval closure="open" id="S4.p10.1.m1.4.5.3.1.cmml" xref="S4.p10.1.m1.4.5.3.2"><ci id="S4.p10.1.m1.3.3.cmml" xref="S4.p10.1.m1.3.3">ğ‘‡</ci><ci id="S4.p10.1.m1.4.4.cmml" xref="S4.p10.1.m1.4.4">ğ»</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.1.m1.4c">F^{3}(T,S)/F^{3}(T,H)</annotation></semantics></math>. The y-axes represent the reported share of records that are closer to training than to the holdout. Presented this way, the holdout dataset serves us as a â€north starâ€ for truly privacy-respecting data synthesizers in the upper right corner. The orange dots represent the range of perturbated datasets and reveal the difficulties of basic obfuscation techniques to protect privacy without sacrificing fidelity, particularly for higher-dimensional datasets. The turquoise marks on the other hand represent the performance metrics for a broad range of emerging synthesizers, whereas all except one exhibit DCR shares close to 50%, and with some getting already very close to representing the characteristics of a true holdout dataset.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">The field of supervised machine learning benefited from having commonly used benchmark datasets and metrics in place to measure performance across methods as well as progress over time. The emerging field of privacy-preserving structured synthetic data is still to converge onto commonly agreed fidelity and privacy measures, as well as to a set of canonical datasets to benchmark on. This research aims at complementing already existing methods by introducing a practical, assumption-free and easy-to-reason empirical assessment framework that can be applied for any black-box synthetization method and thus shall help to objectively capture and measure the progress in the field. In addition, the reported findings from the empirical benchmark experiments demonstrate the promise of AI-based data synthesis when compared to more traditional statistical disclosure techniques. However, they also highlight the need to not only assess fidelity but just as well the privacy risk of these newly emerging, powerful data generators. We hope that our research made a first step towards this direction.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Funding</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">This research is supported by the â€ICT of the Futureâ€ funding programme of the Austrian Federal Ministry for Climate Action, Environment, Energy, Mobility, Innovation and Technology.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Data Availability Statement</h2>

<div id="Sx2.p1" class="ltx_para ltx_noindent">
<p id="Sx2.p1.1" class="ltx_p">A reference implementation of the framework, as well as all datasets of the empirical study are made available in a publicly accessible repository found at <a target="_blank" href="https://github.com/mostly-ai/paper-fidelity-accuracy" title="" class="ltx_ref ltx_href">https://github.com/mostly-ai/paper-fidelity-accuracy</a>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ackley etÂ al. (1985)</span>
<span class="ltx_bibblock">
DavidÂ H Ackley, GeoffreyÂ E Hinton, and TerrenceÂ J Sejnowski.

</span>
<span class="ltx_bibblock">A learning algorithm for boltzmann machines.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Cognitive science</em>, 9(1):147â€“169, 1985.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assefa (2020)</span>
<span class="ltx_bibblock">
Samuel Assefa.

</span>
<span class="ltx_bibblock">Generating synthetic data in finance: opportunities, challenges and
pitfalls.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Challenges and Pitfalls (June 23, 2020)</em>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellman (1966)</span>
<span class="ltx_bibblock">
Richard Bellman.

</span>
<span class="ltx_bibblock">Dynamic programming.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Science</em>, 153(3731):34â€“37, 1966.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellovin etÂ al. (2019)</span>
<span class="ltx_bibblock">
StevenÂ M Bellovin, PreetamÂ K Dutta, and Nathan Reitinger.

</span>
<span class="ltx_bibblock">Privacy and synthetic datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Stan. Tech. L. Rev.</em>, 22:1, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
TomÂ B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
etÂ al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.14165</em>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi etÂ al. (2017)</span>
<span class="ltx_bibblock">
Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, WalterÂ F Stewart, and
Jimeng Sun.

</span>
<span class="ltx_bibblock">Generating multi-label discrete patient records using generative
adversarial networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Machine learning for healthcare conference</em>, pp.Â  286â€“305.
PMLR, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Drechsler (2011)</span>
<span class="ltx_bibblock">
JÃ¶rg Drechsler.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Synthetic datasets for statistical disclosure control: theory
and implementation</em>, volume 201.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 2011.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua &amp; Graff (2017)</span>
<span class="ltx_bibblock">
Dheeru Dua and Casey Graff.

</span>
<span class="ltx_bibblock">UCI machine learning repository, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://archive.ics.uci.edu/ml" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://archive.ics.uci.edu/ml</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork etÂ al. (2006)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Theory of cryptography conference</em>, pp.Â  265â€“284.
Springer, 2006.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al. (2018)</span>
<span class="ltx_bibblock">
Angela Fan, Mike Lewis, and Yann Dauphin.

</span>
<span class="ltx_bibblock">Hierarchical neural story generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1805.04833</em>, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freiman etÂ al. (2017)</span>
<span class="ltx_bibblock">
MÂ Freiman, AÂ Lauger, and JÂ Reiter.

</span>
<span class="ltx_bibblock">Data synthesis and perturbation for the american community survey at
the us census bureau.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">US Census Bureau</em>, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goncalves etÂ al. (2020)</span>
<span class="ltx_bibblock">
Andre Goncalves, Priyadip Ray, Braden Soper, Jennifer Stevens, Linda Coyle, and
AnaÂ Paula Sales.

</span>
<span class="ltx_bibblock">Generation and evaluation of synthetic patient data.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">BMC medical research methodology</em>, 20:1â€“40, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow etÂ al. (2014)</span>
<span class="ltx_bibblock">
IanÂ J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1406.2661</em>, 2014.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ha &amp; Schmidhuber (2018)</span>
<span class="ltx_bibblock">
David Ha and JÃ¼rgen Schmidhuber.

</span>
<span class="ltx_bibblock">World models.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.10122</em>, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hittmeir etÂ al. (2019)</span>
<span class="ltx_bibblock">
Markus Hittmeir, Andreas Ekelhart, and Rudolf Mayer.

</span>
<span class="ltx_bibblock">Utility and privacy assessments of synthetic data for regression
tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International Conference on Big Data (Big Data)</em>,
pp.Â  5763â€“5772. IEEE, 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/BigData47090.2019.9005476</span>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hittmeir etÂ al. (2020)</span>
<span class="ltx_bibblock">
Markus Hittmeir, Rudolf Mayer, and Andreas Ekelhart.

</span>
<span class="ltx_bibblock">A baseline for attribute disclosure risk in synthetic data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth ACM Conference on Data and
Application Security and Privacy</em>, pp.Â  133â€“143, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holtzman etÂ al. (2019)</span>
<span class="ltx_bibblock">
Ari Holtzman, Jan Buys, LiÂ Du, Maxwell Forbes, and Yejin Choi.

</span>
<span class="ltx_bibblock">The curious case of neural text degeneration.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.09751</em>, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Howe etÂ al. (2017)</span>
<span class="ltx_bibblock">
Bill Howe, Julia Stoyanovich, Haoyue Ping, Bernease Herman, and Matt Gee.

</span>
<span class="ltx_bibblock">Synthetic data for social good.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.08874</em>, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon etÂ al. (2018)</span>
<span class="ltx_bibblock">
James Jordon, Jinsung Yoon, and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">Measuring the quality of synthetic data for use in competitions.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.11345</em>, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras etÂ al. (2017)</span>
<span class="ltx_bibblock">
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.

</span>
<span class="ltx_bibblock">Progressive growing of gans for improved quality, stability, and
variation.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.10196</em>, 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krauland etÂ al. (2020)</span>
<span class="ltx_bibblock">
MaryÂ G Krauland, RobertÂ J Frankeny, Josh Lewis, LuAnn Brink, EricÂ G Hulsey,
MarkÂ S Roberts, and KarenÂ A Hacker.

</span>
<span class="ltx_bibblock">Development of a synthetic population model for assessing excess risk
for cardiovascular disease death.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">JAMA network open</em>, 3(9):e2015047â€“e2015047, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2019)</span>
<span class="ltx_bibblock">
Szu-Chuang Li, Bo-Chen Tai, and Yennun Huang.

</span>
<span class="ltx_bibblock">Evaluating variational autoencoder as a private data release
mechanism for tabular data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 24th Pacific Rim International Symposium on
Dependable Computing (PRDC)</em>, pp.Â  198â€“1988. IEEE, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar.

</span>
<span class="ltx_bibblock">Using gans for sharing networked time series data: Challenges,
initial promise, and open questions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Internet Measurement Conference</em>,
pp.Â  464â€“483, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu &amp; Tuzel (2016)</span>
<span class="ltx_bibblock">
Ming-Yu Liu and Oncel Tuzel.

</span>
<span class="ltx_bibblock">Coupled generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.07536</em>, 2016.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2019)</span>
<span class="ltx_bibblock">
Pei-Hsuan Lu, Pang-Chieh Wang, and Chia-Mu Yu.

</span>
<span class="ltx_bibblock">Empirical evaluation on synthetic data generation with generative
adversarial network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 9th International Conference on Web
Intelligence, Mining and Semantics</em>, pp.Â  1â€“6, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Montanez etÂ al. (2018)</span>
<span class="ltx_bibblock">
Andrew Montanez etÂ al.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">SDV: an open source library for synthetic data generation</em>.

</span>
<span class="ltx_bibblock">PhD thesis, Massachusetts Institute of Technology, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nowok etÂ al. (2016)</span>
<span class="ltx_bibblock">
Beata Nowok, GillianÂ M Raab, Chris Dibben, etÂ al.

</span>
<span class="ltx_bibblock">synthpop: Bespoke creation of synthetic data in r.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Journal of statistical software</em>, 74(11):1â€“26, 2016.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park etÂ al. (2018)</span>
<span class="ltx_bibblock">
Noseong Park, Mahmoud Mohammadi, Kshitij Gorde, Sushil Jajodia, Hongkyu Park,
and Youngmin Kim.

</span>
<span class="ltx_bibblock">Data synthesis based on generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.03384</em>, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">PopiÄ‡ etÂ al. (2019)</span>
<span class="ltx_bibblock">
Srdan PopiÄ‡, Bogdan PavkoviÄ‡, Ivan VelikiÄ‡, and Nikola TesliÄ‡.

</span>
<span class="ltx_bibblock">Data generators: a short survey of techniques and use cases with
focus on testing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 9th International Conference on Consumer
Electronics (ICCE-Berlin)</em>, pp.Â  189â€“194. IEEE, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2015)</span>
<span class="ltx_bibblock">
Alec Radford, Luke Metz, and Soumith Chintala.

</span>
<span class="ltx_bibblock">Unsupervised representation learning with deep convolutional
generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1511.06434</em>, 2015.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kai Shu, Yichuan Li, Kaize Ding, and Huan Liu.

</span>
<span class="ltx_bibblock">Fact-enhanced synthetic news generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.04778</em>, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Surendra &amp; MohanH (2017)</span>
<span class="ltx_bibblock">
H.Â Surendra and S.Â MohanH.

</span>
<span class="ltx_bibblock">A review of synthetic data generation methods for privacy preserving
data publishing.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">International Journal of Scientific &amp; Technology Research</em>,
6:95â€“101, 2017.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taub etÂ al. (2018)</span>
<span class="ltx_bibblock">
Jennifer Taub, Mark Elliot, Maria Pampaka, and Duncan Smith.

</span>
<span class="ltx_bibblock">Differential correct attribution probability for synthetic data: an
exploration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International Conference on Privacy in Statistical
Databases</em>, pp.Â  122â€“137. Springer, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Theis etÂ al. (2015)</span>
<span class="ltx_bibblock">
Lucas Theis, AÃ¤ron vanÂ den Oord, and Matthias Bethge.

</span>
<span class="ltx_bibblock">A note on the evaluation of generative models.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1511.01844</em>, 2015.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2019)</span>
<span class="ltx_bibblock">
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">Modeling tabular data using conditional gan.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.00503</em>, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yelmen etÂ al. (2021)</span>
<span class="ltx_bibblock">
Burak Yelmen, AurÃ©lien Decelle, Linda Ongaro, Davide Marnetto, Corentin
Tallec, Francesco Montinaro, Cyril Furtlehner, Luca Pagani, and Flora Jay.

</span>
<span class="ltx_bibblock">Creating artificial human genomes using generative neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">PLoS Genetics</em>, 17(2):e1009303, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.00634" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.00635" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.00635">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.00635" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.00636" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 01:05:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
