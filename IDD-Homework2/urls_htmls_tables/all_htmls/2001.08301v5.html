<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2001.08301] How to Support Users in Understanding Intelligent Systems? Structuring the Discussion</title><meta property="og:description" content="The opaque nature of many intelligent systems violates established usability principles and thus presents a challenge for human-computer interaction. Research in the field therefore highlights the need for transparency…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="How to Support Users in Understanding Intelligent Systems? Structuring the Discussion">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="How to Support Users in Understanding Intelligent Systems? Structuring the Discussion">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2001.08301">

<!--Generated on Thu Mar  7 09:23:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Review,  intelligent systems,  scrutability,  interpretability,  transparency,  explainability,  intelligibility,  accountability,  interactive machine learning,  end-user debugging">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">How to Support Users in Understanding Intelligent Systems? Structuring the Discussion</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Malin Eiband
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:malin.eiband@ifi.lmu.de">malin.eiband@ifi.lmu.de</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">LMU Munich</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_streetaddress">Frauenlobstraße 7a</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_city">Munich</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_state">Germany</span><span id="id5.5.id5" class="ltx_text ltx_affiliation_postcode">80337</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Daniel Buschek
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:daniel.buschek@uni-bayreuth.de">daniel.buschek@uni-bayreuth.de</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id6.1.id1" class="ltx_text ltx_affiliation_institution">Research Group HCI + AI, Department of Computer Science, University of Bayreuth</span><span id="id7.2.id2" class="ltx_text ltx_affiliation_streetaddress">Universitätsstraße 30</span><span id="id8.3.id3" class="ltx_text ltx_affiliation_city">Bayreuth</span><span id="id9.4.id4" class="ltx_text ltx_affiliation_postcode">95447</span><span id="id10.5.id5" class="ltx_text ltx_affiliation_state">Germany</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Heinrich Hussmann
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:hussmann@ifi.lmu.de">hussmann@ifi.lmu.de</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id11.1.id1" class="ltx_text ltx_affiliation_institution">LMU Munich</span><span id="id12.2.id2" class="ltx_text ltx_affiliation_streetaddress">Frauenlobstraße 7a</span><span id="id13.3.id3" class="ltx_text ltx_affiliation_city">Munich</span><span id="id14.4.id4" class="ltx_text ltx_affiliation_state">Germany</span><span id="id15.5.id5" class="ltx_text ltx_affiliation_postcode">80337</span>
</span></span></span>
</div>
<div class="ltx_dates">(2021)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id16.id1" class="ltx_p">The opaque nature of many intelligent systems violates established usability principles and thus presents a challenge for human-computer interaction. Research in the field therefore highlights the need for transparency, scrutability, intelligibility, interpretability and explainability, among others. While all of these terms carry a vision of supporting users in understanding intelligent systems, the underlying notions and assumptions about users and their interaction with the system often remain unclear.</p>
<p id="id17.id2" class="ltx_p">We review the literature in HCI through the lens of implied user questions to synthesise a conceptual framework integrating user mindsets, user involvement, and knowledge outcomes to reveal, differentiate and classify current notions in prior work. This framework aims to resolve conceptual ambiguity in the field and enables researchers to clarify their assumptions and become aware of those made in prior work. We thus hope to advance and structure the dialogue in the HCI research community on supporting users in understanding intelligent systems.</p>
<p id="id18.id3" class="ltx_p"><span id="id18.id3.1" class="ltx_text ltx_font_bold">To appear in the Proceedings of the 26th ACM Annual Conference on Intelligent User Interfaces (IUI ’21), peer reviewed author version 5.0, 18. February 2021</span></p>
</div>
<div class="ltx_keywords">Review, intelligent systems, scrutability, interpretability, transparency, explainability, intelligibility, accountability, interactive machine learning, end-user debugging
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2021</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>26th International Conference on Intelligent User Interfaces; April 14–17, 2021; College Station, TX, USA</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>26th International Conference on Intelligent User Interfaces (IUI ’21), April 14–17, 2021, College Station, TX, USA</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3397481.3450694</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-8017-1/21/04</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing HCI theory, concepts and models</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Interactive intelligent systems violate core interface design principles such as predictable output and easy error correction <cite class="ltx_cite ltx_citemacro_citep">(Amershi
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>; Dudley and
Kristensson, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>.
This makes them hard to design, understand, and use <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2020b</a>)</cite> – an observation that has already been made decades earlier <cite class="ltx_cite ltx_citemacro_citep">(Höök, <a href="#bib.bib47" title="" class="ltx_ref">2000</a>)</cite>, but it is only in the last years that machine learning has increasingly penetrated everyday applications and thus refuelled the discussion on how we want interaction with such systems to be shaped.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One particularly challenging property of intelligent systems is their opaqueness. As a result, researchers <cite class="ltx_cite ltx_citemacro_citep">(Alkhatib and
Bernstein, <a href="#bib.bib4" title="" class="ltx_ref">2019</a>; Association for Computing Machinery US Public
Policy Council (USACM), <a href="#bib.bib11" title="" class="ltx_ref">2017</a>; Hager et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2017</a>)</cite>, practitioners <cite class="ltx_cite ltx_citemacro_citep">(Chander et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite>, policy-makers <cite class="ltx_cite ltx_citemacro_citep">(Parliament and the Council of the European Union, <a href="#bib.bib80" title="" class="ltx_ref">2016</a>)</cite> and the general public <cite class="ltx_cite ltx_citemacro_citep">(Kuang, <a href="#bib.bib61" title="" class="ltx_ref">2017</a>)</cite> increasingly call for intelligent systems to be transparent <cite class="ltx_cite ltx_citemacro_citep">(Eiband
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2018a</a>)</cite>, scrutable <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>, explainable <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>, intelligibile <cite class="ltx_cite ltx_citemacro_citep">(Lim, <a href="#bib.bib69" title="" class="ltx_ref">2010</a>)</cite> and interactive <cite class="ltx_cite ltx_citemacro_citep">(Dudley and
Kristensson, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>, among others, which we will henceforth refer to as <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">system qualities</span>.
Work on the system qualities follows a joint and urgent maxim: Designing interaction in a way that supports users in understanding and dealing with intelligent systems despite their often complex and black-box nature.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Linked by this shared goal, the diverse terms are often employed interchangeably – and yet, prior work implies divergent assumptions about how users may best be supported.
For instance, work on interpretability has recently been criticised for unclear use of the term <cite class="ltx_cite ltx_citemacro_citep">(Doshi-Velez and
Kim, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Lipton, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite>, a survey on explainability in recommenders found incompatible existing taxonomies <cite class="ltx_cite ltx_citemacro_citep">(Nunes and Jannach, <a href="#bib.bib78" title="" class="ltx_ref">2017</a>)</cite>, and discussions about system transparency and accountability revealed diverging assumptions (i.e. disclosing source code vs system auditing through experts) <cite class="ltx_cite ltx_citemacro_citep">(Edwards and Veale, <a href="#bib.bib33" title="" class="ltx_ref">2017</a>)</cite>. A recent HCI survey shows the fractured terminological landscape in the field <cite class="ltx_cite ltx_citemacro_citep">(Abdul et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In particular, for supporting user understanding of intelligent systems, clarifying concepts and connecting diverse approaches is crucial to advance scholarship, as pointed out in a recent “roadmap” towards a rigorous science of interpretability <cite class="ltx_cite ltx_citemacro_citep">(Doshi-Velez and
Kim, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite>. More generally speaking, a lack of conceptual clarity impedes scientific thinking <cite class="ltx_cite ltx_citemacro_citep">(Hornbæk and
Oulasvirta, <a href="#bib.bib48" title="" class="ltx_ref">2017</a>)</cite> and presents challenging problems for researchers in the respective field:
First, a lack of overarching conceptual frameworks renders new ideas difficult to develop and discuss in a structured way.
Second, blurred terminological boundaries impede awareness of existing work, for example through varying use of keywords.
Third, new prototypes often remain disconnected from the existing body of design solutions.
To address this, we need a clearer conceptual understanding of the <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">assumptions</span> that underlie how prior work envisions to foster user understanding of intelligent systems.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2001.08301/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="74" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Our framework for structuring the discussion of how to support users in understanding intelligent
systems: We examine user questions in the literature (left, examples) to synthesise three categories overarching prior work (centre), namely assumed <span id="S1.F1.4.1" class="ltx_text ltx_font_italic">user mindsets</span>, <span id="S1.F1.5.2" class="ltx_text ltx_font_italic">user involvement</span> and <span id="S1.F1.6.3" class="ltx_text ltx_font_italic">knowledge outcomes</span>. We discuss divergent instances of each category (right) to differentiate approaches and solution principles in the literature.</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this paper, we thus aim to answer the following research questions:</p>
</div>
<div id="S1.p6" class="ltx_para">
<blockquote id="S1.p6.1" class="ltx_quote">
<p id="S1.p6.1.1" class="ltx_p"><span id="S1.p6.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ1:<span id="S1.p6.1.1.1.1" class="ltx_text ltx_font_medium"> Which assumptions about users and interaction with intelligent systems do researchers make when referring to the system qualities?</span></span></p>
</blockquote>
<blockquote id="S1.p6.2" class="ltx_quote">
<p id="S1.p6.2.1" class="ltx_p"><span id="S1.p6.2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ2:<span id="S1.p6.2.1.1.1" class="ltx_text ltx_font_medium"> How can we structure and differentiate these assumptions?</span></span></p>
</blockquote>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Contribution and Summary</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We analyse both theoretical concepts and prototype solutions through the lens of implied <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">user questions</span> and synthesise a conceptual framework integrating <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">user mindsets</span>, <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">user involvement</span> and <span id="S2.p1.1.4" class="ltx_text ltx_font_italic">knowledge outcomes</span> to reveal, differentiate and classify notions of supporting user understanding of intelligent systems in prior work.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Our analysis revealed three categories that capture and differentiate current assumptions about users and interaction with intelligent systems from an HCI perspective (also see Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>):</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">User mindsets</span> – what users seek to know (e.g. do they want to know <span id="S2.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">why the system did X</span>, <span id="S2.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">what it was developed for</span>, <span id="S2.I1.i1.p1.1.4" class="ltx_text ltx_font_italic">how trustworthy it is</span>, etc.),</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">User involvement</span> – how users gain knowledge (e.g. do they actively inquire into the system or do they get presented information by it), and</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Knowledge outcomes</span> – what kind of knowledge users gain (e.g. about a specific output or how to correct errors).</p>
</div>
</li>
</ol>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In particular, as we will describe later in more detail, we argue that these three categories are linked to users’ intentions when using a system, influence the direction of information transfer between user and system, and reflect the envisioned outcome of the system qualities, respectively.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Our view helps to resolve conceptual ambiguity in the field and provides researchers with a framework to clarify their assumptions and become aware of those made in prior work. We thus hope to advance and structure the dialogue in the HCI research community on supporting users in understanding intelligent systems.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Scope and Foundations</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Before we present the results of our analysis in detail, we first discuss fundamental conceptual prerequisites for our work and locate our own perspective.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Intelligent Systems</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Our work focuses on interaction with <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">intelligent</span> systems.
Following Singh <cite class="ltx_cite ltx_citemacro_citep">(Singh, <a href="#bib.bib90" title="" class="ltx_ref">1994</a>)</cite>, a system is intelligent if we need to “attribute cognitive concepts such as intentions and beliefs to it in order to characterize, understand, analyze, or predict its behavior”.
While we are aware of the fact that many other definitions of intelligent systems exist, Singh’s definition hints at the potential complexity of intelligent systems and the resulting challenges for <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">users</span> to <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">understand</span> them, and thus motivates work on supporting users in doing so, including this paper.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>A Pragmatic View on Supporting User Understanding</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">One can identify two opposing perspectives in the larger discussion of supporting users in understanding intelligent systems: A normative and a pragmatic one <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">The normative perspective is visible in the ethical discourse about intelligent systems or reflected in legislation. It provides users with what has been called a “right to explanation” <cite class="ltx_cite ltx_citemacro_citep">(Goodman and
Flaxman, <a href="#bib.bib40" title="" class="ltx_ref">2016</a>)</cite>, such as recently articulated in the GDPR <cite class="ltx_cite ltx_citemacro_citep">(Parliament and the Council of the European Union, <a href="#bib.bib80" title="" class="ltx_ref">2016</a>)</cite>, and ties lawful use of intelligent systems to the ability to make users understand their decision-making process <cite class="ltx_cite ltx_citemacro_citep">(Hildebrandt, <a href="#bib.bib45" title="" class="ltx_ref">2016</a>)</cite>. While highly valuable for a legal basis for interaction with intelligent systems, this perspective stems from ethical and moral reflection, not from user needs for interaction with a concrete system. As such, it often lacks specifics on how to implement its claims in a way that benefits users in practice.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In this paper, we therefore adopt the <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_italic">pragmatic</span> perspective, which strives to best support users during interaction with intelligent systems. We define the purpose of this support by transferring a statement by Lynham from philosophy of science <cite class="ltx_cite ltx_citemacro_citep">(Lynham, <a href="#bib.bib74" title="" class="ltx_ref">2002</a>)</cite> to the context of our work: <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_italic">Supporting users in understanding intelligent systems means helping people to use a system better and in more informed ways, and to better ends and outcomes.</span></p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">We argue that this perspective captures well and articulates a core assumption of work on the system qualities: We as HCI researchers in the field of intelligent systems strive to create interfaces and interactions that are explainable, understandable, scrutable, transparent, accountable, intelligible, and so on, precisely because we envision users to then interact with these systems in more informed, effective and efficient ways.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>User Knowledge and Understanding</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In general, HCI has widely adopted mental models <cite class="ltx_cite ltx_citemacro_citep">(Johnson-Laird, <a href="#bib.bib54" title="" class="ltx_ref">1989</a>)</cite> as representations of the knowledge users possess about a system <cite class="ltx_cite ltx_citemacro_citep">(Norman, <a href="#bib.bib77" title="" class="ltx_ref">2013</a>)</cite>, and this is no different in work on the system qualities (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>; Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2012</a>; Tullio
et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2007</a>)</cite>). Mental models originate from a constructivist perspective on knowledge, where knowledge is seen as individually constructed, subjective interpretations of the world, based on previous experiences and assumptions <cite class="ltx_cite ltx_citemacro_citep">(von Glasersfeld, <a href="#bib.bib98" title="" class="ltx_ref">1989</a>)</cite>. In this paper, we adopt this perspective, and use <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">knowledge</span> interchangeably with <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">understanding</span>.
Moreover, we assume that knowledge is gained through the <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_italic">transmission of information</span> between user and system.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_transformed_outer" style="width:411.9pt;height:18034.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.0pt,525.7pt) scale(0.944912323795931,0.944912323795931) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">System quality</span></span>
</span>
</th>
<th id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">User questions (examples)</span></span>
</span>
</th>
<th id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">User mindsets</span></span>
</span>
</th>
<th id="S3.T1.1.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">User involvement</span></span>
</span>
</th>
<th id="S3.T1.1.1.1.1.5" class="ltx_td ltx_nopad_r ltx_align_justify ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.5.1.1" class="ltx_p"><span id="S3.T1.1.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Knowledge outcomes and qualities</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.2.1.1.1.1.1" class="ltx_text" style="font-size:70%;">Accountability</span></span>
</span>
</td>
<td id="S3.T1.1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.2.1.2.1.1.1" class="ltx_text" style="font-size:70%;">How fair and controllable is the system? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.2.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Rader
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.2.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib82" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.2.1.2.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.2.1.2.1.1.5" class="ltx_text" style="font-size:70%;"> How fair are system decisions? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.2.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Binns et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.2.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib14" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.2.1.2.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.2.1.2.1.1.9" class="ltx_text" style="font-size:70%;"> How will algorithmic-decision making impact my (social) work practices? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.2.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Brown et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.2.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib18" title="" class="ltx_ref">2019</a><span id="S3.T1.1.1.2.1.2.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.2.1.2.1.1.13" class="ltx_text" style="font-size:70%;"> How can I as a designer/developer of decision systems support human values? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.2.1.1.14.1" class="ltx_text" style="font-size:70%;">(</span>Holstein et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.2.1.1.15.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib46" title="" class="ltx_ref">2019</a>; Veale
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.2.1.1.15.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib97" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.2.1.2.1.1.16.3" class="ltx_text" style="font-size:70%;">)</span></cite></span>
</span>
</td>
<td id="S3.T1.1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.2.1.3.1.1.1" class="ltx_text" style="font-size:70%;">Users </span><span id="S3.T1.1.1.2.1.3.1.1.2" class="ltx_text ltx_align_left ltx_font_italic" style="font-size:70%;">critique</span><span id="S3.T1.1.1.2.1.3.1.1.3" class="ltx_text" style="font-size:70%;"> the system, often in a wider context beyond use (e.g. legal, ethical concerns).</span></span>
</span>
</td>
<td id="S3.T1.1.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.2.1.4.1.1.1" class="ltx_text" style="font-size:70%;">Users get informed by the system, or by a third party reporting on the system (e.g. journalists) </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.4.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Diakopoulos<span id="S3.T1.1.1.2.1.4.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib26" title="" class="ltx_ref">2015</a>, <a href="#bib.bib28" title="" class="ltx_ref">2017</a><span id="S3.T1.1.1.2.1.4.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.2.1.4.1.1.5" class="ltx_text" style="font-size:70%;">.
People discuss the system and/or challenge its implications beyond use </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.4.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Schlesinger
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.4.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib87" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.2.1.4.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.2.1.4.1.1.9" class="ltx_text" style="font-size:70%;">, e.g. in its organisational context </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.2.1.4.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Brown et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.4.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Holstein et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.4.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib46" title="" class="ltx_ref">2019</a>; Veale
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.2.1.4.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib97" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.2.1.4.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.2.1.4.1.1.13" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S3.T1.1.1.2.1.5" class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.5.1.1" class="ltx_p"><span id="S3.T1.1.1.2.1.5.1.1.1" class="ltx_text" style="font-size:70%;">Users seek reflection on </span><span id="S3.T1.1.1.2.1.5.1.1.2" class="ltx_text ltx_font_italic" style="font-size:70%;">outputs</span><span id="S3.T1.1.1.2.1.5.1.1.3" class="ltx_text" style="font-size:70%;">, </span><span id="S3.T1.1.1.2.1.5.1.1.4" class="ltx_text ltx_font_italic" style="font-size:70%;">processes</span><span id="S3.T1.1.1.2.1.5.1.1.5" class="ltx_text" style="font-size:70%;">, as well as on reasons behind and implications of the system (</span><span id="S3.T1.1.1.2.1.5.1.1.6" class="ltx_text ltx_font_italic" style="font-size:70%;">meta</span><span id="S3.T1.1.1.2.1.5.1.1.7" class="ltx_text" style="font-size:70%;">). What is relevant – and to what extent – may depend on the context of the system’s deployment.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.3.2.1.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Debuggability (end-user debugging)</span></span>
</span>
</td>
<td id="S3.T1.1.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.3.2.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">How can I correct system errors?
How can I tell the system why it was wrong? <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite>
How can I give effective feedback to the system?
Which objects do I have to change?
How do changes affect the rest of the system?
What does the system’s feedback mean?
How can I detect a system error?
How can I find out the cause for an error?
How can I solve this error? <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2008</a>)</cite></span></span>
</span>
</td>
<td id="S3.T1.1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.3.2.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users gain insight into the system to <span id="S3.T1.1.1.3.2.3.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">fix its errors</span>.</span></span>
</span>
</td>
<td id="S3.T1.1.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.3.2.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users fix the system’s errors.</span></span>
</span>
</td>
<td id="S3.T1.1.1.3.2.5" class="ltx_td ltx_nopad_r ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.5.1.1" class="ltx_p"><span id="S3.T1.1.1.3.2.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users need to understand <span id="S3.T1.1.1.3.2.5.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">outputs</span>, <span id="S3.T1.1.1.3.2.5.1.1.1.2" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">processes</span>, and <span id="S3.T1.1.1.3.2.5.1.1.1.3" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">interactions</span> to give good feedback and correct the system. Users make the system more relevant to them by correcting system errors.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.4.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Explainability</span></span>
</span>
</td>
<td id="S3.T1.1.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.4.3.2.1.1.1" class="ltx_text" style="font-size:70%;">Can I trust this model? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.2.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Ribeiro
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.2.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib84" title="" class="ltx_ref">2016</a><span id="S3.T1.1.1.4.3.2.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.4.3.2.1.1.5" class="ltx_text" style="font-size:70%;">
Should I trust this prediction? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.2.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Herlocker
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.2.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib43" title="" class="ltx_ref">2000</a>; Ribeiro
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.2.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib84" title="" class="ltx_ref">2016</a><span id="S3.T1.1.1.4.3.2.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.4.3.2.1.1.9" class="ltx_text" style="font-size:70%;">
What are the strengths and limitations of the system?
How can I add my knowledge and skills to the decision process? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.2.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Herlocker
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.2.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib43" title="" class="ltx_ref">2000</a><span id="S3.T1.1.1.4.3.2.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.4.3.2.1.1.13" class="ltx_text" style="font-size:70%;">
How are input and output related? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.2.1.1.14.1" class="ltx_text" style="font-size:70%;">(</span>Johnson and
Johnson<span id="S3.T1.1.1.4.3.2.1.1.15.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib53" title="" class="ltx_ref">1993</a><span id="S3.T1.1.1.4.3.2.1.1.16.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.4.3.2.1.1.17" class="ltx_text" style="font-size:70%;">
Why does the system think that I want/need X? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.2.1.1.18.1" class="ltx_text" style="font-size:70%;">(</span>Billsus and
Pazzani<span id="S3.T1.1.1.4.3.2.1.1.19.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib13" title="" class="ltx_ref">1999</a>; Donkers
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.2.1.1.19.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib29" title="" class="ltx_ref">2020</a><span id="S3.T1.1.1.4.3.2.1.1.20.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.4.3.2.1.1.21" class="ltx_text" style="font-size:70%;"> Why is this recommendation ranked at the top? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.2.1.1.22.1" class="ltx_text" style="font-size:70%;">(</span>Tsai and
Brusilovsky<span id="S3.T1.1.1.4.3.2.1.1.23.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib95" title="" class="ltx_ref">2019b</a><span id="S3.T1.1.1.4.3.2.1.1.24.3" class="ltx_text" style="font-size:70%;">)</span></cite></span>
</span>
</td>
<td id="S3.T1.1.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.4.3.3.1.1.1" class="ltx_text" style="font-size:70%;">Users gain insight into the system to </span><span id="S3.T1.1.1.4.3.3.1.1.2" class="ltx_text ltx_align_left ltx_font_italic" style="font-size:70%;">better use</span><span id="S3.T1.1.1.4.3.3.1.1.3" class="ltx_text" style="font-size:70%;"> it.</span></span>
</span>
</td>
<td id="S3.T1.1.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.4.3.4.1.1.1" class="ltx_text" style="font-size:70%;">Users get informed by the system.</span></span>
</span>
</td>
<td id="S3.T1.1.1.4.3.5" class="ltx_td ltx_nopad_r ltx_align_justify" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.5.1.1" class="ltx_p"><span id="S3.T1.1.1.4.3.5.1.1.1" class="ltx_text" style="font-size:70%;">Users get information about </span><span id="S3.T1.1.1.4.3.5.1.1.2" class="ltx_text ltx_font_italic" style="font-size:70%;">outputs</span><span id="S3.T1.1.1.4.3.5.1.1.3" class="ltx_text" style="font-size:70%;"> and </span><span id="S3.T1.1.1.4.3.5.1.1.4" class="ltx_text ltx_font_italic" style="font-size:70%;">processes</span><span id="S3.T1.1.1.4.3.5.1.1.5" class="ltx_text" style="font-size:70%;">. Explanations should be relevant to the user.
They should be “sound and complete”, but not overwhelming </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.1.1.4.3.5.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Kulesza et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.5.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib65" title="" class="ltx_ref">2013</a>; Kulesza
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.4.3.5.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib62" title="" class="ltx_ref">2015</a><span id="S3.T1.1.1.4.3.5.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.4.3.5.1.1.9" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.5.4.1.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Intelligibility</span></span>
</span>
</td>
<td id="S3.T1.1.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.5.4.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Why did the system do X?
How / under what conditions does it do Y?
Why did not do Y?
What (else) is it doing?
What if there is a change in conditions, what would happen? <cite class="ltx_cite ltx_citemacro_citep">(Lim and Dey, <a href="#bib.bib70" title="" class="ltx_ref">2009</a>; Coppers et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span>
</td>
<td id="S3.T1.1.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.5.4.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users want to use the system in <span id="S3.T1.1.1.5.4.3.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">better</span> ways or to gain trust <cite class="ltx_cite ltx_citemacro_citep">(Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>; Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2020a</a>)</cite>.</span></span>
</span>
</td>
<td id="S3.T1.1.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.5.4.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users actively inquire into the system’s inner workings.</span></span>
</span>
</td>
<td id="S3.T1.1.1.5.4.5" class="ltx_td ltx_nopad_r ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.5.1.1" class="ltx_p"><span id="S3.T1.1.1.5.4.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users seek information about <span id="S3.T1.1.1.5.4.5.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">outputs</span> and <span id="S3.T1.1.1.5.4.5.1.1.1.2" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">processes</span>. Users’ demand informs what is relevant. Factors related to system and context influence this <cite class="ltx_cite ltx_citemacro_citep">(Lim and Dey, <a href="#bib.bib70" title="" class="ltx_ref">2009</a>)</cite>.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.6.5" class="ltx_tr">
<td id="S3.T1.1.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.6.5.1.1.1.1" class="ltx_text" style="font-size:70%;">Interactivity (interactive machine learning)</span></span>
</span>
</td>
<td id="S3.T1.1.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.6.5.2.1.1.1" class="ltx_text" style="font-size:70%;">How I can assess the state of the learned concept?
Where does the model fail?
Why did the system fail in this specific instance? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.6.5.2.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Dudley and
Kristensson<span id="S3.T1.1.1.6.5.2.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib32" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.6.5.2.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.6.5.2.1.1.5" class="ltx_text" style="font-size:70%;">
How well does the system know the domain?
How sure is the system that a given output is correct?
Did the system do a simple or complex thing to arrive at the output? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.6.5.2.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Sarkar<span id="S3.T1.1.1.6.5.2.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib85" title="" class="ltx_ref">2015</a><span id="S3.T1.1.1.6.5.2.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.6.5.2.1.1.9" class="ltx_text" style="font-size:70%;">
How to combine models? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.6.5.2.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Talbot
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.6.5.2.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib92" title="" class="ltx_ref">2009</a><span id="S3.T1.1.1.6.5.2.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.6.5.2.1.1.13" class="ltx_text" style="font-size:70%;">
Which model works best? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.6.5.2.1.1.14.1" class="ltx_text" style="font-size:70%;">(</span>Amershi et al<span class="ltx_text">.</span><span id="S3.T1.1.1.6.5.2.1.1.15.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib8" title="" class="ltx_ref">2015</a><span id="S3.T1.1.1.6.5.2.1.1.16.3" class="ltx_text" style="font-size:70%;">)</span></cite></span>
</span>
</td>
<td id="S3.T1.1.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.6.5.3.1.1.1" class="ltx_text" style="font-size:70%;">Users inspect the system state to </span><span id="S3.T1.1.1.6.5.3.1.1.2" class="ltx_text ltx_align_left ltx_font_italic" style="font-size:70%;">refine</span><span id="S3.T1.1.1.6.5.3.1.1.3" class="ltx_text" style="font-size:70%;"> it or guide its training </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.6.5.3.1.1.4.1" class="ltx_text" style="font-size:70%;">(</span>Dudley and
Kristensson<span id="S3.T1.1.1.6.5.3.1.1.5.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib32" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.6.5.3.1.1.6.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.6.5.3.1.1.7" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S3.T1.1.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.6.5.4.1.1.1" class="ltx_text" style="font-size:70%;">Users iteratively refine the system and guide its training by giving feedback </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.6.5.4.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Dudley and
Kristensson<span id="S3.T1.1.1.6.5.4.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib32" title="" class="ltx_ref">2018</a><span id="S3.T1.1.1.6.5.4.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.6.5.4.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S3.T1.1.1.6.5.5" class="ltx_td ltx_nopad_r ltx_align_justify" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.5.1.1" class="ltx_p"><span id="S3.T1.1.1.6.5.5.1.1.1" class="ltx_text" style="font-size:70%;">Users need to understand </span><span id="S3.T1.1.1.6.5.5.1.1.2" class="ltx_text ltx_font_italic" style="font-size:70%;">outputs</span><span id="S3.T1.1.1.6.5.5.1.1.3" class="ltx_text" style="font-size:70%;">, </span><span id="S3.T1.1.1.6.5.5.1.1.4" class="ltx_text ltx_font_italic" style="font-size:70%;">processes</span><span id="S3.T1.1.1.6.5.5.1.1.5" class="ltx_text" style="font-size:70%;">, and </span><span id="S3.T1.1.1.6.5.5.1.1.6" class="ltx_text ltx_font_italic" style="font-size:70%;">interactions</span><span id="S3.T1.1.1.6.5.5.1.1.7" class="ltx_text" style="font-size:70%;"> to guide the system.
What is relevant to know is defined by the machine learning task that users and system solve together.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.7.6" class="ltx_tr">
<td id="S3.T1.1.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.7.6.1.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Interpretability</span></span>
</span>
</td>
<td id="S3.T1.1.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.7.6.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">How sensible – and not arbitrary or random – is the system? <cite class="ltx_cite ltx_citemacro_citep">(Alqaraawi et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>; Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>
<span id="S3.T1.1.1.7.6.2.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">Why?</span> questions <cite class="ltx_cite ltx_citemacro_citep">(Gilpin et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2018</a>)</cite>
Can you trust your model?
What else can it tell you about the world? <cite class="ltx_cite ltx_citemacro_citep">(Lipton, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite></span></span>
</span>
</td>
<td id="S3.T1.1.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.7.6.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users gain <span id="S3.T1.1.1.7.6.3.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">utilitarian</span> and <span id="S3.T1.1.1.7.6.3.1.1.1.2" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">interpretative</span> insight into the system to bridge the gap between the system’s criteria and full real-world context <cite class="ltx_cite ltx_citemacro_citep">(Doshi-Velez and
Kim, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Kim, <a href="#bib.bib57" title="" class="ltx_ref">2015</a>)</cite>.</span></span>
</span>
</td>
<td id="S3.T1.1.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.7.6.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users get information about the system’s inner workings <cite class="ltx_cite ltx_citemacro_citep">(Doshi-Velez and
Kim, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Lipton, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite>.</span></span>
</span>
</td>
<td id="S3.T1.1.1.7.6.5" class="ltx_td ltx_nopad_r ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.5.1.1" class="ltx_p"><span id="S3.T1.1.1.7.6.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users can access information about <span id="S3.T1.1.1.7.6.5.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">outputs</span> and <span id="S3.T1.1.1.7.6.5.1.1.1.2" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">processes</span>, which may include low-level (expert) information (e.g. on inner states <cite class="ltx_cite ltx_citemacro_citep">(Kim, <a href="#bib.bib57" title="" class="ltx_ref">2015</a>)</cite>). What is relevant to know depends on the user’s task with the system. Explicit call for rigorous evaluation <cite class="ltx_cite ltx_citemacro_citep">(Doshi-Velez and
Kim, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite>.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.8.7" class="ltx_tr">
<td id="S3.T1.1.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.8.7.1.1.1.1" class="ltx_text" style="font-size:70%;">Scrutability</span></span>
</span>
</td>
<td id="S3.T1.1.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.8.7.2.1.1.1" class="ltx_text" style="font-size:70%;">Why/How did the system do X?
What else does the system think I (don’t) know?
What would the system do if I did Y?
What does the system do for other people?
How can I tell the system what I (don’t) want? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.8.7.2.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Kay and
Kummerfeld<span id="S3.T1.1.1.8.7.2.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib56" title="" class="ltx_ref">2013</a><span id="S3.T1.1.1.8.7.2.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.8.7.2.1.1.5" class="ltx_text" style="font-size:70%;"> How can I efficiently improve recommendations? </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.8.7.2.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Balog
et al<span class="ltx_text">.</span><span id="S3.T1.1.1.8.7.2.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib12" title="" class="ltx_ref">2019</a><span id="S3.T1.1.1.8.7.2.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite></span>
</span>
</td>
<td id="S3.T1.1.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.8.7.3.1.1.1" class="ltx_text" style="font-size:70%;">Users want to be able to </span><span id="S3.T1.1.1.8.7.3.1.1.2" class="ltx_text ltx_align_left ltx_font_italic" style="font-size:70%;">interpret</span><span id="S3.T1.1.1.8.7.3.1.1.3" class="ltx_text" style="font-size:70%;"> the system’s decisions.
They may analyse and control it for more </span><span id="S3.T1.1.1.8.7.3.1.1.4" class="ltx_text ltx_align_left ltx_font_italic" style="font-size:70%;">efficient</span><span id="S3.T1.1.1.8.7.3.1.1.5" class="ltx_text" style="font-size:70%;"> use.</span></span>
</span>
</td>
<td id="S3.T1.1.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.8.7.4.1.1.1" class="ltx_text" style="font-size:70%;">System decision and behaviour is based on a user model, which users can adequately access and control.
Users make “real effort” </span><cite class="ltx_cite ltx_align_left ltx_citemacro_citep"><span id="S3.T1.1.1.8.7.4.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Kay and
Kummerfeld<span id="S3.T1.1.1.8.7.4.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib56" title="" class="ltx_ref">2013</a><span id="S3.T1.1.1.8.7.4.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S3.T1.1.1.8.7.4.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S3.T1.1.1.8.7.5" class="ltx_td ltx_nopad_r ltx_align_justify" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.5.1.1" class="ltx_p"><span id="S3.T1.1.1.8.7.5.1.1.1" class="ltx_text" style="font-size:70%;">Users gain understanding of </span><span id="S3.T1.1.1.8.7.5.1.1.2" class="ltx_text ltx_font_italic" style="font-size:70%;">outputs</span><span id="S3.T1.1.1.8.7.5.1.1.3" class="ltx_text" style="font-size:70%;"> and </span><span id="S3.T1.1.1.8.7.5.1.1.4" class="ltx_text ltx_font_italic" style="font-size:70%;">processes</span><span id="S3.T1.1.1.8.7.5.1.1.5" class="ltx_text" style="font-size:70%;">.
They may also learn about </span><span id="S3.T1.1.1.8.7.5.1.1.6" class="ltx_text ltx_font_italic" style="font-size:70%;">interactions</span><span id="S3.T1.1.1.8.7.5.1.1.7" class="ltx_text" style="font-size:70%;"> to influence how the system uses the user model. Information should be relevant to users, yet they may also learn about what the system considers relevant.</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.9.8" class="ltx_tr">
<td id="S3.T1.1.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.1.1.1" class="ltx_p" style="width:38.5pt;"><span id="S3.T1.1.1.9.8.1.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Transparency</span></span>
</span>
</td>
<td id="S3.T1.1.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.9.8.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">How does the system produce an output (i.e. data sources, reasoning steps)?
Why did the system do sth. (i.e. justification, motivation behind the system)?
What is informed by the intelligent system (i.e. reveal existence of intelligent processing)?
How was the system developed and how is it continually being improved? <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite> How did the system produce the model? <cite class="ltx_cite ltx_citemacro_citep">(Drozdal et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span>
</td>
<td id="S3.T1.1.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.3.1.1" class="ltx_p" style="width:49.0pt;"><span id="S3.T1.1.1.9.8.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users <span id="S3.T1.1.1.9.8.3.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">interpret</span> the system’s output and question the underlying mechanisms.</span></span>
</span>
</td>
<td id="S3.T1.1.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.4.1.1" class="ltx_p" style="width:70.0pt;"><span id="S3.T1.1.1.9.8.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users get informed by the system.</span></span>
</span>
</td>
<td id="S3.T1.1.1.9.8.5" class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_bb" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S3.T1.1.1.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.5.1.1" class="ltx_p"><span id="S3.T1.1.1.9.8.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Users seek understanding of <span id="S3.T1.1.1.9.8.5.1.1.1.1" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">outputs</span> and <span id="S3.T1.1.1.9.8.5.1.1.1.2" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">processes</span>, also beyond use (<span id="S3.T1.1.1.9.8.5.1.1.1.3" class="ltx_text ltx_font_italic" style="background-color:#EFEFEF;">meta</span>). What is relevant – and to what extent – may depend on the context of the user’s inquiry.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>The system qualities in focus of our work through the lens of our framework, along with example user questions and implied user mindsets, user involvement, and knowledge outcomes. Note that we do not attempt to redefine the terms here but rather provide a guiding overview of our coding, which includes some overlap between terms, as found in the literature.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Method</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Here, we shortly describe the process of paper collection and interpretation through which we derived our framework.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Theoretical Sampling</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Our paper set was collected using <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">theoretical sampling</span>, an approach to collection of qualitative data introduced by Glaser and Strauss as a part of Grounded Theory <cite class="ltx_cite ltx_citemacro_citep">(Glaser and
Strauss, <a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite>. In contrast to statistical sampling, where the sample size is fixed a priori, theoretical sampling gradually defines the sample during the interpretation process until <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">theoretical saturation</span> is reached (i.e. the point where further data and interpretation does not further enrich the emerging categories).</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">We started our sampling by looking for a set of the most widely-adopted system qualities in the field. We did so first through collecting search terms for system qualities based on our experiences as researchers
working at the intersection of HCI and AI for several years and then expanded our set of system qualities through the topic networks presented by Abdul et al. <cite class="ltx_cite ltx_citemacro_citep">(Abdul et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> in their 2018 survey of over 12,000 papers at this intersection. Their analysis surfaced many system qualities that we sought to address a priori (e.g. interpretability, scrutability,
explainability), but also related topics (e.g. accountability and different types of transparency).
With keyword searches on the ACM Digital Library, we then iteratively collected papers on these terms, following the above sampling method. We started out with the most cited papers in the field, which we interpreted as described in Section <a href="#S4.SS2" title="4.2. Paper Coding and Interpretation ‣ 4. Method ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> to create first categories. Papers were selected to represent the diversity of approaches in the field, but also according to the below criteria:</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">The presented contribution focuses on the system qualities and is linked to <span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">intelligent</span> systems, and</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">the contribution involves an HCI perspective (e.g. via a prototype,
user study, design guidelines, etc.).</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">Papers were re-visited if necessary, and we integrated new data through snowball searches as well as through updated keyword searches when we extended our system qualities set. Overall, 222 papers contributed to this process before we considered our categories to be theoretically saturated and had defined our framework dimensions. The final set of system qualities emerging from this process included <span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_italic">scrutability, interpretability, transparency, explainability, intelligibility, interactivity (interactive Machine Learning), debuggability (end-user debugging), and accountability</span>.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">The paper set used is available on the project website:
<a target="_blank" href="https://www.medien.ifi.lmu.de/howtosupport/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.medien.ifi.lmu.de/howtosupport/</a></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Paper Coding and Interpretation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We followed the coding process as suggested by Glaser and Strauss <cite class="ltx_cite ltx_citemacro_citep">(Glaser and
Strauss, <a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite> and Strauss and Cobin <cite class="ltx_cite ltx_citemacro_citep">(Strauss and
Corbin, <a href="#bib.bib91" title="" class="ltx_ref">1998</a>)</cite> to code the papers. The coding was done by the first two authors, in joint work on the texts and discussion.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Open Coding: Opening Up the Text</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">To keep the coding process manageable, we mainly focused on the motivation, contribution and conclusion of a paper, making use of the flexibility of the approach to include other sections as needed for a clearer understanding.
We first collected open codes about the assumptions on supporting user understanding made in the text. Open coding was guided by so-called basic questions <cite class="ltx_cite ltx_citemacro_citep">(Glaser and
Strauss, <a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite> (e.g. <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">Who?, What?, How?</span>, etc.).</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">This step resulted in a first set of (sub-)categories, namely
<span id="S4.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">Motivation (of the work), Key Phenomena and Constructs, Support as Property or Process, Reference to Specific System Part, Main Goal of Support, Main Challenge of Support, User Role, System Role, Interaction Design Implications</span>, and <span id="S4.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_italic">Concrete Realisation</span>.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Axial Coding: Eliciting User Questions</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">We then created axial codes to refine and differentiate our categories. During this process, we realised that suitable axial codes could be expressed in the form of questions users have about the workings of intelligent systems (e.g. <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Why did the system do X?</span>).
This is in line with prior work: First established by Lim and Dey <cite class="ltx_cite ltx_citemacro_citep">(Lim and Dey, <a href="#bib.bib70" title="" class="ltx_ref">2009</a>; Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>)</cite> as a manifestation for users’ information demand, such <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">user questions</span> have gained popularity in related work on the system qualities as a way of
anchoring design suggestions and solutions, even if these questions are not always elicited
from actual users (e.g., cf. work by Kay and
Kummerfeld <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite> (scrutability), Kulesza et al. <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite>
(end-user debugging), or Rader et al. <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>
(transparency/accountability)).</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">In our case, coding these questions helped us to extract and contrast underlying perspectives: On the one hand,
they connected prior work on the system qualities, on the other they revealed conceptual differences, and thus refined our preliminary categories.
During this process, we kept close to the text of a paper. For example, “Accountability […] the extent to which participants think the system is fair and they can control the outputs the system produced” <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite> yielded “How fair and controllable is the system?” in our question set. We continuously moved back and forth between the texts and our preliminary categories when integrating new user questions to test our categories against the text passages.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p id="S4.SS2.SSS2.p3.1" class="ltx_p">As the outcome of this coding step, we (1) refined the categories elicited in the open coding, and (2) discovered differences and commonalities between the system qualities by grouping user questions according to the quality in focus of a paper (see Table <a href="#S3.T1" title="Table 1 ‣ 3.3. User Knowledge and Understanding ‣ 3. Scope and Foundations ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for an excerpt; please note that one question could be relevant for multiple system qualities).</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Selective Coding: Building the Framework</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">In the last step, we identified core concepts overarching our categories. Practically, we wrote our user questions on cards we re-arranged on a large wall, plus example papers and stickers for possible core concepts. This set-up was then discussed extensively over several weeks and extended through further paper collection and reviewing. As a result, we identified and defined our framework dimensions presented in Section <a href="#S5" title="5. A User-Centered Framework for Supporting Users in Understanding Intelligent Systems ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Limitations</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Our framework should be understood and applied with several limitations in mind:</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">First, as work on interactive intelligent systems has evolved into a rapidly developing field in the last decade, future approaches might uncover solutions and principles that the presented framework does not cover in its current state.
Second, this work focuses on eight system qualities, listed in Section <a href="#S4.SS1" title="4.1. Theoretical Sampling ‣ 4. Method ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. Since this set was shaped through our sampling process, we are confident that it covers a representative part of the diverse approaches and reflections in the field. However, it is not comprehensive. For a detailed overview of possible system qualities, see <cite class="ltx_cite ltx_citemacro_citet">Abdul et al<span class="ltx_text">.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite>.
Third, our paper set is mainly based on work accessible through the ACM Digital Library. We also included work published through IEEE, Springer, and Elsevier, among others, but only through snowball searches, not as a main database, to keep our paper set at a manually manageable size.
Overall, these limitations might create the need to build on, extend and adapt the framework in future work.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Finally, this work focuses on HCI <span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">researchers</span> as a target audience. In Section <a href="#S6.SS3.SSS1" title="6.3.1. Inspiring New Approaches in Research and Practice ‣ 6.3. Going Beyond ‣ 6. Framework Application: Structuring Past &amp; Future Work ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3.1</span></a>, we suggest ideas on how our framework might be applied to commercial systems and thus serve practitioners, too. However, these ideas still need to be validated in the future, for example, through interviews with designers and developers, or by prototyping applications using the framework dimensions and evaluating them with end-users.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>A User-Centered Framework for Supporting Users in Understanding Intelligent Systems</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our analysis revealed three categories that capture and differentiate current
assumptions about users and interaction with intelligent systems. They thus
serve as a conceptual framework for structuring the discussion about supporting
users in understanding intelligent systems from an HCI perspective, as presented in the next sections.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>What do Users Seek to Know? User Mindsets</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The user questions addressed in work on different system qualities imply different
assumptions about <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">what users seek to know</span>: For example, searching for
information about <span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_italic">why</span> a certain system output came into
being <cite class="ltx_cite ltx_citemacro_citep">(Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>)</cite> implies a very different kind of interest than wanting to
know <span id="S5.SS1.p1.1.3" class="ltx_text ltx_font_italic">how well a program knows a given domain</span> <cite class="ltx_cite ltx_citemacro_citep">(Sarkar, <a href="#bib.bib85" title="" class="ltx_ref">2015</a>)</cite> or
<span id="S5.SS1.p1.1.4" class="ltx_text ltx_font_italic">how a system was developed and continually improved</span> <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>.
Likewise, this is true for users asking <span id="S5.SS1.p1.1.5" class="ltx_text ltx_font_italic">how to correct system
errors</span> <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite> compared to users that want to be merely
<span id="S5.SS1.p1.1.6" class="ltx_text ltx_font_italic">informed</span> about the presence of algorithmic
decision-making <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">To capture these differences, we introduce the category <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">user mindsets</span>.
In psychological research, mindsets describe the “cognitive orientation” of
people that precede the formation of intentions and planning of successive
actions towards reaching a goal <cite class="ltx_cite ltx_citemacro_citep">(Gollwitzer, <a href="#bib.bib39" title="" class="ltx_ref">1993</a>)</cite>. In the same manner, for
this work we define <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">user mindsets</span> as <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_italic">users’ cognitive
orientation that guides concrete intentions to interact with an intelligent
system</span>.
From our analysis emerged three such mindsets that we find in prior work on the
system qualities: <span id="S5.SS1.p2.1.4" class="ltx_text ltx_font_italic">utilitarian</span>, <span id="S5.SS1.p2.1.5" class="ltx_text ltx_font_italic">interpretive</span>, and <span id="S5.SS1.p2.1.6" class="ltx_text ltx_font_italic">critical</span>,
described in detail next.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>Utilitarian Mindset</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">A utilitarian mindset <span id="S5.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">aims to predict and control system behaviour to
reach a practical goal</span>. This mindset carries a strong notion of
<span id="S5.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_italic">utility</span> and/or <span id="S5.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_italic">usability</span>.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p">Consequently, a utilitarian mindset is reflected by many examples in work on
system qualities that imply a very practical view on user inquiry, such as in work
on explainability and intelligibility. For example, users might want to
understand system recommendations to <span id="S5.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_italic">better compare and find</span> products they are interested in (<span id="S5.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_italic">Why was this recommended to me?</span>) <cite class="ltx_cite ltx_citemacro_citep">(Pu and Chen, <a href="#bib.bib81" title="" class="ltx_ref">2006</a>)</cite>. Moreover,
users might want to <span id="S5.SS1.SSS1.p2.1.3" class="ltx_text ltx_font_italic">train more effectively</span> with an intelligent
fitness coach <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite>, or understand a system ranking they <span id="S5.SS1.SSS1.p2.1.4" class="ltx_text ltx_font_italic">financially
depend on</span>, as observed in AirBnB <cite class="ltx_cite ltx_citemacro_citep">(Jhaver
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2018</a>)</cite> or social
media <cite class="ltx_cite ltx_citemacro_citep">(Bucher, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite>. In another example, users worked more efficiently with a system
feedforward based on <span id="S5.SS1.SSS1.p2.1.5" class="ltx_text ltx_font_italic">What if?</span> questions <cite class="ltx_cite ltx_citemacro_citep">(Coppers et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. Similarly, user questions in
work on scrutability such as <span id="S5.SS1.SSS1.p2.1.6" class="ltx_text ltx_font_italic">How can I efficiently improve recommendations?</span> <cite class="ltx_cite ltx_citemacro_citep">(Balog
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> imply a utilitarian mindset.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para">
<p id="S5.SS1.SSS1.p3.1" class="ltx_p">On a meta-level, this mindset can also be found in work on
interactive machine learning and end-user debugging. Research in these areas
addresses user questions such as <span id="S5.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_italic">How can I assess the state of the
learned concept? Where does the model fail?</span> <cite class="ltx_cite ltx_citemacro_citep">(Dudley and
Kristensson, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>, <span id="S5.SS1.SSS1.p3.1.2" class="ltx_text ltx_font_italic">How sure
is the system that a given output is correct?</span> <cite class="ltx_cite ltx_citemacro_citep">(Sarkar, <a href="#bib.bib85" title="" class="ltx_ref">2015</a>)</cite>, <span id="S5.SS1.SSS1.p3.1.3" class="ltx_text ltx_font_italic">How to
combine models?</span> <cite class="ltx_cite ltx_citemacro_citep">(Talbot
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2009</a>)</cite>, <span id="S5.SS1.SSS1.p3.1.4" class="ltx_text ltx_font_italic">Which model works
best?</span> <cite class="ltx_cite ltx_citemacro_citep">(Amershi et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2015</a>)</cite>, or <span id="S5.SS1.SSS1.p3.1.5" class="ltx_text ltx_font_italic">How do changes affect the rest of the
system?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2008</a>)</cite>. These and similar questions imply a focus on
recognising and handling system error, giving feedback, or analysing the system
to better work with it in the future.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>Interpretive Mindset</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">An interpretive mindset <span id="S5.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">strives to interpret system actions based on
one’s perception of and experience with the system and its output.</span> This mindset
embraces the notion of <span id="S5.SS1.SSS2.p1.1.2" class="ltx_text ltx_font_italic">user experience</span>.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">When users adopt this mindset, they do not necessarily want to reach a
particular practical goal, but rather to understand the system based on a
certain experience they have made. For example, a social media user might want
to understand why posts of particular friends are not shown <cite class="ltx_cite ltx_citemacro_citep">(Bucher, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite>.
Moreover, an interpretive mindset might be adopted by users who do not
understand how they are being profiled, when they believe their feedback is not
being considered or feel they lack control over system output <cite class="ltx_cite ltx_citemacro_citep">(Bucher, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para">
<p id="S5.SS1.SSS2.p3.1" class="ltx_p">Examples for an (implied) interpretive mindset can be found in work on
transparency (e.g. <span id="S5.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_italic">How sensible – and not arbitrary or random – is the
system?</span> <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>) and interpretability (e.g. <span id="S5.SS1.SSS2.p3.1.2" class="ltx_text ltx_font_italic">What else can the
model tell me about the world?</span> <cite class="ltx_cite ltx_citemacro_citep">(Lipton, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite>). Moreover, it is reflected in
many user questions articulated in work on scrutability, for example
<span id="S5.SS1.SSS2.p3.1.3" class="ltx_text ltx_font_italic">What else does the system think I (don’t) know?</span>, <span id="S5.SS1.SSS2.p3.1.4" class="ltx_text ltx_font_italic">What would the
system do if I did Y?</span>, or <span id="S5.SS1.SSS2.p3.1.5" class="ltx_text ltx_font_italic">What does the system do for other
people?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>. Although control also plays an important role in
research in this field, the underlying perspective is framed in terms of
experience with and perception of the system and its output rather than a
practical goal.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>Critical mindset</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">A critical mindset <span id="S5.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">stresses normative, ethical and legal reflection
about intelligent systems.</span></p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p">This echoes the wider discussion about the system qualities, such as
transparency, explainability and accountability (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Eiband
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2018a</a>; Hildebrandt, <a href="#bib.bib45" title="" class="ltx_ref">2016</a>; Mittelstadt et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2016</a>; Wachter
et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2017a</a>, <a href="#bib.bib100" title="" class="ltx_ref">b</a>)</cite>). For example, a
user might critique a system’s missing social
intelligence <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Bucher, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite> or might want to know why it was
developed in a certain way <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>. A critical mindset may thus be decoupled from system use.</p>
</div>
<div id="S5.SS1.SSS3.p3" class="ltx_para">
<p id="S5.SS1.SSS3.p3.1" class="ltx_p">Calls for support of critical inquiry are mainly found in work on system
accountability. User questions include <span id="S5.SS1.SSS3.p3.1.1" class="ltx_text ltx_font_italic">How was the system developed and
how is it continually being improved?</span>, <span id="S5.SS1.SSS3.p3.1.2" class="ltx_text ltx_font_italic">What is informed by the
intelligent system (i.e. reveal existence of intelligent decision-making and
processing)?</span>, <span id="S5.SS1.SSS3.p3.1.3" class="ltx_text ltx_font_italic">How fair and controllable is the
system?</span> <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>, <span id="S5.SS1.SSS3.p3.1.4" class="ltx_text ltx_font_italic">How fair is a system
decision?</span> <cite class="ltx_cite ltx_citemacro_citep">(Binns et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite> or <span id="S5.SS1.SSS3.p3.1.5" class="ltx_text ltx_font_italic">Can I trust this
model?</span> <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite> and <span id="S5.SS1.SSS3.p3.1.6" class="ltx_text ltx_font_italic">Should I trust this
prediction?</span> <cite class="ltx_cite ltx_citemacro_citep">(Herlocker
et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2000</a>; Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S5.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS3.p4.1" class="ltx_p"><span id="S5.SS1.SSS3.p4.1.1" class="ltx_text" style="background-color:#EFEFEF;">

<span id="S5.SS1.SSS3.p4.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:424.9pt;"><img src="/html/2001.08301/assets/x2.png" id="S5.SS1.SSS3.p4.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="10" height="10" alt="[Uncaptioned image]">
<span id="S5.SS1.SSS3.p4.1.1.1.1.1" class="ltx_p"><span id="S5.SS1.SSS3.p4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">User mindsets</span> help to understand what users seek to know when interacting with an intelligent system. We should thus make explicit which mindset(s) we assume as a basis for our work (e.g. utilitarian, interpretive or critical).</span>
</span>
</span></p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>How do Users Gain Knowledge? User Involvement</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">As introduced in the Scope and Foundations section of this paper, we assume that user understanding is built through the <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">transmission of information</span> between user and system.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Our analysis revealed that the great majority of work on the system qualities envisions this transmission of information in the form of a <span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_italic">dialogue</span>, that is as a “cycle of communication acts channelled through input/output from the machine perspective, or perception/action from the human perspective” <cite class="ltx_cite ltx_citemacro_citep">(Hornbæk and
Oulasvirta, <a href="#bib.bib48" title="" class="ltx_ref">2017</a>)</cite>. Dialogue as an interaction concept inherently stresses the need for users to understand the system (and vice versa) <cite class="ltx_cite ltx_citemacro_citep">(Hornbæk and
Oulasvirta, <a href="#bib.bib48" title="" class="ltx_ref">2017</a>)</cite>.
It has even been argued that the characteristics of intelligent systems <span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_italic">necessarily</span> involve some sort of dialogue in order for users to understand them <cite class="ltx_cite ltx_citemacro_citep">(Sarkar, <a href="#bib.bib85" title="" class="ltx_ref">2015</a>)</cite>. Elements of dialogue, such as structuring interaction as <span id="S5.SS2.p2.1.3" class="ltx_text ltx_font_italic">stages</span> <cite class="ltx_cite ltx_citemacro_citep">(Hornbæk and
Oulasvirta, <a href="#bib.bib48" title="" class="ltx_ref">2017</a>)</cite>, are commonly found in work on the system qualities. Most notably, end-user debugging <cite class="ltx_cite ltx_citemacro_citep">(Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>)</cite> and interactive machine learning <cite class="ltx_cite ltx_citemacro_citep">(Kapoor
et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2010</a>)</cite> make use of mixed-initiative interfaces <cite class="ltx_cite ltx_citemacro_citep">(Horvitz, <a href="#bib.bib49" title="" class="ltx_ref">1999</a>)</cite>. It thus seems that the system qualities almost <span id="S5.SS2.p2.1.4" class="ltx_text ltx_font_italic">imply</span> this concept of interaction, so closely are they interwoven with a dialogue structure.
To support users in understanding intelligent systems, information may thus be transferred in two directions, either from user to system, or from system to user. From a user perspective, this determines <span id="S5.SS2.p2.1.5" class="ltx_text ltx_font_italic">how users gain knowledge</span> – either through action (active) or perception (passive).</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Our second framework category, <span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_italic">user involvement</span>, captures these two ways of gaining knowledge. <span id="S5.SS2.p3.1.2" class="ltx_text ltx_font_italic">User involvement</span> thus describes <span id="S5.SS2.p3.1.3" class="ltx_text ltx_font_italic">interaction possibilities to transfer information to or receive information from the system as a basis for user understanding</span>.
In the following sections, we distinguish work on the system qualities according to these two directions. In general, a system might support involvement in multiple ways (e.g. via explanation, controls, visualisations) and thus imply transitioning between both directions during use, for example, through interactive visual explanations <cite class="ltx_cite ltx_citemacro_citep">(Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Active User Involvement (User-to-System)</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">User questions such as <span id="S5.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">How can I tell the system what I want?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>, <span id="S5.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_italic">How can I detect system errors?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite>, or <span id="S5.SS2.SSS1.p1.1.3" class="ltx_text ltx_font_italic">What do I have to change to correct the system?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite> point to active users whose corrections and feedback are utilised by the system. The dialogue between system and user may be initiated by both sides and is then indeed based on turn-taking, as described earlier. For example, Alkan et al. <cite class="ltx_cite ltx_citemacro_citep">(Alkan et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> presented a career goal recommender that literally employs a dialogue structure to suggest items and incorporate user feedback. Work on scrutability by Kay and Kummerfeld <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite> emphasises the “real effort” users must make when inquiring into a system. Other work on the system qualities, in particular in end-user-debugging and interactive machine learning, sees users in active roles as debuggers <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2010</a>)</cite> or teachers <cite class="ltx_cite ltx_citemacro_citep">(Amershi
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>)</cite>.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">Systems support an active user by offering <span id="S5.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">interface controls</span> tied to aspects of their “intelligence” (e.g. data processing, user model). These controls may enable users to experiment with the intelligent system (e.g. user model controls <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>). For example, if a user interface offers switches for certain data sources (e.g. in a settings view), users can actively experiment with the way that these data sources influence system output (e.g. switch off GPS to see how recommendations change in a city guide app; also see <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>). Moreover, Coppers et al. <cite class="ltx_cite ltx_citemacro_citep">(Coppers et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> introduced widgets for system feedforward that allow for active inquiry to answer <span id="S5.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_italic">What if?</span> user questions such as <span id="S5.SS2.SSS1.p2.1.3" class="ltx_text ltx_font_italic">What will happen if I click this checkbox?</span>.
Another example is a separate, dedicated GUI for such experimentation, which allows users to directly set the values of certain system inputs and check the resulting output (e.g. “intelligibility testing” <cite class="ltx_cite ltx_citemacro_citep">(Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>)</cite>).</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para">
<p id="S5.SS2.SSS1.p3.1" class="ltx_p">Moreover, many visual explanations offer direct manipulation that also puts users into an active role: For instance, work in interactive machine learning proposed interactions with classifier confusion matrices to express desired changes in resulting decisions <cite class="ltx_cite ltx_citemacro_citep">(Kapoor
et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2010</a>; Talbot
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2009</a>)</cite>. Similarly, work on explanations for spam filtering enabled users to influence the classifier via interactive bar charts of word importance <cite class="ltx_cite ltx_citemacro_citep">(Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Passive User Involvement (System-to-User)</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">User questions such as <span id="S5.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Why does the system think that I want/need X?</span> <cite class="ltx_cite ltx_citemacro_citep">(Billsus and
Pazzani, <a href="#bib.bib13" title="" class="ltx_ref">1999</a>)</cite>, <span id="S5.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Why did the system do X?</span> <cite class="ltx_cite ltx_citemacro_citep">(Lim and Dey, <a href="#bib.bib70" title="" class="ltx_ref">2009</a>; Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>, <span id="S5.SS2.SSS2.p1.1.3" class="ltx_text ltx_font_italic">Why did it not do Y?</span> <cite class="ltx_cite ltx_citemacro_citep">(Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>)</cite> or <span id="S5.SS2.SSS2.p1.1.4" class="ltx_text ltx_font_italic">How does the system produce an output?</span> <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite> suggest that users want to get informed about the systems inner workings, but do not actively provide the system with feedback and corrections. Users may still initiate the dialogue with the system, but are then restricted to be recipients of information. This way of user involvement is typically assumed by work on transparency and explainability, where <span id="S5.SS2.SSS2.p1.1.5" class="ltx_text ltx_font_italic">displaying information</span> about a system’s inner workings is a common tool for user support. For example, related work proposed visual and textual explanations that show how recommendations are influenced by data from customers with similar preferences <cite class="ltx_cite ltx_citemacro_citep">(Gedikli
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2014</a>)</cite>.
Further examples of supporting user understanding in a passive way include icons that indicate “intelligent” data processing <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite>, interaction history <cite class="ltx_cite ltx_citemacro_citep">(Hussein and
Neuhaus, <a href="#bib.bib50" title="" class="ltx_ref">2010</a>)</cite>, annotations for specific recommendations <cite class="ltx_cite ltx_citemacro_citep">(Blanco et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2012</a>)</cite>, and plots and image highlighting for classification decisions <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite> or recommendations <cite class="ltx_cite ltx_citemacro_citep">(Tsai and
Brusilovsky, <a href="#bib.bib94" title="" class="ltx_ref">2019a</a>)</cite>.</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p"><span id="S5.SS2.SSS2.p2.1.1" class="ltx_text">
<span id="S5.SS2.SSS2.p2.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:424.9pt;background-color:#EFEFEF;"><img src="/html/2001.08301/assets/x3.png" id="S5.SS2.SSS2.p2.1.1.1.g1" class="ltx_graphics ltx_img_square" width="10" height="10" alt="[Uncaptioned image]">
<span id="S5.SS2.SSS2.p2.1.1.1.1" class="ltx_p"><span id="S5.SS2.SSS2.p2.1.1.1.1.1" class="ltx_text ltx_font_bold">User involvement</span> describes how user knowledge is built during interaction with a system. This depends on the direction of information transmission between user to system (e.g. users are involved in an active or passive way). We should explicitly state the nature of user involvement and how it is manifested in and supported through design.</span>
</span></span></p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Which Knowledge Do Users Gain? Knowledge Outcomes</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The envisioned result of the different system qualities is knowledge that users gain about an intelligent system. However, this knowledge may refer to different aspects of the system and interaction, such as a specific recommendation <cite class="ltx_cite ltx_citemacro_citep">(Pu and Chen, <a href="#bib.bib81" title="" class="ltx_ref">2006</a>)</cite> or the “reasoning” of a system <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite>.
To account for this variety of <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_italic">which knowledge users gain</span>, we introduce our third framework category, <span id="S5.SS3.p1.1.2" class="ltx_text ltx_font_italic">knowledge outcomes</span>. These <span id="S5.SS3.p1.1.3" class="ltx_text ltx_font_italic">characterise the nature of user understanding developed about an intelligent system</span>.
Overall, our analysis surfaced four different knowledge outcomes currently addressed in the literature (<span id="S5.SS3.p1.1.4" class="ltx_text ltx_font_italic">output</span>, <span id="S5.SS3.p1.1.5" class="ltx_text ltx_font_italic">process</span>, <span id="S5.SS3.p1.1.6" class="ltx_text ltx_font_italic">interaction</span>, and <span id="S5.SS3.p1.1.7" class="ltx_text ltx_font_italic">meta</span>). Since output and process knowledge are often confronted in the literature, we present them in one subsection here, too.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">These knowledge outcomes are not unique to HCI or intelligent systems. For example, output and process knowledge can be found in work on theory on gaining knowledge in practice <cite class="ltx_cite ltx_citemacro_citep">(Lynham, <a href="#bib.bib74" title="" class="ltx_ref">2002</a>)</cite>. Moreover, work on complex problem solving articulates output, process and structural knowledge <cite class="ltx_cite ltx_citemacro_citep">(Schoppek, <a href="#bib.bib88" title="" class="ltx_ref">2002</a>)</cite>, the latter being similar to our interaction knowledge.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">We also introduce two <span id="S5.SS3.p3.1.1" class="ltx_text ltx_font_italic">qualities</span> of knowledge emerging from the reviewed literature. Borrowing established terms for knowledge qualities in applied research theory <cite class="ltx_cite ltx_citemacro_citep">(Hevner
et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2004</a>; Lynham, <a href="#bib.bib74" title="" class="ltx_ref">2002</a>)</cite>, we summarise them as <span id="S5.SS3.p3.1.2" class="ltx_text ltx_font_italic">rigour</span> and <span id="S5.SS3.p3.1.3" class="ltx_text ltx_font_italic">relevance</span> of knowledge.</p>
</div>
<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1. </span>Output and Process Knowledge</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p id="S5.SS3.SSS1.p1.1" class="ltx_p"><span id="S5.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">Output knowledge</span> targets <span id="S5.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_italic">individual instances</span> of an intelligent system (e.g. understanding a specific movie recommendation).
In contrast, <span id="S5.SS3.SSS1.p1.1.3" class="ltx_text ltx_font_italic">process knowledge</span> targets the <span id="S5.SS3.SSS1.p1.1.4" class="ltx_text ltx_font_italic">system’s underlying model and reasoning steps</span> (e.g. the workings of a neural network that processes movie watching behaviour).</p>
</div>
<div id="S5.SS3.SSS1.p2" class="ltx_para">
<p id="S5.SS3.SSS1.p2.1" class="ltx_p">Explainability research in particular distinguishes between explanations for instances and models. For example, Ribeiro et al. <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite> explain classifiers with regard to two questions, <span id="S5.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_italic">Should I trust this prediction?</span> and <span id="S5.SS3.SSS1.p2.1.2" class="ltx_text ltx_font_italic">Can I trust this model?</span>. Therefore, they design for both output and process knowledge. These two knowledge types also motivate the <span id="S5.SS3.SSS1.p2.1.3" class="ltx_text ltx_font_italic">what</span> and <span id="S5.SS3.SSS1.p2.1.4" class="ltx_text ltx_font_italic">how</span> questions posed by Lim and Dey in their work on intelligibility <cite class="ltx_cite ltx_citemacro_citep">(Lim and Dey, <a href="#bib.bib70" title="" class="ltx_ref">2009</a>)</cite> (e.g. <span id="S5.SS3.SSS1.p2.1.5" class="ltx_text ltx_font_italic">What did the system do?</span>). Also, Rana and Bridge <cite class="ltx_cite ltx_citemacro_citep">(Rana and Bridge, <a href="#bib.bib83" title="" class="ltx_ref">2018</a>)</cite> introduced <span id="S5.SS3.SSS1.p2.1.6" class="ltx_text ltx_font_italic">chained</span> explanations (called “Recommendation-by-Explanation”) to explain a specific output to users. Moreover, work on accountability makes system reasoning accessible to users to support the development of process knowledge <cite class="ltx_cite ltx_citemacro_citep">(Binns et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2. </span>Interaction Knowledge</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p id="S5.SS3.SSS2.p1.1" class="ltx_p">Our knowledge type <span id="S5.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_italic">interaction knowledge</span> describes knowing how to do something in an interactive intelligent system. For example, supporting users in gaining this type of knowledge motivates questions in work on scrutability (e.g. <span id="S5.SS3.SSS2.p1.1.2" class="ltx_text ltx_font_italic">How can I tell the system what I want to know (or not)?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>), interactive machine learning (e.g. <span id="S5.SS3.SSS2.p1.1.3" class="ltx_text ltx_font_italic">How to experiment with model inputs?</span> <cite class="ltx_cite ltx_citemacro_citep">(Amershi
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>)</cite>), and end-user debugging (e.g. <span id="S5.SS3.SSS2.p1.1.4" class="ltx_text ltx_font_italic">How can I tell the system why it was wrong?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite>, <span id="S5.SS3.SSS2.p1.1.5" class="ltx_text ltx_font_italic">How can I correct system errors?</span> <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2010</a>)</cite>).</p>
</div>
</section>
<section id="S5.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.3. </span>Meta Knowledge</h4>

<div id="S5.SS3.SSS3.p1" class="ltx_para">
<p id="S5.SS3.SSS3.p1.1" class="ltx_p"><span id="S5.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_italic">Meta knowledge</span> captures system-related knowledge <span id="S5.SS3.SSS3.p1.1.2" class="ltx_text ltx_font_italic">beyond</span> interaction situations, such as information from a developer blog. For example, meta knowledge motivates some questions in work on transparency, such as <span id="S5.SS3.SSS3.p1.1.3" class="ltx_text ltx_font_italic">How is the system developed and how is it continually improved?</span> by Rader et al. <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>. They also explicitly add <span id="S5.SS3.SSS3.p1.1.4" class="ltx_text ltx_font_italic">Objective</span> explanations that inform users about how “a system comes into being” that result in meta knowledge (e.g. development practices and contexts).
Moreover, this knowledge type is a main driver of work on accountability, in which computer science overlaps with journalism: For instance, Diakopoulus “seeks to articulate the power structures, biases, and influences” of intelligent systems <cite class="ltx_cite ltx_citemacro_citep">(Diakopoulos, <a href="#bib.bib26" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.4. </span>Rigour and Relevance of Knowledge</h4>

<div id="S5.SS3.SSS4.p1" class="ltx_para">
<p id="S5.SS3.SSS4.p1.1" class="ltx_p"><span id="S5.SS3.SSS4.p1.1.1" class="ltx_text ltx_font_italic">Rigour:</span> Kulesza et al. propose the concepts of <span id="S5.SS3.SSS4.p1.1.2" class="ltx_text ltx_font_italic">soundness</span> and <span id="S5.SS3.SSS4.p1.1.3" class="ltx_text ltx_font_italic">completeness</span> in their work on explanations in intelligent systems <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2013</a>; Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>)</cite> – <span id="S5.SS3.SSS4.p1.1.4" class="ltx_text ltx_font_italic">soundness</span> is truthful explanation, and <span id="S5.SS3.SSS4.p1.1.5" class="ltx_text ltx_font_italic">completeness</span> means explaining the whole system.
Gilpin et al. <cite class="ltx_cite ltx_citemacro_citep">(Gilpin et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2018</a>)</cite> also refer to completeness, yet understand it as supporting anticipation of system behaviour in more situations.
For an overarching view, we generalise this to a broader level: We regard soundness and completeness as facets of <span id="S5.SS3.SSS4.p1.1.6" class="ltx_text ltx_font_italic">rigour</span>. Linked back to the work by Kulesza et al. <cite class="ltx_cite ltx_citemacro_citep">(Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>; Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2013</a>)</cite>, this means that a rigorous explanation, and the resulting understanding of a system, should be sound and complete.</p>
</div>
<div id="S5.SS3.SSS4.p2" class="ltx_para">
<p id="S5.SS3.SSS4.p2.1" class="ltx_p"><span id="S5.SS3.SSS4.p2.1.1" class="ltx_text ltx_font_italic">Relevance:</span>
A rigorous understanding does not need to be useful. We argue that this aspect should be of explicit interest for a pragmatic HCI perspective.
We thus consider <span id="S5.SS3.SSS4.p2.1.2" class="ltx_text ltx_font_italic">relevance</span> as another general quality of knowledge <cite class="ltx_cite ltx_citemacro_citep">(Lynham, <a href="#bib.bib74" title="" class="ltx_ref">2002</a>)</cite> that is crucial to make explicit in the specific context of user understanding of intelligent systems.
This quality highlights our pragmatic view: Elements like explanations are valuable if they add utility, that is, if they help users to gain knowledge that is relevant for <span id="S5.SS3.SSS4.p2.1.3" class="ltx_text ltx_font_italic">using</span> the system in better ways and towards better outcomes.
In this pragmatic sense, this quality echoes Kulesza et al.’s suggestion to “not overwhelm” users with (irrelevant) information <cite class="ltx_cite ltx_citemacro_citep">(Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>; Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2013</a>)</cite>. What is relevant to know, and to which extent, may also depend on factors such as task and complexity of the system <cite class="ltx_cite ltx_citemacro_citep">(Bunt
et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2012</a>)</cite>.</p>
</div>
<div id="S5.SS3.SSS4.p3" class="ltx_para ltx_noindent">
<p id="S5.SS3.SSS4.p3.1" class="ltx_p"><span id="S5.SS3.SSS4.p3.1.1" class="ltx_text">
<span id="S5.SS3.SSS4.p3.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:424.9pt;background-color:#EFEFEF;"><img src="/html/2001.08301/assets/x4.png" id="S5.SS3.SSS4.p3.1.1.1.g1" class="ltx_graphics ltx_img_square" width="10" height="10" alt="[Uncaptioned image]">
<span id="S5.SS3.SSS4.p3.1.1.1.1" class="ltx_p"><span id="S5.SS3.SSS4.p3.1.1.1.1.1" class="ltx_text ltx_font_bold">Knowledge outcomes and qualities</span> characterise and make explicit what kind of user understanding a system seeks to facilitate. We should thus articulate the goals of our work (e.g. output, process, interaction, and meta knowledge) and reflect on rigour and relevance of the respective kind of knowledge.</span>
</span></span></p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Framework Application: Structuring Past &amp; Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We have presented three categories for supporting user understanding of intelligent systems as emerged from our analysis of the literature – <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">user mindsets</span>, <span id="S6.p1.1.2" class="ltx_text ltx_font_italic">user involvement</span>, and <span id="S6.p1.1.3" class="ltx_text ltx_font_italic">knowledge outcomes</span>. These categories highlight differences and commonalities between work on the system qualities and serve as a conceptual framework of supporting users in understanding intelligent systems.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our framework introduces an overarching user-centric structure to the field that abstracts from the fractured terminological landscape.
We now propose to use our framework categories as a means for researchers in HCI and adjoining fields to clarify and make explicit the assumptions of their work, and to structure past and future work and discussions about how to support users in understanding intelligent systems. The boxes presented throughout this article provide inspiration on what to consider. The following sections highlight further applications of our framework.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Structuring Past Approaches and Solution Principles</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In Figure <a href="#S6.F2" title="Figure 2 ‣ 6.1. Structuring Past Approaches and Solution Principles ‣ 6. Framework Application: Structuring Past &amp; Future Work ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we demonstrate the application of our framework based on an interactive intelligent mood board creation tool by Koch et al. <cite class="ltx_cite ltx_citemacro_citep">(Koch
et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2019</a>)</cite> as an example for system-aided design ideation. In their prototype, system and user collaborate to find suitable imagery, the system making suggestions which the user can accept or discard. For each suggestion, the system offers a textual explanation and different feedback options. In terms of <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_italic">user involvement</span>, this approach thus supports both an <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_italic">active</span> user (via options for feedback and correction and turn-taking), as well as a <span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_italic">passive</span> one (via information about why an image was suggested). With regard to <span id="S6.SS1.p1.1.4" class="ltx_text ltx_font_italic">knowledge outcomes</span>, users gain <span id="S6.SS1.p1.1.5" class="ltx_text ltx_font_italic">relevant</span> knowledge about a specific <span id="S6.SS1.p1.1.6" class="ltx_text ltx_font_italic">output</span> (a specific image suggestion) and <span id="S6.SS1.p1.1.7" class="ltx_text ltx_font_italic">interaction</span> knowledge about how to control future system suggestions (by telling the system what they like or not). Overall, the prototype is designed so as to best support users in the creation of a mood board as an ideation activity, and thus implies a <span id="S6.SS1.p1.1.8" class="ltx_text ltx_font_italic">utilitarian</span> mindset.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">Moreover, Table <a href="#S6.T2" title="Table 2 ‣ 6.2.1. Reframing User Questions ‣ 6.2. Reflecting on Your Own Approach ‣ 6. Framework Application: Structuring Past &amp; Future Work ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents other exemplary solution principles from the literature to illustrate how user mindsets, user involvement and knowledge outcomes may be used to structure past work. We do not claim to provide a comprehensive survey in our work, but selected these examples to show the diversity of approaches in our paper set.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">Studying the approaches as arranged in Table <a href="#S6.T2" title="Table 2 ‣ 6.2.1. Reframing User Questions ‣ 6.2. Reflecting on Your Own Approach ‣ 6. Framework Application: Structuring Past &amp; Future Work ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reveals interesting structures:
For example, explanations appear across the charted space and thus could be seen as the go-to building block for many solution principles. They commonly provide output and process knowledge via text and/or plots <cite class="ltx_cite ltx_citemacro_citep">(Gedikli
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2014</a>; Hussein and
Neuhaus, <a href="#bib.bib50" title="" class="ltx_ref">2010</a>; Kizilcec, <a href="#bib.bib58" title="" class="ltx_ref">2016</a>; Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>; Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>; Lim and Dey, <a href="#bib.bib71" title="" class="ltx_ref">2011</a>; Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite>.
Sometimes these representations also allow for interactivity and user corrections <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>; Kulesza
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>; Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>)</cite>, in particular when explanations are referred to in work on scrutability, end-user debugging, and interactive machine learning <cite class="ltx_cite ltx_citemacro_citep">(Kapoor
et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2010</a>; Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>; De Russis and
Monge Roffarello, <a href="#bib.bib25" title="" class="ltx_ref">2018</a>; Talbot
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2009</a>)</cite>. Explanations commonly arise from utilitarian mindsets, yet they also appear in work with interpretive and critical questions <cite class="ltx_cite ltx_citemacro_citep">(Blanco et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2012</a>; Diakopoulos, <a href="#bib.bib27" title="" class="ltx_ref">2016</a>; Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>; Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<figure id="S6.F2" class="ltx_figure"><img src="/html/2001.08301/assets/x5.png" id="S6.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="202" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Application of our framework using Koch et al.’s system-aided mood board creation tool <cite class="ltx_cite ltx_citemacro_citep">(Koch
et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2019</a>)</cite> as an example. System image from Koch et al. <cite class="ltx_cite ltx_citemacro_citep">(Koch
et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2019</a>)</cite> used with the authors’ permission.</figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Reflecting on Your Own Approach</h3>

<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1. </span>Reframing User Questions</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para">
<p id="S6.SS2.SSS1.p1.1" class="ltx_p">User questions are a helpful way to uncover users’ information needs. Our framework can be used to re-frame such questions in related work, in particular by reconsidering the underlying mindsets to view questions from a novel angle:
For example, a question such as <span id="S6.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">Why did the system do X?</span> is currently mostly tied to a context implying a utilitarian mindset <cite class="ltx_cite ltx_citemacro_citep">(Lim and Dey, <a href="#bib.bib70" title="" class="ltx_ref">2009</a>)</cite>. However, this question could also reflect other mindsets and thus different underlying user motives for inquiry, depending on the envisioned context. Design solutions to this question could then foster utilitarian (e.g. explain feature influences), interpretive (e.g. explain in terms of a user’s daily life context), critical (e.g. explain system decision given a community’s norms), or all three mindsets.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<div id="S6.T2.1" class="ltx_inline-block ltx_transformed_outer" style="width:401.1pt;height:15401.4pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.3pt,624.3pt) scale(0.925003026280785,0.925003026280785) ;">
<table id="S6.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T2.1.1.1.1" class="ltx_tr">
<td id="S6.T2.1.1.1.1.1" class="ltx_td" style="padding-top:1.75pt;padding-bottom:1.75pt;"></td>
<th id="S6.T2.1.1.1.1.2" class="ltx_td ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"></th>
<th id="S6.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;" colspan="4"><span id="S6.T2.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Knowledge Outcomes</span></th>
<th id="S6.T2.1.1.1.1.4" class="ltx_td ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"></th>
<td id="S6.T2.1.1.1.1.5" class="ltx_td" style="padding-top:1.75pt;padding-bottom:1.75pt;"></td>
</tr>
<tr id="S6.T2.1.1.2.2" class="ltx_tr">
<td id="S6.T2.1.1.2.2.1" class="ltx_td" style="padding-top:1.75pt;padding-bottom:1.75pt;"></td>
<th id="S6.T2.1.1.2.2.2" class="ltx_td ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"></th>
<th id="S6.T2.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.2.2.3.1" class="ltx_text" style="font-size:90%;">Output</span></th>
<th id="S6.T2.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.2.2.4.1" class="ltx_text" style="font-size:90%;">Process</span></th>
<th id="S6.T2.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.2.2.5.1" class="ltx_text" style="font-size:90%;">Interaction</span></th>
<th id="S6.T2.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.2.2.6.1" class="ltx_text" style="font-size:90%;">Meta</span></th>
<th id="S6.T2.1.1.2.2.7" class="ltx_td ltx_th ltx_th_column" style="padding-top:1.75pt;padding-bottom:1.75pt;"></th>
<td id="S6.T2.1.1.2.2.8" class="ltx_td" style="padding-top:1.75pt;padding-bottom:1.75pt;"></td>
</tr>
<tr id="S6.T2.1.1.3.3" class="ltx_tr">
<td id="S6.T2.1.1.3.3.1" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;" rowspan="6"><span id="S6.T2.1.1.3.3.1.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.3.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.3.3.1.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.3.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:76.2pt;vertical-align:-34.6pt;"><span class="ltx_transformed_inner" style="width:76.2pt;transform:translate(-34.63pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.3.3.1.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:143%;">User Involvement</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.3.3.2" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.3.3.2.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.3.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.3.3.2.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.3.3.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.2.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:25.3pt;vertical-align:-9.6pt;"><span class="ltx_transformed_inner" style="width:25.3pt;transform:translate(-9.55pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.3.3.2.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Active</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.3.3.3.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.3.1.1.1" class="ltx_text" style="font-size:70%;">Visualisations explain classification via features, user “explains back” corrections by manipulating these plots </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.3.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Kulesza et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.3.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib66" title="" class="ltx_ref">2011</a>; Kulesza
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.3.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib62" title="" class="ltx_ref">2015</a><span id="S6.T2.1.1.3.3.3.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.3.1.1.5" class="ltx_text" style="font-size:70%;">. “Reasons” tabs show sensor-specific visualisations that explain current prediction </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.3.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Lim and Dey<span id="S6.T2.1.1.3.3.3.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib71" title="" class="ltx_ref">2011</a><span id="S6.T2.1.1.3.3.3.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.3.1.1.9" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.3.3.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.3.3.4.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.4.1.1.1" class="ltx_text" style="font-size:70%;">Users build if-rules in an editor, system detects problems via simulation (e.g. loops), user corrects them </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.4.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>De Russis and
Monge Roffarello<span id="S6.T2.1.1.3.3.4.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib25" title="" class="ltx_ref">2018</a><span id="S6.T2.1.1.3.3.4.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.4.1.1.5" class="ltx_text" style="font-size:70%;">. “Experimentation view” allows users to try out inputs and see system output </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.4.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Lim
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.4.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib72" title="" class="ltx_ref">2009</a><span id="S6.T2.1.1.3.3.4.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.4.1.1.9" class="ltx_text" style="font-size:70%;">. Confusion matrices show current state of classifier </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.4.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Kapoor
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.4.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib55" title="" class="ltx_ref">2010</a>; Talbot
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.4.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib92" title="" class="ltx_ref">2009</a><span id="S6.T2.1.1.3.3.4.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.4.1.1.13" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.3.3.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.3.3.5.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.5.1.1.1" class="ltx_text" style="font-size:70%;">Natural language dialogue enables users to ask system what they could do next </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.5.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Tintarev and
Kutlak<span id="S6.T2.1.1.3.3.5.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib93" title="" class="ltx_ref">2014</a><span id="S6.T2.1.1.3.3.5.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.5.1.1.5" class="ltx_text" style="font-size:70%;">. Users manipulate confusion matrix to change model </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.5.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Kapoor
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.5.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib55" title="" class="ltx_ref">2010</a><span id="S6.T2.1.1.3.3.5.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.5.1.1.9" class="ltx_text" style="font-size:70%;">, including re-combining multiple models </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.5.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Talbot
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.3.3.5.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib92" title="" class="ltx_ref">2009</a><span id="S6.T2.1.1.3.3.5.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.5.1.1.13" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.3.3.6" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.3.3.6.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.6.1.1.1" class="ltx_text" style="font-size:70%;">Beyond runtime: Open source enables code audits and facilitates understanding of system </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.3.3.6.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Burrell<span id="S6.T2.1.1.3.3.6.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib21" title="" class="ltx_ref">2016</a><span id="S6.T2.1.1.3.3.6.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.3.3.6.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.3.3.7" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;" rowspan="2"><span id="S6.T2.1.1.3.3.7.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.3.3.7.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.3.3.7.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.3.3.7.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.7.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:41.3pt;vertical-align:-17.5pt;"><span class="ltx_transformed_inner" style="width:41.3pt;transform:translate(-17.51pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.3.3.7.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.7.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Utilitarian</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.3.3.8" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;" rowspan="6"><span id="S6.T2.1.1.3.3.8.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.3.3.8.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.3.3.8.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.3.3.8.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.3.3.8.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:35.3pt;vertical-align:-14.2pt;"><span class="ltx_transformed_inner" style="width:35.3pt;transform:translate(-14.19pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.3.3.8.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.3.3.8.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:143%;">Mindset</span></span>
</span></span></span></span>
</span></span></td>
</tr>
<tr id="S6.T2.1.1.4.4" class="ltx_tr">
<td id="S6.T2.1.1.4.4.1" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.4.4.1.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.4.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.4.4.1.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.4.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.4.4.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:28.5pt;vertical-align:-11.2pt;"><span class="ltx_transformed_inner" style="width:28.5pt;transform:translate(-11.16pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.4.4.1.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.4.4.1.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Passive</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.4.4.2" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.4.4.2.1.1" class="ltx_p"><span id="S6.T2.1.1.4.4.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Bar charts and image regions show importance of predictors to explain specific classification <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite>. Visualisations show similar users’ input to explain recommendation <cite class="ltx_cite ltx_citemacro_citep">(Gedikli
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2014</a>)</cite>. Tree of images of training instances explains classification <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2020a</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.4.4.3" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.4.4.3.1.1" class="ltx_p"><span id="S6.T2.1.1.4.4.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Explaining a classifier by explaining multiple specific classifications <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2016</a>)</cite>. Animation shows learning algorithm at work <cite class="ltx_cite ltx_citemacro_citep">(Jackson and
Fovargue, <a href="#bib.bib51" title="" class="ltx_ref">1997</a>)</cite>. Text highlighting shows which words contributed to meeting detection in emails. <cite class="ltx_cite ltx_citemacro_citep">(Kocielnik
et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span>
</td>
<td id="S6.T2.1.1.4.4.4" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.4.4.4.1.1" class="ltx_p"><span id="S6.T2.1.1.4.4.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">List shows user’s past interactions to explain specific recommendation <cite class="ltx_cite ltx_citemacro_citep">(Hussein and
Neuhaus, <a href="#bib.bib50" title="" class="ltx_ref">2010</a>)</cite>. Step-by-step explanations of trigger-action rules by simulating user and system actions <cite class="ltx_cite ltx_citemacro_citep">(Corno
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2019</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.4.4.5" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.4.4.5.1.1" class="ltx_p"><span id="S6.T2.1.1.4.4.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Beyond single systems: Educate public in computational skills to facilitate system understanding overall <cite class="ltx_cite ltx_citemacro_citep">(Burrell, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite>.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.1.1.5.5" class="ltx_tr">
<td id="S6.T2.1.1.5.5.1" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.5.5.1.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.5.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.5.5.1.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.5.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.5.5.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:25.3pt;vertical-align:-9.6pt;"><span class="ltx_transformed_inner" style="width:25.3pt;transform:translate(-9.55pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.5.5.1.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.5.5.1.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Active</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.5.5.2.1.1" class="ltx_p"><span id="S6.T2.1.1.5.5.2.1.1.1" class="ltx_text" style="font-size:70%;">Rule-based reasoning system verbalises system decisions in natural language dialogue with user </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.2.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Tintarev and
Kutlak<span id="S6.T2.1.1.5.5.2.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib93" title="" class="ltx_ref">2014</a><span id="S6.T2.1.1.5.5.2.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.2.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.5.5.3.1.1" class="ltx_p"><span id="S6.T2.1.1.5.5.3.1.1.1" class="ltx_text" style="font-size:70%;">Separate profile page displays current user model </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.3.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Kay and
Kummerfeld<span id="S6.T2.1.1.5.5.3.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib56" title="" class="ltx_ref">2013</a><span id="S6.T2.1.1.5.5.3.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.3.1.1.5" class="ltx_text" style="font-size:70%;">. Natural language dialogue enables users to ask system why it has not decided differently. </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.3.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Tintarev and
Kutlak<span id="S6.T2.1.1.5.5.3.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib93" title="" class="ltx_ref">2014</a><span id="S6.T2.1.1.5.5.3.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.3.1.1.9" class="ltx_text" style="font-size:70%;"> Constructivist learning: user manipulates system and updates mental model of it based on resulting changes in output </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.3.1.1.10.1" class="ltx_text" style="font-size:70%;">(</span>Sarkar<span id="S6.T2.1.1.5.5.3.1.1.11.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib86" title="" class="ltx_ref">2016</a><span id="S6.T2.1.1.5.5.3.1.1.12.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.3.1.1.13" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.5.5.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.5.5.4.1.1" class="ltx_p"><span id="S6.T2.1.1.5.5.4.1.1.1" class="ltx_text" style="font-size:70%;">Separate profile page enables users to edit what the system knows about them </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.4.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Kay and
Kummerfeld<span id="S6.T2.1.1.5.5.4.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib56" title="" class="ltx_ref">2013</a><span id="S6.T2.1.1.5.5.4.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.4.1.1.5" class="ltx_text" style="font-size:70%;"> “Algorithmic profiling management”: Profile page reveals what system knows and how this influences content, including past interactions; controls enable modifications </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.4.1.1.6.1" class="ltx_text" style="font-size:70%;">(</span>Alvarado and
Waern<span id="S6.T2.1.1.5.5.4.1.1.7.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib6" title="" class="ltx_ref">2018</a><span id="S6.T2.1.1.5.5.4.1.1.8.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.4.1.1.9" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.5.5.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.5.5.5.1.1" class="ltx_p"><span id="S6.T2.1.1.5.5.5.1.1.1" class="ltx_text" style="font-size:70%;">“Algorithmic UX” beyond interaction: Users engage in communication and relationship building with intelligent agents </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.5.5.5.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Oh
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.5.5.5.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib79" title="" class="ltx_ref">2017</a><span id="S6.T2.1.1.5.5.5.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.5.5.5.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.5.5.6" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;" rowspan="2"><span id="S6.T2.1.1.5.5.6.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.5.5.6.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.5.5.6.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.5.5.6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.5.5.6.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.9pt;height:46pt;vertical-align:-20.8pt;"><span class="ltx_transformed_inner" style="width:46.1pt;transform:translate(-19.08pt,2.63pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.5.5.6.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.5.5.6.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Interpretive</span></span>
</span></span></span></span>
</span></span></td>
</tr>
<tr id="S6.T2.1.1.6.6" class="ltx_tr">
<td id="S6.T2.1.1.6.6.1" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.6.6.1.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.6.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.6.6.1.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.6.6.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.6.6.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:28.5pt;vertical-align:-11.2pt;"><span class="ltx_transformed_inner" style="width:28.5pt;transform:translate(-11.16pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.6.6.1.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.6.6.1.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Passive</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.6.6.2" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.6.6.2.1.1" class="ltx_p"><span id="S6.T2.1.1.6.6.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Icon indicates which system output is influenced by AI <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite>. Text analysis extracts relevant sentences from reviews to show along with recommendation <cite class="ltx_cite ltx_citemacro_citep">(Donkers
et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.6.6.3" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.6.6.3.1.1" class="ltx_p"><span id="S6.T2.1.1.6.6.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Output shown with textual explanation of the decision process <cite class="ltx_cite ltx_citemacro_citep">(Kizilcec, <a href="#bib.bib58" title="" class="ltx_ref">2016</a>)</cite>. Animation indicates how system output is generated (e.g. dice roll for randomness) <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.6.6.4" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.6.6.4.1.1" class="ltx_p"><span id="S6.T2.1.1.6.6.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Explain Recommendations with usage statistics (e.g. global popularity, repeated interest) <cite class="ltx_cite ltx_citemacro_citep">(Blanco et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2012</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.6.6.5" class="ltx_td ltx_align_justify" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.6.6.5.1.1" class="ltx_p"><span id="S6.T2.1.1.6.6.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Beyond code: Educate/sensitise developers and decision makers to consequences of systems <cite class="ltx_cite ltx_citemacro_citep">(Burrell, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite>. Icons indicate when and for which high-level goal (e.g. ads) user data is processed by the system <cite class="ltx_cite ltx_citemacro_citep">(Siljee, <a href="#bib.bib89" title="" class="ltx_ref">2015</a>)</cite>.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.1.1.7.7" class="ltx_tr">
<td id="S6.T2.1.1.7.7.1" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.7.7.1.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.7.7.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.7.7.1.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.7.7.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.7.7.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:25.3pt;vertical-align:-9.6pt;"><span class="ltx_transformed_inner" style="width:25.3pt;transform:translate(-9.55pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.7.7.1.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.7.7.1.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Active</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.7.7.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.7.7.2.1.1" class="ltx_p"><span id="S6.T2.1.1.7.7.2.1.1.1" class="ltx_text" style="font-size:70%;">“Algorithmic accountability reporting”: Journalists report on black box systems, e.g. by trying out inputs systematically </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.7.7.2.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Diakopoulos<span id="S6.T2.1.1.7.7.2.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib26" title="" class="ltx_ref">2015</a>, <a href="#bib.bib28" title="" class="ltx_ref">2017</a><span id="S6.T2.1.1.7.7.2.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.7.7.2.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.7.7.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.7.7.3.1.1" class="ltx_p"><span id="S6.T2.1.1.7.7.3.1.1.1" class="ltx_text" style="font-size:70%;">Beyond system understanding: Society must look not into systems but across them, that is, see their role within a larger network of actors (incl. humans and institutions) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.7.7.3.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Ananny and
Crawford<span id="S6.T2.1.1.7.7.3.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib10" title="" class="ltx_ref">2018</a><span id="S6.T2.1.1.7.7.3.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.7.7.3.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.7.7.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.7.7.4.1.1" class="ltx_p"><span id="S6.T2.1.1.7.7.4.1.1.1" class="ltx_text" style="font-size:70%;">Challenging the system: People learn from past interactions and output how to challenge system intelligence and its normative implications through unexpected or malicious input (e.g. manipulating public chatbot via twitter) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.7.7.4.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Neff and Nagy<span id="S6.T2.1.1.7.7.4.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib76" title="" class="ltx_ref">2016</a><span id="S6.T2.1.1.7.7.4.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.7.7.4.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.7.7.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.7.7.5.1.1" class="ltx_p"><span id="S6.T2.1.1.7.7.5.1.1.1" class="ltx_text" style="font-size:70%;">Beyond system use: People discuss and reflect on social implications and context of the system’s output </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S6.T2.1.1.7.7.5.1.1.2.1" class="ltx_text" style="font-size:70%;">(</span>Brown et al<span class="ltx_text">.</span><span id="S6.T2.1.1.7.7.5.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Schlesinger
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.7.7.5.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib87" title="" class="ltx_ref">2018</a>; Veale
et al<span class="ltx_text">.</span><span id="S6.T2.1.1.7.7.5.1.1.3.2.1.1" class="ltx_text" style="font-size:70%;">, </span><a href="#bib.bib97" title="" class="ltx_ref">2018</a><span id="S6.T2.1.1.7.7.5.1.1.4.3" class="ltx_text" style="font-size:70%;">)</span></cite><span id="S6.T2.1.1.7.7.5.1.1.5" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T2.1.1.7.7.6" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;" rowspan="2"><span id="S6.T2.1.1.7.7.6.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.7.7.6.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.7.7.6.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.7.7.6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.7.7.6.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:33.5pt;vertical-align:-13.6pt;"><span class="ltx_transformed_inner" style="width:33.5pt;transform:translate(-13.64pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.7.7.6.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.7.7.6.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Crictical</span></span>
</span></span></span></span>
</span></span></td>
</tr>
<tr id="S6.T2.1.1.8.8" class="ltx_tr">
<td id="S6.T2.1.1.8.8.1" class="ltx_td ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;"><span id="S6.T2.1.1.8.8.1.1" class="ltx_text" style="font-size:70%;">
<span id="S6.T2.1.1.8.8.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.1.1.8.8.1.1.1.1" class="ltx_tr">
<span id="S6.T2.1.1.8.8.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.8.8.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:28.5pt;vertical-align:-11.2pt;"><span class="ltx_transformed_inner" style="width:28.5pt;transform:translate(-11.16pt,0pt) rotate(-90deg) ;">
<span id="S6.T2.1.1.8.8.1.1.1.1.1.1.1" class="ltx_p"><span id="S6.T2.1.1.8.8.1.1.1.1.1.1.1.1" class="ltx_text" style="font-size:129%;">Passive</span></span>
</span></span></span></span>
</span></span></td>
<td id="S6.T2.1.1.8.8.2" class="ltx_td ltx_align_justify ltx_border_b" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.8.8.2.1.1" class="ltx_p"><span id="S6.T2.1.1.8.8.2.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Record models, algorithms, data, decisions for later audit <cite class="ltx_cite ltx_citemacro_citep">(Association for Computing Machinery US Public
Policy Council (USACM), <a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite>. Annotate recommended content pieces with indicators for quality/reliability of their source (e.g. for news) <cite class="ltx_cite ltx_citemacro_citep">(Lazer et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2018</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.8.8.3" class="ltx_td ltx_align_justify ltx_border_b" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.8.8.3.1.1" class="ltx_p"><span id="S6.T2.1.1.8.8.3.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Textual explanations of system intelligence on a high level, not integrated into the system (e.g. articles about system) <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>. Explaining the logic behind an algorithm with another algorithm <cite class="ltx_cite ltx_citemacro_citep">(Brkan, <a href="#bib.bib17" title="" class="ltx_ref">2017</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.8.8.4" class="ltx_td ltx_align_justify ltx_border_b" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.8.8.4.1.1" class="ltx_p"><span id="S6.T2.1.1.8.8.4.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">“Algorithmic Imaginary”: People develop understanding of intelligent systems and how to influence them based on how “they are being articulated, experienced and contested in the public domain” <cite class="ltx_cite ltx_citemacro_citep">(Bucher, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite>.</span></span>
</span>
</td>
<td id="S6.T2.1.1.8.8.5" class="ltx_td ltx_align_justify ltx_border_b" style="background-color:#EFEFEF;padding-top:1.75pt;padding-bottom:1.75pt;">
<span id="S6.T2.1.1.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.8.8.5.1.1" class="ltx_p"><span id="S6.T2.1.1.8.8.5.1.1.1" class="ltx_text" style="font-size:70%;background-color:#EFEFEF;">Textual explanations of developers’ intentions on a high level, not integrated into the system (e.g. articles about system) <cite class="ltx_cite ltx_citemacro_citep">(Rader
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite>.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 2. </span>Examples of approaches and solution principles for supporting user understanding of intelligent systems, structured through our framework. This is not a comprehensive survey; examples were selected to illustrate the diversity of approaches in the literature.</figcaption>
</figure>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2. </span>Explicating Perspectives with Mixed Mindsets</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para">
<p id="S6.SS2.SSS2.p1.1" class="ltx_p">Related, reflecting on the three mindsets presented here can help to discover structure in perspectives that mix multiple mindsets: For example, a recent set of 18 guidelines for interaction with AI <cite class="ltx_cite ltx_citemacro_citep">(Amershi et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite> contained mostly utilitarian guidelines (e.g. “Support efficient dismissial”, “Provide global controls”), yet two stand out as following a critical mindset (“Match relevant social norms”, “Mitigate social biases”). Our lens allows to clarify and explicate this mix, revealing, in this example, that the guidelines already follow a broader perspective than the related work itself alluded to with its stated focus “on AI design guidelines that […] could be easily evaluated by inspection of a system’s interface”. Such analysis could help to structure discussions about similarly mixed perspectives.</p>
</div>
</section>
<section id="S6.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.3. </span>Explicitly Determining Relevance</h4>

<div id="S6.SS2.SSS3.p1" class="ltx_para">
<p id="S6.SS2.SSS3.p1.1" class="ltx_p">What is relevant to know for users is considered differently across the system qualities. Highlighting relevance and rigour (see section on <span id="S6.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">knowledge outcomes</span> and Table <a href="#S3.T1" title="Table 1 ‣ 3.3. User Knowledge and Understanding ‣ 3. Scope and Foundations ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> last column) thus helps to reflect on what we consider important, for whom, and to what extent – and how we choose to determine it.</p>
</div>
<div id="S6.SS2.SSS3.p2" class="ltx_para">
<p id="S6.SS2.SSS3.p2.1" class="ltx_p">For example, explanation design often involves non-expert users, possibly via a user-centred design process <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite> or scenario-based elicitation <cite class="ltx_cite ltx_citemacro_citep">(Lim
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2009</a>)</cite> to inform what is relevant, what should be explained, and to what extent.</p>
</div>
<div id="S6.SS2.SSS3.p3" class="ltx_para">
<p id="S6.SS2.SSS3.p3.1" class="ltx_p">In contrast, interactive machine learning focuses on information that is relevant to the task of the <span id="S6.SS2.SSS3.p3.1.1" class="ltx_text ltx_font_italic">system</span> (e.g. to improve a classifier), which is often operated by experts <cite class="ltx_cite ltx_citemacro_citep">(Amershi
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>)</cite>. Therefore, what is relevant here (and to what extent) is foremost informed by the machine learning task, and less so by studying or asking end-users. This can be seen, for example, in the UI elements derived in a recent survey on interactive machine learning <cite class="ltx_cite ltx_citemacro_citep">(Dudley and
Kristensson, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>, which are closely coupled to the machine learning task (e.g. they serve “sample review”, “feedback assignment”, etc.).</p>
</div>
<div id="S6.SS2.SSS3.p4" class="ltx_para">
<p id="S6.SS2.SSS3.p4.1" class="ltx_p">As another example, work on end-user debugging presents an action-focused middle-ground, between user-focused (as explainability) and system-focused (as interactive machine learning): Here, resulting knowledge should help users to <span id="S6.SS2.SSS3.p4.1.1" class="ltx_text ltx_font_italic">make</span> the system more relevant to them, for example, by correcting system errors from the users’ point of view; users may be both experts <cite class="ltx_cite ltx_citemacro_citep">(Amershi et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2015</a>)</cite> or non-experts <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2011</a>)</cite>.</p>
</div>
</section>
<section id="S6.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.4. </span>Informing Methodology</h4>

<div id="S6.SS2.SSS4.p1" class="ltx_para">
<p id="S6.SS2.SSS4.p1.1" class="ltx_p">Our framework may be used to motivate methodological choices, for example when informing or evaluating the design of a new approach for supporting user understanding:</p>
</div>
<div id="S6.SS2.SSS4.p2" class="ltx_para">
<p id="S6.SS2.SSS4.p2.1" class="ltx_p">For instance, work catering to a utilitarian mindset might benefit from a controlled environment and precise measurements in a lab study. Even simulation of system decisions might be a (first) option <cite class="ltx_cite ltx_citemacro_citep">(Doshi-Velez and
Kim, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite>. A lab study might also be a suitable choice to evaluate support for developing interaction knowledge, since users can be directly observed during interaction (e.g. see <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>; Talbot
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2009</a>)</cite>).
In contrast, if a design or research question targets an interpretive mindset and/or meta knowledge, it might be worthwhile or required to study user and system in their daily contexts of use (e.g. see lab vs field study in education context in <cite class="ltx_cite ltx_citemacro_citep">(Kay and
Kummerfeld, <a href="#bib.bib56" title="" class="ltx_ref">2013</a>)</cite>).
The same holds for work motivated by a critical mindset, yet other methods exist here as well, such as online surveys or data analyses of views expressed through mass media and social network discussions <cite class="ltx_cite ltx_citemacro_citep">(Lazer et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2018</a>)</cite>, or policy and legal texts <cite class="ltx_cite ltx_citemacro_citep">(Association for Computing Machinery US Public
Policy Council (USACM), <a href="#bib.bib11" title="" class="ltx_ref">2017</a>; Parliament and the Council of the European Union, <a href="#bib.bib80" title="" class="ltx_ref">2016</a>; Goodman and
Flaxman, <a href="#bib.bib40" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Going Beyond</h3>

<section id="S6.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.1. </span>Inspiring New Approaches in Research and Practice</h4>

<div id="S6.SS3.SSS1.p1" class="ltx_para">
<p id="S6.SS3.SSS1.p1.1" class="ltx_p">Our framework may provide inspiration for new approaches and solution principles. While the target audience of this paper are foremost researchers in the field, we believe that the framework might also be used by practitioners, for example, as a brainstorming tool for prototype development.</p>
</div>
<div id="S6.SS3.SSS1.p2" class="ltx_para">
<p id="S6.SS3.SSS1.p2.1" class="ltx_p">We illustrate this using the proposed mindsets: UIs could support users in examining the system with different mindsets via “modes” for explanation views. Users could then switch between utilitarian explanations (e.g. explain a recommendation with product features) and interpretive or critical ones (e.g. explain system beliefs about a user, such as that the user is part of a certain target group; reveal that recommendations are assembled by an AI and not by a human, cf. <cite class="ltx_cite ltx_citemacro_citep">(Eiband et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018b</a>)</cite>).</p>
</div>
<div id="S6.SS3.SSS1.p3" class="ltx_para">
<p id="S6.SS3.SSS1.p3.1" class="ltx_p">A more radical solution could offer three different views of the system that display or hide UI elements depending on the respective “mode”. Or the mindsets might simply help to decide which user approach to support in a system, and to identify those remaining unaddressed so far.
Prototypes could then be tested with the respective end-users of the application. Yet, the actual generative power of our framework has to be validated in the future.</p>
</div>
</section>
<section id="S6.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.2. </span>Understanding Systems Beyond Interaction Situations</h4>

<div id="S6.SS3.SSS2.p1" class="ltx_para">
<p id="S6.SS3.SSS2.p1.1" class="ltx_p">The critical mindset and meta knowledge capture a crucial difference between traditional (non-intelligent) systems and what we see today and what is yet to come: Systems are increasingly interwoven with our lives, be it in everyday applications or in areas of consequential decision-making (e.g. financial, medical or legal). Their effects thus do not remain limited to a particular interaction situation. It is important that we as researchers reflect on the impact of the systems we design beyond the duration of direct use. This also includes reflections on when and how intelligent systems can learn compared to humans in the same roles <cite class="ltx_cite ltx_citemacro_citep">(Alkhatib and
Bernstein, <a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>.
Examples for work in such a larger context are presented in Table <a href="#S6.T2" title="Table 2 ‣ 6.2.1. Reframing User Questions ‣ 6.2. Reflecting on Your Own Approach ‣ 6. Framework Application: Structuring Past &amp; Future Work ‣ How to Support Users in Understanding Intelligent Systems? Structuring the Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, in particular in the <span id="S6.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_italic">critical</span> and <span id="S6.SS3.SSS2.p1.1.2" class="ltx_text ltx_font_italic">meta</span> areas (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Ananny and
Crawford, <a href="#bib.bib10" title="" class="ltx_ref">2018</a>; Burrell, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>; Diakopoulos, <a href="#bib.bib26" title="" class="ltx_ref">2015</a>, <a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite>). Connections with HCI in such work commonly refer to <span id="S6.SS3.SSS2.p1.1.3" class="ltx_text ltx_font_italic">accountability</span> and <span id="S6.SS3.SSS2.p1.1.4" class="ltx_text ltx_font_italic">transparency</span> of intelligent systems.</p>
</div>
</section>
<section id="S6.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.3. </span>Motivating Connections Beyond HCI &amp; Machine Learning/AI</h4>

<div id="S6.SS3.SSS3.p1" class="ltx_para">
<p id="S6.SS3.SSS3.p1.1" class="ltx_p">We see recent calls for more joint research at the intersection of HCI and AI to improve system understanding <cite class="ltx_cite ltx_citemacro_citep">(Abdul et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite>. However, this is mostly motivated by utilitarian or interpretive mindsets. Thus, another related key takeaway is to draw attention to interdisciplinary connections via the <span id="S6.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_italic">critical</span> of the three mindsets proposed in this article: As is evident from recent “AI and data scandals” (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Grassegger and
Krogerus, <a href="#bib.bib41" title="" class="ltx_ref">2017</a>; Lazer et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2018</a>; Neff and Nagy, <a href="#bib.bib76" title="" class="ltx_ref">2016</a>)</cite>), developing more understandable (and accountable) intelligent systems also needs to be addressed in a wider view (cf. third wave HCI <cite class="ltx_cite ltx_citemacro_citep">(Bødker, <a href="#bib.bib16" title="" class="ltx_ref">2015</a>)</cite>), for example across networks of human and AI actors <cite class="ltx_cite ltx_citemacro_citep">(Ananny and
Crawford, <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>.
More generally, fruitful connections could span considerations from fields like journalism <cite class="ltx_cite ltx_citemacro_citep">(Diakopoulos, <a href="#bib.bib26" title="" class="ltx_ref">2015</a>, <a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite> and communication <cite class="ltx_cite ltx_citemacro_citep">(Lazer et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2018</a>; Neff and Nagy, <a href="#bib.bib76" title="" class="ltx_ref">2016</a>)</cite>, policy <cite class="ltx_cite ltx_citemacro_citep">(Alkhatib and
Bernstein, <a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>, sociology <cite class="ltx_cite ltx_citemacro_citep">(Ananny and
Crawford, <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite> and education <cite class="ltx_cite ltx_citemacro_citep">(Burrell, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite>, and ethical and legal concerns <cite class="ltx_cite ltx_citemacro_citep">(Brkan, <a href="#bib.bib17" title="" class="ltx_ref">2017</a>; Eiband
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2018a</a>)</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Intelligent systems tend to violate UI principles, such as predictable output <cite class="ltx_cite ltx_citemacro_citep">(Amershi
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>; Dudley and
Kristensson, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>, which makes them difficult to understand and use.
To address this, researchers, practitioners, policy-makers and the general public call for <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">system qualities</span> such as transparency, scrutability, explainability, interpretability, interactivity, and so on.
However, these terms are often blurred and employed with varying interpretations. This impedes conceptual clarity of the very properties that are envisioned to foster users’ understanding of intelligent systems.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">This review responds to this lack of conceptual clarity with an analysis and discuhssion of theoretical concepts and prototype solutions from the literature: We make explicit the diversity of different implied views on <span id="S7.p2.1.1" class="ltx_text ltx_font_italic">user mindsets</span>, <span id="S7.p2.1.2" class="ltx_text ltx_font_italic">user involvement</span>, and <span id="S7.p2.1.3" class="ltx_text ltx_font_italic">knowledge outcomes</span>.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">In conclusion, we provide researchers with a framework to (1) clearly motivate and frame their work, (2) draw connections across work on different system qualities and related design solutions, and (3) articulate explicitly their underlying assumptions and goals.
With our work, we thus hope to facilitate, structure and advance further discussions and research on supporting users’ understanding of intelligent systems.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This project is funded by the Bavarian State Ministry of Science and the Arts and coordinated by the Bavarian Research Institute for Digital Transformation (bidt).

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdul et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ashraf Abdul, Jo
Vermeulen, Danding Wang, Brian Y. Lim,
and Mohan Kankanhalli. 2018.

</span>
<span class="ltx_bibblock">Trends and Trajectories for Explainable,
Accountable and Intelligible Systems: An HCI Research Agenda. In
<em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on Human
Factors in Computing Systems</em> (Montreal QC, Canada)
<em id="bib.bib2.4.2" class="ltx_emph ltx_font_italic">(CHI ’18)</em>. ACM,
New York, NY, USA, Article 582,
18 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3174156" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3174156</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alkan et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Oznur Alkan, Elizabeth M.
Daly, Adi Botea, Abel N. Valente, and
Pablo Pedemonte. 2019.

</span>
<span class="ltx_bibblock">Where Can My Career Take Me?: Harnessing Dialogue
for Interactive Career Goal Recommendations. In
<em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th International Conference on
Intelligent User Interfaces</em> (Marina del Ray, California)
<em id="bib.bib3.4.2" class="ltx_emph ltx_font_italic">(IUI ’19)</em>. ACM,
New York, NY, USA, 603–613.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3301275.3302311" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3301275.3302311</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alkhatib and
Bernstein (2019)</span>
<span class="ltx_bibblock">
Ali Alkhatib and Michael
Bernstein. 2019.

</span>
<span class="ltx_bibblock">Street-Level Algorithms: A Theory at the Gaps
Between Policy and Decisions. In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2019 CHI Conference on Human Factors in Computing Systems</em> (Glasgow,
Scotland Uk) <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. ACM,
New York, NY, USA, Article 530,
13 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300760" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300760</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alqaraawi et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ahmed Alqaraawi, Martin
Schuessler, Philipp Weiß, Enrico
Costanza, and Nadia Berthouze.
2020.

</span>
<span class="ltx_bibblock">Evaluating Saliency Map Explanations for
Convolutional Neural Networks: A User Study. In
<em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference on
Intelligent User Interfaces</em> (Cagliari, Italy) <em id="bib.bib5.4.2" class="ltx_emph ltx_font_italic">(IUI
’20)</em>. Association for Computing Machinery,
New York, NY, USA, 275–285.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3377325.3377519" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3377325.3377519</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alvarado and
Waern (2018)</span>
<span class="ltx_bibblock">
Oscar Alvarado and
Annika Waern. 2018.

</span>
<span class="ltx_bibblock">Towards Algorithmic Experience: Initial Efforts for
Social Media Contexts. In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018
CHI Conference on Human Factors in Computing Systems</em> (Montreal QC, Canada)
<em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">(CHI ’18)</em>. ACM,
New York, NY, USA, Article 286,
12 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3173860" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3173860</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amershi
et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Saleema Amershi, Maya
Cakmak, William Bradley Knox, and Todd
Kulesza. 2014.

</span>
<span class="ltx_bibblock">Power to the People: The Role of Humans in
Interactive Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">AI Magazine</em> 35,
4 (December 2014),
105.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1609/aimag.v35i4.2513" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aimag.v35i4.2513</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amershi et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Saleema Amershi, Max
Chickering, Steven M. Drucker, Bongshin
Lee, Patrice Simard, and Jina Suh.
2015.

</span>
<span class="ltx_bibblock">ModelTracker: Redesigning Performance Analysis
Tools for Machine Learning. In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
33rd Annual ACM Conference on Human Factors in Computing Systems</em> (Seoul,
Republic of Korea) <em id="bib.bib8.4.2" class="ltx_emph ltx_font_italic">(CHI ’15)</em>.
ACM, New York, NY, USA,
337–346.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2702123.2702509" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2702123.2702509</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amershi et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Saleema Amershi, Dan
Weld, Mihaela Vorvoreanu, Adam Fourney,
Besmira Nushi, Penny Collisson,
Jina Suh, Shamsi Iqbal,
Paul N. Bennett, Kori Inkpen,
Jaime Teevan, Ruth Kikin-Gil, and
Eric Horvitz. 2019.

</span>
<span class="ltx_bibblock">Guidelines for Human-AI Interaction. In
<em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib9.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. ACM,
New York, NY, USA, Article 3,
13 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300233" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300233</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ananny and
Crawford (2018)</span>
<span class="ltx_bibblock">
Mike Ananny and Kate
Crawford. 2018.

</span>
<span class="ltx_bibblock">Seeing Without Knowing: Limitations of the
Transparency Ideal and its Application to Algorithmic Accountability.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">New Media &amp; Society</em>
20, 3 (March
2018), 973–989.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1177/1461444816676645" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/1461444816676645</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Association for Computing Machinery US Public
Policy Council (USACM) (2017)</span>
<span class="ltx_bibblock">
Association for Computing Machinery US
Public Policy Council (USACM). 2017.

</span>
<span class="ltx_bibblock">Statement on Algorithmic Transparency and
Accountability.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balog
et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Krisztian Balog, Filip
Radlinski, and Shushan Arakelyan.
2019.

</span>
<span class="ltx_bibblock">Transparent, Scrutable and Explainable User Models
for Personalized Recommendation. In <em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 42nd International ACM SIGIR Conference on Research and Development in
Information Retrieval</em> (Paris France) <em id="bib.bib12.4.2" class="ltx_emph ltx_font_italic">(SIGIR ’19)</em>.
Association for Computing Machinery,
New York, NY, USA, 265–274.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3331184.3331211" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3331184.3331211</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Billsus and
Pazzani (1999)</span>
<span class="ltx_bibblock">
Daniel Billsus and
Michael J. Pazzani. 1999.

</span>
<span class="ltx_bibblock">A Personal News Agent That Talks, Learns and
Explains. In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third Annual
Conference on Autonomous Agents</em> (Seattle, Washington, USA)
<em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic">(AGENTS ’99)</em>. ACM,
New York, NY, USA, 268–275.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/301136.301208" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/301136.301208</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Binns et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Reuben Binns, Max
Van Kleek, Michael Veale, Ulrik Lyngs,
Jun Zhao, and Nigel Shadbolt.
2018.

</span>
<span class="ltx_bibblock">“It’s Reducing a Human Being to a Percentage”:
Perceptions of Justice in Algorithmic Decisions. In
<em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on Human
Factors in Computing Systems</em> (Montreal QC, Canada)
<em id="bib.bib14.4.2" class="ltx_emph ltx_font_italic">(CHI ’18)</em>. ACM,
New York, NY, USA, Article 377,
14 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3173951" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3173951</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanco et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Roi Blanco, Diego
Ceccarelli, Claudio Lucchese, Raffaele
Perego, and Fabrizio Silvestri.
2012.

</span>
<span class="ltx_bibblock">You Should Read This! Let Me Explain You Why:
Explaining News Recommendations to Users. In
<em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 21st ACM International
Conference on Information and Knowledge Management</em> (Maui, Hawaii, USA)
<em id="bib.bib15.4.2" class="ltx_emph ltx_font_italic">(CIKM ’12)</em>. ACM,
New York, NY, USA, 1995–1999.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2396761.2398559" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2396761.2398559</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bødker (2015)</span>
<span class="ltx_bibblock">
Susanne Bødker.
2015.

</span>
<span class="ltx_bibblock">Third-wave HCI, 10 Years Later – Participation and
Sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">interactions</em> 22,
5 (Aug. 2015),
24–31.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2804405" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2804405</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brkan (2017)</span>
<span class="ltx_bibblock">
Maja Brkan.
2017.

</span>
<span class="ltx_bibblock">AI-supported Decision-making Under the General Data
Protection Regulation. In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th
Edition of the International Conference on Articial Intelligence and Law</em>
(London, United Kingdom) <em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic">(ICAIL ’17)</em>.
ACM, New York, NY, USA,
3–8.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3086512.3086513" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3086512.3086513</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Anna Brown, Alexandra
Chouldechova, Emily Putnam-Hornstein,
Andrew Tobin, and Rhema Vaithianathan.
2019.

</span>
<span class="ltx_bibblock">Toward Algorithmic Accountability in Public
Services: A Qualitative Study of Affected Community Perspectives on
Algorithmic Decision-making in Child Welfare Services. In
<em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib18.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. ACM,
New York, NY, USA, Article 41,
12 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300271" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300271</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bucher (2017)</span>
<span class="ltx_bibblock">
Taina Bucher.
2017.

</span>
<span class="ltx_bibblock">The Algorithmic Imaginary: Exploring the Ordinary
Affects of Facebook Algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Information Communication and Society</em>
20, 1 (2017),
30–44.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1080/1369118X.2016.1154086" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/1369118X.2016.1154086</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bunt
et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Andrea Bunt, Matthew
Lount, and Catherine Lauzon.
2012.

</span>
<span class="ltx_bibblock">Are Explanations Always Important?: A Study of
Deployed, Low-cost Intelligent Interactive Systems. In
<em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2012 ACM International
Conference on Intelligent User Interfaces</em> (Lisbon, Portugal)
<em id="bib.bib20.4.2" class="ltx_emph ltx_font_italic">(IUI ’12)</em>. ACM,
New York, NY, USA, 169–178.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2166966.2166996" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2166966.2166996</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burrell (2016)</span>
<span class="ltx_bibblock">
Jenna Burrell.
2016.

</span>
<span class="ltx_bibblock">How the Machine “Thinks”: Understanding Opacity
in Machine Learning Algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Big Data &amp; Society</em> 3,
1 (2016),
2053951715622512.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1177/2053951715622512" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/2053951715622512</a>
arXiv:https://doi.org/10.1177/2053951715622512

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chander et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ajay Chander, Ramya
Srinivasan, Suhas Chelian, Jun Wang,
and Kanji Uchino. 2018.

</span>
<span class="ltx_bibblock">Working with Beliefs: AI Transparency in the
Enterprise. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Explainable Smart Systems Workshop
at IUI 2018</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://ceur-ws.org/Vol-2068/exss14.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://ceur-ws.org/Vol-2068/exss14.pdf</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Coppers et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Sven Coppers, Kris
Luyten, Davy Vanacken, David Navarre,
Philippe Palanque, and Christine Gris.
2019.

</span>
<span class="ltx_bibblock">Fortunettes: Feedforward About the Future State of
GUI Widgets.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 3, EICS, Article
20 (June 2019),
20 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3331162" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3331162</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corno
et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Fulvio Corno, Luigi
De Russis, and Alberto Monge Roffarello.
2019.

</span>
<span class="ltx_bibblock">Empowering End Users in Debugging Trigger-Action
Rules. In <em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference
on Human Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib24.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. ACM,
New York, NY, USA, Article 388,
13 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300618" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300618</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Russis and
Monge Roffarello (2018)</span>
<span class="ltx_bibblock">
Luigi De Russis and
Alberto Monge Roffarello. 2018.

</span>
<span class="ltx_bibblock">A Debugging Approach for Trigger-Action
Programming. In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Extended Abstracts of the 2018 CHI
Conference on Human Factors in Computing Systems</em> (Montreal QC, Canada)
<em id="bib.bib25.2.2" class="ltx_emph ltx_font_italic">(CHI EA ’18)</em>. ACM,
New York, NY, USA, Article LBW105,
6 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3170427.3188641" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3170427.3188641</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diakopoulos (2015)</span>
<span class="ltx_bibblock">
Nicholas Diakopoulos.
2015.

</span>
<span class="ltx_bibblock">Algorithmic Accountability.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Digital Journalism</em> 3,
3 (2015), 398–415.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1080/21670811.2014.976411" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/21670811.2014.976411</a>
arXiv:https://doi.org/10.1080/21670811.2014.976411

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diakopoulos (2016)</span>
<span class="ltx_bibblock">
Nicholas Diakopoulos.
2016.

</span>
<span class="ltx_bibblock">Accountability in Algorithmic Decision Making.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 59,
2 (January 2016),
56–62.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2844110" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2844110</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diakopoulos (2017)</span>
<span class="ltx_bibblock">
Nicholas Diakopoulos.
2017.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Enabling Accountability of Algorithmic
Media: Transparency as a Constructive and Critical Lens</em>.

</span>
<span class="ltx_bibblock">Springer International Publishing,
Cham, 25–43.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/978-3-319-54024-5_2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-319-54024-5_2</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donkers
et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tim Donkers, Timm
Kleemann, and Jürgen Ziegler.
2020.

</span>
<span class="ltx_bibblock">Explaining Recommendations by Means of Aspect-Based
Transparent Memories. In <em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th
International Conference on Intelligent User Interfaces</em> (Cagliari, Italy)
<em id="bib.bib29.4.2" class="ltx_emph ltx_font_italic">(IUI ’20)</em>. Association for
Computing Machinery, New York, NY, USA,
166–176.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3377325.3377520" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3377325.3377520</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doshi-Velez and
Kim (2017)</span>
<span class="ltx_bibblock">
Finale Doshi-Velez and
Been Kim. 2017.

</span>
<span class="ltx_bibblock">Towards A Rigorous Science of Interpretable
Machine Learning.

</span>
<span class="ltx_bibblock">(February 2017).

</span>
<span class="ltx_bibblock">arXiv:1702.08608

<a target="_blank" href="http://arxiv.org/abs/1702.08608" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1702.08608</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Drozdal et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jaimie Drozdal, Justin
Weisz, Dakuo Wang, Gaurav Dass,
Bingsheng Yao, Changruo Zhao,
Michael Muller, Lin Ju, and
Hui Su. 2020.

</span>
<span class="ltx_bibblock">Trust in AutoML: Exploring Information Needs for
Establishing Trust in Automated Machine Learning Systems. In
<em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference on
Intelligent User Interfaces</em> (Cagliari, Italy) <em id="bib.bib31.4.2" class="ltx_emph ltx_font_italic">(IUI
’20)</em>. Association for Computing Machinery,
New York, NY, USA, 297–307.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3377325.3377501" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3377325.3377501</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dudley and
Kristensson (2018)</span>
<span class="ltx_bibblock">
John J. Dudley and
Per Ola Kristensson. 2018.

</span>
<span class="ltx_bibblock">A Review of User Interface Design for Interactive
Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Interactive Intelligent
Systems</em> 8, 2, Article
8 (June 2018),
37 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3185517" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3185517</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edwards and Veale (2017)</span>
<span class="ltx_bibblock">
Lilian Edwards and
Michael Veale. 2017.

</span>
<span class="ltx_bibblock">Slave to the Algorithm? Why a “Right to an
Explanation” Is Probably Not the Remedy You Are Looking For.
(2017).

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.2139/ssrn.2972855" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2139/ssrn.2972855</a>
arXiv:arXiv:1802.01557v1

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eiband et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Malin Eiband, Hanna
Schneider, Mark Bilandzic, Julian
Fazekas-Con, Mareike Haug, and Heinrich
Hussmann. 2018b.

</span>
<span class="ltx_bibblock">Bringing Transparency Design into Practice.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on
Intelligent User Interfaces IUI ’18</em> (2018),
211–223.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3172944.3172961" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3172944.3172961</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eiband
et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Malin Eiband, Hanna
Schneider, and Daniel Buschek.
2018a.

</span>
<span class="ltx_bibblock">Normative vs Pragmatic: Two Perspectives on the
Design of Explanations in Intelligent Systems. In
<em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Explainable Smart Systems Workshop at IUI 2018</em>.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gedikli
et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Fatih Gedikli, Dietmar
Jannach, and Mouzhi Ge.
2014.

</span>
<span class="ltx_bibblock">How Should I Explain? A Comparison of Different
Explanation Types for Recommender Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">International Journal of Human Computer
Studies</em> (2014).

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1016/j.ijhcs.2013.12.007" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.ijhcs.2013.12.007</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilpin et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Leilani H. Gilpin, David
Bau, Ben Z. Yuan, Ayesha Bajwa,
Michael Specter, and Lalana Kagal.
2018.

</span>
<span class="ltx_bibblock">Explaining Explanations: An Approach to Evaluating
Interpretability of Machine Learning.

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/arXiv:1806.00069v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/arXiv:1806.00069v2</a>
arXiv:1806.00069

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glaser and
Strauss (2017)</span>
<span class="ltx_bibblock">
Barney G. Glaser and
Anselm L. Strauss. 2017.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Discovery of Grounded Theory: Strategies
for Qualitative Research</em>.

</span>
<span class="ltx_bibblock">Routledge.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gollwitzer (1993)</span>
<span class="ltx_bibblock">
Peter M. Gollwitzer.
1993.

</span>
<span class="ltx_bibblock">Goal Achievement: The Role of Intentions.

</span>
<span class="ltx_bibblock">4, 1 (1993),
141–185.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1080/14792779343000059" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/14792779343000059</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodman and
Flaxman (2016)</span>
<span class="ltx_bibblock">
Bryce Goodman and Seth
Flaxman. 2016.

</span>
<span class="ltx_bibblock">EU Regulations on Algorithmic Decision-making and a
“Right to Explanation”.

</span>
<span class="ltx_bibblock">38 (June 2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grassegger and
Krogerus (2017)</span>
<span class="ltx_bibblock">
Hannes Grassegger and
Mikael Krogerus. 2017.

</span>
<span class="ltx_bibblock">The Data that Turned the World Upside Down.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://motherboard.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://motherboard.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 01.10.2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hager et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Gregory D. Hager, Randal
Bryant, Eric Horvitz, Maja J. Mataric,
and Vasant G. Honavar. 2017.

</span>
<span class="ltx_bibblock">Advances in Artificial Intelligence Require
Progress Across all of Computer Science.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1707.04352
(2017).

</span>
<span class="ltx_bibblock">arXiv:1707.04352

<a target="_blank" href="http://arxiv.org/abs/1707.04352" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1707.04352</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herlocker
et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2000)</span>
<span class="ltx_bibblock">
Jonathan L. Herlocker,
Joseph A. Konstan, and John Riedl.
2000.

</span>
<span class="ltx_bibblock">Explaining Collaborative Filtering
Recommendations. In <em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2000 ACM
Conference on Computer Supported Cooperative Work</em> (Philadelphia,
Pennsylvania, USA) <em id="bib.bib43.4.2" class="ltx_emph ltx_font_italic">(CSCW ’00)</em>.
ACM, New York, NY, USA,
241–250.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/358916.358995" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/358916.358995</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hevner
et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2004)</span>
<span class="ltx_bibblock">
Alan R. Hevner,
Salvatore T. March, Jinsoo Park, and
Sudha Ram. 2004.

</span>
<span class="ltx_bibblock">Design Science in Information Systems Research.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">MIS Q.</em> 28,
1 (March 2004),
75–105.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="http://dl.acm.org/citation.cfm?id=2017212.2017217" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dl.acm.org/citation.cfm?id=2017212.2017217</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hildebrandt (2016)</span>
<span class="ltx_bibblock">
Mireille Hildebrandt.
2016.

</span>
<span class="ltx_bibblock">The New Imbroglio: Living with Machine
Algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">The Art of Ethics in the Information Society.
Mind you</em> (2016), 55–60.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holstein et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kenneth Holstein, Jennifer
Wortman Vaughan, Hal Daumé, III, Miro
Dudik, and Hanna Wallach.
2019.

</span>
<span class="ltx_bibblock">Improving Fairness in Machine Learning Systems:
What Do Industry Practitioners Need?. In
<em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib46.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. ACM,
New York, NY, USA, Article 600,
16 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300830" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300830</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Höök (2000)</span>
<span class="ltx_bibblock">
Kristina Höök.
2000.

</span>
<span class="ltx_bibblock">Steps to Take Before Intelligent User Interfaces
Become Real.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Interacting with Computers</em>
12, 4 (2000),
409–426.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1016/S0953-5438(99)00006-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/S0953-5438(99)00006-5</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hornbæk and
Oulasvirta (2017)</span>
<span class="ltx_bibblock">
Kasper Hornbæk and
Antti Oulasvirta. 2017.

</span>
<span class="ltx_bibblock">What Is Interaction?. In
<em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 CHI Conference on Human
Factors in Computing Systems</em> (Denver, Colorado, USA)
<em id="bib.bib48.2.2" class="ltx_emph ltx_font_italic">(CHI ’17)</em>. ACM,
New York, NY, USA, 5040–5052.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3025453.3025765" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3025453.3025765</a>

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Horvitz (1999)</span>
<span class="ltx_bibblock">
Eric Horvitz.
1999.

</span>
<span class="ltx_bibblock">Principles of Mixed-initiative User Interfaces.
In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1999 CHI Conference on Human
Factors in Computing Systems</em> <em id="bib.bib49.2.2" class="ltx_emph ltx_font_italic">(CHI ’99)</em>.
ACM Press, New York, New York, USA,
159–166.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/302979.303030" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/302979.303030</a>

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hussein and
Neuhaus (2010)</span>
<span class="ltx_bibblock">
Tim Hussein and
Sebastian Neuhaus. 2010.

</span>
<span class="ltx_bibblock">Explanation of Spreading Activation Based
Recommendations. In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st
International Workshop on Semantic Models for Adaptive Interactive Systems</em>
(Hong Kong, China) <em id="bib.bib50.2.2" class="ltx_emph ltx_font_italic">(SEMAIS ’10)</em>.
ACM, New York, NY, USA,
24–28.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2002375.2002381" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2002375.2002381</a>

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jackson and
Fovargue (1997)</span>
<span class="ltx_bibblock">
David Jackson and Andrew
Fovargue. 1997.

</span>
<span class="ltx_bibblock">The Use of Animation to Explain Genetic
Algorithms. In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-eighth
SIGCSE Technical Symposium on Computer Science Education</em> (San Jose,
California, USA) <em id="bib.bib51.2.2" class="ltx_emph ltx_font_italic">(SIGCSE ’97)</em>.
ACM, New York, NY, USA,
243–247.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/268084.268175" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/268084.268175</a>

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jhaver
et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Shagun Jhaver, Yoni
Karpfen, and Judd Antin.
2018.

</span>
<span class="ltx_bibblock">Algorithmic Anxiety and Coping Strategies of
Airbnb Hosts.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on
Human Factors in Computing Systems</em> (2018),
1–12.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3173995" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3173995</a>

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson and
Johnson (1993)</span>
<span class="ltx_bibblock">
Hilary Johnson and Peter
Johnson. 1993.

</span>
<span class="ltx_bibblock">Explanation Facilities and Interactive Systems. In
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st International Conference on
Intelligent User Interfaces</em> (Orlando, Florida, USA)
<em id="bib.bib53.2.2" class="ltx_emph ltx_font_italic">(IUI ’93)</em>. ACM,
New York, NY, USA, 159–166.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/169891.169951" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/169891.169951</a>

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson-Laird (1989)</span>
<span class="ltx_bibblock">
Philip N. Johnson-Laird.
1989.

</span>
<span class="ltx_bibblock">Mental Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Foundations of Cognitive Science</em>.
The MIT Press, Cambridge, MA, US.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kapoor
et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Ashish Kapoor, Bongshin
Lee, Desney Tan, and Eric Horvitz.
2010.

</span>
<span class="ltx_bibblock">Interactive Optimization for Steering Machine
Classification. In <em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems</em> (Atlanta, Georgia, USA)
<em id="bib.bib55.4.2" class="ltx_emph ltx_font_italic">(CHI ’10)</em>. ACM,
New York, NY, USA, 1343–1352.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1753326.1753529" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1753326.1753529</a>

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kay and
Kummerfeld (2013)</span>
<span class="ltx_bibblock">
Judy Kay and Bob
Kummerfeld. 2013.

</span>
<span class="ltx_bibblock">Creating Personalized Systems That People Can
Scrutinize and Control: Drivers, Principles and Experience.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Interactive Intelligent
Systems</em> 2, 4, Article
24 (January 2013),
42 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2395123.2395129" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2395123.2395129</a>

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim (2015)</span>
<span class="ltx_bibblock">
Been Kim. 2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Interactive and Interpretable Machine Learning
Models for Human Machine Collaboration</em>.

</span>
<span class="ltx_bibblock">Ph.D. Dissertation.
Massachusetts Institute of Technology (MIT).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kizilcec (2016)</span>
<span class="ltx_bibblock">
René F. Kizilcec.
2016.

</span>
<span class="ltx_bibblock">How Much Information?: Effects of Transparency on
Trust in an Algorithmic Interface. In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2016 CHI Conference on Human Factors in Computing Systems</em> (San Jose,
California, USA) <em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic">(CHI ’16)</em>.
ACM, New York, NY, USA,
2390–2395.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2858036.2858402" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2858036.2858402</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koch
et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Janin Koch, Andrés
Lucero, Lena Hegemann, and Antti
Oulasvirta. 2019.

</span>
<span class="ltx_bibblock">May AI? Design Ideation with Cooperative Contextual
Bandits. In <em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference
on Human Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib59.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. Association for
Computing Machinery, New York, NY, USA,
1–12.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300863" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300863</a>

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocielnik
et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Rafal Kocielnik, Saleema
Amershi, and Paul N. Bennett.
2019.

</span>
<span class="ltx_bibblock">Will You Accept an Imperfect AI?: Exploring Designs
for Adjusting End-user Expectations of AI Systems. In
<em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib60.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. ACM,
New York, NY, USA, Article 411,
14 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3290605.3300641" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300641</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuang (2017)</span>
<span class="ltx_bibblock">
Cliff Kuang.
2017.

</span>
<span class="ltx_bibblock">Can A.I. Be Taught to Explain Itself?

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 01.10.2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza
et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Todd Kulesza, Margaret
Burnett, Weng-Keen Wong, and Simone
Stumpf. 2015.

</span>
<span class="ltx_bibblock">Principles of Explanatory Debugging to Personalize
Interactive Machine Learning. In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 20th International Conference on Intelligent User Interfaces</em> (Atlanta,
Georgia, USA) <em id="bib.bib62.4.2" class="ltx_emph ltx_font_italic">(IUI ’15)</em>. ACM,
New York, NY, USA, 126–137.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2678025.2701399" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2678025.2701399</a>

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza
et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Todd Kulesza, Simone
Stumpf, Margaret Burnett, and Irwin
Kwan. 2012.

</span>
<span class="ltx_bibblock">Tell me more? The Effects of Mental Model
Soundness on Personalizing an Intelligent Agent.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2012 ACM Conference on
Human Factors in Computing Systems</em> (2012),
1.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1145/2207676.2207678" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2207676.2207678</a>

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Todd Kulesza, Simone
Stumpf, Margaret Burnett, Weng-Keen
Wong, Yann Riche, Travis Moore,
Ian Oberst, Amber Shinsel, and
Kevin McIntosh. 2010.

</span>
<span class="ltx_bibblock">Explanatory Debugging: Supporting End-User
Debugging of Machine-Learned Programs. In <em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">2010
IEEE Symposium on Visual Languages and Human-Centric Computing</em>.
41–48.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/VLHCC.2010.15" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/VLHCC.2010.15</a>

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Todd Kulesza, Simone
Stumpf, Margaret Burnett, Sherry Yang,
Irwin Kwan, and Weng-Keen Wong.
2013.

</span>
<span class="ltx_bibblock">Too Much, too Little, or Just Right? Ways
Explanations Impact End Users’ Mental Models. In
<em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">2013 IEEE Symposium on Visual Languages and Human
Centric Computing</em>. 3–10.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/VLHCC.2013.6645235" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/VLHCC.2013.6645235</a>

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Todd Kulesza, Simone
Stumpf, Weng-Keen Wong, Margaret M.
Burnett, Stephen Perona, Andrew Ko,
and Ian Oberst. 2011.

</span>
<span class="ltx_bibblock">Why-oriented End-user Debugging of Naive Bayes Text
Classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Interactive Intelligent
Systems</em> 1, 1, Article
2 (October 2011),
31 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2030365.2030367" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2030365.2030367</a>

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
Todd Kulesza, Weng-Keen
Wong, Simone Stumpf, Stephen Perona,
Rachel White, Margaret M. Burnett,
Ian Oberst, and Andrew J. Ko.
2008.

</span>
<span class="ltx_bibblock">Fixing the Program my Computer Learned. In
<em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 13th International Conference on
Intelligent User Interfaces</em> <em id="bib.bib67.4.2" class="ltx_emph ltx_font_italic">(IUI ’09)</em>.
187–196.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1502650.1502678" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1502650.1502678</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lazer et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
David M. J. Lazer,
Matthew A. Baum, Yochai Benkler,
Adam J. Berinsky, Kelly M. Greenhill,
Filippo Menczer, Miriam J. Metzger,
Brendan Nyhan, Gordon Pennycook,
David Rothschild, Michael Schudson,
Steven A. Sloman, Cass R. Sunstein,
Emily A. Thorson, Duncan J. Watts, and
Jonathan L. Zittrain. 2018.

</span>
<span class="ltx_bibblock">The Science of Fake News.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">Science</em> 359,
6380 (2018), 1094–1096.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1126/science.aao2998" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1126/science.aao2998</a>
arXiv:http://science.sciencemag.org/content/359/6380/1094.full.pdf

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim (2010)</span>
<span class="ltx_bibblock">
Brian Y. Lim.
2010.

</span>
<span class="ltx_bibblock">Improving Trust in Context-aware Applications with
Intelligibility. In <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM
International Conference Adjunct Papers on Ubiquitous Computing</em>
(Copenhagen, Denmark) <em id="bib.bib69.2.2" class="ltx_emph ltx_font_italic">(UbiComp ’10 Adjunct)</em>.
ACM, New York, NY, USA,
477–480.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1864431.1864491" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1864431.1864491</a>

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim and Dey (2009)</span>
<span class="ltx_bibblock">
Brian Y. Lim and
Anind K. Dey. 2009.

</span>
<span class="ltx_bibblock">Assessing Demand for Intelligibility in
Context-aware Applications. In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
11th International Conference on Ubiquitous Computing</em>
<em id="bib.bib70.2.2" class="ltx_emph ltx_font_italic">(UbiComp ’09)</em>. 195–204.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1145/1620545.1620576" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1620545.1620576</a>

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim and Dey (2011)</span>
<span class="ltx_bibblock">
Brian Y. Lim and
Anind K. Dey. 2011.

</span>
<span class="ltx_bibblock">Design of an Intelligible Mobile Context-aware
Application. In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 13th
International Conference on Human Computer Interaction with Mobile Devices
and Services</em> <em id="bib.bib71.2.2" class="ltx_emph ltx_font_italic">(MobileHCI ’11)</em>.
157–166.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2037373.2037399" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2037373.2037399</a>

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim
et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Brian Y. Lim, Anind K.
Dey, and Daniel Avrahami.
2009.

</span>
<span class="ltx_bibblock">Why and Why Not Explanations Improve the
Intelligibility of Context-aware Intelligent Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th International
Conference on Human factors in Computing Systems</em>,
2119–2128.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1145/1518701.1519023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1518701.1519023</a>

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lipton (2018)</span>
<span class="ltx_bibblock">
Zachary C. Lipton.
2018.

</span>
<span class="ltx_bibblock">The Mythos of Model Interpretability.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Queue</em> 16,
3, Article 30 (June
2018), 27 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3236386.3241340" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3236386.3241340</a>

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lynham (2002)</span>
<span class="ltx_bibblock">
Susan A. Lynham.
2002.

</span>
<span class="ltx_bibblock">The General Method of Theory-Building Research in
Applied Disciplines.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Advances in Developing Human Resources</em>
4, 3 (2002),
221–241.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1177/1523422302043002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/1523422302043002</a>

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mittelstadt et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Brent D. Mittelstadt,
Patrick Allo, Mariarosaria Taddeo,
Sandra Wachter, and Luciano Floridi.
2016.

</span>
<span class="ltx_bibblock">The Ethics of Algorithms: Mapping the Debate.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Big Data &amp; Society</em> 3,
2 (2016), 205395171667967.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1177/2053951716679679" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/2053951716679679</a>

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neff and Nagy (2016)</span>
<span class="ltx_bibblock">
Gina Neff and Peter
Nagy. 2016.

</span>
<span class="ltx_bibblock">Automation, Algorithms, and Politics — Talking to
Bots: Symbiotic Agency and the Case of Tay.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">International Journal of Communication</em>
10 (2016).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="http://ijoc.org/index.php/ijoc/article/view/6277" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://ijoc.org/index.php/ijoc/article/view/6277</a>

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Norman (2013)</span>
<span class="ltx_bibblock">
Donald A. Norman.
2013.

</span>
<span class="ltx_bibblock">The Design of Everyday Things.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1002/hfm.20127" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/hfm.20127</a>
arXiv:arXiv:1011.1669v3

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nunes and Jannach (2017)</span>
<span class="ltx_bibblock">
Ingrid Nunes and Dietmar
Jannach. 2017.

</span>
<span class="ltx_bibblock">A Systematic Review and Taxonomy of Explanations in
Decision Support and Recommender Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">User Modeling and User-Adapted Interaction</em>
27, 3 (01 December
2017), 393–444.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s11257-017-9195-0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s11257-017-9195-0</a>

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oh
et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Changhoon Oh, Taeyoung
Lee, Yoojung Kim, SoHyun Park,
Sae bom Kwon, and Bongwon Suh.
2017.

</span>
<span class="ltx_bibblock">Us vs. Them: Understanding Artificial Intelligence
Technophobia over the Google DeepMind Challenge Match. In
<em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 CHI Conference on Human
Factors in Computing Systems</em> (Denver, Colorado, USA)
<em id="bib.bib79.4.2" class="ltx_emph ltx_font_italic">(CHI ’17)</em>. ACM,
New York, NY, USA, 2523–2534.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3025453.3025539" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3025453.3025539</a>

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parliament and the Council of the European Union (2016)</span>
<span class="ltx_bibblock">
The European Parliament and
the Council of the European Union.
2016.

</span>
<span class="ltx_bibblock">General Data Protection Regulation.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://gdpr-info.eu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://gdpr-info.eu/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 09.10.2020.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pu and Chen (2006)</span>
<span class="ltx_bibblock">
Pearl Pu and Li Chen.
2006.

</span>
<span class="ltx_bibblock">Trust Building with Explanation Interfaces. In
<em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th International Conference on
Intelligent User Interfaces</em> <em id="bib.bib81.2.2" class="ltx_emph ltx_font_italic">(IUI ’06)</em>.
93–100.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1111449.1111475" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1111449.1111475</a>

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rader
et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Emilee Rader, Kelley
Cotter, and Janghee Cho.
2018.

</span>
<span class="ltx_bibblock">Explanations As Mechanisms for Supporting
Algorithmic Transparency. In <em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
2018 CHI Conference on Human Factors in Computing Systems</em> (Montreal QC,
Canada) <em id="bib.bib82.4.2" class="ltx_emph ltx_font_italic">(CHI ’18)</em>. ACM,
New York, NY, USA, Article 103,
13 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3173677" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3173677</a>

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rana and Bridge (2018)</span>
<span class="ltx_bibblock">
Arpit Rana and Derek
Bridge. 2018.

</span>
<span class="ltx_bibblock">Explanations That Are Intrinsic to
Recommendations. In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th
Conference on User Modeling, Adaptation and Personalization</em> (Singapore,
Singapore) <em id="bib.bib83.2.2" class="ltx_emph ltx_font_italic">(UMAP ’18)</em>. ACM,
New York, NY, USA, 187–195.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3209219.3209230" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3209219.3209230</a>

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ribeiro
et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Marco Tulio Ribeiro,
Sameer Singh, and Carlos Guestrin.
2016.

</span>
<span class="ltx_bibblock">“Why Should I Trust You?”: Explaining the
Predictions of Any Classifier. In <em id="bib.bib84.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining</em> (San Francisco, California, USA) <em id="bib.bib84.4.2" class="ltx_emph ltx_font_italic">(KDD ’16)</em>.
ACM, New York, NY, USA,
1135–1144.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2939672.2939778" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2939672.2939778</a>

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarkar (2015)</span>
<span class="ltx_bibblock">
Advait Sarkar.
2015.

</span>
<span class="ltx_bibblock">Confidence, Command, Complexity: Metamodels for
Structured Interaction with Machine Intelligence. In
<em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th Annual Conference of the
Psychology of Programming Interest Group</em>. 23–36.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://www.ppig.org/library/paper/confidence-command-complexity-metamodels-structured-interaction-machine-intelligence" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.ppig.org/library/paper/confidence-command-complexity-metamodels-structured-interaction-machine-intelligence</a>

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarkar (2016)</span>
<span class="ltx_bibblock">
Advait Sarkar.
2016.

</span>
<span class="ltx_bibblock">Constructivist Design for Interactive Machine
Learning. In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 CHI
Conference Extended Abstracts on Human Factors in Computing Systems</em> (San
Jose, California, USA) <em id="bib.bib86.2.2" class="ltx_emph ltx_font_italic">(CHI EA ’16)</em>.
ACM, New York, NY, USA,
1467–1475.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2851581.2892547" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2851581.2892547</a>

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schlesinger
et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ari Schlesinger, Kenton P.
O’Hara, and Alex S. Taylor.
2018.

</span>
<span class="ltx_bibblock">Let’s Talk About Race: Identity, Chatbots, and AI.
In <em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on Human
Factors in Computing Systems</em> (Montreal QC, Canada)
<em id="bib.bib87.4.2" class="ltx_emph ltx_font_italic">(CHI ’18)</em>. ACM,
New York, NY, USA, Article 315,
14 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3173889" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3173889</a>

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schoppek (2002)</span>
<span class="ltx_bibblock">
Wolfgang Schoppek.
2002.

</span>
<span class="ltx_bibblock">Examples, Rules, and Strategies in the Control of
Dynamic Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Cognitive Science Quarterly</em>
2, 1 (2002),
63–92.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siljee (2015)</span>
<span class="ltx_bibblock">
Johanneke Siljee.
2015.

</span>
<span class="ltx_bibblock">Privacy Transparency Patterns. In
<em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th European Conference on
Pattern Languages of Programs</em> (Kaufbeuren, Germany)
<em id="bib.bib89.2.2" class="ltx_emph ltx_font_italic">(EuroPLoP ’15)</em>. ACM,
New York, NY, USA, Article 52,
11 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2855321.2855374" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2855321.2855374</a>

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh (1994)</span>
<span class="ltx_bibblock">
Munindar P. Singh.
1994.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Multiagent Systems</em>.

</span>
<span class="ltx_bibblock">Springer Berlin Heidelberg,
Berlin, Heidelberg, 1–14.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/BFb0030532" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/BFb0030532</a>

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strauss and
Corbin (1998)</span>
<span class="ltx_bibblock">
Anselm Strauss and
Juliet Corbin. 1998.

</span>
<span class="ltx_bibblock"><em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Basics of Qualitative Research
Techniques</em>.

</span>
<span class="ltx_bibblock">SAGE.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talbot
et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Justin Talbot, Bongshin
Lee, Ashish Kapoor, and Desney S.
Tan. 2009.

</span>
<span class="ltx_bibblock">EnsembleMatrix: Interactive Visualization to
Support Machine Learning with Multiple Classifiers. In
<em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems</em> (Boston, MA, USA) <em id="bib.bib92.4.2" class="ltx_emph ltx_font_italic">(CHI
’09)</em>. ACM, New York, NY, USA,
1283–1292.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1518701.1518895" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1518701.1518895</a>

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tintarev and
Kutlak (2014)</span>
<span class="ltx_bibblock">
Nava Tintarev and Roman
Kutlak. 2014.

</span>
<span class="ltx_bibblock">Demo: Making Plans Scrutable with Argumentation and
Natural Language Generation. In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Companion Publication of the 19th International Conference on Intelligent
User Interfaces</em> (Haifa, Israel) <em id="bib.bib93.2.2" class="ltx_emph ltx_font_italic">(IUI Companion
’14)</em>. ACM, New York, NY, USA,
29–32.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2559184.2559202" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2559184.2559202</a>

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsai and
Brusilovsky (2019a)</span>
<span class="ltx_bibblock">
Chun-Hua Tsai and Peter
Brusilovsky. 2019a.

</span>
<span class="ltx_bibblock">Evaluating Visual Explanations for Similarity-Based
Recommendations: User Perception and Performance. In
<em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM Conference on User
Modeling, Adaptation and Personalization</em> (Larnaca, Cyprus)
<em id="bib.bib94.2.2" class="ltx_emph ltx_font_italic">(UMAP ’19)</em>. ACM,
New York, NY, USA, 22–30.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3320435.3320465" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3320435.3320465</a>

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsai and
Brusilovsky (2019b)</span>
<span class="ltx_bibblock">
Chun-Hua Tsai and Peter
Brusilovsky. 2019b.

</span>
<span class="ltx_bibblock">Explaining Recommendations in an Interactive Hybrid
Social Recommender. In <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th
International Conference on Intelligent User Interfaces</em> (Marina del Ray,
California) <em id="bib.bib95.2.2" class="ltx_emph ltx_font_italic">(IUI ’19)</em>. ACM,
New York, NY, USA, 391–396.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3301275.3302318" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3301275.3302318</a>

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tullio
et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2007)</span>
<span class="ltx_bibblock">
Joe Tullio, Anind K. Dey,
Jason Chalecki, and James Fogarty.
2007.

</span>
<span class="ltx_bibblock">How it Works: A Field Study of Non-technical Users
Interacting with an Intelligent System. In
<em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems</em> <em id="bib.bib96.4.2" class="ltx_emph ltx_font_italic">(CHI ’07)</em>.
31–40.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1145/1240624.1240630" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1240624.1240630</a>

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veale
et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Michael Veale, Max
Van Kleek, and Reuben Binns.
2018.

</span>
<span class="ltx_bibblock">Fairness and Accountability Design Needs for
Algorithmic Support in High-Stakes Public Sector Decision-Making. In
<em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on Human
Factors in Computing Systems</em> (Montreal QC, Canada)
<em id="bib.bib97.4.2" class="ltx_emph ltx_font_italic">(CHI ’18)</em>. ACM,
New York, NY, USA, Article 440,
14 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3174014" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3174014</a>

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Glasersfeld (1989)</span>
<span class="ltx_bibblock">
Ernst von Glasersfeld.
1989.

</span>
<span class="ltx_bibblock">Cognition, Construction of Knowledge, and
Teaching.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Synthese</em> (1989).

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1007/BF00869951" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/BF00869951</a>
arXiv:arXiv:1011.1669v3

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wachter
et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2017a)</span>
<span class="ltx_bibblock">
Sandra Wachter, Brent
Mittelstadt, and Luciano Floridi.
2017a.

</span>
<span class="ltx_bibblock">Transparent, Explainable, and Accountable AI for
Robotics.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">Science Robotics</em> 2,
6 (2017).

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.1126/scirobotics.aan6080" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1126/scirobotics.aan6080</a>
arXiv:2794335

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wachter
et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2017b)</span>
<span class="ltx_bibblock">
Sandra Wachter, Brent
Mittelstadt, and Luciano Floridi.
2017b.

</span>
<span class="ltx_bibblock">Why a Right to Explanation of Automated
Decision-Making Does Not Exist in the General Data Protection Regulation.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">Ssrn</em> (2017),
1–47.

</span>
<span class="ltx_bibblock">


<a target="_blank" href="https://doi.org/10.2139/ssrn.2903469" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2139/ssrn.2903469</a>
arXiv:1606.08813

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Fumeng Yang, Zhuanyi
Huang, Jean Scholtz, and Dustin L.
Arendt. 2020a.

</span>
<span class="ltx_bibblock">How Do Visual Explanations Foster End Users’
Appropriate Trust in Machine Learning?. In
<em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference on
Intelligent User Interfaces</em> (Cagliari, Italy) <em id="bib.bib101.4.2" class="ltx_emph ltx_font_italic">(IUI
’20)</em>. Association for Computing Machinery,
New York, NY, USA, 189–201.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3377325.3377480" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3377325.3377480</a>

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Qian Yang, Aaron
Steinfeld, Carolyn Rosé, and John
Zimmerman. 2020b.

</span>
<span class="ltx_bibblock">Re-Examining Whether, Why, and How Human-AI
Interaction Is Uniquely Difficult to Design. In
<em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 CHI Conference on Human
Factors in Computing Systems</em> (Honolulu, HI, USA)
<em id="bib.bib102.4.2" class="ltx_emph ltx_font_italic">(CHI ’20)</em>. Association for
Computing Machinery, New York, NY, USA,
1–13.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3313831.3376301" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3313831.3376301</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2001.08300" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2001.08301" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2001.08301">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2001.08301" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2001.08302" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 09:23:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
