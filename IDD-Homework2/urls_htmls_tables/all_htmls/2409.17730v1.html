<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Autoregressive Generation Strategies for Top-K Sequential Recommendations</title>
<!--Generated on Thu Sep 26 10:42:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="recommender systems; sequential recommendations; transformers; autoregressive generation; GPTRec" lang="en" name="keywords"/>
<base href="/html/2409.17730v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S1" title="In Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S2" title="In Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S2.SS1" title="In 2. Related Work ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Top-K sequential recommendation task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S2.SS2" title="In 2. Related Work ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Generative approaches to sequential recommendations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3" title="In Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proposed approach</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS1" title="In 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Recommendation model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2" title="In 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Generation strategies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS1" title="In 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Top-K prediction approach</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS2" title="In 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Autoregressive generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS3" title="In 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Commonly used autoregressive generation strategies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS4" title="In 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.4 </span>Proposed multi-sequence aggregation strategies.</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS4.Px1" title="In 3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title">Reciprocal Rank Aggregation strategy (RRA)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS4.Px2" title="In 3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title">Relevance Aggregation strategy (RA)</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4" title="In Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1" title="In 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS1" title="In 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS2" title="In 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS3" title="In 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Generative model (GPT-2)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS4" title="In 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.4 </span>Baseline methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS5" title="In 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.5 </span>Implementation Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS2" title="In 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Single Sequence Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS2.SSS1" title="In 4.2. Single Sequence Generation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Temperature sampling.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS2.SSS2" title="In 4.2. Single Sequence Generation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Beam search.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3" title="In 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Multi-Sequence Aggregation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3.SSS1" title="In 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Choosing top-k for reciprocal rank aggregation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3.SSS2" title="In 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Dependency on temperature value.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3.SSS3" title="In 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Dependency on the number of sequences.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3.SSS4" title="In 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.4 </span>Inference speed considerations.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS4" title="In 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Overall Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS5" title="In 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Performance by Ground Truth Item Position</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S5" title="In Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Autoregressive Generation Strategies for Top-K Sequential Recommendations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anna Volodkevich
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:volodkanna@yandex.ru">volodkanna@yandex.ru</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Sber AI Lab</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Moscow</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">Russian Federation</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Danil Gusak
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:Danil.Gusak@skoltech.ru">Danil.Gusak@skoltech.ru</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">Skoltech, HSE University</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">Moscow</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">Russian Federation</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anton Klenitskiy
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:antklen@gmail.com">antklen@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Sber AI Lab</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">Moscow</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">Russian Federation</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alexey Vasilev
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:alexxl.vasilev@yandex.ru">alexxl.vasilev@yandex.ru</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">Sber AI Lab</span><span class="ltx_text ltx_affiliation_city" id="id11.2.id2">Moscow</span><span class="ltx_text ltx_affiliation_country" id="id12.3.id3">Russian Federation</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id13.id1">The goal of modern sequential recommender systems is often formulated in terms of next-item prediction. In this paper, we explore the applicability of generative transformer-based models for the Top-K sequential recommendation task, where the goal is to predict items a user is likely to interact with in the “near future”.</p>
<p class="ltx_p" id="id14.id2">We explore commonly used autoregressive generation strategies, including greedy decoding, beam search, and temperature sampling, to evaluate their performance for the Top-K sequential recommendation task. In addition, we propose novel <span class="ltx_text ltx_font_italic" id="id14.id2.1">Reciprocal Rank Aggregation (RRA)</span> and <span class="ltx_text ltx_font_italic" id="id14.id2.2">Relevance Aggregation (RA)</span> generation strategies based on multi-sequence generation with temperature sampling and subsequent aggregation.</p>
<p class="ltx_p" id="id15.id3">Experiments on diverse datasets give valuable insights regarding commonly used strategies’ applicability and show that suggested approaches improve performance on longer time horizons compared to widely-used Top-K prediction approach and single-sequence autoregressive generation strategies.</p>
</div>
<div class="ltx_keywords">recommender systems; sequential recommendations; transformers; autoregressive generation; GPTRec
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>The 18th ACM International Conference on Web Search and Data Mining; March 10–14,
2025; Hannover, Germany</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Sequential recommender systems with Transformer-based models are a popular area of research. Such systems aim to leverage the order of user-item interactions in historical data to predict future user interactions. However, previous works that have significantly shaped the direction of research within the field, such as SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib22" title="">2018</a>)</cite> and BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib44" title="">2019</a>)</cite> were focused on the next-item prediction task. In this formulation, the goal of the model is to predict only one next item in a user sequence. While it is a valid and useful approach for many applications, such as music services or video streaming, prediction over a longer time horizon draws the attention of the scientific community as well <cite class="ltx_cite ltx_citemacro_citep">(Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>; Pancha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib31" title="">2022</a>; Kolesnikov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib24" title="">2021</a>; Devooght and Bersini, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib13" title="">2017</a>; Bacciu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib5" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Further, we denote the number of recommendations by K and the number of ground truth items for each user by N. The goal of Top-K sequential recommendations is to predict a ranked list of K items a user is likely to interact with in the ”near future” <cite class="ltx_cite ltx_citemacro_citep">(Tang and Wang, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib46" title="">2018</a>)</cite>. Following <cite class="ltx_cite ltx_citemacro_citep">(Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>)</cite>, we aim to correctly predict exactly N hidden future user’s actions. This validation strategy allows to easily compare short-term and longer-term performance of considered approaches.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">One option to solve this task is to use the Top-K recommendation strategy commonly applied to the next-item prediction task as in <cite class="ltx_cite ltx_citemacro_citep">(Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>; Devooght and Bersini, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib13" title="">2017</a>)</cite>. The first limitation of this approach is that the model is not directly trained to predict several next items, so the training objective and final task are not aligned. Second, in this approach, the model scores all candidates simultaneously and independently. So, similar items may have close scores and dominate the recommendation list.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We propose to use a model trained for the next-item prediction task and modify the inference scheme to suit the Top-K sequential recommendation task better. This approach allows to adapt the widely-used Transformer-based models without training objective modification and use the same model for the next-item prediction and the Top-K sequential recommendation.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We train the GPT-2 model to predict the next item in a sequence, similar to the popular SASRec model <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib22" title="">2018</a>)</cite>. After that, we autoregressively generate recommendations item-by-item: at each step, we include already generated items in a sequence to generate the following item. So, the model considers already recommended items at each subsequent step and can adjust predictions accordingly. This way, the model can predict more complex and interdependent recommendation lists; for example, it can generate complementary items. The apparent drawback of autoregressive generation is that it is more computationally expensive because we need to score all items <math alttext="K" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mi id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><ci id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">italic_K</annotation></semantics></math> times.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In our paper, we adopt different generation strategies, commonly used for text generation, namely greedy decoding, temperature sampling, and beam search for the Top-K sequential recommendation task. Besides single sequence continuation generation, it is also possible to generate diverse future sequences (several possible realizations of future user behavior) with the same model and combine them into one final recommendation list. We introduce novel approaches with multi-sequence aggregation to make more robust and powerful recommendations.
This approach leads to some computational overhead but significantly boosts the performance of recommendations. It acts as an ensemble of models, reducing error accumulation on a longer prediction horizon. The difference with standard ensemble methods is that we sample multiple sequences using the same single model, so we don’t need to train several models. As we do not aim to predict the exact user sequence ordered by interaction time, we could aggregate generated sequences to enhance the quality of the recommendations.
</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">In short, the main contributions of this paper are:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We evaluate several commonly used autoregressive generation strategies and compare them with the Top-K prediction approach to determine their applicability to the Top-K recommendation task.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose novel multi-sequence generation approaches, <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">Reciprocal
Rank Aggregation</span> and <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.2">Relevance Aggregation</span>, which are based on the generation of several sequences and subsequent aggregation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Proposed approaches enhance the performance GPT-2 on Top-K sequential recommendations and could be applied to a wide range of generative models trained for the next-item prediction task.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Top-K sequential recommendation task</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Recent works on sequential recommendations often consider short-term predictions and namely next-item prediction task, aiming to predict the item a user is going to interact with next <cite class="ltx_cite ltx_citemacro_citep">(Quadrana et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib37" title="">2018</a>)</cite>.
Current state-of-the-art approaches for this task are based on Transformer models, such as SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib22" title="">2018</a>)</cite> and BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib44" title="">2019</a>)</cite>. In the Top-K and long-term sequential recommendations, the goal is to understand what the user will do at a longer time horizon. Works <cite class="ltx_cite ltx_citemacro_citep">(Devooght and Bersini, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib13" title="">2017</a>; Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>)</cite> investigate approaches based on recurrent neural networks for long-term sequential recommendations. The Caser model’s <cite class="ltx_cite ltx_citemacro_citep">(Tang and Wang, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib46" title="">2018</a>)</cite> authors propose the Top-K sequential recommendation approach with convolutional networks. The PinnerFormer paper <cite class="ltx_cite ltx_citemacro_citep">(Pancha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib31" title="">2022</a>)</cite> uses a Transformer-based model to predict user interactions over a horizon of several days and introduce the new Dense All Action loss designed specifically for this task. In recent work <cite class="ltx_cite ltx_citemacro_citep">(Bacciu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib5" title="">2023</a>)</cite>, authors argue for the importance of predicting several next items and also create a specific loss function for the SASRec model.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Generative approaches to sequential recommendations</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Generative language models such as T5 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib40" title="">2020</a>)</cite>, GPT-2 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib39" title="">2019</a>)</cite>, and GPT-3 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib8" title="">2020</a>)</cite> show significant progress on a wide range of tasks. Adoption of language models’ architectures to a recommendation domain is a promising research direction as stated in <cite class="ltx_cite ltx_citemacro_citep">(de Souza Pereira Moreira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib12" title="">2021</a>)</cite> and additionally confirmed by the popularity of the corresponding Transformers4Rec library, which adopts the latest Transformer architectures for sequential recommendation tasks.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Some works, like P5 <cite class="ltx_cite ltx_citemacro_citep">(Geng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib18" title="">2022</a>)</cite> and GPT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib26" title="">2023</a>)</cite>, adopt pre-trained language models and consider recommendations as text generation tasks. Unlike this work, we consider sequences of item IDs as input and train the model from scratch.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Recent paper <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib34" title="">2023a</a>)</cite> also formulates recommendation as an autoregressive item sequence generation with GPT-2. In contrast to our work, the authors evaluate the model on the next-item prediction task while we consider long-term recommendations. In addition, we explore existing commonly used decoding strategies for text generation from NLP <cite class="ltx_cite ltx_citemacro_citep">(Welleck et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib50" title="">2020</a>; Holtzman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib21" title="">2019</a>; Zarrieß et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib54" title="">2021</a>)</cite> and introduce a novel multi-sequence aggregation approach.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Autoregressive generation could also be applied to solve the other related sequential recommendation tasks, such as bundle recommendation <cite class="ltx_cite ltx_citemacro_citep">(Bai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib6" title="">2019</a>)</cite>, aimed at the generation of a collection of associated products that users consume as a whole under the circumstances, e.g., specific intents.
Recent work <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib45" title="">2023</a>)</cite> uses autoregressive generation with a Transformer-based model for next-basket recommendation, which refers to the task of predicting a set of items that a user will purchase in the next session, rather than in the current session. Apart from the different tasks, this work considers the Encoder-Decoder model type while we consider the Decoder-only model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Proposed approach</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Recommendation model</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In our work, we evaluate the performance of commonly used generation strategies in a Top-K sequential recommendation task and propose novel multi-sequence aggregation strategies. Those strategies may be applied to any autoregressive model, which returns the next-item probability distribution. Proposed approaches do not affect model training and do not impose additional training costs. In our work, we use GPT-2 to conduct experiments. We motivate the model choice and briefly describe GPT-2 architecture and training process in <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS3" title="4.1.3. Generative model (GPT-2) ‣ 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Generation strategies</h3>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Top-K prediction approach</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">Suppose we have a sequence of user interactions <math alttext="i_{1:t}=\{i_{1},i_{2},...i_{t}\}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.1.m1.3"><semantics id="S3.SS2.SSS1.p1.1.m1.3a"><mrow id="S3.SS2.SSS1.p1.1.m1.3.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.cmml"><msub id="S3.SS2.SSS1.p1.1.m1.3.3.5" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.3.3.5.2" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.2.cmml">i</mi><mrow id="S3.SS2.SSS1.p1.1.m1.3.3.5.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.cmml"><mn id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.2" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.2.cmml">1</mn><mo id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.1.cmml">:</mo><mi id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.3.cmml">t</mi></mrow></msub><mo id="S3.SS2.SSS1.p1.1.m1.3.3.4" xref="S3.SS2.SSS1.p1.1.m1.3.3.4.cmml">=</mo><mrow id="S3.SS2.SSS1.p1.1.m1.3.3.3.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.4.cmml"><mo id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.4" stretchy="false" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.4.cmml">{</mo><msub id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.2.cmml">i</mi><mn id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.5" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.4.cmml">,</mo><msub id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.2.cmml">i</mi><mn id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.3" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.6" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.4.cmml">,</mo><mrow id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.2" mathvariant="normal" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.2.cmml">…</mi><mo id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.1" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.1.cmml">⁢</mo><msub id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.2" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.2.cmml">i</mi><mi id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.3" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.3.cmml">t</mi></msub></mrow><mo id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.7" stretchy="false" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.3b"><apply id="S3.SS2.SSS1.p1.1.m1.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3"><eq id="S3.SS2.SSS1.p1.1.m1.3.3.4.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.4"></eq><apply id="S3.SS2.SSS1.p1.1.m1.3.3.5.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.3.3.5.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.5">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.3.3.5.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.2">𝑖</ci><apply id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3"><ci id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.1">:</ci><cn id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.2.cmml" type="integer" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.2">1</cn><ci id="S3.SS2.SSS1.p1.1.m1.3.3.5.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.5.3.3">𝑡</ci></apply></apply><set id="S3.SS2.SSS1.p1.1.m1.3.3.3.4.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3"><apply id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.2">𝑖</ci><cn id="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.2">𝑖</ci><cn id="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.2.2.3">2</cn></apply><apply id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3"><times id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.1"></times><ci id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.2">…</ci><apply id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.2">𝑖</ci><ci id="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.3.3.3.3.3.3.3">𝑡</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.3c">i_{1:t}=\{i_{1},i_{2},...i_{t}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.1.m1.3d">italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT = { italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … italic_i start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT }</annotation></semantics></math>, and aim to get the Top-K sequential recommendations. One of the commonly used recommendation strategies with sequential models is to apply the model to a known user’s interactions sequence, get the model scores for next-item and recommend the Top-K items with the highest score as is done in <cite class="ltx_cite ltx_citemacro_citep">(Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>; Devooght and Bersini, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib13" title="">2017</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Autoregressive generation</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">In our work, we examine commonly used generation strategies performance in a Top-K sequential recommendation task and propose novel strategies, based on existing ones. Thus, we provide a brief description of the standard generation strategies below.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">Autoregressive generation is based on the assumption that the probability distribution of the sequence continuation can be decomposed into the product of conditional distributions:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(i_{t+1:t+K}|i_{1:t})=\prod_{k=1}^{K}P(i_{t+k}|i_{1:t+k-1})" class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">P</mi><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.cmml">i</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.3.2.1" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.1.cmml">+</mo><mn id="S3.E1.m1.1.1.1.1.1.1.2.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.3.cmml">1</mn></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.1.1.1.1.1.1.2.3.1.cmml">:</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.1.cmml">+</mo><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.3.cmml">K</mi></mrow></mrow></msub><mo fence="false" id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mn id="S3.E1.m1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">:</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.3" rspace="0.111em" xref="S3.E1.m1.2.2.3.cmml">=</mo><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><munderover id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><mo id="S3.E1.m1.2.2.2.2.2.2" movablelimits="false" xref="S3.E1.m1.2.2.2.2.2.2.cmml">∏</mo><mrow id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3.cmml"><mi id="S3.E1.m1.2.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.2.3.2.cmml">k</mi><mo id="S3.E1.m1.2.2.2.2.2.3.1" xref="S3.E1.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml">K</mi></munderover><mrow id="S3.E1.m1.2.2.2.1" xref="S3.E1.m1.2.2.2.1.cmml"><mi id="S3.E1.m1.2.2.2.1.3" xref="S3.E1.m1.2.2.2.1.3.cmml">P</mi><mo id="S3.E1.m1.2.2.2.1.2" xref="S3.E1.m1.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.2.1.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.1.cmml"><msub id="S3.E1.m1.2.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.1.2.2" xref="S3.E1.m1.2.2.2.1.1.1.1.2.2.cmml">i</mi><mrow id="S3.E1.m1.2.2.2.1.1.1.1.2.3" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.1.2.3.2" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E1.m1.2.2.2.1.1.1.1.2.3.1" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.1.cmml">+</mo><mi id="S3.E1.m1.2.2.2.1.1.1.1.2.3.3" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.3.cmml">k</mi></mrow></msub><mo fence="false" id="S3.E1.m1.2.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.1.1.cmml">|</mo><msub id="S3.E1.m1.2.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.2.1.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.1.3.2" xref="S3.E1.m1.2.2.2.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.E1.m1.2.2.2.1.1.1.1.3.3" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.cmml"><mn id="S3.E1.m1.2.2.2.1.1.1.1.3.3.2" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.E1.m1.2.2.2.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.1.cmml">:</mo><mrow id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.cmml"><mrow id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.2" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.2.cmml">t</mi><mo id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.1" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.1.cmml">+</mo><mi id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.3" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.3.cmml">k</mi></mrow><mo id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.1" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.1.cmml">−</mo><mn id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.3" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.3.cmml">1</mn></mrow></mrow></msub></mrow><mo id="S3.E1.m1.2.2.2.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><eq id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3"></eq><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">𝑃</ci><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2">𝑖</ci><apply id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3"><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.1">:</ci><apply id="S3.E1.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2"><plus id="S3.E1.m1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.1"></plus><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.2">𝑡</ci><cn id="S3.E1.m1.1.1.1.1.1.1.2.3.2.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.3">1</cn></apply><apply id="S3.E1.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3"><plus id="S3.E1.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.1"></plus><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.2">𝑡</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.3">𝐾</ci></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">𝑖</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1">:</ci><cn id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2">1</cn><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2">subscript</csymbol><csymbol cd="latexml" id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2">product</csymbol><apply id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.3"><eq id="S3.E1.m1.2.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.2.3.1"></eq><ci id="S3.E1.m1.2.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.2.3.2">𝑘</ci><cn id="S3.E1.m1.2.2.2.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3">𝐾</ci></apply><apply id="S3.E1.m1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.1"><times id="S3.E1.m1.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.1.2"></times><ci id="S3.E1.m1.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.1.3">𝑃</ci><apply id="S3.E1.m1.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2.2">𝑖</ci><apply id="S3.E1.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3"><plus id="S3.E1.m1.2.2.2.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.1"></plus><ci id="S3.E1.m1.2.2.2.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E1.m1.2.2.2.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.2.3.3">𝑘</ci></apply></apply><apply id="S3.E1.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.2">𝑖</ci><apply id="S3.E1.m1.2.2.2.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3"><ci id="S3.E1.m1.2.2.2.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.1">:</ci><cn id="S3.E1.m1.2.2.2.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.2">1</cn><apply id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3"><minus id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.1"></minus><apply id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2"><plus id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.1"></plus><ci id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.2">𝑡</ci><ci id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.2.3">𝑘</ci></apply><cn id="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.2.1.1.1.1.3.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">P(i_{t+1:t+K}|i_{1:t})=\prod_{k=1}^{K}P(i_{t+k}|i_{1:t+k-1})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">italic_P ( italic_i start_POSTSUBSCRIPT italic_t + 1 : italic_t + italic_K end_POSTSUBSCRIPT | italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT ) = ∏ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT italic_P ( italic_i start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT | italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k - 1 end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p4">
<p class="ltx_p" id="S3.SS2.SSS2.p4.1">Various sequence generation strategies are used and under development in the NLP area <cite class="ltx_cite ltx_citemacro_citep">(Zarrieß et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib54" title="">2021</a>)</cite>. Some methods, such as greedy decoding, beam search, and temperature sampling, may be adopted for sequential recommendation tasks.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Commonly used autoregressive generation strategies</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">Each generation strategy described below is based on the next item probability distribution <math alttext="P(i|i_{1:t})" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p1.1.m1.1"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mrow id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS3.p1.1.m1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS3.p1.1.m1.1.1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.cmml"><mn id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.1.cmml">:</mo><mi id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><apply id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"><times id="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2"></times><ci id="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3">𝑃</ci><apply id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.2">𝑖</ci><apply id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.2">𝑖</ci><apply id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3"><ci id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.1">:</ci><cn id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.2">1</cn><ci id="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">P(i|i_{1:t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p1.1.m1.1d">italic_P ( italic_i | italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>, which is inferred as a softmax over an output vector of the last transformer block multiplied by the transposed embedding matrix <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib38" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">For the recommendation task, one needs to convert the generated sequence into a sorted recommendation list. For the commonly used generation strategies we adopt an intuitive approach, which was also used in <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib34" title="">2023a</a>)</cite>, and consider the first item in the generated sequence as the first item in a list, the item in the second position as the second item in the recommendation list, and so on.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.1">Greedy decoding.</span> Greedy decoding, or greedy search, selects the most probable item as the next item of a sequence:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="i_{t+1}=argmax_{i}P(i|i_{1:t})" class="ltx_Math" display="block" id="S3.Ex1.m1.1"><semantics id="S3.Ex1.m1.1a"><mrow id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml"><msub id="S3.Ex1.m1.1.1.3" xref="S3.Ex1.m1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.3.2" xref="S3.Ex1.m1.1.1.3.2.cmml">i</mi><mrow id="S3.Ex1.m1.1.1.3.3" xref="S3.Ex1.m1.1.1.3.3.cmml"><mi id="S3.Ex1.m1.1.1.3.3.2" xref="S3.Ex1.m1.1.1.3.3.2.cmml">t</mi><mo id="S3.Ex1.m1.1.1.3.3.1" xref="S3.Ex1.m1.1.1.3.3.1.cmml">+</mo><mn id="S3.Ex1.m1.1.1.3.3.3" xref="S3.Ex1.m1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S3.Ex1.m1.1.1.2" xref="S3.Ex1.m1.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.1.1.1" xref="S3.Ex1.m1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.3.cmml">a</mi><mo id="S3.Ex1.m1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.4" xref="S3.Ex1.m1.1.1.1.4.cmml">r</mi><mo id="S3.Ex1.m1.1.1.1.2a" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.5" xref="S3.Ex1.m1.1.1.1.5.cmml">g</mi><mo id="S3.Ex1.m1.1.1.1.2b" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.6" xref="S3.Ex1.m1.1.1.1.6.cmml">m</mi><mo id="S3.Ex1.m1.1.1.1.2c" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.7" xref="S3.Ex1.m1.1.1.1.7.cmml">a</mi><mo id="S3.Ex1.m1.1.1.1.2d" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><msub id="S3.Ex1.m1.1.1.1.8" xref="S3.Ex1.m1.1.1.1.8.cmml"><mi id="S3.Ex1.m1.1.1.1.8.2" xref="S3.Ex1.m1.1.1.1.8.2.cmml">x</mi><mi id="S3.Ex1.m1.1.1.1.8.3" xref="S3.Ex1.m1.1.1.1.8.3.cmml">i</mi></msub><mo id="S3.Ex1.m1.1.1.1.2e" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.9" xref="S3.Ex1.m1.1.1.1.9.cmml">P</mi><mo id="S3.Ex1.m1.1.1.1.2f" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex1.m1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="S3.Ex1.m1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.Ex1.m1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.cmml"><mn id="S3.Ex1.m1.1.1.1.1.1.1.3.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.cmml">:</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S3.Ex1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1"><eq id="S3.Ex1.m1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.2"></eq><apply id="S3.Ex1.m1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.3.2">𝑖</ci><apply id="S3.Ex1.m1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.3.3"><plus id="S3.Ex1.m1.1.1.3.3.1.cmml" xref="S3.Ex1.m1.1.1.3.3.1"></plus><ci id="S3.Ex1.m1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.1.1.3.3.2">𝑡</ci><cn id="S3.Ex1.m1.1.1.3.3.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.Ex1.m1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1"><times id="S3.Ex1.m1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.2"></times><ci id="S3.Ex1.m1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.3">𝑎</ci><ci id="S3.Ex1.m1.1.1.1.4.cmml" xref="S3.Ex1.m1.1.1.1.4">𝑟</ci><ci id="S3.Ex1.m1.1.1.1.5.cmml" xref="S3.Ex1.m1.1.1.1.5">𝑔</ci><ci id="S3.Ex1.m1.1.1.1.6.cmml" xref="S3.Ex1.m1.1.1.1.6">𝑚</ci><ci id="S3.Ex1.m1.1.1.1.7.cmml" xref="S3.Ex1.m1.1.1.1.7">𝑎</ci><apply id="S3.Ex1.m1.1.1.1.8.cmml" xref="S3.Ex1.m1.1.1.1.8"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.8.1.cmml" xref="S3.Ex1.m1.1.1.1.8">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.8.2.cmml" xref="S3.Ex1.m1.1.1.1.8.2">𝑥</ci><ci id="S3.Ex1.m1.1.1.1.8.3.cmml" xref="S3.Ex1.m1.1.1.1.8.3">𝑖</ci></apply><ci id="S3.Ex1.m1.1.1.1.9.cmml" xref="S3.Ex1.m1.1.1.1.9">𝑃</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2">𝑖</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.2">𝑖</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3"><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1">:</ci><cn id="S3.Ex1.m1.1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.2">1</cn><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">i_{t+1}=argmax_{i}P(i|i_{1:t})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.1d">italic_i start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = italic_a italic_r italic_g italic_m italic_a italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_P ( italic_i | italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p5">
<p class="ltx_p" id="S3.SS2.SSS3.p5.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p5.1.1">Beam search.</span> Beam search with B beams, where B is known as the beam width, leaves top-B most probable sequence continuations at each generation step, where sequence continuation probability is calculated by the equation (<a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.E1" title="In 3.2.2. Autoregressive generation ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>).
More details of beam search implementation for NLP tasks and its modifications can be found in <cite class="ltx_cite ltx_citemacro_citep">(Vijayakumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib47" title="">2016</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Graves, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib19" title="">2012</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p6">
<p class="ltx_p" id="S3.SS2.SSS3.p6.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p6.1.1">Temperature sampling.</span> Another prominent generation strategy is sampling. Following the sampling strategy, the next item is randomly chosen according to its conditional probability distribution:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="i_{t+1}\sim P(i|i_{1:t})" class="ltx_Math" display="block" id="S3.Ex2.m1.1"><semantics id="S3.Ex2.m1.1a"><mrow id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml"><msub id="S3.Ex2.m1.1.1.3" xref="S3.Ex2.m1.1.1.3.cmml"><mi id="S3.Ex2.m1.1.1.3.2" xref="S3.Ex2.m1.1.1.3.2.cmml">i</mi><mrow id="S3.Ex2.m1.1.1.3.3" xref="S3.Ex2.m1.1.1.3.3.cmml"><mi id="S3.Ex2.m1.1.1.3.3.2" xref="S3.Ex2.m1.1.1.3.3.2.cmml">t</mi><mo id="S3.Ex2.m1.1.1.3.3.1" xref="S3.Ex2.m1.1.1.3.3.1.cmml">+</mo><mn id="S3.Ex2.m1.1.1.3.3.3" xref="S3.Ex2.m1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S3.Ex2.m1.1.1.2" xref="S3.Ex2.m1.1.1.2.cmml">∼</mo><mrow id="S3.Ex2.m1.1.1.1" xref="S3.Ex2.m1.1.1.1.cmml"><mi id="S3.Ex2.m1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.3.cmml">P</mi><mo id="S3.Ex2.m1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex2.m1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml"><mo id="S3.Ex2.m1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex2.m1.1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml"><mi id="S3.Ex2.m1.1.1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="S3.Ex2.m1.1.1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.Ex2.m1.1.1.1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex2.m1.1.1.1.1.1.1.3.2" xref="S3.Ex2.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.Ex2.m1.1.1.1.1.1.1.3.3" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.cmml"><mn id="S3.Ex2.m1.1.1.1.1.1.1.3.3.2" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.Ex2.m1.1.1.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.1.cmml">:</mo><mi id="S3.Ex2.m1.1.1.1.1.1.1.3.3.3" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S3.Ex2.m1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.1b"><apply id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1"><csymbol cd="latexml" id="S3.Ex2.m1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.2">similar-to</csymbol><apply id="S3.Ex2.m1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.3.1.cmml" xref="S3.Ex2.m1.1.1.3">subscript</csymbol><ci id="S3.Ex2.m1.1.1.3.2.cmml" xref="S3.Ex2.m1.1.1.3.2">𝑖</ci><apply id="S3.Ex2.m1.1.1.3.3.cmml" xref="S3.Ex2.m1.1.1.3.3"><plus id="S3.Ex2.m1.1.1.3.3.1.cmml" xref="S3.Ex2.m1.1.1.3.3.1"></plus><ci id="S3.Ex2.m1.1.1.3.3.2.cmml" xref="S3.Ex2.m1.1.1.3.3.2">𝑡</ci><cn id="S3.Ex2.m1.1.1.3.3.3.cmml" type="integer" xref="S3.Ex2.m1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.Ex2.m1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1"><times id="S3.Ex2.m1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.2"></times><ci id="S3.Ex2.m1.1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.1.3">𝑃</ci><apply id="S3.Ex2.m1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex2.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex2.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.2">𝑖</ci><apply id="S3.Ex2.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.3.2">𝑖</ci><apply id="S3.Ex2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3"><ci id="S3.Ex2.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.1">:</ci><cn id="S3.Ex2.m1.1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.2">1</cn><ci id="S3.Ex2.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.1c">i_{t+1}\sim P(i|i_{1:t})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.1d">italic_i start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ∼ italic_P ( italic_i | italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS3.p7.6">Softmax temperature tuning may be used to modify probability distribution <math alttext="P(i|i_{1:t})" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p7.1.m1.1"><semantics id="S3.SS2.SSS3.p7.1.m1.1a"><mrow id="S3.SS2.SSS3.p7.1.m1.1.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p7.1.m1.1.1.3" xref="S3.SS2.SSS3.p7.1.m1.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS3.p7.1.m1.1.1.2" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS3.p7.1.m1.1.1.1.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.2" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.cmml"><mn id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.2" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.1.cmml">:</mo><mi id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.3" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.1.m1.1b"><apply id="S3.SS2.SSS3.p7.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1"><times id="S3.SS2.SSS3.p7.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.2"></times><ci id="S3.SS2.SSS3.p7.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.3">𝑃</ci><apply id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.2">𝑖</ci><apply id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.2">𝑖</ci><apply id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3"><ci id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.1">:</ci><cn id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.2">1</cn><ci id="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.1.m1.1c">P(i|i_{1:t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p7.1.m1.1d">italic_P ( italic_i | italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>, e.g., to increase probabilities of the most probable items and lower probabilities of long-tail items. Temperature tuning is widely used in text generation <cite class="ltx_cite ltx_citemacro_citep">(Holtzman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib21" title="">2019</a>)</cite> and could be used in recommendation tasks to balance the recommendation’s accuracy and diversity. For input sequence <math alttext="i_{1:t}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p7.2.m2.1"><semantics id="S3.SS2.SSS3.p7.2.m2.1a"><msub id="S3.SS2.SSS3.p7.2.m2.1.1" xref="S3.SS2.SSS3.p7.2.m2.1.1.cmml"><mi id="S3.SS2.SSS3.p7.2.m2.1.1.2" xref="S3.SS2.SSS3.p7.2.m2.1.1.2.cmml">i</mi><mrow id="S3.SS2.SSS3.p7.2.m2.1.1.3" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.cmml"><mn id="S3.SS2.SSS3.p7.2.m2.1.1.3.2" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.2.cmml">1</mn><mo id="S3.SS2.SSS3.p7.2.m2.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.1.cmml">:</mo><mi id="S3.SS2.SSS3.p7.2.m2.1.1.3.3" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.3.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.2.m2.1b"><apply id="S3.SS2.SSS3.p7.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p7.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p7.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.2">𝑖</ci><apply id="S3.SS2.SSS3.p7.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.3"><ci id="S3.SS2.SSS3.p7.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.1">:</ci><cn id="S3.SS2.SSS3.p7.2.m2.1.1.3.2.cmml" type="integer" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.2">1</cn><ci id="S3.SS2.SSS3.p7.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.2.m2.1c">i_{1:t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p7.2.m2.1d">italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, given the output model scores before softmax (logits) <math alttext="l_{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p7.3.m3.1"><semantics id="S3.SS2.SSS3.p7.3.m3.1a"><msub id="S3.SS2.SSS3.p7.3.m3.1.1" xref="S3.SS2.SSS3.p7.3.m3.1.1.cmml"><mi id="S3.SS2.SSS3.p7.3.m3.1.1.2" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.cmml">l</mi><mi id="S3.SS2.SSS3.p7.3.m3.1.1.3" xref="S3.SS2.SSS3.p7.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.3.m3.1b"><apply id="S3.SS2.SSS3.p7.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p7.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p7.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.2">𝑙</ci><ci id="S3.SS2.SSS3.p7.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.3.m3.1c">l_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p7.3.m3.1d">italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> for each item <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p7.4.m4.1"><semantics id="S3.SS2.SSS3.p7.4.m4.1a"><mi id="S3.SS2.SSS3.p7.4.m4.1.1" xref="S3.SS2.SSS3.p7.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.4.m4.1b"><ci id="S3.SS2.SSS3.p7.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p7.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p7.4.m4.1d">italic_i</annotation></semantics></math> in the item set <math alttext="I" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p7.5.m5.1"><semantics id="S3.SS2.SSS3.p7.5.m5.1a"><mi id="S3.SS2.SSS3.p7.5.m5.1.1" xref="S3.SS2.SSS3.p7.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.5.m5.1b"><ci id="S3.SS2.SSS3.p7.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p7.5.m5.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.5.m5.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p7.5.m5.1d">italic_I</annotation></semantics></math> and temperature <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p7.6.m6.1"><semantics id="S3.SS2.SSS3.p7.6.m6.1a"><mi id="S3.SS2.SSS3.p7.6.m6.1.1" xref="S3.SS2.SSS3.p7.6.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.6.m6.1b"><ci id="S3.SS2.SSS3.p7.6.m6.1.1.cmml" xref="S3.SS2.SSS3.p7.6.m6.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.6.m6.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p7.6.m6.1d">italic_T</annotation></semantics></math>, the softmax is re-estimated as:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p8">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P_{T}(i|i_{1:t})=\frac{exp(l_{i}/T)}{\sum_{j\in I}{exp(l_{j}/T)}}" class="ltx_Math" display="block" id="S3.Ex3.m1.3"><semantics id="S3.Ex3.m1.3a"><mrow id="S3.Ex3.m1.3.3" xref="S3.Ex3.m1.3.3.cmml"><mrow id="S3.Ex3.m1.3.3.1" xref="S3.Ex3.m1.3.3.1.cmml"><msub id="S3.Ex3.m1.3.3.1.3" xref="S3.Ex3.m1.3.3.1.3.cmml"><mi id="S3.Ex3.m1.3.3.1.3.2" xref="S3.Ex3.m1.3.3.1.3.2.cmml">P</mi><mi id="S3.Ex3.m1.3.3.1.3.3" xref="S3.Ex3.m1.3.3.1.3.3.cmml">T</mi></msub><mo id="S3.Ex3.m1.3.3.1.2" xref="S3.Ex3.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.Ex3.m1.3.3.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.2" stretchy="false" xref="S3.Ex3.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.cmml"><mi id="S3.Ex3.m1.3.3.1.1.1.1.2" xref="S3.Ex3.m1.3.3.1.1.1.1.2.cmml">i</mi><mo fence="false" id="S3.Ex3.m1.3.3.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.cmml">|</mo><msub id="S3.Ex3.m1.3.3.1.1.1.1.3" xref="S3.Ex3.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.Ex3.m1.3.3.1.1.1.1.3.2" xref="S3.Ex3.m1.3.3.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.Ex3.m1.3.3.1.1.1.1.3.3" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.cmml"><mn id="S3.Ex3.m1.3.3.1.1.1.1.3.3.2" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.2.cmml">1</mn><mo id="S3.Ex3.m1.3.3.1.1.1.1.3.3.1" lspace="0.278em" rspace="0.278em" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.1.cmml">:</mo><mi id="S3.Ex3.m1.3.3.1.1.1.1.3.3.3" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.3" stretchy="false" xref="S3.Ex3.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex3.m1.3.3.2" xref="S3.Ex3.m1.3.3.2.cmml">=</mo><mfrac id="S3.Ex3.m1.2.2" xref="S3.Ex3.m1.2.2.cmml"><mrow id="S3.Ex3.m1.1.1.1" xref="S3.Ex3.m1.1.1.1.cmml"><mi id="S3.Ex3.m1.1.1.1.3" xref="S3.Ex3.m1.1.1.1.3.cmml">e</mi><mo id="S3.Ex3.m1.1.1.1.2" xref="S3.Ex3.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex3.m1.1.1.1.4" xref="S3.Ex3.m1.1.1.1.4.cmml">x</mi><mo id="S3.Ex3.m1.1.1.1.2a" xref="S3.Ex3.m1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex3.m1.1.1.1.5" xref="S3.Ex3.m1.1.1.1.5.cmml">p</mi><mo id="S3.Ex3.m1.1.1.1.2b" xref="S3.Ex3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex3.m1.1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.1.1.cmml"><mo id="S3.Ex3.m1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex3.m1.1.1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.1.1.cmml"><msub id="S3.Ex3.m1.1.1.1.1.1.1.2" xref="S3.Ex3.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex3.m1.1.1.1.1.1.1.2.2" xref="S3.Ex3.m1.1.1.1.1.1.1.2.2.cmml">l</mi><mi id="S3.Ex3.m1.1.1.1.1.1.1.2.3" xref="S3.Ex3.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.Ex3.m1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S3.Ex3.m1.1.1.1.1.1.1.3" xref="S3.Ex3.m1.1.1.1.1.1.1.3.cmml">T</mi></mrow><mo id="S3.Ex3.m1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex3.m1.2.2.2" xref="S3.Ex3.m1.2.2.2.cmml"><msub id="S3.Ex3.m1.2.2.2.2" xref="S3.Ex3.m1.2.2.2.2.cmml"><mo id="S3.Ex3.m1.2.2.2.2.2" xref="S3.Ex3.m1.2.2.2.2.2.cmml">∑</mo><mrow id="S3.Ex3.m1.2.2.2.2.3" xref="S3.Ex3.m1.2.2.2.2.3.cmml"><mi id="S3.Ex3.m1.2.2.2.2.3.2" xref="S3.Ex3.m1.2.2.2.2.3.2.cmml">j</mi><mo id="S3.Ex3.m1.2.2.2.2.3.1" xref="S3.Ex3.m1.2.2.2.2.3.1.cmml">∈</mo><mi id="S3.Ex3.m1.2.2.2.2.3.3" xref="S3.Ex3.m1.2.2.2.2.3.3.cmml">I</mi></mrow></msub><mrow id="S3.Ex3.m1.2.2.2.1" xref="S3.Ex3.m1.2.2.2.1.cmml"><mi id="S3.Ex3.m1.2.2.2.1.3" xref="S3.Ex3.m1.2.2.2.1.3.cmml">e</mi><mo id="S3.Ex3.m1.2.2.2.1.2" xref="S3.Ex3.m1.2.2.2.1.2.cmml">⁢</mo><mi id="S3.Ex3.m1.2.2.2.1.4" xref="S3.Ex3.m1.2.2.2.1.4.cmml">x</mi><mo id="S3.Ex3.m1.2.2.2.1.2a" xref="S3.Ex3.m1.2.2.2.1.2.cmml">⁢</mo><mi id="S3.Ex3.m1.2.2.2.1.5" xref="S3.Ex3.m1.2.2.2.1.5.cmml">p</mi><mo id="S3.Ex3.m1.2.2.2.1.2b" xref="S3.Ex3.m1.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.Ex3.m1.2.2.2.1.1.1" xref="S3.Ex3.m1.2.2.2.1.1.1.1.cmml"><mo id="S3.Ex3.m1.2.2.2.1.1.1.2" stretchy="false" xref="S3.Ex3.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.Ex3.m1.2.2.2.1.1.1.1" xref="S3.Ex3.m1.2.2.2.1.1.1.1.cmml"><msub id="S3.Ex3.m1.2.2.2.1.1.1.1.2" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2.cmml"><mi id="S3.Ex3.m1.2.2.2.1.1.1.1.2.2" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2.2.cmml">l</mi><mi id="S3.Ex3.m1.2.2.2.1.1.1.1.2.3" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2.3.cmml">j</mi></msub><mo id="S3.Ex3.m1.2.2.2.1.1.1.1.1" xref="S3.Ex3.m1.2.2.2.1.1.1.1.1.cmml">/</mo><mi id="S3.Ex3.m1.2.2.2.1.1.1.1.3" xref="S3.Ex3.m1.2.2.2.1.1.1.1.3.cmml">T</mi></mrow><mo id="S3.Ex3.m1.2.2.2.1.1.1.3" stretchy="false" xref="S3.Ex3.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.3b"><apply id="S3.Ex3.m1.3.3.cmml" xref="S3.Ex3.m1.3.3"><eq id="S3.Ex3.m1.3.3.2.cmml" xref="S3.Ex3.m1.3.3.2"></eq><apply id="S3.Ex3.m1.3.3.1.cmml" xref="S3.Ex3.m1.3.3.1"><times id="S3.Ex3.m1.3.3.1.2.cmml" xref="S3.Ex3.m1.3.3.1.2"></times><apply id="S3.Ex3.m1.3.3.1.3.cmml" xref="S3.Ex3.m1.3.3.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.3.3.1.3.1.cmml" xref="S3.Ex3.m1.3.3.1.3">subscript</csymbol><ci id="S3.Ex3.m1.3.3.1.3.2.cmml" xref="S3.Ex3.m1.3.3.1.3.2">𝑃</ci><ci id="S3.Ex3.m1.3.3.1.3.3.cmml" xref="S3.Ex3.m1.3.3.1.3.3">𝑇</ci></apply><apply id="S3.Ex3.m1.3.3.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1"><csymbol cd="latexml" id="S3.Ex3.m1.3.3.1.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex3.m1.3.3.1.1.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.2">𝑖</ci><apply id="S3.Ex3.m1.3.3.1.1.1.1.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.3.2">𝑖</ci><apply id="S3.Ex3.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3"><ci id="S3.Ex3.m1.3.3.1.1.1.1.3.3.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.1">:</ci><cn id="S3.Ex3.m1.3.3.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.2">1</cn><ci id="S3.Ex3.m1.3.3.1.1.1.1.3.3.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S3.Ex3.m1.2.2.cmml" xref="S3.Ex3.m1.2.2"><divide id="S3.Ex3.m1.2.2.3.cmml" xref="S3.Ex3.m1.2.2"></divide><apply id="S3.Ex3.m1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1"><times id="S3.Ex3.m1.1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.1.2"></times><ci id="S3.Ex3.m1.1.1.1.3.cmml" xref="S3.Ex3.m1.1.1.1.3">𝑒</ci><ci id="S3.Ex3.m1.1.1.1.4.cmml" xref="S3.Ex3.m1.1.1.1.4">𝑥</ci><ci id="S3.Ex3.m1.1.1.1.5.cmml" xref="S3.Ex3.m1.1.1.1.5">𝑝</ci><apply id="S3.Ex3.m1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1"><divide id="S3.Ex3.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1"></divide><apply id="S3.Ex3.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex3.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.2.2">𝑙</ci><ci id="S3.Ex3.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S3.Ex3.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.3">𝑇</ci></apply></apply><apply id="S3.Ex3.m1.2.2.2.cmml" xref="S3.Ex3.m1.2.2.2"><apply id="S3.Ex3.m1.2.2.2.2.cmml" xref="S3.Ex3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.2.2.2.2.1.cmml" xref="S3.Ex3.m1.2.2.2.2">subscript</csymbol><sum id="S3.Ex3.m1.2.2.2.2.2.cmml" xref="S3.Ex3.m1.2.2.2.2.2"></sum><apply id="S3.Ex3.m1.2.2.2.2.3.cmml" xref="S3.Ex3.m1.2.2.2.2.3"><in id="S3.Ex3.m1.2.2.2.2.3.1.cmml" xref="S3.Ex3.m1.2.2.2.2.3.1"></in><ci id="S3.Ex3.m1.2.2.2.2.3.2.cmml" xref="S3.Ex3.m1.2.2.2.2.3.2">𝑗</ci><ci id="S3.Ex3.m1.2.2.2.2.3.3.cmml" xref="S3.Ex3.m1.2.2.2.2.3.3">𝐼</ci></apply></apply><apply id="S3.Ex3.m1.2.2.2.1.cmml" xref="S3.Ex3.m1.2.2.2.1"><times id="S3.Ex3.m1.2.2.2.1.2.cmml" xref="S3.Ex3.m1.2.2.2.1.2"></times><ci id="S3.Ex3.m1.2.2.2.1.3.cmml" xref="S3.Ex3.m1.2.2.2.1.3">𝑒</ci><ci id="S3.Ex3.m1.2.2.2.1.4.cmml" xref="S3.Ex3.m1.2.2.2.1.4">𝑥</ci><ci id="S3.Ex3.m1.2.2.2.1.5.cmml" xref="S3.Ex3.m1.2.2.2.1.5">𝑝</ci><apply id="S3.Ex3.m1.2.2.2.1.1.1.1.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1"><divide id="S3.Ex3.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1.1.1"></divide><apply id="S3.Ex3.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex3.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2.2">𝑙</ci><ci id="S3.Ex3.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1.1.2.3">𝑗</ci></apply><ci id="S3.Ex3.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.Ex3.m1.2.2.2.1.1.1.1.3">𝑇</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.3c">P_{T}(i|i_{1:t})=\frac{exp(l_{i}/T)}{\sum_{j\in I}{exp(l_{j}/T)}}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex3.m1.3d">italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_i | italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT ) = divide start_ARG italic_e italic_x italic_p ( italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_T ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j ∈ italic_I end_POSTSUBSCRIPT italic_e italic_x italic_p ( italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT / italic_T ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p9">
<p class="ltx_p" id="S3.SS2.SSS3.p9.1">Temperature sampling may be combined with top-k sampling <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib15" title="">2018</a>)</cite> or Nucleus sampling <cite class="ltx_cite ltx_citemacro_citep">(Holtzman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib21" title="">2019</a>)</cite>. These approaches cut off long-tail items and redistribute the probability mass among selected top items. Following the generation strategy utilized by the original GPT-2 model <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib39" title="">2019</a>)</cite>, we applied top-k sampling in our experiments. According to this approach, the k most likely next items are filtered, all other items are discarded, and probabilities for those k items are re-normalized. We refer to the sampling strategy as ”top-k sampling” and to the baseline prediction strategy as ”Top-K prediction strategy” to prevent ambiguity.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4. </span>Proposed multi-sequence aggregation strategies.</h4>
<div class="ltx_para" id="S3.SS2.SSS4.p1">
<p class="ltx_p" id="S3.SS2.SSS4.p1.1">We propose to generate multiple diverse sequences with temperature sampling and aggregate generation results into one recommendation list. For this purpose, we introduce and explore two different aggregation strategies described below.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS4.p2">
<p class="ltx_p" id="S3.SS2.SSS4.p2.1">The proposed approach is closely connected to ensemble techniques, which are widely known to be effective in machine learning <cite class="ltx_cite ltx_citemacro_citep">(Dietterich, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib14" title="">2000</a>; Caruana et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib9" title="">2004</a>)</cite>. The classic ensemble approach consists of training several models and combining their predictions to make the model more robust and outperform single models’ quality. With the generative model, we can sample multiple sequences using a single model, which is significantly cheaper in terms of computation.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS4.p3">
<p class="ltx_p" id="S3.SS2.SSS4.p3.1">Both proposed strategies share common parts related to the results aggregation. The general pipeline and common parts are described below:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.5">Given a sequence of user interactions <math alttext="i_{1:t}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><msub id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml">i</mi><mrow id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml"><mn id="S3.I1.i1.p1.1.m1.1.1.3.2" xref="S3.I1.i1.p1.1.m1.1.1.3.2.cmml">1</mn><mo id="S3.I1.i1.p1.1.m1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S3.I1.i1.p1.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.3" xref="S3.I1.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">𝑖</ci><apply id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3"><ci id="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.1">:</ci><cn id="S3.I1.i1.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S3.I1.i1.p1.1.m1.1.1.3.2">1</cn><ci id="S3.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">i_{1:t}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">italic_i start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT</annotation></semantics></math> of length <math alttext="t" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.1"><semantics id="S3.I1.i1.p1.2.m2.1a"><mi id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.1d">italic_t</annotation></semantics></math> generate <math alttext="S" class="ltx_Math" display="inline" id="S3.I1.i1.p1.3.m3.1"><semantics id="S3.I1.i1.p1.3.m3.1a"><mi id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><ci id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.3.m3.1d">italic_S</annotation></semantics></math> sequence continuations of length <math alttext="K" class="ltx_Math" display="inline" id="S3.I1.i1.p1.4.m4.1"><semantics id="S3.I1.i1.p1.4.m4.1a"><mi id="S3.I1.i1.p1.4.m4.1.1" xref="S3.I1.i1.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.4.m4.1b"><ci id="S3.I1.i1.p1.4.m4.1.1.cmml" xref="S3.I1.i1.p1.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.4.m4.1d">italic_K</annotation></semantics></math> with the trained autoregressive <math alttext="model" class="ltx_Math" display="inline" id="S3.I1.i1.p1.5.m5.1"><semantics id="S3.I1.i1.p1.5.m5.1a"><mrow id="S3.I1.i1.p1.5.m5.1.1" xref="S3.I1.i1.p1.5.m5.1.1.cmml"><mi id="S3.I1.i1.p1.5.m5.1.1.2" xref="S3.I1.i1.p1.5.m5.1.1.2.cmml">m</mi><mo id="S3.I1.i1.p1.5.m5.1.1.1" xref="S3.I1.i1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.5.m5.1.1.3" xref="S3.I1.i1.p1.5.m5.1.1.3.cmml">o</mi><mo id="S3.I1.i1.p1.5.m5.1.1.1a" xref="S3.I1.i1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.5.m5.1.1.4" xref="S3.I1.i1.p1.5.m5.1.1.4.cmml">d</mi><mo id="S3.I1.i1.p1.5.m5.1.1.1b" xref="S3.I1.i1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.5.m5.1.1.5" xref="S3.I1.i1.p1.5.m5.1.1.5.cmml">e</mi><mo id="S3.I1.i1.p1.5.m5.1.1.1c" xref="S3.I1.i1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.5.m5.1.1.6" xref="S3.I1.i1.p1.5.m5.1.1.6.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.5.m5.1b"><apply id="S3.I1.i1.p1.5.m5.1.1.cmml" xref="S3.I1.i1.p1.5.m5.1.1"><times id="S3.I1.i1.p1.5.m5.1.1.1.cmml" xref="S3.I1.i1.p1.5.m5.1.1.1"></times><ci id="S3.I1.i1.p1.5.m5.1.1.2.cmml" xref="S3.I1.i1.p1.5.m5.1.1.2">𝑚</ci><ci id="S3.I1.i1.p1.5.m5.1.1.3.cmml" xref="S3.I1.i1.p1.5.m5.1.1.3">𝑜</ci><ci id="S3.I1.i1.p1.5.m5.1.1.4.cmml" xref="S3.I1.i1.p1.5.m5.1.1.4">𝑑</ci><ci id="S3.I1.i1.p1.5.m5.1.1.5.cmml" xref="S3.I1.i1.p1.5.m5.1.1.5">𝑒</ci><ci id="S3.I1.i1.p1.5.m5.1.1.6.cmml" xref="S3.I1.i1.p1.5.m5.1.1.6">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.5.m5.1c">model</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.5.m5.1d">italic_m italic_o italic_d italic_e italic_l</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.3"><span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.3.1">Single-sequence generation and aggregation:</span> For each sequence continuation, calculate scores for all items, which are referred to as <math alttext="\mathbf{r^{s}}\in\mathbb{R}^{I}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><msup id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.2.2" xref="S3.I1.i2.p1.1.m1.1.1.2.2.cmml">𝐫</mi><mi id="S3.I1.i2.p1.1.m1.1.1.2.3" xref="S3.I1.i2.p1.1.m1.1.1.2.3.cmml">𝐬</mi></msup><mo id="S3.I1.i2.p1.1.m1.1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.3.2" xref="S3.I1.i2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S3.I1.i2.p1.1.m1.1.1.3.3" xref="S3.I1.i2.p1.1.m1.1.1.3.3.cmml">I</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><in id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.1"></in><apply id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2.2">𝐫</ci><ci id="S3.I1.i2.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2.3">𝐬</ci></apply><apply id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.2">ℝ</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">\mathbf{r^{s}}\in\mathbb{R}^{I}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT</annotation></semantics></math> in Algorithms <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#algorithm1" title="In Reciprocal Rank Aggregation strategy (RRA) ‣ 3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#algorithm2" title="In Relevance Aggregation strategy (RA) ‣ 3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a>. <math alttext="I" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">italic_I</annotation></semantics></math> is a number of items in the catalog and <math alttext="s" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.1"><semantics id="S3.I1.i2.p1.3.m3.1a"><mi id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><ci id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.1d">italic_s</annotation></semantics></math> is a considered sequence continuation number. The proposed approaches differ in this step, therefore, it will be additionally explained in the following subsections.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.3"><span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.3.1">Multi-sequence aggregation:</span>
Aggregate scores are obtained from each sequence continuation, so the final relevance is equal to the sum of previously assigned scores <math alttext="\mathbf{r}=\sum_{s=1}^{S}\mathbf{r^{s}}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mrow id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.2" xref="S3.I1.i3.p1.1.m1.1.1.2.cmml">𝐫</mi><mo id="S3.I1.i3.p1.1.m1.1.1.1" rspace="0.111em" xref="S3.I1.i3.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.I1.i3.p1.1.m1.1.1.3" xref="S3.I1.i3.p1.1.m1.1.1.3.cmml"><msubsup id="S3.I1.i3.p1.1.m1.1.1.3.1" xref="S3.I1.i3.p1.1.m1.1.1.3.1.cmml"><mo id="S3.I1.i3.p1.1.m1.1.1.3.1.2.2" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.2" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.2.cmml">s</mi><mo id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.1" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.3" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.I1.i3.p1.1.m1.1.1.3.1.3" xref="S3.I1.i3.p1.1.m1.1.1.3.1.3.cmml">S</mi></msubsup><msup id="S3.I1.i3.p1.1.m1.1.1.3.2" xref="S3.I1.i3.p1.1.m1.1.1.3.2.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.3.2.2" xref="S3.I1.i3.p1.1.m1.1.1.3.2.2.cmml">𝐫</mi><mi id="S3.I1.i3.p1.1.m1.1.1.3.2.3" xref="S3.I1.i3.p1.1.m1.1.1.3.2.3.cmml">𝐬</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1"><eq id="S3.I1.i3.p1.1.m1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1"></eq><ci id="S3.I1.i3.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2">𝐫</ci><apply id="S3.I1.i3.p1.1.m1.1.1.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3"><apply id="S3.I1.i3.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.3.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1">superscript</csymbol><apply id="S3.I1.i3.p1.1.m1.1.1.3.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.3.1.2.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1">subscript</csymbol><sum id="S3.I1.i3.p1.1.m1.1.1.3.1.2.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.2"></sum><apply id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3"><eq id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.1"></eq><ci id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.2">𝑠</ci><cn id="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.3.cmml" type="integer" xref="S3.I1.i3.p1.1.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.I1.i3.p1.1.m1.1.1.3.1.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.1.3">𝑆</ci></apply><apply id="S3.I1.i3.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.3.2.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.2">superscript</csymbol><ci id="S3.I1.i3.p1.1.m1.1.1.3.2.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.2.2">𝐫</ci><ci id="S3.I1.i3.p1.1.m1.1.1.3.2.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3.2.3">𝐬</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">\mathbf{r}=\sum_{s=1}^{S}\mathbf{r^{s}}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">bold_r = ∑ start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT</annotation></semantics></math>. The <math alttext="K" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m2.1"><semantics id="S3.I1.i3.p1.2.m2.1a"><mi id="S3.I1.i3.p1.2.m2.1.1" xref="S3.I1.i3.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b"><ci id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m2.1d">italic_K</annotation></semantics></math> most relevant items from <math alttext="\mathbf{r}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.3.m3.1"><semantics id="S3.I1.i3.p1.3.m3.1a"><mi id="S3.I1.i3.p1.3.m3.1.1" xref="S3.I1.i3.p1.3.m3.1.1.cmml">𝐫</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.3.m3.1b"><ci id="S3.I1.i3.p1.3.m3.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1">𝐫</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.3.m3.1c">\mathbf{r}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.3.m3.1d">bold_r</annotation></semantics></math> constitute the user’s recommendations.</p>
</div>
</li>
</ol>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS4.Px1">
<h5 class="ltx_title ltx_title_paragraph">Reciprocal Rank Aggregation strategy (RRA)</h5>
<div class="ltx_para" id="S3.SS2.SSS4.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS4.Px1.p1.1">The first proposed aggregation strategy is <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS4.Px1.p1.1.1">Reciprocal Rank Aggregation</span>, adapted from the popular Reciprocal Rank method from Information Retrieval <cite class="ltx_cite ltx_citemacro_citep">(Wegmann and Henrich, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib49" title="">2018</a>; Macdonald and Ounis, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib27" title="">2006</a>; Robertson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib43" title="">1995</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS4.Px1.p2">
<p class="ltx_p" id="S3.SS2.SSS4.Px1.p2.1">RRA strategy is illustrated with pseudocode in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#algorithm1" title="In Reciprocal Rank Aggregation strategy (RRA) ‣ 3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>. Single-sequence generation and aggregation of scores with RRA strategy consists of the following steps:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Generate sequence continuations of length <math alttext="K" class="ltx_Math" display="inline" id="S3.I2.i1.p1.1.m1.1"><semantics id="S3.I2.i1.p1.1.m1.1a"><mi id="S3.I2.i1.p1.1.m1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><ci id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i1.p1.1.m1.1d">italic_K</annotation></semantics></math> with temperature sampling. Repetition of already generated items at subsequent generation steps is prohibited.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Each item in the generated sequence is assigned relevance equal to an item’s reciprocal position (i.e. rank), which gives a relevance sequence of (1, 1/2, 1/3, …), the relevance of the remaining items is 0.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS2.SSS4.Px1.p2.2">Thus, we promote items from the beginning of generated sequences to remain in recommendations and simultaneously allow items that frequently appear in continuation to be present in final recommendations.</p>
</div>
<figure class="ltx_float ltx_algorithm" id="algorithm1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm1.13">
<div class="ltx_listingline" id="algorithm1.13.14">
</div>
<div class="ltx_listingline" id="algorithm1.1.1">
<math alttext="\mathbf{r}\leftarrow[0]\times I" class="ltx_Math" display="inline" id="algorithm1.1.1.m1.1"><semantics id="algorithm1.1.1.m1.1a"><mrow id="algorithm1.1.1.m1.1.2" xref="algorithm1.1.1.m1.1.2.cmml"><mi id="algorithm1.1.1.m1.1.2.2" xref="algorithm1.1.1.m1.1.2.2.cmml">𝐫</mi><mo id="algorithm1.1.1.m1.1.2.1" stretchy="false" xref="algorithm1.1.1.m1.1.2.1.cmml">←</mo><mrow id="algorithm1.1.1.m1.1.2.3" xref="algorithm1.1.1.m1.1.2.3.cmml"><mrow id="algorithm1.1.1.m1.1.2.3.2.2" xref="algorithm1.1.1.m1.1.2.3.2.1.cmml"><mo id="algorithm1.1.1.m1.1.2.3.2.2.1" stretchy="false" xref="algorithm1.1.1.m1.1.2.3.2.1.1.cmml">[</mo><mn id="algorithm1.1.1.m1.1.1" xref="algorithm1.1.1.m1.1.1.cmml">0</mn><mo id="algorithm1.1.1.m1.1.2.3.2.2.2" rspace="0.055em" stretchy="false" xref="algorithm1.1.1.m1.1.2.3.2.1.1.cmml">]</mo></mrow><mo id="algorithm1.1.1.m1.1.2.3.1" rspace="0.222em" xref="algorithm1.1.1.m1.1.2.3.1.cmml">×</mo><mi id="algorithm1.1.1.m1.1.2.3.3" xref="algorithm1.1.1.m1.1.2.3.3.cmml">I</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.1b"><apply id="algorithm1.1.1.m1.1.2.cmml" xref="algorithm1.1.1.m1.1.2"><ci id="algorithm1.1.1.m1.1.2.1.cmml" xref="algorithm1.1.1.m1.1.2.1">←</ci><ci id="algorithm1.1.1.m1.1.2.2.cmml" xref="algorithm1.1.1.m1.1.2.2">𝐫</ci><apply id="algorithm1.1.1.m1.1.2.3.cmml" xref="algorithm1.1.1.m1.1.2.3"><times id="algorithm1.1.1.m1.1.2.3.1.cmml" xref="algorithm1.1.1.m1.1.2.3.1"></times><apply id="algorithm1.1.1.m1.1.2.3.2.1.cmml" xref="algorithm1.1.1.m1.1.2.3.2.2"><csymbol cd="latexml" id="algorithm1.1.1.m1.1.2.3.2.1.1.cmml" xref="algorithm1.1.1.m1.1.2.3.2.2.1">delimited-[]</csymbol><cn id="algorithm1.1.1.m1.1.1.cmml" type="integer" xref="algorithm1.1.1.m1.1.1">0</cn></apply><ci id="algorithm1.1.1.m1.1.2.3.3.cmml" xref="algorithm1.1.1.m1.1.2.3.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.1c">\mathbf{r}\leftarrow[0]\times I</annotation><annotation encoding="application/x-llamapun" id="algorithm1.1.1.m1.1d">bold_r ← [ 0 ] × italic_I</annotation></semantics></math>;
</div>
<div class="ltx_listingline" id="algorithm1.13.15">
</div>
<div class="ltx_listingline" id="algorithm1.3.3">
<span class="ltx_text ltx_font_bold" id="algorithm1.3.3.3">for</span> <em class="ltx_emph ltx_font_italic" id="algorithm1.3.3.2"><math alttext="s\leftarrow 1" class="ltx_Math" display="inline" id="algorithm1.2.2.1.m1.1"><semantics id="algorithm1.2.2.1.m1.1a"><mrow id="algorithm1.2.2.1.m1.1.1" xref="algorithm1.2.2.1.m1.1.1.cmml"><mi id="algorithm1.2.2.1.m1.1.1.2" xref="algorithm1.2.2.1.m1.1.1.2.cmml">s</mi><mo id="algorithm1.2.2.1.m1.1.1.1" stretchy="false" xref="algorithm1.2.2.1.m1.1.1.1.cmml">←</mo><mn id="algorithm1.2.2.1.m1.1.1.3" xref="algorithm1.2.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.1.m1.1b"><apply id="algorithm1.2.2.1.m1.1.1.cmml" xref="algorithm1.2.2.1.m1.1.1"><ci id="algorithm1.2.2.1.m1.1.1.1.cmml" xref="algorithm1.2.2.1.m1.1.1.1">←</ci><ci id="algorithm1.2.2.1.m1.1.1.2.cmml" xref="algorithm1.2.2.1.m1.1.1.2">𝑠</ci><cn id="algorithm1.2.2.1.m1.1.1.3.cmml" type="integer" xref="algorithm1.2.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.1.m1.1c">s\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algorithm1.2.2.1.m1.1d">italic_s ← 1</annotation></semantics></math> <span class="ltx_text ltx_font_bold ltx_font_upright" id="algorithm1.3.3.2.1">to</span> <math alttext="S" class="ltx_Math" display="inline" id="algorithm1.3.3.2.m2.1"><semantics id="algorithm1.3.3.2.m2.1a"><mi id="algorithm1.3.3.2.m2.1.1" xref="algorithm1.3.3.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.2.m2.1b"><ci id="algorithm1.3.3.2.m2.1.1.cmml" xref="algorithm1.3.3.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.2.m2.1c">S</annotation><annotation encoding="application/x-llamapun" id="algorithm1.3.3.2.m2.1d">italic_S</annotation></semantics></math></em> <span class="ltx_text ltx_font_bold" id="algorithm1.3.3.4">do</span> <span class="ltx_text ltx_font_typewriter" id="algorithm1.3.3.5">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm1.3.3.6">computes in parallel</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.16">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="algorithm1.4.4">
<span class="ltx_text" id="algorithm1.4.4.1" style="font-size:90%;">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span><math alttext="\mathbf{r^{s}}\leftarrow[0]\times I" class="ltx_Math" display="inline" id="algorithm1.4.4.m1.1"><semantics id="algorithm1.4.4.m1.1a"><mrow id="algorithm1.4.4.m1.1.2" xref="algorithm1.4.4.m1.1.2.cmml"><msup id="algorithm1.4.4.m1.1.2.2" xref="algorithm1.4.4.m1.1.2.2.cmml"><mi id="algorithm1.4.4.m1.1.2.2.2" mathsize="90%" xref="algorithm1.4.4.m1.1.2.2.2.cmml">𝐫</mi><mi id="algorithm1.4.4.m1.1.2.2.3" mathsize="90%" xref="algorithm1.4.4.m1.1.2.2.3.cmml">𝐬</mi></msup><mo id="algorithm1.4.4.m1.1.2.1" mathsize="90%" stretchy="false" xref="algorithm1.4.4.m1.1.2.1.cmml">←</mo><mrow id="algorithm1.4.4.m1.1.2.3" xref="algorithm1.4.4.m1.1.2.3.cmml"><mrow id="algorithm1.4.4.m1.1.2.3.2.2" xref="algorithm1.4.4.m1.1.2.3.2.1.cmml"><mo id="algorithm1.4.4.m1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="algorithm1.4.4.m1.1.2.3.2.1.1.cmml">[</mo><mn id="algorithm1.4.4.m1.1.1" mathsize="90%" xref="algorithm1.4.4.m1.1.1.cmml">0</mn><mo id="algorithm1.4.4.m1.1.2.3.2.2.2" maxsize="90%" minsize="90%" rspace="0.055em" xref="algorithm1.4.4.m1.1.2.3.2.1.1.cmml">]</mo></mrow><mo id="algorithm1.4.4.m1.1.2.3.1" mathsize="90%" rspace="0.222em" xref="algorithm1.4.4.m1.1.2.3.1.cmml">×</mo><mi id="algorithm1.4.4.m1.1.2.3.3" mathsize="90%" xref="algorithm1.4.4.m1.1.2.3.3.cmml">I</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.m1.1b"><apply id="algorithm1.4.4.m1.1.2.cmml" xref="algorithm1.4.4.m1.1.2"><ci id="algorithm1.4.4.m1.1.2.1.cmml" xref="algorithm1.4.4.m1.1.2.1">←</ci><apply id="algorithm1.4.4.m1.1.2.2.cmml" xref="algorithm1.4.4.m1.1.2.2"><csymbol cd="ambiguous" id="algorithm1.4.4.m1.1.2.2.1.cmml" xref="algorithm1.4.4.m1.1.2.2">superscript</csymbol><ci id="algorithm1.4.4.m1.1.2.2.2.cmml" xref="algorithm1.4.4.m1.1.2.2.2">𝐫</ci><ci id="algorithm1.4.4.m1.1.2.2.3.cmml" xref="algorithm1.4.4.m1.1.2.2.3">𝐬</ci></apply><apply id="algorithm1.4.4.m1.1.2.3.cmml" xref="algorithm1.4.4.m1.1.2.3"><times id="algorithm1.4.4.m1.1.2.3.1.cmml" xref="algorithm1.4.4.m1.1.2.3.1"></times><apply id="algorithm1.4.4.m1.1.2.3.2.1.cmml" xref="algorithm1.4.4.m1.1.2.3.2.2"><csymbol cd="latexml" id="algorithm1.4.4.m1.1.2.3.2.1.1.cmml" xref="algorithm1.4.4.m1.1.2.3.2.2.1">delimited-[]</csymbol><cn id="algorithm1.4.4.m1.1.1.cmml" type="integer" xref="algorithm1.4.4.m1.1.1">0</cn></apply><ci id="algorithm1.4.4.m1.1.2.3.3.cmml" xref="algorithm1.4.4.m1.1.2.3.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.m1.1c">\mathbf{r^{s}}\leftarrow[0]\times I</annotation><annotation encoding="application/x-llamapun" id="algorithm1.4.4.m1.1d">bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT ← [ 0 ] × italic_I</annotation></semantics></math><span class="ltx_text" id="algorithm1.4.4.2" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.17">
<span class="ltx_text" id="algorithm1.13.17.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.13.17.2" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.13.17.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm1.6.6">
<span class="ltx_text" id="algorithm1.6.6.3" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.6.6.4" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm1.6.6.5" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm1.6.6.6" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm1.6.6.2" style="font-size:90%;"><math alttext="k\leftarrow 1" class="ltx_Math" display="inline" id="algorithm1.5.5.1.m1.1"><semantics id="algorithm1.5.5.1.m1.1a"><mrow id="algorithm1.5.5.1.m1.1.1" xref="algorithm1.5.5.1.m1.1.1.cmml"><mi id="algorithm1.5.5.1.m1.1.1.2" xref="algorithm1.5.5.1.m1.1.1.2.cmml">k</mi><mo id="algorithm1.5.5.1.m1.1.1.1" stretchy="false" xref="algorithm1.5.5.1.m1.1.1.1.cmml">←</mo><mn id="algorithm1.5.5.1.m1.1.1.3" xref="algorithm1.5.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.1.m1.1b"><apply id="algorithm1.5.5.1.m1.1.1.cmml" xref="algorithm1.5.5.1.m1.1.1"><ci id="algorithm1.5.5.1.m1.1.1.1.cmml" xref="algorithm1.5.5.1.m1.1.1.1">←</ci><ci id="algorithm1.5.5.1.m1.1.1.2.cmml" xref="algorithm1.5.5.1.m1.1.1.2">𝑘</ci><cn id="algorithm1.5.5.1.m1.1.1.3.cmml" type="integer" xref="algorithm1.5.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.1.m1.1c">k\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algorithm1.5.5.1.m1.1d">italic_k ← 1</annotation></semantics></math> <span class="ltx_text ltx_font_bold ltx_font_upright" id="algorithm1.6.6.2.1">to</span> <math alttext="K" class="ltx_Math" display="inline" id="algorithm1.6.6.2.m2.1"><semantics id="algorithm1.6.6.2.m2.1a"><mi id="algorithm1.6.6.2.m2.1.1" xref="algorithm1.6.6.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.2.m2.1b"><ci id="algorithm1.6.6.2.m2.1.1.cmml" xref="algorithm1.6.6.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="algorithm1.6.6.2.m2.1d">italic_K</annotation></semantics></math></em><span class="ltx_text" id="algorithm1.6.6.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm1.6.6.8" style="font-size:90%;">do</span>
</div>
<div class="ltx_listingline" id="algorithm1.7.7">
<span class="ltx_text" id="algorithm1.7.7.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.7.7.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.7.7.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.7.7.4" style="font-size:90%;">
</span><math alttext="i_{t+k}\leftarrow model.generate(i_{1:t+k-1})" class="ltx_Math" display="inline" id="algorithm1.7.7.m1.2"><semantics id="algorithm1.7.7.m1.2a"><mrow id="algorithm1.7.7.m1.2.2.2" xref="algorithm1.7.7.m1.2.2.3.cmml"><mrow id="algorithm1.7.7.m1.1.1.1.1" xref="algorithm1.7.7.m1.1.1.1.1.cmml"><msub id="algorithm1.7.7.m1.1.1.1.1.2" xref="algorithm1.7.7.m1.1.1.1.1.2.cmml"><mi id="algorithm1.7.7.m1.1.1.1.1.2.2" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.2.2.cmml">i</mi><mrow id="algorithm1.7.7.m1.1.1.1.1.2.3" xref="algorithm1.7.7.m1.1.1.1.1.2.3.cmml"><mi id="algorithm1.7.7.m1.1.1.1.1.2.3.2" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="algorithm1.7.7.m1.1.1.1.1.2.3.1" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.2.3.1.cmml">+</mo><mi id="algorithm1.7.7.m1.1.1.1.1.2.3.3" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.2.3.3.cmml">k</mi></mrow></msub><mo id="algorithm1.7.7.m1.1.1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.7.7.m1.1.1.1.1.1.cmml">←</mo><mrow id="algorithm1.7.7.m1.1.1.1.1.3" xref="algorithm1.7.7.m1.1.1.1.1.3.cmml"><mi id="algorithm1.7.7.m1.1.1.1.1.3.2" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.3.2.cmml">m</mi><mo id="algorithm1.7.7.m1.1.1.1.1.3.1" xref="algorithm1.7.7.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm1.7.7.m1.1.1.1.1.3.3" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.3.3.cmml">o</mi><mo id="algorithm1.7.7.m1.1.1.1.1.3.1a" xref="algorithm1.7.7.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm1.7.7.m1.1.1.1.1.3.4" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.3.4.cmml">d</mi><mo id="algorithm1.7.7.m1.1.1.1.1.3.1b" xref="algorithm1.7.7.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm1.7.7.m1.1.1.1.1.3.5" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.3.5.cmml">e</mi><mo id="algorithm1.7.7.m1.1.1.1.1.3.1c" xref="algorithm1.7.7.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm1.7.7.m1.1.1.1.1.3.6" mathsize="90%" xref="algorithm1.7.7.m1.1.1.1.1.3.6.cmml">l</mi></mrow></mrow><mo id="algorithm1.7.7.m1.2.2.2.3" lspace="0em" mathsize="90%" rspace="0.167em" xref="algorithm1.7.7.m1.2.2.3a.cmml">.</mo><mrow id="algorithm1.7.7.m1.2.2.2.2" xref="algorithm1.7.7.m1.2.2.2.2.cmml"><mi id="algorithm1.7.7.m1.2.2.2.2.3" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.3.cmml">g</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.4" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.4.cmml">e</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2a" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.5" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.5.cmml">n</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2b" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.6" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.6.cmml">e</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2c" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.7" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.7.cmml">r</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2d" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.8" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.8.cmml">a</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2e" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.9" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.9.cmml">t</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2f" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm1.7.7.m1.2.2.2.2.10" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.10.cmml">e</mi><mo id="algorithm1.7.7.m1.2.2.2.2.2g" xref="algorithm1.7.7.m1.2.2.2.2.2.cmml">⁢</mo><mrow id="algorithm1.7.7.m1.2.2.2.2.1.1" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.cmml"><mo id="algorithm1.7.7.m1.2.2.2.2.1.1.2" maxsize="90%" minsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.cmml">(</mo><msub id="algorithm1.7.7.m1.2.2.2.2.1.1.1" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.cmml"><mi id="algorithm1.7.7.m1.2.2.2.2.1.1.1.2" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.2.cmml">i</mi><mrow id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.cmml"><mn id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.2" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.2.cmml">1</mn><mo id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.1" lspace="0.278em" mathsize="90%" rspace="0.278em" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.1.cmml">:</mo><mrow id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.cmml"><mrow id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.cmml"><mi id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.2" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.2.cmml">t</mi><mo id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.1" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.1.cmml">+</mo><mi id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.3" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.3.cmml">k</mi></mrow><mo id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.1" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.1.cmml">−</mo><mn id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.3" mathsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.3.cmml">1</mn></mrow></mrow></msub><mo id="algorithm1.7.7.m1.2.2.2.2.1.1.3" maxsize="90%" minsize="90%" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m1.2b"><apply id="algorithm1.7.7.m1.2.2.3.cmml" xref="algorithm1.7.7.m1.2.2.2"><csymbol cd="ambiguous" id="algorithm1.7.7.m1.2.2.3a.cmml" xref="algorithm1.7.7.m1.2.2.2.3">formulae-sequence</csymbol><apply id="algorithm1.7.7.m1.1.1.1.1.cmml" xref="algorithm1.7.7.m1.1.1.1.1"><ci id="algorithm1.7.7.m1.1.1.1.1.1.cmml" xref="algorithm1.7.7.m1.1.1.1.1.1">←</ci><apply id="algorithm1.7.7.m1.1.1.1.1.2.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.7.7.m1.1.1.1.1.2.1.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2">subscript</csymbol><ci id="algorithm1.7.7.m1.1.1.1.1.2.2.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2.2">𝑖</ci><apply id="algorithm1.7.7.m1.1.1.1.1.2.3.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2.3"><plus id="algorithm1.7.7.m1.1.1.1.1.2.3.1.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2.3.1"></plus><ci id="algorithm1.7.7.m1.1.1.1.1.2.3.2.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2.3.2">𝑡</ci><ci id="algorithm1.7.7.m1.1.1.1.1.2.3.3.cmml" xref="algorithm1.7.7.m1.1.1.1.1.2.3.3">𝑘</ci></apply></apply><apply id="algorithm1.7.7.m1.1.1.1.1.3.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3"><times id="algorithm1.7.7.m1.1.1.1.1.3.1.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3.1"></times><ci id="algorithm1.7.7.m1.1.1.1.1.3.2.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3.2">𝑚</ci><ci id="algorithm1.7.7.m1.1.1.1.1.3.3.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3.3">𝑜</ci><ci id="algorithm1.7.7.m1.1.1.1.1.3.4.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3.4">𝑑</ci><ci id="algorithm1.7.7.m1.1.1.1.1.3.5.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3.5">𝑒</ci><ci id="algorithm1.7.7.m1.1.1.1.1.3.6.cmml" xref="algorithm1.7.7.m1.1.1.1.1.3.6">𝑙</ci></apply></apply><apply id="algorithm1.7.7.m1.2.2.2.2.cmml" xref="algorithm1.7.7.m1.2.2.2.2"><times id="algorithm1.7.7.m1.2.2.2.2.2.cmml" xref="algorithm1.7.7.m1.2.2.2.2.2"></times><ci id="algorithm1.7.7.m1.2.2.2.2.3.cmml" xref="algorithm1.7.7.m1.2.2.2.2.3">𝑔</ci><ci id="algorithm1.7.7.m1.2.2.2.2.4.cmml" xref="algorithm1.7.7.m1.2.2.2.2.4">𝑒</ci><ci id="algorithm1.7.7.m1.2.2.2.2.5.cmml" xref="algorithm1.7.7.m1.2.2.2.2.5">𝑛</ci><ci id="algorithm1.7.7.m1.2.2.2.2.6.cmml" xref="algorithm1.7.7.m1.2.2.2.2.6">𝑒</ci><ci id="algorithm1.7.7.m1.2.2.2.2.7.cmml" xref="algorithm1.7.7.m1.2.2.2.2.7">𝑟</ci><ci id="algorithm1.7.7.m1.2.2.2.2.8.cmml" xref="algorithm1.7.7.m1.2.2.2.2.8">𝑎</ci><ci id="algorithm1.7.7.m1.2.2.2.2.9.cmml" xref="algorithm1.7.7.m1.2.2.2.2.9">𝑡</ci><ci id="algorithm1.7.7.m1.2.2.2.2.10.cmml" xref="algorithm1.7.7.m1.2.2.2.2.10">𝑒</ci><apply id="algorithm1.7.7.m1.2.2.2.2.1.1.1.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.7.7.m1.2.2.2.2.1.1.1.1.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1">subscript</csymbol><ci id="algorithm1.7.7.m1.2.2.2.2.1.1.1.2.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.2">𝑖</ci><apply id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3"><ci id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.1.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.1">:</ci><cn id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.2.cmml" type="integer" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.2">1</cn><apply id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3"><minus id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.1.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.1"></minus><apply id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2"><plus id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.1.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.1"></plus><ci id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.2.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.2">𝑡</ci><ci id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.3.cmml" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.2.3">𝑘</ci></apply><cn id="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.3.cmml" type="integer" xref="algorithm1.7.7.m1.2.2.2.2.1.1.1.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m1.2c">i_{t+k}\leftarrow model.generate(i_{1:t+k-1})</annotation><annotation encoding="application/x-llamapun" id="algorithm1.7.7.m1.2d">italic_i start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT ← italic_m italic_o italic_d italic_e italic_l . italic_g italic_e italic_n italic_e italic_r italic_a italic_t italic_e ( italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k - 1 end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="algorithm1.7.7.5" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm1.10.10">
<span class="ltx_text" id="algorithm1.10.10.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.10.10.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.10.10.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.10.10.4" style="font-size:90%;">
</span><math alttext="i_{1:t+k}\leftarrow i_{1:t+k-1}" class="ltx_Math" display="inline" id="algorithm1.8.8.m1.1"><semantics id="algorithm1.8.8.m1.1a"><mrow id="algorithm1.8.8.m1.1.1" xref="algorithm1.8.8.m1.1.1.cmml"><msub id="algorithm1.8.8.m1.1.1.2" xref="algorithm1.8.8.m1.1.1.2.cmml"><mi id="algorithm1.8.8.m1.1.1.2.2" mathsize="90%" xref="algorithm1.8.8.m1.1.1.2.2.cmml">i</mi><mrow id="algorithm1.8.8.m1.1.1.2.3" xref="algorithm1.8.8.m1.1.1.2.3.cmml"><mn id="algorithm1.8.8.m1.1.1.2.3.2" mathsize="90%" xref="algorithm1.8.8.m1.1.1.2.3.2.cmml">1</mn><mo id="algorithm1.8.8.m1.1.1.2.3.1" lspace="0.278em" mathsize="90%" rspace="0.278em" xref="algorithm1.8.8.m1.1.1.2.3.1.cmml">:</mo><mrow id="algorithm1.8.8.m1.1.1.2.3.3" xref="algorithm1.8.8.m1.1.1.2.3.3.cmml"><mi id="algorithm1.8.8.m1.1.1.2.3.3.2" mathsize="90%" xref="algorithm1.8.8.m1.1.1.2.3.3.2.cmml">t</mi><mo id="algorithm1.8.8.m1.1.1.2.3.3.1" mathsize="90%" xref="algorithm1.8.8.m1.1.1.2.3.3.1.cmml">+</mo><mi id="algorithm1.8.8.m1.1.1.2.3.3.3" mathsize="90%" xref="algorithm1.8.8.m1.1.1.2.3.3.3.cmml">k</mi></mrow></mrow></msub><mo id="algorithm1.8.8.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.8.8.m1.1.1.1.cmml">←</mo><msub id="algorithm1.8.8.m1.1.1.3" xref="algorithm1.8.8.m1.1.1.3.cmml"><mi id="algorithm1.8.8.m1.1.1.3.2" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.2.cmml">i</mi><mrow id="algorithm1.8.8.m1.1.1.3.3" xref="algorithm1.8.8.m1.1.1.3.3.cmml"><mn id="algorithm1.8.8.m1.1.1.3.3.2" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.3.2.cmml">1</mn><mo id="algorithm1.8.8.m1.1.1.3.3.1" lspace="0.278em" mathsize="90%" rspace="0.278em" xref="algorithm1.8.8.m1.1.1.3.3.1.cmml">:</mo><mrow id="algorithm1.8.8.m1.1.1.3.3.3" xref="algorithm1.8.8.m1.1.1.3.3.3.cmml"><mrow id="algorithm1.8.8.m1.1.1.3.3.3.2" xref="algorithm1.8.8.m1.1.1.3.3.3.2.cmml"><mi id="algorithm1.8.8.m1.1.1.3.3.3.2.2" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.3.3.2.2.cmml">t</mi><mo id="algorithm1.8.8.m1.1.1.3.3.3.2.1" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.3.3.2.1.cmml">+</mo><mi id="algorithm1.8.8.m1.1.1.3.3.3.2.3" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.3.3.2.3.cmml">k</mi></mrow><mo id="algorithm1.8.8.m1.1.1.3.3.3.1" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.3.3.1.cmml">−</mo><mn id="algorithm1.8.8.m1.1.1.3.3.3.3" mathsize="90%" xref="algorithm1.8.8.m1.1.1.3.3.3.3.cmml">1</mn></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m1.1b"><apply id="algorithm1.8.8.m1.1.1.cmml" xref="algorithm1.8.8.m1.1.1"><ci id="algorithm1.8.8.m1.1.1.1.cmml" xref="algorithm1.8.8.m1.1.1.1">←</ci><apply id="algorithm1.8.8.m1.1.1.2.cmml" xref="algorithm1.8.8.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.8.8.m1.1.1.2.1.cmml" xref="algorithm1.8.8.m1.1.1.2">subscript</csymbol><ci id="algorithm1.8.8.m1.1.1.2.2.cmml" xref="algorithm1.8.8.m1.1.1.2.2">𝑖</ci><apply id="algorithm1.8.8.m1.1.1.2.3.cmml" xref="algorithm1.8.8.m1.1.1.2.3"><ci id="algorithm1.8.8.m1.1.1.2.3.1.cmml" xref="algorithm1.8.8.m1.1.1.2.3.1">:</ci><cn id="algorithm1.8.8.m1.1.1.2.3.2.cmml" type="integer" xref="algorithm1.8.8.m1.1.1.2.3.2">1</cn><apply id="algorithm1.8.8.m1.1.1.2.3.3.cmml" xref="algorithm1.8.8.m1.1.1.2.3.3"><plus id="algorithm1.8.8.m1.1.1.2.3.3.1.cmml" xref="algorithm1.8.8.m1.1.1.2.3.3.1"></plus><ci id="algorithm1.8.8.m1.1.1.2.3.3.2.cmml" xref="algorithm1.8.8.m1.1.1.2.3.3.2">𝑡</ci><ci id="algorithm1.8.8.m1.1.1.2.3.3.3.cmml" xref="algorithm1.8.8.m1.1.1.2.3.3.3">𝑘</ci></apply></apply></apply><apply id="algorithm1.8.8.m1.1.1.3.cmml" xref="algorithm1.8.8.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.8.8.m1.1.1.3.1.cmml" xref="algorithm1.8.8.m1.1.1.3">subscript</csymbol><ci id="algorithm1.8.8.m1.1.1.3.2.cmml" xref="algorithm1.8.8.m1.1.1.3.2">𝑖</ci><apply id="algorithm1.8.8.m1.1.1.3.3.cmml" xref="algorithm1.8.8.m1.1.1.3.3"><ci id="algorithm1.8.8.m1.1.1.3.3.1.cmml" xref="algorithm1.8.8.m1.1.1.3.3.1">:</ci><cn id="algorithm1.8.8.m1.1.1.3.3.2.cmml" type="integer" xref="algorithm1.8.8.m1.1.1.3.3.2">1</cn><apply id="algorithm1.8.8.m1.1.1.3.3.3.cmml" xref="algorithm1.8.8.m1.1.1.3.3.3"><minus id="algorithm1.8.8.m1.1.1.3.3.3.1.cmml" xref="algorithm1.8.8.m1.1.1.3.3.3.1"></minus><apply id="algorithm1.8.8.m1.1.1.3.3.3.2.cmml" xref="algorithm1.8.8.m1.1.1.3.3.3.2"><plus id="algorithm1.8.8.m1.1.1.3.3.3.2.1.cmml" xref="algorithm1.8.8.m1.1.1.3.3.3.2.1"></plus><ci id="algorithm1.8.8.m1.1.1.3.3.3.2.2.cmml" xref="algorithm1.8.8.m1.1.1.3.3.3.2.2">𝑡</ci><ci id="algorithm1.8.8.m1.1.1.3.3.3.2.3.cmml" xref="algorithm1.8.8.m1.1.1.3.3.3.2.3">𝑘</ci></apply><cn id="algorithm1.8.8.m1.1.1.3.3.3.3.cmml" type="integer" xref="algorithm1.8.8.m1.1.1.3.3.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m1.1c">i_{1:t+k}\leftarrow i_{1:t+k-1}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.8.8.m1.1d">italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k end_POSTSUBSCRIPT ← italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k - 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.10.10.5" style="font-size:90%;"> </span><math alttext="append" class="ltx_Math" display="inline" id="algorithm1.9.9.m2.1"><semantics id="algorithm1.9.9.m2.1a"><mrow id="algorithm1.9.9.m2.1.1" xref="algorithm1.9.9.m2.1.1.cmml"><mi id="algorithm1.9.9.m2.1.1.2" mathsize="90%" xref="algorithm1.9.9.m2.1.1.2.cmml">a</mi><mo id="algorithm1.9.9.m2.1.1.1" xref="algorithm1.9.9.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.9.9.m2.1.1.3" mathsize="90%" xref="algorithm1.9.9.m2.1.1.3.cmml">p</mi><mo id="algorithm1.9.9.m2.1.1.1a" xref="algorithm1.9.9.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.9.9.m2.1.1.4" mathsize="90%" xref="algorithm1.9.9.m2.1.1.4.cmml">p</mi><mo id="algorithm1.9.9.m2.1.1.1b" xref="algorithm1.9.9.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.9.9.m2.1.1.5" mathsize="90%" xref="algorithm1.9.9.m2.1.1.5.cmml">e</mi><mo id="algorithm1.9.9.m2.1.1.1c" xref="algorithm1.9.9.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.9.9.m2.1.1.6" mathsize="90%" xref="algorithm1.9.9.m2.1.1.6.cmml">n</mi><mo id="algorithm1.9.9.m2.1.1.1d" xref="algorithm1.9.9.m2.1.1.1.cmml">⁢</mo><mi id="algorithm1.9.9.m2.1.1.7" mathsize="90%" xref="algorithm1.9.9.m2.1.1.7.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.m2.1b"><apply id="algorithm1.9.9.m2.1.1.cmml" xref="algorithm1.9.9.m2.1.1"><times id="algorithm1.9.9.m2.1.1.1.cmml" xref="algorithm1.9.9.m2.1.1.1"></times><ci id="algorithm1.9.9.m2.1.1.2.cmml" xref="algorithm1.9.9.m2.1.1.2">𝑎</ci><ci id="algorithm1.9.9.m2.1.1.3.cmml" xref="algorithm1.9.9.m2.1.1.3">𝑝</ci><ci id="algorithm1.9.9.m2.1.1.4.cmml" xref="algorithm1.9.9.m2.1.1.4">𝑝</ci><ci id="algorithm1.9.9.m2.1.1.5.cmml" xref="algorithm1.9.9.m2.1.1.5">𝑒</ci><ci id="algorithm1.9.9.m2.1.1.6.cmml" xref="algorithm1.9.9.m2.1.1.6">𝑛</ci><ci id="algorithm1.9.9.m2.1.1.7.cmml" xref="algorithm1.9.9.m2.1.1.7">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.m2.1c">append</annotation><annotation encoding="application/x-llamapun" id="algorithm1.9.9.m2.1d">italic_a italic_p italic_p italic_e italic_n italic_d</annotation></semantics></math><span class="ltx_text" id="algorithm1.10.10.6" style="font-size:90%;"> </span><math alttext="i_{t+k}" class="ltx_Math" display="inline" id="algorithm1.10.10.m3.1"><semantics id="algorithm1.10.10.m3.1a"><msub id="algorithm1.10.10.m3.1.1" xref="algorithm1.10.10.m3.1.1.cmml"><mi id="algorithm1.10.10.m3.1.1.2" mathsize="90%" xref="algorithm1.10.10.m3.1.1.2.cmml">i</mi><mrow id="algorithm1.10.10.m3.1.1.3" xref="algorithm1.10.10.m3.1.1.3.cmml"><mi id="algorithm1.10.10.m3.1.1.3.2" mathsize="90%" xref="algorithm1.10.10.m3.1.1.3.2.cmml">t</mi><mo id="algorithm1.10.10.m3.1.1.3.1" mathsize="90%" xref="algorithm1.10.10.m3.1.1.3.1.cmml">+</mo><mi id="algorithm1.10.10.m3.1.1.3.3" mathsize="90%" xref="algorithm1.10.10.m3.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.m3.1b"><apply id="algorithm1.10.10.m3.1.1.cmml" xref="algorithm1.10.10.m3.1.1"><csymbol cd="ambiguous" id="algorithm1.10.10.m3.1.1.1.cmml" xref="algorithm1.10.10.m3.1.1">subscript</csymbol><ci id="algorithm1.10.10.m3.1.1.2.cmml" xref="algorithm1.10.10.m3.1.1.2">𝑖</ci><apply id="algorithm1.10.10.m3.1.1.3.cmml" xref="algorithm1.10.10.m3.1.1.3"><plus id="algorithm1.10.10.m3.1.1.3.1.cmml" xref="algorithm1.10.10.m3.1.1.3.1"></plus><ci id="algorithm1.10.10.m3.1.1.3.2.cmml" xref="algorithm1.10.10.m3.1.1.3.2">𝑡</ci><ci id="algorithm1.10.10.m3.1.1.3.3.cmml" xref="algorithm1.10.10.m3.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.m3.1c">i_{t+k}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.10.10.m3.1d">italic_i start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.10.10.7" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm1.11.11">
<span class="ltx_text" id="algorithm1.11.11.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.11.11.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.11.11.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.11.11.4" style="font-size:90%;">
</span><math alttext="\mathbf{r^{s}}_{i_{t+k}}\leftarrow\frac{1}{k}" class="ltx_Math" display="inline" id="algorithm1.11.11.m1.1"><semantics id="algorithm1.11.11.m1.1a"><mrow id="algorithm1.11.11.m1.1.1" xref="algorithm1.11.11.m1.1.1.cmml"><mmultiscripts id="algorithm1.11.11.m1.1.1.2" xref="algorithm1.11.11.m1.1.1.2.cmml"><mi id="algorithm1.11.11.m1.1.1.2.2.2" mathsize="90%" xref="algorithm1.11.11.m1.1.1.2.2.2.cmml">𝐫</mi><mrow id="algorithm1.11.11.m1.1.1.2a" xref="algorithm1.11.11.m1.1.1.2.cmml"></mrow><mi id="algorithm1.11.11.m1.1.1.2.2.3" mathsize="90%" xref="algorithm1.11.11.m1.1.1.2.2.3.cmml">𝐬</mi><msub id="algorithm1.11.11.m1.1.1.2.3" xref="algorithm1.11.11.m1.1.1.2.3.cmml"><mi id="algorithm1.11.11.m1.1.1.2.3.2" mathsize="90%" xref="algorithm1.11.11.m1.1.1.2.3.2.cmml">i</mi><mrow id="algorithm1.11.11.m1.1.1.2.3.3" xref="algorithm1.11.11.m1.1.1.2.3.3.cmml"><mi id="algorithm1.11.11.m1.1.1.2.3.3.2" mathsize="90%" xref="algorithm1.11.11.m1.1.1.2.3.3.2.cmml">t</mi><mo id="algorithm1.11.11.m1.1.1.2.3.3.1" mathsize="90%" xref="algorithm1.11.11.m1.1.1.2.3.3.1.cmml">+</mo><mi id="algorithm1.11.11.m1.1.1.2.3.3.3" mathsize="90%" xref="algorithm1.11.11.m1.1.1.2.3.3.3.cmml">k</mi></mrow></msub><mrow id="algorithm1.11.11.m1.1.1.2b" xref="algorithm1.11.11.m1.1.1.2.cmml"></mrow></mmultiscripts><mo id="algorithm1.11.11.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.11.11.m1.1.1.1.cmml">←</mo><mfrac id="algorithm1.11.11.m1.1.1.3" xref="algorithm1.11.11.m1.1.1.3.cmml"><mn id="algorithm1.11.11.m1.1.1.3.2" mathsize="90%" xref="algorithm1.11.11.m1.1.1.3.2.cmml">1</mn><mi id="algorithm1.11.11.m1.1.1.3.3" mathsize="90%" xref="algorithm1.11.11.m1.1.1.3.3.cmml">k</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.m1.1b"><apply id="algorithm1.11.11.m1.1.1.cmml" xref="algorithm1.11.11.m1.1.1"><ci id="algorithm1.11.11.m1.1.1.1.cmml" xref="algorithm1.11.11.m1.1.1.1">←</ci><apply id="algorithm1.11.11.m1.1.1.2.cmml" xref="algorithm1.11.11.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.11.11.m1.1.1.2.1.cmml" xref="algorithm1.11.11.m1.1.1.2">subscript</csymbol><apply id="algorithm1.11.11.m1.1.1.2.2.cmml" xref="algorithm1.11.11.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.11.11.m1.1.1.2.2.1.cmml" xref="algorithm1.11.11.m1.1.1.2">superscript</csymbol><ci id="algorithm1.11.11.m1.1.1.2.2.2.cmml" xref="algorithm1.11.11.m1.1.1.2.2.2">𝐫</ci><ci id="algorithm1.11.11.m1.1.1.2.2.3.cmml" xref="algorithm1.11.11.m1.1.1.2.2.3">𝐬</ci></apply><apply id="algorithm1.11.11.m1.1.1.2.3.cmml" xref="algorithm1.11.11.m1.1.1.2.3"><csymbol cd="ambiguous" id="algorithm1.11.11.m1.1.1.2.3.1.cmml" xref="algorithm1.11.11.m1.1.1.2.3">subscript</csymbol><ci id="algorithm1.11.11.m1.1.1.2.3.2.cmml" xref="algorithm1.11.11.m1.1.1.2.3.2">𝑖</ci><apply id="algorithm1.11.11.m1.1.1.2.3.3.cmml" xref="algorithm1.11.11.m1.1.1.2.3.3"><plus id="algorithm1.11.11.m1.1.1.2.3.3.1.cmml" xref="algorithm1.11.11.m1.1.1.2.3.3.1"></plus><ci id="algorithm1.11.11.m1.1.1.2.3.3.2.cmml" xref="algorithm1.11.11.m1.1.1.2.3.3.2">𝑡</ci><ci id="algorithm1.11.11.m1.1.1.2.3.3.3.cmml" xref="algorithm1.11.11.m1.1.1.2.3.3.3">𝑘</ci></apply></apply></apply><apply id="algorithm1.11.11.m1.1.1.3.cmml" xref="algorithm1.11.11.m1.1.1.3"><divide id="algorithm1.11.11.m1.1.1.3.1.cmml" xref="algorithm1.11.11.m1.1.1.3"></divide><cn id="algorithm1.11.11.m1.1.1.3.2.cmml" type="integer" xref="algorithm1.11.11.m1.1.1.3.2">1</cn><ci id="algorithm1.11.11.m1.1.1.3.3.cmml" xref="algorithm1.11.11.m1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.m1.1c">\mathbf{r^{s}}_{i_{t+k}}\leftarrow\frac{1}{k}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.11.11.m1.1d">bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ← divide start_ARG 1 end_ARG start_ARG italic_k end_ARG</annotation></semantics></math><span class="ltx_text" id="algorithm1.11.11.5" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.18">
<span class="ltx_text" id="algorithm1.13.18.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.13.18.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.13.18.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.13.18.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm1.12.12">
<span class="ltx_text" id="algorithm1.12.12.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.12.12.2" style="font-size:90%;">   </span><math alttext="\mathbf{r}\leftarrow\mathbf{r}+\mathbf{r^{s}}" class="ltx_Math" display="inline" id="algorithm1.12.12.m1.1"><semantics id="algorithm1.12.12.m1.1a"><mrow id="algorithm1.12.12.m1.1.1" xref="algorithm1.12.12.m1.1.1.cmml"><mi id="algorithm1.12.12.m1.1.1.2" mathsize="90%" xref="algorithm1.12.12.m1.1.1.2.cmml">𝐫</mi><mo id="algorithm1.12.12.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.12.12.m1.1.1.1.cmml">←</mo><mrow id="algorithm1.12.12.m1.1.1.3" xref="algorithm1.12.12.m1.1.1.3.cmml"><mi id="algorithm1.12.12.m1.1.1.3.2" mathsize="90%" xref="algorithm1.12.12.m1.1.1.3.2.cmml">𝐫</mi><mo id="algorithm1.12.12.m1.1.1.3.1" mathsize="90%" xref="algorithm1.12.12.m1.1.1.3.1.cmml">+</mo><msup id="algorithm1.12.12.m1.1.1.3.3" xref="algorithm1.12.12.m1.1.1.3.3.cmml"><mi id="algorithm1.12.12.m1.1.1.3.3.2" mathsize="90%" xref="algorithm1.12.12.m1.1.1.3.3.2.cmml">𝐫</mi><mi id="algorithm1.12.12.m1.1.1.3.3.3" mathsize="90%" xref="algorithm1.12.12.m1.1.1.3.3.3.cmml">𝐬</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.m1.1b"><apply id="algorithm1.12.12.m1.1.1.cmml" xref="algorithm1.12.12.m1.1.1"><ci id="algorithm1.12.12.m1.1.1.1.cmml" xref="algorithm1.12.12.m1.1.1.1">←</ci><ci id="algorithm1.12.12.m1.1.1.2.cmml" xref="algorithm1.12.12.m1.1.1.2">𝐫</ci><apply id="algorithm1.12.12.m1.1.1.3.cmml" xref="algorithm1.12.12.m1.1.1.3"><plus id="algorithm1.12.12.m1.1.1.3.1.cmml" xref="algorithm1.12.12.m1.1.1.3.1"></plus><ci id="algorithm1.12.12.m1.1.1.3.2.cmml" xref="algorithm1.12.12.m1.1.1.3.2">𝐫</ci><apply id="algorithm1.12.12.m1.1.1.3.3.cmml" xref="algorithm1.12.12.m1.1.1.3.3"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.1.1.3.3.1.cmml" xref="algorithm1.12.12.m1.1.1.3.3">superscript</csymbol><ci id="algorithm1.12.12.m1.1.1.3.3.2.cmml" xref="algorithm1.12.12.m1.1.1.3.3.2">𝐫</ci><ci id="algorithm1.12.12.m1.1.1.3.3.3.cmml" xref="algorithm1.12.12.m1.1.1.3.3.3">𝐬</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.m1.1c">\mathbf{r}\leftarrow\mathbf{r}+\mathbf{r^{s}}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.12.12.m1.1d">bold_r ← bold_r + bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.12.12.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.13">
<span class="ltx_text ltx_font_bold" id="algorithm1.13.13.2" style="font-size:90%;">return</span><span class="ltx_text" id="algorithm1.13.13.3" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm1.13.13.1" style="font-size:90%;"><math alttext="argsort(-\mathbf{r})[:K]" class="ltx_math_unparsed" display="inline" id="algorithm1.13.13.1.m1.1"><semantics id="algorithm1.13.13.1.m1.1a"><mrow id="algorithm1.13.13.1.m1.1b"><mi id="algorithm1.13.13.1.m1.1.1">a</mi><mi id="algorithm1.13.13.1.m1.1.2">r</mi><mi id="algorithm1.13.13.1.m1.1.3">g</mi><mi id="algorithm1.13.13.1.m1.1.4">s</mi><mi id="algorithm1.13.13.1.m1.1.5">o</mi><mi id="algorithm1.13.13.1.m1.1.6">r</mi><mi id="algorithm1.13.13.1.m1.1.7">t</mi><mrow id="algorithm1.13.13.1.m1.1.8"><mo id="algorithm1.13.13.1.m1.1.8.1" stretchy="false">(</mo><mo id="algorithm1.13.13.1.m1.1.8.2" lspace="0em">−</mo><mi id="algorithm1.13.13.1.m1.1.8.3">𝐫</mi><mo id="algorithm1.13.13.1.m1.1.8.4" stretchy="false">)</mo></mrow><mrow id="algorithm1.13.13.1.m1.1.9"><mo id="algorithm1.13.13.1.m1.1.9.1" stretchy="false">[</mo><mo id="algorithm1.13.13.1.m1.1.9.2" rspace="0.278em">:</mo><mi id="algorithm1.13.13.1.m1.1.9.3">K</mi><mo id="algorithm1.13.13.1.m1.1.9.4" stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="algorithm1.13.13.1.m1.1c">argsort(-\mathbf{r})[:K]</annotation><annotation encoding="application/x-llamapun" id="algorithm1.13.13.1.m1.1d">italic_a italic_r italic_g italic_s italic_o italic_r italic_t ( - bold_r ) [ : italic_K ]</annotation></semantics></math></em><span class="ltx_text" id="algorithm1.13.13.4" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.19">
<span class="ltx_text" id="algorithm1.13.19.1" style="font-size:90%;">  </span><span class="ltx_text ltx_font_typewriter" id="algorithm1.13.19.2" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm1.13.19.3" style="font-size:90%;">get Top-K</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.20">
<span class="ltx_text" id="algorithm1.13.20.1" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.21">
<span class="ltx_text" id="algorithm1.13.21.1" style="font-size:90%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.17.1.1">Algorithm 1</span> </span>Top-K sequential recommendations generation with the RRA strategy</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS4.Px2">
<h5 class="ltx_title ltx_title_paragraph">Relevance Aggregation strategy (RA)</h5>
<div class="ltx_para" id="S3.SS2.SSS4.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS4.Px2.p1.1">The second aggregation strategy we consider is based on the CombSUM method <cite class="ltx_cite ltx_citemacro_citep">(Oliveira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib29" title="">2020</a>; Bałchanowski and Boryczka, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib7" title="">2023</a>)</cite>. According to it, we aggregate predicted scores (relevances) for each item from each generation step instead of reciprocal ranks of generated items. RA strategy is illustrated with pseudocode in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#algorithm2" title="In Relevance Aggregation strategy (RA) ‣ 3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a>. Single-sequence generation and scores aggregation with RA strategy consists of the following steps:</p>
<ol class="ltx_enumerate" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.3">Generate sequence continuations of length <math alttext="K" class="ltx_Math" display="inline" id="S3.I3.i1.p1.1.m1.1"><semantics id="S3.I3.i1.p1.1.m1.1a"><mi id="S3.I3.i1.p1.1.m1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.1.m1.1b"><ci id="S3.I3.i1.p1.1.m1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.1.m1.1d">italic_K</annotation></semantics></math> with temperature sampling. This time we allow the model to predict already generated items and keep predicted relevances <math alttext="\mathbf{r^{sk}}\in\mathbb{R}^{I}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.2.m2.1"><semantics id="S3.I3.i1.p1.2.m2.1a"><mrow id="S3.I3.i1.p1.2.m2.1.1" xref="S3.I3.i1.p1.2.m2.1.1.cmml"><msup id="S3.I3.i1.p1.2.m2.1.1.2" xref="S3.I3.i1.p1.2.m2.1.1.2.cmml"><mi id="S3.I3.i1.p1.2.m2.1.1.2.2" xref="S3.I3.i1.p1.2.m2.1.1.2.2.cmml">𝐫</mi><mi id="S3.I3.i1.p1.2.m2.1.1.2.3" xref="S3.I3.i1.p1.2.m2.1.1.2.3.cmml">𝐬𝐤</mi></msup><mo id="S3.I3.i1.p1.2.m2.1.1.1" xref="S3.I3.i1.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S3.I3.i1.p1.2.m2.1.1.3" xref="S3.I3.i1.p1.2.m2.1.1.3.cmml"><mi id="S3.I3.i1.p1.2.m2.1.1.3.2" xref="S3.I3.i1.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S3.I3.i1.p1.2.m2.1.1.3.3" xref="S3.I3.i1.p1.2.m2.1.1.3.3.cmml">I</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.2.m2.1b"><apply id="S3.I3.i1.p1.2.m2.1.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1"><in id="S3.I3.i1.p1.2.m2.1.1.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1.1"></in><apply id="S3.I3.i1.p1.2.m2.1.1.2.cmml" xref="S3.I3.i1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.I3.i1.p1.2.m2.1.1.2.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1.2">superscript</csymbol><ci id="S3.I3.i1.p1.2.m2.1.1.2.2.cmml" xref="S3.I3.i1.p1.2.m2.1.1.2.2">𝐫</ci><ci id="S3.I3.i1.p1.2.m2.1.1.2.3.cmml" xref="S3.I3.i1.p1.2.m2.1.1.2.3">𝐬𝐤</ci></apply><apply id="S3.I3.i1.p1.2.m2.1.1.3.cmml" xref="S3.I3.i1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.I3.i1.p1.2.m2.1.1.3.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.I3.i1.p1.2.m2.1.1.3.2.cmml" xref="S3.I3.i1.p1.2.m2.1.1.3.2">ℝ</ci><ci id="S3.I3.i1.p1.2.m2.1.1.3.3.cmml" xref="S3.I3.i1.p1.2.m2.1.1.3.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.2.m2.1c">\mathbf{r^{sk}}\in\mathbb{R}^{I}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.2.m2.1d">bold_r start_POSTSUPERSCRIPT bold_sk end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT</annotation></semantics></math> for all items on each generation step <math alttext="k" class="ltx_Math" display="inline" id="S3.I3.i1.p1.3.m3.1"><semantics id="S3.I3.i1.p1.3.m3.1a"><mi id="S3.I3.i1.p1.3.m3.1.1" xref="S3.I3.i1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.3.m3.1b"><ci id="S3.I3.i1.p1.3.m3.1.1.cmml" xref="S3.I3.i1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.3.m3.1d">italic_k</annotation></semantics></math>. Also, for this approach, we don’t use top-k sampling.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1">Each item in the catalog is assigned relevance equal to the sum of its relevances at each generation step.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS2.SSS4.Px2.p1.2">This way, we don’t promote items from the beginning of generated sequences and consider all generated steps equivalent.</p>
</div>
<figure class="ltx_float ltx_algorithm" id="algorithm2">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm2.14">
<div class="ltx_listingline" id="algorithm2.1.1">
<math alttext="\mathbf{r}\leftarrow[0]\times I" class="ltx_Math" display="inline" id="algorithm2.1.1.m1.1"><semantics id="algorithm2.1.1.m1.1a"><mrow id="algorithm2.1.1.m1.1.2" xref="algorithm2.1.1.m1.1.2.cmml"><mi id="algorithm2.1.1.m1.1.2.2" mathsize="90%" xref="algorithm2.1.1.m1.1.2.2.cmml">𝐫</mi><mo id="algorithm2.1.1.m1.1.2.1" mathsize="90%" stretchy="false" xref="algorithm2.1.1.m1.1.2.1.cmml">←</mo><mrow id="algorithm2.1.1.m1.1.2.3" xref="algorithm2.1.1.m1.1.2.3.cmml"><mrow id="algorithm2.1.1.m1.1.2.3.2.2" xref="algorithm2.1.1.m1.1.2.3.2.1.cmml"><mo id="algorithm2.1.1.m1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="algorithm2.1.1.m1.1.2.3.2.1.1.cmml">[</mo><mn id="algorithm2.1.1.m1.1.1" mathsize="90%" xref="algorithm2.1.1.m1.1.1.cmml">0</mn><mo id="algorithm2.1.1.m1.1.2.3.2.2.2" maxsize="90%" minsize="90%" rspace="0.055em" xref="algorithm2.1.1.m1.1.2.3.2.1.1.cmml">]</mo></mrow><mo id="algorithm2.1.1.m1.1.2.3.1" mathsize="90%" rspace="0.222em" xref="algorithm2.1.1.m1.1.2.3.1.cmml">×</mo><mi id="algorithm2.1.1.m1.1.2.3.3" mathsize="90%" xref="algorithm2.1.1.m1.1.2.3.3.cmml">I</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.1.1.m1.1b"><apply id="algorithm2.1.1.m1.1.2.cmml" xref="algorithm2.1.1.m1.1.2"><ci id="algorithm2.1.1.m1.1.2.1.cmml" xref="algorithm2.1.1.m1.1.2.1">←</ci><ci id="algorithm2.1.1.m1.1.2.2.cmml" xref="algorithm2.1.1.m1.1.2.2">𝐫</ci><apply id="algorithm2.1.1.m1.1.2.3.cmml" xref="algorithm2.1.1.m1.1.2.3"><times id="algorithm2.1.1.m1.1.2.3.1.cmml" xref="algorithm2.1.1.m1.1.2.3.1"></times><apply id="algorithm2.1.1.m1.1.2.3.2.1.cmml" xref="algorithm2.1.1.m1.1.2.3.2.2"><csymbol cd="latexml" id="algorithm2.1.1.m1.1.2.3.2.1.1.cmml" xref="algorithm2.1.1.m1.1.2.3.2.2.1">delimited-[]</csymbol><cn id="algorithm2.1.1.m1.1.1.cmml" type="integer" xref="algorithm2.1.1.m1.1.1">0</cn></apply><ci id="algorithm2.1.1.m1.1.2.3.3.cmml" xref="algorithm2.1.1.m1.1.2.3.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.1.1.m1.1c">\mathbf{r}\leftarrow[0]\times I</annotation><annotation encoding="application/x-llamapun" id="algorithm2.1.1.m1.1d">bold_r ← [ 0 ] × italic_I</annotation></semantics></math><span class="ltx_text" id="algorithm2.1.1.1" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.15">
<span class="ltx_text" id="algorithm2.14.15.1" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.3.3">
<span class="ltx_text ltx_font_bold" id="algorithm2.3.3.3" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm2.3.3.4" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm2.3.3.2" style="font-size:90%;"><math alttext="s\leftarrow 1" class="ltx_Math" display="inline" id="algorithm2.2.2.1.m1.1"><semantics id="algorithm2.2.2.1.m1.1a"><mrow id="algorithm2.2.2.1.m1.1.1" xref="algorithm2.2.2.1.m1.1.1.cmml"><mi id="algorithm2.2.2.1.m1.1.1.2" xref="algorithm2.2.2.1.m1.1.1.2.cmml">s</mi><mo id="algorithm2.2.2.1.m1.1.1.1" stretchy="false" xref="algorithm2.2.2.1.m1.1.1.1.cmml">←</mo><mn id="algorithm2.2.2.1.m1.1.1.3" xref="algorithm2.2.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.2.2.1.m1.1b"><apply id="algorithm2.2.2.1.m1.1.1.cmml" xref="algorithm2.2.2.1.m1.1.1"><ci id="algorithm2.2.2.1.m1.1.1.1.cmml" xref="algorithm2.2.2.1.m1.1.1.1">←</ci><ci id="algorithm2.2.2.1.m1.1.1.2.cmml" xref="algorithm2.2.2.1.m1.1.1.2">𝑠</ci><cn id="algorithm2.2.2.1.m1.1.1.3.cmml" type="integer" xref="algorithm2.2.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.2.2.1.m1.1c">s\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algorithm2.2.2.1.m1.1d">italic_s ← 1</annotation></semantics></math> <span class="ltx_text ltx_font_bold ltx_font_upright" id="algorithm2.3.3.2.1">to</span> <math alttext="S" class="ltx_Math" display="inline" id="algorithm2.3.3.2.m2.1"><semantics id="algorithm2.3.3.2.m2.1a"><mi id="algorithm2.3.3.2.m2.1.1" xref="algorithm2.3.3.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="algorithm2.3.3.2.m2.1b"><ci id="algorithm2.3.3.2.m2.1.1.cmml" xref="algorithm2.3.3.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.3.3.2.m2.1c">S</annotation><annotation encoding="application/x-llamapun" id="algorithm2.3.3.2.m2.1d">italic_S</annotation></semantics></math></em><span class="ltx_text" id="algorithm2.3.3.5" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm2.3.3.6" style="font-size:90%;">do</span><span class="ltx_text" id="algorithm2.3.3.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.3.3.8" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.3.3.9" style="font-size:90%;">computes in parallel</span>
</div>
<div class="ltx_listingline" id="algorithm2.4.4">
<span class="ltx_text" id="algorithm2.4.4.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.4.4.2" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.4.4.3" style="font-size:90%;">
</span><math alttext="\mathbf{r^{s}}\leftarrow[0]\times I" class="ltx_Math" display="inline" id="algorithm2.4.4.m1.1"><semantics id="algorithm2.4.4.m1.1a"><mrow id="algorithm2.4.4.m1.1.2" xref="algorithm2.4.4.m1.1.2.cmml"><msup id="algorithm2.4.4.m1.1.2.2" xref="algorithm2.4.4.m1.1.2.2.cmml"><mi id="algorithm2.4.4.m1.1.2.2.2" mathsize="90%" xref="algorithm2.4.4.m1.1.2.2.2.cmml">𝐫</mi><mi id="algorithm2.4.4.m1.1.2.2.3" mathsize="90%" xref="algorithm2.4.4.m1.1.2.2.3.cmml">𝐬</mi></msup><mo id="algorithm2.4.4.m1.1.2.1" mathsize="90%" stretchy="false" xref="algorithm2.4.4.m1.1.2.1.cmml">←</mo><mrow id="algorithm2.4.4.m1.1.2.3" xref="algorithm2.4.4.m1.1.2.3.cmml"><mrow id="algorithm2.4.4.m1.1.2.3.2.2" xref="algorithm2.4.4.m1.1.2.3.2.1.cmml"><mo id="algorithm2.4.4.m1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="algorithm2.4.4.m1.1.2.3.2.1.1.cmml">[</mo><mn id="algorithm2.4.4.m1.1.1" mathsize="90%" xref="algorithm2.4.4.m1.1.1.cmml">0</mn><mo id="algorithm2.4.4.m1.1.2.3.2.2.2" maxsize="90%" minsize="90%" rspace="0.055em" xref="algorithm2.4.4.m1.1.2.3.2.1.1.cmml">]</mo></mrow><mo id="algorithm2.4.4.m1.1.2.3.1" mathsize="90%" rspace="0.222em" xref="algorithm2.4.4.m1.1.2.3.1.cmml">×</mo><mi id="algorithm2.4.4.m1.1.2.3.3" mathsize="90%" xref="algorithm2.4.4.m1.1.2.3.3.cmml">I</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.4.4.m1.1b"><apply id="algorithm2.4.4.m1.1.2.cmml" xref="algorithm2.4.4.m1.1.2"><ci id="algorithm2.4.4.m1.1.2.1.cmml" xref="algorithm2.4.4.m1.1.2.1">←</ci><apply id="algorithm2.4.4.m1.1.2.2.cmml" xref="algorithm2.4.4.m1.1.2.2"><csymbol cd="ambiguous" id="algorithm2.4.4.m1.1.2.2.1.cmml" xref="algorithm2.4.4.m1.1.2.2">superscript</csymbol><ci id="algorithm2.4.4.m1.1.2.2.2.cmml" xref="algorithm2.4.4.m1.1.2.2.2">𝐫</ci><ci id="algorithm2.4.4.m1.1.2.2.3.cmml" xref="algorithm2.4.4.m1.1.2.2.3">𝐬</ci></apply><apply id="algorithm2.4.4.m1.1.2.3.cmml" xref="algorithm2.4.4.m1.1.2.3"><times id="algorithm2.4.4.m1.1.2.3.1.cmml" xref="algorithm2.4.4.m1.1.2.3.1"></times><apply id="algorithm2.4.4.m1.1.2.3.2.1.cmml" xref="algorithm2.4.4.m1.1.2.3.2.2"><csymbol cd="latexml" id="algorithm2.4.4.m1.1.2.3.2.1.1.cmml" xref="algorithm2.4.4.m1.1.2.3.2.2.1">delimited-[]</csymbol><cn id="algorithm2.4.4.m1.1.1.cmml" type="integer" xref="algorithm2.4.4.m1.1.1">0</cn></apply><ci id="algorithm2.4.4.m1.1.2.3.3.cmml" xref="algorithm2.4.4.m1.1.2.3.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.4.4.m1.1c">\mathbf{r^{s}}\leftarrow[0]\times I</annotation><annotation encoding="application/x-llamapun" id="algorithm2.4.4.m1.1d">bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT ← [ 0 ] × italic_I</annotation></semantics></math><span class="ltx_text" id="algorithm2.4.4.4" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.16">
<span class="ltx_text" id="algorithm2.14.16.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.14.16.2" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.14.16.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.6.6">
<span class="ltx_text" id="algorithm2.6.6.3" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.6.6.4" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm2.6.6.5" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm2.6.6.6" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm2.6.6.2" style="font-size:90%;"><math alttext="k\leftarrow 1" class="ltx_Math" display="inline" id="algorithm2.5.5.1.m1.1"><semantics id="algorithm2.5.5.1.m1.1a"><mrow id="algorithm2.5.5.1.m1.1.1" xref="algorithm2.5.5.1.m1.1.1.cmml"><mi id="algorithm2.5.5.1.m1.1.1.2" xref="algorithm2.5.5.1.m1.1.1.2.cmml">k</mi><mo id="algorithm2.5.5.1.m1.1.1.1" stretchy="false" xref="algorithm2.5.5.1.m1.1.1.1.cmml">←</mo><mn id="algorithm2.5.5.1.m1.1.1.3" xref="algorithm2.5.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.5.5.1.m1.1b"><apply id="algorithm2.5.5.1.m1.1.1.cmml" xref="algorithm2.5.5.1.m1.1.1"><ci id="algorithm2.5.5.1.m1.1.1.1.cmml" xref="algorithm2.5.5.1.m1.1.1.1">←</ci><ci id="algorithm2.5.5.1.m1.1.1.2.cmml" xref="algorithm2.5.5.1.m1.1.1.2">𝑘</ci><cn id="algorithm2.5.5.1.m1.1.1.3.cmml" type="integer" xref="algorithm2.5.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.5.5.1.m1.1c">k\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algorithm2.5.5.1.m1.1d">italic_k ← 1</annotation></semantics></math> <span class="ltx_text ltx_font_bold ltx_font_upright" id="algorithm2.6.6.2.1">to</span> <math alttext="K" class="ltx_Math" display="inline" id="algorithm2.6.6.2.m2.1"><semantics id="algorithm2.6.6.2.m2.1a"><mi id="algorithm2.6.6.2.m2.1.1" xref="algorithm2.6.6.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="algorithm2.6.6.2.m2.1b"><ci id="algorithm2.6.6.2.m2.1.1.cmml" xref="algorithm2.6.6.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.6.6.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="algorithm2.6.6.2.m2.1d">italic_K</annotation></semantics></math></em><span class="ltx_text" id="algorithm2.6.6.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm2.6.6.8" style="font-size:90%;">do</span>
</div>
<div class="ltx_listingline" id="algorithm2.8.8">
<span class="ltx_text" id="algorithm2.8.8.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.8.8.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.8.8.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.8.8.4" style="font-size:90%;">
</span><math alttext="i_{t+k}" class="ltx_Math" display="inline" id="algorithm2.7.7.m1.1"><semantics id="algorithm2.7.7.m1.1a"><msub id="algorithm2.7.7.m1.1.1" xref="algorithm2.7.7.m1.1.1.cmml"><mi id="algorithm2.7.7.m1.1.1.2" mathsize="90%" xref="algorithm2.7.7.m1.1.1.2.cmml">i</mi><mrow id="algorithm2.7.7.m1.1.1.3" xref="algorithm2.7.7.m1.1.1.3.cmml"><mi id="algorithm2.7.7.m1.1.1.3.2" mathsize="90%" xref="algorithm2.7.7.m1.1.1.3.2.cmml">t</mi><mo id="algorithm2.7.7.m1.1.1.3.1" mathsize="90%" xref="algorithm2.7.7.m1.1.1.3.1.cmml">+</mo><mi id="algorithm2.7.7.m1.1.1.3.3" mathsize="90%" xref="algorithm2.7.7.m1.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="algorithm2.7.7.m1.1b"><apply id="algorithm2.7.7.m1.1.1.cmml" xref="algorithm2.7.7.m1.1.1"><csymbol cd="ambiguous" id="algorithm2.7.7.m1.1.1.1.cmml" xref="algorithm2.7.7.m1.1.1">subscript</csymbol><ci id="algorithm2.7.7.m1.1.1.2.cmml" xref="algorithm2.7.7.m1.1.1.2">𝑖</ci><apply id="algorithm2.7.7.m1.1.1.3.cmml" xref="algorithm2.7.7.m1.1.1.3"><plus id="algorithm2.7.7.m1.1.1.3.1.cmml" xref="algorithm2.7.7.m1.1.1.3.1"></plus><ci id="algorithm2.7.7.m1.1.1.3.2.cmml" xref="algorithm2.7.7.m1.1.1.3.2">𝑡</ci><ci id="algorithm2.7.7.m1.1.1.3.3.cmml" xref="algorithm2.7.7.m1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.7.7.m1.1c">i_{t+k}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.7.7.m1.1d">italic_i start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.8.8.5" style="font-size:90%;">, </span><math alttext="r^{sk}\leftarrow model.generate(i_{1:t+k-1})" class="ltx_Math" display="inline" id="algorithm2.8.8.m2.2"><semantics id="algorithm2.8.8.m2.2a"><mrow id="algorithm2.8.8.m2.2.2.2" xref="algorithm2.8.8.m2.2.2.3.cmml"><mrow id="algorithm2.8.8.m2.1.1.1.1" xref="algorithm2.8.8.m2.1.1.1.1.cmml"><msup id="algorithm2.8.8.m2.1.1.1.1.2" xref="algorithm2.8.8.m2.1.1.1.1.2.cmml"><mi id="algorithm2.8.8.m2.1.1.1.1.2.2" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.2.2.cmml">r</mi><mrow id="algorithm2.8.8.m2.1.1.1.1.2.3" xref="algorithm2.8.8.m2.1.1.1.1.2.3.cmml"><mi id="algorithm2.8.8.m2.1.1.1.1.2.3.2" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.2.3.2.cmml">s</mi><mo id="algorithm2.8.8.m2.1.1.1.1.2.3.1" xref="algorithm2.8.8.m2.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="algorithm2.8.8.m2.1.1.1.1.2.3.3" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.2.3.3.cmml">k</mi></mrow></msup><mo id="algorithm2.8.8.m2.1.1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.8.8.m2.1.1.1.1.1.cmml">←</mo><mrow id="algorithm2.8.8.m2.1.1.1.1.3" xref="algorithm2.8.8.m2.1.1.1.1.3.cmml"><mi id="algorithm2.8.8.m2.1.1.1.1.3.2" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.3.2.cmml">m</mi><mo id="algorithm2.8.8.m2.1.1.1.1.3.1" xref="algorithm2.8.8.m2.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm2.8.8.m2.1.1.1.1.3.3" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.3.3.cmml">o</mi><mo id="algorithm2.8.8.m2.1.1.1.1.3.1a" xref="algorithm2.8.8.m2.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm2.8.8.m2.1.1.1.1.3.4" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.3.4.cmml">d</mi><mo id="algorithm2.8.8.m2.1.1.1.1.3.1b" xref="algorithm2.8.8.m2.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm2.8.8.m2.1.1.1.1.3.5" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.3.5.cmml">e</mi><mo id="algorithm2.8.8.m2.1.1.1.1.3.1c" xref="algorithm2.8.8.m2.1.1.1.1.3.1.cmml">⁢</mo><mi id="algorithm2.8.8.m2.1.1.1.1.3.6" mathsize="90%" xref="algorithm2.8.8.m2.1.1.1.1.3.6.cmml">l</mi></mrow></mrow><mo id="algorithm2.8.8.m2.2.2.2.3" lspace="0em" mathsize="90%" rspace="0.167em" xref="algorithm2.8.8.m2.2.2.3a.cmml">.</mo><mrow id="algorithm2.8.8.m2.2.2.2.2" xref="algorithm2.8.8.m2.2.2.2.2.cmml"><mi id="algorithm2.8.8.m2.2.2.2.2.3" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.3.cmml">g</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.4" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.4.cmml">e</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2a" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.5" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.5.cmml">n</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2b" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.6" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.6.cmml">e</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2c" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.7" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.7.cmml">r</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2d" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.8" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.8.cmml">a</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2e" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.9" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.9.cmml">t</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2f" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mi id="algorithm2.8.8.m2.2.2.2.2.10" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.10.cmml">e</mi><mo id="algorithm2.8.8.m2.2.2.2.2.2g" xref="algorithm2.8.8.m2.2.2.2.2.2.cmml">⁢</mo><mrow id="algorithm2.8.8.m2.2.2.2.2.1.1" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.cmml"><mo id="algorithm2.8.8.m2.2.2.2.2.1.1.2" maxsize="90%" minsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.cmml">(</mo><msub id="algorithm2.8.8.m2.2.2.2.2.1.1.1" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.cmml"><mi id="algorithm2.8.8.m2.2.2.2.2.1.1.1.2" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.2.cmml">i</mi><mrow id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.cmml"><mn id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.2" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.2.cmml">1</mn><mo id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.1" lspace="0.278em" mathsize="90%" rspace="0.278em" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.1.cmml">:</mo><mrow id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.cmml"><mrow id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.cmml"><mi id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.2" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.2.cmml">t</mi><mo id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.1" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.1.cmml">+</mo><mi id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.3" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.3.cmml">k</mi></mrow><mo id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.1" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.1.cmml">−</mo><mn id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.3" mathsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.3.cmml">1</mn></mrow></mrow></msub><mo id="algorithm2.8.8.m2.2.2.2.2.1.1.3" maxsize="90%" minsize="90%" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.8.8.m2.2b"><apply id="algorithm2.8.8.m2.2.2.3.cmml" xref="algorithm2.8.8.m2.2.2.2"><csymbol cd="ambiguous" id="algorithm2.8.8.m2.2.2.3a.cmml" xref="algorithm2.8.8.m2.2.2.2.3">formulae-sequence</csymbol><apply id="algorithm2.8.8.m2.1.1.1.1.cmml" xref="algorithm2.8.8.m2.1.1.1.1"><ci id="algorithm2.8.8.m2.1.1.1.1.1.cmml" xref="algorithm2.8.8.m2.1.1.1.1.1">←</ci><apply id="algorithm2.8.8.m2.1.1.1.1.2.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.8.8.m2.1.1.1.1.2.1.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2">superscript</csymbol><ci id="algorithm2.8.8.m2.1.1.1.1.2.2.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2.2">𝑟</ci><apply id="algorithm2.8.8.m2.1.1.1.1.2.3.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2.3"><times id="algorithm2.8.8.m2.1.1.1.1.2.3.1.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2.3.1"></times><ci id="algorithm2.8.8.m2.1.1.1.1.2.3.2.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2.3.2">𝑠</ci><ci id="algorithm2.8.8.m2.1.1.1.1.2.3.3.cmml" xref="algorithm2.8.8.m2.1.1.1.1.2.3.3">𝑘</ci></apply></apply><apply id="algorithm2.8.8.m2.1.1.1.1.3.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3"><times id="algorithm2.8.8.m2.1.1.1.1.3.1.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3.1"></times><ci id="algorithm2.8.8.m2.1.1.1.1.3.2.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3.2">𝑚</ci><ci id="algorithm2.8.8.m2.1.1.1.1.3.3.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3.3">𝑜</ci><ci id="algorithm2.8.8.m2.1.1.1.1.3.4.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3.4">𝑑</ci><ci id="algorithm2.8.8.m2.1.1.1.1.3.5.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3.5">𝑒</ci><ci id="algorithm2.8.8.m2.1.1.1.1.3.6.cmml" xref="algorithm2.8.8.m2.1.1.1.1.3.6">𝑙</ci></apply></apply><apply id="algorithm2.8.8.m2.2.2.2.2.cmml" xref="algorithm2.8.8.m2.2.2.2.2"><times id="algorithm2.8.8.m2.2.2.2.2.2.cmml" xref="algorithm2.8.8.m2.2.2.2.2.2"></times><ci id="algorithm2.8.8.m2.2.2.2.2.3.cmml" xref="algorithm2.8.8.m2.2.2.2.2.3">𝑔</ci><ci id="algorithm2.8.8.m2.2.2.2.2.4.cmml" xref="algorithm2.8.8.m2.2.2.2.2.4">𝑒</ci><ci id="algorithm2.8.8.m2.2.2.2.2.5.cmml" xref="algorithm2.8.8.m2.2.2.2.2.5">𝑛</ci><ci id="algorithm2.8.8.m2.2.2.2.2.6.cmml" xref="algorithm2.8.8.m2.2.2.2.2.6">𝑒</ci><ci id="algorithm2.8.8.m2.2.2.2.2.7.cmml" xref="algorithm2.8.8.m2.2.2.2.2.7">𝑟</ci><ci id="algorithm2.8.8.m2.2.2.2.2.8.cmml" xref="algorithm2.8.8.m2.2.2.2.2.8">𝑎</ci><ci id="algorithm2.8.8.m2.2.2.2.2.9.cmml" xref="algorithm2.8.8.m2.2.2.2.2.9">𝑡</ci><ci id="algorithm2.8.8.m2.2.2.2.2.10.cmml" xref="algorithm2.8.8.m2.2.2.2.2.10">𝑒</ci><apply id="algorithm2.8.8.m2.2.2.2.2.1.1.1.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="algorithm2.8.8.m2.2.2.2.2.1.1.1.1.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1">subscript</csymbol><ci id="algorithm2.8.8.m2.2.2.2.2.1.1.1.2.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.2">𝑖</ci><apply id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3"><ci id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.1.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.1">:</ci><cn id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.2.cmml" type="integer" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.2">1</cn><apply id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3"><minus id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.1.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.1"></minus><apply id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2"><plus id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.1.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.1"></plus><ci id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.2.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.2">𝑡</ci><ci id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.3.cmml" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.2.3">𝑘</ci></apply><cn id="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.3.cmml" type="integer" xref="algorithm2.8.8.m2.2.2.2.2.1.1.1.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.8.8.m2.2c">r^{sk}\leftarrow model.generate(i_{1:t+k-1})</annotation><annotation encoding="application/x-llamapun" id="algorithm2.8.8.m2.2d">italic_r start_POSTSUPERSCRIPT italic_s italic_k end_POSTSUPERSCRIPT ← italic_m italic_o italic_d italic_e italic_l . italic_g italic_e italic_n italic_e italic_r italic_a italic_t italic_e ( italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k - 1 end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="algorithm2.8.8.6" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm2.11.11">
<span class="ltx_text" id="algorithm2.11.11.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.11.11.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.11.11.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.11.11.4" style="font-size:90%;">
</span><math alttext="i_{1:t+k}\leftarrow i_{1:t+k-1}" class="ltx_Math" display="inline" id="algorithm2.9.9.m1.1"><semantics id="algorithm2.9.9.m1.1a"><mrow id="algorithm2.9.9.m1.1.1" xref="algorithm2.9.9.m1.1.1.cmml"><msub id="algorithm2.9.9.m1.1.1.2" xref="algorithm2.9.9.m1.1.1.2.cmml"><mi id="algorithm2.9.9.m1.1.1.2.2" mathsize="90%" xref="algorithm2.9.9.m1.1.1.2.2.cmml">i</mi><mrow id="algorithm2.9.9.m1.1.1.2.3" xref="algorithm2.9.9.m1.1.1.2.3.cmml"><mn id="algorithm2.9.9.m1.1.1.2.3.2" mathsize="90%" xref="algorithm2.9.9.m1.1.1.2.3.2.cmml">1</mn><mo id="algorithm2.9.9.m1.1.1.2.3.1" lspace="0.278em" mathsize="90%" rspace="0.278em" xref="algorithm2.9.9.m1.1.1.2.3.1.cmml">:</mo><mrow id="algorithm2.9.9.m1.1.1.2.3.3" xref="algorithm2.9.9.m1.1.1.2.3.3.cmml"><mi id="algorithm2.9.9.m1.1.1.2.3.3.2" mathsize="90%" xref="algorithm2.9.9.m1.1.1.2.3.3.2.cmml">t</mi><mo id="algorithm2.9.9.m1.1.1.2.3.3.1" mathsize="90%" xref="algorithm2.9.9.m1.1.1.2.3.3.1.cmml">+</mo><mi id="algorithm2.9.9.m1.1.1.2.3.3.3" mathsize="90%" xref="algorithm2.9.9.m1.1.1.2.3.3.3.cmml">k</mi></mrow></mrow></msub><mo id="algorithm2.9.9.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.9.9.m1.1.1.1.cmml">←</mo><msub id="algorithm2.9.9.m1.1.1.3" xref="algorithm2.9.9.m1.1.1.3.cmml"><mi id="algorithm2.9.9.m1.1.1.3.2" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.2.cmml">i</mi><mrow id="algorithm2.9.9.m1.1.1.3.3" xref="algorithm2.9.9.m1.1.1.3.3.cmml"><mn id="algorithm2.9.9.m1.1.1.3.3.2" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.3.2.cmml">1</mn><mo id="algorithm2.9.9.m1.1.1.3.3.1" lspace="0.278em" mathsize="90%" rspace="0.278em" xref="algorithm2.9.9.m1.1.1.3.3.1.cmml">:</mo><mrow id="algorithm2.9.9.m1.1.1.3.3.3" xref="algorithm2.9.9.m1.1.1.3.3.3.cmml"><mrow id="algorithm2.9.9.m1.1.1.3.3.3.2" xref="algorithm2.9.9.m1.1.1.3.3.3.2.cmml"><mi id="algorithm2.9.9.m1.1.1.3.3.3.2.2" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.3.3.2.2.cmml">t</mi><mo id="algorithm2.9.9.m1.1.1.3.3.3.2.1" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.3.3.2.1.cmml">+</mo><mi id="algorithm2.9.9.m1.1.1.3.3.3.2.3" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.3.3.2.3.cmml">k</mi></mrow><mo id="algorithm2.9.9.m1.1.1.3.3.3.1" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.3.3.1.cmml">−</mo><mn id="algorithm2.9.9.m1.1.1.3.3.3.3" mathsize="90%" xref="algorithm2.9.9.m1.1.1.3.3.3.3.cmml">1</mn></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.9.9.m1.1b"><apply id="algorithm2.9.9.m1.1.1.cmml" xref="algorithm2.9.9.m1.1.1"><ci id="algorithm2.9.9.m1.1.1.1.cmml" xref="algorithm2.9.9.m1.1.1.1">←</ci><apply id="algorithm2.9.9.m1.1.1.2.cmml" xref="algorithm2.9.9.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.9.9.m1.1.1.2.1.cmml" xref="algorithm2.9.9.m1.1.1.2">subscript</csymbol><ci id="algorithm2.9.9.m1.1.1.2.2.cmml" xref="algorithm2.9.9.m1.1.1.2.2">𝑖</ci><apply id="algorithm2.9.9.m1.1.1.2.3.cmml" xref="algorithm2.9.9.m1.1.1.2.3"><ci id="algorithm2.9.9.m1.1.1.2.3.1.cmml" xref="algorithm2.9.9.m1.1.1.2.3.1">:</ci><cn id="algorithm2.9.9.m1.1.1.2.3.2.cmml" type="integer" xref="algorithm2.9.9.m1.1.1.2.3.2">1</cn><apply id="algorithm2.9.9.m1.1.1.2.3.3.cmml" xref="algorithm2.9.9.m1.1.1.2.3.3"><plus id="algorithm2.9.9.m1.1.1.2.3.3.1.cmml" xref="algorithm2.9.9.m1.1.1.2.3.3.1"></plus><ci id="algorithm2.9.9.m1.1.1.2.3.3.2.cmml" xref="algorithm2.9.9.m1.1.1.2.3.3.2">𝑡</ci><ci id="algorithm2.9.9.m1.1.1.2.3.3.3.cmml" xref="algorithm2.9.9.m1.1.1.2.3.3.3">𝑘</ci></apply></apply></apply><apply id="algorithm2.9.9.m1.1.1.3.cmml" xref="algorithm2.9.9.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm2.9.9.m1.1.1.3.1.cmml" xref="algorithm2.9.9.m1.1.1.3">subscript</csymbol><ci id="algorithm2.9.9.m1.1.1.3.2.cmml" xref="algorithm2.9.9.m1.1.1.3.2">𝑖</ci><apply id="algorithm2.9.9.m1.1.1.3.3.cmml" xref="algorithm2.9.9.m1.1.1.3.3"><ci id="algorithm2.9.9.m1.1.1.3.3.1.cmml" xref="algorithm2.9.9.m1.1.1.3.3.1">:</ci><cn id="algorithm2.9.9.m1.1.1.3.3.2.cmml" type="integer" xref="algorithm2.9.9.m1.1.1.3.3.2">1</cn><apply id="algorithm2.9.9.m1.1.1.3.3.3.cmml" xref="algorithm2.9.9.m1.1.1.3.3.3"><minus id="algorithm2.9.9.m1.1.1.3.3.3.1.cmml" xref="algorithm2.9.9.m1.1.1.3.3.3.1"></minus><apply id="algorithm2.9.9.m1.1.1.3.3.3.2.cmml" xref="algorithm2.9.9.m1.1.1.3.3.3.2"><plus id="algorithm2.9.9.m1.1.1.3.3.3.2.1.cmml" xref="algorithm2.9.9.m1.1.1.3.3.3.2.1"></plus><ci id="algorithm2.9.9.m1.1.1.3.3.3.2.2.cmml" xref="algorithm2.9.9.m1.1.1.3.3.3.2.2">𝑡</ci><ci id="algorithm2.9.9.m1.1.1.3.3.3.2.3.cmml" xref="algorithm2.9.9.m1.1.1.3.3.3.2.3">𝑘</ci></apply><cn id="algorithm2.9.9.m1.1.1.3.3.3.3.cmml" type="integer" xref="algorithm2.9.9.m1.1.1.3.3.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.9.9.m1.1c">i_{1:t+k}\leftarrow i_{1:t+k-1}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.9.9.m1.1d">italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k end_POSTSUBSCRIPT ← italic_i start_POSTSUBSCRIPT 1 : italic_t + italic_k - 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.11.11.5" style="font-size:90%;"> </span><math alttext="append" class="ltx_Math" display="inline" id="algorithm2.10.10.m2.1"><semantics id="algorithm2.10.10.m2.1a"><mrow id="algorithm2.10.10.m2.1.1" xref="algorithm2.10.10.m2.1.1.cmml"><mi id="algorithm2.10.10.m2.1.1.2" mathsize="90%" xref="algorithm2.10.10.m2.1.1.2.cmml">a</mi><mo id="algorithm2.10.10.m2.1.1.1" xref="algorithm2.10.10.m2.1.1.1.cmml">⁢</mo><mi id="algorithm2.10.10.m2.1.1.3" mathsize="90%" xref="algorithm2.10.10.m2.1.1.3.cmml">p</mi><mo id="algorithm2.10.10.m2.1.1.1a" xref="algorithm2.10.10.m2.1.1.1.cmml">⁢</mo><mi id="algorithm2.10.10.m2.1.1.4" mathsize="90%" xref="algorithm2.10.10.m2.1.1.4.cmml">p</mi><mo id="algorithm2.10.10.m2.1.1.1b" xref="algorithm2.10.10.m2.1.1.1.cmml">⁢</mo><mi id="algorithm2.10.10.m2.1.1.5" mathsize="90%" xref="algorithm2.10.10.m2.1.1.5.cmml">e</mi><mo id="algorithm2.10.10.m2.1.1.1c" xref="algorithm2.10.10.m2.1.1.1.cmml">⁢</mo><mi id="algorithm2.10.10.m2.1.1.6" mathsize="90%" xref="algorithm2.10.10.m2.1.1.6.cmml">n</mi><mo id="algorithm2.10.10.m2.1.1.1d" xref="algorithm2.10.10.m2.1.1.1.cmml">⁢</mo><mi id="algorithm2.10.10.m2.1.1.7" mathsize="90%" xref="algorithm2.10.10.m2.1.1.7.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.10.10.m2.1b"><apply id="algorithm2.10.10.m2.1.1.cmml" xref="algorithm2.10.10.m2.1.1"><times id="algorithm2.10.10.m2.1.1.1.cmml" xref="algorithm2.10.10.m2.1.1.1"></times><ci id="algorithm2.10.10.m2.1.1.2.cmml" xref="algorithm2.10.10.m2.1.1.2">𝑎</ci><ci id="algorithm2.10.10.m2.1.1.3.cmml" xref="algorithm2.10.10.m2.1.1.3">𝑝</ci><ci id="algorithm2.10.10.m2.1.1.4.cmml" xref="algorithm2.10.10.m2.1.1.4">𝑝</ci><ci id="algorithm2.10.10.m2.1.1.5.cmml" xref="algorithm2.10.10.m2.1.1.5">𝑒</ci><ci id="algorithm2.10.10.m2.1.1.6.cmml" xref="algorithm2.10.10.m2.1.1.6">𝑛</ci><ci id="algorithm2.10.10.m2.1.1.7.cmml" xref="algorithm2.10.10.m2.1.1.7">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.10.10.m2.1c">append</annotation><annotation encoding="application/x-llamapun" id="algorithm2.10.10.m2.1d">italic_a italic_p italic_p italic_e italic_n italic_d</annotation></semantics></math><span class="ltx_text" id="algorithm2.11.11.6" style="font-size:90%;"> </span><math alttext="i_{t+k}" class="ltx_Math" display="inline" id="algorithm2.11.11.m3.1"><semantics id="algorithm2.11.11.m3.1a"><msub id="algorithm2.11.11.m3.1.1" xref="algorithm2.11.11.m3.1.1.cmml"><mi id="algorithm2.11.11.m3.1.1.2" mathsize="90%" xref="algorithm2.11.11.m3.1.1.2.cmml">i</mi><mrow id="algorithm2.11.11.m3.1.1.3" xref="algorithm2.11.11.m3.1.1.3.cmml"><mi id="algorithm2.11.11.m3.1.1.3.2" mathsize="90%" xref="algorithm2.11.11.m3.1.1.3.2.cmml">t</mi><mo id="algorithm2.11.11.m3.1.1.3.1" mathsize="90%" xref="algorithm2.11.11.m3.1.1.3.1.cmml">+</mo><mi id="algorithm2.11.11.m3.1.1.3.3" mathsize="90%" xref="algorithm2.11.11.m3.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="algorithm2.11.11.m3.1b"><apply id="algorithm2.11.11.m3.1.1.cmml" xref="algorithm2.11.11.m3.1.1"><csymbol cd="ambiguous" id="algorithm2.11.11.m3.1.1.1.cmml" xref="algorithm2.11.11.m3.1.1">subscript</csymbol><ci id="algorithm2.11.11.m3.1.1.2.cmml" xref="algorithm2.11.11.m3.1.1.2">𝑖</ci><apply id="algorithm2.11.11.m3.1.1.3.cmml" xref="algorithm2.11.11.m3.1.1.3"><plus id="algorithm2.11.11.m3.1.1.3.1.cmml" xref="algorithm2.11.11.m3.1.1.3.1"></plus><ci id="algorithm2.11.11.m3.1.1.3.2.cmml" xref="algorithm2.11.11.m3.1.1.3.2">𝑡</ci><ci id="algorithm2.11.11.m3.1.1.3.3.cmml" xref="algorithm2.11.11.m3.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.11.11.m3.1c">i_{t+k}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.11.11.m3.1d">italic_i start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.11.11.7" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm2.12.12">
<span class="ltx_text" id="algorithm2.12.12.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.12.12.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.12.12.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.12.12.4" style="font-size:90%;">
</span><math alttext="\mathbf{r^{s}}\leftarrow\mathbf{r^{s}}+\mathbf{r^{sk}}" class="ltx_Math" display="inline" id="algorithm2.12.12.m1.1"><semantics id="algorithm2.12.12.m1.1a"><mrow id="algorithm2.12.12.m1.1.1" xref="algorithm2.12.12.m1.1.1.cmml"><msup id="algorithm2.12.12.m1.1.1.2" xref="algorithm2.12.12.m1.1.1.2.cmml"><mi id="algorithm2.12.12.m1.1.1.2.2" mathsize="90%" xref="algorithm2.12.12.m1.1.1.2.2.cmml">𝐫</mi><mi id="algorithm2.12.12.m1.1.1.2.3" mathsize="90%" xref="algorithm2.12.12.m1.1.1.2.3.cmml">𝐬</mi></msup><mo id="algorithm2.12.12.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.12.12.m1.1.1.1.cmml">←</mo><mrow id="algorithm2.12.12.m1.1.1.3" xref="algorithm2.12.12.m1.1.1.3.cmml"><msup id="algorithm2.12.12.m1.1.1.3.2" xref="algorithm2.12.12.m1.1.1.3.2.cmml"><mi id="algorithm2.12.12.m1.1.1.3.2.2" mathsize="90%" xref="algorithm2.12.12.m1.1.1.3.2.2.cmml">𝐫</mi><mi id="algorithm2.12.12.m1.1.1.3.2.3" mathsize="90%" xref="algorithm2.12.12.m1.1.1.3.2.3.cmml">𝐬</mi></msup><mo id="algorithm2.12.12.m1.1.1.3.1" mathsize="90%" xref="algorithm2.12.12.m1.1.1.3.1.cmml">+</mo><msup id="algorithm2.12.12.m1.1.1.3.3" xref="algorithm2.12.12.m1.1.1.3.3.cmml"><mi id="algorithm2.12.12.m1.1.1.3.3.2" mathsize="90%" xref="algorithm2.12.12.m1.1.1.3.3.2.cmml">𝐫</mi><mi id="algorithm2.12.12.m1.1.1.3.3.3" mathsize="90%" xref="algorithm2.12.12.m1.1.1.3.3.3.cmml">𝐬𝐤</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.12.12.m1.1b"><apply id="algorithm2.12.12.m1.1.1.cmml" xref="algorithm2.12.12.m1.1.1"><ci id="algorithm2.12.12.m1.1.1.1.cmml" xref="algorithm2.12.12.m1.1.1.1">←</ci><apply id="algorithm2.12.12.m1.1.1.2.cmml" xref="algorithm2.12.12.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.12.12.m1.1.1.2.1.cmml" xref="algorithm2.12.12.m1.1.1.2">superscript</csymbol><ci id="algorithm2.12.12.m1.1.1.2.2.cmml" xref="algorithm2.12.12.m1.1.1.2.2">𝐫</ci><ci id="algorithm2.12.12.m1.1.1.2.3.cmml" xref="algorithm2.12.12.m1.1.1.2.3">𝐬</ci></apply><apply id="algorithm2.12.12.m1.1.1.3.cmml" xref="algorithm2.12.12.m1.1.1.3"><plus id="algorithm2.12.12.m1.1.1.3.1.cmml" xref="algorithm2.12.12.m1.1.1.3.1"></plus><apply id="algorithm2.12.12.m1.1.1.3.2.cmml" xref="algorithm2.12.12.m1.1.1.3.2"><csymbol cd="ambiguous" id="algorithm2.12.12.m1.1.1.3.2.1.cmml" xref="algorithm2.12.12.m1.1.1.3.2">superscript</csymbol><ci id="algorithm2.12.12.m1.1.1.3.2.2.cmml" xref="algorithm2.12.12.m1.1.1.3.2.2">𝐫</ci><ci id="algorithm2.12.12.m1.1.1.3.2.3.cmml" xref="algorithm2.12.12.m1.1.1.3.2.3">𝐬</ci></apply><apply id="algorithm2.12.12.m1.1.1.3.3.cmml" xref="algorithm2.12.12.m1.1.1.3.3"><csymbol cd="ambiguous" id="algorithm2.12.12.m1.1.1.3.3.1.cmml" xref="algorithm2.12.12.m1.1.1.3.3">superscript</csymbol><ci id="algorithm2.12.12.m1.1.1.3.3.2.cmml" xref="algorithm2.12.12.m1.1.1.3.3.2">𝐫</ci><ci id="algorithm2.12.12.m1.1.1.3.3.3.cmml" xref="algorithm2.12.12.m1.1.1.3.3.3">𝐬𝐤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.12.12.m1.1c">\mathbf{r^{s}}\leftarrow\mathbf{r^{s}}+\mathbf{r^{sk}}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.12.12.m1.1d">bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT ← bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT + bold_r start_POSTSUPERSCRIPT bold_sk end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.12.12.5" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.17">
<span class="ltx_text" id="algorithm2.14.17.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.14.17.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.14.17.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.14.17.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.13.13">
<span class="ltx_text" id="algorithm2.13.13.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.13.13.2" style="font-size:90%;">   </span><math alttext="\mathbf{r}\leftarrow\mathbf{r}+\mathbf{r^{s}}" class="ltx_Math" display="inline" id="algorithm2.13.13.m1.1"><semantics id="algorithm2.13.13.m1.1a"><mrow id="algorithm2.13.13.m1.1.1" xref="algorithm2.13.13.m1.1.1.cmml"><mi id="algorithm2.13.13.m1.1.1.2" mathsize="90%" xref="algorithm2.13.13.m1.1.1.2.cmml">𝐫</mi><mo id="algorithm2.13.13.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.13.13.m1.1.1.1.cmml">←</mo><mrow id="algorithm2.13.13.m1.1.1.3" xref="algorithm2.13.13.m1.1.1.3.cmml"><mi id="algorithm2.13.13.m1.1.1.3.2" mathsize="90%" xref="algorithm2.13.13.m1.1.1.3.2.cmml">𝐫</mi><mo id="algorithm2.13.13.m1.1.1.3.1" mathsize="90%" xref="algorithm2.13.13.m1.1.1.3.1.cmml">+</mo><msup id="algorithm2.13.13.m1.1.1.3.3" xref="algorithm2.13.13.m1.1.1.3.3.cmml"><mi id="algorithm2.13.13.m1.1.1.3.3.2" mathsize="90%" xref="algorithm2.13.13.m1.1.1.3.3.2.cmml">𝐫</mi><mi id="algorithm2.13.13.m1.1.1.3.3.3" mathsize="90%" xref="algorithm2.13.13.m1.1.1.3.3.3.cmml">𝐬</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.13.13.m1.1b"><apply id="algorithm2.13.13.m1.1.1.cmml" xref="algorithm2.13.13.m1.1.1"><ci id="algorithm2.13.13.m1.1.1.1.cmml" xref="algorithm2.13.13.m1.1.1.1">←</ci><ci id="algorithm2.13.13.m1.1.1.2.cmml" xref="algorithm2.13.13.m1.1.1.2">𝐫</ci><apply id="algorithm2.13.13.m1.1.1.3.cmml" xref="algorithm2.13.13.m1.1.1.3"><plus id="algorithm2.13.13.m1.1.1.3.1.cmml" xref="algorithm2.13.13.m1.1.1.3.1"></plus><ci id="algorithm2.13.13.m1.1.1.3.2.cmml" xref="algorithm2.13.13.m1.1.1.3.2">𝐫</ci><apply id="algorithm2.13.13.m1.1.1.3.3.cmml" xref="algorithm2.13.13.m1.1.1.3.3"><csymbol cd="ambiguous" id="algorithm2.13.13.m1.1.1.3.3.1.cmml" xref="algorithm2.13.13.m1.1.1.3.3">superscript</csymbol><ci id="algorithm2.13.13.m1.1.1.3.3.2.cmml" xref="algorithm2.13.13.m1.1.1.3.3.2">𝐫</ci><ci id="algorithm2.13.13.m1.1.1.3.3.3.cmml" xref="algorithm2.13.13.m1.1.1.3.3.3">𝐬</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.13.13.m1.1c">\mathbf{r}\leftarrow\mathbf{r}+\mathbf{r^{s}}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.13.13.m1.1d">bold_r ← bold_r + bold_r start_POSTSUPERSCRIPT bold_s end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.13.13.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.14">
<span class="ltx_text ltx_font_bold" id="algorithm2.14.14.2" style="font-size:90%;">return</span><span class="ltx_text" id="algorithm2.14.14.3" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm2.14.14.1" style="font-size:90%;"><math alttext="argsort(-\mathbf{r})[:K]" class="ltx_math_unparsed" display="inline" id="algorithm2.14.14.1.m1.1"><semantics id="algorithm2.14.14.1.m1.1a"><mrow id="algorithm2.14.14.1.m1.1b"><mi id="algorithm2.14.14.1.m1.1.1">a</mi><mi id="algorithm2.14.14.1.m1.1.2">r</mi><mi id="algorithm2.14.14.1.m1.1.3">g</mi><mi id="algorithm2.14.14.1.m1.1.4">s</mi><mi id="algorithm2.14.14.1.m1.1.5">o</mi><mi id="algorithm2.14.14.1.m1.1.6">r</mi><mi id="algorithm2.14.14.1.m1.1.7">t</mi><mrow id="algorithm2.14.14.1.m1.1.8"><mo id="algorithm2.14.14.1.m1.1.8.1" stretchy="false">(</mo><mo id="algorithm2.14.14.1.m1.1.8.2" lspace="0em">−</mo><mi id="algorithm2.14.14.1.m1.1.8.3">𝐫</mi><mo id="algorithm2.14.14.1.m1.1.8.4" stretchy="false">)</mo></mrow><mrow id="algorithm2.14.14.1.m1.1.9"><mo id="algorithm2.14.14.1.m1.1.9.1" stretchy="false">[</mo><mo id="algorithm2.14.14.1.m1.1.9.2" rspace="0.278em">:</mo><mi id="algorithm2.14.14.1.m1.1.9.3">K</mi><mo id="algorithm2.14.14.1.m1.1.9.4" stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="algorithm2.14.14.1.m1.1c">argsort(-\mathbf{r})[:K]</annotation><annotation encoding="application/x-llamapun" id="algorithm2.14.14.1.m1.1d">italic_a italic_r italic_g italic_s italic_o italic_r italic_t ( - bold_r ) [ : italic_K ]</annotation></semantics></math></em><span class="ltx_text" id="algorithm2.14.14.4" style="font-size:90%;">;</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.18">
<span class="ltx_text" id="algorithm2.14.18.1" style="font-size:90%;">  </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.14.18.2" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.14.18.3" style="font-size:90%;">get Top-K</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.19">
<span class="ltx_text" id="algorithm2.14.19.1" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.20">
<span class="ltx_text" id="algorithm2.14.20.1" style="font-size:90%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm2.18.1.1">Algorithm 2</span> </span>Top-K sequential recommendations generation with the RA strategy</figcaption>
</figure>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we present our experimental setup and
empirical results. Our experiments are designed to answer the following research questions:</p>
<dl class="ltx_description" id="S4.I1">
<dt class="ltx_item" id="S4.I1.ix1"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.ix1.1.1.1">RQ1:: </span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1">How well do the autoregressive generation strategies, such as greedy and beam search, perform in the Top-K sequential recommendation task compared to the Top-K prediction approach?</p>
</div>
</dd>
<dt class="ltx_item" id="S4.I1.ix2"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.ix2.1.1.1">RQ2:: </span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S4.I1.ix2.p1">
<p class="ltx_p" id="S4.I1.ix2.p1.1">Do the proposed multi-sequence aggregation strategies outperform the autoregressive generation strategies? How do the hyperparameters affect their performance?</p>
</div>
</dd>
<dt class="ltx_item" id="S4.I1.ix3"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.ix3.1.1.1">RQ3:: </span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S4.I1.ix3.p1">
<p class="ltx_p" id="S4.I1.ix3.p1.1">How significant the computational overhead of multi-sequence aggregation is compared to standard generation approaches?</p>
</div>
</dd>
<dt class="ltx_item" id="S4.I1.ix4"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.ix4.1.1.1">RQ4:: </span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S4.I1.ix4.p1">
<p class="ltx_p" id="S4.I1.ix4.p1.1">How well do all the considered strategies perform on a longer prediction horizon? Do the proposed multi-sequence aggregation strategies perform better in predicting longer-term user preferences?</p>
</div>
</dd>
</dl>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experimental Settings</h3>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Datasets</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">We conduct experiments on six datasets collected from real-world platforms. The datasets vary significantly in domains, sparsity, and types of feedback:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">MovieLens-20M (ML-20M) <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib20" title="">2015</a>)</cite>:</span> This is a movie recommendation dataset, which is widely used for benchmarking sequential recommenders <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib53" title="">2021</a>; Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib11" title="">2020</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib56" title="">2020</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib25" title="">2021</a>; Fischer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib16" title="">2020</a>)</cite>. In this work, ML-20M is the dataset with the largest number of user-item interactions after preprocessing.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Yelp <cite class="ltx_cite ltx_citemacro_citep">(Asghar, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib4" title="">2016</a>)</cite>:</span> This is a business reviews dataset and is another popular benchmark for sequential recommendations <cite class="ltx_cite ltx_citemacro_citep">(Padungkiatwattana et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib30" title="">2022</a>; Amjadi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib3" title="">2021</a>; Qiu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib36" title="">2022</a>)</cite>, and is the sparsest dataset in the list.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">Steam <cite class="ltx_cite ltx_citemacro_citep">(Pathak et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib32" title="">2017</a>)</cite>:</span> This is a dataset collected from Steam, a large online video game distribution platform.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">Gowalla <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib10" title="">2011</a>)</cite>:</span> The dataset from Gowalla – location-based social networking platform, where users share their locations by checking in.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i5.p1.1.1">Twitch-100k <cite class="ltx_cite ltx_citemacro_citep">(Rappaz et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib41" title="">2021</a>)</cite>:</span> This is a dataset of 100 thousand users consuming streaming content on Twitch.
</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i6.p1">
<p class="ltx_p" id="S4.I2.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i6.p1.1.1">BeerAdvocate <cite class="ltx_cite ltx_citemacro_citep">(McAuley et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib28" title="">2012</a>)</cite>:</span> This dataset consists of beer reviews from BeerAdvocate and has the highest average interaction length of all datasets.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">As in previous publications <cite class="ltx_cite ltx_citemacro_citep">(Tang and Wang, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib46" title="">2018</a>; Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib22" title="">2018</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib44" title="">2019</a>)</cite>, the presence of a review or rating is considered implicit feedback.
For testing a model’s ability to make long-term recommendations, it’s essential to use datasets with a long enough history of interactions for each user. We filter out users with fewer than 20 interaction records for these purposes. Following common practice <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib55" title="">2019</a>; Rendle et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib42" title="">2010</a>)</cite>, we also discard unpopular items with less than five interactions. The final statistics of datasets are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.T1" title="Table 1 ‣ 4.1.1. Datasets ‣ 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.3.1.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text ltx_font_bold" id="S4.T1.4.2" style="font-size:90%;">Statistics of the datasets after preprocessing.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T1.5" style="width:433.6pt;height:159.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(45.3pt,-16.6pt) scale(1.26419593067967,1.26419593067967) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T1.5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.2.1">#Users</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.3.1">#Items</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.4.1">#Interactions</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.5.1">Avg. length</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.6.1">Density</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.5.1.2.1.1">ML-20M</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.5.1.2.1.2">138,476</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.5.1.2.1.3">18,345</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.5.1.2.1.4">19,983,706</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.5.1.2.1.5">144.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.5.1.2.1.6">0.79%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.3.2.1">Yelp</th>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.3.2.2">42,429</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.3.2.3">137,039</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.3.2.4">2,294,804</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.3.2.5">54.1</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.3.2.6">0.04%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.4.3.1">Steam</th>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.4.3.2">33,375</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.4.3.3">11,945</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.4.3.4">1,448,441</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.4.3.5">43.4</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.4.3.6">0.36%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.5.4.1">Gowalla</th>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.5.4.2">27,516</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.5.4.3">173,511</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.5.4.4">2,627,663</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.5.4.5">95.5</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.5.4.6">0.06%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.6.5.1">Twitch-100k</th>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.6.5.2">20,899</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.6.5.3">28,339</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.6.5.4">1,577,168</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.6.5.5">75.5</td>
<td class="ltx_td ltx_align_right" id="S4.T1.5.1.6.5.6">0.27%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T1.5.1.7.6.1">BeerAdvocate</th>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T1.5.1.7.6.2">7,606</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T1.5.1.7.6.3">22,307</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T1.5.1.7.6.4">1,409,494</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T1.5.1.7.6.5">185.3</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T1.5.1.7.6.6">0.83%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Evaluation</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">We applied the following recommendation list generation constraints: we do not generate items already presented in the user history and forbid items repetition in the generated sequence (except for the singe-sequence generation step in RA approach, see section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS4" title="3.2.4. Proposed multi-sequence aggregation strategies. ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">3.2.4</span></a>).</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.3">We follow <cite class="ltx_cite ltx_citemacro_citep">(Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>)</cite> and hold the last <math alttext="N" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.1.m1.1"><semantics id="S4.SS1.SSS2.p2.1.m1.1a"><mi id="S4.SS1.SSS2.p2.1.m1.1.1" xref="S4.SS1.SSS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.1.m1.1b"><ci id="S4.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.1.m1.1d">italic_N</annotation></semantics></math> items of each user interaction sequence for validation and testing with <math alttext="N=10" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.2.m2.1"><semantics id="S4.SS1.SSS2.p2.2.m2.1a"><mrow id="S4.SS1.SSS2.p2.2.m2.1.1" xref="S4.SS1.SSS2.p2.2.m2.1.1.cmml"><mi id="S4.SS1.SSS2.p2.2.m2.1.1.2" xref="S4.SS1.SSS2.p2.2.m2.1.1.2.cmml">N</mi><mo id="S4.SS1.SSS2.p2.2.m2.1.1.1" xref="S4.SS1.SSS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS2.p2.2.m2.1.1.3" xref="S4.SS1.SSS2.p2.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.2.m2.1b"><apply id="S4.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p2.2.m2.1.1"><eq id="S4.SS1.SSS2.p2.2.m2.1.1.1.cmml" xref="S4.SS1.SSS2.p2.2.m2.1.1.1"></eq><ci id="S4.SS1.SSS2.p2.2.m2.1.1.2.cmml" xref="S4.SS1.SSS2.p2.2.m2.1.1.2">𝑁</ci><cn id="S4.SS1.SSS2.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.SSS2.p2.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.2.m2.1c">N=10</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.2.m2.1d">italic_N = 10</annotation></semantics></math>. All previous interactions are used for training. Data with the last <math alttext="N" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.3.m3.1"><semantics id="S4.SS1.SSS2.p2.3.m3.1a"><mi id="S4.SS1.SSS2.p2.3.m3.1.1" xref="S4.SS1.SSS2.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.3.m3.1b"><ci id="S4.SS1.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS2.p2.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.3.m3.1d">italic_N</annotation></semantics></math> items is further split into validation and test set randomly by users. Hyperparameter tuning is performed on the validation set, and the final performance is evaluated on the test set.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p3">
<p class="ltx_p" id="S4.SS1.SSS2.p3.1">For performance evaluation, we use three commonly used ranking metrics: Normalized Discounted Cumulative Gain (NDCG@10), Recall@10, and Mean Average Precision (MAP@10) from the popular library Recommenders<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/recommenders-team/recommenders" title="">https://github.com/recommenders-team/recommenders</a></span></span></span>. In addition, we look at the performance for each position in a test sequence separately. In this case, ground truth consists of only one item on the corresponding position in the original ground truth sequence. Such an approach was used in <cite class="ltx_cite ltx_citemacro_citep">(Villatel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib48" title="">2018</a>)</cite>. This is done to more thoroughly evaluate how generation strategy influences predictions on longer-term horizons.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Generative model (GPT-2)</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">We use GPT-2 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib39" title="">2019</a>)</cite> model in our experiments as it is a popular generative model architecturally close to SASRec <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib34" title="">2023a</a>)</cite>. To be able to use a wide range of sequence generation methods (decoding strategies) out of the box<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/blog/how-to-generate" title="">https://huggingface.co/blog/how-to-generate</a></span></span></span> we utilized its implementation in HuggingFace Transformers library <cite class="ltx_cite ltx_citemacro_citep">(Wolf et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib52" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p2">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1">We train GPT-2 from scratch using standard language modeling objective (with item IDs instead of token IDs as inputs). The model aims to predict the input sequence shifted by one item to the left. Item probabilities are modeled with softmax operation over model outputs. The model is trained with the cross-entropy loss, which corresponds to the maximum likelihood principle, and is used in language modeling and many sequential recommendations models <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib44" title="">2019</a>; Klenitskiy and Vasilev, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib23" title="">2023</a>; Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib34" title="">2023a</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4. </span>Baseline methods</h4>
<div class="ltx_para" id="S4.SS1.SSS4.p1">
<p class="ltx_p" id="S4.SS1.SSS4.p1.1">The proposed generation strategies may be applied to any autoregressive model, which can return the next-item probability distribution. Thus, our main goal is to compare suggested generation approaches with standard prediction approach without generation. According to this, our primary baseline for comparison is the same <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS4.p1.1.1">GPT-2</span> model with a standard Top-K prediction strategy.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS4.p2">
<p class="ltx_p" id="S4.SS1.SSS4.p2.1">Additional baselines are <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS4.p2.1.1">BPR-MF</span> (classic matrix factorization-based approach with a
pairwise BPR loss) and two the most widely used state-of-the-art baselines in sequential recommendations - <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS4.p2.1.2">SASRec</span> and <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS4.p2.1.3">BERT4Rec</span>. In recent papers <cite class="ltx_cite ltx_citemacro_citep">(Klenitskiy and Vasilev, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib23" title="">2023</a>; Wilm et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib51" title="">2023</a>; Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib35" title="">2023b</a>)</cite>, it was shown that the SASRec model could achieve much better performance if trained with the cross-entropy loss or sampled cross-entropy loss instead of original binary cross-entropy loss. So we train SASRec with the cross-entropy loss and refer to it as <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS4.p2.1.4">SASRec+</span> following <cite class="ltx_cite ltx_citemacro_citep">(Klenitskiy and Vasilev, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib23" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.5. </span>Implementation Details</h4>
<div class="ltx_para" id="S4.SS1.SSS5.p1">
<p class="ltx_p" id="S4.SS1.SSS5.p1.1">We choose the hidden representation size to be equal to 256 for MovieLens-20M and 64 for all other datasets based on the results of hyperparameter tuning.
For all models, we use a dropout rate of 0.1, two self-attention blocks, and one attention head (except for two attention heads for BERT4Rec). The masking probability for BERT4Rec was set to 0.2. These settings are consistent with parameters used in previous papers <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib22" title="">2018</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib44" title="">2019</a>; Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib33" title="">2022</a>)</cite>. We set a maximum sequence length of 128. All models were trained with a batch size of 64 and Adam optimizer with a learning rate 1e-3. We use the early stopping criterion to determine the number of training epochs.
For temperature sampling and Reciprocal Rank Aggregation strategy, there is an additional parameter top-k to cut off long-tail items. We set its value to 10 as we find this to work the best experimentally (see section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3.SSS1" title="4.3.1. Choosing top-k for reciprocal rank aggregation. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>).
For BPR-MF, we use fast GPU implementation from the Implicit library <cite class="ltx_cite ltx_citemacro_citep">(Frederickson, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib17" title="">2018</a>)</cite> and tuned the number of latent components, regularization, and the learning rate with Optuna <cite class="ltx_cite ltx_citemacro_citep">(Akiba et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#bib.bib2" title="">2019</a>)</cite>.
The code to reproduce experiments is provided in the corresponding GitHub repository<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/dalibra/autoregressive-generation-strategies-longterm-seqrec" title="">https://github.com/dalibra/autoregressive-generation-strategies-longterm-seqrec</a></span></span></span>.
HuggingFace Transformers sequence generation functionality was used in this code. All experiments were conducted using an NVIDIA Tesla V100 GPU.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Single Sequence Generation</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We tuned the main parameters for beam search and temperature sampling (number of beams and temperature respectively) and found that none of these strategies outperform simple greedy decoding. This is expected for temperature sampling, as sampling means taking more random and less optimal predictions. However, it is less expected for beam search and contradicts experience from text generation. We analyze these results in the following sections.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Temperature sampling.</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F1" title="Figure 1 ‣ 4.2.2. Beam search. ‣ 4.2. Single Sequence Generation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates performance for different temperature values. A low-temperature setting is effectively equivalent to greedy decoding. As the temperature increases, model performance degrades. This degradation occurs because sampling at higher temperatures introduces a greater degree of randomness into the prediction process. Instead of prioritizing the most probable item, the model selects items with lower confidence levels at each step, leading to a decline in performance metrics. Despite this drawback, sampling with high enough temperatures can enhance the diversity recommendations and plays an important role in multi-sequence aggregation strategies.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Beam search.</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">The observation that beam search, despite its efficiency in NLP tasks, does not outperform greedy decoding in the field of recommender systems is a less expected result. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F1" title="Figure 1 ‣ 4.2.2. Beam search. ‣ 4.2. Single Sequence Generation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates that the optimal number of beams is one, which corresponds to greedy generation.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1">To explain this observation, we note that in text generation the goal is to produce plausible and coherent text. Each step in the sequence is equally important, with the end of the sentence requiring as much accuracy and relevance as the beginning. In the context of recommender systems, the situation is different. Predicting the initial steps is inherently simpler while predicting subsequent steps is significantly more challenging due to an error accumulation. In the process of choosing the optimal beam, beam search considers the probabilities of later items and makes less probable choices for the first steps. While this approach might slightly improve the quality of later steps, early step errors lead to overall performance degradation. With the greedy approach, on the contrary, the most probable items are chosen for the first steps, which leads to better results.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1">To confirm this explanation, we measure HitRate for each generation step separately in both greedy and beam search scenarios (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.T2" title="Table 2 ‣ 4.2.2. Beam search. ‣ 4.2. Single Sequence Generation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a>). In the first step, the difference is significant, with beam search severely degrading the quality due to choosing less probable items. This gap diminishes in later steps, and towards the sequence’s end, beam search performs better.</p>
</div>
<figure class="ltx_figure" id="S4.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F1.1" style="width:212.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="245" id="S4.F1.1.g1" src="extracted/5845354/recsys_content/images/temp.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.1.1.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F1.1.2.2" style="font-size:90%;">Temperature sampling. The left point is close to greedy decoding.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F1.2" style="width:212.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="245" id="S4.F1.2.g1" src="extracted/5845354/recsys_content/images/num_beams.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.2.1.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F1.2.2.2" style="font-size:90%;">Beam search. The leftmost point is equivalent to greedy decoding.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.4.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S4.F1.5.2" style="font-size:90%;">Comparison of different generation strategies and their impact on NDCG@10 on Movielens-20M and Yelp datasets. The horizontal dashed lines correspond to the Top-K prediction strategy without generation.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F1.6">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F1.7">[Comparison of different generation strategies]Comparison of different generation strategiesy</p>
</div>
</div>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.3.1.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text ltx_font_bold" id="S4.T2.4.2" style="font-size:90%;">Dependence of the HitRate on generation step for Steam dataset.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T2.5" style="width:433.6pt;height:56.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.9pt,-1.3pt) scale(1.04767406361042,1.04767406361042) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T2.5.1.1.1.1"><span class="ltx_text" id="S4.T2.5.1.1.1.1.1" style="font-size:90%;">Generation step #</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.2"><span class="ltx_text" id="S4.T2.5.1.1.1.2.1" style="font-size:90%;">1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.3"><span class="ltx_text" id="S4.T2.5.1.1.1.3.1" style="font-size:90%;">2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.4"><span class="ltx_text" id="S4.T2.5.1.1.1.4.1" style="font-size:90%;">3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.5"><span class="ltx_text" id="S4.T2.5.1.1.1.5.1" style="font-size:90%;">4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.6"><span class="ltx_text" id="S4.T2.5.1.1.1.6.1" style="font-size:90%;">5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.7"><span class="ltx_text" id="S4.T2.5.1.1.1.7.1" style="font-size:90%;">6</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.8"><span class="ltx_text" id="S4.T2.5.1.1.1.8.1" style="font-size:90%;">7</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.9"><span class="ltx_text" id="S4.T2.5.1.1.1.9.1" style="font-size:90%;">8</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.10"><span class="ltx_text" id="S4.T2.5.1.1.1.10.1" style="font-size:90%;">9</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.1.1.1.11"><span class="ltx_text" id="S4.T2.5.1.1.1.11.1" style="font-size:90%;">10</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.5.1.2.1.1">
<span class="ltx_text" id="S4.T2.5.1.2.1.1.1" style="font-size:90%;">Greedy</span><sub class="ltx_sub" id="S4.T2.5.1.2.1.1.2"><span class="ltx_text" id="S4.T2.5.1.2.1.1.2.1" style="font-size:90%;">GPT-2</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.2"><span class="ltx_text" id="S4.T2.5.1.2.1.2.1" style="font-size:90%;">0.101</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.3"><span class="ltx_text" id="S4.T2.5.1.2.1.3.1" style="font-size:90%;">0.083</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.4"><span class="ltx_text" id="S4.T2.5.1.2.1.4.1" style="font-size:90%;">0.077</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.5"><span class="ltx_text" id="S4.T2.5.1.2.1.5.1" style="font-size:90%;">0.074</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.6"><span class="ltx_text" id="S4.T2.5.1.2.1.6.1" style="font-size:90%;">0.070</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.7"><span class="ltx_text" id="S4.T2.5.1.2.1.7.1" style="font-size:90%;">0.066</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.8"><span class="ltx_text" id="S4.T2.5.1.2.1.8.1" style="font-size:90%;">0.061</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.9"><span class="ltx_text" id="S4.T2.5.1.2.1.9.1" style="font-size:90%;">0.056</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.10"><span class="ltx_text" id="S4.T2.5.1.2.1.10.1" style="font-size:90%;">0.055</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.1.11"><span class="ltx_text" id="S4.T2.5.1.2.1.11.1" style="font-size:90%;">0.050</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.5.1.3.2.1">
<span class="ltx_text" id="S4.T2.5.1.3.2.1.1" style="font-size:90%;">Beam search</span><sub class="ltx_sub" id="S4.T2.5.1.3.2.1.2"><span class="ltx_text" id="S4.T2.5.1.3.2.1.2.1" style="font-size:90%;">GPT-2</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.2"><span class="ltx_text" id="S4.T2.5.1.3.2.2.1" style="font-size:90%;">0.076</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.3"><span class="ltx_text" id="S4.T2.5.1.3.2.3.1" style="font-size:90%;">0.075</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.4"><span class="ltx_text" id="S4.T2.5.1.3.2.4.1" style="font-size:90%;">0.074</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.5"><span class="ltx_text" id="S4.T2.5.1.3.2.5.1" style="font-size:90%;">0.070</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.6"><span class="ltx_text" id="S4.T2.5.1.3.2.6.1" style="font-size:90%;">0.063</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.7"><span class="ltx_text" id="S4.T2.5.1.3.2.7.1" style="font-size:90%;">0.059</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.8"><span class="ltx_text" id="S4.T2.5.1.3.2.8.1" style="font-size:90%;">0.060</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.9"><span class="ltx_text" id="S4.T2.5.1.3.2.9.1" style="font-size:90%;">0.053</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.10"><span class="ltx_text" id="S4.T2.5.1.3.2.10.1" style="font-size:90%;">0.056</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.2.11"><span class="ltx_text" id="S4.T2.5.1.3.2.11.1" style="font-size:90%;">0.057</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Multi-Sequence Aggregation</h3>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Choosing top-k for reciprocal rank aggregation.</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">When we use temperature sampling and reciprocal rank aggregation, there is an additional hyperparameter to tune - top-k (see section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S3.SS2.SSS3" title="3.2.3. Commonly used autoregressive generation strategies ‣ 3.2. Generation strategies ‣ 3. Proposed approach ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>). The best top-k value can depend on temperature. So, we perform a grid search for top-k and temperature for reciprocal rank aggregation with 30 sequences on two datasets, MovieLens-20M and Yelp. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F2" title="Figure 2 ‣ 4.3.1. Choosing top-k for reciprocal rank aggregation. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a>. For low-temperature performance for different top-k values is the same. With lower temperatures, only the most relevant items are generated, which makes the generated sequences more similar, and thus, aggregation of those sequences does not allow to to achieve competitive quality. But for higher temperature values, dependence on top-k becomes significant. With high top-k values (or without top-k sampling), the model generates more irrelevant items which leads to a decrease in quality. We choose top-k=10 for all experiments with the Reciprocal Rank Aggregation strategy based on the grid search results.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="232" id="S4.F2.g1" src="extracted/5845354/recsys_content/images/top_k.png" width="240"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">NDCG@10 for different top-k and temperature values. Reciprocal Rank Aggregation with 30 sequences.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F2.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.5">[NDCG for different top-k and temperature values]NDCG for different top-k and temperature values

</p>
</div>
</div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Dependency on temperature value.</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">When we aggregate multiple sequences, sampling with temperature turns from weakness to strength. To take advantage of combining several predictions, we need to generate diverse enough sequences, thus, relatively high temperature values are desirable. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F3" title="Figure 3 ‣ 4.3.2. Dependency on temperature value. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates NDCG@10 for different temperature values for proposed aggregation strategies on all datasets. We chose 30 sequences for aggregation as a reasonable trade-off between quality and speed. As shown in section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS3.SSS3" title="4.3.3. Dependency on the number of sequences. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4.3.3</span></a>, taking more sequences won’t result in significant improvements.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1">For MovieLens-20M, Yelp, BeerAdvocate, and Steam, both aggregation strategies consistently outperform standard Top-K prediction for a wide range of temperature values. There is not enough diversity for too low temperature, while for too high temperature, there is too much randomness, so proper tuning of this parameter is essential. The Relevance Aggregation strategy shows better results than the Reciprocal Rank Aggregation on all datasets except for Gowalla.</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="220" id="S4.F3.g1" src="extracted/5845354/recsys_content/images/temp_agg.png" width="479"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">NDCG@10 for different values of temperature. Multi-sequence aggregation with 30 sequences on all datasets. The horizontal dashed line corresponds to the Top-K prediction strategy without generation.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S4.F3.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S4.F3.5">[NDCG for different values of temperature]NDCG for different values of temperature</p>
</div>
</div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>Dependency on the number of sequences.</h4>
<div class="ltx_para" id="S4.SS3.SSS3.p1">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F4" title="Figure 4 ‣ 4.3.3. Dependency on the number of sequences. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates NDCG@10 for different number of sequences to aggregate on MovieLens-20M and Yelp datasets. The results for both aggregation strategies are very similar. Metrics are constantly growing with the addition of sequences, but most of the improvement is achieved in the beginning. This result is expected because aggregating multiple sequences acts are similar to the models’ ensemble. Around 30 sequences, performance saturates and starts to grow slower, so we fixed this number of sequences for the other experiments. Certainly, there is a trade-off between performance improvement and the additional computational cost of adding more sequences. Aggregating too many sequences will not be practically useful.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.1" style="width:212.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="197" id="S4.F4.1.g1" src="extracted/5845354/recsys_content/images/num_seq.png" width="432"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.1.1.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F4.1.2.2" style="font-size:90%;">NDCG@10 for a different number of sequences.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.2" style="width:212.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="197" id="S4.F4.2.g1" src="extracted/5845354/recsys_content/images/time.png" width="432"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.2.1.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F4.2.2.2" style="font-size:90%;">Prediction time for a single user for different numbers of sequences in milliseconds.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.4.1.1" style="font-size:90%;">Figure 4</span>. </span><span class="ltx_text" id="S4.F4.5.2" style="font-size:90%;">Comparative analysis of different multi-sequence aggregation strategies with the best temperature on Movielens-20M and Yelp datasets. The vertical dashed line marks the number of sequences equal to 30, which was used in other experiments.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F4.6">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F4.7">[Comparative analysis of different multi-sequence aggregation strategies]Comparative analysis of different multi-sequence aggregation strategies</p>
</div>
</div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4. </span>Inference speed considerations.</h4>
<div class="ltx_para" id="S4.SS3.SSS4.p1">
<p class="ltx_p" id="S4.SS3.SSS4.p1.1">Generating multiple sequences with subsequent aggregation brings additional computation costs compared with the baseline Top-K prediction approach. We report an inference time for the entire set of users on Movielens-20M and Yelp datasets in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.T3" title="Table 3 ‣ 4.3.4. Inference speed considerations. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">3</span></a>. The computational overhead of aggregation strategies for the entire test set with fixed GPU resources is significant.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS4.p2">
<p class="ltx_p" id="S4.SS3.SSS4.p2.1">However, in real-world systems, inference is highly parallelized by users. Besides, multiple sequence generation could be performed in parallel for a single user, so the latency overhead is manageable and could be further reduced. We analyzed the inference time per user based on the number of generated sequences (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F4" title="Figure 4 ‣ 4.3.3. Dependency on the number of sequences. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4</span></a>) and confirmed that the dependence is close to linear with a relatively slight slope. The inference time for 30 sequences is only 1.5 times longer than the inference time for one sequence. In addition, the inference time per user for 30 sequences is less than 50 ms, which demonstrates the efficiency of the proposed approach in terms of latency. This paves the way for further refinement and potential deployment of multi-sequence aggregation strategies in industrial applications.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.3.1.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text ltx_font_bold" id="S4.T3.4.2" style="font-size:90%;">Prediction time in seconds for entire set of users on Movielens-20M and Yelp datasets. For the Reciprocal Rank Aggregation and Relevance Aggregation strategies, the number of sequences equals 30. The test batch sizes for the Movielens-20M and Yelp are set at 72 and 12, respectively.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T3.5" style="width:346.9pt;height:70.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(41.2pt,-8.4pt) scale(1.31108527878811,1.31108527878811) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.1.1.1.1"><span class="ltx_text" id="S4.T3.5.1.1.1.1.1" style="font-size:90%;">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.1.1.1.2"><span class="ltx_text" id="S4.T3.5.1.1.1.2.1" style="font-size:90%;">GPT-2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.1.1.1.3">
<span class="ltx_text" id="S4.T3.5.1.1.1.3.1" style="font-size:90%;">Greedy</span><sub class="ltx_sub" id="S4.T3.5.1.1.1.3.2"><span class="ltx_text" id="S4.T3.5.1.1.1.3.2.1" style="font-size:90%;">GPT-2</span></sub>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.1.1.1.4">
<span class="ltx_text" id="S4.T3.5.1.1.1.4.1" style="font-size:90%;">RRA</span><sub class="ltx_sub" id="S4.T3.5.1.1.1.4.2"><span class="ltx_text" id="S4.T3.5.1.1.1.4.2.1" style="font-size:90%;">GPT-2</span></sub>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.1.1.1.5">
<span class="ltx_text" id="S4.T3.5.1.1.1.5.1" style="font-size:90%;">RA</span><sub class="ltx_sub" id="S4.T3.5.1.1.1.5.2"><span class="ltx_text" id="S4.T3.5.1.1.1.5.2.1" style="font-size:90%;">GPT-2</span></sub>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.1.2.1.1"><span class="ltx_text" id="S4.T3.5.1.2.1.1.1" style="font-size:90%;">ML-20M</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.1.2.1.2"><span class="ltx_text" id="S4.T3.5.1.2.1.2.1" style="font-size:90%;">32</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.1.2.1.3"><span class="ltx_text" id="S4.T3.5.1.2.1.3.1" style="font-size:90%;">89</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.1.2.1.4"><span class="ltx_text" id="S4.T3.5.1.2.1.4.1" style="font-size:90%;">1281</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.1.2.1.5"><span class="ltx_text" id="S4.T3.5.1.2.1.5.1" style="font-size:90%;">874</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T3.5.1.3.2.1"><span class="ltx_text" id="S4.T3.5.1.3.2.1.1" style="font-size:90%;">Yelp</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T3.5.1.3.2.2"><span class="ltx_text" id="S4.T3.5.1.3.2.2.1" style="font-size:90%;">31</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.5.1.3.2.3"><span class="ltx_text" id="S4.T3.5.1.3.2.3.1" style="font-size:90%;">122</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.5.1.3.2.4"><span class="ltx_text" id="S4.T3.5.1.3.2.4.1" style="font-size:90%;">709</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.5.1.3.2.5"><span class="ltx_text" id="S4.T3.5.1.3.2.5.1" style="font-size:90%;">570</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.4.2.1" style="font-size:90%;">Table 4</span>. </span><span class="ltx_text ltx_font_bold" id="S4.T4.2.1" style="font-size:90%;">Performance comparison on all datasets. Bold scores are the best in the baselines/proposed strategies subgroups, while underlined scores are the second best. The last column represents the relative improvement of the best-proposed strategy over the best baseline. The symbol * denotes the statistical significance via paired t-test at <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S4.T4.2.1.m1.1"><semantics id="S4.T4.2.1.m1.1b"><mrow id="S4.T4.2.1.m1.1.1" xref="S4.T4.2.1.m1.1.1.cmml"><mi id="S4.T4.2.1.m1.1.1.2" xref="S4.T4.2.1.m1.1.1.2.cmml">p</mi><mo id="S4.T4.2.1.m1.1.1.1" xref="S4.T4.2.1.m1.1.1.1.cmml">&lt;</mo><mn id="S4.T4.2.1.m1.1.1.3" xref="S4.T4.2.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.1.m1.1c"><apply id="S4.T4.2.1.m1.1.1.cmml" xref="S4.T4.2.1.m1.1.1"><lt id="S4.T4.2.1.m1.1.1.1.cmml" xref="S4.T4.2.1.m1.1.1.1"></lt><ci id="S4.T4.2.1.m1.1.1.2.cmml" xref="S4.T4.2.1.m1.1.1.2">𝑝</ci><cn id="S4.T4.2.1.m1.1.1.3.cmml" type="float" xref="S4.T4.2.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.1.m1.1d">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.1.m1.1e">italic_p &lt; 0.05</annotation></semantics></math> when comparing the proposed strategy performance with the best baseline. GPT-2 stands for Top-K prediction strategy, Greedy<sub class="ltx_sub" id="S4.T4.2.1.1">GPT-2</sub> - greedy decoding, RRA<sub class="ltx_sub" id="S4.T4.2.1.2">GPT-2</sub> - Reciprocal Rank Aggregation, RA<sub class="ltx_sub" id="S4.T4.2.1.3">GPT-2</sub>- Relevance Aggregation.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.5" style="width:346.9pt;height:201.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-120.4pt,70.1pt) scale(0.590239471834447,0.590239471834447) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.5.1.1.1.2">Metric</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.1.1.1.3">BPR-MF</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.1.1.1.4">BERT4Rec</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.1.1.1.5">SASRec+</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.5.1.1.1.6">GPT-2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.1.1.1.7">Greedy<sub class="ltx_sub" id="S4.T4.5.1.1.1.7.1">GPT-2</sub>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.1.1.1.8">RRA<sub class="ltx_sub" id="S4.T4.5.1.1.1.8.1">GPT-2</sub>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.5.1.1.1.9">RA<sub class="ltx_sub" id="S4.T4.5.1.1.1.9.1">GPT-2</sub>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.5.1.1.1.10">Improv.</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.5.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.2.1.1" rowspan="3"><span class="ltx_text" id="S4.T4.5.1.2.1.1.1">ML-20M</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.2.1.2">NDCG@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.2.1.3">0.0732</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.2.1.4">0.1713</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.2.1.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.2.1.5.1">0.1852</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.2.1.6"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.2.1.6.1">0.1876</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.2.1.7">0.1897*</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.2.1.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.2.1.8.1">0.2103*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.2.1.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.2.1.9.1">0.2280*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.2.1.10">21.54%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.3.2">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.3.2.1">Recall@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.3.2.2">0.0682</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.3.2.3">0.1553</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.3.2.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.3.2.4.1">0.1677</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.3.2.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.3.2.5.1">0.1693</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.3.2.6">0.1691</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.3.2.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.3.2.7.1">0.1933*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.3.2.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.3.2.8.1">0.2073*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.3.2.9">22.45%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.4.3">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.4.3.1">MAP@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.4.3.2">0.0313</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.4.3.3">0.0872</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.4.3.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.4.3.4.1">0.0961</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.4.3.5.1">0.0979</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.4.3.6">0.1055*</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.4.3.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.4.3.7.1">0.1165*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.4.3.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.4.3.8.1">0.1277*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.4.3.9">30.44%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.5.4.1" rowspan="3"><span class="ltx_text" id="S4.T4.5.1.5.4.1.1">Yelp</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.5.4.2">NDCG@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.5.4.3">0.0179</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.5.4.4">0.0268</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.5.4.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.5.4.5.1">0.0301</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.5.4.6"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.4.6.1">0.0305</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.5.4.7">0.0310*</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.5.4.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.5.4.8.1">0.0323*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.5.4.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.4.9.1">0.0339*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.5.4.10">11.15%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.6.5">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.6.5.1">Recall@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.6.5.2">0.0161</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.6.5.3">0.0253</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.6.5.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.6.5.4.1">0.0283</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.6.5.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.6.5.5.1">0.0286</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.6.5.6">0.0293*</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.6.5.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.6.5.7.1">0.0304*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.6.5.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.6.5.8.1">0.0315*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.6.5.9">10.14%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.7.6">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.7.6.1">MAP@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.7.6.2">0.0058</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.7.6.3">0.0091</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.7.6.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.7.6.4.1">0.0105</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.7.6.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.7.6.5.1">0.0106</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.7.6.6">0.0109*</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.7.6.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.7.6.7.1">0.0113*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.7.6.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.7.6.8.1">0.0119*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.7.6.9">12.26%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.8.7.1" rowspan="3"><span class="ltx_text" id="S4.T4.5.1.8.7.1.1">Steam</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.8.7.2">NDCG@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.8.7.3">0.0434</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.8.7.4"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.8.7.4.1">0.0689</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.8.7.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.8.7.5.1">0.0682</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.8.7.6">0.0657</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.8.7.7">0.0706*</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.8.7.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.8.7.8.1">0.0743*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.8.7.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.8.7.9.1">0.0777*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.8.7.10">12.77%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.9.8">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.9.8.1">Recall@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.9.8.2">0.0395</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.9.8.3"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.8.3.1">0.0621</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.9.8.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.9.8.4.1">0.0608</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.9.8.5">0.0586</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.9.8.6">0.0644*</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.9.8.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.9.8.7.1">0.0681*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.9.8.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.8.8.1">0.0698*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.9.8.9">12.40%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.10.9">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.10.9.1">MAP@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.10.9.2">0.0156</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.10.9.3"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.10.9.3.1">0.0258</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.10.9.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.10.9.4.1">0.0257</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.10.9.5">0.0248</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.10.9.6">0.0271*</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.10.9.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.10.9.7.1">0.0287*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.10.9.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.10.9.8.1">0.0303*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.10.9.9">17.44%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.11.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.11.10.1" rowspan="3"><span class="ltx_text" id="S4.T4.5.1.11.10.1.1">Gowalla</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.11.10.2">NDCG@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.11.10.3">0.0119</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.11.10.4">0.0296</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.11.10.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.11.10.5.1">0.0470</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.11.10.6"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.11.10.6.1">0.0471</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.11.10.7">0.0430</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.11.10.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.11.10.8.1">0.0477</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.11.10.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.11.10.9.1">0.0480*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.11.10.10">1.91%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.12.11">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.12.11.1">Recall@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.12.11.2">0.0085</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.12.11.3">0.0260</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.12.11.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.12.11.4.1">0.0402</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.12.11.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.12.11.5.1">0.0404</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.12.11.6">0.0355</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.12.11.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.12.11.7.1">0.0411*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.12.11.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.12.11.8.1">0.0414*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.12.11.9">2.48%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.13.12">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.13.12.1">MAP@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.13.12.2">0.0033</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.13.12.3">0.0122</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.13.12.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.13.12.4.1">0.0207</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.13.12.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.13.12.5.1">0.0209</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.13.12.6">0.0195</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.13.12.7"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.13.12.7.1">0.0210</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.13.12.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.13.12.8.1">0.0207</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.13.12.9">0.48%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.14.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.14.13.1" rowspan="3"><span class="ltx_text" id="S4.T4.5.1.14.13.1.1">Twitch-100k</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.14.13.2">NDCG@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.14.13.3">0.0822</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.14.13.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.14.13.4.1">0.0849</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.14.13.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.14.13.5.1">0.0853</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.14.13.6">0.0847</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.14.13.7">0.0852</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.14.13.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.14.13.8.1">0.0863</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.14.13.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.14.13.9.1">0.0882*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.14.13.10">3.40%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.15.14">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.15.14.1">Recall@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.15.14.2">0.0514</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.15.14.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.15.14.3.1">0.0726</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.15.14.4"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.15.14.4.1">0.0728</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.15.14.5">0.0721</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.15.14.6">0.0732</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.15.14.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.15.14.7.1">0.0740*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.15.14.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.15.14.8.1">0.0745*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.15.14.9">2.34%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.16.15">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.16.15.1">MAP@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.16.15.2">0.0275</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.16.15.3"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.16.15.3.1">0.0401</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.16.15.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.16.15.4.1">0.0397</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.16.15.5">0.0392</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.16.15.6">0.0394</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.16.15.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.16.15.7.1">0.0399</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.16.15.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.16.15.8.1">0.0416*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.16.15.9">3.74%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.17.16">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.5.1.17.16.1" rowspan="3"><span class="ltx_text" id="S4.T4.5.1.17.16.1.1">BeerAdvocate</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.17.16.2">NDCG@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.17.16.3">0.0358</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.17.16.4">0.0407</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.17.16.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.17.16.5.1">0.0514</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.17.16.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.17.16.6.1">0.0498</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.17.16.7">0.0476</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.17.16.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.17.16.8.1">0.0537*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.5.1.17.16.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.17.16.9.1">0.0569*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.5.1.17.16.10">10.70%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.18.17">
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.18.17.1">Recall@10</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.18.17.2">0.0328</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.18.17.3">0.0374</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.18.17.4"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.18.17.4.1">0.0465</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.18.17.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.18.17.5.1">0.0451</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.18.17.6">0.0421</td>
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.18.17.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.18.17.7.1">0.0484*</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.5.1.18.17.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.18.17.8.1">0.0524*</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T4.5.1.18.17.9">12.69%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.19.18">
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r" id="S4.T4.5.1.19.18.1">MAP@10</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.5.1.19.18.2">0.0128</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.5.1.19.18.3">0.0147</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.5.1.19.18.4"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.19.18.4.1">0.0200</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T4.5.1.19.18.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.19.18.5.1">0.0190</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.5.1.19.18.6">0.0184</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.5.1.19.18.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.1.19.18.7.1">0.0205*</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T4.5.1.19.18.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.19.18.8.1">0.0212*</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r" id="S4.T4.5.1.19.18.9">6.00%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Overall Performance</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.T4" title="Table 4 ‣ 4.3.4. Inference speed considerations. ‣ 4.3. Multi-Sequence Aggregation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes the main results of experiments on all datasets. We compare the baseline autoregressive generation strategy (greedy decoding) with the two proposed multi-sequence aggregation strategies (Reciprocal Rank Aggregation and Relevance Aggregation) and the baselines from section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS1.SSS4" title="4.1.4. Baseline methods ‣ 4.1. Experimental Settings ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4.1.4</span></a>. We don’t include beam search and temperature sampling in the final comparison because optimal parameters for these strategies correspond to greedy decoding (number of beams equals one and the lowest considered temperature); see section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS2" title="4.2. Single Sequence Generation ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">For multi-sequence aggregation, 30 sequences and the best value of temperature for each dataset are used (for reciprocal rank aggregation and relevance aggregation respectively: 0.5 and 1.2 for Movielens-20M, 0.5 and 1.8 for Yelp, 0.3 and 1.0 for Steam, 0.8 and 1.6 for Gowalla, 0.4 and 5.0 for Twitch-100k, 0.5 and 2.0 for BeerAdvocate).</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">Generation with greedy decoding is comparable with the standard Top-K prediction strategy. It is slightly better on some datasets (MovieLens-20M, Yelp, Steam) and a little worse on others (Gowalla, BeerAdvocate). However, as shown in section <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.SS5" title="4.5. Performance by Ground Truth Item Position ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">4.5</span></a>, it could be better at predicting later time steps. With multi-sequence aggregation, it is possible to significantly outperform baselines on 4 of 6 datasets (MovieLens-20M, Yelp, BeerAdvocate, and Steam). For Gowalla and Twitch-100k improvements are very small. The relevance aggregation strategy is consistently better than reciprocal rank aggregation. To summarize, we noted statistically significant improvement in quality metrics for the majority of considered datasets. Thus, we confirmed that proposed generation strategies could be applied for datasets significantly varying in domains and sparsity. In the next section, the influence on longer time horizons is investigated further.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Performance by Ground Truth Item Position</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">To more thoroughly evaluate long-term predictions, we have inspected the performance for each item position in test sequences separately. We consider only one item at a time from each user’s sequence in the test set as ground truth and compare it with our recommendation list. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17730v1#S4.F5" title="Figure 5 ‣ 4.5. Performance by Ground Truth Item Position ‣ 4. Experiments ‣ Autoregressive Generation Strategies for Top-K Sequential Recommendations"><span class="ltx_text ltx_ref_tag">5</span></a> shows how HitRate@10 (HR@10) depends on ground truth item position for MovieLens-20M and Yelp datasets. When looking at longer time horizons, performance degrades very quickly. However, degradation is less severe for recommendations made with the autoregressive generation strategies. Curves for MovieLens-20M are much smoother as this dataset is much bigger. The Top-K prediction strategy is better for the first positions, which is reasonable, as the model was directly trained to predict the next item in a sequence. For later positions, generation strategies outperform the Top-K prediction strategy. Our experimental evaluation confirms that autoregressive generation could be a valuable option for longer-term recommendations. Interestingly, greedy decoding and multi-sequence aggregation perform similarly for later positions on MovieLens-20M. The main difference is that aggregation is better for short-term predictions.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="272" id="S4.F5.g1" src="extracted/5845354/recsys_content/images/positionn.png" width="598"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">Figure 5</span>. </span><span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">Performance by ground truth item position on Movielens-20M and Yelp datasets. The dashed green line corresponds to the standard Top-K prediction strategy without generation.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F5.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F5.5">[Performance by ground truth item position]Performance by ground truth item position</p>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we explored different strategies for the autoregressive generation for the Top-K Sequential recommendation task. We found that commonly used single-sequence autoregressive generation strategies such as greedy, beam search, and temperature sampling do not outperform the Top-K prediction approach. However, the autoregressive generation strategies show higher performance in predicting longer-term user preferences. Next, we found that greedy decoding outperforms temperature sampling and beam search. This observation contradicts experience in text generation, so we analyzed the reasons to explain this behavior.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Proposed multi-sequence aggregation approaches, <span class="ltx_text ltx_font_italic" id="S5.p2.1.1">Reciprocal Rank Aggregation strategy</span> and <span class="ltx_text ltx_font_italic" id="S5.p2.1.2">Relevance Aggregation strategy</span>, outperform single-sequence generation and Top-K prediction approaches. They require additional computational resources and increase inference time compared to single sequence generation approaches, but the inference time increase could be negligible due to parallelization.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">The multi-sequence aggregation strategies may be used with various backbone models. Evaluation of proposed strategies with the other backbone models besides GPT-2 is one of the possible future research directions that can build upon this work.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akiba et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Takuya Akiba, Shotaro
Sano, Toshihiko Yanase, Takeru Ohta,
and Masanori Koyama. 2019.

</span>
<span class="ltx_bibblock">Optuna: A Next-generation Hyperparameter Optimization
Framework.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1907.10902 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amjadi et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Mehrnaz Amjadi,
Seyed Danial Mohseni Taheri, and Theja
Tulabandhula. 2021.

</span>
<span class="ltx_bibblock">Katrec: Knowledge aware attentive sequential
recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Discovery Science: 24th
International Conference, DS 2021, Halifax, NS, Canada, October 11–13, 2021,
Proceedings 24</em>. Springer, 305–320.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asghar (2016)</span>
<span class="ltx_bibblock">
Nabiha Asghar.
2016.

</span>
<span class="ltx_bibblock">Yelp Dataset Challenge: Review Rating Prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:1605.05362</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bacciu et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Andrea Bacciu, Federico
Siciliano, Nicola Tonellotto, and
Fabrizio Silvestri. 2023.

</span>
<span class="ltx_bibblock">Integrating Item Relevance in Training Loss for
Sequential Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">arXiv preprint arXiv:2305.10824</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jinze Bai, Chang Zhou,
Junshuai Song, Xiaoru Qu,
Weiting An, Zhao Li, and
Jun Gao. 2019.

</span>
<span class="ltx_bibblock">Personalized bundle list recommendation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">The World Wide Web Conference</em>.
60–71.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bałchanowski and Boryczka (2023)</span>
<span class="ltx_bibblock">
Michał Bałchanowski and
Urszula Boryczka. 2023.

</span>
<span class="ltx_bibblock">A Comparative Study of Rank Aggregation Methods in
Recommendation Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Entropy</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann,
Nick Ryder, Melanie Subbiah,
Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
et al<span class="ltx_text" id="bib.bib8.3.1">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.4.1">Advances in neural information processing
systems</em> 33 (2020),
1877–1901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caruana et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2004)</span>
<span class="ltx_bibblock">
Rich Caruana, Alexandru
Niculescu-Mizil, Geoff Crew, and Alex
Ksikes. 2004.

</span>
<span class="ltx_bibblock">Ensemble selection from libraries of models. In
<em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the twenty-first international
conference on Machine learning</em>. 18.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Eunjoon Cho, Seth A.
Myers, and Jure Leskovec.
2011.

</span>
<span class="ltx_bibblock">Friendship and mobility: user movement in
location-based social networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Knowledge
Discovery and Data Mining</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Sung Min Cho, Eunhyeok
Park, and Sungjoo Yoo. 2020.

</span>
<span class="ltx_bibblock">MEANTIME: Mixture of attention mechanisms with
multi-temporal embeddings for sequential recommendation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the 14th ACM Conference on
Recommender Systems</em>. 515–520.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Souza Pereira Moreira et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Gabriel de Souza Pereira Moreira,
Sara Rabhi, Jeong Min Lee,
Ronay Ak, and Even Oldridge.
2021.

</span>
<span class="ltx_bibblock">Transformers4rec: Bridging the gap between nlp and
sequential/session-based recommendation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Proceedings of the 15th ACM conference on
recommender systems</em>. 143–153.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devooght and Bersini (2017)</span>
<span class="ltx_bibblock">
Robin Devooght and
Hugues Bersini. 2017.

</span>
<span class="ltx_bibblock">Long and short-term recommendations with recurrent
neural networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 25th
conference on user modeling, adaptation and personalization</em>.
13–21.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dietterich (2000)</span>
<span class="ltx_bibblock">
Thomas G Dietterich.
2000.

</span>
<span class="ltx_bibblock">Ensemble methods in machine learning. In
<em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International workshop on multiple classifier
systems</em>. Springer, 1–15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Angela Fan, Mike Lewis,
and Yann Dauphin. 2018.

</span>
<span class="ltx_bibblock">Hierarchical neural story generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">arXiv preprint arXiv:1805.04833</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fischer et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Elisabeth Fischer, Daniel
Zoller, Alexander Dallmann, and Andreas
Hotho. 2020.

</span>
<span class="ltx_bibblock">Integrating Keywords into BERT4Rec for Sequential
Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Deutsche Jahrestagung für
Künstliche Intelligenz</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frederickson (2018)</span>
<span class="ltx_bibblock">
Ben Frederickson.
2018.

</span>
<span class="ltx_bibblock">Fast python collaborative filtering for implicit
datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">URL https://github. com/benfred/implicit</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shijie Geng, Shuchang
Liu, Zuohui Fu, Yingqiang Ge, and
Yongfeng Zhang. 2022.

</span>
<span class="ltx_bibblock">Recommendation as language processing (rlp): A
unified pretrain, personalized prompt &amp; predict paradigm (p5). In
<em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the 16th ACM Conference on
Recommender Systems</em>. 299–315.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves (2012)</span>
<span class="ltx_bibblock">
Alex Graves.
2012.

</span>
<span class="ltx_bibblock">Sequence transduction with recurrent neural
networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:1211.3711</em>
(2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F Maxwell Harper and
Joseph A Konstan. 2015.

</span>
<span class="ltx_bibblock">The movielens datasets: History and context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Acm transactions on interactive intelligent
systems (tiis)</em> 5, 4
(2015), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holtzman et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Ari Holtzman, Jan Buys,
Li Du, Maxwell Forbes, and
Yejin Choi. 2019.

</span>
<span class="ltx_bibblock">The curious case of neural text degeneration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">arXiv preprint arXiv:1904.09751</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and
Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">2018 IEEE international conference on data mining
(ICDM)</em>. IEEE, 197–206.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klenitskiy and Vasilev (2023)</span>
<span class="ltx_bibblock">
Anton Klenitskiy and
Alexey Vasilev. 2023.

</span>
<span class="ltx_bibblock">Turning Dross Into Gold Loss: is BERT4Rec really
better than SASRec?. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 17th
ACM Conference on Recommender Systems</em>. 1120–1125.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kolesnikov et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Sergey Kolesnikov, Oleg
Lashinin, Michail Pechatov, and
Alexander Kosov. 2021.

</span>
<span class="ltx_bibblock">TTRS: Tinkoff Transactions Recommender System
benchmark.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">arXiv e-prints</em> (2021),
arXiv–2110.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Haoyang Li, Xin Wang,
Ziwei Zhang, Jianxin Ma,
Peng Cui, and Wenwu Zhu.
2021.

</span>
<span class="ltx_bibblock">Intention-Aware Sequential Recommendation With
Structured Intent Transition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">IEEE Transactions on Knowledge and Data
Engineering</em> PP (2021),
1–1.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinming Li, Wentao Zhang,
Tian Wang, Guanglei Xiong,
Alan Lu, and Gerard Medioni.
2023.

</span>
<span class="ltx_bibblock">GPT4Rec: A generative framework for personalized
recommendation and user interests interpretation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">arXiv preprint arXiv:2304.03879</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macdonald and Ounis (2006)</span>
<span class="ltx_bibblock">
Craig Macdonald and Iadh
Ounis. 2006.

</span>
<span class="ltx_bibblock">Voting for candidates: adapting data fusion
techniques for an expert search task. In
<em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">International Conference on Information and
Knowledge Management</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McAuley et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Julian McAuley, Jure
Leskovec, and Dan Jurafsky.
2012.

</span>
<span class="ltx_bibblock">Learning attitudes and attributes from multi-aspect
reviews. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">2012 IEEE 12th International
Conference on Data Mining</em>. IEEE, 1020–1025.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oliveira et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Samuel E. L. Oliveira,
Victor Diniz, Anísio Mendes Lacerda,
Luiz Merschmanm, and Gisele Lobo
Pappa. 2020.

</span>
<span class="ltx_bibblock">Is Rank Aggregation Effective in Recommender
Systems? An Experimental Analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">ACM Transactions on Intelligent Systems and
Technology (TIST)</em> (2020), 1 – 26.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Padungkiatwattana et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Umaporn Padungkiatwattana,
Thitiya Sae-diae, Saranya Maneeroj, and
Atsuhiro Takasu. 2022.

</span>
<span class="ltx_bibblock">ARERec: Attentive Local Interaction Model for
Sequential Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">IEEE Access</em> 10
(2022), 31340–31358.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pancha et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Nikil Pancha, Andrew
Zhai, Jure Leskovec, and Charles
Rosenberg. 2022.

</span>
<span class="ltx_bibblock">PinnerFormer: Sequence Modeling for User
Representation at Pinterest. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Proceedings of the
28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>.
3702–3712.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pathak et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Apurva Pathak, Kshitiz
Gupta, and Julian McAuley.
2017.

</span>
<span class="ltx_bibblock">Generating and Personalizing Bundle Recommendations
on Steam. 1073–1076.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov and Macdonald (2022)</span>
<span class="ltx_bibblock">
Aleksandr Petrov and
Craig Macdonald. 2022.

</span>
<span class="ltx_bibblock">A Systematic Review and Replicability Study of
BERT4Rec for Sequential Recommendation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 16th ACM Conference on
Recommender Systems</em>. 436–447.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov and Macdonald (2023a)</span>
<span class="ltx_bibblock">
Aleksandr V Petrov and
Craig Macdonald. 2023a.

</span>
<span class="ltx_bibblock">Generative Sequential Recommendation with GPTRec.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2306.11114</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov and Macdonald (2023b)</span>
<span class="ltx_bibblock">
Aleksandr Vladimirovich Petrov and
Craig Macdonald. 2023b.

</span>
<span class="ltx_bibblock">gSASRec: Reducing Overconfidence in Sequential
Recommendation Trained with Negative Sampling. In
<em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 17th ACM Conference on
Recommender Systems</em>. 116–128.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Ruihong Qiu, Zi Huang,
Hongzhi Yin, and Zijian Wang.
2022.

</span>
<span class="ltx_bibblock">Contrastive Learning for Representation
Degeneration Problem in Sequential Recommendation.
813–823.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Quadrana et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Massimo Quadrana, Paolo
Cremonesi, and Dietmar Jannach.
2018.

</span>
<span class="ltx_bibblock">Sequence-aware recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">ACM computing surveys (CSUR)</em>
51, 4 (2018),
1–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Alec Radford, Karthik
Narasimhan, Tim Salimans, Ilya
Sutskever, et al<span class="ltx_text" id="bib.bib38.3.1">.</span> 2018.

</span>
<span class="ltx_bibblock">Improving language understanding by generative
pre-training.

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu,
Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever,
et al<span class="ltx_text" id="bib.bib39.3.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask
learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.4.1">OpenAI blog</em> 1,
8 (2019), 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam
Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and
Peter J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a
unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">The Journal of Machine Learning Research</em>
21, 1 (2020),
5485–5551.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rappaz et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jérémie Rappaz, Julian
McAuley, and Karl Aberer.
2021.

</span>
<span class="ltx_bibblock">Recommendation on Live-Streaming Platforms: Dynamic
Availability and Repeat Consumption. 390–399.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rendle et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Steffen Rendle, Christoph
Freudenthaler, and Lars Schmidt-Thieme.
2010.

</span>
<span class="ltx_bibblock">Factorizing personalized markov chains for
next-basket recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the
19th international conference on World wide web</em>. 811–820.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (1995)</span>
<span class="ltx_bibblock">
Stephen E. Robertson,
Steve Walker, Micheline Hancock-Beaulieu,
Mike Gatford, and A. Payne.
1995.

</span>
<span class="ltx_bibblock">Okapi at TREC-4. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">Text
Retrieval Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu,
Jian Wu, Changhua Pei,
Xiao Lin, Wenwu Ou, and
Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential recommendation with
bidirectional encoder representations from transformer. In
<em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Proceedings of the 28th ACM international
conference on information and knowledge management</em>.
1441–1450.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenqi Sun, Ruobing Xie,
Junjie Zhang, Wayne Xin Zhao,
Leyu Lin, and Ji-Rong Wen.
2023.

</span>
<span class="ltx_bibblock">Generative Next-Basket Recommendation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">Proceedings of the 17th ACM Conference on
Recommender Systems</em>. 737–743.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang and Wang (2018)</span>
<span class="ltx_bibblock">
Jiaxi Tang and Ke
Wang. 2018.

</span>
<span class="ltx_bibblock">Personalized top-n sequential recommendation via
convolutional sequence embedding. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings
of the eleventh ACM international conference on web search and data mining</em>.
565–573.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vijayakumar et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Ashwin K Vijayakumar,
Michael Cogswell, Ramprasath R Selvaraju,
Qing Sun, Stefan Lee,
David Crandall, and Dhruv Batra.
2016.

</span>
<span class="ltx_bibblock">Diverse beam search: Decoding diverse solutions
from neural sequence models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">arXiv preprint arXiv:1610.02424</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villatel et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Kiewan Villatel, Elena
Smirnova, Jérémie Mary, and
Philippe Preux. 2018.

</span>
<span class="ltx_bibblock">Recurrent neural networks for long and short-term
sequential recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">arXiv preprint arXiv:1807.09142</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wegmann and Henrich (2018)</span>
<span class="ltx_bibblock">
Markus Wegmann and
Andreas Henrich. 2018.

</span>
<span class="ltx_bibblock">Search for an Appropriate Journal - In Depth
Evaluation of Data Fusion Techniques. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Lernen,
Wissen, Daten, Analysen</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welleck et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Sean Welleck, Ilia
Kulikov, Jaedeok Kim, Richard Yuanzhe
Pang, and Kyunghyun Cho.
2020.

</span>
<span class="ltx_bibblock">Consistency of a recurrent language model with
respect to incomplete decoding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">arXiv preprint arXiv:2002.02492</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilm et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Timo Wilm, Philipp
Normann, Sophie Baumeister, and
Paul-Vincent Kobow. 2023.

</span>
<span class="ltx_bibblock">Scaling Session-Based Transformer Recommendations
using Optimized Negative Sampling and Loss Functions. In
<em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Proceedings of the 17th ACM Conference on
Recommender Systems</em>. 1023–1026.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre
Debut, Victor Sanh, Julien Chaumond,
Clement Delangue, Anthony Moi,
Pierric Cistac, Tim Rault,
Rémi Louf, Morgan Funtowicz,
et al<span class="ltx_text" id="bib.bib52.3.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Huggingface’s transformers: State-of-the-art
natural language processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.4.1">arXiv preprint arXiv:1910.03771</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Qitian Wu, Chenxiao Yang,
Shuodian Yu, Xiaofeng Gao, and
Guihai Chen. 2021.

</span>
<span class="ltx_bibblock">Seq2Bubbles: Region-Based Embedding Learning for
User Behaviors in Sequential Recommenders. 2160–2169.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zarrieß et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Sina Zarrieß, Henrik
Voigt, and Simeon Schüz.
2021.

</span>
<span class="ltx_bibblock">Decoding methods in neural language generation: a
survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Information</em> 12,
9 (2021), 355.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Tingting Zhang, Pengpeng
Zhao, Yanchi Liu, Victor S. Sheng,
Jiajie Xu, Deqing Wang,
Guanfeng Liu, and Xiaofang Zhou.
2019.

</span>
<span class="ltx_bibblock">Feature-level Deeper Self-Attention Network for
Sequential Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">International Joint
Conference on Artificial Intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Pengyu Zhao, Tianxiao
Shui, Yuanxing Zhang, Kecheng Xiao,
and Kaigui Bian. 2020.

</span>
<span class="ltx_bibblock">Adversarial Oracular Seq2seq Learning for
Sequential Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">Proceedings of the
Twenty-Ninth International Joint Conference on Artificial Intelligence,
IJCAI-20</em>. International Joint Conferences on
Artificial Intelligence Organization, 1905–1911.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 26 10:42:00 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
