<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.07053] Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</title><meta property="og:description" content="Although most current large multimodal models (LMMs) can already understand photos of natural scenes and portraits, their understanding of abstract images, e.g., charts, maps, or layouts, and visual reasoning capabilit…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.07053">

<!--Generated on Mon Aug  5 12:55:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wenqi Zhang<sup id="id15.15.id1" class="ltx_sup"><span id="id15.15.id1.1" class="ltx_text ltx_font_italic">1,∗</span></sup>, Zhenglin Cheng<sup id="id16.16.id2" class="ltx_sup"><span id="id16.16.id2.1" class="ltx_text ltx_font_italic">1,∗</span></sup>, Yuanyu He<sup id="id17.17.id3" class="ltx_sup"><span id="id17.17.id3.1" class="ltx_text ltx_font_italic">1</span></sup>, Mengna Wang<sup id="id18.18.id4" class="ltx_sup"><span id="id18.18.id4.1" class="ltx_text ltx_font_italic">2</span></sup>, Yongliang Shen<sup id="id19.19.id5" class="ltx_sup"><span id="id19.19.id5.1" class="ltx_text ltx_font_italic">1</span></sup>
<br class="ltx_break"><span id="id12.12.7" class="ltx_text ltx_font_bold">Zeqi Tan<sup id="id12.12.7.1" class="ltx_sup"><span id="id12.12.7.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Guiyang Hou<sup id="id12.12.7.2" class="ltx_sup"><span id="id12.12.7.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Mingqian He<sup id="id12.12.7.3" class="ltx_sup"><span id="id12.12.7.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Yanna Ma<sup id="id12.12.7.4" class="ltx_sup"><span id="id12.12.7.4.1" class="ltx_text ltx_font_medium ltx_font_italic">3</span></sup>, Weiming Lu<sup id="id12.12.7.5" class="ltx_sup"><span id="id12.12.7.5.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Yueting Zhuang<sup id="id12.12.7.6" class="ltx_sup"><span id="id12.12.7.6.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>
<br class="ltx_break"><sup id="id12.12.7.7" class="ltx_sup"><span id="id12.12.7.7.1" class="ltx_text ltx_font_medium">1</span></sup></span>College of Computer Science and Technology, Zhejiang University
<br class="ltx_break"><sup id="id20.20.id6" class="ltx_sup">2</sup>Institute of Software, Chinese Academy of Sciences
<br class="ltx_break"><sup id="id21.21.id7" class="ltx_sup">3</sup>University of Shanghai for Science and Technology
<br class="ltx_break"><span id="id22.22.id8" class="ltx_text ltx_font_typewriter">{zhangwenqi, luwm}@zju.edu.cn
<br class="ltx_break"></span>Project Page: <a target="_blank" href="https://multi-modal-self-instruct.github.io" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://multi-modal-self-instruct.github.io</a>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id23.id1" class="ltx_p">Although most current large multimodal models (LMMs) can already understand photos of natural scenes and portraits, their understanding of abstract images, e.g., charts, maps, or layouts, and visual reasoning capabilities remains quite rudimentary. They often struggle with simple daily tasks, such as reading time from a clock, understanding a flowchart, or planning a route using a road map. In light of this, we design a multi-modal self-instruct, utilizing large language models and their code capabilities to synthesize massive abstract images and visual reasoning instructions across daily scenarios. Our strategy effortlessly creates a multimodal benchmark with 11,193 instructions for eight visual scenarios: charts, tables, simulated maps, dashboards, flowcharts, relation graphs, floor plans, and visual puzzles. <span id="id23.id1.1" class="ltx_text ltx_font_bold">This benchmark, constructed with simple lines and geometric elements, exposes the shortcomings of most advanced LMMs</span> like Claude-3.5-Sonnet and GPT-4o in abstract image understanding, spatial relations reasoning, and visual element induction. Besides, to verify the quality of our synthetic data, we fine-tune an LMM using 62,476 synthetic chart, table and road map instructions.
The results demonstrate improved chart understanding and map navigation performance, and also demonstrate potential benefits for other visual reasoning tasks. Our code is available at: <a target="_blank" href="https://github.com/zwq2018/Multi-modal-Self-instruct" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zwq2018/Multi-modal-Self-instruct</a>.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.14" class="ltx_block ltx_align_bottom">
<p id="p1.14.15" class="ltx_p"><span id="p1.14.15.1" class="ltx_text ltx_font_bold">Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.14.14" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.14.14.14" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.14.14.14.14" class="ltx_tabular ltx_align_top">
<span id="p1.5.5.5.5.5" class="ltx_tr">
<span id="p1.5.5.5.5.5.5" class="ltx_td ltx_align_center"><span id="p1.5.5.5.5.5.5.5" class="ltx_text ltx_font_bold">Wenqi Zhang<sup id="p1.5.5.5.5.5.5.5.1" class="ltx_sup"><span id="p1.5.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup>, Zhenglin Cheng<sup id="p1.5.5.5.5.5.5.5.2" class="ltx_sup"><span id="p1.5.5.5.5.5.5.5.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup>, Yuanyu He<sup id="p1.5.5.5.5.5.5.5.3" class="ltx_sup"><span id="p1.5.5.5.5.5.5.5.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Mengna Wang<sup id="p1.5.5.5.5.5.5.5.4" class="ltx_sup"><span id="p1.5.5.5.5.5.5.5.4.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup>, Yongliang Shen<sup id="p1.5.5.5.5.5.5.5.5" class="ltx_sup"><span id="p1.5.5.5.5.5.5.5.5.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span></span></span>
<span id="p1.11.11.11.11.11" class="ltx_tr">
<span id="p1.11.11.11.11.11.6" class="ltx_td ltx_align_center"><span id="p1.11.11.11.11.11.6.6" class="ltx_text ltx_font_bold">Zeqi Tan<sup id="p1.11.11.11.11.11.6.6.1" class="ltx_sup"><span id="p1.11.11.11.11.11.6.6.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Guiyang Hou<sup id="p1.11.11.11.11.11.6.6.2" class="ltx_sup"><span id="p1.11.11.11.11.11.6.6.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Mingqian He<sup id="p1.11.11.11.11.11.6.6.3" class="ltx_sup"><span id="p1.11.11.11.11.11.6.6.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Yanna Ma<sup id="p1.11.11.11.11.11.6.6.4" class="ltx_sup"><span id="p1.11.11.11.11.11.6.6.4.1" class="ltx_text ltx_font_medium ltx_font_italic">3</span></sup>, Weiming Lu<sup id="p1.11.11.11.11.11.6.6.5" class="ltx_sup"><span id="p1.11.11.11.11.11.6.6.5.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Yueting Zhuang<sup id="p1.11.11.11.11.11.6.6.6" class="ltx_sup"><span id="p1.11.11.11.11.11.6.6.6.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span></span></span>
<span id="p1.12.12.12.12.12" class="ltx_tr">
<span id="p1.12.12.12.12.12.1" class="ltx_td ltx_align_center"><sup id="p1.12.12.12.12.12.1.1" class="ltx_sup">1</sup>College of Computer Science and Technology, Zhejiang University</span></span>
<span id="p1.13.13.13.13.13" class="ltx_tr">
<span id="p1.13.13.13.13.13.1" class="ltx_td ltx_align_center"><sup id="p1.13.13.13.13.13.1.1" class="ltx_sup">2</sup>Institute of Software, Chinese Academy of Sciences</span></span>
<span id="p1.14.14.14.14.14" class="ltx_tr">
<span id="p1.14.14.14.14.14.1" class="ltx_td ltx_align_center"><sup id="p1.14.14.14.14.14.1.1" class="ltx_sup">3</sup>University of Shanghai for Science and Technology</span></span>
<span id="p1.14.14.14.14.15" class="ltx_tr">
<span id="p1.14.14.14.14.15.1" class="ltx_td ltx_align_center"><span id="p1.14.14.14.14.15.1.1" class="ltx_text ltx_font_typewriter">{zhangwenqi, luwm}@zju.edu.cn</span></span></span>
<span id="p1.14.14.14.14.16" class="ltx_tr">
<span id="p1.14.14.14.14.16.1" class="ltx_td ltx_align_center">Project Page: <a target="_blank" href="https://multi-modal-self-instruct.github.io" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://multi-modal-self-instruct.github.io</a></span></span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotetext: </span>The first two authors have equal contributions.</span></span></span>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2407.07053/assets/x1.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="443" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>We leverage LLM and code to synthesize abstract images and self-instruct diverse reasoning instructions, e.g., charts, road maps, dashboards, visual puzzles, and relation graphs. Unlike natural landscapes and human photos, these non-natural images constructed with geometric elements require stronger perception and spatial relation reasoning. Our benchmark indicates that current LMMs are far from human-level performance. They even fail to complete simple daily tasks, e.g., reading the time on a clock or planning a route using a map.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent times, spurred by breakthroughs in large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al., <a href="#bib.bib75" title="" class="ltx_ref">2023</a>; Touvron et al., <a href="#bib.bib50" title="" class="ltx_ref">2023a</a>; OpenAI, <a href="#bib.bib43" title="" class="ltx_ref">2022</a>, <a href="#bib.bib44" title="" class="ltx_ref">2023</a>; Touvron et al., <a href="#bib.bib51" title="" class="ltx_ref">2023b</a>; Bi et al., <a href="#bib.bib7" title="" class="ltx_ref">2024</a>; Jiang et al., <a href="#bib.bib21" title="" class="ltx_ref">2024</a>; Anthropic, <a href="#bib.bib3" title="" class="ltx_ref">2024</a>; Abdin et al., <a href="#bib.bib1" title="" class="ltx_ref">2024</a>)</cite>, large multimodal models (LMMs) have also undergone rapid advancements <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib32" title="" class="ltx_ref">2024b</a>, <a href="#bib.bib31" title="" class="ltx_ref">a</a>; Team et al., <a href="#bib.bib48" title="" class="ltx_ref">2023</a>; Bai et al., <a href="#bib.bib5" title="" class="ltx_ref">2023a</a>; Lu et al., <a href="#bib.bib36" title="" class="ltx_ref">2024</a>; McKinzie et al., <a href="#bib.bib41" title="" class="ltx_ref">2024</a>)</cite>. Leveraging a pre-trained LLM to encode all modalities empowers LMMs to understand human daily environments and execute complex tasks <cite class="ltx_cite ltx_citemacro_citep">(Hong et al., <a href="#bib.bib16" title="" class="ltx_ref">2023</a>; Zhang et al., <a href="#bib.bib80" title="" class="ltx_ref">2023b</a>; Hu et al., <a href="#bib.bib17" title="" class="ltx_ref">2023</a>; Zhang et al., <a href="#bib.bib77" title="" class="ltx_ref">2023a</a>; Koh et al., <a href="#bib.bib23" title="" class="ltx_ref">2024</a>; Zhang et al., <a href="#bib.bib81" title="" class="ltx_ref">2024c</a>)</cite>. This greatly expands the potential of general-purpose AI assistants.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite these achievements, LMMs still exhibit significant deficiencies when deployed in human daily life <cite class="ltx_cite ltx_citemacro_citep">(Yin et al., <a href="#bib.bib69" title="" class="ltx_ref">2023</a>; Xie et al., <a href="#bib.bib64" title="" class="ltx_ref">2024</a>)</cite>. For instance, LMMs often fail when planning a route using a road map, reading the time from a clock image, or interpreting a flowchart. We observe that these simple daily activities require LMMs to understand abstract images, such as maps, charts, and dashboards, rather than natural photographs or portraits with explicit semantics. These abstract images composed of simple geometric elements are more challenging for LMMs. Furthermore, even many advanced LMMs are easily stumped by simple visual-level reasoning tasks, such as geometric pattern induction and visual symbol comparison.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, these capabilities, i.e., perceiving abstract images and reasoning about visual elements, are essential for LMMs if we deploy an LMM-driven agent in our daily lives. It can help us with data analysis, map navigation, web searches, and many other tedious tasks. On the one hand, despite valuable explorations by some pioneers <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a href="#bib.bib73" title="" class="ltx_ref">2023b</a>; Liu et al., <a href="#bib.bib35" title="" class="ltx_ref">2023b</a>; Han et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Ying et al., <a href="#bib.bib71" title="" class="ltx_ref">2024</a>; Wei et al., <a href="#bib.bib57" title="" class="ltx_ref">2024</a>)</cite>, these abstract image understanding and visual reasoning abilities have not been adequately emphasized, and we need a dedicated benchmark to systematically evaluate the performance of current LMMs in this aspect. On the other hand, unlike semantic-related tasks, collecting such abstract image-text pairs with reasoning context is labor-intensive and time-consuming.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To fill in the gap, we drew inspiration from synthetic data <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib54" title="" class="ltx_ref">2022b</a>; Liu et al., <a href="#bib.bib33" title="" class="ltx_ref">2024c</a>; Han et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Du et al., <a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite>, which is widely used to supplement the insufficiency of instruction-following data. For instance, distilling high-quality dialogue data from a strong LLM <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib54" title="" class="ltx_ref">2022b</a>; Xu et al., <a href="#bib.bib65" title="" class="ltx_ref">2023a</a>; Yu et al., <a href="#bib.bib72" title="" class="ltx_ref">2023a</a>; Chen et al., <a href="#bib.bib9" title="" class="ltx_ref">2023a</a>; Zhao et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite>, or using external tools to refine the quality of synthetic data <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a href="#bib.bib58" title="" class="ltx_ref">2023</a>; Lee et al., <a href="#bib.bib24" title="" class="ltx_ref">2024</a>)</cite>. However, synthesizing image-text data for LMM is not easy, as current LLMs can not directly generate images. An intuitive approach is to combine LLMs with a text-to-image model for producing &lt;image, question, answer&gt; <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib29" title="" class="ltx_ref">2023c</a>; Wu et al., <a href="#bib.bib61" title="" class="ltx_ref">2023b</a>)</cite>, but most text-to-image models fail to finely control the details of the image, potentially leading to a misalignment between image and text.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Considering that abstract images are composed of lines and geometric elements, we can utilize code to accurately synthesize them. In light of this, we advocate a code-centric self-instruct strategy to synthesize massive abstract images with reasoning questions and answer pairs. We first instruct LLM to autonomously propose a creative visual idea for a daily scenario and then self-propose the necessary data and code to draw an abstract image, such as plotting a relation graph or house layout. After synthesizing images, our strategy self-instructs multiple reasoning question-answer pairs based on the plotting idea and code. This code-centric design can effortlessly synthesize diverse abstract images and reasoning instructions, involving chart interpretation, spatial relation reasoning, visual puzzles, and mathematical geometry problems, and also provide accurate answers and rationale.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">As shown in <a href="#S0.F1" title="In Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>, our strategy synthesized an abstract image benchmark for daily scenarios, including 11,193 high-quality instructions covering eight scenarios: Dashboard, Road Map, Chart, Table, Flowchart, Relation Graph, Visual Puzzles, and 2D Planar Layout. Empowered by this benchmark, we evaluate several representative LMMs and identify their significant deficiencies in abstract image understanding and visual reasoning. For example, in the dashboard scene, the best-performing LMM (GPT-4o) only achieved a score of 54.7, far below the human level of 85.3. Our abstract image benchmark further indicates that the gap between current open-source models and closed-source models remains significant, despite their comparable performance on semantics-related benchmarks.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Besides, to verify the quality of the synthesized data, we synthesized 62,476 charts and road map instructions for fine-tuning Llava-1.5-7B. Experimental results show that our synthesized data can significantly enhance in-domain performance and also benefit other abstract image reasoning tasks.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Our contributions can be summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We identify that current LMMs have a significant gap compared to humans in understanding and visually reasoning about abstract images, such as maps, charts, and layouts.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Utilizing LLM and code, We design a multi-modal self-instruct strategy to synthesize a diverse set of abstract images and reasoning instructions, providing value data for LMMs.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We synthesized a benchmark of 11,193 high-quality abstract images, covering eight common scenarios. Our benchmark reveals significant deficiencies even in advanced LMMs. Besides, we synthesized 62,476 chart and road map instructions for fine-tuning, verifying the effectiveness of the synthesized data.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2407.07053/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="428" height="419" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Our multi-modal self-instruct strategy first self-proposes a visual idea to depict an abstract image. Based on this, the LLM generates simulated data and writes code to create the drawings. Subsequently, LLM is instructed to design multiple Q&amp;A based on the code and idea, covering various aspects such as spatial reasoning, color recognition, and mathematical reasoning, constructing a rich set of multimodal instructions.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Multi-modal Self-Instruct</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Overview</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Our multi-modal self-instruct is an LLM-driven data synthesis strategy capable of producing abstract images and aligned reasoning instructions for various daily scenarios, including road maps, dashboards, 2D planar layouts, charts, relation graphs, flowcharts, and visual puzzles.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Firstly, our strategy can autonomously propose a creative idea for visual scenarios, e.g., <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">using a step-by-step flowchart to demonstrate how to attend an academy conference</span> or <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">designing road map</span> (<a href="#S2.SS2" title="2.2 Visual Idea Proposal ‣ 2 Multi-modal Self-Instruct ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2.2</span></a>). Then it generates detailed code to visualize this idea (<a href="#S2.SS3" title="2.3 Image Synthesis ‣ 2 Multi-modal Self-Instruct ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2.3</span></a>). After synthesizing the desired image, LLMs self-instruct multiple high-quality Q&amp;A pairs for this visual content (<a href="#S2.SS4" title="2.4 Visual Instruction Construction ‣ 2 Multi-modal Self-Instruct ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2.4</span></a>). The entire process is fully completed by the LLM with a few demonstrations.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">As shown in <a href="#S1.F2" title="In 1 Introduction ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>, we illustrate the entire process of our image-text synthesis, including using road maps for navigation, interpreting pie charts, solving visual puzzles, and using operating workflow. For each scenario, we synthesize multiple questions, annotated answers, and rationales. For example, in the pie chart case, the LLM designs a multi-step math question about the difference between the largest and smallest categories.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Visual Idea Proposal</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To generate an image from scratch, we first instruct the LLM to propose an innovative visual idea. This visual idea illustrates a scenario commonly encountered in daily life or work, e.g., a chart about a specific topic or a road map. Besides, this scenario image can be rendered with code, rather than real portraits or natural scenes. Therefore, we focus on eight common types of abstract images that are rarely covered in current datasets:</p>
<div id="S2.SS2.p1.2" class="ltx_listing ltx_lstlisting ltx_listing" style="background-color:#F5F5F4;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,KCpAXGNvbG9ye2JsdWV9e1dvcmtpbmcgU2NlbmUgYW5kIExpZmUgU2NlbmV9QCopCigqQFx0ZXh0YmZ7Q2hhcnRzIGFuZCBUYWJsZX1AKik6IExpbmUsIGJhciwgcGllLCBjb21wb3NpdGUgY2hhcnRzLCBhbmQgc2luZ2xlIGFuZCBtdWx0aXBsZSB0YWJsZXMuCigqQFx0ZXh0YmZ7Rmxvd2NoYXJ0fUAqKTogQWxnb3JpdGhtIGZsb3djaGFydHMgYW5kIG9wZXJhdGluZyB3b3JrZmxvd3MsIHN1Y2ggYXMgZGVzaWduaW5nIGEgc2xpZGUgcHJlc2VudGF0aW9uLgooKkBcdGV4dGJme1JlbGF0aW9uIEdyYXBofUAqKTogTXVsdGlwbGUgcmVsYXRpb25hbCBncmFwaHMgd2l0aCBjb21wbGV4IGNvbm5lY3Rpb25zLgooKkBcdGV4dGJme1JvYWQgTWFwfUAqKTogU2ltdWxhdGVkIHJvYWQgbWFwcyBhbm5vdGF0ZWQgd2l0aCBpbnRlcnNlY3Rpb24gbmFtZXMuCigqQFx0ZXh0YmZ7VmlzdWFsIFB1enpsZXN9QCopOiAxLiBJbmR1Y3RpdmUgcmVhc29uaW5nIGFjcm9zcyBtdWx0aXBsZSBpbWFnZXMuIDIuIENvbXBhcmluZyB0aGUgZGlmZmVyZW5jZXMgYmV0d2VlbiBtdWx0aXBsZSBpbWFnZXMuCigqQFx0ZXh0YmZ7MkQgUGxhbmFyIExheW91dH1AKik6IEZsb29yIHBsYW5zIHdpdGggZGlmZmVyZW50IHN0cnVjdHVyZXMgYW5kIGxheW91dHMuCigqQFx0ZXh0YmZ7SW5zdHJ1bWVudCBEYXNoYm9hcmRzfUAqKTogTWVjaGFuaWNhbCBkaWFscywgc3VjaCBhcyBjbG9ja3MsIG9kb21ldGVycywgc3BlZWRvbWV0ZXJzLCB0aGVybW9tZXRlcnMsIGJhcm9tZXRlcnMuLg==" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Working Scene and Life Scene</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Charts and Table</span><span id="lstnumberx2.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx2.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Line</span><span id="lstnumberx2.5" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx2.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">bar</span><span id="lstnumberx2.8" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx2.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pie</span><span id="lstnumberx2.11" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx2.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">composite</span><span id="lstnumberx2.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">charts</span><span id="lstnumberx2.16" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx2.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx2.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">single</span><span id="lstnumberx2.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx2.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">multiple</span><span id="lstnumberx2.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">tables</span><span id="lstnumberx2.27" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Flowchart</span><span id="lstnumberx3.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx3.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Algorithm</span><span id="lstnumberx3.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">flowcharts</span><span id="lstnumberx3.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx3.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">operating</span><span id="lstnumberx3.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">workflows</span><span id="lstnumberx3.13" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx3.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">such</span><span id="lstnumberx3.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">as</span><span id="lstnumberx3.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">designing</span><span id="lstnumberx3.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx3.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">slide</span><span id="lstnumberx3.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">presentation</span><span id="lstnumberx3.26" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Relation Graph</span><span id="lstnumberx4.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Multiple</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">relational</span><span id="lstnumberx4.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graphs</span><span id="lstnumberx4.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">with</span><span id="lstnumberx4.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">complex</span><span id="lstnumberx4.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">connections</span><span id="lstnumberx4.15" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Road Map</span><span id="lstnumberx5.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx5.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Simulated</span><span id="lstnumberx5.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">road</span><span id="lstnumberx5.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">maps</span><span id="lstnumberx5.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">annotated</span><span id="lstnumberx5.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">with</span><span id="lstnumberx5.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">intersection</span><span id="lstnumberx5.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">names</span><span id="lstnumberx5.17" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Visual Puzzles</span><span id="lstnumberx6.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx6.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.4" class="ltx_text ltx_font_typewriter">1.</span><span id="lstnumberx6.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Inductive</span><span id="lstnumberx6.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">reasoning</span><span id="lstnumberx6.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">across</span><span id="lstnumberx6.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">multiple</span><span id="lstnumberx6.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">images</span><span id="lstnumberx6.15" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx6.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.17" class="ltx_text ltx_font_typewriter">2.</span><span id="lstnumberx6.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Comparing</span><span id="lstnumberx6.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx6.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">differences</span><span id="lstnumberx6.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">between</span><span id="lstnumberx6.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">multiple</span><span id="lstnumberx6.28" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter">images</span><span id="lstnumberx6.30" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_font_typewriter ltx_font_bold">2D Planar Layout</span><span id="lstnumberx7.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx7.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Floor</span><span id="lstnumberx7.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">plans</span><span id="lstnumberx7.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">with</span><span id="lstnumberx7.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">different</span><span id="lstnumberx7.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">structures</span><span id="lstnumberx7.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx7.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">layouts</span><span id="lstnumberx7.17" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Instrument Dashboards</span><span id="lstnumberx8.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx8.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Mechanical</span><span id="lstnumberx8.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dials</span><span id="lstnumberx8.7" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx8.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">such</span><span id="lstnumberx8.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">as</span><span id="lstnumberx8.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clocks</span><span id="lstnumberx8.14" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx8.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">odometers</span><span id="lstnumberx8.17" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx8.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">speedometers</span><span id="lstnumberx8.20" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx8.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">thermometers</span><span id="lstnumberx8.23" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx8.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">barometers</span><span id="lstnumberx8.26" class="ltx_text ltx_font_typewriter">..</span>
</div>
</div>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">We design some examples for each scenario as in-context demonstrations. Prompted by them, the LLM is encouraged to propose a creative and detailed plotting idea using natural language.
These visual ideas depict the basic outlines of visual information. By incorporating detailed parameters, a visual idea can control the specifics of image synthesis, enabling the creation of a diverse range of images.
Additionally, when constructing visual instructions, visual ideas can provide a visual reference for the generation of instructions in natural language form.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Image Synthesis</h3>

<section id="S2.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Simulated Data</h4>

<div id="S2.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px1.p1.1" class="ltx_p">To render the proposed idea into an image, we guide the LLM to first generate some simulated data for the proposed idea. For example, for the pie chart in <a href="#S1.F2" title="In 1 Introduction ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>, the LLM needs to fabricate the percentage data for the four types.</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Code Generation</h4>

<div id="S2.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px2.p1.1" class="ltx_p">After producing simulated data, LLM generates corresponding Python code to visualize the proposed idea. We encourage the LLM to use popular visualization packages, e.g., Matplotlib<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://matplotlib.org</span></span></span> or ECharts<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://echarts.apache.org/zh/index.html</span></span></span>, to create desired visual elements, as it significantly reduces the complexity of code generation. Besides, we instruct the LLM to explicitly define all parameters in the code for plotting images, such as image style, color, font size, and legend position. These explicitly stated parameters control the details of the synthesized images and can be used to produce Q&amp;A.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Visual Instruction Construction</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">After executing the code, we obtain the expected image. Next, the LLM autonomously proposes multiple high-quality &lt;question, answer&gt; pairs related to this synthetic image.</p>
</div>
<section id="S2.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question-Answer Pair Generation.</h4>

<div id="S2.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS4.SSS0.Px1.p1.1" class="ltx_p">To make the LLM aware of all the image details, we concatenate the proposed idea, simulated data, and generated code in the prompt, and then guide the LLM to design instructions following data for this synthesized image. More than just image comprehension and captioning tasks, our strategy can self-propose a wide range of unconventional questions for this synthesized image, such as comparing differences among multiple images, area estimation, and spatial relation inference. Furthermore, it can even design diverse multi-step reasoning problems based on multiple synthesized images.</p>
</div>
</section>
<section id="S2.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Annotate Answers with Rationale.</h4>

<div id="S2.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS4.SSS0.Px2.p1.1" class="ltx_p">To enhance the training effectiveness of multimodal instruction-following data, we also provide a detailed rationale for each question. We prompt the LLM to carefully review the idea and code, and then generate a detailed rationale for the given question, rather than just providing an answer. Similar to the chain-of-thought process, rationale can be used to train LMMs, enhancing their reasoning capabilities.</p>
</div>
<div id="S2.SS4.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS4.SSS0.Px2.p2.1" class="ltx_p">Below is a complete case for our pipeline, including Idea Proposal, Image Synthesis, and Instruction Construction. We also provide the results of GPT-4 and Gemini-1.5, which all failed on this case.</p>
</div>
<div id="S2.SS4.SSS0.Px2.p3" class="ltx_para">
<div id="S2.SS4.SSS0.Px2.p3.1" class="ltx_listing ltx_lstlisting ltx_listing" style="background-color:#F5F5F4;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,KCpAXGNvbG9ye2JsdWV9e0lkZWEgUHJvcG9zYWx9QCopOiBEcmF3IGEgY2xvY2sgd2l0aCBob3VyIGFuZCBtaW51dGUgaGFuZHMuCigqQFxjb2xvcntibHVlfXtTaW11bGF0ZWQgRGF0YX1AKik6IHRpbWU9Jzg6MTAnLCBTaGFwZT0nUm91bmQgQ2xvY2snLCBjb2xvcj0nYmxhY2snLCBzaXplPS4uLgooKkBcY29sb3J7Ymx1ZX17Q29kZSBHZW5lcmF0aW9ufUAqKTogJ2ltcG9ydCBweWVjaGFydC4uLicKKCpAXGNvbG9ye2JsdWV9e0luc3RydWN0aW9uIENvbnN0cnVjdGlvbn1AKikKKCpAXHRleHRiZntRdWVzdGlvbn1AKik6IFdoYXQgdGltZSBpcyBzaG93biBvbiB0aGUgZGlhbD8KKCpAXHRleHRiZntBbnN3ZXIxOiA4OjEwfUAqKQooKkBcY29sb3J7cmVkfXtHUFQtNFY6IDEwOjEwfUAqKS4gKCpAXGNvbG9ye3JlZH17R2VtaW5pLTEuNS1wcm86IDI6NDJ9QCopLgooKkBcdGV4dGJme01hdGggUXVlc3Rpb259QCopOiBXaGVuIEkgbGVmdCBob21lLCB0aGUgY2xvY2sgc2hvd2VkIHRoZSB0aW1lIGluZGljYXRlZCBpbiB0aGUgZmlndXJlLiBXaGF0IHRpbWUgaXMgaXQgYWZ0ZXIgOCBob3VycyBvZiB3b3JrPwooKkBcdGV4dGJme0Fuc3dlcjI6IDQ6MTAgb3IgMTY6MTB9QCopCigqQFx0ZXh0YmZ7UmF0aW9uYWxlfUAqKTogSSBzZWUgdGhhdCB0aGUgY2xvY2sgc2hvd3MgdGhlIHRpbWUgYXMgODoxMC4gQWZ0ZXIgd29ya2luZyBmb3IgZWlnaHQgaG91cnMsIHRoZSB0aW1lIHNob3VsZCBiZSAxNjoxMC4KKCpAXGNvbG9ye3JlZH17R1BULTRWOiA3OjEwfUAqKS4gVGhlIGNsb2NrIHNob3dzIDExOjEwIC4uLgooKkBcY29sb3J7cmVkfXtHZW1pbmktMS41LXBybzogOTo1MH1AKikuIFRoZSB0aW1lIGlzIDE6NTAgLi4uCigqQFx0ZXh0YmZ7UmVhc29uaW5nIFF1ZXN0aW9ufUAqKTogSSBleGVyY2lzZWQgZm9yIG9uZSBhbmQgYSBoYWxmIGhvdXJzLiBBZnRlciBmaW5pc2hpbmcsIHRoZSBjbG9jayBzaG93ZWQgdGhlIHRpbWUgYXMgaWxsdXN0cmF0ZWQuIFdoYXQgbnVtYmVyIGRpZCB0aGUgaG91ciBoYW5kIHBvaW50IHRvIHdoZW4gSSBzdGFydGVkIG15IHdvcmtvdXQ/CigqQFx0ZXh0YmZ7QW5zd2VyMzogNiBvciA3fUAqKQooKkBcdGV4dGJme1JhdGlvbmFsZX1AKik6IEkgcmVhZCB0aGUgdGltZSBmcm9tIHRoZSBjbG9jayBhcyA4OjEwLCBhbmQgeW91IGhhdmUgYmVlbiBleGVyY2lzaW5nIGZvciBhbiBob3VyIGFuZCBhIGhhbGYuIFRoaXMgbWVhbnMgeW91IGxlZnQgYXQgNjo0MC4gVGhlcmVmb3JlIC4uLgooKkBcY29sb3J7cmVkfXtHUFQtNFY6IDEyLn1AKikgVGhlIGNsb2NrIHNob3dzIHRoZSB0aW1lIGFzIDE6MzAgLi4uIDE6MzAtMS41IGhvdXJzPTEyOjAwIFBNIC4uLgooKkBcY29sb3J7cmVkfXtHZW1pbmktMS41LXBybzogMS59QCopIFRoZSBjbG9jayBpcyAyOjMwIC4uLiBBbiBob3VyIGFuZCBhIGhhbGYgYmVmb3JlIHdhcyAxOjAwIC4uLg==" download="">⬇</a></div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Idea Proposal</span><span id="lstnumberx9.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx9.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Draw</span><span id="lstnumberx9.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx9.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx9.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">with</span><span id="lstnumberx9.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hour</span><span id="lstnumberx9.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx9.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">minute</span><span id="lstnumberx9.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hands</span><span id="lstnumberx9.19" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Simulated Data</span><span id="lstnumberx10.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx10.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx10.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx10.5" class="ltx_text ltx_font_typewriter">=’8:10’,</span><span id="lstnumberx10.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx10.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Shape</span><span id="lstnumberx10.8" class="ltx_text ltx_font_typewriter">=’</span><span id="lstnumberx10.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Round</span><span id="lstnumberx10.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx10.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Clock</span><span id="lstnumberx10.12" class="ltx_text ltx_font_typewriter">’,</span><span id="lstnumberx10.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx10.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">color</span><span id="lstnumberx10.15" class="ltx_text ltx_font_typewriter">=’</span><span id="lstnumberx10.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">black</span><span id="lstnumberx10.17" class="ltx_text ltx_font_typewriter">’,</span><span id="lstnumberx10.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx10.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">size</span><span id="lstnumberx10.20" class="ltx_text ltx_font_typewriter">=...</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Code Generation</span><span id="lstnumberx11.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx11.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx11.4" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx11.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">import</span><span id="lstnumberx11.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx11.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pyechart</span><span id="lstnumberx11.8" class="ltx_text ltx_font_typewriter">...’</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Instruction Construction</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Question</span><span id="lstnumberx13.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx13.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx13.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx13.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">is</span><span id="lstnumberx13.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">shown</span><span id="lstnumberx13.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">on</span><span id="lstnumberx13.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx13.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dial</span><span id="lstnumberx13.17" class="ltx_text ltx_font_typewriter">?</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span id="lstnumberx14.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Answer1: 8:10</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">GPT-4V: 10:10</span><span id="lstnumberx15.2" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx15.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx15.4" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">Gemini-1.5-pro: 2:42</span><span id="lstnumberx15.5" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Math Question</span><span id="lstnumberx16.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx16.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">When</span><span id="lstnumberx16.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">I</span><span id="lstnumberx16.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">left</span><span id="lstnumberx16.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">home</span><span id="lstnumberx16.11" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx16.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx16.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx16.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">showed</span><span id="lstnumberx16.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx16.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx16.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">indicated</span><span id="lstnumberx16.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx16.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx16.28" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter">figure</span><span id="lstnumberx16.30" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx16.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx16.33" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.34" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx16.35" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.36" class="ltx_text ltx_lst_identifier ltx_font_typewriter">is</span><span id="lstnumberx16.37" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.38" class="ltx_text ltx_lst_identifier ltx_font_typewriter">it</span><span id="lstnumberx16.39" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.40" class="ltx_text ltx_lst_identifier ltx_font_typewriter">after</span><span id="lstnumberx16.41" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.42" class="ltx_text ltx_font_typewriter">8</span><span id="lstnumberx16.43" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.44" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hours</span><span id="lstnumberx16.45" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.46" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx16.47" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.48" class="ltx_text ltx_lst_identifier ltx_font_typewriter">work</span><span id="lstnumberx16.49" class="ltx_text ltx_font_typewriter">?</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Answer2: 4:10 or 16:10</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span id="lstnumberx18.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Rationale</span><span id="lstnumberx18.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx18.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">I</span><span id="lstnumberx18.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">see</span><span id="lstnumberx18.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">that</span><span id="lstnumberx18.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx18.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx18.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">shows</span><span id="lstnumberx18.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx18.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx18.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">as</span><span id="lstnumberx18.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.22" class="ltx_text ltx_font_typewriter">8:10.</span><span id="lstnumberx18.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">After</span><span id="lstnumberx18.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">working</span><span id="lstnumberx18.27" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.28" class="ltx_text ltx_lst_identifier ltx_font_typewriter">for</span><span id="lstnumberx18.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">eight</span><span id="lstnumberx18.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hours</span><span id="lstnumberx18.33" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx18.34" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.35" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx18.36" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.37" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx18.38" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.39" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx18.40" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.41" class="ltx_text ltx_lst_identifier ltx_font_typewriter">be</span><span id="lstnumberx18.42" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.43" class="ltx_text ltx_font_typewriter">16:10.</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">GPT-4V: 7:10</span><span id="lstnumberx19.2" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx19.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx19.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx19.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">shows</span><span id="lstnumberx19.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.10" class="ltx_text ltx_font_typewriter">11:10</span><span id="lstnumberx19.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.12" class="ltx_text ltx_font_typewriter">...</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">Gemini-1.5-pro: 9:50</span><span id="lstnumberx20.2" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx20.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx20.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx20.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">is</span><span id="lstnumberx20.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.10" class="ltx_text ltx_font_typewriter">1:50</span><span id="lstnumberx20.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.12" class="ltx_text ltx_font_typewriter">...</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Reasoning Question</span><span id="lstnumberx21.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx21.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">I</span><span id="lstnumberx21.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">exercised</span><span id="lstnumberx21.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">for</span><span id="lstnumberx21.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">one</span><span id="lstnumberx21.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx21.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx21.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">half</span><span id="lstnumberx21.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hours</span><span id="lstnumberx21.19" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx21.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">After</span><span id="lstnumberx21.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">finishing</span><span id="lstnumberx21.24" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx21.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx21.27" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.28" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx21.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">showed</span><span id="lstnumberx21.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx21.33" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.34" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx21.35" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.36" class="ltx_text ltx_lst_identifier ltx_font_typewriter">as</span><span id="lstnumberx21.37" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.38" class="ltx_text ltx_lst_identifier ltx_font_typewriter">illustrated</span><span id="lstnumberx21.39" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx21.40" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.41" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx21.42" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.43" class="ltx_text ltx_lst_identifier ltx_font_typewriter">number</span><span id="lstnumberx21.44" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.45" class="ltx_text ltx_lst_identifier ltx_font_typewriter">did</span><span id="lstnumberx21.46" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.47" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx21.48" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.49" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hour</span><span id="lstnumberx21.50" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.51" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hand</span><span id="lstnumberx21.52" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.53" class="ltx_text ltx_lst_identifier ltx_font_typewriter">point</span><span id="lstnumberx21.54" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.55" class="ltx_text ltx_lst_identifier ltx_font_typewriter">to</span><span id="lstnumberx21.56" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.57" class="ltx_text ltx_lst_identifier ltx_font_typewriter">when</span><span id="lstnumberx21.58" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.59" class="ltx_text ltx_lst_identifier ltx_font_typewriter">I</span><span id="lstnumberx21.60" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.61" class="ltx_text ltx_lst_identifier ltx_font_typewriter">started</span><span id="lstnumberx21.62" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.63" class="ltx_text ltx_lst_identifier ltx_font_typewriter">my</span><span id="lstnumberx21.64" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx21.65" class="ltx_text ltx_lst_identifier ltx_font_typewriter">workout</span><span id="lstnumberx21.66" class="ltx_text ltx_font_typewriter">?</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span id="lstnumberx22.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Answer3: 6 or 7</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span id="lstnumberx23.1" class="ltx_text ltx_font_typewriter ltx_font_bold">Rationale</span><span id="lstnumberx23.2" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx23.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">I</span><span id="lstnumberx23.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">read</span><span id="lstnumberx23.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx23.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx23.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">from</span><span id="lstnumberx23.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx23.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx23.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">as</span><span id="lstnumberx23.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.20" class="ltx_text ltx_font_typewriter">8:10,</span><span id="lstnumberx23.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx23.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">you</span><span id="lstnumberx23.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">have</span><span id="lstnumberx23.27" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.28" class="ltx_text ltx_lst_identifier ltx_font_typewriter">been</span><span id="lstnumberx23.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">exercising</span><span id="lstnumberx23.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">for</span><span id="lstnumberx23.33" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.34" class="ltx_text ltx_lst_identifier ltx_font_typewriter">an</span><span id="lstnumberx23.35" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.36" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hour</span><span id="lstnumberx23.37" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.38" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx23.39" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.40" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx23.41" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.42" class="ltx_text ltx_lst_identifier ltx_font_typewriter">half</span><span id="lstnumberx23.43" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx23.44" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.45" class="ltx_text ltx_lst_identifier ltx_font_typewriter">This</span><span id="lstnumberx23.46" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.47" class="ltx_text ltx_lst_identifier ltx_font_typewriter">means</span><span id="lstnumberx23.48" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.49" class="ltx_text ltx_lst_identifier ltx_font_typewriter">you</span><span id="lstnumberx23.50" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.51" class="ltx_text ltx_lst_identifier ltx_font_typewriter">left</span><span id="lstnumberx23.52" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.53" class="ltx_text ltx_lst_identifier ltx_font_typewriter">at</span><span id="lstnumberx23.54" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.55" class="ltx_text ltx_font_typewriter">6:40.</span><span id="lstnumberx23.56" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.57" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Therefore</span><span id="lstnumberx23.58" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx23.59" class="ltx_text ltx_font_typewriter">...</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span id="lstnumberx24.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">GPT-4V: 12.</span><span id="lstnumberx24.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx24.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx24.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">shows</span><span id="lstnumberx24.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx24.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx24.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">as</span><span id="lstnumberx24.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.15" class="ltx_text ltx_font_typewriter">1:30</span><span id="lstnumberx24.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.17" class="ltx_text ltx_font_typewriter">...</span><span id="lstnumberx24.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.19" class="ltx_text ltx_font_typewriter">1:30-1.5</span><span id="lstnumberx24.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hours</span><span id="lstnumberx24.22" class="ltx_text ltx_font_typewriter">=12:00</span><span id="lstnumberx24.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">PM</span><span id="lstnumberx24.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.26" class="ltx_text ltx_font_typewriter">...</span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span id="lstnumberx25.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">Gemini-1.5-pro: 1.</span><span id="lstnumberx25.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx25.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">clock</span><span id="lstnumberx25.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">is</span><span id="lstnumberx25.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.9" class="ltx_text ltx_font_typewriter">2:30</span><span id="lstnumberx25.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.11" class="ltx_text ltx_font_typewriter">...</span><span id="lstnumberx25.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">An</span><span id="lstnumberx25.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hour</span><span id="lstnumberx25.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx25.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx25.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">half</span><span id="lstnumberx25.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">before</span><span id="lstnumberx25.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">was</span><span id="lstnumberx25.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.27" class="ltx_text ltx_font_typewriter">1:00</span><span id="lstnumberx25.28" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.29" class="ltx_text ltx_font_typewriter">...</span>
</div>
</div>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.1.1" class="ltx_text"></span><span id="S2.T1.1.1.1.2" class="ltx_text ltx_font_bold">
<span id="S2.T1.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.2.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Task</span></span>
</span></span><span id="S2.T1.1.1.1.3" class="ltx_text"></span><span id="S2.T1.1.1.1.4" class="ltx_text ltx_font_bold"></span>
</td>
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T1.1.1.2.1" class="ltx_text ltx_font_bold">#Image</span></td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.3.1" class="ltx_text"></span><span id="S2.T1.1.1.3.2" class="ltx_text ltx_font_bold"> <span id="S2.T1.1.1.3.2.1" class="ltx_text">
<span id="S2.T1.1.1.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.3.2.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.3.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"># Instruction</span></span>
</span></span><span id="S2.T1.1.1.3.2.2" class="ltx_text"></span></span>
</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.4.1" class="ltx_text"></span><span id="S2.T1.1.1.4.2" class="ltx_text ltx_font_bold"> <span id="S2.T1.1.1.4.2.1" class="ltx_text">
<span id="S2.T1.1.1.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.4.2.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.4.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">#Usage</span></span>
</span></span><span id="S2.T1.1.1.4.2.2" class="ltx_text"></span></span>
</td>
</tr>
<tr id="S2.T1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Chart</td>
<td id="S2.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1,768</td>
<td id="S2.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">34,590</td>
<td id="S2.T1.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Train</td>
</tr>
<tr id="S2.T1.1.3" class="ltx_tr">
<td id="S2.T1.1.3.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Table</td>
<td id="S2.T1.1.3.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">570</td>
<td id="S2.T1.1.3.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">10,886</td>
<td id="S2.T1.1.3.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Train</td>
</tr>
<tr id="S2.T1.1.4" class="ltx_tr">
<td id="S2.T1.1.4.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Road map</td>
<td id="S2.T1.1.4.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">17,000</td>
<td id="S2.T1.1.4.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">17,000</td>
<td id="S2.T1.1.4.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Train</td>
</tr>
<tr id="S2.T1.1.5" class="ltx_tr">
<td id="S2.T1.1.5.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T1.1.5.1.1" class="ltx_text ltx_font_bold">All</span></td>
<td id="S2.T1.1.5.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">19,338</td>
<td id="S2.T1.1.5.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">62,476</td>
<td id="S2.T1.1.5.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Train</td>
</tr>
<tr id="S2.T1.1.6" class="ltx_tr">
<td id="S2.T1.1.6.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Chart</td>
<td id="S2.T1.1.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">149</td>
<td id="S2.T1.1.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">3,018</td>
<td id="S2.T1.1.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.7" class="ltx_tr">
<td id="S2.T1.1.7.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Table</td>
<td id="S2.T1.1.7.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">58</td>
<td id="S2.T1.1.7.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">1,108</td>
<td id="S2.T1.1.7.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.8" class="ltx_tr">
<td id="S2.T1.1.8.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Road map</td>
<td id="S2.T1.1.8.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">3,000</td>
<td id="S2.T1.1.8.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">3,000</td>
<td id="S2.T1.1.8.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.9" class="ltx_tr">
<td id="S2.T1.1.9.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Dashboard</td>
<td id="S2.T1.1.9.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">73</td>
<td id="S2.T1.1.9.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">1,013</td>
<td id="S2.T1.1.9.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.10" class="ltx_tr">
<td id="S2.T1.1.10.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Relation Graph</td>
<td id="S2.T1.1.10.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">66</td>
<td id="S2.T1.1.10.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">822</td>
<td id="S2.T1.1.10.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.11" class="ltx_tr">
<td id="S2.T1.1.11.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Flowchart</td>
<td id="S2.T1.1.11.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">98</td>
<td id="S2.T1.1.11.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">1,451</td>
<td id="S2.T1.1.11.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.12" class="ltx_tr">
<td id="S2.T1.1.12.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Visual Puzzle</td>
<td id="S2.T1.1.12.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">189</td>
<td id="S2.T1.1.12.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">529</td>
<td id="S2.T1.1.12.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.13" class="ltx_tr">
<td id="S2.T1.1.13.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">2D Planar Layout</td>
<td id="S2.T1.1.13.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">25</td>
<td id="S2.T1.1.13.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">252</td>
<td id="S2.T1.1.13.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
<tr id="S2.T1.1.14" class="ltx_tr">
<td id="S2.T1.1.14.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T1.1.14.1.1" class="ltx_text ltx_font_bold">All</span></td>
<td id="S2.T1.1.14.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">3,658</td>
<td id="S2.T1.1.14.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">11,193</td>
<td id="S2.T1.1.14.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The statistics of our dataset, including eight tasks from work and life scenarios. All data were synthesized using our multi-modal self-instruct strategy.</figcaption>
</figure>
<figure id="S2.F3" class="ltx_figure"><img src="" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Left: The distribution of different chart types. Right: The number of questions for each category.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Multimodal Self-instruct Dataset</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset Statistics</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We focus on eight common but under-explored scenario images, including Chart, Table, Road Map, Relation Graph, Flowchart, Visual Puzzle, Dashboard, and 2D Planar Layout. We initially synthesized a benchmark involving all 8 scenarios, containing 3,658 images and 11,193 instructions in total, to benchmark several representative LMMs. Besides, to evaluate the quality of the synthesized data, we also synthesize three training sets for chart, table, and road map tasks, comprising 34,590, 10,886, and 17,000 training instructions, respectively. As shown in <a href="#S2.T1" title="In Annotate Answers with Rationale. ‣ 2.4 Visual Instruction Construction ‣ 2 Multi-modal Self-Instruct ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>, we provide detailed statistics about our synthesized dataset.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2407.07053/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="198" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Top: We present three examples of road maps with different path complexity. Bottom: We categorize all maps into five levels of complexity.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Synthesis Details</h3>

<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Chart and Table</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">Firstly, we design some keyword seeds, e.g., GDP, energy consumption, employment rate, and then we prompt the LLM to expand these seed keywords into a huge keyword library covering economics, technology, and society domains. Before generation, we first randomly sample a keyword from the library and then prompt the LLM to generate corresponding visual ideas, code, and instruction data. We synthesize five types of charts: <span id="S3.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">line charts, bar charts, pie charts, table screenshots, and composite charts (containing multiple sub-charts)</span>. For each chart, we prompt LLMs to self-instruct five types of questions: <span id="S3.SS2.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">Optical Character Recognition (OCR), Caption, Detailed Perception (involving issues of position, quantity, layout), Data Extraction, and Mathematical Reasoning</span>. As shown in <a href="#S2.F3" title="In Annotate Answers with Rationale. ‣ 2.4 Visual Instruction Construction ‣ 2 Multi-modal Self-Instruct ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a>, we provide statistics based on chart types and question types separately. Besides, we provide several detailed examples for each type of chart and question in <a href="#A1.F2" title="In Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">A2</span></a>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Road map Navigation.</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.2" class="ltx_p">To generate simulated maps with obstacles and paths, we design a path generation strategy based on the rapidly exploring random tree algorithm<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://en.wikipedia.org/wiki/Rapidly_exploring_random_tree" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/wiki/Rapidly_exploring_random_tree</a></span></span></span>: Starting from an initial point, the agent randomly walks within an under-explored map, sampling the path according to the predefined walking parameters, including direction, probability, and maximum walking steps. The process stops when the maximum walking steps are reached, and the stopping position is set as the endpoint. When synthesizing maps, the LLM first sets the map size, and randomly walking parameters. Then it generates code to implement our path generation process. Ultimately, we synthesized 17<math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">k</annotation></semantics></math> training maps and 3<math id="S3.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a"><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">k</annotation></semantics></math> testing maps. Based on the path complexity, we categorized all maps into five levels. As shown in <a href="#S3.F4" title="In 3.1 Dataset Statistics ‣ 3 Multimodal Self-instruct Dataset ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>, most maps are of medium difficulty or higher, requiring at least two intersections and turns to reach the endpoint. We provide two complete cases in <a href="#A1.F4" title="In Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">A4</span></a>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Other Scenarios Synthesis.</h4>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">We employ similar processes to synthesize images of the other five scenarios, producing 1,013 Dashboard, 822 Relation Graph, 1,451 Flowchart, 529 Visual Puzzle, and 252 2D Planar Layout instructions. Specifically, for Flowchart, we synthesize two types: algorithm flowcharts and operating workflow. For the Relation Graph, we generate graphs with different structures, such as trees or graphs. For Dashboard, we synthesize circular dials, such as clocks, speedometers, and fuel gauges, and some elongated dials like thermometers and barometers. Regarding the Visual Puzzle task, we synthesize two types of puzzles: visual pattern induction and multi-subgraph comparison. As for the 2D Planar Layout, we synthesize architectural layouts, webpage layouts, and more. These instructions are all used as test benchmarks to evaluate the current mainstream LMMs performance. We provide some visualized cases for each task in <a href="#A1.F6" title="In Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figures</span> <span class="ltx_text ltx_ref_tag">A6</span></a>, <a href="#A1.F5" title="Figure A5 ‣ Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A5</span></a>, <a href="#A1.F8" title="Figure A8 ‣ Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A8</span></a> and <a href="#A1.F7" title="Figure A7 ‣ Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A7</span></a>.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Implementation Details</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p"><span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_bold">LLM and Prompts.</span> We employ <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">gpt-4-turbo-2024-04-09</span> to implement our data synthesis: idea proposal, code generation, and instruction construction. A detailed prompt is shown in <a href="#A1" title="Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Dataset Quality.</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">To ensure the quality of the synthesized data, we filtered the data at three levels: <span id="S3.SS3.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_bold">code feasibility, image aesthetics, and answer accuracy</span>. I. If the generated code fails to run, we prompt the LLM to self-reflect based on the error feedback from the compiler. If the LLM still cannot produce valid code after three retries, we discard that visual idea. II. For each synthesized image, we employed Llava-1.5 <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib31" title="" class="ltx_ref">2024a</a>)</cite> to check the image aesthetics, including whether visual elements within the image interfere with each other, the reasonableness of the layout, and the legibility of any text. These rules allowed us to filter out aesthetically unpleasing images. III. To ensure answer accuracy, we adopted the self-consistency <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib53" title="" class="ltx_ref">2022a</a>)</cite> for answer generation: instructing the LLM to generate multiple responses based on the idea, code, and question, and then selecting the final answer through a voting process. IV. Additionally, we randomly selected 10% of the question-answer pairs for human verification. The results confirmed that the quality of our dataset is assured.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.4.5" class="ltx_tr">
<td id="S3.T2.4.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:0.9pt;padding-right:0.9pt;" rowspan="2"><span id="S3.T2.4.5.1.1" class="ltx_text ltx_font_bold">LMMs</span></td>
<td id="S3.T2.4.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.9pt;padding-right:0.9pt;" colspan="3"><span id="S3.T2.4.5.2.1" class="ltx_text ltx_font_bold">Acc (%)</span></td>
</tr>
<tr id="S3.T2.4.6" class="ltx_tr">
<td id="S3.T2.4.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;"><span id="S3.T2.4.6.1.1" class="ltx_text ltx_font_bold">Chart</span></td>
<td id="S3.T2.4.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;"><span id="S3.T2.4.6.2.1" class="ltx_text ltx_font_bold">Table</span></td>
<td id="S3.T2.4.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;"><span id="S3.T2.4.6.3.1" class="ltx_text ltx_font_bold">Road Map</span></td>
</tr>
<tr id="S3.T2.4.7" class="ltx_tr">
<td id="S3.T2.4.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">GPT-4-Vision-1106</td>
<td id="S3.T2.4.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;"><span id="S3.T2.4.7.2.1" class="ltx_text ltx_font_bold">50.6</span></td>
<td id="S3.T2.4.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;"><span id="S3.T2.4.7.3.1" class="ltx_text ltx_font_bold">75.8</span></td>
<td id="S3.T2.4.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">23.3</td>
</tr>
<tr id="S3.T2.4.8" class="ltx_tr">
<td id="S3.T2.4.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">Claude-3-Sonnet</td>
<td id="S3.T2.4.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">46.4</td>
<td id="S3.T2.4.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">68.4</td>
<td id="S3.T2.4.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">38.3</td>
</tr>
<tr id="S3.T2.4.9" class="ltx_tr">
<td id="S3.T2.4.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">Qwen-VL-Plus-70B</td>
<td id="S3.T2.4.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">40.1</td>
<td id="S3.T2.4.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">51.6</td>
<td id="S3.T2.4.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">18.6</td>
</tr>
<tr id="S3.T2.4.10" class="ltx_tr">
<td id="S3.T2.4.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">Vanilla Llava-1.5-7B</td>
<td id="S3.T2.4.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">10.5</td>
<td id="S3.T2.4.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">15.8</td>
<td id="S3.T2.4.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">0.3</td>
</tr>
<tr id="S3.T2.4.11" class="ltx_tr">
<td id="S3.T2.4.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">Vanilla Llava-1.5-13B</td>
<td id="S3.T2.4.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">13.4</td>
<td id="S3.T2.4.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">18.3</td>
<td id="S3.T2.4.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">5.1</td>
</tr>
<tr id="S3.T2.4.12" class="ltx_tr">
<td id="S3.T2.4.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">InstructBLIP-7B</td>
<td id="S3.T2.4.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">8.8</td>
<td id="S3.T2.4.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">7.7</td>
<td id="S3.T2.4.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">0.4</td>
</tr>
<tr id="S3.T2.4.13" class="ltx_tr">
<td id="S3.T2.4.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">InstructBLIP-13B</td>
<td id="S3.T2.4.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">2.8</td>
<td id="S3.T2.4.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">2.1</td>
<td id="S3.T2.4.13.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">0.6</td>
</tr>
<tr id="S3.T2.4.14" class="ltx_tr">
<td id="S3.T2.4.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">Deepseek-VL-Chat-1.3B</td>
<td id="S3.T2.4.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">18.4</td>
<td id="S3.T2.4.14.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">24.2</td>
<td id="S3.T2.4.14.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">9.6</td>
</tr>
<tr id="S3.T2.4.15" class="ltx_tr">
<td id="S3.T2.4.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.9pt;padding-right:0.9pt;">Deepseek-VL-Chat-7B</td>
<td id="S3.T2.4.15.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">25.2</td>
<td id="S3.T2.4.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">31.1</td>
<td id="S3.T2.4.15.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.9pt;padding-right:0.9pt;">18.8</td>
</tr>
<tr id="S3.T2.4.4" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">Llava-our-62<math id="S3.T2.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T2.1.1.1.m1.1a"><mi id="S3.T2.1.1.1.m1.1.1" xref="S3.T2.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">30.3 <math id="S3.T2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.2.2.2.m1.1a"><mo stretchy="false" id="S3.T2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>19.8</td>
<td id="S3.T2.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">51.8 <math id="S3.T2.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.3.3.3.m1.1a"><mo stretchy="false" id="S3.T2.3.3.3.m1.1.1" xref="S3.T2.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.m1.1b"><ci id="S3.T2.3.3.3.m1.1.1.cmml" xref="S3.T2.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.m1.1c">\uparrow</annotation></semantics></math>36.0</td>
<td id="S3.T2.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:0.9pt;padding-right:0.9pt;">
<span id="S3.T2.4.4.4.1" class="ltx_text ltx_font_bold">67.7</span> <math id="S3.T2.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.4.4.4.m1.1a"><mo stretchy="false" id="S3.T2.4.4.4.m1.1.1" xref="S3.T2.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.m1.1b"><ci id="S3.T2.4.4.4.m1.1.1.cmml" xref="S3.T2.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.m1.1c">\uparrow</annotation></semantics></math>67.4</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Our model is fine-tuned on chart, table, and roadmap tasks. The arrows indicate the improvements compared to Vanilla Llava-1.5-7B.</figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.10" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.10.11" class="ltx_tr">
<td id="S3.T3.10.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S3.T3.10.11.1.1" class="ltx_text ltx_font_bold">Data Selection</span></td>
<td id="S3.T3.10.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S3.T3.10.11.2.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="S3.T3.10.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S3.T3.10.11.3.1" class="ltx_text ltx_font_bold">Chart (%)</span></td>
<td id="S3.T3.10.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S3.T3.10.11.4.1" class="ltx_text ltx_font_bold">Table (%)</span></td>
<td id="S3.T3.10.11.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S3.T3.10.11.5.1" class="ltx_text ltx_font_bold">Map (%)</span></td>
</tr>
<tr id="S3.T3.10.12" class="ltx_tr">
<td id="S3.T3.10.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">Vanilla Llava</td>
<td id="S3.T3.10.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">0</td>
<td id="S3.T3.10.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">10.5</td>
<td id="S3.T3.10.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">15.8</td>
<td id="S3.T3.10.12.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">0.3</td>
</tr>
<tr id="S3.T3.2.2" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">
<math id="S3.T3.1.1.1.m1.1" class="ltx_math_unparsed" alttext="w/" display="inline"><semantics id="S3.T3.1.1.1.m1.1a"><mrow id="S3.T3.1.1.1.m1.1b"><mi id="S3.T3.1.1.1.m1.1.1">w</mi><mo id="S3.T3.1.1.1.m1.1.2">/</mo></mrow><annotation encoding="application/x-tex" id="S3.T3.1.1.1.m1.1c">w/</annotation></semantics></math> Chart</td>
<td id="S3.T3.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">34.5<math id="S3.T3.2.2.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T3.2.2.2.m1.1a"><mi id="S3.T3.2.2.2.m1.1.1" xref="S3.T3.2.2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.m1.1b"><ci id="S3.T3.2.2.2.m1.1.1.cmml" xref="S3.T3.2.2.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T3.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">29.8</td>
<td id="S3.T3.2.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">26.7</td>
<td id="S3.T3.2.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">8.9</td>
</tr>
<tr id="S3.T3.4.4" class="ltx_tr">
<td id="S3.T3.3.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.5pt;padding-right:1.5pt;">
<math id="S3.T3.3.3.1.m1.1" class="ltx_math_unparsed" alttext="w/" display="inline"><semantics id="S3.T3.3.3.1.m1.1a"><mrow id="S3.T3.3.3.1.m1.1b"><mi id="S3.T3.3.3.1.m1.1.1">w</mi><mo id="S3.T3.3.3.1.m1.1.2">/</mo></mrow><annotation encoding="application/x-tex" id="S3.T3.3.3.1.m1.1c">w/</annotation></semantics></math> Table</td>
<td id="S3.T3.4.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">10.8<math id="S3.T3.4.4.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T3.4.4.2.m1.1a"><mi id="S3.T3.4.4.2.m1.1.1" xref="S3.T3.4.4.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.2.m1.1b"><ci id="S3.T3.4.4.2.m1.1.1.cmml" xref="S3.T3.4.4.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.2.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T3.4.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">17.3</td>
<td id="S3.T3.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">47.8</td>
<td id="S3.T3.4.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">6.0</td>
</tr>
<tr id="S3.T3.6.6" class="ltx_tr">
<td id="S3.T3.5.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.5pt;padding-right:1.5pt;">
<math id="S3.T3.5.5.1.m1.1" class="ltx_math_unparsed" alttext="w/" display="inline"><semantics id="S3.T3.5.5.1.m1.1a"><mrow id="S3.T3.5.5.1.m1.1b"><mi id="S3.T3.5.5.1.m1.1.1">w</mi><mo id="S3.T3.5.5.1.m1.1.2">/</mo></mrow><annotation encoding="application/x-tex" id="S3.T3.5.5.1.m1.1c">w/</annotation></semantics></math> Map</td>
<td id="S3.T3.6.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">17<math id="S3.T3.6.6.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T3.6.6.2.m1.1a"><mi id="S3.T3.6.6.2.m1.1.1" xref="S3.T3.6.6.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.2.m1.1b"><ci id="S3.T3.6.6.2.m1.1.1.cmml" xref="S3.T3.6.6.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.2.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T3.6.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">9.8</td>
<td id="S3.T3.6.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">10.3</td>
<td id="S3.T3.6.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">62.0</td>
</tr>
<tr id="S3.T3.8.8" class="ltx_tr">
<td id="S3.T3.7.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.5pt;padding-right:1.5pt;">
<math id="S3.T3.7.7.1.m1.1" class="ltx_math_unparsed" alttext="w/" display="inline"><semantics id="S3.T3.7.7.1.m1.1a"><mrow id="S3.T3.7.7.1.m1.1b"><mi id="S3.T3.7.7.1.m1.1.1">w</mi><mo id="S3.T3.7.7.1.m1.1.2">/</mo></mrow><annotation encoding="application/x-tex" id="S3.T3.7.7.1.m1.1c">w/</annotation></semantics></math> Chart, Table</td>
<td id="S3.T3.8.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">45.3<math id="S3.T3.8.8.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T3.8.8.2.m1.1a"><mi id="S3.T3.8.8.2.m1.1.1" xref="S3.T3.8.8.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.2.m1.1b"><ci id="S3.T3.8.8.2.m1.1.1.cmml" xref="S3.T3.8.8.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.2.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T3.8.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">31.0</td>
<td id="S3.T3.8.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">50.4</td>
<td id="S3.T3.8.8.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">7.6</td>
</tr>
<tr id="S3.T3.10.10" class="ltx_tr">
<td id="S3.T3.9.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">
<math id="S3.T3.9.9.1.m1.1" class="ltx_math_unparsed" alttext="w/" display="inline"><semantics id="S3.T3.9.9.1.m1.1a"><mrow id="S3.T3.9.9.1.m1.1b"><mi id="S3.T3.9.9.1.m1.1.1">w</mi><mo id="S3.T3.9.9.1.m1.1.2">/</mo></mrow><annotation encoding="application/x-tex" id="S3.T3.9.9.1.m1.1c">w/</annotation></semantics></math> Chart, Table, Map</td>
<td id="S3.T3.10.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">62.3<math id="S3.T3.10.10.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T3.10.10.2.m1.1a"><mi id="S3.T3.10.10.2.m1.1.1" xref="S3.T3.10.10.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.2.m1.1b"><ci id="S3.T3.10.10.2.m1.1.1.cmml" xref="S3.T3.10.10.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.2.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T3.10.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">30.3</td>
<td id="S3.T3.10.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">51.8</td>
<td id="S3.T3.10.10.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">67.7</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>We investigate the synergistic effects between the three tasks. Chart and table corpus can improve each other and both benefit road map tasks.</figcaption>
</figure>
<figure id="S3.T4" class="ltx_table">
<table id="S3.T4.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T4.7.8" class="ltx_tr">
<td id="S3.T4.7.8.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;" rowspan="2"><span id="S3.T4.7.8.1.1" class="ltx_text ltx_font_bold">LLM</span></td>
<td id="S3.T4.7.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2"><span id="S3.T4.7.8.2.1" class="ltx_text ltx_font_bold">Weak-related Tasks (%)</span></td>
<td id="S3.T4.7.8.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="5"><span id="S3.T4.7.8.3.1" class="ltx_text ltx_font_bold">Our Synthetic Benchmark (%)</span></td>
</tr>
<tr id="S3.T4.7.9" class="ltx_tr">
<td id="S3.T4.7.9.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">ChartQA</td>
<td id="S3.T4.7.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">MathVista</td>
<td id="S3.T4.7.9.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">Dashboard</td>
<td id="S3.T4.7.9.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">Relation Graph</td>
<td id="S3.T4.7.9.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">Flowchart</td>
<td id="S3.T4.7.9.6" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">Visual Puzzle</td>
<td id="S3.T4.7.9.7" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">Planar Layout</td>
</tr>
<tr id="S3.T4.7.10" class="ltx_tr">
<td id="S3.T4.7.10.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Vanilla Llava</td>
<td id="S3.T4.7.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">19.9</td>
<td id="S3.T4.7.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">25.1</td>
<td id="S3.T4.7.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">16.5</td>
<td id="S3.T4.7.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">29.6</td>
<td id="S3.T4.7.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">9.6</td>
<td id="S3.T4.7.10.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">3.4</td>
<td id="S3.T4.7.10.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">37.7</td>
</tr>
<tr id="S3.T4.7.7" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">Llava-our-62<math id="S3.T4.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.T4.1.1.1.m1.1a"><mi id="S3.T4.1.1.1.m1.1.1" xref="S3.T4.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.m1.1b"><ci id="S3.T4.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.m1.1c">k</annotation></semantics></math>
</td>
<td id="S3.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">23.9 <math id="S3.T4.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.2.2.2.m1.1a"><mo stretchy="false" id="S3.T4.2.2.2.m1.1.1" xref="S3.T4.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.m1.1b"><ci id="S3.T4.2.2.2.m1.1.1.cmml" xref="S3.T4.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.m1.1c">\uparrow</annotation></semantics></math>4</td>
<td id="S3.T4.3.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">25.9 <math id="S3.T4.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.3.3.3.m1.1a"><mo stretchy="false" id="S3.T4.3.3.3.m1.1.1" xref="S3.T4.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.3.3.3.m1.1b"><ci id="S3.T4.3.3.3.m1.1.1.cmml" xref="S3.T4.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.3.3.3.m1.1c">\uparrow</annotation></semantics></math>0.8</td>
<td id="S3.T4.7.7.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">16.5</td>
<td id="S3.T4.4.4.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">30.1 <math id="S3.T4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.4.4.4.m1.1a"><mo stretchy="false" id="S3.T4.4.4.4.m1.1.1" xref="S3.T4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.4.4.4.m1.1b"><ci id="S3.T4.4.4.4.m1.1.1.cmml" xref="S3.T4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>0.5</td>
<td id="S3.T4.5.5.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">12.3 <math id="S3.T4.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.5.5.5.m1.1a"><mo stretchy="false" id="S3.T4.5.5.5.m1.1.1" xref="S3.T4.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.5.5.5.m1.1b"><ci id="S3.T4.5.5.5.m1.1.1.cmml" xref="S3.T4.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.5.5.m1.1c">\uparrow</annotation></semantics></math>2.7</td>
<td id="S3.T4.6.6.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">3.6 <math id="S3.T4.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.6.6.6.m1.1a"><mo stretchy="false" id="S3.T4.6.6.6.m1.1.1" xref="S3.T4.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.6.6.6.m1.1b"><ci id="S3.T4.6.6.6.m1.1.1.cmml" xref="S3.T4.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.6.6.m1.1c">\uparrow</annotation></semantics></math>0.2</td>
<td id="S3.T4.7.7.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">44.1 <math id="S3.T4.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.7.7.7.m1.1a"><mo stretchy="false" id="S3.T4.7.7.7.m1.1.1" xref="S3.T4.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.7.7.7.m1.1b"><ci id="S3.T4.7.7.7.m1.1.1.cmml" xref="S3.T4.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.7.7.7.m1.1c">\uparrow</annotation></semantics></math>6.4</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>We used two weakly related tasks and our synthetic benchmarks from five untrained tasks to evaluate the generalization capability of our <math id="S3.T4.9.m1.1" class="ltx_Math" alttext="62k" display="inline"><semantics id="S3.T4.9.m1.1b"><mrow id="S3.T4.9.m1.1.1" xref="S3.T4.9.m1.1.1.cmml"><mn id="S3.T4.9.m1.1.1.2" xref="S3.T4.9.m1.1.1.2.cmml">62</mn><mo lspace="0em" rspace="0em" id="S3.T4.9.m1.1.1.1" xref="S3.T4.9.m1.1.1.1.cmml">​</mo><mi id="S3.T4.9.m1.1.1.3" xref="S3.T4.9.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.9.m1.1c"><apply id="S3.T4.9.m1.1.1.cmml" xref="S3.T4.9.m1.1.1"><times id="S3.T4.9.m1.1.1.1.cmml" xref="S3.T4.9.m1.1.1.1"></times><cn type="integer" id="S3.T4.9.m1.1.1.2.cmml" xref="S3.T4.9.m1.1.1.2">62</cn><ci id="S3.T4.9.m1.1.1.3.cmml" xref="S3.T4.9.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.9.m1.1d">62k</annotation></semantics></math> model, which was fine-tuned solely on chart, table, and road map tasks.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">First, we evaluate the performance of many leading LMMs using our benchmark containing all tasks in <a href="#S4.SS2" title="4.2 Benchmarking LMM’s Visual Reasoning ‣ 4 Experiments ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>. Next, we perform instruction fine-tuning on the Llava-1.5-7B using 62,476 charts, tables, and road map instructions (denoted as Llava-our-<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="62k" display="inline"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mn id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">62</mn><mo lspace="0em" rspace="0em" id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><times id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">62</cn><ci id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">62k</annotation></semantics></math>). Then, we discuss the in-domain performance Llava-our-<math id="S4.p1.2.m2.1" class="ltx_Math" alttext="62k" display="inline"><semantics id="S4.p1.2.m2.1a"><mrow id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mn id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">62</mn><mo lspace="0em" rspace="0em" id="S4.p1.2.m2.1.1.1" xref="S4.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><times id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2">62</cn><ci id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">62k</annotation></semantics></math> and the impact of the quantity of synthetic data (<a href="#S4.SS3" title="4.3 Main Results After Fine-tuning ‣ 4 Experiments ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3</span></a>). Lastly, we investigate whether it can be generalized to other reasoning tasks (<a href="#S4.SS4" title="4.4 Generalized to Untrained Tasks ‣ 4 Experiments ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.4</span></a>).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Settings</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluated the performance of mainstream open-source and closed-source LMMs, including Llava-1.5-7B <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib31" title="" class="ltx_ref">2024a</a>)</cite>, Llava-1.5-13B, InstructBLIP-7B <cite class="ltx_cite ltx_citemacro_citep">(Dai et al., <a href="#bib.bib11" title="" class="ltx_ref">2024</a>)</cite>, InstructBLIP-13B, Deepseek-VL-Chat-1.3B <cite class="ltx_cite ltx_citemacro_citep">(Lu et al., <a href="#bib.bib36" title="" class="ltx_ref">2024</a>)</cite>, Deepseek-VL-Chat-7B, Claude-3.5-Sonnet, Claude-3-Sonnet<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://www.anthropic.com/news/claude-3-family" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.anthropic.com/news/claude-3-family</a></span></span></span>, GPT-4o, GPT-4-Vision-1106 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite>, Gemini-1.5-pro<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://deepmind.google/technologies/gemini/pro/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://deepmind.google/technologies/gemini/pro/</a></span></span></span> and Qwen-VL-Plus <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a href="#bib.bib6" title="" class="ltx_ref">2023b</a>)</cite>. All models were evaluated using the same prompts and temperature settings. We provide the evaluation metrics and other training details in  <a href="#A1" title="Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Benchmarking LMM’s Visual Reasoning</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">As shown <a href="#S0.F1" title="In Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>, we evaluate the performance of many LMMs, Llava-our-<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="62k" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">62</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">62</cn><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">62k</annotation></semantics></math> across eight tasks, i.e., chart, table, road map, dashboard, relation graph, flowchart, visual puzzle, and planar layout. Additionally, we invited two undergraduate students to test on our benchmark. Their scores were then averaged to represent the human-level performance. The detailed results are shown in <a href="#A1.T1" title="In Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">A1</span></a>.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Underwhelming Abstract Image Comprehension.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">We observe that for these abstract images, even advanced LMMs like GPT-4o and Claude-3.5-Sonnet achieved only 64.7% and 59.9% accuracy on average for all tasks, leaving a significant gap to human-level performance (82.1%). Surprisingly, some tasks that seem straightforward for humans, such as planning a route on a map and recognizing clocks, prove challenging for LMMs. Specifically, in the dashboard task, even the best LMMs only achieved an accuracy of 54.79% (GPT-4o). In the chart and relation graph tasks, we observe that LMMs often make errors when dealing with abstract concepts and spatial relationships. For example, in the Planar Layout task, GPT-4v often fails to distinguish the size of the three bedrooms accurately and whether they contain a washroom. These results indicate that despite significant progress in understanding semantic-rich natural photos, current LMMs still possess only a rudimentary understanding of abstract images and concepts.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Significant Disparity in Visual Reasoning Ability Among LMMs.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">In the road map navigation task, LMMs need to dynamically plan reasonable paths based on visual input. In the visual puzzle task, LMMs should carefully observe the given diagrams, induce visual patterns, and then perform reasoning. For these two tasks, we observed a significant performance disparity between open-source and closed-source LMMs. For example, Claude-3.5-Sonnet achieved 59.2% and 62.3% for road map and visual puzzles, respectively, while smaller open-source models all achieved very low accuracy (<math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><leq id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">\leq</annotation></semantics></math> 20%). This disparity between open-source and closed-source LMMs is particularly pronounced in these visual reasoning tasks.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Main Results After Fine-tuning</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In addition to constructing the benchmark, we fine-tuned the Llava-1.5-7B model using the training sets from chart, table, and map tasks, and compared its performance with other baselines.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">In-domain Performance.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">First, as shown in <a href="#S3.T2" title="In Dataset Quality. ‣ 3.3 Implementation Details ‣ 3 Multimodal Self-instruct Dataset ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>, compared to vanilla Llava-1.5-7B, we significantly improved its chart understanding capabilities by 19.8% and 36%, and also achieved the best performance in the road map navigation task (67.7%), far surpassing closed-source LMMs like GPT-4 (23.3%) and Claude-3 (38.3%). Notably, we only use 68<math id="S4.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">k</annotation></semantics></math> synthetic data and 4 hours of LoRA fine-tuning, elevating the chart understanding capability of Llava-1.5-7B to the Qwen-VL-Plus level. This demonstrates the tremendous potential of our synthetic data. Besides, we observe that most LMMs perform poorly on the road map navigation task, but can quickly improve after fine-tuning using our data. This highlights that current LMMs are not well-aligned in these reasoning scenarios.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Synergy Between Chart, Table and Road Map.</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.3" class="ltx_p">We also studied the synergistic effects among the three tasks, such as whether chart training data benefits table and road map navigation tasks. As shown in <a href="#S3.T3" title="In Dataset Quality. ‣ 3.3 Implementation Details ‣ 3 Multimodal Self-instruct Dataset ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>, we trained separately on the chart (<math id="S4.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="34.5k" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">34.5</mn><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1"><times id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1"></times><cn type="float" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2">34.5</cn><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">34.5k</annotation></semantics></math>), table (<math id="S4.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="10.8k" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml">10.8</mn><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1"><times id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1"></times><cn type="float" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2">10.8</cn><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">10.8k</annotation></semantics></math>), and roadmap (<math id="S4.SS3.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="17k" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.3.m3.1a"><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml"><mn id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2.cmml">17</mn><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1"><times id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1"></times><cn type="integer" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2">17</cn><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.3.m3.1c">17k</annotation></semantics></math>) datasets. Then, we train with a mix of chart and table data, and finally with a mix of all three tasks. We found that training on charts and tables does have a positive effect on road map tasks. For example, training solely on charts or tables can lead to approximately a +5% performance improvement in road map tasks, despite the significant differences in task types. Interestingly, the reverse is not true. The training process on road maps does not have a significant impact on chart and table tasks. We speculate that this may be due to the different capabilities required for each task.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Impact of Synthetic Data Quantity.</h4>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.3" class="ltx_p">To investigate the impact of synthetic data quantity, we fine-tuned the Llava-1.5-7B model using 35<math id="S4.SS3.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS0.Px3.p1.1.m1.1a"><mi id="S4.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.1.m1.1b"><ci id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.1.m1.1c">k</annotation></semantics></math>, 47<math id="S4.SS3.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS0.Px3.p1.2.m2.1a"><mi id="S4.SS3.SSS0.Px3.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.2.m2.1b"><ci id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.2.m2.1c">k</annotation></semantics></math>, and 62<math id="S4.SS3.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS0.Px3.p1.3.m3.1a"><mi id="S4.SS3.SSS0.Px3.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.3.m3.1b"><ci id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.3.m3.1c">k</annotation></semantics></math> synthetic instructions respectively. As shown in <a href="#A1.F1" title="In Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">A1</span></a>, we observe that as the quantity of synthetic data increases, the model’s performance steadily improves without reaching a plateau, especially in the math reasoning sub-task. Specifically, the accuracy for chart tasks increased from 25.78% to 29.5%, and the table accuracy improved by 5.4%. These results indicate that our synthetic data are of high quality and diversity.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Generalized to Untrained Tasks</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p">We evaluate whether Llava-our-62<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">k</annotation></semantics></math> can generalize to other benchmarks, especially the tasks with significant differences. We use 1) two weakly correlated tasks: ChartQA <cite class="ltx_cite ltx_citemacro_citep">(Masry et al., <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>, MathVista <cite class="ltx_cite ltx_citemacro_citep">(Lu et al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>, and 2) our synthetic benchmarks from other five reasoning tasks. As shown in <a href="#S3.T4" title="In Dataset Quality. ‣ 3.3 Implementation Details ‣ 3 Multimodal Self-instruct Dataset ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>, we observe that although our 62<math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">k</annotation></semantics></math> model is only trained on chart, table, and road map data, it also demonstrates improvements in other benchmarks, including chartQA (+4%), MathVista (+0.8%), and our synthetic benchmarks (+1.95% on average). These results show that our model can generalize to other types of visual reasoning tasks, rather than merely fitting to the training scenarios.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">We observe that current LMMs perform sub-optimally in perceiving and reasoning with abstract images, often failing at simple daily tasks. Therefore, we design a multimodal self-instruct strategy, enabling LLMs to autonomously synthesize various diagrams, instrument dashboards, and visual puzzles using code, and self-propose reasoning Q&amp;A. We synthesized <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="11k" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mn id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">11</mn><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">11</cn><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">11k</annotation></semantics></math> data to benchmark the current LMMs. Evaluation results underscore the significant challenges posed by our benchmark. We also synthesized <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="62k" display="inline"><semantics id="S5.p1.2.m2.1a"><mrow id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mn id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">62</mn><mo lspace="0em" rspace="0em" id="S5.p1.2.m2.1.1.1" xref="S5.p1.2.m2.1.1.1.cmml">​</mo><mi id="S5.p1.2.m2.1.1.3" xref="S5.p1.2.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><times id="S5.p1.2.m2.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1"></times><cn type="integer" id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2">62</cn><ci id="S5.p1.2.m2.1.1.3.cmml" xref="S5.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">62k</annotation></semantics></math> chart and road map training instructions to fine-tune a Llava-7B, enhancing its chart interpretation and map navigation abilities.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Our multi-modal strategy can synthesize a vast amount of abstract images and reasoning instructions, providing valuable training data to enhance LMMs. However, we want to highlight that there remain some limitations or areas for improvement: 1. Our data synthesis process relies on the code generation and reasoning capabilities of LLMs, which are only available in closed-source models like GPT-4. Using these models is costly. As the capabilities of open-source models improve, we are attempting to use open-source LLMs, such as Llama 3 and Deepseek-V2, to synthesize data. This will significantly reduce our expenses. 2. This work used code to synthesize abstract images in eight scenarios, such as tables and maps. In the future, we can expand to more scenarios, such as using code to control robot simulators to generate specific house layouts and structures, thereby producing a massive amount of data. 3. We believe that the image resolution of visual encoders is a bottleneck for current LMMs, especially for these abstract diagrams. In the future, we plan to improve the image resolution of the encoders to enhance the fine-grained perception capabilities of LMMs.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdin et al. (2024)</span>
<span class="ltx_bibblock">
Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. 2024.

</span>
<span class="ltx_bibblock">Phi-3 technical report: A highly capable language model locally on your phone.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.14219</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alayrac et al. (2022)</span>
<span class="ltx_bibblock">
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2204.14198" title="" class="ltx_ref ltx_href">Flamingo: a visual language model for few-shot learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Preprint</em>, arXiv:2204.14198.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2024)</span>
<span class="ltx_bibblock">
AI Anthropic. 2024.

</span>
<span class="ltx_bibblock">The claude 3 model family: Opus, sonnet, haiku.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Claude-3 Model Card</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antol et al. (2015)</span>
<span class="ltx_bibblock">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. 2015.

</span>
<span class="ltx_bibblock">Vqa: Visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer vision</em>, pages 2425–2433.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023a)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. 2023a.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.16609</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023b)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. 2023b.

</span>
<span class="ltx_bibblock">Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bi et al. (2024)</span>
<span class="ltx_bibblock">
Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al. 2024.

</span>
<span class="ltx_bibblock">Deepseek llm: Scaling open-source language models with longtermism.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.02954</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Lei Chen, Feng Yan, Yujie Zhong, Shaoxiang Chen, Zequn Jie, and Lin Ma. 2024.

</span>
<span class="ltx_bibblock">Mindbench: A comprehensive benchmark for mind map structure recognition and analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.02842</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023a)</span>
<span class="ltx_bibblock">
Lin Chen, Jisong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, and Dahua Lin. 2023a.

</span>
<span class="ltx_bibblock">Sharegpt4v: Improving large multi-modal models with better captions.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.12793</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023b)</span>
<span class="ltx_bibblock">
Sijin Chen, Xin Chen, China. Xiaoyan Zhang, Mingsheng Li, Gang Yu, Hao Fei, Hongyuan Zhu, Jiayuan Fan, and Tao Chen. 2023b.

</span>
<span class="ltx_bibblock">Ll3da: Visual interactive instruction tuning for omni-3d understanding, reasoning, and planning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2024)</span>
<span class="ltx_bibblock">
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale N Fung, and Steven Hoi. 2024.

</span>
<span class="ltx_bibblock">Instructblip: Towards general-purpose vision-language models with instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Driess et al. (2023)</span>
<span class="ltx_bibblock">
Danny Driess, F. Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Ho Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine, Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, and Peter R. Florence. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:257364842" title="" class="ltx_ref ltx_href">Palm-e: An embodied multimodal language model</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2023)</span>
<span class="ltx_bibblock">
Yifan Du, Hangyu Guo, Kun Zhou, Wayne Xin Zhao, Jinpeng Wang, Chuyuan Wang, Mingchen Cai, Ruihua Song, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock">What makes for good visual instructions? synthesizing complex visual reasoning instructions for visual instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.01487</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2023)</span>
<span class="ltx_bibblock">
Chaoyou Fu, Peixian Chen, Yunhang Shen, Yulei Qin, Mengdan Zhang, Xu Lin, Zhenyu Qiu, Wei Lin, Jinrui Yang, Xiawu Zheng, Ke Li, Xing Sun, and Rongrong Ji. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:259243928" title="" class="ltx_ref ltx_href">Mme: A comprehensive evaluation benchmark for multimodal large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2306.13394.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2023)</span>
<span class="ltx_bibblock">
Yucheng Han, Chi Zhang, Xin Chen, Xu Yang, Zhibin Wang, Gang Yu, Bin Fu, and Hanwang Zhang. 2023.

</span>
<span class="ltx_bibblock">Chartllama: A multimodal llm for chart understanding and generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.16483</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. (2023)</span>
<span class="ltx_bibblock">
Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding, et al. 2023.

</span>
<span class="ltx_bibblock">Cogagent: A visual language model for gui agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.08914</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2023)</span>
<span class="ltx_bibblock">
Anwen Hu, Yaya Shi, Haiyang Xu, Jiabo Ye, Qinghao Ye, Ming Yan, Chenliang Li, Qi Qian, Ji Zhang, and Fei Huang. 2023.

</span>
<span class="ltx_bibblock">mplug-paperowl: Scientific diagram analysis with the multimodal large language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.18248</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.09685</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Qiang Liu, Kriti Aggarwal, Zewen Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:257219775" title="" class="ltx_ref ltx_href">Language is not all you need: Aligning perception with language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2302.14045.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024)</span>
<span class="ltx_bibblock">
Zhen Huang, Zengzhi Wang, Shijie Xia, Xuefeng Li, Haoyang Zou, Ruijie Xu, Run-Ze Fan, Lyumanshan Ye, Ethan Chern, Yixin Ye, et al. 2024.

</span>
<span class="ltx_bibblock">Olympicarena: Benchmarking multi-discipline cognitive reasoning for superintelligent ai.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.12753</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024.

</span>
<span class="ltx_bibblock">Mixtral of experts.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.04088</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2024)</span>
<span class="ltx_bibblock">
Yoonsik Kim, Moonbin Yim, and Ka Yeon Song. 2024.

</span>
<span class="ltx_bibblock">Tablevqa-bench: A visual question answering benchmark on multiple table domains.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.19205</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koh et al. (2024)</span>
<span class="ltx_bibblock">
Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, Po-Yu Huang, Graham Neubig, Shuyan Zhou, Ruslan Salakhutdinov, and Daniel Fried. 2024.

</span>
<span class="ltx_bibblock">Visualwebarena: Evaluating multimodal agents on realistic visual web tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.13649</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2024)</span>
<span class="ltx_bibblock">
Nicholas Lee, Thanakul Wattanawong, Sehoon Kim, Karttikeya Mangalam, Sheng Shen, Gopala Anumanchipali, Michael W Mahoney, Kurt Keutzer, and Amir Gholami. 2024.

</span>
<span class="ltx_bibblock">Llm2llm: Boosting llms with novel iterative data enhancement.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2403.15042</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al. (2024)</span>
<span class="ltx_bibblock">
Bin Lei, Yuchen Li, and Qiuwu Chen. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:270045303" title="" class="ltx_ref ltx_href">Autocoder: Enhancing code large language model with {AIEV-Instruct}</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258547300" title="" class="ltx_ref ltx_href">Otter: A multi-modal model with in-context instruction tuning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.03726.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Bohao Li, Yuying Ge, Yixiao Ge, Guangzhi Wang, Rui Wang, Ruimao Zhang, and Ying Shan. 2024.

</span>
<span class="ltx_bibblock">Seed-bench: Benchmarking multimodal large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 13299–13308.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Junnan Li, Dongxu Li, S. Savarese, and Steven Hoi. 2023b.

</span>
<span class="ltx_bibblock">Blip-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2301.12597.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023c)</span>
<span class="ltx_bibblock">
Yanda Li, Chi Zhang, Gang Yu, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, and Yunchao Wei. 2023c.

</span>
<span class="ltx_bibblock">Stablellava: Enhanced visual instruction tuning with synthesized image-dialogue data.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.10253</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
Fuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen, Kaiqiang Song, Sangwoo Cho, Yaser Yacoob, and Dong Yu. 2023a.

</span>
<span class="ltx_bibblock">Mmc: Advancing multimodal chart understanding with large-scale instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.10774</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024a)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. 2024a.

</span>
<span class="ltx_bibblock">Improved baselines with visual instruction tuning.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024b)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2024b.

</span>
<span class="ltx_bibblock">Visual instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 36.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024c)</span>
<span class="ltx_bibblock">
Ruibo Liu, Jerry Wei, Fangyu Liu, Chenglei Si, Yanzhe Zhang, Jinmeng Rao, Steven Zheng, Daiyi Peng, Diyi Yang, Denny Zhou, et al. 2024c.

</span>
<span class="ltx_bibblock">Best practices and lessons learned on synthetic data for language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.07503</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024d)</span>
<span class="ltx_bibblock">
Yexin Liu, Zhengyang Liang, Yueze Wang, Muyang He, Jian Li, and Bo Zhao. 2024d.

</span>
<span class="ltx_bibblock">Seeing clearly, answering incorrectly: A multimodal robustness benchmark for evaluating mllms on leading questions.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.10638</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi Wang, Conghui He, Ziwei Liu, et al. 2023b.

</span>
<span class="ltx_bibblock">Mmbench: Is your multi-modal model an all-around player?

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.06281</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2024)</span>
<span class="ltx_bibblock">
Haoyu Lu, Wen Liu, Bo Zhang, Bingxuan Wang, Kai Dong, Bo Liu, Jingxiang Sun, Tongzheng Ren, Zhuoshu Li, Yaofeng Sun, et al. 2024.

</span>
<span class="ltx_bibblock">Deepseek-vl: towards real-world vision-language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2403.05525</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2023)</span>
<span class="ltx_bibblock">
Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.02255</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masry et al. (2023)</span>
<span class="ltx_bibblock">
Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, and Shafiq R. Joty. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258865561" title="" class="ltx_ref ltx_href">Unichart: A universal vision-language pretrained model for chart comprehension and reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.14761.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masry et al. (2022)</span>
<span class="ltx_bibblock">
Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. 2022.

</span>
<span class="ltx_bibblock">Chartqa: A benchmark for question answering about charts with visual and logical reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.10244</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masry et al. (2024)</span>
<span class="ltx_bibblock">
Ahmed Masry, Mehrad Shahmohammadi, Md Rizwan Parvez, Enamul Hoque, and Shafiq Joty. 2024.

</span>
<span class="ltx_bibblock">Chartinstruct: Instruction tuning for chart comprehension and reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2403.09028</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKinzie et al. (2024)</span>
<span class="ltx_bibblock">
Brandon McKinzie, Zhe Gan, Jean-Philippe Fauconnier, Sam Dodge, Bowen Zhang, Philipp Dufter, Dhruti Shah, Xianzhi Du, Futang Peng, Floris Weers, et al. 2024.

</span>
<span class="ltx_bibblock">Mm1: Methods, analysis &amp; insights from multimodal llm pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2403.09611</em>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al. (2024)</span>
<span class="ltx_bibblock">
Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, and Ping Luo. 2024.

</span>
<span class="ltx_bibblock">Chartassisstant: A universal chart multimodal language model via chart-to-table pre-training and multitask instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.02384</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock">Chatgpt.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:259262263" title="" class="ltx_ref ltx_href">Kosmos-2: Grounding multimodal large language models to the world</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2306.14824.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. (2024)</span>
<span class="ltx_bibblock">
Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, and Dan Roth. 2024.

</span>
<span class="ltx_bibblock">Flowvqa: Mapping multimodal logic in visual question answering with flowcharts.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.19237</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2023)</span>
<span class="ltx_bibblock">
Yixuan Su, Tian Lan, Huayang Li, Jialu Xu, Yan Wang, and Deng Cai. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258947721" title="" class="ltx_ref ltx_href">Pandagpt: One model to instruction-follow them all</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.16355.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2023)</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tong et al. (2024)</span>
<span class="ltx_bibblock">
Shengbang Tong, Zhuang Liu, Yuexiang Zhai, Yi Ma, Yann LeCun, and Saining Xie. 2024.

</span>
<span class="ltx_bibblock">Eyes wide shut? exploring the visual shortcomings of multimodal llms.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 9568–9578.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock">Llama: Open and Efficient Foundation Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2302.13971.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin R. Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cristian Cantón Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel M. Kloumann, A. V. Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, R. Subramanian, Xia Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and
Thomas Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:259950998" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2307.09288.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024a)</span>
<span class="ltx_bibblock">
Jiayu Wang, Yifei Ming, Zhenmei Shi, Vibhav Vineet, Xin Wang, and Neel Joshi. 2024a.

</span>
<span class="ltx_bibblock">Is a picture worth a thousand words? delving into spatial reasoning for vision language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.14852</em>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022a)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai hsin Chi, and Denny Zhou. 2022a.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2203.11171.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022b)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.10560" title="" class="ltx_ref ltx_href">Self-instruct: Aligning language model with self generated instructions</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Preprint</em>, arXiv:2212.10560.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Ziao Wang, Yuhang Li, Junda Wu, Jaehyeon Soon, and Xiaofeng Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:260438486" title="" class="ltx_ref ltx_href">Finvis-gpt: A multimodal large language model for financial chart analysis</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2308.01430.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024b)</span>
<span class="ltx_bibblock">
Zirui Wang, Mengzhou Xia, Luxi He, Howard Chen, Yitao Liu, Richard Zhu, Kaiqu Liang, Xindi Wu, Haotian Liu, Sadhika Malladi, et al. 2024b.

</span>
<span class="ltx_bibblock">Charxiv: Charting gaps in realistic chart understanding in multimodal llms.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.18521</em>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2024)</span>
<span class="ltx_bibblock">
Jingxuan Wei, Nan Xu, Guiyong Chang, Yin Luo, BiHui Yu, and Ruifeng Guo. 2024.

</span>
<span class="ltx_bibblock">mchartqa: A universal benchmark for multimodal chart question answer based on vision-language alignment and reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.01548</em>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. 2023.

</span>
<span class="ltx_bibblock">Magicoder: Source code is all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.02120</em>.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2024)</span>
<span class="ltx_bibblock">
Qiucheng Wu, Handong Zhao, Michael Saxon, Trung Bui, William Yang Wang, Yang Zhang, and Shiyu Chang. 2024.

</span>
<span class="ltx_bibblock">Vsp: Assessing the dual challenges of perception and reasoning in spatial planning tasks for vlms.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.01863</em>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023a)</span>
<span class="ltx_bibblock">
Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:261696650" title="" class="ltx_ref ltx_href">Next-gpt: Any-to-any multimodal llm</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2309.05519.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023b)</span>
<span class="ltx_bibblock">
Weijia Wu, Yuzhong Zhao, Hao Chen, Yuchao Gu, Rui Zhao, Yefei He, Hong Zhou, Mike Zheng Shou, and Chunhua Shen. 2023b.

</span>
<span class="ltx_bibblock">Datasetdm: Synthesizing data with perception annotations using diffusion models.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36:54683–54695.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2023)</span>
<span class="ltx_bibblock">
Renqiu Xia, Bo Zhang, Hao Peng, Ning Liao, Peng Ye, Botian Shi, Junchi Yan, and Y. Qiao. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:262067829" title="" class="ltx_ref ltx_href">Structchart: Perception, structuring, reasoning for visual chart understanding</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2309.11268.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2024)</span>
<span class="ltx_bibblock">
Renqiu Xia, Bo Zhang, Hancheng Ye, Xiangchao Yan, Qi Liu, Hongbin Zhou, Zijun Chen, Min Dou, Botian Shi, Junchi Yan, et al. 2024.

</span>
<span class="ltx_bibblock">Chartx &amp; chartvlm: A versatile benchmark and foundation model for complicated chart reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.12185</em>.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2024)</span>
<span class="ltx_bibblock">
Junlin Xie, Zhihong Chen, Ruifei Zhang, Xiang Wan, and Guanbin Li. 2024.

</span>
<span class="ltx_bibblock">Large multimodal agents: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.15116</em>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023a)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023a.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023b)</span>
<span class="ltx_bibblock">
Peng Xu, Wenqi Shao, Kaipeng Zhang, Peng Gao, Shuo Liu, Meng Lei, Fanqing Meng, Siyuan Huang, Yu Qiao, and Ping Luo. 2023b.

</span>
<span class="ltx_bibblock">Lvlm-ehub: A comprehensive evaluation benchmark for large vision-language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.09265</em>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023a)</span>
<span class="ltx_bibblock">
Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye, Mingshi Yan, Yuhao Dan, Chenlin Zhao, Guohai Xu, Chenliang Li, Junfeng Tian, Qiang Qi, Ji Zhang, and Feiyan Huang. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:259360848" title="" class="ltx_ref ltx_href">mplug-docowl: Modularized multimodal large language model for document understanding</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2307.02499.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023b)</span>
<span class="ltx_bibblock">
Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yi Zhou, Junyan Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qiang Qi, Ji Zhang, and Feiyan Huang. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258352455" title="" class="ltx_ref ltx_href">mplug-owl: Modularization empowers large language models with multimodality</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2304.14178.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2023)</span>
<span class="ltx_bibblock">
Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. 2023.

</span>
<span class="ltx_bibblock">A survey on multimodal large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.13549</em>.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2024)</span>
<span class="ltx_bibblock">
Zhenfei Yin, Jiong Wang, Jianjian Cao, Zhelun Shi, Dingning Liu, Mukai Li, Xiaoshui Huang, Zhiyong Wang, Lu Sheng, Lei Bai, et al. 2024.

</span>
<span class="ltx_bibblock">Lamm: Language-assisted multi-modal instruction-tuning dataset, framework, and benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ying et al. (2024)</span>
<span class="ltx_bibblock">
Kaining Ying, Fanqing Meng, Jin Wang, Zhiqian Li, Han Lin, Yue Yang, Hao Zhang, Wenbo Zhang, Yuqi Lin, Shuo Liu, et al. 2024.

</span>
<span class="ltx_bibblock">Mmt-bench: A comprehensive multimodal benchmark for evaluating large vision-language models towards multitask agi.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.16006</em>.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023a)</span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023a.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.12284</em>.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023b)</span>
<span class="ltx_bibblock">
Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Zicheng Liu, Xinchao Wang, and Lijuan Wang. 2023b.

</span>
<span class="ltx_bibblock">Mm-vet: Evaluating large multimodal models for integrated capabilities.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.02490</em>.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al. (2024)</span>
<span class="ltx_bibblock">
Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, et al. 2024.

</span>
<span class="ltx_bibblock">Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 9556–9567.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. (2023)</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie Tang. 2023.

</span>
<span class="ltx_bibblock">Glm-130b: An Open Bilingual Pre-trained Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">ICLR 2023 poster</em>.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhan et al. (2024)</span>
<span class="ltx_bibblock">
Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang, and Xipeng Qiu. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:267750101" title="" class="ltx_ref ltx_href">Anygpt: Unified multimodal llm with discrete sequence modeling</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2402.12226.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023a)</span>
<span class="ltx_bibblock">
Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, and Gang Yu. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2312.13771" title="" class="ltx_ref ltx_href">Appagent: Multimodal agents as smartphone users</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Preprint</em>, arXiv:2312.13771.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024a)</span>
<span class="ltx_bibblock">
Liang Zhang, Anwen Hu, Haiyang Xu, Mingshi Yan, Yichen Xu, Qin Jin, Ji Zhang, and Fei Huang. 2024a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:269362640" title="" class="ltx_ref ltx_href">Tinychart: Efficient chart understanding with visual token merging and program-of-thoughts learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2404.16635.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024b)</span>
<span class="ltx_bibblock">
Tianyu Zhang, Suyuchen Wang, Lu Li, Ge Zhang, Perouz Taslakian, Sai Rajeswar, Jie Fu, Bang Liu, and Yoshua Bengio. 2024b.

</span>
<span class="ltx_bibblock">Vcr: Visual caption restoration.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.06462</em>.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023b)</span>
<span class="ltx_bibblock">
Wenqi Zhang, Yongliang Shen, Weiming Lu, and Yueting Zhuang. 2023b.

</span>
<span class="ltx_bibblock">Data-copilot: Bridging billions of data and humans with autonomous workflow.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.07209</em>.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024c)</span>
<span class="ltx_bibblock">
Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, and Weiming Lu. 2024c.

</span>
<span class="ltx_bibblock">Agent-pro: Learning to evolve via policy-level reflection and optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.17574</em>.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Henry Hengyuan Zhao, Pan Zhou, and Mike Zheng Shou. 2023.

</span>
<span class="ltx_bibblock">Genixer: Empowering multimodal large language models as a powerful data generator.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.06731</em>.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2023)</span>
<span class="ltx_bibblock">
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258291930" title="" class="ltx_ref ltx_href">Minigpt-4: Enhancing vision-language understanding with advanced large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2304.10592.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Experiments Details</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p"><span id="A1.p1.1.1" class="ltx_text ltx_font_bold">Metrics.</span> Considering the diversity of output formats, including numerical values, single phrases, and long sentences, we employed different evaluation metrics. For numerical questions in chart, table, and dashboard tasks, answers within a 5% error margin are considered correct. For numerical questions in other tasks, the predicted values must match the labeled values exactly. For single-phrase answers, the predictions should either precisely match or contain the labeled answers. For long-sentence answers, we used the Rouge-L score as the evaluation metric. For the map navigation task, we evaluated the predicted paths by calculating the Landmark Coverage Rate (LCR(%)): we first extracted the predicted landmark sequence from the LMM’s response and then compared it sequentially with the annotated landmarks sequence, calculating the proportion of correctly ordered landmarks.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p"><span id="A1.p2.1.1" class="ltx_text ltx_font_bold">Training Details.</span> We fine-tuned the Llava-1.5-7B using LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> (denoted as Llava-our-62<math id="A1.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p2.1.m1.1a"><mi id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><ci id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">k</annotation></semantics></math>) on chart, table, and road map training sets for 1 epoch, with a batch size of 16, a learning rate of 2e-4, a rank of 128 and alpha of 256. All other parameters were kept consistent with those of Llava-1.5-7B. For reasoning questions, we concatenated the answer and rationale for instruction-following training.</p>
</div>
<figure id="A1.T1" class="ltx_table">
<table id="A1.T1.10" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T1.10.11" class="ltx_tr">
<td id="A1.T1.10.11.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="A1.T1.10.11.1.1" class="ltx_text">LLMs</span></td>
<td id="A1.T1.10.11.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="9">Acc (%)</td>
</tr>
<tr id="A1.T1.10.12" class="ltx_tr">
<td id="A1.T1.10.12.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Chart</td>
<td id="A1.T1.10.12.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Table</td>
<td id="A1.T1.10.12.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="A1.T1.10.12.3.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T1.10.12.3.1.1" class="ltx_tr">
<td id="A1.T1.10.12.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Road Map</td>
</tr>
</table>
</td>
<td id="A1.T1.10.12.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="A1.T1.10.12.4.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T1.10.12.4.1.1" class="ltx_tr">
<td id="A1.T1.10.12.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Dashboard</td>
</tr>
</table>
</td>
<td id="A1.T1.10.12.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="A1.T1.10.12.5.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T1.10.12.5.1.1" class="ltx_tr">
<td id="A1.T1.10.12.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Relation Graph</td>
</tr>
</table>
</td>
<td id="A1.T1.10.12.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Flowchart</td>
<td id="A1.T1.10.12.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="A1.T1.10.12.7.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T1.10.12.7.1.1" class="ltx_tr">
<td id="A1.T1.10.12.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Visual Puzzles</td>
</tr>
</table>
</td>
<td id="A1.T1.10.12.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="A1.T1.10.12.8.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T1.10.12.8.1.1" class="ltx_tr">
<td id="A1.T1.10.12.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Layout</td>
</tr>
</table>
</td>
<td id="A1.T1.10.12.9" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Avg.</td>
</tr>
<tr id="A1.T1.10.13" class="ltx_tr">
<td id="A1.T1.10.13.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Human</td>
<td id="A1.T1.10.13.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.2.1" class="ltx_text ltx_font_bold">93.5</span></td>
<td id="A1.T1.10.13.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.3.1" class="ltx_text ltx_font_bold">95.1</span></td>
<td id="A1.T1.10.13.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.4.1" class="ltx_text ltx_font_bold">75.0</span></td>
<td id="A1.T1.10.13.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.5.1" class="ltx_text ltx_font_bold">85.3</span></td>
<td id="A1.T1.10.13.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.6.1" class="ltx_text ltx_font_bold">82.5</span></td>
<td id="A1.T1.10.13.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.7.1" class="ltx_text ltx_font_bold">65.5</span></td>
<td id="A1.T1.10.13.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.8.1" class="ltx_text ltx_font_bold">62.5</span></td>
<td id="A1.T1.10.13.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.9.1" class="ltx_text ltx_font_bold">97.6</span></td>
<td id="A1.T1.10.13.10" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.10.13.10.1" class="ltx_text ltx_font_bold">82.1</span></td>
</tr>
<tr id="A1.T1.5.5" class="ltx_tr">
<td id="A1.T1.5.5.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Claude-3.5-Sonnet</td>
<td id="A1.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">67.24<sup id="A1.T1.1.1.1.1" class="ltx_sup"><span id="A1.T1.1.1.1.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.5.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">84.38</td>
<td id="A1.T1.5.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">59.24</td>
<td id="A1.T1.5.5.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">54.00</td>
<td id="A1.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">58.52<sup id="A1.T1.2.2.2.1" class="ltx_sup"><span id="A1.T1.2.2.2.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.5.5.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">49.21</td>
<td id="A1.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">62.38<sup id="A1.T1.3.3.3.1" class="ltx_sup"><span id="A1.T1.3.3.3.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">82.94<sup id="A1.T1.4.4.4.1" class="ltx_sup"><span id="A1.T1.4.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.5.5.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">64.74<sup id="A1.T1.5.5.5.1" class="ltx_sup"><span id="A1.T1.5.5.5.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
</tr>
<tr id="A1.T1.8.8" class="ltx_tr">
<td id="A1.T1.8.8.4" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">GPT-4o</td>
<td id="A1.T1.8.8.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">61.83</td>
<td id="A1.T1.6.6.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">88.76<sup id="A1.T1.6.6.1.1" class="ltx_sup"><span id="A1.T1.6.6.1.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.8.8.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">37.82</td>
<td id="A1.T1.7.7.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">54.79<sup id="A1.T1.7.7.2.1" class="ltx_sup"><span id="A1.T1.7.7.2.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.8.8.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">54.50</td>
<td id="A1.T1.8.8.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">54.31<sup id="A1.T1.8.8.3.1" class="ltx_sup"><span id="A1.T1.8.8.3.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.8.8.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">45.37</td>
<td id="A1.T1.8.8.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">82.54</td>
<td id="A1.T1.8.8.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">59.99</td>
</tr>
<tr id="A1.T1.10.14" class="ltx_tr">
<td id="A1.T1.10.14.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Claude-3-Sonnet</td>
<td id="A1.T1.10.14.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">46.4</td>
<td id="A1.T1.10.14.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">68.4</td>
<td id="A1.T1.10.14.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">38.3</td>
<td id="A1.T1.10.14.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">35.4</td>
<td id="A1.T1.10.14.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">56.2</td>
<td id="A1.T1.10.14.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">40.3</td>
<td id="A1.T1.10.14.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">47.0</td>
<td id="A1.T1.10.14.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">69.1</td>
<td id="A1.T1.10.14.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">50.1</td>
</tr>
<tr id="A1.T1.10.15" class="ltx_tr">
<td id="A1.T1.10.15.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">GPT-4V-1106</td>
<td id="A1.T1.10.15.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">50.6</td>
<td id="A1.T1.10.15.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">75.8</td>
<td id="A1.T1.10.15.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">23.3</td>
<td id="A1.T1.10.15.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">36.2</td>
<td id="A1.T1.10.15.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">52.4</td>
<td id="A1.T1.10.15.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">45.3</td>
<td id="A1.T1.10.15.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">35.9</td>
<td id="A1.T1.10.15.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">76.6</td>
<td id="A1.T1.10.15.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">49.5</td>
</tr>
<tr id="A1.T1.10.16" class="ltx_tr">
<td id="A1.T1.10.16.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Claude-3-Opus</td>
<td id="A1.T1.10.16.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">46.73</td>
<td id="A1.T1.10.16.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">67.71</td>
<td id="A1.T1.10.16.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">38.26</td>
<td id="A1.T1.10.16.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">38.70</td>
<td id="A1.T1.10.16.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">48.78</td>
<td id="A1.T1.10.16.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">35.77</td>
<td id="A1.T1.10.16.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">47.26</td>
<td id="A1.T1.10.16.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">65.48</td>
<td id="A1.T1.10.16.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">48.59</td>
</tr>
<tr id="A1.T1.10.17" class="ltx_tr">
<td id="A1.T1.10.17.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Claude-3-Haiku</td>
<td id="A1.T1.10.17.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">41.83</td>
<td id="A1.T1.10.17.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">57.33</td>
<td id="A1.T1.10.17.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">23.17</td>
<td id="A1.T1.10.17.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">35.83</td>
<td id="A1.T1.10.17.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">45.99</td>
<td id="A1.T1.10.17.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">23.09</td>
<td id="A1.T1.10.17.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">45.94</td>
<td id="A1.T1.10.17.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">58.73</td>
<td id="A1.T1.10.17.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">41.49</td>
</tr>
<tr id="A1.T1.10.18" class="ltx_tr">
<td id="A1.T1.10.18.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Gemini-1.5-Flash</td>
<td id="A1.T1.10.18.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">43.61</td>
<td id="A1.T1.10.18.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">64.06</td>
<td id="A1.T1.10.18.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">3.71</td>
<td id="A1.T1.10.18.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">39.04</td>
<td id="A1.T1.10.18.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">42.09</td>
<td id="A1.T1.10.18.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">36.03</td>
<td id="A1.T1.10.18.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">30.81</td>
<td id="A1.T1.10.18.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">69.72</td>
<td id="A1.T1.10.18.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">41.13</td>
</tr>
<tr id="A1.T1.10.19" class="ltx_tr">
<td id="A1.T1.10.19.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Gemini-Pro-Vision</td>
<td id="A1.T1.10.19.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">43.11</td>
<td id="A1.T1.10.19.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">64.92</td>
<td id="A1.T1.10.19.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">3.76</td>
<td id="A1.T1.10.19.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">38.87</td>
<td id="A1.T1.10.19.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">41.12</td>
<td id="A1.T1.10.19.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">36.09</td>
<td id="A1.T1.10.19.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">29.68</td>
<td id="A1.T1.10.19.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">70.12</td>
<td id="A1.T1.10.19.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">40.96</td>
</tr>
<tr id="A1.T1.10.20" class="ltx_tr">
<td id="A1.T1.10.20.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Gemini-1.5-Pro</td>
<td id="A1.T1.10.20.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">43.41</td>
<td id="A1.T1.10.20.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">63.78</td>
<td id="A1.T1.10.20.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">3.77</td>
<td id="A1.T1.10.20.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">38.71</td>
<td id="A1.T1.10.20.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">41.85</td>
<td id="A1.T1.10.20.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">35.55</td>
<td id="A1.T1.10.20.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">30.62</td>
<td id="A1.T1.10.20.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">69.32</td>
<td id="A1.T1.10.20.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">40.88</td>
</tr>
<tr id="A1.T1.10.21" class="ltx_tr">
<td id="A1.T1.10.21.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Qwen-VL-Plus</td>
<td id="A1.T1.10.21.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">40.1</td>
<td id="A1.T1.10.21.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">51.6</td>
<td id="A1.T1.10.21.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">18.6</td>
<td id="A1.T1.10.21.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">26.4</td>
<td id="A1.T1.10.21.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">52.2</td>
<td id="A1.T1.10.21.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">32.5</td>
<td id="A1.T1.10.21.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">32.3</td>
<td id="A1.T1.10.21.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">61.5</td>
<td id="A1.T1.10.21.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">39.4</td>
</tr>
<tr id="A1.T1.10.22" class="ltx_tr">
<td id="A1.T1.10.22.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Deepseek-VL-Chat-7B</td>
<td id="A1.T1.10.22.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">25.2</td>
<td id="A1.T1.10.22.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">31.1</td>
<td id="A1.T1.10.22.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">18.8</td>
<td id="A1.T1.10.22.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">18.2</td>
<td id="A1.T1.10.22.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">37.6</td>
<td id="A1.T1.10.22.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">20.8</td>
<td id="A1.T1.10.22.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">15.0</td>
<td id="A1.T1.10.22.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">47.2</td>
<td id="A1.T1.10.22.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">26.7</td>
</tr>
<tr id="A1.T1.10.23" class="ltx_tr">
<td id="A1.T1.10.23.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Vanilla Llava-1.5-7B</td>
<td id="A1.T1.10.23.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">10.5</td>
<td id="A1.T1.10.23.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">15.8</td>
<td id="A1.T1.10.23.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.3</td>
<td id="A1.T1.10.23.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">16.5</td>
<td id="A1.T1.10.23.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">29.6</td>
<td id="A1.T1.10.23.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">9.6</td>
<td id="A1.T1.10.23.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">3.4</td>
<td id="A1.T1.10.23.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">37.7</td>
<td id="A1.T1.10.23.10" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">15.4</td>
</tr>
<tr id="A1.T1.10.10" class="ltx_tr">
<td id="A1.T1.9.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Llava-our-<math id="A1.T1.9.9.1.m1.1" class="ltx_Math" alttext="62k" display="inline"><semantics id="A1.T1.9.9.1.m1.1a"><mrow id="A1.T1.9.9.1.m1.1.1" xref="A1.T1.9.9.1.m1.1.1.cmml"><mn id="A1.T1.9.9.1.m1.1.1.2" xref="A1.T1.9.9.1.m1.1.1.2.cmml">62</mn><mo lspace="0em" rspace="0em" id="A1.T1.9.9.1.m1.1.1.1" xref="A1.T1.9.9.1.m1.1.1.1.cmml">​</mo><mi id="A1.T1.9.9.1.m1.1.1.3" xref="A1.T1.9.9.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.9.9.1.m1.1b"><apply id="A1.T1.9.9.1.m1.1.1.cmml" xref="A1.T1.9.9.1.m1.1.1"><times id="A1.T1.9.9.1.m1.1.1.1.cmml" xref="A1.T1.9.9.1.m1.1.1.1"></times><cn type="integer" id="A1.T1.9.9.1.m1.1.1.2.cmml" xref="A1.T1.9.9.1.m1.1.1.2">62</cn><ci id="A1.T1.9.9.1.m1.1.1.3.cmml" xref="A1.T1.9.9.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.9.9.1.m1.1c">62k</annotation></semantics></math>
</td>
<td id="A1.T1.10.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">30.3</td>
<td id="A1.T1.10.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">51.8</td>
<td id="A1.T1.10.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">67.7<sup id="A1.T1.10.10.2.1" class="ltx_sup"><span id="A1.T1.10.10.2.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="A1.T1.10.10.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">16.5</td>
<td id="A1.T1.10.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">30.1</td>
<td id="A1.T1.10.10.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">12.3</td>
<td id="A1.T1.10.10.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">3.6</td>
<td id="A1.T1.10.10.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">44.1</td>
<td id="A1.T1.10.10.10" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">32.0</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table A1: </span>Evaluating LMMs using our synthesized benchmark containing eight reasoning tasks. Bold indicates the best performance. <sup id="A1.T1.14.1" class="ltx_sup"><span id="A1.T1.14.1.1" class="ltx_text ltx_font_italic">∗</span></sup> indicates the second highest.</figcaption>
</figure>
<figure id="A1.F1" class="ltx_figure"><img src="/html/2407.07053/assets/x5.png" id="A1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="230" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A1: </span> We analyzed the impact of synthetic data quantity on the model’s performance. We fine-tune Llava-1.5-7B using chart and table instruction data of varying scales and report its accuracy. Additionally, we report the accuracy for four sub-category tasks: Detailed Perception, Data Extraction, Math Reasoning, and OCR.</figcaption>
</figure>
<figure id="A1.F2" class="ltx_figure"><img src="/html/2407.07053/assets/x6.png" id="A1.F2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="573" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A2: </span>The chart task includes five types of charts (<span id="A1.F2.3.1" class="ltx_text" style="color:#FFFF00;">pie chart, line chart, table, bar chart, composite chart</span>), each containing five types of questions (<span id="A1.F2.4.2" class="ltx_text" style="color:#00FF00;">Data Extraction, Math Reasoning, OCR, Detailed Perception, Caption Problem</span>).</figcaption>
</figure>
<figure id="A1.F3" class="ltx_figure"><img src="/html/2407.07053/assets/x7.png" id="A1.F3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="573" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A3: </span>We present two examples of road map navigation, including the synthesized simulated maps, questions, and answers.</figcaption>
</figure>
<figure id="A1.F4" class="ltx_figure"><img src="/html/2407.07053/assets/x8.png" id="A1.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="573" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A4: </span>We present five examples of dashboard.</figcaption>
</figure>
<figure id="A1.F5" class="ltx_figure"><img src="/html/2407.07053/assets/x9.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="553" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A5: </span>We present two examples of relation graph, each containing two types of questions.</figcaption>
</figure>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2407.07053/assets/x10.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="573" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A6: </span>We present two examples of flowchart (<span id="A1.F6.3.1" class="ltx_text" style="color:#FFFF00;">algorithm workflow and operating workflow</span>), each containing two kinds of questions (<span id="A1.F6.4.2" class="ltx_text" style="color:#00FF00;">Structural and Reasoning Problem</span>).</figcaption>
</figure>
<figure id="A1.F7" class="ltx_figure"><img src="/html/2407.07053/assets/x11.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="573" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A7: </span>We present two categories of visual puzzles (<span id="A1.F7.2.1" class="ltx_text" style="color:#FFFF00;">visual pattern reasoning and muti-subgraph comparison</span>), each containing four visual puzzle graphs, questions, and answers.</figcaption>
</figure>
<figure id="A1.F8" class="ltx_figure"><img src="/html/2407.07053/assets/x12.png" id="A1.F8.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="573" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A8: </span>We present five examples of 2D planar layout, including the layout graph, problems, answers and rationales.</figcaption>
</figure>
<figure id="A1.1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A1.1.1" class="ltx_listing ltx_figure_panel ltx_lstlisting ltx_listing" style="background-color:#F5F5F4;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,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" download="">⬇</a></div>
<div id="lstnumberx26" class="ltx_listingline">
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span id="lstnumberx27.1" class="ltx_text ltx_font_typewriter">---------------</span><span id="lstnumberx27.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx27.3" class="ltx_text ltx_font_typewriter ltx_font_bold">Data Prompt</span><span id="lstnumberx27.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx27.5" class="ltx_text ltx_font_typewriter">---------------</span>
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span id="lstnumberx28.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Generate</span><span id="lstnumberx28.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx28.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx28.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx28.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">related</span><span id="lstnumberx28.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx28.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">to</span><span id="lstnumberx28.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx28.9" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Digital Forensics Unit</span><span id="lstnumberx28.10" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx29" class="ltx_listingline">
<span id="lstnumberx29.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Requirements</span><span id="lstnumberx29.2" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx30" class="ltx_listingline">
<span id="lstnumberx30.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx30.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx30.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx30.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">describe</span><span id="lstnumberx30.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx30.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">tree</span><span id="lstnumberx30.12" class="ltx_text ltx_font_typewriter">-</span><span id="lstnumberx30.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">like</span><span id="lstnumberx30.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">structure</span><span id="lstnumberx30.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx30.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Digital</span><span id="lstnumberx30.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Forensics</span><span id="lstnumberx30.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx30.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Unit</span><span id="lstnumberx30.24" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx31" class="ltx_listingline">
<span id="lstnumberx31.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">There</span><span id="lstnumberx31.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">can</span><span id="lstnumberx31.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">be</span><span id="lstnumberx31.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">multiple</span><span id="lstnumberx31.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">layers</span><span id="lstnumberx31.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx31.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">certain</span><span id="lstnumberx31.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx31.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">can</span><span id="lstnumberx31.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">have</span><span id="lstnumberx31.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">no</span><span id="lstnumberx31.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">children</span><span id="lstnumberx31.24" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx32" class="ltx_listingline">
<span id="lstnumberx32.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx32.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx32.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx32.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">not</span><span id="lstnumberx32.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">contain</span><span id="lstnumberx32.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">too</span><span id="lstnumberx32.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">much</span><span id="lstnumberx32.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx32.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx32.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx32.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">not</span><span id="lstnumberx32.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">be</span><span id="lstnumberx32.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">too</span><span id="lstnumberx32.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx32.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">complicated</span><span id="lstnumberx32.28" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx33" class="ltx_listingline">
<span id="lstnumberx33.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Increase</span><span id="lstnumberx33.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx33.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">depth</span><span id="lstnumberx33.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx33.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx33.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx33.12" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx33.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">but</span><span id="lstnumberx33.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">no</span><span id="lstnumberx33.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">more</span><span id="lstnumberx33.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">than</span><span id="lstnumberx33.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.22" class="ltx_text ltx_font_typewriter">3</span><span id="lstnumberx33.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx33.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx33.27" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.28" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx33.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">same</span><span id="lstnumberx33.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">layer</span><span id="lstnumberx33.33" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx34" class="ltx_listingline">
<span id="lstnumberx34.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx34.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">total</span><span id="lstnumberx34.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">number</span><span id="lstnumberx34.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx34.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx34.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx34.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">not</span><span id="lstnumberx34.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">exceed</span><span id="lstnumberx34.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.17" class="ltx_text ltx_font_typewriter">8.</span>
</div>
<div id="lstnumberx35" class="ltx_listingline">
<span id="lstnumberx35.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Output</span><span id="lstnumberx35.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx35.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">format</span><span id="lstnumberx35.4" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx35.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx35.6" class="ltx_text ltx_font_typewriter">{"</span><span id="lstnumberx35.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx35.8" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx35.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx35.10" class="ltx_text ltx_font_typewriter">{...}}</span>
</div>
<div id="lstnumberx36" class="ltx_listingline">
</div>
<div id="lstnumberx37" class="ltx_listingline">
<span id="lstnumberx37.1" class="ltx_text ltx_font_typewriter" style="color:#00FF00;">Instance:</span>
</div>
<div id="lstnumberx38" class="ltx_listingline">
<span id="lstnumberx38.1" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx39" class="ltx_listingline">
<span id="lstnumberx39.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx39.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx39.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx39.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx39.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx39.6" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx40" class="ltx_listingline">
<span id="lstnumberx40.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx40.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx40.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Digital</span><span id="lstnumberx40.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx40.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Forensics</span><span id="lstnumberx40.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx40.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Unit</span><span id="lstnumberx40.8" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx40.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx40.10" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx41" class="ltx_listingline">
<span id="lstnumberx41.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx41.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx41.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Case</span><span id="lstnumberx41.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx41.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Management</span><span id="lstnumberx41.6" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx41.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx41.8" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx42" class="ltx_listingline">
<span id="lstnumberx42.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx42.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx42.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Evidence</span><span id="lstnumberx42.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx42.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Collection</span><span id="lstnumberx42.6" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx42.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx42.8" class="ltx_text ltx_font_typewriter">{},</span>
</div>
<div id="lstnumberx43" class="ltx_listingline">
<span id="lstnumberx43.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx43.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx43.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Analysis</span><span id="lstnumberx43.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx43.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx43.6" class="ltx_text ltx_font_typewriter">{}</span>
</div>
<div id="lstnumberx44" class="ltx_listingline">
<span id="lstnumberx44.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx44.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx45" class="ltx_listingline">
<span id="lstnumberx45.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx45.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx45.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Training</span><span id="lstnumberx45.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx45.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Development</span><span id="lstnumberx45.8" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx45.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.10" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx46" class="ltx_listingline">
<span id="lstnumberx46.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx46.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx46.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Workshops</span><span id="lstnumberx46.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx46.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx46.6" class="ltx_text ltx_font_typewriter">{},</span>
</div>
<div id="lstnumberx47" class="ltx_listingline">
<span id="lstnumberx47.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx47.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx47.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Certifications</span><span id="lstnumberx47.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx47.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx47.6" class="ltx_text ltx_font_typewriter">{}</span>
</div>
<div id="lstnumberx48" class="ltx_listingline">
<span id="lstnumberx48.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx48.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx49" class="ltx_listingline">
<span id="lstnumberx49.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx49.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx50" class="ltx_listingline">
<span id="lstnumberx50.1" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx51" class="ltx_listingline">
</div>
<div id="lstnumberx52" class="ltx_listingline">
<span id="lstnumberx52.1" class="ltx_text ltx_font_typewriter">---------------</span><span id="lstnumberx52.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx52.3" class="ltx_text ltx_font_typewriter ltx_font_bold">Title Prompt</span><span id="lstnumberx52.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx52.5" class="ltx_text ltx_font_typewriter">---------------</span>
</div>
<div id="lstnumberx53" class="ltx_listingline">
<span id="lstnumberx53.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Generate</span><span id="lstnumberx53.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx53.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx53.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx53.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">title</span><span id="lstnumberx53.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx53.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">for</span><span id="lstnumberx53.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx53.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx53.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx53.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx53.12" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx54" class="ltx_listingline">
<span id="lstnumberx54.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Requirements</span><span id="lstnumberx54.2" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx55" class="ltx_listingline">
<span id="lstnumberx55.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx55.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx55.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">title</span><span id="lstnumberx55.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx55.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx55.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx55.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">be</span><span id="lstnumberx55.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx55.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">brief</span><span id="lstnumberx55.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx55.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx55.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx55.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">concise</span><span id="lstnumberx55.14" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx56" class="ltx_listingline">
<span id="lstnumberx56.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx56.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">title</span><span id="lstnumberx56.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx56.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">describe</span><span id="lstnumberx56.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx56.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">general</span><span id="lstnumberx56.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">content</span><span id="lstnumberx56.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx56.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx56.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx56.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx56.20" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx57" class="ltx_listingline">
<span id="lstnumberx57.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Output</span><span id="lstnumberx57.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx57.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">format</span><span id="lstnumberx57.4" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx57.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx57.6" class="ltx_text ltx_font_typewriter">{"</span><span id="lstnumberx57.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">caption</span><span id="lstnumberx57.8" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx57.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx57.10" class="ltx_text ltx_font_typewriter">"..."</span><span id="lstnumberx57.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx57.12" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx58" class="ltx_listingline">
</div>
<div id="lstnumberx59" class="ltx_listingline">
<span id="lstnumberx59.1" class="ltx_text ltx_font_typewriter" style="color:#00FF00;">Instance:</span><span id="lstnumberx59.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx59.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Digital</span><span id="lstnumberx59.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx59.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Forensics</span><span id="lstnumberx59.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx59.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Unit</span>
</div>
<div id="lstnumberx60" class="ltx_listingline">
</div>
<div id="lstnumberx61" class="ltx_listingline">
<span id="lstnumberx61.1" class="ltx_text ltx_font_typewriter">---------------</span><span id="lstnumberx61.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx61.3" class="ltx_text ltx_font_typewriter ltx_font_bold">Code Prompt</span><span id="lstnumberx61.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx61.5" class="ltx_text ltx_font_typewriter">---------------</span>
</div>
<div id="lstnumberx62" class="ltx_listingline">
<span id="lstnumberx62.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Generate</span><span id="lstnumberx62.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">high</span><span id="lstnumberx62.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">quality</span><span id="lstnumberx62.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.7" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">python code</span><span id="lstnumberx62.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">to</span><span id="lstnumberx62.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">draw</span><span id="lstnumberx62.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx62.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx62.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx62.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">for</span><span id="lstnumberx62.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx62.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx62.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx62.24" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx63" class="ltx_listingline">
<span id="lstnumberx63.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Requirements</span><span id="lstnumberx63.2" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx64" class="ltx_listingline">
<span id="lstnumberx64.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx64.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">code</span><span id="lstnumberx64.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">should</span><span id="lstnumberx64.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">only</span><span id="lstnumberx64.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">use</span><span id="lstnumberx64.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">packages</span><span id="lstnumberx64.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">from</span><span id="lstnumberx64.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx64.15" class="ltx_text ltx_font_typewriter">[’</span><span id="lstnumberx64.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graphviz</span><span id="lstnumberx64.17" class="ltx_text ltx_font_typewriter">’].</span>
</div>
<div id="lstnumberx65" class="ltx_listingline">
<span id="lstnumberx65.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">The</span><span id="lstnumberx65.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">code</span><span id="lstnumberx65.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">must</span><span id="lstnumberx65.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">conform</span><span id="lstnumberx65.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">general</span><span id="lstnumberx65.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">requirements</span><span id="lstnumberx65.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.13" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx65.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">given</span><span id="lstnumberx65.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx65.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">JSON</span><span id="lstnumberx65.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx65.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">format</span><span id="lstnumberx65.21" class="ltx_text ltx_font_typewriter">):</span>
</div>
<div id="lstnumberx66" class="ltx_listingline">
<span id="lstnumberx66.1" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx67" class="ltx_listingline">
<span id="lstnumberx67.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx67.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx67.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">title</span><span id="lstnumberx67.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx67.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx67.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx67.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Graphic</span><span id="lstnumberx67.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx67.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Design</span><span id="lstnumberx67.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx67.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Team</span><span id="lstnumberx67.12" class="ltx_text ltx_font_typewriter">",</span>
</div>
<div id="lstnumberx68" class="ltx_listingline">
<span id="lstnumberx68.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx68.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx68.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx68.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx68.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx68.6" class="ltx_text ltx_font_typewriter">[</span>
</div>
<div id="lstnumberx69" class="ltx_listingline">
<span id="lstnumberx69.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx69.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx69.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">all</span><span id="lstnumberx69.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx69.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx69.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx69.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">must</span><span id="lstnumberx69.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx69.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">be</span><span id="lstnumberx69.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx69.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">used</span><span id="lstnumberx69.12" class="ltx_text ltx_font_typewriter">",</span>
</div>
<div id="lstnumberx70" class="ltx_listingline">
<span id="lstnumberx70.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx70.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx70.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">annotate</span><span id="lstnumberx70.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx70.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx70.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx70.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx70.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx70.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">on</span><span id="lstnumberx70.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx70.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx70.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx70.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx70.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx70.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx70.16" class="ltx_text ltx_font_typewriter">"</span>
</div>
<div id="lstnumberx71" class="ltx_listingline">
<span id="lstnumberx71.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx71.2" class="ltx_text ltx_font_typewriter">],</span>
</div>
<div id="lstnumberx72" class="ltx_listingline">
<span id="lstnumberx72.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx72.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx72.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">layout</span><span id="lstnumberx72.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx72.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx72.6" class="ltx_text ltx_font_typewriter">[</span>
</div>
<div id="lstnumberx73" class="ltx_listingline">
<span id="lstnumberx73.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx73.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx73.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">draw</span><span id="lstnumberx73.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">an</span><span id="lstnumberx73.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">hierarchy</span><span id="lstnumberx73.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">structured</span><span id="lstnumberx73.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx73.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx73.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx73.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx73.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx73.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx73.20" class="ltx_text ltx_font_typewriter">",</span>
</div>
<div id="lstnumberx74" class="ltx_listingline">
<span id="lstnumberx74.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx74.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx74.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx74.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">different</span><span id="lstnumberx74.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">levels</span><span id="lstnumberx74.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx74.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">positioned</span><span id="lstnumberx74.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">vertically</span><span id="lstnumberx74.14" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx74.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx74.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">on</span><span id="lstnumberx74.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx74.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">same</span><span id="lstnumberx74.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">level</span><span id="lstnumberx74.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx74.27" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.28" class="ltx_text ltx_lst_identifier ltx_font_typewriter">positioned</span><span id="lstnumberx74.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">horizontallyuse</span><span id="lstnumberx74.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">arrows</span><span id="lstnumberx74.33" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.34" class="ltx_text ltx_lst_identifier ltx_font_typewriter">or</span><span id="lstnumberx74.35" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.36" class="ltx_text ltx_lst_identifier ltx_font_typewriter">lines</span><span id="lstnumberx74.37" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.38" class="ltx_text ltx_lst_identifier ltx_font_typewriter">to</span><span id="lstnumberx74.39" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.40" class="ltx_text ltx_lst_identifier ltx_font_typewriter">connect</span><span id="lstnumberx74.41" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx74.42" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx74.43" class="ltx_text ltx_font_typewriter">",</span>
</div>
<div id="lstnumberx75" class="ltx_listingline">
<span id="lstnumberx75.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx75.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx75.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">do</span><span id="lstnumberx75.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx75.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">not</span><span id="lstnumberx75.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx75.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">show</span><span id="lstnumberx75.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx75.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">axis</span><span id="lstnumberx75.10" class="ltx_text ltx_font_typewriter">"</span>
</div>
<div id="lstnumberx76" class="ltx_listingline">
<span id="lstnumberx76.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx76.2" class="ltx_text ltx_font_typewriter">]</span>
</div>
<div id="lstnumberx77" class="ltx_listingline">
<span id="lstnumberx77.1" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx78" class="ltx_listingline">
<span id="lstnumberx78.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Output</span><span id="lstnumberx78.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx78.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">format</span><span id="lstnumberx78.4" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx78.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx78.6" class="ltx_text ltx_font_typewriter">‘‘‘</span><span id="lstnumberx78.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">python</span><span id="lstnumberx78.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx78.9" class="ltx_text ltx_font_typewriter">...</span><span id="lstnumberx78.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx78.11" class="ltx_text ltx_font_typewriter">‘‘‘</span>
</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2407.07053/assets/figure/20240613194333999985.png" id="A1.1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="479" height="192" alt="[Uncaptioned image]"></div>
</div>
</figure>
<figure id="A1.fig1" class="ltx_figure">
<div id="A1.fig1.1" class="ltx_listing ltx_lstlisting ltx_listing" style="background-color:#F5F5F4;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,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" download="">⬇</a></div>
<div id="lstnumberx79" class="ltx_listingline">
<span id="lstnumberx79.1" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx79.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">continue</span><span id="lstnumberx79.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx79.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">from</span><span id="lstnumberx79.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx79.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">last</span><span id="lstnumberx79.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx79.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">page</span><span id="lstnumberx79.9" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx80" class="ltx_listingline">
</div>
<div id="lstnumberx81" class="ltx_listingline">
<span id="lstnumberx81.1" class="ltx_text ltx_font_typewriter">---------------</span><span id="lstnumberx81.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx81.3" class="ltx_text ltx_font_typewriter ltx_font_bold">Question-Answer Prompt</span><span id="lstnumberx81.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx81.5" class="ltx_text ltx_font_typewriter">---------------</span>
</div>
<div id="lstnumberx82" class="ltx_listingline">
<span id="lstnumberx82.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Generate</span><span id="lstnumberx82.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">correct</span><span id="lstnumberx82.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx82.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">high</span><span id="lstnumberx82.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">quality</span><span id="lstnumberx82.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.11" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">question-answer</span><span id="lstnumberx82.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pairs</span><span id="lstnumberx82.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">about</span><span id="lstnumberx82.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx82.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx82.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx82.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx82.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx82.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx82.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx82.28" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx83" class="ltx_listingline">
<span id="lstnumberx83.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Requirements</span><span id="lstnumberx83.2" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx84" class="ltx_listingline">
<span id="lstnumberx84.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Question</span><span id="lstnumberx84.2" class="ltx_text ltx_font_typewriter">-</span><span id="lstnumberx84.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">answer</span><span id="lstnumberx84.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx84.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">types</span><span id="lstnumberx84.6" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx85" class="ltx_listingline">
<span id="lstnumberx85.1" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx86" class="ltx_listingline">
<span id="lstnumberx86.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx86.2" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">STRUCTURAL</span><span id="lstnumberx86.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx86.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx86.5" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx87" class="ltx_listingline">
<span id="lstnumberx87.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx87.2" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx87.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Example</span><span id="lstnumberx87.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.5" class="ltx_text ltx_font_typewriter">1’:</span><span id="lstnumberx87.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.7" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx87.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx87.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">is</span><span id="lstnumberx87.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx87.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">type</span><span id="lstnumberx87.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx87.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">this</span><span id="lstnumberx87.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">figure</span><span id="lstnumberx87.21" class="ltx_text ltx_font_typewriter">?</span><span id="lstnumberx87.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Choose</span><span id="lstnumberx87.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">your</span><span id="lstnumberx87.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">answer</span><span id="lstnumberx87.28" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter">from</span><span id="lstnumberx87.30" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.31" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx87.32" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.33" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx87.34" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx87.35" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.36" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pie</span><span id="lstnumberx87.37" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.38" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx87.39" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx87.40" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.41" class="ltx_text ltx_lst_identifier ltx_font_typewriter">line</span><span id="lstnumberx87.42" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.43" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx87.44" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx87.45" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.46" class="ltx_text ltx_lst_identifier ltx_font_typewriter">gantt</span><span id="lstnumberx87.47" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx87.48" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx87.49" class="ltx_text ltx_font_typewriter">.’,</span>
</div>
<div id="lstnumberx88" class="ltx_listingline">
<span id="lstnumberx88.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx88.2" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx88.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Example</span><span id="lstnumberx88.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx88.5" class="ltx_text ltx_font_typewriter">2’:</span><span id="lstnumberx88.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx88.7" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx88.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx88.9" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx88.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">s</span><span id="lstnumberx88.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx88.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx88.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx88.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">color</span><span id="lstnumberx88.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx88.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx88.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx88.18" class="ltx_text ltx_font_typewriter">{</span><span id="lstnumberx88.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx88.20" class="ltx_text ltx_font_typewriter">}?"},</span>
</div>
<div id="lstnumberx89" class="ltx_listingline">
<span id="lstnumberx89.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx89.2" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">MATH_REASONING</span><span id="lstnumberx89.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx89.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx89.5" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx90" class="ltx_listingline">
<span id="lstnumberx90.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx90.2" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx90.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Example</span><span id="lstnumberx90.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.5" class="ltx_text ltx_font_typewriter">1’:</span><span id="lstnumberx90.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.7" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx90.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Does</span><span id="lstnumberx90.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.10" class="ltx_text ltx_font_typewriter">{</span><span id="lstnumberx90.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">name</span><span id="lstnumberx90.12" class="ltx_text ltx_font_typewriter">}</span><span id="lstnumberx90.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx90.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">exist</span><span id="lstnumberx90.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx90.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">this</span><span id="lstnumberx90.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx90.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">figure</span><span id="lstnumberx90.23" class="ltx_text ltx_font_typewriter">?’,</span>
</div>
<div id="lstnumberx91" class="ltx_listingline">
<span id="lstnumberx91.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx91.2" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx91.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Example</span><span id="lstnumberx91.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx91.5" class="ltx_text ltx_font_typewriter">2’:</span><span id="lstnumberx91.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx91.7" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx91.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">How</span><span id="lstnumberx91.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx91.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">many</span><span id="lstnumberx91.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx91.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx91.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx91.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx91.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx91.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">there</span><span id="lstnumberx91.17" class="ltx_text ltx_font_typewriter">?’}</span>
</div>
<div id="lstnumberx92" class="ltx_listingline">
<span id="lstnumberx92.1" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx93" class="ltx_listingline">
<span id="lstnumberx93.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">If</span><span id="lstnumberx93.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">applicable</span><span id="lstnumberx93.4" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx93.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx93.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">answer</span><span id="lstnumberx93.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">can</span><span id="lstnumberx93.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">be</span><span id="lstnumberx93.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">a</span><span id="lstnumberx93.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">single</span><span id="lstnumberx93.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx93.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">word</span><span id="lstnumberx93.19" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx94" class="ltx_listingline">
<span id="lstnumberx94.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Consider</span><span id="lstnumberx94.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx94.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">data</span><span id="lstnumberx94.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx94.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">code</span><span id="lstnumberx94.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">together</span><span id="lstnumberx94.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">to</span><span id="lstnumberx94.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">get</span><span id="lstnumberx94.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx94.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx94.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">answer</span><span id="lstnumberx94.20" class="ltx_text ltx_font_typewriter">.</span>
</div>
<div id="lstnumberx95" class="ltx_listingline">
<span id="lstnumberx95.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Output</span><span id="lstnumberx95.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx95.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">format</span><span id="lstnumberx95.4" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx95.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx95.6" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx96" class="ltx_listingline">
<span id="lstnumberx96.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx96.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx96.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">STRUCTURAL</span><span id="lstnumberx96.4" class="ltx_text ltx_font_typewriter">":[{"</span><span id="lstnumberx96.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx96.6" class="ltx_text ltx_font_typewriter">":"...",</span><span id="lstnumberx96.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx96.8" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx96.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx96.10" class="ltx_text ltx_font_typewriter">":"..."},</span><span id="lstnumberx96.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx96.12" class="ltx_text ltx_font_typewriter">...],</span>
</div>
<div id="lstnumberx97" class="ltx_listingline">
<span id="lstnumberx97.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx97.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx97.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">MATH_REASONING</span><span id="lstnumberx97.4" class="ltx_text ltx_font_typewriter">":[{"</span><span id="lstnumberx97.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx97.6" class="ltx_text ltx_font_typewriter">":"...",</span><span id="lstnumberx97.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx97.8" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx97.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx97.10" class="ltx_text ltx_font_typewriter">":"..."},</span><span id="lstnumberx97.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx97.12" class="ltx_text ltx_font_typewriter">...]</span>
</div>
<div id="lstnumberx98" class="ltx_listingline">
<span id="lstnumberx98.1" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx99" class="ltx_listingline">
</div>
<div id="lstnumberx100" class="ltx_listingline">
<span id="lstnumberx100.1" class="ltx_text ltx_font_typewriter" style="color:#00FF00;">Instance:</span>
</div>
<div id="lstnumberx101" class="ltx_listingline">
<span id="lstnumberx101.1" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx102" class="ltx_listingline">
<span id="lstnumberx102.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx102.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx102.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">STRUCTURAL</span><span id="lstnumberx102.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx102.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx102.6" class="ltx_text ltx_font_typewriter">[</span>
</div>
<div id="lstnumberx103" class="ltx_listingline">
<span id="lstnumberx103.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx103.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx104" class="ltx_listingline">
<span id="lstnumberx104.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx104.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx104.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx104.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx104.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx104.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx104.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">is</span><span id="lstnumberx104.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx104.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">type</span><span id="lstnumberx104.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx104.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">this</span><span id="lstnumberx104.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">figure</span><span id="lstnumberx104.20" class="ltx_text ltx_font_typewriter">?</span><span id="lstnumberx104.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Choose</span><span id="lstnumberx104.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">your</span><span id="lstnumberx104.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">answer</span><span id="lstnumberx104.27" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.28" class="ltx_text ltx_lst_identifier ltx_font_typewriter">from</span><span id="lstnumberx104.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx104.31" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx104.33" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx104.34" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.35" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pie</span><span id="lstnumberx104.36" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.37" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx104.38" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx104.39" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.40" class="ltx_text ltx_lst_identifier ltx_font_typewriter">line</span><span id="lstnumberx104.41" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.42" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx104.43" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx104.44" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.45" class="ltx_text ltx_lst_identifier ltx_font_typewriter">gantt</span><span id="lstnumberx104.46" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx104.47" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx104.48" class="ltx_text ltx_font_typewriter">.",</span>
</div>
<div id="lstnumberx105" class="ltx_listingline">
<span id="lstnumberx105.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx105.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx105.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx105.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx105.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx105.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx105.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">organization</span><span id="lstnumberx105.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx105.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">chart</span><span id="lstnumberx105.10" class="ltx_text ltx_font_typewriter">"</span>
</div>
<div id="lstnumberx106" class="ltx_listingline">
<span id="lstnumberx106.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx106.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx107" class="ltx_listingline">
<span id="lstnumberx107.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx107.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx108" class="ltx_listingline">
<span id="lstnumberx108.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx108.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx108.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx108.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx108.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx108.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">What</span><span id="lstnumberx108.8" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx108.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">s</span><span id="lstnumberx108.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx108.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">color</span><span id="lstnumberx108.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">of</span><span id="lstnumberx108.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx108.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.19" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx108.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Digital</span><span id="lstnumberx108.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Forensics</span><span id="lstnumberx108.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Unit</span><span id="lstnumberx108.25" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx108.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx108.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx108.28" class="ltx_text ltx_font_typewriter">?",</span>
</div>
<div id="lstnumberx109" class="ltx_listingline">
<span id="lstnumberx109.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx109.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx109.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx109.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx109.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx109.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx109.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">lightblue</span><span id="lstnumberx109.8" class="ltx_text ltx_font_typewriter">"</span>
</div>
<div id="lstnumberx110" class="ltx_listingline">
<span id="lstnumberx110.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx110.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx111" class="ltx_listingline">
<span id="lstnumberx111.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx111.2" class="ltx_text ltx_font_typewriter">],</span>
</div>
<div id="lstnumberx112" class="ltx_listingline">
<span id="lstnumberx112.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx112.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx112.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">MATH_REASONING</span><span id="lstnumberx112.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx112.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx112.6" class="ltx_text ltx_font_typewriter">[</span>
</div>
<div id="lstnumberx113" class="ltx_listingline">
<span id="lstnumberx113.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx113.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx114" class="ltx_listingline">
<span id="lstnumberx114.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx114.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx114.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx114.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx114.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx114.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">How</span><span id="lstnumberx114.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">many</span><span id="lstnumberx114.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx114.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx114.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">there</span><span id="lstnumberx114.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx114.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx114.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.21" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx114.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Digital</span><span id="lstnumberx114.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Forensics</span><span id="lstnumberx114.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx114.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Unit</span><span id="lstnumberx114.27" class="ltx_text ltx_font_typewriter">’?",</span>
</div>
<div id="lstnumberx115" class="ltx_listingline">
<span id="lstnumberx115.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx115.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx115.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx115.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx115.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx115.6" class="ltx_text ltx_font_typewriter">"2"</span>
</div>
<div id="lstnumberx116" class="ltx_listingline">
<span id="lstnumberx116.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx116.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx117" class="ltx_listingline">
<span id="lstnumberx117.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx117.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx118" class="ltx_listingline">
<span id="lstnumberx118.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx118.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx118.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx118.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx118.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx118.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Does</span><span id="lstnumberx118.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx118.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.11" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx118.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Evidence</span><span id="lstnumberx118.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Collection</span><span id="lstnumberx118.15" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx118.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx118.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">exist</span><span id="lstnumberx118.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx118.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">this</span><span id="lstnumberx118.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx118.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">figure</span><span id="lstnumberx118.26" class="ltx_text ltx_font_typewriter">?",</span>
</div>
<div id="lstnumberx119" class="ltx_listingline">
<span id="lstnumberx119.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx119.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx119.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx119.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx119.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx119.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx119.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Yes</span><span id="lstnumberx119.8" class="ltx_text ltx_font_typewriter">"</span>
</div>
<div id="lstnumberx120" class="ltx_listingline">
<span id="lstnumberx120.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx120.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx121" class="ltx_listingline">
<span id="lstnumberx121.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx121.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx122" class="ltx_listingline">
<span id="lstnumberx122.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx122.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx122.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx122.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx122.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx122.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">How</span><span id="lstnumberx122.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">many</span><span id="lstnumberx122.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx122.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx122.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">there</span><span id="lstnumberx122.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx122.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx122.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.21" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx122.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Case</span><span id="lstnumberx122.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Management</span><span id="lstnumberx122.25" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx122.26" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx122.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">department</span><span id="lstnumberx122.28" class="ltx_text ltx_font_typewriter">?",</span>
</div>
<div id="lstnumberx123" class="ltx_listingline">
<span id="lstnumberx123.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx123.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx123.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx123.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx123.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx123.6" class="ltx_text ltx_font_typewriter">"2"</span>
</div>
<div id="lstnumberx124" class="ltx_listingline">
<span id="lstnumberx124.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx124.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx125" class="ltx_listingline">
<span id="lstnumberx125.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx125.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx126" class="ltx_listingline">
<span id="lstnumberx126.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx126.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx126.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx126.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx126.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx126.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">How</span><span id="lstnumberx126.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">many</span><span id="lstnumberx126.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">nodes</span><span id="lstnumberx126.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx126.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">there</span><span id="lstnumberx126.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx126.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx126.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.21" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx126.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Training</span><span id="lstnumberx126.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">and</span><span id="lstnumberx126.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Development</span><span id="lstnumberx126.27" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx126.28" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx126.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter">department</span><span id="lstnumberx126.30" class="ltx_text ltx_font_typewriter">?",</span>
</div>
<div id="lstnumberx127" class="ltx_listingline">
<span id="lstnumberx127.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx127.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx127.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx127.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx127.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx127.6" class="ltx_text ltx_font_typewriter">"2"</span>
</div>
<div id="lstnumberx128" class="ltx_listingline">
<span id="lstnumberx128.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx128.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx129" class="ltx_listingline">
<span id="lstnumberx129.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx129.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx130" class="ltx_listingline">
<span id="lstnumberx130.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx130.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx130.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Q</span><span id="lstnumberx130.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx130.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.6" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx130.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">How</span><span id="lstnumberx130.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">many</span><span id="lstnumberx130.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">departments</span><span id="lstnumberx130.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">are</span><span id="lstnumberx130.14" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">there</span><span id="lstnumberx130.16" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx130.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">the</span><span id="lstnumberx130.20" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.21" class="ltx_text ltx_font_typewriter">’</span><span id="lstnumberx130.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Digital</span><span id="lstnumberx130.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Forensics</span><span id="lstnumberx130.25" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx130.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Unit</span><span id="lstnumberx130.27" class="ltx_text ltx_font_typewriter">’?",</span>
</div>
<div id="lstnumberx131" class="ltx_listingline">
<span id="lstnumberx131.1" class="ltx_text ltx_lst_space ltx_font_typewriter">          </span><span id="lstnumberx131.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx131.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">A</span><span id="lstnumberx131.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx131.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx131.6" class="ltx_text ltx_font_typewriter">"2"</span>
</div>
<div id="lstnumberx132" class="ltx_listingline">
<span id="lstnumberx132.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx132.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx133" class="ltx_listingline">
<span id="lstnumberx133.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx133.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx134" class="ltx_listingline">
<span id="lstnumberx134.1" class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional Experiment Results</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">As discussed in <a href="#S4.SS2" title="4.2 Benchmarking LMM’s Visual Reasoning ‣ 4 Experiments ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a>, we evaluate the performance of many LMMs, Llava-our-62k
and humans using our benchmark. All results are shown in <a href="#A1.T1" title="In Appendix A Experiments Details ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">A1</span></a>. Besides, as shown in <a href="#A2.T2" title="In Appendix B Additional Experiment Results ‣ Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">B2</span></a>, we also calculated the Rough-L score for the caption sub-task in the chart and table.</p>
</div>
<figure id="A2.T2" class="ltx_table">
<table id="A2.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T2.1.1" class="ltx_tr">
<td id="A2.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="A2.T2.1.1.1.1" class="ltx_text ltx_font_bold">LLMs</span></td>
<td id="A2.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="A2.T2.1.1.2.1" class="ltx_text ltx_font_bold">Rough-L</span></td>
</tr>
<tr id="A2.T2.1.2" class="ltx_tr">
<td id="A2.T2.1.2.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A2.T2.1.2.1.1" class="ltx_text ltx_font_bold">Chart</span></td>
<td id="A2.T2.1.2.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A2.T2.1.2.2.1" class="ltx_text ltx_font_bold">Table</span></td>
</tr>
<tr id="A2.T2.1.3" class="ltx_tr">
<td id="A2.T2.1.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">GPT-4Vision-1106</td>
<td id="A2.T2.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.42</td>
<td id="A2.T2.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.42</td>
</tr>
<tr id="A2.T2.1.4" class="ltx_tr">
<td id="A2.T2.1.4.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Claude-3-Sonnet</td>
<td id="A2.T2.1.4.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.48</td>
<td id="A2.T2.1.4.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.46</td>
</tr>
<tr id="A2.T2.1.5" class="ltx_tr">
<td id="A2.T2.1.5.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Qwen-VL-Plus</td>
<td id="A2.T2.1.5.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.36</td>
<td id="A2.T2.1.5.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.37</td>
</tr>
<tr id="A2.T2.1.6" class="ltx_tr">
<td id="A2.T2.1.6.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Vanilla Llava-1.5-7B</td>
<td id="A2.T2.1.6.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.33</td>
<td id="A2.T2.1.6.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.37</td>
</tr>
<tr id="A2.T2.1.7" class="ltx_tr">
<td id="A2.T2.1.7.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Vanilla Llava-1.5-13B</td>
<td id="A2.T2.1.7.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.33</td>
<td id="A2.T2.1.7.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.40</td>
</tr>
<tr id="A2.T2.1.8" class="ltx_tr">
<td id="A2.T2.1.8.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">InstructBLIP-7B</td>
<td id="A2.T2.1.8.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.04</td>
<td id="A2.T2.1.8.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.23</td>
</tr>
<tr id="A2.T2.1.9" class="ltx_tr">
<td id="A2.T2.1.9.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">InstructBLIP-13B</td>
<td id="A2.T2.1.9.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.05</td>
<td id="A2.T2.1.9.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.11</td>
</tr>
<tr id="A2.T2.1.10" class="ltx_tr">
<td id="A2.T2.1.10.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Deepseek-VL-Chat-1.3B</td>
<td id="A2.T2.1.10.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.36</td>
<td id="A2.T2.1.10.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.35</td>
</tr>
<tr id="A2.T2.1.11" class="ltx_tr">
<td id="A2.T2.1.11.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Deepseek-VL-Chat-7B</td>
<td id="A2.T2.1.11.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.39</td>
<td id="A2.T2.1.11.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">0.37</td>
</tr>
<tr id="A2.T2.1.12" class="ltx_tr">
<td id="A2.T2.1.12.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">Llava-our-62k</td>
<td id="A2.T2.1.12.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">0.46</td>
<td id="A2.T2.1.12.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">0.44</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table B2: </span>For the chart and table tasks, we also calculated the captioning results.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Related Work</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Multi-modal LLMs</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p id="A3.SS1.p1.1" class="ltx_p">With the rapid development of Large Language Models (LLM), many researchers are currently devoting their efforts to developing multimodal large models (MLLM) for visual understanding and reasoning tasks. Beyond OpenAI’s GPT-4V and Google’s Gemini, numerous open-sourced MLLMs have also emerged and gained significant progress.</p>
</div>
<div id="A3.SS1.p2" class="ltx_para">
<p id="A3.SS1.p2.1" class="ltx_p">Recently, MLLMs commonly align visual perception with LLMs to acquire multimodal perceptions through lightweight vision-to-language adapters, including projection, Q-former and additional cross-attention layers. For example, Kosmos-1/2 <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a href="#bib.bib19" title="" class="ltx_ref">2023</a>; Peng et al., <a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite> and LLaVA-series models <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib32" title="" class="ltx_ref">2024b</a>, <a href="#bib.bib31" title="" class="ltx_ref">a</a>)</cite> adopt a linear layer or an MLP to project visual inputs into textual embeddings. Furthermore, PaLM-E <cite class="ltx_cite ltx_citemacro_citep">(Driess et al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>, PandaGPT <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a href="#bib.bib47" title="" class="ltx_ref">2023</a>)</cite>, NExT-GPT <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a href="#bib.bib60" title="" class="ltx_ref">2023a</a>)</cite> and AnyGPT <cite class="ltx_cite ltx_citemacro_citep">(Zhan et al., <a href="#bib.bib76" title="" class="ltx_ref">2024</a>)</cite> even project other multimodal data such as audio, video and robot sensor data into the textual embeddings.
Q-former was first proposed in BLIP-2 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib28" title="" class="ltx_ref">2023b</a>)</cite> by employing a set of learnable queries to bridge the gap between a frozen image encoder and the LLM. It has been used in several other approaches, such as LL3DA <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib10" title="" class="ltx_ref">2023b</a>)</cite>, minigpt-4 <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a href="#bib.bib83" title="" class="ltx_ref">2023</a>)</cite>, InstructBLIP <cite class="ltx_cite ltx_citemacro_citep">(Dai et al., <a href="#bib.bib11" title="" class="ltx_ref">2024</a>)</cite> and mPLUG-Owl <cite class="ltx_cite ltx_citemacro_citep">(Ye et al., <a href="#bib.bib68" title="" class="ltx_ref">2023b</a>)</cite>. Additionally, Flamingo <cite class="ltx_cite ltx_citemacro_citep">(Alayrac et al., <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> and Otter <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib26" title="" class="ltx_ref">2023a</a>)</cite> inserted additional cross-attention layers into the frozen LLM to bridge the vision-only and language-only models.</p>
</div>
<div id="A3.SS1.p3" class="ltx_para">
<p id="A3.SS1.p3.1" class="ltx_p">However, those models are primarily focused on natural images, and there still remain challenges in the comprehension of complex fine-grained images such as charts, documents, and diagrams.</p>
</div>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Benchmark For Multimodal Model</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p id="A3.SS2.p1.1" class="ltx_p">Designing a fair benchmark to evaluate the capabilities of multimodal models has garnered widespread attention within the academic community<cite class="ltx_cite ltx_citemacro_citep">(Antol et al., <a href="#bib.bib4" title="" class="ltx_ref">2015</a>; Fu et al., <a href="#bib.bib14" title="" class="ltx_ref">2023</a>; Xu et al., <a href="#bib.bib66" title="" class="ltx_ref">2023b</a>; Liu et al., <a href="#bib.bib30" title="" class="ltx_ref">2023a</a>; Yu et al., <a href="#bib.bib73" title="" class="ltx_ref">2023b</a>; Yue et al., <a href="#bib.bib74" title="" class="ltx_ref">2024</a>; Liu et al., <a href="#bib.bib34" title="" class="ltx_ref">2024d</a>; Tong et al., <a href="#bib.bib49" title="" class="ltx_ref">2024</a>; Huang et al., <a href="#bib.bib20" title="" class="ltx_ref">2024</a>)</cite>. Recently, some multimodal benchmarks have made valuable explorations into the visual reasoning capabilities and fine-grained recognition abilities of LMMs <cite class="ltx_cite ltx_citemacro_citep">(Yin et al., <a href="#bib.bib70" title="" class="ltx_ref">2024</a>; Liu et al., <a href="#bib.bib35" title="" class="ltx_ref">2023b</a>; Ying et al., <a href="#bib.bib71" title="" class="ltx_ref">2024</a>; Li et al., <a href="#bib.bib27" title="" class="ltx_ref">2024</a>; Wang et al., <a href="#bib.bib52" title="" class="ltx_ref">2024a</a>; Chen et al., <a href="#bib.bib8" title="" class="ltx_ref">2024</a>; Wu et al., <a href="#bib.bib59" title="" class="ltx_ref">2024</a>; Singh et al., <a href="#bib.bib46" title="" class="ltx_ref">2024</a>; Zhang et al., <a href="#bib.bib79" title="" class="ltx_ref">2024b</a>)</cite>.</p>
</div>
<div id="A3.SS2.p2" class="ltx_para">
<p id="A3.SS2.p2.1" class="ltx_p">Besides, several MLLMs have been proposed for chart comprehension and reasoning, including ChartLlama <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>, Unichart <cite class="ltx_cite ltx_citemacro_citep">(Masry et al., <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite>, Structchart <cite class="ltx_cite ltx_citemacro_citep">(Xia et al., <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite>, FinVis-GPT <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>, TinyChart <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib78" title="" class="ltx_ref">2024a</a>)</cite>, CharXiv <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib56" title="" class="ltx_ref">2024b</a>)</cite>, ChartX <cite class="ltx_cite ltx_citemacro_citep">(Xia et al., <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite>, TableVQA-Bench <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2024</a>)</cite> and mChartQA <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a href="#bib.bib57" title="" class="ltx_ref">2024</a>)</cite>. mPLUG-DocOwl <cite class="ltx_cite ltx_citemacro_citep">(Ye et al., <a href="#bib.bib67" title="" class="ltx_ref">2023a</a>)</cite> strengthens the OCR-free document understanding ability with a document instruction tuning dataset. Chartassisstant <cite class="ltx_cite ltx_citemacro_citep">(Meng et al., <a href="#bib.bib42" title="" class="ltx_ref">2024</a>)</cite> undergoes a two-stage training process, starting with pre-training on chart-to-table parsing to align chart and text, followed by multitask instruction-following fine-tuning. ChartInstruct <cite class="ltx_cite ltx_citemacro_citep">(Masry et al., <a href="#bib.bib40" title="" class="ltx_ref">2024</a>)</cite> employs a
two-step approach to extract chart data tables
and input them into the LLM. These efforts have all contributed to the advancement of multimodal technologies.</p>
</div>
</section>
<section id="A3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Data Synthesis</h3>

<div id="A3.SS3.p1" class="ltx_para">
<p id="A3.SS3.p1.1" class="ltx_p">Data synthesis is widely used in LLM training to supplement the insufficiency of instruction-following data. Many studies focus on generating high-quality synthetic data either distilling dialogue data from a strong LLM <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib54" title="" class="ltx_ref">2022b</a>; Xu et al., <a href="#bib.bib65" title="" class="ltx_ref">2023a</a>; Yu et al., <a href="#bib.bib72" title="" class="ltx_ref">2023a</a>; Chen et al., <a href="#bib.bib9" title="" class="ltx_ref">2023a</a>; Zhao et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite>, or using external tools to refine LLM-generated synthetic data <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a href="#bib.bib58" title="" class="ltx_ref">2023</a>; Lee et al., <a href="#bib.bib24" title="" class="ltx_ref">2024</a>)</cite>. For instance, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a href="#bib.bib54" title="" class="ltx_ref">2022b</a>)</cite> proposed <em id="A3.SS3.p1.1.1" class="ltx_emph ltx_font_italic">Self-Instruct</em> to improve the instruction-following ability of LLMs via their own generation of instruction data. <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a href="#bib.bib65" title="" class="ltx_ref">2023a</a>)</cite> further generated more complex instruction through <em id="A3.SS3.p1.1.2" class="ltx_emph ltx_font_italic">Evol-Instruct</em>.
<cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a href="#bib.bib72" title="" class="ltx_ref">2023a</a>)</cite> synthesized a mathematical dataset from LLMs by bootstrapping mathematical questions and rewriting the question from multiple perspectives. <cite class="ltx_cite ltx_citemacro_citet">Wei et al. (<a href="#bib.bib58" title="" class="ltx_ref">2023</a>)</cite> can generate diverse and realistic coding problems from open-source code snippets. <cite class="ltx_cite ltx_citemacro_citet">Lei et al. (<a href="#bib.bib25" title="" class="ltx_ref">2024</a>)</cite> can also create high-quality large code datasets for LLMs. It simulates programmers writing code and conducting unit tests through agent interactions, ensuring annotation accuracy with an external code executor.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.07052" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.07053" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.07053">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.07053" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.07054" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 12:55:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
