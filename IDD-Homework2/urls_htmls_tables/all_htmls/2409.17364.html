<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Exploring synthetic data for cross-speaker style transfer in style representation based TTS</title>
<!--Generated on Wed Sep 25 21:08:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.17364v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S1" title="In Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S2" title="In Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S2.SS1" title="In 2 Method ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Synthetic data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S2.SS2" title="In 2 Method ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Stage 1: Style Encoder</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S2.SS3" title="In 2 Method ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Stage 2: TTS</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S3" title="In Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S3.SS1" title="In 3 Experiments ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Training setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S3.SS2" title="In 3 Experiments ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S4" title="In Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S5" title="In Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion and future work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S6" title="In Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Acknowledgements</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\interspeechcameraready</span><span class="ltx_ERROR undefined" id="p1.2">\name</span>
<p class="ltx_p" id="p1.3">[affiliation=1,2]Lucas H.Ueda
<span class="ltx_ERROR undefined" id="p1.3.1">\name</span>[affiliation=1,2]Leonardo B. de M. M.Marques
<span class="ltx_ERROR undefined" id="p1.3.2">\name</span>[affiliation=2]Flávio O.Simões
<span class="ltx_ERROR undefined" id="p1.3.3">\name</span>[affiliation=2]Mário U.Neto
<span class="ltx_ERROR undefined" id="p1.3.4">\name</span>[affiliation=2]FernandoRunstein
<span class="ltx_ERROR undefined" id="p1.3.5">\name</span>[affiliation=2]BiancaDal Bó
<span class="ltx_ERROR undefined" id="p1.3.6">\name</span>[affiliation=1]Paula D. P.Costa




</p>
</div>
<h1 class="ltx_title ltx_title_document">Exploring synthetic data for cross-speaker style transfer in style representation based TTS</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Incorporating cross-speaker style transfer in text-to-speech (TTS) models is challenging due to the need to disentangle speaker and style information in audio. In low-resource expressive data scenarios, voice conversion (VC) can generate expressive speech for target speakers, which can then be used to train the TTS model. However, the quality and style transfer ability of the VC model are crucial for the overall TTS model quality. In this work, we explore the use of synthetic data generated by a VC model to assist the TTS model in cross-speaker style transfer tasks. Additionally, we employ pre-training of the style encoder using timbre perturbation and prototypical angular loss to mitigate speaker leakage. Our results show that using VC synthetic data can improve the naturalness and speaker similarity of TTS in cross-speaker scenarios. Furthermore, we extend this approach to a cross-language scenario, enhancing accent transfer.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>text-to-speech, cross-speaker style transfer, expressive speech synthesis, synthetic data, representation learning
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Generating expressive speech in text-to-speech (TTS) models usually relies on recording and using data with specific expressive styles. However, recording for all desired speakers is not feasible in many cases. Recent studies aim to mitigate this problem through style transfer between speakers (cross-speaker style transfer), where the speaking style of a reference speaker is transferred to a target speaker with only neutral recordings.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib1" title="">1</a>]</cite>, the Reference Encoder (RE) is proposed as a module that generates a style representation extracted from a reference audio and is incorporated into the TTS model, enabling prosody transfer from a reference speaker to a target speaker. When dealing with datasets labeled with styles, approaches such as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib2" title="">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib3" title="">3</a>]</cite> use these style representations to generate a latent space of representations, thereby controlling and transferring speech styles to neutral speakers in a cross-speaker approach. While the first one uses the centroids of each emotion to perform cross-speaker style transfer, the second employs Principal Component Analysis (PCA) to achieve the same.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">These approaches, based on style representations generated by a module coupled with the TTS model, known as style encoder, rely on generating this latent representation from a reference mel-spectrogram, usually the TTS target mel-spectrogram during training. These modules aim to create a bottleneck capable of capturing prosodic information from the reference while ignoring content or speaker-specific information. In practice, this approach tends to leak speaker information into these representations (speaker leakage), causing the synthetic speech’s timbre to match that of the conditioning representation during inference <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib4" title="">4</a>]</cite>. Moreover, degraded performance is observed when the trained TTS tries to transfer a specific style to a new speaker <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib5" title="">5</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Recent approaches aim to propose style encoders capable of generating disentangled representations, thereby avoiding speaker leakage. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib6" title="">6</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib7" title="">7</a>]</cite> , the use of a gradient reversal layer (GRL) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib8" title="">8</a>]</cite> is proposed to remove speaker information from style encoder. However, these methods still suffer from source speaker leakage and low perceived naturalness in cross-speaker scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In Nansy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib10" title="">10</a>]</cite>, formant shifting is used to remove speaker information from one of the model’s modules. By perturbing the speaker information (timbre perturbation) of this module, it was able to model aspects unrelated to the speaker’s timbre. This approach was utilized by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib11" title="">11</a>]</cite> to disentangle speaker information and emotion, thereby transferring the style of the source speaker while maintaining the target speaker’s timbre. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib12" title="">12</a>]</cite>, timbre perturbation was also employed, successfully transferring not only emotions but also accents, proposing a model capable of performing cross-speaker style and accent transfer.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In scenarios where a large amount of expressive data is not easily available, it may affect the model’s ability to perform style transfer. The use of synthetic data to incorporate cross-speaker style transfer in low-resource scenarios was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib13" title="">13</a>]</cite>, where a voice conversion (VC) model trained on neutral target speakers is used to convert source expressive speech (newscaster and conversational). The TTS is then fine-tuned with the expressive synthetic target speaker data. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib14" title="">14</a>]</cite> also applies a similar methodology to transfer a conversational style to neutral speakers. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib15" title="">15</a>]</cite>, voice conversion is used to generate synthetic cross-language data, as VC can effectively retain content information, thereby training a multilingual TTS system. Although several approaches use synthetic data in TTS training, the quality of the VC model is extremely important, especially in low-resource and highly expressive data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib16" title="">16</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">In this work, we explore the use of synthetic data generated by an F0-conditioned VITS-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib17" title="">17</a>]</cite> voice conversion model to create expressive data for neutral speakers’ voices. We conducted experiments using synthetic data combined with original data to achieve cross-speaker style transfer in a TTS model based on FastPitch <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib18" title="">18</a>]</cite>, augmented with a RE-based style encoder. To obtain meaningful style representations from the style encoder and avoid speaker leakage, we pre-trained it separately using both timbre perturbation and metric learning. Our observations indicate that synthetic data can enhance both naturalness and speaker similarity in cross-speaker TTS models. Additionally, by conditioning on original style representations, it is possible to maintain naturalness improvement while performing style transfer, even for styles that the VC model could not transfer well. Furthermore, we demonstrate that this approach is effective for accent transfer in cross-language tasks. Audio samples are provided in demo page<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Audio samples available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://bit.ly/3VCzFdd" title="">http://bit.ly/3VCzFdd</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="442" id="S2.F1.g1" src="extracted/5848610/fig/2stagetraining.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Two stages TTS training pipeline. Style encoder is pre-trained in stage 1 and remains frozen during TTS training at stage 2. The speaker look-up table encodes speaker information in FastPitch for multi-speaker extension.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We explore the use of synthetic data to aid in cross-speaker style transfer in a TTS model with a style encoder. Initially, we train a voice conversion model on neutral data and convert the expressive speech of the source speaker to all target speakers. Next, we use a two-stage approach for training the TTS model (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S2.F1" title="Figure 1 ‣ 2 Method ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">1</span></a>). In the first stage, we pre-train the style encoder, and in the second stage, we train the TTS using the pre-trained, frozen style encoder. In all stages, the original data is used with or without the addition of synthetic data. To explore the use of synthetic data, we conduct three experiments:</p>
</div>
<div class="ltx_para" id="S2.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Synth none</span>: Only ground truth data is used;</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Synth TTS</span>: Augmenting with synthetic data only in TTS training (stage 2);</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Synth both</span>: Augmenting with synthetic data in both style encoder and TTS (stages 1 and 2).</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Synthetic data</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">To generate synthetic data, we employed the open-source SO-VITS-SVC<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>SO-VITS-SVC available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="github.com/PlayVoice/whisper-vits-svc" title="">github.com/PlayVoice/whisper-vits-svc</a></span></span></span> F0-conditioned voice conversion model. This model integrates four distinct audio encoders, each extracting different meaningful representations. A pre-trained timbre encoder extracts speaker embeddings, a Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib19" title="">19</a>]</cite> encoder extracts content information, a soft HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib20" title="">20</a>]</cite> model extracts prosody representation, and a CREPE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib21" title="">21</a>]</cite> model extracts the F0. These representations are processed by a flow-based decoder and an adversarial training process based on VITS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib17" title="">17</a>]</cite>. The model is also trained with a speaker classifier using a gradient reversal layer to achieve speaker disentanglement. We used the publicly available pre-trained checkpoint to fine-tune on our datasets. To ensure consistent conversions in cross-speaker scenarios, we also extracted the F0 statistics for each speaker in the dataset, and at inference time, we performed semitonal correction on the source expressive speech F0 to match the target speaker’s F0.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Stage 1: Style Encoder</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">For the style encoder, we used the Reference Encoder (RE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib1" title="">1</a>]</cite> with several modifications to prevent information leakage. First, it was pre-trained separately to avoid modeling timbre information during TTS training. Additionally, to generate representations with distinct clusters for each style, we trained the Reference Encoder using the Prototypical Angular Loss <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib22" title="">22</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">We also perturbed the input mel-spectrogram of the Reference Encoder using two approaches. The first approach randomly selects slices of frames from the mel-spectrogram, ensuring that different segments of speech with the same style are used in each iteration. The second approach applies the timbre perturbation proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib10" title="">10</a>]</cite>, which involves randomly applying formant shifting to the input audio and then passing the perturbed mel-spectrogram to the Reference Encoder.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Stage 2: TTS</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">For the TTS model, we based our approach on the FastPitch <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib18" title="">18</a>]</cite> architecture, which is a non-autoregressive model conditioned on F0. We also included speech energy modeling and normalized both energy and F0 to the statistics of each speaker in the dataset to reduce the amount of speaker-specific information carried by these features. During training, FastPitch is conditioned on the representations generated by the pre-trained Reference Encoder with its layers frozen. During inference, the ground truth centroid representation of each style is used to perform cross-speaker style transfer.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">To achieve faster convergence, we trained all TTS models from a pre-trained FastPitch model trained on six neutral Brazilian Portuguese speakers from an 30h internal dataset. Finally, we used the Parallel WaveGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib23" title="">23</a>]</cite> vocoder to convert the mel-spectrogram into waveform.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We performed the experiments on an internal Brazilian Portuguese dataset. The dataset consists of three speakers, coded as PTBR 1 (female), PTBR 2 (male), and PTBR 3 (female), as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S3.T1" title="Table 1 ‣ 3 Experiments ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">1</span></a>. Speaker PTBR 1 has three highly expressive styles of speech in addition to neutral: lively, welcoming, and harsh. Speakers PTBR 2 and 3 only have neutral recordings.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Training dataset detailed overview.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:216.8pt;height:113.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.9pt,15.2pt) scale(0.789435362863548,0.789435362863548) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1.1">Speaker ID</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.2.1">Style (pt-br)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.3.1">Style (en)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.4.1">#Files</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.5.1">#Hours</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.1" rowspan="4"><span class="ltx_text" id="S3.T1.1.1.2.2.1.1">PTBR 1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.2">Neutro</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.3">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.4">3574</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.5">3.97</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.3.1">Animado</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.3.2">Lively</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.3.3">1307</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3.4">1.66</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.4.1">Acolhedor</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.4.2">Welcoming</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.4.3">1308</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4.4">1.69</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.1">Rispido</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.2">Harsh</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.3">1256</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.4">1.60</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.1">PTBR 2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.2">Neutro</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.3">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.6.6.4">4725</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.6.6.5">4.62</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.7.7">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.1">PTBR 3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.2">Neutro</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.3">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.7.7.4">6759</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.7.7.5">7.29</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.8.8">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.8.8.1"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.8.8.2"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.8.8.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.1.1.8.8.4">18929</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.8.8.5">20.83</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We used 90% of the data for training, 10% for validation, and manually selected 20 style-paired samples from PTBR 1 and 20 random samples for each remaining speaker for evaluation.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Additionally, to evaluate this approach for cross-language in a one-speaker-one-language scenario (only one speaker for each foreign language), we conducted experiments aimed at transferring native English and Spanish accents to Brazilian Portuguese speakers. We used the LJspeech dataset for English references and the Blizzard2021 dataset for Spanish references. We used 80% of each dataset for training, 10% for validation, and manually extracted 20 out-of-distribution sentences from each language for testing.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Training setup</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">All experiments were conducted on a single T4 GPU (16GB) using the same training and validation partitions. The voice conversion model was trained for 100k steps starting from a publicly available checkpoint with a batch size of 8 with 2 steps of gradient accumulation and AdamW with learning rate (LR) of 5e-5. The style encoder was trained from scratch for 60k steps, with spectrogram segments of 1.6s, a formant shifting factor of 1.4, a batch of 10 examples for each of the 4 styles in the dataset, resulting in a total batch size of 40 and RAdam with LR 1e-4. The TTS models were trained from a pre-trained neutral model for 250k steps with a batch size of 16 and Adam with LR 1e-4. The Parallel WaveGAN vocoder was trained in a 30h internal dataset (PTBR speakers included) for 600k steps from scratch using the recipe from Parallel WaveGAN repository<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>PW-GAN available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kan-bayashi/ParallelWaveGAN" title="">https://github.com/kan-bayashi/ParallelWaveGAN</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We evaluated the model through subjective assessments of naturalness, style intensity, and speaker similarity. A total of 21 native Brazilian participants conducted the tests. For naturalness, we used a Mean Opinion Score (MOS) evaluation ranging from 1 to 5, where 1 represented completely artificial audio and 5 represented completely natural audio. Each participant evaluated 5 sentences generated by each of the models. The sentences were generated for each voice and style in the dataset, totaling 12 stimuli per sentence for each model.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To assess the intensity of emotion, an example page with samples of each style was presented to describe each style in the dataset. The evaluation used a MOS scale where 1 was given to audio completely different from the target style, and higher scores represented increasing intensities of the audio exhibiting that style, with 5 being the highest intensity. For each expressive style in the dataset, 3 sentences were evaluated in each of the 3 voices by each model, totaling 9 stimuli per model for each style.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Finally, for speaker similarity, 4 sentences for each speaker were evaluated with stimuli generated by each of the explored models. On each evaluation page, a ground truth reference of the target voice was provided, and the participants rated how similar each stimulus was to the reference voice, with 1 meaning it did not resemble the reference at all and 5 meaning it was the same person speaking.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">For the cross-language experiment, we assessed the results through objective metrics. We used UTMOS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib24" title="">24</a>]</cite> to estimate the naturalness of synthetic speech, character error rate (CER) for intelligibility evaluation using Whisper large, and a Resemblyzer<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Resemblyzer available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/resemble-ai/Resemblyzer" title="">https://github.com/resemble-ai/Resemblyzer</a></span></span></span>-based speaker embedding cosine similarity (SECS) metric to assess speaker similarity, similar to used in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib25" title="">25</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We report the overall naturalness MOS results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S4.T2" title="Table 2 ‣ 4 Results ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">2</span></a>. The results indicate that synthetic data generated by voice conversion (VC) exhibit higher naturalness than those from cross-speaker style transfer experiments. Consequently, both the Synth TTS and Synth both experiments, which incorporate synthetic data during training, show increased naturalness compared to Synth None, with Synth both demonstrating the highest improvement.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Naturalness MOS with 95% confidence intervals.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.5.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.5.6.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.6.1.2.1">MOS</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.1.2">GT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1"><math alttext="4.11\pm 0.13" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml"><mn id="S4.T2.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.m1.1.1.2.cmml">4.11</mn><mo id="S4.T2.1.1.1.m1.1.1.1" xref="S4.T2.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.m1.1.1.3.cmml">0.13</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T2.1.1.1.m1.1.1.2.cmml" type="float" xref="S4.T2.1.1.1.m1.1.1.2">4.11</cn><cn id="S4.T2.1.1.1.m1.1.1.3.cmml" type="float" xref="S4.T2.1.1.1.m1.1.1.3">0.13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">4.11\pm 0.13</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">4.11 ± 0.13</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.2.2.2">Synth none</th>
<td class="ltx_td ltx_align_center" id="S4.T2.2.2.1"><math alttext="2.53\pm 0.13" class="ltx_Math" display="inline" id="S4.T2.2.2.1.m1.1"><semantics id="S4.T2.2.2.1.m1.1a"><mrow id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml"><mn id="S4.T2.2.2.1.m1.1.1.2" xref="S4.T2.2.2.1.m1.1.1.2.cmml">2.53</mn><mo id="S4.T2.2.2.1.m1.1.1.1" xref="S4.T2.2.2.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.2.2.1.m1.1.1.3" xref="S4.T2.2.2.1.m1.1.1.3.cmml">0.13</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><apply id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.2.2.1.m1.1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T2.2.2.1.m1.1.1.2.cmml" type="float" xref="S4.T2.2.2.1.m1.1.1.2">2.53</cn><cn id="S4.T2.2.2.1.m1.1.1.3.cmml" type="float" xref="S4.T2.2.2.1.m1.1.1.3">0.13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">2.53\pm 0.13</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.1.m1.1d">2.53 ± 0.13</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.3.3.2">Synth TTS</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.1"><math alttext="2.79\pm 0.13" class="ltx_Math" display="inline" id="S4.T2.3.3.1.m1.1"><semantics id="S4.T2.3.3.1.m1.1a"><mrow id="S4.T2.3.3.1.m1.1.1" xref="S4.T2.3.3.1.m1.1.1.cmml"><mn id="S4.T2.3.3.1.m1.1.1.2" xref="S4.T2.3.3.1.m1.1.1.2.cmml">2.79</mn><mo id="S4.T2.3.3.1.m1.1.1.1" xref="S4.T2.3.3.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.3.3.1.m1.1.1.3" xref="S4.T2.3.3.1.m1.1.1.3.cmml">0.13</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.m1.1b"><apply id="S4.T2.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.3.3.1.m1.1.1.1.cmml" xref="S4.T2.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T2.3.3.1.m1.1.1.2.cmml" type="float" xref="S4.T2.3.3.1.m1.1.1.2">2.79</cn><cn id="S4.T2.3.3.1.m1.1.1.3.cmml" type="float" xref="S4.T2.3.3.1.m1.1.1.3">0.13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.m1.1c">2.79\pm 0.13</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.1.m1.1d">2.79 ± 0.13</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.4.4.2">Synth both</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.1"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.4.4.1.1"><math alttext="3.06\pm 0.14" class="ltx_Math" display="inline" id="S4.T2.4.4.1.1.m1.1"><semantics id="S4.T2.4.4.1.1.m1.1a"><mrow id="S4.T2.4.4.1.1.m1.1.1" xref="S4.T2.4.4.1.1.m1.1.1.cmml"><mn id="S4.T2.4.4.1.1.m1.1.1.2" xref="S4.T2.4.4.1.1.m1.1.1.2.cmml">3.06</mn><mo id="S4.T2.4.4.1.1.m1.1.1.1" xref="S4.T2.4.4.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.4.4.1.1.m1.1.1.3" xref="S4.T2.4.4.1.1.m1.1.1.3.cmml">0.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.1.m1.1b"><apply id="S4.T2.4.4.1.1.m1.1.1.cmml" xref="S4.T2.4.4.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.4.4.1.1.m1.1.1.1.cmml" xref="S4.T2.4.4.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T2.4.4.1.1.m1.1.1.2.cmml" type="float" xref="S4.T2.4.4.1.1.m1.1.1.2">3.06</cn><cn id="S4.T2.4.4.1.1.m1.1.1.3.cmml" type="float" xref="S4.T2.4.4.1.1.m1.1.1.3">0.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.1.1.m1.1c">3.06\pm 0.14</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.1.1.m1.1d">3.06 ± 0.14</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T2.5.5.2">VC</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.5.1"><math alttext="\mathbf{3.78\pm 0.20}" class="ltx_Math" display="inline" id="S4.T2.5.5.1.m1.1"><semantics id="S4.T2.5.5.1.m1.1a"><mrow id="S4.T2.5.5.1.m1.1.1" xref="S4.T2.5.5.1.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T2.5.5.1.m1.1.1.2" mathvariant="bold" xref="S4.T2.5.5.1.m1.1.1.2.cmml">3.78</mn><mo id="S4.T2.5.5.1.m1.1.1.1" xref="S4.T2.5.5.1.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T2.5.5.1.m1.1.1.3" mathvariant="bold" xref="S4.T2.5.5.1.m1.1.1.3.cmml">0.20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.m1.1b"><apply id="S4.T2.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T2.5.5.1.m1.1.1.2.cmml" type="float" xref="S4.T2.5.5.1.m1.1.1.2">3.78</cn><cn id="S4.T2.5.5.1.m1.1.1.3.cmml" type="float" xref="S4.T2.5.5.1.m1.1.1.3">0.20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.m1.1c">\mathbf{3.78\pm 0.20}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.1.m1.1d">bold_3.78 ± bold_0.20</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Style Intensity (SI-MOS) and Naturalness (N-MOS) Mean Opinion Scores with 95% confidence intervals.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.30">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.30.31.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T3.30.31.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" colspan="2" id="S4.T3.30.31.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.30.31.1.2.1">Lively</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.30.31.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.30.31.1.3.1">Harsh</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.30.31.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.30.31.1.4.1">Wellcoming</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.30.32.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.30.32.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.30.32.2.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.30.32.2.2">SI-MOS</th>
<td class="ltx_td ltx_align_center" id="S4.T3.30.32.2.3">N-MOS</td>
<td class="ltx_td ltx_align_center" id="S4.T3.30.32.2.4">SI-MOS</td>
<td class="ltx_td ltx_align_center" id="S4.T3.30.32.2.5">N-MOS</td>
<td class="ltx_td ltx_align_center" id="S4.T3.30.32.2.6">SI-MOS</td>
<td class="ltx_td ltx_align_center" id="S4.T3.30.32.2.7">N-MOS</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T3.6.6.7">GT</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.1"><math alttext="4.49\pm 0.14" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mn id="S4.T3.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.m1.1.1.2.cmml">4.49</mn><mo id="S4.T3.1.1.1.m1.1.1.1" xref="S4.T3.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.m1.1.1.3.cmml">0.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.1.1.1.m1.1.1.2.cmml" type="float" xref="S4.T3.1.1.1.m1.1.1.2">4.49</cn><cn id="S4.T3.1.1.1.m1.1.1.3.cmml" type="float" xref="S4.T3.1.1.1.m1.1.1.3">0.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">4.49\pm 0.14</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">4.49 ± 0.14</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.2"><math alttext="4.28\pm 0.38" class="ltx_Math" display="inline" id="S4.T3.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.m1.1a"><mrow id="S4.T3.2.2.2.m1.1.1" xref="S4.T3.2.2.2.m1.1.1.cmml"><mn id="S4.T3.2.2.2.m1.1.1.2" xref="S4.T3.2.2.2.m1.1.1.2.cmml">4.28</mn><mo id="S4.T3.2.2.2.m1.1.1.1" xref="S4.T3.2.2.2.m1.1.1.1.cmml">±</mo><mn id="S4.T3.2.2.2.m1.1.1.3" xref="S4.T3.2.2.2.m1.1.1.3.cmml">0.38</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><apply id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1"><csymbol cd="latexml" id="S4.T3.2.2.2.m1.1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.2.2.2.m1.1.1.2.cmml" type="float" xref="S4.T3.2.2.2.m1.1.1.2">4.28</cn><cn id="S4.T3.2.2.2.m1.1.1.3.cmml" type="float" xref="S4.T3.2.2.2.m1.1.1.3">0.38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">4.28\pm 0.38</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.m1.1d">4.28 ± 0.38</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.3"><math alttext="4.52\pm 0.14" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.m1.1a"><mrow id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml"><mn id="S4.T3.3.3.3.m1.1.1.2" xref="S4.T3.3.3.3.m1.1.1.2.cmml">4.52</mn><mo id="S4.T3.3.3.3.m1.1.1.1" xref="S4.T3.3.3.3.m1.1.1.1.cmml">±</mo><mn id="S4.T3.3.3.3.m1.1.1.3" xref="S4.T3.3.3.3.m1.1.1.3.cmml">0.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><apply id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1"><csymbol cd="latexml" id="S4.T3.3.3.3.m1.1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.3.3.3.m1.1.1.2.cmml" type="float" xref="S4.T3.3.3.3.m1.1.1.2">4.52</cn><cn id="S4.T3.3.3.3.m1.1.1.3.cmml" type="float" xref="S4.T3.3.3.3.m1.1.1.3">0.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">4.52\pm 0.14</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.m1.1d">4.52 ± 0.14</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.4.4"><math alttext="4.85\pm 0.21" class="ltx_Math" display="inline" id="S4.T3.4.4.4.m1.1"><semantics id="S4.T3.4.4.4.m1.1a"><mrow id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml"><mn id="S4.T3.4.4.4.m1.1.1.2" xref="S4.T3.4.4.4.m1.1.1.2.cmml">4.85</mn><mo id="S4.T3.4.4.4.m1.1.1.1" xref="S4.T3.4.4.4.m1.1.1.1.cmml">±</mo><mn id="S4.T3.4.4.4.m1.1.1.3" xref="S4.T3.4.4.4.m1.1.1.3.cmml">0.21</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><apply id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1"><csymbol cd="latexml" id="S4.T3.4.4.4.m1.1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.4.4.4.m1.1.1.2.cmml" type="float" xref="S4.T3.4.4.4.m1.1.1.2">4.85</cn><cn id="S4.T3.4.4.4.m1.1.1.3.cmml" type="float" xref="S4.T3.4.4.4.m1.1.1.3">0.21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">4.85\pm 0.21</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.m1.1d">4.85 ± 0.21</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.5"><math alttext="4.01\pm 0.26" class="ltx_Math" display="inline" id="S4.T3.5.5.5.m1.1"><semantics id="S4.T3.5.5.5.m1.1a"><mrow id="S4.T3.5.5.5.m1.1.1" xref="S4.T3.5.5.5.m1.1.1.cmml"><mn id="S4.T3.5.5.5.m1.1.1.2" xref="S4.T3.5.5.5.m1.1.1.2.cmml">4.01</mn><mo id="S4.T3.5.5.5.m1.1.1.1" xref="S4.T3.5.5.5.m1.1.1.1.cmml">±</mo><mn id="S4.T3.5.5.5.m1.1.1.3" xref="S4.T3.5.5.5.m1.1.1.3.cmml">0.26</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><apply id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1"><csymbol cd="latexml" id="S4.T3.5.5.5.m1.1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.5.5.5.m1.1.1.2.cmml" type="float" xref="S4.T3.5.5.5.m1.1.1.2">4.01</cn><cn id="S4.T3.5.5.5.m1.1.1.3.cmml" type="float" xref="S4.T3.5.5.5.m1.1.1.3">0.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">4.01\pm 0.26</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.m1.1d">4.01 ± 0.26</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.6"><math alttext="4.28\pm 0.29" class="ltx_Math" display="inline" id="S4.T3.6.6.6.m1.1"><semantics id="S4.T3.6.6.6.m1.1a"><mrow id="S4.T3.6.6.6.m1.1.1" xref="S4.T3.6.6.6.m1.1.1.cmml"><mn id="S4.T3.6.6.6.m1.1.1.2" xref="S4.T3.6.6.6.m1.1.1.2.cmml">4.28</mn><mo id="S4.T3.6.6.6.m1.1.1.1" xref="S4.T3.6.6.6.m1.1.1.1.cmml">±</mo><mn id="S4.T3.6.6.6.m1.1.1.3" xref="S4.T3.6.6.6.m1.1.1.3.cmml">0.29</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><apply id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1"><csymbol cd="latexml" id="S4.T3.6.6.6.m1.1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.6.6.6.m1.1.1.2.cmml" type="float" xref="S4.T3.6.6.6.m1.1.1.2">4.28</cn><cn id="S4.T3.6.6.6.m1.1.1.3.cmml" type="float" xref="S4.T3.6.6.6.m1.1.1.3">0.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">4.28\pm 0.29</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.m1.1d">4.28 ± 0.29</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.12.12.7">Synth none</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.7.7.1"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.7.7.1.1"><math alttext="2.67\pm 0.26" class="ltx_Math" display="inline" id="S4.T3.7.7.1.1.m1.1"><semantics id="S4.T3.7.7.1.1.m1.1a"><mrow id="S4.T3.7.7.1.1.m1.1.1" xref="S4.T3.7.7.1.1.m1.1.1.cmml"><mn id="S4.T3.7.7.1.1.m1.1.1.2" xref="S4.T3.7.7.1.1.m1.1.1.2.cmml">2.67</mn><mo id="S4.T3.7.7.1.1.m1.1.1.1" xref="S4.T3.7.7.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.7.7.1.1.m1.1.1.3" xref="S4.T3.7.7.1.1.m1.1.1.3.cmml">0.26</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.1.1.m1.1b"><apply id="S4.T3.7.7.1.1.m1.1.1.cmml" xref="S4.T3.7.7.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.7.7.1.1.m1.1.1.1.cmml" xref="S4.T3.7.7.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.7.7.1.1.m1.1.1.2.cmml" type="float" xref="S4.T3.7.7.1.1.m1.1.1.2">2.67</cn><cn id="S4.T3.7.7.1.1.m1.1.1.3.cmml" type="float" xref="S4.T3.7.7.1.1.m1.1.1.3">0.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.1.1.m1.1c">2.67\pm 0.26</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.1.1.m1.1d">2.67 ± 0.26</annotation></semantics></math></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.2"><math alttext="1.74\pm 0.24" class="ltx_Math" display="inline" id="S4.T3.8.8.2.m1.1"><semantics id="S4.T3.8.8.2.m1.1a"><mrow id="S4.T3.8.8.2.m1.1.1" xref="S4.T3.8.8.2.m1.1.1.cmml"><mn id="S4.T3.8.8.2.m1.1.1.2" xref="S4.T3.8.8.2.m1.1.1.2.cmml">1.74</mn><mo id="S4.T3.8.8.2.m1.1.1.1" xref="S4.T3.8.8.2.m1.1.1.1.cmml">±</mo><mn id="S4.T3.8.8.2.m1.1.1.3" xref="S4.T3.8.8.2.m1.1.1.3.cmml">0.24</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.2.m1.1b"><apply id="S4.T3.8.8.2.m1.1.1.cmml" xref="S4.T3.8.8.2.m1.1.1"><csymbol cd="latexml" id="S4.T3.8.8.2.m1.1.1.1.cmml" xref="S4.T3.8.8.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.8.8.2.m1.1.1.2.cmml" type="float" xref="S4.T3.8.8.2.m1.1.1.2">1.74</cn><cn id="S4.T3.8.8.2.m1.1.1.3.cmml" type="float" xref="S4.T3.8.8.2.m1.1.1.3">0.24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.2.m1.1c">1.74\pm 0.24</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.8.2.m1.1d">1.74 ± 0.24</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.9.9.3"><math alttext="\mathbf{2.71\pm 0.14}" class="ltx_Math" display="inline" id="S4.T3.9.9.3.m1.1"><semantics id="S4.T3.9.9.3.m1.1a"><mrow id="S4.T3.9.9.3.m1.1.1" xref="S4.T3.9.9.3.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T3.9.9.3.m1.1.1.2" mathvariant="bold" xref="S4.T3.9.9.3.m1.1.1.2.cmml">2.71</mn><mo id="S4.T3.9.9.3.m1.1.1.1" xref="S4.T3.9.9.3.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T3.9.9.3.m1.1.1.3" mathvariant="bold" xref="S4.T3.9.9.3.m1.1.1.3.cmml">0.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.3.m1.1b"><apply id="S4.T3.9.9.3.m1.1.1.cmml" xref="S4.T3.9.9.3.m1.1.1"><csymbol cd="latexml" id="S4.T3.9.9.3.m1.1.1.1.cmml" xref="S4.T3.9.9.3.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.9.9.3.m1.1.1.2.cmml" type="float" xref="S4.T3.9.9.3.m1.1.1.2">2.71</cn><cn id="S4.T3.9.9.3.m1.1.1.3.cmml" type="float" xref="S4.T3.9.9.3.m1.1.1.3">0.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.3.m1.1c">\mathbf{2.71\pm 0.14}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.9.9.3.m1.1d">bold_2.71 ± bold_0.14</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.10.10.4"><math alttext="2.20\pm 0.22" class="ltx_Math" display="inline" id="S4.T3.10.10.4.m1.1"><semantics id="S4.T3.10.10.4.m1.1a"><mrow id="S4.T3.10.10.4.m1.1.1" xref="S4.T3.10.10.4.m1.1.1.cmml"><mn id="S4.T3.10.10.4.m1.1.1.2" xref="S4.T3.10.10.4.m1.1.1.2.cmml">2.20</mn><mo id="S4.T3.10.10.4.m1.1.1.1" xref="S4.T3.10.10.4.m1.1.1.1.cmml">±</mo><mn id="S4.T3.10.10.4.m1.1.1.3" xref="S4.T3.10.10.4.m1.1.1.3.cmml">0.22</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.4.m1.1b"><apply id="S4.T3.10.10.4.m1.1.1.cmml" xref="S4.T3.10.10.4.m1.1.1"><csymbol cd="latexml" id="S4.T3.10.10.4.m1.1.1.1.cmml" xref="S4.T3.10.10.4.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.10.10.4.m1.1.1.2.cmml" type="float" xref="S4.T3.10.10.4.m1.1.1.2">2.20</cn><cn id="S4.T3.10.10.4.m1.1.1.3.cmml" type="float" xref="S4.T3.10.10.4.m1.1.1.3">0.22</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.4.m1.1c">2.20\pm 0.22</annotation><annotation encoding="application/x-llamapun" id="S4.T3.10.10.4.m1.1d">2.20 ± 0.22</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.11.11.5"><math alttext="2.63\pm 0.17" class="ltx_Math" display="inline" id="S4.T3.11.11.5.m1.1"><semantics id="S4.T3.11.11.5.m1.1a"><mrow id="S4.T3.11.11.5.m1.1.1" xref="S4.T3.11.11.5.m1.1.1.cmml"><mn id="S4.T3.11.11.5.m1.1.1.2" xref="S4.T3.11.11.5.m1.1.1.2.cmml">2.63</mn><mo id="S4.T3.11.11.5.m1.1.1.1" xref="S4.T3.11.11.5.m1.1.1.1.cmml">±</mo><mn id="S4.T3.11.11.5.m1.1.1.3" xref="S4.T3.11.11.5.m1.1.1.3.cmml">0.17</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.5.m1.1b"><apply id="S4.T3.11.11.5.m1.1.1.cmml" xref="S4.T3.11.11.5.m1.1.1"><csymbol cd="latexml" id="S4.T3.11.11.5.m1.1.1.1.cmml" xref="S4.T3.11.11.5.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.11.11.5.m1.1.1.2.cmml" type="float" xref="S4.T3.11.11.5.m1.1.1.2">2.63</cn><cn id="S4.T3.11.11.5.m1.1.1.3.cmml" type="float" xref="S4.T3.11.11.5.m1.1.1.3">0.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.5.m1.1c">2.63\pm 0.17</annotation><annotation encoding="application/x-llamapun" id="S4.T3.11.11.5.m1.1d">2.63 ± 0.17</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.6"><math alttext="2.33\pm 0.27" class="ltx_Math" display="inline" id="S4.T3.12.12.6.m1.1"><semantics id="S4.T3.12.12.6.m1.1a"><mrow id="S4.T3.12.12.6.m1.1.1" xref="S4.T3.12.12.6.m1.1.1.cmml"><mn id="S4.T3.12.12.6.m1.1.1.2" xref="S4.T3.12.12.6.m1.1.1.2.cmml">2.33</mn><mo id="S4.T3.12.12.6.m1.1.1.1" xref="S4.T3.12.12.6.m1.1.1.1.cmml">±</mo><mn id="S4.T3.12.12.6.m1.1.1.3" xref="S4.T3.12.12.6.m1.1.1.3.cmml">0.27</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.6.m1.1b"><apply id="S4.T3.12.12.6.m1.1.1.cmml" xref="S4.T3.12.12.6.m1.1.1"><csymbol cd="latexml" id="S4.T3.12.12.6.m1.1.1.1.cmml" xref="S4.T3.12.12.6.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.12.12.6.m1.1.1.2.cmml" type="float" xref="S4.T3.12.12.6.m1.1.1.2">2.33</cn><cn id="S4.T3.12.12.6.m1.1.1.3.cmml" type="float" xref="S4.T3.12.12.6.m1.1.1.3">0.27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.6.m1.1c">2.33\pm 0.27</annotation><annotation encoding="application/x-llamapun" id="S4.T3.12.12.6.m1.1d">2.33 ± 0.27</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.18.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.18.18.7">Synth TTS</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.13.13.1"><math alttext="2.65\pm 0.15" class="ltx_Math" display="inline" id="S4.T3.13.13.1.m1.1"><semantics id="S4.T3.13.13.1.m1.1a"><mrow id="S4.T3.13.13.1.m1.1.1" xref="S4.T3.13.13.1.m1.1.1.cmml"><mn id="S4.T3.13.13.1.m1.1.1.2" xref="S4.T3.13.13.1.m1.1.1.2.cmml">2.65</mn><mo id="S4.T3.13.13.1.m1.1.1.1" xref="S4.T3.13.13.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.13.13.1.m1.1.1.3" xref="S4.T3.13.13.1.m1.1.1.3.cmml">0.15</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.13.13.1.m1.1b"><apply id="S4.T3.13.13.1.m1.1.1.cmml" xref="S4.T3.13.13.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.13.13.1.m1.1.1.1.cmml" xref="S4.T3.13.13.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.13.13.1.m1.1.1.2.cmml" type="float" xref="S4.T3.13.13.1.m1.1.1.2">2.65</cn><cn id="S4.T3.13.13.1.m1.1.1.3.cmml" type="float" xref="S4.T3.13.13.1.m1.1.1.3">0.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.13.1.m1.1c">2.65\pm 0.15</annotation><annotation encoding="application/x-llamapun" id="S4.T3.13.13.1.m1.1d">2.65 ± 0.15</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T3.14.14.2"><math alttext="2.55\pm 0.16" class="ltx_Math" display="inline" id="S4.T3.14.14.2.m1.1"><semantics id="S4.T3.14.14.2.m1.1a"><mrow id="S4.T3.14.14.2.m1.1.1" xref="S4.T3.14.14.2.m1.1.1.cmml"><mn id="S4.T3.14.14.2.m1.1.1.2" xref="S4.T3.14.14.2.m1.1.1.2.cmml">2.55</mn><mo id="S4.T3.14.14.2.m1.1.1.1" xref="S4.T3.14.14.2.m1.1.1.1.cmml">±</mo><mn id="S4.T3.14.14.2.m1.1.1.3" xref="S4.T3.14.14.2.m1.1.1.3.cmml">0.16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.14.14.2.m1.1b"><apply id="S4.T3.14.14.2.m1.1.1.cmml" xref="S4.T3.14.14.2.m1.1.1"><csymbol cd="latexml" id="S4.T3.14.14.2.m1.1.1.1.cmml" xref="S4.T3.14.14.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.14.14.2.m1.1.1.2.cmml" type="float" xref="S4.T3.14.14.2.m1.1.1.2">2.55</cn><cn id="S4.T3.14.14.2.m1.1.1.3.cmml" type="float" xref="S4.T3.14.14.2.m1.1.1.3">0.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.14.2.m1.1c">2.55\pm 0.16</annotation><annotation encoding="application/x-llamapun" id="S4.T3.14.14.2.m1.1d">2.55 ± 0.16</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.15.15.3"><math alttext="2.17\pm 0.15" class="ltx_Math" display="inline" id="S4.T3.15.15.3.m1.1"><semantics id="S4.T3.15.15.3.m1.1a"><mrow id="S4.T3.15.15.3.m1.1.1" xref="S4.T3.15.15.3.m1.1.1.cmml"><mn id="S4.T3.15.15.3.m1.1.1.2" xref="S4.T3.15.15.3.m1.1.1.2.cmml">2.17</mn><mo id="S4.T3.15.15.3.m1.1.1.1" xref="S4.T3.15.15.3.m1.1.1.1.cmml">±</mo><mn id="S4.T3.15.15.3.m1.1.1.3" xref="S4.T3.15.15.3.m1.1.1.3.cmml">0.15</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.15.15.3.m1.1b"><apply id="S4.T3.15.15.3.m1.1.1.cmml" xref="S4.T3.15.15.3.m1.1.1"><csymbol cd="latexml" id="S4.T3.15.15.3.m1.1.1.1.cmml" xref="S4.T3.15.15.3.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.15.15.3.m1.1.1.2.cmml" type="float" xref="S4.T3.15.15.3.m1.1.1.2">2.17</cn><cn id="S4.T3.15.15.3.m1.1.1.3.cmml" type="float" xref="S4.T3.15.15.3.m1.1.1.3">0.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.15.3.m1.1c">2.17\pm 0.15</annotation><annotation encoding="application/x-llamapun" id="S4.T3.15.15.3.m1.1d">2.17 ± 0.15</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.16.16.4"><math alttext="2.11\pm 0.19" class="ltx_Math" display="inline" id="S4.T3.16.16.4.m1.1"><semantics id="S4.T3.16.16.4.m1.1a"><mrow id="S4.T3.16.16.4.m1.1.1" xref="S4.T3.16.16.4.m1.1.1.cmml"><mn id="S4.T3.16.16.4.m1.1.1.2" xref="S4.T3.16.16.4.m1.1.1.2.cmml">2.11</mn><mo id="S4.T3.16.16.4.m1.1.1.1" xref="S4.T3.16.16.4.m1.1.1.1.cmml">±</mo><mn id="S4.T3.16.16.4.m1.1.1.3" xref="S4.T3.16.16.4.m1.1.1.3.cmml">0.19</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.16.16.4.m1.1b"><apply id="S4.T3.16.16.4.m1.1.1.cmml" xref="S4.T3.16.16.4.m1.1.1"><csymbol cd="latexml" id="S4.T3.16.16.4.m1.1.1.1.cmml" xref="S4.T3.16.16.4.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.16.16.4.m1.1.1.2.cmml" type="float" xref="S4.T3.16.16.4.m1.1.1.2">2.11</cn><cn id="S4.T3.16.16.4.m1.1.1.3.cmml" type="float" xref="S4.T3.16.16.4.m1.1.1.3">0.19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.16.4.m1.1c">2.11\pm 0.19</annotation><annotation encoding="application/x-llamapun" id="S4.T3.16.16.4.m1.1d">2.11 ± 0.19</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.17.17.5"><math alttext="2.99\pm 0.14" class="ltx_Math" display="inline" id="S4.T3.17.17.5.m1.1"><semantics id="S4.T3.17.17.5.m1.1a"><mrow id="S4.T3.17.17.5.m1.1.1" xref="S4.T3.17.17.5.m1.1.1.cmml"><mn id="S4.T3.17.17.5.m1.1.1.2" xref="S4.T3.17.17.5.m1.1.1.2.cmml">2.99</mn><mo id="S4.T3.17.17.5.m1.1.1.1" xref="S4.T3.17.17.5.m1.1.1.1.cmml">±</mo><mn id="S4.T3.17.17.5.m1.1.1.3" xref="S4.T3.17.17.5.m1.1.1.3.cmml">0.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.17.17.5.m1.1b"><apply id="S4.T3.17.17.5.m1.1.1.cmml" xref="S4.T3.17.17.5.m1.1.1"><csymbol cd="latexml" id="S4.T3.17.17.5.m1.1.1.1.cmml" xref="S4.T3.17.17.5.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.17.17.5.m1.1.1.2.cmml" type="float" xref="S4.T3.17.17.5.m1.1.1.2">2.99</cn><cn id="S4.T3.17.17.5.m1.1.1.3.cmml" type="float" xref="S4.T3.17.17.5.m1.1.1.3">0.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.17.5.m1.1c">2.99\pm 0.14</annotation><annotation encoding="application/x-llamapun" id="S4.T3.17.17.5.m1.1d">2.99 ± 0.14</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.18.18.6"><math alttext="2.55\pm 0.27" class="ltx_Math" display="inline" id="S4.T3.18.18.6.m1.1"><semantics id="S4.T3.18.18.6.m1.1a"><mrow id="S4.T3.18.18.6.m1.1.1" xref="S4.T3.18.18.6.m1.1.1.cmml"><mn id="S4.T3.18.18.6.m1.1.1.2" xref="S4.T3.18.18.6.m1.1.1.2.cmml">2.55</mn><mo id="S4.T3.18.18.6.m1.1.1.1" xref="S4.T3.18.18.6.m1.1.1.1.cmml">±</mo><mn id="S4.T3.18.18.6.m1.1.1.3" xref="S4.T3.18.18.6.m1.1.1.3.cmml">0.27</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.18.18.6.m1.1b"><apply id="S4.T3.18.18.6.m1.1.1.cmml" xref="S4.T3.18.18.6.m1.1.1"><csymbol cd="latexml" id="S4.T3.18.18.6.m1.1.1.1.cmml" xref="S4.T3.18.18.6.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.18.18.6.m1.1.1.2.cmml" type="float" xref="S4.T3.18.18.6.m1.1.1.2">2.55</cn><cn id="S4.T3.18.18.6.m1.1.1.3.cmml" type="float" xref="S4.T3.18.18.6.m1.1.1.3">0.27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.18.6.m1.1c">2.55\pm 0.27</annotation><annotation encoding="application/x-llamapun" id="S4.T3.18.18.6.m1.1d">2.55 ± 0.27</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.24.24">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.24.24.7">Synth both</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.19.19.1"><math alttext="2.24\pm 0.14" class="ltx_Math" display="inline" id="S4.T3.19.19.1.m1.1"><semantics id="S4.T3.19.19.1.m1.1a"><mrow id="S4.T3.19.19.1.m1.1.1" xref="S4.T3.19.19.1.m1.1.1.cmml"><mn id="S4.T3.19.19.1.m1.1.1.2" xref="S4.T3.19.19.1.m1.1.1.2.cmml">2.24</mn><mo id="S4.T3.19.19.1.m1.1.1.1" xref="S4.T3.19.19.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.19.19.1.m1.1.1.3" xref="S4.T3.19.19.1.m1.1.1.3.cmml">0.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.19.19.1.m1.1b"><apply id="S4.T3.19.19.1.m1.1.1.cmml" xref="S4.T3.19.19.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.19.19.1.m1.1.1.1.cmml" xref="S4.T3.19.19.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.19.19.1.m1.1.1.2.cmml" type="float" xref="S4.T3.19.19.1.m1.1.1.2">2.24</cn><cn id="S4.T3.19.19.1.m1.1.1.3.cmml" type="float" xref="S4.T3.19.19.1.m1.1.1.3">0.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.19.1.m1.1c">2.24\pm 0.14</annotation><annotation encoding="application/x-llamapun" id="S4.T3.19.19.1.m1.1d">2.24 ± 0.14</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T3.20.20.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.20.20.2.1"><math alttext="2.90\pm 0.31" class="ltx_Math" display="inline" id="S4.T3.20.20.2.1.m1.1"><semantics id="S4.T3.20.20.2.1.m1.1a"><mrow id="S4.T3.20.20.2.1.m1.1.1" xref="S4.T3.20.20.2.1.m1.1.1.cmml"><mn id="S4.T3.20.20.2.1.m1.1.1.2" xref="S4.T3.20.20.2.1.m1.1.1.2.cmml">2.90</mn><mo id="S4.T3.20.20.2.1.m1.1.1.1" xref="S4.T3.20.20.2.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.20.20.2.1.m1.1.1.3" xref="S4.T3.20.20.2.1.m1.1.1.3.cmml">0.31</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.20.20.2.1.m1.1b"><apply id="S4.T3.20.20.2.1.m1.1.1.cmml" xref="S4.T3.20.20.2.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.20.20.2.1.m1.1.1.1.cmml" xref="S4.T3.20.20.2.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.20.20.2.1.m1.1.1.2.cmml" type="float" xref="S4.T3.20.20.2.1.m1.1.1.2">2.90</cn><cn id="S4.T3.20.20.2.1.m1.1.1.3.cmml" type="float" xref="S4.T3.20.20.2.1.m1.1.1.3">0.31</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.20.2.1.m1.1c">2.90\pm 0.31</annotation><annotation encoding="application/x-llamapun" id="S4.T3.20.20.2.1.m1.1d">2.90 ± 0.31</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.21.21.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.21.21.3.1"><math alttext="2.25\pm 0.15" class="ltx_Math" display="inline" id="S4.T3.21.21.3.1.m1.1"><semantics id="S4.T3.21.21.3.1.m1.1a"><mrow id="S4.T3.21.21.3.1.m1.1.1" xref="S4.T3.21.21.3.1.m1.1.1.cmml"><mn id="S4.T3.21.21.3.1.m1.1.1.2" xref="S4.T3.21.21.3.1.m1.1.1.2.cmml">2.25</mn><mo id="S4.T3.21.21.3.1.m1.1.1.1" xref="S4.T3.21.21.3.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.21.21.3.1.m1.1.1.3" xref="S4.T3.21.21.3.1.m1.1.1.3.cmml">0.15</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.21.21.3.1.m1.1b"><apply id="S4.T3.21.21.3.1.m1.1.1.cmml" xref="S4.T3.21.21.3.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.21.21.3.1.m1.1.1.1.cmml" xref="S4.T3.21.21.3.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.21.21.3.1.m1.1.1.2.cmml" type="float" xref="S4.T3.21.21.3.1.m1.1.1.2">2.25</cn><cn id="S4.T3.21.21.3.1.m1.1.1.3.cmml" type="float" xref="S4.T3.21.21.3.1.m1.1.1.3">0.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.21.3.1.m1.1c">2.25\pm 0.15</annotation><annotation encoding="application/x-llamapun" id="S4.T3.21.21.3.1.m1.1d">2.25 ± 0.15</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.22.22.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.22.22.4.1"><math alttext="2.28\pm 0.20" class="ltx_Math" display="inline" id="S4.T3.22.22.4.1.m1.1"><semantics id="S4.T3.22.22.4.1.m1.1a"><mrow id="S4.T3.22.22.4.1.m1.1.1" xref="S4.T3.22.22.4.1.m1.1.1.cmml"><mn id="S4.T3.22.22.4.1.m1.1.1.2" xref="S4.T3.22.22.4.1.m1.1.1.2.cmml">2.28</mn><mo id="S4.T3.22.22.4.1.m1.1.1.1" xref="S4.T3.22.22.4.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.22.22.4.1.m1.1.1.3" xref="S4.T3.22.22.4.1.m1.1.1.3.cmml">0.20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.22.22.4.1.m1.1b"><apply id="S4.T3.22.22.4.1.m1.1.1.cmml" xref="S4.T3.22.22.4.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.22.22.4.1.m1.1.1.1.cmml" xref="S4.T3.22.22.4.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.22.22.4.1.m1.1.1.2.cmml" type="float" xref="S4.T3.22.22.4.1.m1.1.1.2">2.28</cn><cn id="S4.T3.22.22.4.1.m1.1.1.3.cmml" type="float" xref="S4.T3.22.22.4.1.m1.1.1.3">0.20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.22.4.1.m1.1c">2.28\pm 0.20</annotation><annotation encoding="application/x-llamapun" id="S4.T3.22.22.4.1.m1.1d">2.28 ± 0.20</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.23.23.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.23.23.5.1"><math alttext="3.06\pm 0.17" class="ltx_Math" display="inline" id="S4.T3.23.23.5.1.m1.1"><semantics id="S4.T3.23.23.5.1.m1.1a"><mrow id="S4.T3.23.23.5.1.m1.1.1" xref="S4.T3.23.23.5.1.m1.1.1.cmml"><mn id="S4.T3.23.23.5.1.m1.1.1.2" xref="S4.T3.23.23.5.1.m1.1.1.2.cmml">3.06</mn><mo id="S4.T3.23.23.5.1.m1.1.1.1" xref="S4.T3.23.23.5.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.23.23.5.1.m1.1.1.3" xref="S4.T3.23.23.5.1.m1.1.1.3.cmml">0.17</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.23.23.5.1.m1.1b"><apply id="S4.T3.23.23.5.1.m1.1.1.cmml" xref="S4.T3.23.23.5.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.23.23.5.1.m1.1.1.1.cmml" xref="S4.T3.23.23.5.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.23.23.5.1.m1.1.1.2.cmml" type="float" xref="S4.T3.23.23.5.1.m1.1.1.2">3.06</cn><cn id="S4.T3.23.23.5.1.m1.1.1.3.cmml" type="float" xref="S4.T3.23.23.5.1.m1.1.1.3">0.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.23.23.5.1.m1.1c">3.06\pm 0.17</annotation><annotation encoding="application/x-llamapun" id="S4.T3.23.23.5.1.m1.1d">3.06 ± 0.17</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.24.24.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.24.24.6.1"><math alttext="3.44\pm 0.28" class="ltx_Math" display="inline" id="S4.T3.24.24.6.1.m1.1"><semantics id="S4.T3.24.24.6.1.m1.1a"><mrow id="S4.T3.24.24.6.1.m1.1.1" xref="S4.T3.24.24.6.1.m1.1.1.cmml"><mn id="S4.T3.24.24.6.1.m1.1.1.2" xref="S4.T3.24.24.6.1.m1.1.1.2.cmml">3.44</mn><mo id="S4.T3.24.24.6.1.m1.1.1.1" xref="S4.T3.24.24.6.1.m1.1.1.1.cmml">±</mo><mn id="S4.T3.24.24.6.1.m1.1.1.3" xref="S4.T3.24.24.6.1.m1.1.1.3.cmml">0.28</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.24.24.6.1.m1.1b"><apply id="S4.T3.24.24.6.1.m1.1.1.cmml" xref="S4.T3.24.24.6.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.24.24.6.1.m1.1.1.1.cmml" xref="S4.T3.24.24.6.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.24.24.6.1.m1.1.1.2.cmml" type="float" xref="S4.T3.24.24.6.1.m1.1.1.2">3.44</cn><cn id="S4.T3.24.24.6.1.m1.1.1.3.cmml" type="float" xref="S4.T3.24.24.6.1.m1.1.1.3">0.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.24.24.6.1.m1.1c">3.44\pm 0.28</annotation><annotation encoding="application/x-llamapun" id="S4.T3.24.24.6.1.m1.1d">3.44 ± 0.28</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.30.30">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T3.30.30.7">VC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T3.25.25.1"><math alttext="\mathbf{3.04\pm 0.16}" class="ltx_Math" display="inline" id="S4.T3.25.25.1.m1.1"><semantics id="S4.T3.25.25.1.m1.1a"><mrow id="S4.T3.25.25.1.m1.1.1" xref="S4.T3.25.25.1.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T3.25.25.1.m1.1.1.2" mathvariant="bold" xref="S4.T3.25.25.1.m1.1.1.2.cmml">3.04</mn><mo id="S4.T3.25.25.1.m1.1.1.1" xref="S4.T3.25.25.1.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T3.25.25.1.m1.1.1.3" mathvariant="bold" xref="S4.T3.25.25.1.m1.1.1.3.cmml">0.16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.25.25.1.m1.1b"><apply id="S4.T3.25.25.1.m1.1.1.cmml" xref="S4.T3.25.25.1.m1.1.1"><csymbol cd="latexml" id="S4.T3.25.25.1.m1.1.1.1.cmml" xref="S4.T3.25.25.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.25.25.1.m1.1.1.2.cmml" type="float" xref="S4.T3.25.25.1.m1.1.1.2">3.04</cn><cn id="S4.T3.25.25.1.m1.1.1.3.cmml" type="float" xref="S4.T3.25.25.1.m1.1.1.3">0.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.25.25.1.m1.1c">\mathbf{3.04\pm 0.16}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.25.25.1.m1.1d">bold_3.04 ± bold_0.16</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.26.26.2"><math alttext="\mathbf{3.66\pm 0.26}" class="ltx_Math" display="inline" id="S4.T3.26.26.2.m1.1"><semantics id="S4.T3.26.26.2.m1.1a"><mrow id="S4.T3.26.26.2.m1.1.1" xref="S4.T3.26.26.2.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T3.26.26.2.m1.1.1.2" mathvariant="bold" xref="S4.T3.26.26.2.m1.1.1.2.cmml">3.66</mn><mo id="S4.T3.26.26.2.m1.1.1.1" xref="S4.T3.26.26.2.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T3.26.26.2.m1.1.1.3" mathvariant="bold" xref="S4.T3.26.26.2.m1.1.1.3.cmml">0.26</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.26.26.2.m1.1b"><apply id="S4.T3.26.26.2.m1.1.1.cmml" xref="S4.T3.26.26.2.m1.1.1"><csymbol cd="latexml" id="S4.T3.26.26.2.m1.1.1.1.cmml" xref="S4.T3.26.26.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.26.26.2.m1.1.1.2.cmml" type="float" xref="S4.T3.26.26.2.m1.1.1.2">3.66</cn><cn id="S4.T3.26.26.2.m1.1.1.3.cmml" type="float" xref="S4.T3.26.26.2.m1.1.1.3">0.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.26.26.2.m1.1c">\mathbf{3.66\pm 0.26}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.26.26.2.m1.1d">bold_3.66 ± bold_0.26</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.27.27.3"><math alttext="1.93\pm 0.29" class="ltx_Math" display="inline" id="S4.T3.27.27.3.m1.1"><semantics id="S4.T3.27.27.3.m1.1a"><mrow id="S4.T3.27.27.3.m1.1.1" xref="S4.T3.27.27.3.m1.1.1.cmml"><mn id="S4.T3.27.27.3.m1.1.1.2" xref="S4.T3.27.27.3.m1.1.1.2.cmml">1.93</mn><mo id="S4.T3.27.27.3.m1.1.1.1" xref="S4.T3.27.27.3.m1.1.1.1.cmml">±</mo><mn id="S4.T3.27.27.3.m1.1.1.3" xref="S4.T3.27.27.3.m1.1.1.3.cmml">0.29</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.27.27.3.m1.1b"><apply id="S4.T3.27.27.3.m1.1.1.cmml" xref="S4.T3.27.27.3.m1.1.1"><csymbol cd="latexml" id="S4.T3.27.27.3.m1.1.1.1.cmml" xref="S4.T3.27.27.3.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.27.27.3.m1.1.1.2.cmml" type="float" xref="S4.T3.27.27.3.m1.1.1.2">1.93</cn><cn id="S4.T3.27.27.3.m1.1.1.3.cmml" type="float" xref="S4.T3.27.27.3.m1.1.1.3">0.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.27.27.3.m1.1c">1.93\pm 0.29</annotation><annotation encoding="application/x-llamapun" id="S4.T3.27.27.3.m1.1d">1.93 ± 0.29</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.28.28.4"><math alttext="\mathbf{3.66\pm 0.38}" class="ltx_Math" display="inline" id="S4.T3.28.28.4.m1.1"><semantics id="S4.T3.28.28.4.m1.1a"><mrow id="S4.T3.28.28.4.m1.1.1" xref="S4.T3.28.28.4.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T3.28.28.4.m1.1.1.2" mathvariant="bold" xref="S4.T3.28.28.4.m1.1.1.2.cmml">3.66</mn><mo id="S4.T3.28.28.4.m1.1.1.1" xref="S4.T3.28.28.4.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T3.28.28.4.m1.1.1.3" mathvariant="bold" xref="S4.T3.28.28.4.m1.1.1.3.cmml">0.38</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.28.28.4.m1.1b"><apply id="S4.T3.28.28.4.m1.1.1.cmml" xref="S4.T3.28.28.4.m1.1.1"><csymbol cd="latexml" id="S4.T3.28.28.4.m1.1.1.1.cmml" xref="S4.T3.28.28.4.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.28.28.4.m1.1.1.2.cmml" type="float" xref="S4.T3.28.28.4.m1.1.1.2">3.66</cn><cn id="S4.T3.28.28.4.m1.1.1.3.cmml" type="float" xref="S4.T3.28.28.4.m1.1.1.3">0.38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.28.28.4.m1.1c">\mathbf{3.66\pm 0.38}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.28.28.4.m1.1d">bold_3.66 ± bold_0.38</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.29.29.5"><math alttext="\mathbf{3.61\pm 0.19}" class="ltx_Math" display="inline" id="S4.T3.29.29.5.m1.1"><semantics id="S4.T3.29.29.5.m1.1a"><mrow id="S4.T3.29.29.5.m1.1.1" xref="S4.T3.29.29.5.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T3.29.29.5.m1.1.1.2" mathvariant="bold" xref="S4.T3.29.29.5.m1.1.1.2.cmml">3.61</mn><mo id="S4.T3.29.29.5.m1.1.1.1" xref="S4.T3.29.29.5.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T3.29.29.5.m1.1.1.3" mathvariant="bold" xref="S4.T3.29.29.5.m1.1.1.3.cmml">0.19</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.29.29.5.m1.1b"><apply id="S4.T3.29.29.5.m1.1.1.cmml" xref="S4.T3.29.29.5.m1.1.1"><csymbol cd="latexml" id="S4.T3.29.29.5.m1.1.1.1.cmml" xref="S4.T3.29.29.5.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.29.29.5.m1.1.1.2.cmml" type="float" xref="S4.T3.29.29.5.m1.1.1.2">3.61</cn><cn id="S4.T3.29.29.5.m1.1.1.3.cmml" type="float" xref="S4.T3.29.29.5.m1.1.1.3">0.19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.29.29.5.m1.1c">\mathbf{3.61\pm 0.19}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.29.29.5.m1.1d">bold_3.61 ± bold_0.19</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.30.30.6"><math alttext="\mathbf{3.95\pm 0.54}" class="ltx_Math" display="inline" id="S4.T3.30.30.6.m1.1"><semantics id="S4.T3.30.30.6.m1.1a"><mrow id="S4.T3.30.30.6.m1.1.1" xref="S4.T3.30.30.6.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T3.30.30.6.m1.1.1.2" mathvariant="bold" xref="S4.T3.30.30.6.m1.1.1.2.cmml">3.95</mn><mo id="S4.T3.30.30.6.m1.1.1.1" xref="S4.T3.30.30.6.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T3.30.30.6.m1.1.1.3" mathvariant="bold" xref="S4.T3.30.30.6.m1.1.1.3.cmml">0.54</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.30.30.6.m1.1b"><apply id="S4.T3.30.30.6.m1.1.1.cmml" xref="S4.T3.30.30.6.m1.1.1"><csymbol cd="latexml" id="S4.T3.30.30.6.m1.1.1.1.cmml" xref="S4.T3.30.30.6.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T3.30.30.6.m1.1.1.2.cmml" type="float" xref="S4.T3.30.30.6.m1.1.1.2">3.95</cn><cn id="S4.T3.30.30.6.m1.1.1.3.cmml" type="float" xref="S4.T3.30.30.6.m1.1.1.3">0.54</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.30.30.6.m1.1c">\mathbf{3.95\pm 0.54}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.30.30.6.m1.1d">bold_3.95 ± bold_0.54</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">However, we note that for style intensity, the Synth none configuration performed better in two out of three expressive styles in the dataset, despite having lower naturalness in each case (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S4.T3" title="Table 3 ‣ 4 Results ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Although VC can achieve higher overall naturalness for all styles, it drops in terms of style intensity for specific styles. Specifically, in the harsh style, Synth None exhibits higher style intensity than VC, even though it performs lower in terms of naturalness in this style. Synth both consistently maintains a mid-level of higher style intensity and higher naturalness. In cases where VC’s style intensity is higher (e.g., welcoming), Synth both achieves higher style intensity than the other configurations. Moreover, even in the harsh style, where VC performs poorly, Synth both can still retain some style intensity from the original data.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">Regarding speaker similarity (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S4.T4" title="Table 4 ‣ 4 Results ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">4</span></a>), we observe that Synth TTS mostly preserves the similarity of timbre in cross-speaker scenarios, with Synth both following closely. However, Synth none performs worse in this aspect.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Speaker Similarity MOS 95% confidence intervals.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T4.3.4.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.3.4.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.2.1">Similarity</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T4.1.1.2">Synth none</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.1"><math alttext="2.44\pm 0.20" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.m1.1a"><mrow id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mn id="S4.T4.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.m1.1.1.2.cmml">2.44</mn><mo id="S4.T4.1.1.1.m1.1.1.1" xref="S4.T4.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T4.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.m1.1.1.3.cmml">0.20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T4.1.1.1.m1.1.1.2.cmml" type="float" xref="S4.T4.1.1.1.m1.1.1.2">2.44</cn><cn id="S4.T4.1.1.1.m1.1.1.3.cmml" type="float" xref="S4.T4.1.1.1.m1.1.1.3">0.20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">2.44\pm 0.20</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.m1.1d">2.44 ± 0.20</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.2.2.2">Synth TTS</th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.1"><math alttext="\mathbf{2.93\pm 0.20}" class="ltx_Math" display="inline" id="S4.T4.2.2.1.m1.1"><semantics id="S4.T4.2.2.1.m1.1a"><mrow id="S4.T4.2.2.1.m1.1.1" xref="S4.T4.2.2.1.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S4.T4.2.2.1.m1.1.1.2" mathvariant="bold" xref="S4.T4.2.2.1.m1.1.1.2.cmml">2.93</mn><mo id="S4.T4.2.2.1.m1.1.1.1" xref="S4.T4.2.2.1.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" id="S4.T4.2.2.1.m1.1.1.3" mathvariant="bold" xref="S4.T4.2.2.1.m1.1.1.3.cmml">0.20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.1.m1.1b"><apply id="S4.T4.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.2.2.1.m1.1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T4.2.2.1.m1.1.1.2.cmml" type="float" xref="S4.T4.2.2.1.m1.1.1.2">2.93</cn><cn id="S4.T4.2.2.1.m1.1.1.3.cmml" type="float" xref="S4.T4.2.2.1.m1.1.1.3">0.20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.1.m1.1c">\mathbf{2.93\pm 0.20}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.1.m1.1d">bold_2.93 ± bold_0.20</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T4.3.3.2">Synth both</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.3.1"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.3.3.1.1"><math alttext="2.72\pm 0.19" class="ltx_Math" display="inline" id="S4.T4.3.3.1.1.m1.1"><semantics id="S4.T4.3.3.1.1.m1.1a"><mrow id="S4.T4.3.3.1.1.m1.1.1" xref="S4.T4.3.3.1.1.m1.1.1.cmml"><mn id="S4.T4.3.3.1.1.m1.1.1.2" xref="S4.T4.3.3.1.1.m1.1.1.2.cmml">2.72</mn><mo id="S4.T4.3.3.1.1.m1.1.1.1" xref="S4.T4.3.3.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T4.3.3.1.1.m1.1.1.3" xref="S4.T4.3.3.1.1.m1.1.1.3.cmml">0.19</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.1.m1.1b"><apply id="S4.T4.3.3.1.1.m1.1.1.cmml" xref="S4.T4.3.3.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.3.3.1.1.m1.1.1.1.cmml" xref="S4.T4.3.3.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S4.T4.3.3.1.1.m1.1.1.2.cmml" type="float" xref="S4.T4.3.3.1.1.m1.1.1.2">2.72</cn><cn id="S4.T4.3.3.1.1.m1.1.1.3.cmml" type="float" xref="S4.T4.3.3.1.1.m1.1.1.3">0.19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.1.m1.1c">2.72\pm 0.19</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.1.1.m1.1d">2.72 ± 0.19</annotation></semantics></math></span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Although using only original expressive data appears to yield higher style intensity perception in synthetic speech, it results in lower naturalness and speaker similarity. Employing synthetic data generated by a Voice Conversion (VC) model improved both naturalness and speaker similarity. However, the effectiveness of style transfer in TTS for highly expressive styles is sensitive to the quality of the VC for each style. Also, training stage 1 with both synthetic and ground truth data generates a more meaningful representations as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S4.F2" title="Figure 2 ‣ 4 Results ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="211" id="S4.F2.g1" src="extracted/5848610/fig/style_spaces.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Style representations projected using UMAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#bib.bib26" title="">26</a>]</cite> when training with and without synthetic data in Stage 1 (“x” markers are synthetic expressive data).</figcaption>
</figure>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">When synthetic data is not used in style encoder training, the expressive synthetic data share the same representation as the original neutral data. While this does not affect the overall cross-speaker style transfer in experiments, since the ground truth centroids are used for inference, it prevents the TTS model from leveraging the style information of the synthetic samples.</p>
</div>
<div class="ltx_para" id="S4.p7">
<p class="ltx_p" id="S4.p7.1">Analyzing the effect of using synthetic data in a more content-dependent cross-speaker transfer, we performed the same experiments to transfer accents for our three PTBR speakers to two languages: English and Spanish. We report the objective metrics in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17364v1#S4.T5" title="Table 5 ‣ 4 Results ‣ Exploring synthetic data for cross-speaker style transfer in style representation based TTS"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Cross-language objective metrics.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T5.3.3.4.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1">UTMOS <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.1.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.1.m1.1a"><mo id="S4.T5.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T5.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.1">CER (%) <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.2.2.2.1.m1.1"><semantics id="S4.T5.2.2.2.1.m1.1a"><mo id="S4.T5.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T5.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.1.m1.1b"><ci id="S4.T5.2.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T5.3.3.3.1">SECS</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.3.3.3.m1.1"><semantics id="S4.T5.3.3.3.m1.1a"><mo id="S4.T5.3.3.3.m1.1.1" stretchy="false" xref="S4.T5.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><ci id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.3.4.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.1">GT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.2">4.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.5.2">
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.1">Synth none</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.2">2.93</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.3">12.73</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.4">0.56</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.6.3">
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.1">Synth TTS</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.2">3.04</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.3">10.42</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.4">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.7.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.3.7.4.1">Synth both</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.3.7.4.2"><span class="ltx_text ltx_font_bold" id="S4.T5.3.7.4.2.1">3.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.3.7.4.3"><span class="ltx_text ltx_font_bold" id="S4.T5.3.7.4.3.1">10.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.3.7.4.4"><span class="ltx_text ltx_font_bold" id="S4.T5.3.7.4.4.1">0.79</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.p8">
<p class="ltx_p" id="S4.p8.1">We observed that in this case, Synth both performed better than the other methods. Specifically, not using synthetic data appears to suffer from both content and speaker leakage. Adding synthetic data only in TTS seems to improve overall naturalness and intelligibility, but it still suffers from speaker leakage. Finally, by combining synthetic speech in both style encoder pre-training and TTS, it is possible to disentangle speaker information from accent representations, allowing the model to transfer the accent in a cross-speaker scenario, even when each language is dependent on a specific speaker.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and future work</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Cross-speaker style transfer in low resource expressive data scenarios is still hard due to quality degradation or information leakage. Results shows that synthetic data can be used to improve both naturalness and speaker similarity in style transfer scenario. Although style intensity is very sensitive to the quality of the style transfer capacity of voice conversion model, using it as partial representations together with ground truth style data can balance style and naturalness of synthetic speech. This approach seems effective for cross-language accent-transfer even in scenario where we have only one speaker for each foreign language, improving naturalness, intelligibility and speaker similarity. In future work, we intend to explore the usage of cross-language expressive datasets to improve languages with low resource expressive data through cross-language cross-speaker synthetic augmentation.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This study is partially funded by the Coordenação de Aperfeiçoamento de Pessoal de Nivel Superior – Brasil (CAPES) – Finance Code 001, and it is supported by the BI0S - Brazilian Institute of Data Science, grant #2020/09838-0, São Paulo Research Foundation (FAPESP). Paula D. P. Costa, Lucas H. Ueda, and Leonardo B. de M. M. Marques are also affiliated with the Dept. of Computer Engineering and Automation (DCA), Faculdade de Engenharia Elétrica e de Computação and are part of the Artificial Intelligence Lab., Recod.ai, Institute of Computing, UNICAMP.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
R. J. Skerry-Ryan, E. Battenberg, Y. Xiao, Y. Wang, D. Stanton, J. Shor, R. Weiss, R. Clark, and R. A. Saurous, “Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,” in <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 35th International Conference on Machine Learning</em>.   PMLR, Jul. 2018, pp. 4693–4702, iSSN: 2640-3498. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.mlr.press/v80/skerry-ryan18a.html" title="">https://proceedings.mlr.press/v80/skerry-ryan18a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
O. Kwon, I. Jang, C. Ahn, and H.-G. Kang, “An Effective Style Token Weight Control Technique for End-to-End Emotional Speech Synthesis,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Signal Processing Letters</em>, vol. 26, no. 9, pp. 1383–1387, Sep. 2019, conference Name: IEEE Signal Processing Letters. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/8778667" title="">https://ieeexplore.ieee.org/document/8778667</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Sorin, S. Shechtman, and R. Hoory, “Principal Style Components: Expressive Style Control and Cross-Speaker Transfer in Neural TTS,” 2020, pp. 3411–3415. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.isca-archive.org/interspeech_2020/sorin20_interspeech.html" title="">https://www.isca-archive.org/interspeech_2020/sorin20_interspeech.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
I. Vallés-Pérez, J. Roth, G. Beringer, R. Barra-Chicote, and J. Droppo, “Improving multi-speaker TTS prosody variance with a residual encoder and normalizing flows,” Jun. 2021, arXiv:2106.05762 [cs, eess]. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2106.05762" title="">http://arxiv.org/abs/2106.05762</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X. An, F. K. Soong, and L. Xie, “Disentangling Style and Speaker Attributes for TTS Style Transfer,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 30, pp. 646–658, 2022, conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9693198/" title="">https://ieeexplore.ieee.org/document/9693198/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Z. Shang, Z. Huang, H. Zhang, P. Zhang, and Y. Yan, <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Incorporating Cross-Speaker Style Transfer for Multi-Language Text-to-Speech</em>, Aug. 2021, pages: 1623.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Zaïdi, H. Seuté, B. van Niekerk, and M.-A. Carbonneau, “Daft-Exprt: Cross-Speaker Prosody Transfer on Any Text for Expressive Speech Synthesis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proc. Interspeech 2022</em>, 2022, pp. 4591–4595.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Ganin and V. Lempitsky, “Unsupervised Domain Adaptation by Backpropagation,” 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A. T. Sigurgeirsson and S. King, “Do Prosody Transfer Models Transfer Prosody?” Mar. 2023, arXiv:2303.04289 [cs, eess]. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.04289" title="">http://arxiv.org/abs/2303.04289</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
H.-S. Choi, J. Lee, W. Kim, J. Lee, H. Heo, and K. Lee, “Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in Neural Information Processing Systems</em>, vol. 34.   Curran Associates, Inc., 2021, pp. 16 251–16 265. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/87682805257e619d49b8e0dfdc14affa-Abstract.html" title="">https://proceedings.neurips.cc/paper_files/paper/2021/hash/87682805257e619d49b8e0dfdc14affa-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y. Lei, S. Yang, X. Zhu, L. Xie, and D. Su, “Cross-Speaker Emotion Transfer Through Information Perturbation in Emotional Speech Synthesis,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">IEEE Signal Processing Letters</em>, vol. 29, pp. 1948–1952, 2022, conference Name: IEEE Signal Processing Letters. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9874835" title="">https://ieeexplore.ieee.org/document/9874835</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
X. Zhu, Y. Lei, T. Li, Y. Zhang, H. Zhou, H. Lu, and L. Xie, “METTS: Multilingual Emotional Text-to-Speech by Cross-Speaker and Cross-Lingual Emotion Transfer,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, vol. 32, pp. 1506–1518, Feb. 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TASLP.2024.3363444" title="">https://doi.org/10.1109/TASLP.2024.3363444</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
G. Huybrechts, T. Merritt, G. Comini, B. Perz, R. Shah, and J. Lorenzo-Trueba, “Low-resource expressive text-to-speech using data augmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2021, pp. 6593–6597.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Sam Ribeiro, J. Roth, G. Comini, G. Huybrechts, A. Gabryś, and J. Lorenzo-Trueba, “Cross-Speaker Style Transfer for Text-to-Speech Using Data Augmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, May 2022, pp. 6797–6801, iSSN: 2379-190X. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9746179" title="">https://ieeexplore.ieee.org/document/9746179</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
H.-W. Yoon, J.-S. Kim, R. Yamamoto, R. Terashima, C.-H. Song, J.-M. Kim, and E. Song, “Enhancing multilingual tts with voice conversion based data augmentation and posterior embedding,” in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2024, pp. 12 186–12 190.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
R. Terashima, R. Yamamoto, E. Song, Y. Shirahata, H.-W. Yoon, J.-M. Kim, and K. Tachibana, “Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Interspeech 2022</em>.   ISCA, Sep. 2022, pp. 3018–3022. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.isca-archive.org/interspeech_2022/terashima22_interspeech.html" title="">https://www.isca-archive.org/interspeech_2022/terashima22_interspeech.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Kim, J. Kong, and J. Son, “Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 38th International Conference on Machine Learning</em>.   PMLR, Jul. 2021, pp. 5530–5540, iSSN: 2640-3498. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.mlr.press/v139/kim21f.html" title="">https://proceedings.mlr.press/v139/kim21f.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Łańcucki, “Fastpitch: Parallel Text-to-Speech with Pitch Prediction,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Jun. 2021, pp. 6588–6592, iSSN: 2379-190X. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9413889" title="">https://ieeexplore.ieee.org/document/9413889</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, T. Xu, G. Brockman, C. Mcleavey, and I. Sutskever, “Robust speech recognition via large-scale weak supervision,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, ser. Proceedings of Machine Learning Research, A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202.   PMLR, 23–29 Jul 2023, pp. 28 492–28 518. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.mlr.press/v202/radford23a.html" title="">https://proceedings.mlr.press/v202/radford23a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
B. van Niekerk, M.-A. Carbonneau, J. Zaïdi, M. Baas, H. Seuté, and H. Kamper, “A comparison of discrete and soft speech units for improved voice conversion,” in <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2022, pp. 6562–6566.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. W. Kim, J. Salamon, P. Li, and J. P. Bello, “Crepe: A convolutional representation for pitch estimation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2018, pp. 161–165.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. S. Chung, J. Huh, S. Mun, M. Lee, H.-S. Heo, S. Choe, C. Ham, S. Jung, B.-J. Lee, and I. Han, “In Defence of Metric Learning for Speaker Recognition,” 2020, pp. 2977–2981. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.isca-archive.org/interspeech_2020/chung20b_interspeech.html" title="">https://www.isca-archive.org/interspeech_2020/chung20b_interspeech.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
R. Yamamoto, E. Song, and J.-M. Kim, “Parallel Wavegan: A Fast Waveform Generation Model Based on Generative Adversarial Networks with Multi-Resolution Spectrogram,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, May 2020, pp. 6199–6203, iSSN: 2379-190X. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9053795" title="">https://ieeexplore.ieee.org/document/9053795</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
T. Saeki, D. Xin, W. Nakata, T. Koriyama, S. Takamichi, and H. Saruwatari, “UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022,” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proc. Interspeech 2022</em>, 2022, pp. 4521–4525.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M. Kang, W. Han, S. J. Hwang, and E. Yang, “ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech Synthesis with Diffusion and Style-based Models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">INTERSPEECH 2023</em>.   ISCA, Aug. 2023, pp. 4339–4343. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.isca-archive.org/interspeech_2023/kang23_interspeech.html" title="">https://www.isca-archive.org/interspeech_2023/kang23_interspeech.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
L. McInnes, J. Healy, N. Saul, and L. Großberger, “Umap: Uniform manifold approximation and projection,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Journal of Open Source Software</em>, vol. 3, no. 29, p. 861, 2018. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.21105/joss.00861" title="">https://doi.org/10.21105/joss.00861</a>
</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" content="{Under review}" property="dcterms:title"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 25 21:08:33 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
