<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Data Imputation using Large Language Model to Accelerate Recommender System</title>
<!--Generated on Wed Aug  7 21:05:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Large Language Model,  Data Imputation,  Recommender System" lang="en" name="keywords"/>
<base href="/html/2407.10078v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S1" title="In Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S2" title="In Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S2.SS1" title="In 2. Related Work ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Data Imputation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S2.SS2" title="In 2. Related Work ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Large Language Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S2.SS3" title="In 2. Related Work ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Recommender System</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3" title="In Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3.SS1" title="In 3. Method ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data Preparation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3.SS2" title="In 3. Method ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Fine-tune LLM Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3.SS3" title="In 3. Method ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Data Imputation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3.SS4" title="In 3. Method ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Evaluation in Recommender System</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4" title="In Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4.SS1" title="In 4. Experiment ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Model and Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4.SS2" title="In 4. Experiment ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4.SS3" title="In 4. Experiment ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S5" title="In Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Data Imputation using Large Language Model to Accelerate Recommender System</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhicheng Ding
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:zhicheng.ding@columbia.edu">zhicheng.ding@columbia.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Columbia University</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">New York</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">NY</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiahao Tian
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jtian83@gatech.edu">jtian83@gatech.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Georgia Institute of Technology</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Atlanta</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">Georgia</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhenkai Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:kay.zhenkai.wang@utexas.edu">kay.zhenkai.wang@utexas.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">The University of Texas at Austin</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Austin</span><span class="ltx_text ltx_affiliation_state" id="id11.3.id3">Texas</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinman Zhao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jinman.zhao@mail.utoronto.ca">jinman.zhao@mail.utoronto.ca</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Univeristy of Toronto</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">Toronto</span><span class="ltx_text ltx_affiliation_state" id="id15.3.id3">Ontario</span><span class="ltx_text ltx_affiliation_country" id="id16.4.id4">Canada</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Siyang Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:lisiyang98@hotmail.com">lisiyang98@hotmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">Pace University</span><span class="ltx_text ltx_affiliation_city" id="id18.2.id2">New York</span><span class="ltx_text ltx_affiliation_state" id="id19.3.id3">NY</span><span class="ltx_text ltx_affiliation_country" id="id20.4.id4">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id21.id1">The importance of recommender systems continues to grow as the volume of data generated increases. A robust recommender system can significantly enhance user experience and engagement. However, these systems often face challenges due to missing data, which can arise from various factors, including user privacy concerns and other reasons. In this paper, we propose a framework to address the challenge of sparse and missing data in recommendation systems, a significant hurdle in the age of big data. Traditional imputation methods struggle to capture complex relationships within the data. We propose a novel approach that uses fine-tuned Large Language Model (LLM) to impute missing values for recommendation tasks. LLM, trained on vast amounts of text, is able to understand complex relationships among data and intelligently fill in missing information. We evaluate our LLM-based imputation method across various tasks within the recommendation system domain, including single classification, multi-classification, and regression compared to classical data imputation methods. By demonstrating the superiority of LLM imputation over traditional methods, we establish its potential for improving recommendation system performance.</p>
</div>
<div class="ltx_keywords">Large Language Model, Data Imputation, Recommender System
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The exponential growth of big data has revolutionized many fields, offering unprecedented access to vast amounts of information. Researchers can find tons of information for uncovering patterns and making informed decisions <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib38" title="">2024</a>; Belyaeva et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib4" title="">2024</a>)</cite>. However, this abundance often masks a hidden adversary: sparse and small data. Missing information, often due to user inactivity, limited data collection, or technical constraints, can significantly hinder the effectiveness of big data models <cite class="ltx_cite ltx_citemacro_citep">(Fazlikhani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib8" title="">2018</a>)</cite>. This is particularly true in recommendation systems, where personalized experiences hinge on a rich understanding of users and items, incomplete data significantly hinders the ability to generate accurate suggestions <cite class="ltx_cite ltx_citemacro_citep">(Acharya et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib2" title="">2023</a>)</cite>. Traditional statistical methods for data imputation, like mean or median imputation, often fall short in capturing the complex relationships and underlying context within the data <cite class="ltx_cite ltx_citemacro_citep">(Jin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib15" title="">2024b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib14" title="">a</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">This paper tackles this challenge by proposing a novel approach that leverages the transformative power of LLM to address the challenge of data imputation in recommendation systems. LLMs, with their remarkable ability to process and understand vast amounts of natural language, possess the potential to intelligently fill in these missing data points. By harnessing the LLM’s capability to learn intricate relationships and context from large text corpora, our proposed method aims to impute data that is not only statistically sound but also semantically meaningful <cite class="ltx_cite ltx_citemacro_citep">(Jäger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib16" title="">2021</a>)</cite>. This enriched data can then be utilized by recommendation systems to generate more accurate and personalized suggestions for users.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Focusing on the domain of recommendation systems, we explore the specific application of LLM-based data imputation. Recommender systems rely heavily on comprehensive user and item data to generate personalized suggestions that resonate with individual preferences. By effectively imputing missing values, we aim to create a more complete picture of user behavior and item characteristics. This, in turn, allows the recommendation system to generate more accurate and relevant suggestions, ultimately enhancing the user experience.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We meticulously design a series of experiments to evaluate the effectiveness of our approach. The experiences encompass a diverse range of classification and regression tasks. These experiments delve into single classification, where the system predicts a single category for an item, multi-classification, which allows for assigning multiple categories, and regression, where the focus is on predicting continuous values like ratings. By demonstrating the superiority of LLM imputation over traditional statistical methods across these varied scenarios, we aim to establish its significance as a game-changer in improving the performance of recommendation systems.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To comprehensively assess the effectiveness of LLM-based imputation, we conduct rigorous experiments across a diverse range of tasks within the recommender system domain. These experiments encompass single classification, where the system predicts a single category for an item (e.g., AD recommendation), multi-classification, where multiple categories can be assigned (e.g., multiple categorical movies recommendation), and regression, which focuses on predicting continuous values like ratings or purchase likelihood (e.g., movie rating prediction). By demonstrating the advantage of LLM data imputation over traditional statistical methods in these varied scenarios, we experiment our proposed approach in different recommendations system tasks with different datasets. In summary, our paper makes the following primary contributions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.I1.ix1.1.1.m1.1"><semantics id="S1.I1.ix1.1.1.m1.1b"><mo id="S1.I1.ix1.1.1.m1.1.1" xref="S1.I1.ix1.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix1.1.1.m1.1c"><ci id="S1.I1.ix1.1.1.m1.1.1.cmml" xref="S1.I1.ix1.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix1.1.1.m1.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S1.I1.ix1.1.1.m1.1e">∙</annotation></semantics></math></span>
<div class="ltx_para" id="S1.I1.ix1.p1">
<p class="ltx_p" id="S1.I1.ix1.p1.1">We propose a novel approach that utilize LLM to impute missing data which aims to handle data sparsity and data bias issue.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.I1.ix2.1.1.m1.1"><semantics id="S1.I1.ix2.1.1.m1.1b"><mo id="S1.I1.ix2.1.1.m1.1.1" xref="S1.I1.ix2.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix2.1.1.m1.1c"><ci id="S1.I1.ix2.1.1.m1.1.1.cmml" xref="S1.I1.ix2.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix2.1.1.m1.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S1.I1.ix2.1.1.m1.1e">∙</annotation></semantics></math></span>
<div class="ltx_para" id="S1.I1.ix2.p1">
<p class="ltx_p" id="S1.I1.ix2.p1.1">We further utilize the imputed data and evaluate in the recommendation system which shows improvement to other statistical data imputation strategy.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.I1.ix3.1.1.m1.1"><semantics id="S1.I1.ix3.1.1.m1.1b"><mo id="S1.I1.ix3.1.1.m1.1.1" xref="S1.I1.ix3.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix3.1.1.m1.1c"><ci id="S1.I1.ix3.1.1.m1.1.1.cmml" xref="S1.I1.ix3.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix3.1.1.m1.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S1.I1.ix3.1.1.m1.1e">∙</annotation></semantics></math></span>
<div class="ltx_para" id="S1.I1.ix3.p1">
<p class="ltx_p" id="S1.I1.ix3.p1.1">Extensive experiment are done to further prove that LLM-based data imputation works better in single classification, multiple classification task and regression recommendation tasks.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Data Imputation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Data imputation has been studied extensively in both statistics and machine learning, with a rich history of methodological development. Traditional methods, such as replacing missing values with constants (e.g., zero, minimum, maximum) or aggregated measures (mean, median, most frequent), are simple but often introduce bias into the dataset <cite class="ltx_cite ltx_citemacro_citep">(Newman, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib24" title="">2014</a>)</cite>. To mitigate this limitation, more sophisticated techniques have been developed, including k-Nearest Neighbors (kNN) imputation, which imputes missing values based on similar data points, and model-based methods that leverage statistical models to predict missing values <cite class="ltx_cite ltx_citemacro_citep">(Sanjar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib28" title="">2020</a>; Peng and Leng, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib26" title="">2024</a>)</cite>. Recently, research has focused more on machine learning algorithms for imputation, such as matrix factorization and deep learning techniques <cite class="ltx_cite ltx_citemacro_citep">(Hwang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib12" title="">2018</a>)</cite>
, which can handle complex patterns and relationships within the data for more accurate imputations. However, choosing the optimal imputation method remains a critical task, which is influenced by factors such as data type, missing data mechanism (missing completely at random, missing at random, or missing not at random), the amount and pattern of missing data, and specific analytical goals <cite class="ltx_cite ltx_citemacro_citep">(Ben et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib5" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Large Language Model</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">LLM is trained on massive amounts of text data, have shown promise due to their ability to capture complex relationships and semantic information within data. This capability allows them to potentially impute missing values in a more reliable way than traditional methods. For instance, some approaches treat imputation as a classification task, where the LLM predicts the most likely value for the missing entry based on the surrounding data <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib19" title="">2024a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib20" title="">b</a>)</cite>. Others leverage the generative nature of LLMs to create a distribution of possible values, providing a more comprehensive picture of the imputation uncertainty. While promising, research on LLM-based data imputation is still evolving. Areas of exploration include mitigating potential biases present in training data and ensuring the imputed values maintain data integrity, particularly in sensitive domains like healthcare <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib36" title="">2024</a>; Deng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib7" title="">2024</a>)</cite>. Overall, LLMs offer a new avenue for tackling missing data issues, with the potential to improve the accuracy and robustness of data analysis in various fields. There are also many successful LLM applications such as in Relation Extration(RE) <cite class="ltx_cite ltx_citemacro_citep">(Wan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib32" title="">2023</a>)</cite>, NER <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib33" title="">2023</a>; Xie et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib37" title="">2023</a>)</cite>, feature engineering <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib34" title="">2024</a>)</cite>, text summarization <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib9" title="">2023</a>)</cite> and sentiment analysis <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib31" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Recommender System</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Recommender System(RS) is used to generate meaningful suggestions to a collection of users for items or products that might interest them. RS can be divided into personalized <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib35" title="">2022</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib42" title="">2022</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib41" title="">2022</a>)</cite> and group-based <cite class="ltx_cite ltx_citemacro_citep">(Stratigi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib30" title="">2022</a>; Kumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib18" title="">2022</a>; Zan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib39" title="">2021</a>; Sato, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib29" title="">2022</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib40" title="">2022</a>)</cite> systems. In recent years, neural networks like CNN <cite class="ltx_cite ltx_citemacro_citep">(An and Moon, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib3" title="">2022</a>)</cite>, GCN <cite class="ltx_cite ltx_citemacro_citep">(Kipf and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib17" title="">2016</a>)</cite>, GraphSAGE <cite class="ltx_cite ltx_citemacro_citep">(Hamilton et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib10" title="">2017</a>)</cite>, and others have significantly enhanced RS models.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Data sparsity is a persistent challenge in such systems, significantly impacting the accuracy and effectiveness of recommendations. Collaborative filtering techniques, a mainstay in recommendation systems, struggle when user-item interaction matrices are highly sparse, with many missing entries. This sparsity makes it difficult to identify similar users or items for accurate recommendations <cite class="ltx_cite ltx_citemacro_citep">(Lubos et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib21" title="">2024</a>)</cite>. More and more research has explored various approaches to address this issue, focus on developing robust recommendation systems that can effectively handle data sparsity and deliver personalized recommendations even with limited user-item interactions. In this paper, we aims to handle those missing data using LLM-based data imputation technology.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Method</h2>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S3.F1.g1" src="extracted/5772771/figs/Data_imputation.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Framework of our proposed method. Original dataset contain missing data. Using complete data to fine-tune LLM which can be further utilized to impute the missing data. After that, complete tabular data are used to feed into Recommender System.</figcaption>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we present the major components of our proposed architecture. We start with fine-tuning a pre-trained model using our task-specific dataset that only contains complete data. This fine-tuned model is then employed to impute missing data. The resulting dataset, which contains both the complete and imputed data, is then fed into the recommender system. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3.F1" title="Figure 1 ‣ 3. Method ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_tag">1</span></a> provides a visual representation of the architecture. Detailed discussions are provided in the subsequent sections.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Data Preparation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To tailor LLM for our specific task and data at hand,
we first need to fine-tune LLM. By fine-tuning a model on a much smaller dataset, its performance on the task can be improved while preserving its general language knowledge. We divide our dataset into two subsets, one is the set that only contains complete data, and the other contains data entries with missing values.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Fine-tune LLM Model</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">For the fine-tuning process, we utilize the complete dataset to enable the model to learn task-specific information. We adopt Low-Rank Adaptation (LoRA) technique  <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib11" title="">2022</a>)</cite> to achieve efficient fine-tuning of LLM. LLM is typically trained with billions of parameters, rendering comprehensive fine-tuning computationally expensive. LoRA offers a cost-effective alternative by freezing the pre-trained model weights and introducing a set of trainable low-rank adapter parameters. This approach significantly reduces the computational burden associated with fine-tuning while enabling the LLM to adapt to the specific task or domain <cite class="ltx_cite ltx_citemacro_citep">(Borisov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib6" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The data flow in the fine-tuning process begins with the collection and pre-processing of task-specific data, which is tokenized and converted into input tensors compatible with the LLM architecture. These tensors are then fed into the pre-trained LLM model. Instead of updating the entire weight matrices, LoRA introduces low-rank matrices that approximate the necessary updates. During each forward pass, the input data propagates through the attention and feed-forward layers, where the low-rank matrices are applied to modify the output dynamically. The resulting predictions are compared with the ground truth to compute the loss, which is then backpropagated through the model. Only the parameters associated with the low-rank matrices are updated, leaving the original pre-trained weights largely intact. This selective adaptation allows the model to learn task-specific features efficiently while preserving its general language understanding capabilities learned during LLM’s original training. The low-rank matrices focus on the most influential components of the dataset, enhancing the model’s ability to predict and fill in missing values accurately. This approach not only speeds up the fine-tuning process but also reduces memory and storage requirements, improving LLM’s accuracy on data imputation tasks.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">By fine-tuning the pre-trained model with a dataset containing only complete entries, we obtain a LLM that not only retains knowledge from its extensive pre-training but incorporates specific patterns from the current dataset. This approach leverages the model’s broad understanding while adapting it to the nuances of our specific task.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Data Imputation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Subsequently, the fine-tuned LLM mentioned above is used to impute missing data. We incorporate existing data information as relevant knowledge into the prompt. Prompts constructed in this manner contain example-specific information and LLM is used to model the distribution of the missing attributes. Note that the prompt can also be constructed to impute multiple values for a single example simultaneously.For instance, given a data entry with attributes <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">UserId=11</span>, <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2">MovieId=44</span>, <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.3">Genres=Sci-FI</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.4">Rating=NaN</span> (indicating missing value), the prompt would be formulated as: <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.5">”given a UserID of 11, a MovieID of 44, and a Genre of Sci-Fi, what is the corresponding Rating?”</span>. As a result, LLM will generate the most probable values based on patterns learnt from the training data and the given prompt. Then <math alttext="NaN" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">N</mi><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">a</mi><mo id="S3.SS3.p1.1.m1.1.1.1a" xref="S3.SS3.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.4" xref="S3.SS3.p1.1.m1.1.1.4.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><times id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></times><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑁</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑎</ci><ci id="S3.SS3.p1.1.m1.1.1.4.cmml" xref="S3.SS3.p1.1.m1.1.1.4">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">NaN</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_N italic_a italic_N</annotation></semantics></math>s are replaced with LLM imputed values. The imputed data is combined with the complete data to form a whole dataset used for training the Recommender System.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Evaluation in Recommender System</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">To comprehensively assess the efficacy of the LLM-based data imputation approach, the newly constructed dataset was subsequently employed to train a deep-learning-based recommendation system. To achieve a holistic evaluation of the advantages offered by LLM-based imputation, performance metrics was utilized across various task categories, encompassing single classification, multi-class classification, and regression. Within the single classification domain, precision, recall, and F1-score were adopted as the evaluation metrics. For multi-class classification tasks, Recall at k (denoted as R@k) and Normalized Discounted Cumulative Gain at k (denoted as N@k) were employed. Finally, Mean Absolute Error (MAE), Mean Squared Error (MSE), or Root Mean Squared Error (RMSE) were leveraged to assess the performance of the regression task.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S3.T1.6.6.7">model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.1.1">R@3<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.2.2.2">R@5<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.2.2.2.m1.1"><semantics id="S3.T1.2.2.2.m1.1a"><mo id="S3.T1.2.2.2.m1.1.1" stretchy="false" xref="S3.T1.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><ci id="S3.T1.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T1.3.3.3">R@10<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.3.3.3.m1.1"><semantics id="S3.T1.3.3.3.m1.1a"><mo id="S3.T1.3.3.3.m1.1.1" stretchy="false" xref="S3.T1.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.m1.1b"><ci id="S3.T1.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.4.4.4">N@3<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.4.4.4.m1.1"><semantics id="S3.T1.4.4.4.m1.1a"><mo id="S3.T1.4.4.4.m1.1.1" stretchy="false" xref="S3.T1.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.m1.1b"><ci id="S3.T1.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.5.5.5">N@5<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.5.5.5.m1.1"><semantics id="S3.T1.5.5.5.m1.1a"><mo id="S3.T1.5.5.5.m1.1.1" stretchy="false" xref="S3.T1.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.m1.1b"><ci id="S3.T1.5.5.5.m1.1.1.cmml" xref="S3.T1.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.6.6.6">N@10<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.6.6.6.m1.1"><semantics id="S3.T1.6.6.6.m1.1a"><mo id="S3.T1.6.6.6.m1.1.1" stretchy="false" xref="S3.T1.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.m1.1b"><ci id="S3.T1.6.6.6.m1.1.1.cmml" xref="S3.T1.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.6.7.1.1">Case-Wise Deletion</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.7.1.2">0.2510</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.7.1.3">0.3470</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.6.7.1.4">0.6050</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.7.1.5">0.4853</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.7.1.6">0.5381</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.7.1.7">0.7011</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.8.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.8.2.1">Zero</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.8.2.2">0.2370</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.8.2.3">0.3250</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.6.8.2.4">0.5760</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.8.2.5">0.4412</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.8.2.6">0.5005</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.8.2.7">0.6629</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.9.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.9.3.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.3.2">0.2610</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.3.3">0.3490</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.6.9.3.4">0.6110</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.3.5">0.5064</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.3.6">0.5455</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.3.7">0.7294</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.10.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.10.4.1">Knn</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.4.2">0.2880</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.4.3">0.3870</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.6.10.4.4">0.6420</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.4.5">0.5213</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.4.6">0.5674</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.4.7">0.7331</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.11.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.11.5.1">Multivariate</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.5.2">0.2760</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.5.3">0.3680</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.6.11.5.4">0.6440</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.5.5">0.5154</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.5.6">0.5401</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.5.7">0.7420</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.12.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.12.6.1">LLM</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.6.2"><span class="ltx_text ltx_font_bold" id="S3.T1.6.12.6.2.1">0.2930</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.6.3"><span class="ltx_text ltx_font_bold" id="S3.T1.6.12.6.3.1">0.4050</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.6.12.6.4"><span class="ltx_text ltx_font_bold" id="S3.T1.6.12.6.4.1">0.6530</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.6.5"><span class="ltx_text ltx_font_bold" id="S3.T1.6.12.6.5.1">0.5692</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.6.6"><span class="ltx_text ltx_font_bold" id="S3.T1.6.12.6.6.1">0.6216</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.6.7"><span class="ltx_text ltx_font_bold" id="S3.T1.6.12.6.7.1">0.7632</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Comparison among LLM-based and statistical data imputation on multiple classification task</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiment</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Model and Dataset</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We chose to utilize the pre-trained distilled version of GPT-2 model <cite class="ltx_cite ltx_citemacro_citep">(Sanh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib27" title="">2019</a>)</cite>
as our LLM because of its open-source accessibility and proven effectiveness across a wide range of tasks. For the choice of dataset, we use AdClick <cite class="ltx_cite ltx_citemacro_citep">(Jean-Baptiste Tien, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib13" title="">2014</a>)</cite> and MovieLen <cite class="ltx_cite ltx_citemacro_citep">(Nacho, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib22" title="">2022</a>)</cite> dataset for this experiment due to the fact that these are large well-structured dataset without requiring extensive data cleaning. In addition, there have been many researches conducted on these two datasets and they are available for both classification and regression tasks.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The original dataset is a structured tabular dataset. To simulate a dataset with missing values, we introduce missing data in a controlled manner. For each column in the dataset, we randomly select 5% of the data points and mark them as missing.
This selection is done independently for each column so that the rows with missing data will vary from column to column. Due to the independent selection process, more than 5% of the rows may contain at least one missing value. Here we break down into 3 different recommendation tasks:</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Single Classification:</span> We leverage the AD Click dataset to evaluate the effectiveness of our proposed architecture. The imputed data is then fed into a recommendation system designed to classify user clicks on advertisements. This approach aims to improve the accuracy of predicting user engagement with targeted advertising.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Multiple Classification: </span> We employ the widely used MovieLens dataset to assess the impact of LLM-based data imputation on movie recommendations. The imputed data is subsequently utilized by a recommendation system to suggest a personalized list of top-k movies for each user. This research aims to enhance the effectiveness of recommendation systems by addressing data sparsity issues.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Regression: </span> Building upon the MovieLens dataset, we investigate the use of LLMs for data imputation in predicting user ratings. The imputed data is then incorporated into a recommendation system tasked with predicting user ratings on a scale of 0.0 to 5.0. This approach seeks to improve the accuracy of rating predictions within recommendation systems.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Baselines</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The pre-processed datasets above contain about 5% rows with missing data. To evaluate the effectiveness and efficacy of the proposed LLM-based data imputation, we compare its performance against the following competing baseline methods:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Case-Wise Deletion: </span> without imputing missing data, feed data directly to the recommender system and discard examples with one or more missing values.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Zero Imputation: </span> replaces all missing numeric values with 0.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">Mean Imputation: </span> calculates the arithmetic mean of the column and replaces missing values with it.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">KNN Imputation: </span> imputes missing values using k-Nearest Neighbors. Each sample’s missing values are imputed using the mean value from n-th neighbors nearest neighbors found in the training set.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i5.p1.1.1">Multivariate Imputation: </span> estimates each feature from all the others and imputes missing values by modeling each feature with missing values as a function of other features in a round-robin fashion <cite class="ltx_cite ltx_citemacro_citep">(Pedregosa et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib25" title="">2011</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Evaluation</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To better evaluate LLM-based data imputation technique, we evaluate our model’s performance across three tasks: single classification, multi-class classification, and regression. Two benchmark datasets, AD click and MovieLens, are used. For both datasets, we meticulously curate the data to achieve a targeted missing value ratio of approximately 5%. Then, we feed the data with no imputation into our recommendation system for baseline performance. The DLRM <cite class="ltx_cite ltx_citemacro_citep">(Naumov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#bib.bib23" title="">2019</a>)</cite> model is utilized for this purpose and we randomly split of 60/20/20 is used for training, testing, and validation, respectively.
In addition, we applied statistical methods (mean, zero, KNN, and iterative) and our LLM-based approaches. The imputed data by different approaches will feed into DLRM one by one following the same 60/20/20 ratio for the evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The detailed results of single classification task are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4.T2" title="Table 2 ‣ 4.3. Evaluation ‣ 4. Experiment ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_tag">2</span></a>, with the top and second-highest performing models highlighted for clarity. While LLM-based data imputation approach did not achieve the absolute top performance in this particular task, as we will demonstrate in the following section, it exhibits potential for superior performance in more complex scenarios. Table <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S3.T1" title="Table 1 ‣ 3.4. Evaluation in Recommender System ‣ 3. Method ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_tag">1</span></a> presents the results of multiple classification task. Due to the richer metadata and intricate relationships within the MovieLens dataset, the LLM-based model demonstrates a clear advantage over other models. Finally, we evaluate the effectiveness of LLM-based data imputation within a regression task comparing with statistical methods.
Table <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4.T3" title="Table 3 ‣ 4.3. Evaluation ‣ 4. Experiment ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_tag">3</span></a> showcases the results, highlighting the superior performance of the LLM-based data imputation approach compared to other models.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T2.3.3.4">model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.1.1.1">precision<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.2.2.2">recall<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.m1.1a"><mo id="S4.T2.2.2.2.m1.1.1" stretchy="false" xref="S4.T2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.3.3.3">f1-score<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.m1.1.1" stretchy="false" xref="S4.T2.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.3.4.1.1">Case-Wise Deletion</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.4.1.2">0.1980</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.4.1.3">0.4450</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.4.1.4">0.2740</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.3.5.2.1">Zero</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.5.2.2">0.7207</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.5.2.3">0.7200</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.5.2.4">0.7200</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.3.6.3.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.6.3.2">0.8846</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.6.3.3">0.8700</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.6.3.4">0.8702</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.3.7.4.1">Knn</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.7.4.2"><span class="ltx_text ltx_font_bold" id="S4.T2.3.7.4.2.1">0.9192</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.7.4.3"><span class="ltx_text ltx_font_bold" id="S4.T2.3.7.4.3.1">0.9150</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.7.4.4"><span class="ltx_text ltx_font_bold" id="S4.T2.3.7.4.4.1">0.9150</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.3.8.5.1">Multivariate</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.8.5.2">0.8970</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.8.5.3">0.8900</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.8.5.4">0.8903</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.3.9.6.1">LLM</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.9.6.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.9.6.2.1">0.9071</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.9.6.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.9.6.3.1">0.9001</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.9.6.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.9.6.4.1">0.9003</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Comparison among LLM-based and statistical data imputation on single classification task</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Finally, we evaluate the effectiveness of LLM-based data imputation within a regression task comparing with statistical methods.
Table <a class="ltx_ref" href="https://arxiv.org/html/2407.10078v2#S4.T3" title="Table 3 ‣ 4.3. Evaluation ‣ 4. Experiment ‣ Data Imputation using Large Language Model to Accelerate Recommender System"><span class="ltx_text ltx_ref_tag">3</span></a> showcases the results, highlighting the superior performance of the LLM-based data imputation approach compared to other models.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T3.3.3.4">model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.1.1">MAE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.2">MSE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.m1.1a"><mo id="S4.T3.2.2.2.m1.1.1" stretchy="false" xref="S4.T3.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.3.3.3">RMSE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.m1.1a"><mo id="S4.T3.3.3.3.m1.1.1" stretchy="false" xref="S4.T3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.3.4.1.1">Case-Wise Deletion</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.4.1.2">0.7659</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.4.1.3">0.9792</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.4.1.4">0.9895</td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.3.5.2.1">Zero</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.5.2.2">0.7798</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.5.2.3">0.9928</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.5.2.4">0.9964</td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.3.6.3.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.3.2">0.7804</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.3.3">0.9883</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.6.3.4">0.9942</td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.3.7.4.1">Knn</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.4.2">0.7791</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.4.3">0.9909</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.7.4.4">0.9955</td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.3.8.5.1">Multivariate</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.8.5.2">0.7785</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.8.5.3">0.9887</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.8.5.4">0.9943</td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.3.9.6.1">LLM</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.9.6.2"><span class="ltx_text ltx_font_bold" id="S4.T3.3.9.6.2.1">0.7612</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.9.6.3"><span class="ltx_text ltx_font_bold" id="S4.T3.3.9.6.3.1">0.9647</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.9.6.4"><span class="ltx_text ltx_font_bold" id="S4.T3.3.9.6.4.1">0.9822</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Comparison among LLM-based and statistical data imputation on regression task</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In conclusion, this paper proposes a novel approach that leverages the power of LLM to address missing data in the Recommender System. By imputing missing data in a semantically meaningful way, our method enriches data and allows the Recommender System to generate more accurate and personalized suggestions, ultimately enhancing user experience. We extensively evaluate our approach across various recommender system tasks, demonstrating its effectiveness in improving performance compared to traditional data imputation methods. The implications of this research extend beyond recommender systems, opening new avenues for utilizing LLMs to mitigate data sparsity and small sample size issues in big data models, leading to a more robust Recommender System.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acharya et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Arkadeep Acharya, Brijraj Singh, and Naoyuki Onoe. 2023.

</span>
<span class="ltx_bibblock">LLM Based Generation of Item-Description for Recommendation System. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib2.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1204–1207.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3610647" title="">https://doi.org/10.1145/3604915.3610647</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An and Moon (2022)</span>
<span class="ltx_bibblock">
Hyeon-woo An and Nammee Moon. 2022.

</span>
<span class="ltx_bibblock">Design of recommendation system for tourist spot using sentiment analysis based on CNN-LSTM.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of Ambient Intelligence and Humanized Computing</em> 13, 3 (2022), 1653–1663.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belyaeva et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Anastasiya Belyaeva, Justin Cosentino, Farhad Hormozdiari, Krish Eswaran, Shravya Shetty, Greg Corrado, Andrew Carroll, Cory Y. McLean, and Nicholas A. Furlotte. 2024.

</span>
<span class="ltx_bibblock">Multimodal LLMs for Health Grounded in Individual-Specific Data. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Machine Learning for Multimodal Healthcare Data</em>, Andreas K. Maier, Julia A. Schnabel, Pallavi Tiwari, and Oliver Stegle (Eds.). Springer Nature Switzerland, Cham, 86–102.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ângela Jornada Ben, Johanna M. van Dongen, Mohamed El Alili, Martijn W. Heymans, Jos W. R. Twisk, Janet L. MacNeil-Vroomen, Maartje de Wit, Susan E. M. van Dijk, Teddy Oosterhuis, and Judith E. Bosmans. 2023.

</span>
<span class="ltx_bibblock">The handling of missing data in trial-based economic evaluations: should data be multiply imputed prior to longitudinal linear mixed-model analyses?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">The European Journal of Health Economics</em> 24, 6 (01 Aug 2023), 951–965.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10198-022-01525-y" title="">https://doi.org/10.1007/s10198-022-01525-y</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borisov et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Vadim Borisov, Kathrin Sessler, Tobias Leemann, Martin Pawelczyk, and Gjergji Kasneci. 2023.

</span>
<span class="ltx_bibblock">Language Models are Realistic Tabular Data Generators. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">The Eleventh International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=cEygmQNOeI" title="">https://openreview.net/forum?id=cEygmQNOeI</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Qixin Deng, Qikai Yang, Ruibin Yuan, Yipeng Huang, Yi Wang, Xubo Liu, Zeyue Tian, Jiahao Pan, Ge Zhang, Hanfeng Lin, et al<span class="ltx_text" id="bib.bib7.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">ComposerX: Multi-Agent Symbolic Music Composition with LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.4.1">arXiv preprint arXiv:2404.18081</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fazlikhani et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Fatemeh Fazlikhani, Pegah Motakefi, and Mir Mohsen Pedram. 2018.

</span>
<span class="ltx_bibblock">Missing Data Imputation by LOLIMOT and FSVM/FSVR Algorithms with a Novel Approach: A Comparative Study. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations</em>, Jesús Medina, Manuel Ojeda-Aciego, José Luis Verdegay, David A. Pelta, Inma P. Cabrera, Bernadette Bouchon-Meunier, and Ronald R. Yager (Eds.). Springer International Publishing, Cham, 551–569.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2023.

</span>
<span class="ltx_bibblock">News Summarization and Evaluation in the Era of GPT-3.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2209.12356 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hamilton et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017.

</span>
<span class="ltx_bibblock">Inductive representation learning on large graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Advances in neural information processing systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">https://openreview.net/forum?id=nZeVKeeFYf9</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hwang et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Won Seok Hwang, Shu Li, Seung Woo Kim, and Keun Ho Lee. 2018.

</span>
<span class="ltx_bibblock">Data imputation using a trust network for recommendation via matrix factorization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Computer Science and Information Systems</em> 15, 2 (2018), 347–368.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jean-Baptiste Tien (2014)</span>
<span class="ltx_bibblock">
Olivier Chapelle Jean-Baptiste Tien, joycenv. 2014.

</span>
<span class="ltx_bibblock">Display Advertising Challenge.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kaggle.com/competitions/criteo-display-ad-challenge" title="">https://kaggle.com/competitions/criteo-display-ad-challenge</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2024a)</span>
<span class="ltx_bibblock">
Can Jin, Tong Che, Hongwu Peng, Yiyuan Li, and Marco Pavone. 2024a.

</span>
<span class="ltx_bibblock">Learning from teaching regularization: Generalizable correlations should be easy to imitate.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">arXiv preprint arXiv:2402.02769</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2024b)</span>
<span class="ltx_bibblock">
Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong, Sanguthevar Rajasekaran, and Dimitris N Metaxas. 2024b.

</span>
<span class="ltx_bibblock">APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">arXiv preprint arXiv:2406.14449</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jäger et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Sebastian Jäger, Arndt Allhorn, and Felix Bießmann. 2021.

</span>
<span class="ltx_bibblock">A Benchmark for Data Imputation Methods.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Frontiers in Big Data</em> 4 (2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3389/fdata.2021.693674" title="">https://doi.org/10.3389/fdata.2021.693674</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kipf and Welling (2016)</span>
<span class="ltx_bibblock">
Thomas N Kipf and Max Welling. 2016.

</span>
<span class="ltx_bibblock">Semi-supervised classification with graph convolutional networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:1609.02907</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chintoo Kumar, C Ravindranath Chowdary, and Deepika Shukla. 2022.

</span>
<span class="ltx_bibblock">Automatically detecting groups using locality-sensitive hashing in group recommendations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Information Sciences</em> 601 (2022), 207–223.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2024a)</span>
<span class="ltx_bibblock">
Xinjin Li, Jinghao Chang, Tiexin Li, Wenhan Fan, Yu Ma, and Haowei Ni. 2024a.

</span>
<span class="ltx_bibblock">A Vehicle Classification Method Based on Machine Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Preprints</em> (July 2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.20944/preprints202407.0981.v1" title="">https://doi.org/10.20944/preprints202407.0981.v1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2024b)</span>
<span class="ltx_bibblock">
Xinjin Li, Yuanzhe Yang, Yixiao Yuan, Haowei Ni, Yu Ma, and Yangchen Huang. 2024b.

</span>
<span class="ltx_bibblock">Intelligent Vehicle Classification System Based on Deep Learning and Multi-Sensor Fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Preprints</em> (July 2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.20944/preprints202407.2102.v1" title="">https://doi.org/10.20944/preprints202407.2102.v1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lubos et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Sebastian Lubos, Thi Ngoc Trang Tran, Alexander Felfernig, Seda Polat Erdeniz, and Viet-Man Le. 2024.

</span>
<span class="ltx_bibblock">LLM-generated Explanations for Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization</em> (Cagliari, Italy) <em class="ltx_emph ltx_font_italic" id="bib.bib21.4.2">(UMAP Adjunct ’24)</em>. Association for Computing Machinery, New York, NY, USA, 276–285.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3631700.3665185" title="">https://doi.org/10.1145/3631700.3665185</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nacho (2022)</span>
<span class="ltx_bibblock">
Nacho. 2022.

</span>
<span class="ltx_bibblock">Movie recommender system (2022).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kaggle.com/competitions/movie-recommender-system-2022" title="">https://kaggle.com/competitions/movie-recommender-system-2022</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naumov et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, Carole-Jean Wu, Alisson G. Azzolini, Dmytro Dzhulgakov, Andrey Mallevich, Ilia Cherniavskii, Yinghai Lu, Raghuraman Krishnamoorthi, Ansha Yu, Volodymyr Kondratenko, Stephanie Pereira, Xianjie Chen, Wenlin Chen, Vijay Rao, Bill Jia, Liang Xiong, and Misha Smelyanskiy. 2019.

</span>
<span class="ltx_bibblock">Deep Learning Recommendation Model for Personalization and Recommendation Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">CoRR</em> abs/1906.00091 (2019).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1906.00091" title="">https://arxiv.org/abs/1906.00091</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Newman (2014)</span>
<span class="ltx_bibblock">
Daniel A Newman. 2014.

</span>
<span class="ltx_bibblock">Missing data: Five practical guidelines.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Organizational Research Methods</em> 17, 4 (2014), 372–411.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedregosa et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine Learning in Python.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Journal of Machine Learning Research</em> 12 (2011), 2825–2830.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng and Leng (2024)</span>
<span class="ltx_bibblock">
Lai Peng and Qian Leng. 2024.

</span>
<span class="ltx_bibblock">Research on the Application of Support Vector Machine Algorithm Model With Multi-Modal Data Fusion in Breast Cancer Ultrasound Image Classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Applied and Computational Engineering</em> 67, 1.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.54254/2755-2721/67/20240671" title="">https://doi.org/10.54254/2755-2721/67/20240671</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.

</span>
<span class="ltx_bibblock">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">NeurIPS EMC<sup class="ltx_sup" id="bib.bib27.3.1.1">2</sup> Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanjar et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Karshiev Sanjar, Olimov Bekhzod, Jaesoo Kim, Anand Paul, and Jeonghong Kim. 2020.

</span>
<span class="ltx_bibblock">Missing Data Imputation for Geolocation-based Price Prediction Using KNN–MCF Method.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">ISPRS International Journal of Geo-Information</em> 9, 4 (2020).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/ijgi9040227" title="">https://doi.org/10.3390/ijgi9040227</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sato (2022)</span>
<span class="ltx_bibblock">
Ryoma Sato. 2022.

</span>
<span class="ltx_bibblock">Enumerating fair packages for group recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em>. 870–878.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stratigi et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Maria Stratigi, Evaggelia Pitoura, Jyrki Nummenmaa, and Kostas Stefanidis. 2022.

</span>
<span class="ltx_bibblock">Sequential group recommendations based on satisfaction and disagreement scores.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Journal of Intelligent Information Systems</em> (2022), 1–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li, Tianwei Zhang, and Guoyin Wang. 2023.

</span>
<span class="ltx_bibblock">Sentiment Analysis through LLM Negotiations.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2311.01876 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, and Sadao Kurohashi. 2023.

</span>
<span class="ltx_bibblock">GPT-RE: In-context Learning for Relation Extraction using Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 3534–3547.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.214" title="">https://doi.org/10.18653/v1/2023.emnlp-main.214</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang. 2023.

</span>
<span class="ltx_bibblock">GPT-NER: Named Entity Recognition via Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2304.10428 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yining Wang, Jinman Zhao, and Yuri Lawryshyn. 2024.

</span>
<span class="ltx_bibblock">GPT-Signal: Generative AI for Semi-automated Feature Engineering in the Alpha Research Process.. In <em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">Proceedings of the Joint Workshop of the 8th Financial Technology and Natural Language Processing, and the 1st Workshop on Agent AI for Scenario Planning @ IJCAI 2024</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chao Wu, Sannyuya Liu, Zeyu Zeng, Mao Chen, Adi Alhudhaif, Xiangyang Tang, Fayadh Alenezi, Norah Alnaim, and Xicheng Peng. 2022.

</span>
<span class="ltx_bibblock">Knowledge graph-based multi-context-aware recommendation algorithm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Information Sciences</em> 595 (2022), 179–194.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua. 2024.

</span>
<span class="ltx_bibblock">NExT-GPT: Any-to-Any Multimodal LLM.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2309.05519 [cs.AI]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2309.05519" title="">https://arxiv.org/abs/2309.05519</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tingyu Xie, Qi Li, Jian Zhang, Yan Zhang, Zuozhu Liu, and Hongwei Wang. 2023.

</span>
<span class="ltx_bibblock">Empirical Study of Zero-Shot NER with ChatGPT. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 7935–7956.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.493" title="">https://doi.org/10.18653/v1/2023.emnlp-main.493</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, and Yue Zhang. 2024.

</span>
<span class="ltx_bibblock">A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">High-Confidence Computing</em> 4, 2 (2024), 100211.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.hcc.2024.100211" title="">https://doi.org/10.1016/j.hcc.2024.100211</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zan et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Shuxun Zan, Yujie Zhang, Xiangwu Meng, Pengtao Lv, and Yulu Du. 2021.

</span>
<span class="ltx_bibblock">UDA: A user-difference attention for group recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Information Sciences</em> 571 (2021), 401–417.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Song Zhang, Nan Zheng, and Danli Wang. 2022.

</span>
<span class="ltx_bibblock">GBERT: Pre-training user representations for ephemeral group recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em>. 2631–2639.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Rongmei Zhao, Shenggen Ju, Jian Peng, Ning Yang, Fanli Yan, and Siyu Sun. 2022.

</span>
<span class="ltx_bibblock">Two-level graph path reasoning for conversational recommendation with user realistic preference. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">proceedings of the 31st ACM international conference on information &amp; knowledge management</em>. 2701–2710.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiayin Zheng, Juanyun Mai, and Yanlong Wen. 2022.

</span>
<span class="ltx_bibblock">Explainable session-based recommendation with meta-path guided instances and self-attention mechanism. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 2555–2559.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug  7 21:05:31 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
