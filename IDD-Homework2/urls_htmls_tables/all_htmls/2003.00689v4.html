<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2003.00689] What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?</title><meta property="og:description" content="Although automated driving systems have been used frequently, they are still unpopular in society.
To increase the popularity of automated vehicles (AVs), assisting pedestrians to accurately understand the driving inte…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2003.00689">

<!--Generated on Sat Mar  2 13:28:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">What Timing for an Automated Vehicle
<br class="ltx_break">to Make Pedestrians Understand Its Driving Intentions
<br class="ltx_break">for Improving Their Perception of Safety?
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span id="id5.5.5" class="ltx_text ltx_font_bold" style="font-size:120%;">Hailong Liu <math id="id1.1.1.m1.1" class="ltx_Math" alttext="{}^{*~{}1}" display="inline"><semantics id="id1.1.1.m1.1a"><msup id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml"><mi id="id1.1.1.m1.1.1a" xref="id1.1.1.m1.1.1.cmml"></mi><mrow id="id1.1.1.m1.1.1.1" xref="id1.1.1.m1.1.1.1.cmml"><mi id="id1.1.1.m1.1.1.1.2" xref="id1.1.1.m1.1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.502em" id="id1.1.1.m1.1.1.1.1" xref="id1.1.1.m1.1.1.1.1.cmml">∗</mo><mn id="id1.1.1.m1.1.1.1.3" xref="id1.1.1.m1.1.1.1.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><apply id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1"><apply id="id1.1.1.m1.1.1.1.cmml" xref="id1.1.1.m1.1.1.1"><times id="id1.1.1.m1.1.1.1.1.cmml" xref="id1.1.1.m1.1.1.1.1"></times><csymbol cd="latexml" id="id1.1.1.m1.1.1.1.2.cmml" xref="id1.1.1.m1.1.1.1.2">absent</csymbol><cn type="integer" id="id1.1.1.m1.1.1.1.3.cmml" xref="id1.1.1.m1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">{}^{*~{}1}</annotation></semantics></math>, Takatsugu Hirayama <sup id="id5.5.5.1" class="ltx_sup"><span id="id5.5.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">#</span></sup>, Luis Yoichi Morales <sup id="id5.5.5.2" class="ltx_sup"><span id="id5.5.5.2.1" class="ltx_text ltx_font_medium ltx_font_italic">#</span></sup>, Hiroshi Murase <sup id="id5.5.5.3" class="ltx_sup"><span id="id5.5.5.3.1" class="ltx_text ltx_font_medium ltx_font_italic">∗</span></sup>
<br class="ltx_break"><sup id="id5.5.5.4" class="ltx_sup"><span id="id5.5.5.4.1" class="ltx_text ltx_font_medium ltx_font_italic">∗</span></sup><span id="id5.5.5.5" class="ltx_text ltx_font_medium"> Graduate School of Informatics</span></span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Nagoya University
<br class="ltx_break"><sup id="id10.2.id1" class="ltx_sup"><span id="id10.2.id1.1" class="ltx_text ltx_font_italic">#</span></sup> Institutes of Innovation for Future Society
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Nagoya University
<br class="ltx_break">Furo-cho
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Chikusa-ku
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Nagoya
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Aichi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 464-8601
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> JAPAN
<br class="ltx_break"><sup id="id11.2.id1" class="ltx_sup"><span id="id11.2.id1.1" class="ltx_text ltx_font_italic">1</span></sup> E-mail: lhl881210@live.com
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.2" class="ltx_p">Although automated driving systems have been used frequently, they are still unpopular in society.
To increase the popularity of automated vehicles (AVs), assisting pedestrians to accurately understand the driving intentions and improving their perception of safety when interacting with AVs are considered effective.
Therefore, the AV should send information about its driving intention to pedestrians when they interact with each other.
However, the following questions should be answered regarding how the AV sends the information to them:
1) What timing for an AV to make pedestrians understand its driving intentions after being noticed by them?
2) What timing for an AV to make pedestrians feel safe after being noticed by them?
Thirteen participants were invited to interact with a manually driven vehicle and an AV in an experiment.
The participants’ gaze information and a subjective evaluation of their understanding of the driving intention as well as their perception of safety were collected.
By analyzing the participants’ gaze duration on the vehicle with their subjective evaluations, we found that the AV should enable the pedestrian to accurately understand its driving intention within <math id="id8.1.m1.1" class="ltx_Math" alttext="0.5\sim 6.5" display="inline"><semantics id="id8.1.m1.1a"><mrow id="id8.1.m1.1.1" xref="id8.1.m1.1.1.cmml"><mn id="id8.1.m1.1.1.2" xref="id8.1.m1.1.1.2.cmml">0.5</mn><mo id="id8.1.m1.1.1.1" xref="id8.1.m1.1.1.1.cmml">∼</mo><mn id="id8.1.m1.1.1.3" xref="id8.1.m1.1.1.3.cmml">6.5</mn></mrow><annotation-xml encoding="MathML-Content" id="id8.1.m1.1b"><apply id="id8.1.m1.1.1.cmml" xref="id8.1.m1.1.1"><csymbol cd="latexml" id="id8.1.m1.1.1.1.cmml" xref="id8.1.m1.1.1.1">similar-to</csymbol><cn type="float" id="id8.1.m1.1.1.2.cmml" xref="id8.1.m1.1.1.2">0.5</cn><cn type="float" id="id8.1.m1.1.1.3.cmml" xref="id8.1.m1.1.1.3">6.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.1.m1.1c">0.5\sim 6.5</annotation></semantics></math> [s] and make the pedestrian feel safe within <math id="id9.2.m2.1" class="ltx_Math" alttext="0.5\sim 8.0" display="inline"><semantics id="id9.2.m2.1a"><mrow id="id9.2.m2.1.1" xref="id9.2.m2.1.1.cmml"><mn id="id9.2.m2.1.1.2" xref="id9.2.m2.1.1.2.cmml">0.5</mn><mo id="id9.2.m2.1.1.1" xref="id9.2.m2.1.1.1.cmml">∼</mo><mn id="id9.2.m2.1.1.3" xref="id9.2.m2.1.1.3.cmml">8.0</mn></mrow><annotation-xml encoding="MathML-Content" id="id9.2.m2.1b"><apply id="id9.2.m2.1.1.cmml" xref="id9.2.m2.1.1"><csymbol cd="latexml" id="id9.2.m2.1.1.1.cmml" xref="id9.2.m2.1.1.1">similar-to</csymbol><cn type="float" id="id9.2.m2.1.1.2.cmml" xref="id9.2.m2.1.1.2">0.5</cn><cn type="float" id="id9.2.m2.1.1.3.cmml" xref="id9.2.m2.1.1.3">8.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.2.m2.1c">0.5\sim 8.0</annotation></semantics></math> [s] while the pedestrian is gazing at it.</p>
</div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>INTRODUCTION</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As the development of automated driving technology has progressed, it has been used in a variety of cases such as intelligent traffic systems, goods distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and hospital logistics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
As a result, interaction between people and automated vehicles (AVs) is expected to increase.
This new technology is often not accepted by the public at the current stage of popularization within society  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> due to a lack of trust in AVs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
The essential reason for this distrust is the fear of the unknown <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, specifically a lack of knowledge regarding the intended actions of the AV while driving, i.e., the current and subsequent actions that would be taken by the AV.
Therefore, many studies claim that providing information to pedestrians regarding the driving intention of the AV is helpful in improving pedestrians’ understanding of driving intentions and their perception of safety in interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Communication between pedestrians and the AV can improved the understanding of driving intentions and perception of safety are considered effective in increasing the popularity of AVs in society.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Thus, in this work the following two problems for pedestrian–vehicle interaction are studied:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">What timing for an AV to make pedestrians understand its driving intentions after being noticed by them?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">What timing for an AV to make pedestrians feel safe after being noticed by them?</p>
</div>
</li>
</ol>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">For the above questions, we formulate and propose a hypothesis based on a decision–making process of pedestrians, including the situation model and the theory of risk homeostasis.
Based on this hypothetical model, we design an experiment of pedestrian–vehicle interaction.
The participants’ gaze information, and their subjective evaluations of the understanding of driving intentions and their perception of safety, are collected.
We seek to identify when pedestrians do not understand the intention of the vehicle, as well as when pedestrians feel danger, by analyzing the participants’ gaze duration on the vehicle with their subjective evaluations.</p>
</div>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>RELATED WORKS</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2003.00689/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="410" height="101" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Decision–making process of a pedestrian including the situation model and the theory of risk homeostasis.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In most studies of pedestrian–vehicle interaction, the availability of different information transmission methods has been subjectively evaluated.
Stefanie et al. evaluated the communication efficacy of external human–machine interfaces (eHMIs) by various light signals with the use of questionnaires and interviews <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
Clercq et al. asked participants to continuously evaluate their feeling of safety by pressing a button during a pedestrian–AV interaction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In addition, the pedestrians’ gaze behavior could be used as an objective factor to analyze pedestrian and vehicle interactions.
This is explained by the fact that the observation of the vehicle by the pedestrian could be considered as his/her desire to obtain information from the vehicle, e.g., determining the intent of the vehicle and predicting if the interaction is dangerous.
For example, Dey et al. found that the gaze point of pedestrians gradually gathered in the driver’s position through a windshield when a manually driven vehicle (MV) was approaching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
In our previous study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we found that there was a correlation between pedestrians’ gaze durations and their understanding of the driving intentions of the AV.
Besides, we considered that pedestrians’ gaze durations on the AV could represent the request for information about the AV.
Therefore, we suggested that the AV should send information about its driving intentions to the pedestrian when they interact with each other.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">However, when AVs should send information to pedestrians is still an unsolved issue.
To solve this issue, we analyze changes in pedestrians’ understanding of driving intentions and changes in their perception of safety according to the gaze duration when they are interacting a AV in this paper.</p>
</div>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>DECISION–MAKING MODEL OF PEDESTRIAN</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To improve pedestrian’s perception of safety during interactions with AVs, the mechanism upon which the perception of safety is based should be clarified.
Thus, we propose a hypothesis which shows the decision–making process of a pedestrian who is interacting with a vehicle.
It is showed in Fig. <a href="#S2.F1" title="Figure 1 ‣ 2 RELATED WORKS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
This hypothesis includes three parts: situation awareness, hazard perception, and decision-making based on risk homeostasis.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Situation awareness could be modeled by the situation model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
Firstly, situation model relies on the perception of things in the surrounding environment, e.g., AV’s relative position, relative distance, and relative speed.
Secondly, comprehension shows the understanding of the current state of the AV in a given situation, such as the driving intention of the AV.
Thirdly, based on the result of comprehension, the pedestrian will predict the driving behavior and moving trajectory of the AV.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">After establishing situation awareness, the pedestrian realizes hazards, such as anomaly detection by comparing the predicted driving behavior of the AV with his/her experience.
The subjective risk is assessed by evaluating the perceived hazards.
Subsequently, the subjective risk could be seen as the degree to which the pedestrian feels threatened, e.g., the perception of safety or the perception of danger.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">The pedestrian decides his/her behavior by comparing the perceived risk with his/her acceptable risk level according to the risk homeostasis theory <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
If the perceived risk is lower than the acceptable risk level,
the pedestrian will make a decision to do a riskier behavior.
In the opposite case, the pedestrian will make a decision to change the behavior become more careful.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">According to the above hypothesis, the gaze duration of the pedestrian at the AV will increase during interaction if pedestrians do not clearly understand the driving intentions of the AV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Besides, the pedestrians may also perceive further danger due to a lack of the understanding of driving intentions.
Thus, the gaze duration could be used to objectively evaluate the pedestrians’ understanding of the driving intentions and their perception of safety in an interaction with the AV.</p>
</div>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>EXPERIMENT DESIGN</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We convened 13 experimental participants within an age range of <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="20\sim 29" display="inline"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mn id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">20</mn><mo id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">∼</mo><mn id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">29</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1">similar-to</csymbol><cn type="integer" id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">20</cn><cn type="integer" id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3">29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">20\sim 29</annotation></semantics></math> as pedestrians.
They had different educational backgrounds because they came from various disciplines of our university.
All of them had no prior experience of interaction with AVs.
They were requested to walk from the origin to the destination as shown in Fig. <a href="#S4.F3" title="Figure 3 ‣ 4 EXPERIMENT DESIGN ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
They were told that a vehicle would interact with them during their walk.
Additionally, the participants were informed of interacting with a MV under the control of a driver and interacting with an AV automatically.
A wearable eye tracker <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">Tobii Pro Glasses 2</span> was used to measure the participants’ gaze behavior during this experement.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">A robotic wheelchair–<span id="S4.p2.1.1" class="ltx_text ltx_font_italic">WHILL Model CR</span> (Fig. <a href="#S4.F3" title="Figure 3 ‣ 4 EXPERIMENT DESIGN ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) was used as an experimental vehicle to interact with the participants during their walk.
The two modes (i.e., manual and automated) were used to drive the vehicle with a maximum speed of 1 [m/s].
In the manual driving mode, an experimenter rode on the vehicle and manipulated it using the available joystick.
The experimenter did not actively send information about their driving intention to the participants, but eye contact could not be ruled out.
In the automated driving mode, the vehicle was automatically controlled without a crew using a multi-layered LiDAR (Velodyne VLP–16) and wheel encoders.
Importantly, the AV could not recognize participants, so it could not automatically interact with them.
To achieve a smooth interaction between the AV and the participants, a wireless remote controller was secretly used by the experimenter to control whether the AV would give the right-of-way to the participant.
In other words, when the AV automatically moved along the designed route, it stopped if the experimenter pressed a button on the remote control.
If the experimenter released the button on the remote control, the AV resumed the automatic movement.
The participants did not know that the AV was being manipulated by the experimenter.
For both the MV and AV, the experimenter adjusted the driving behavior through the distance to the participant, as well as the speed and walking direction of the participant, so as to realize interaction with the participant.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:214.6pt;"><img src="/html/2003.00689/assets/x2.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_portrait" width="415" height="720" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Moving routes.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:206.0pt;"><img src="/html/2003.00689/assets/x3.png" id="S4.F3.2.g1" class="ltx_graphics ltx_img_portrait" width="416" height="736" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Experimental vehicle.</figcaption>
</figure>
</div>
</div>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">After the completion of each trial of interaction, the participants were required to complete a questionnaire on their subjective evaluations.
There were two evaluation items on the questionnaire that were answered according to 5 point Likert scales.
The first question was used to evaluate the participants’ understanding or confusion regarding the driving intention of the vehicle during the interaction according to the following scales:
<span id="S4.p3.1.1" class="ltx_text ltx_font_italic">1. Completely did not understand</span>,
<span id="S4.p3.1.2" class="ltx_text ltx_font_italic">2. Did not understand much</span>,
<span id="S4.p3.1.3" class="ltx_text ltx_font_italic">3. Neutral</span>,
<span id="S4.p3.1.4" class="ltx_text ltx_font_italic">4. Mostly understood</span>,
and <span id="S4.p3.1.5" class="ltx_text ltx_font_italic">5. Fully understood</span>.
The second question was used to evaluate the participants’ perception of safety during the interaction according to the following scales:
<span id="S4.p3.1.6" class="ltx_text ltx_font_italic">1. Very dangerous</span>,
<span id="S4.p3.1.7" class="ltx_text ltx_font_italic">2. Slightly dangerous</span>,
<span id="S4.p3.1.8" class="ltx_text ltx_font_italic">3. Neutral</span>,
<span id="S4.p3.1.9" class="ltx_text ltx_font_italic">4. Slightly safe</span>;
and <span id="S4.p3.1.10" class="ltx_text ltx_font_italic">5. Very safe</span>.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">There were three routes designed for the movement of the vehicle as shown in Fig. <a href="#S4.F3" title="Figure 3 ‣ 4 EXPERIMENT DESIGN ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
To simulate the scenario of a pedestrian interacting with the vehicle when crossing the street, route 1 was designed to cross the path of the participant.
In order to simulate the scenario of a pedestrian avoiding the vehicle, route 2 was designed to allow the vehicle and the participant move opposite each others on a straight road.
Route 3 was designed as a contrast, with no behavioral interaction between them.
Overall, each participant interacted with the MV and AV 20 times respectively.
Routes of those 40 interactions were chosen randomly.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">This experiment was permitted by an ethics review committee of Institutes of Innovation for Future Society, Nagoya University.</p>
</div>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>EXPERIMENT RESULTS</h2>

<section id="S5.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Data preprocessing</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.2" class="ltx_p">Data of route 3 were excluded for analysis because this study focuses on the gaze behavior and psychological states of participants when interacting with the vehicle.
The observed gaze data of participant <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="\#11" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">#</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">​</mo><mn id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml">11</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><times id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1"></times><ci id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">#</ci><cn type="integer" id="S5.SS1.p1.1.m1.1.1.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3">11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\#11</annotation></semantics></math> was also excluded because it had a lot of noise.
Besides, three trials of participant <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="\#3" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mrow id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">#</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p1.2.m2.1.1.1" xref="S5.SS1.p1.2.m2.1.1.1.cmml">​</mo><mn id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><times id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1"></times><ci id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">#</ci><cn type="integer" id="S5.SS1.p1.2.m2.1.1.3.cmml" xref="S5.SS1.p1.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">\#3</annotation></semantics></math>’s gaze data for interacting with the MV were excluded due to equipment problems.
In total, data from 198 trials (route 1: 114 trials, route 2: 84 trials) of interacting with the MV and data from 204 trials (route 1: 120 trials, route 2: 84 trials) of interacting with the AV were observed.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">Tobii Pro Glasses 2</span> measured the foreground video and sequence of gaze points of each participant.
The size of the measured foreground video is <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="1920\times 1080" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mn id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">1920</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p2.1.m1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">1080</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><times id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">1920</cn><cn type="integer" id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3">1080</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">1920\times 1080</annotation></semantics></math> pixels.
In each frame, the gaze point of the participant was recorded as a two-dimensional coordinate value on the plane of the foreground image.
In this experiment, the central visual field of participants was defined as a circle.
The gaze point was the center of a circle with a diameter of 108 pixels.
If any part of the vehicle area overlapped with part of the circle, then it was determined that the participant was gazing at the vehicle.
Under the abovementioned conditions, the total time of the gazes on the vehicle was calculated as the gaze duration in each trial.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The difference between this experiment and our previous experiment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is that each participant’s gaze duration data was not standardized in this study.
The reason was that AVs cannot perceive the individual differences in the gaze duration of each participant in practical applications and situations.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Subjective evaluation results</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Referring to the selection ratio of each subjective evaluation in Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Subjective evaluation results ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the most frequent evaluation for the MV was <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">5. Fully understood</span> (42.4%).
Besides, <span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_italic">4. Mostly understood</span> was the most frequent evaluation for the AV (44.1%).
The selection ratio for the MV was significantly less than that for the AV when the participants chose <span id="S5.SS2.p1.1.3" class="ltx_text ltx_font_italic">1. Completely did not understand</span> (MV is 1%, AV is 3.4%) and <span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_italic">2. Did not understand much</span> (MV is 4.5%, AV is 19.1%).
The above can be explained as being more difficult for them to understand the driving intention of the vehicle when interacting with the AV than when interacting with the MV.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Meanwhile, evaluation results for the perception of safety were similar to the evaluation results for the understanding of driving intentions.
Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Subjective evaluation results ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows that the most frequently selected scale was <span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_italic">5. Very safe</span> for the MV (43.4%) and <span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_italic">4. Slightly safe</span> for the AV (42.2%).
0.5% trails of interaction with the MV and 2.5% trails of interaction with the AV were evaluated as <span id="S5.SS2.p2.1.3" class="ltx_text ltx_font_italic">1. Very dangerous</span>.
The ratio of selecting <span id="S5.SS2.p2.1.4" class="ltx_text ltx_font_italic">2. Slightly dangerous</span> when interacting with the AV (10.3%) was also higher than that when interacting with the MV (8.1%).
The above results show that participants felt situations to be more dangerous when interacting with the AV than when interacting with the MV.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Gaze durations and subjective evaluation scales.</figcaption>
<table id="S5.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"></th>
<th id="S5.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;" colspan="3"><span id="S5.T1.1.1.1.2.1" class="ltx_text" style="font-size:80%;">MV</span></th>
<th id="S5.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;" colspan="3"><span id="S5.T1.1.1.1.3.1" class="ltx_text" style="font-size:80%;">AV</span></th>
<th id="S5.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;" rowspan="2"><span id="S5.T1.1.1.1.4.1" class="ltx_text" style="font-size:80%;">
<span id="S5.T1.1.1.1.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T1.1.1.1.4.1.1.1" class="ltx_tr">
<span id="S5.T1.1.1.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;">Difference between median</span></span>
<span id="S5.T1.1.1.1.4.1.1.2" class="ltx_tr">
<span id="S5.T1.1.1.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;">values of gaze duration</span></span>
<span id="S5.T1.1.1.1.4.1.1.3" class="ltx_tr">
<span id="S5.T1.1.1.1.4.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;">on AV and MV [s]</span></span>
</span></span></th>
</tr>
<tr id="S5.T1.1.2.2" class="ltx_tr">
<th id="S5.T1.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"></th>
<th id="S5.T1.1.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;">
<table id="S5.T1.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.2.2.2.1.1" class="ltx_tr">
<td id="S5.T1.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Selection</span></td>
</tr>
<tr id="S5.T1.1.2.2.2.1.2" class="ltx_tr">
<td id="S5.T1.1.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.2.1.2.1.1" class="ltx_text" style="font-size:80%;">ratio</span></td>
</tr>
</table>
</th>
<th id="S5.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;">
<table id="S5.T1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.2.2.3.1.1" class="ltx_tr">
<td id="S5.T1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.3.1.1.1.1" class="ltx_text" style="font-size:80%;">Median</span></td>
</tr>
<tr id="S5.T1.1.2.2.3.1.2" class="ltx_tr">
<td id="S5.T1.1.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.3.1.2.1.1" class="ltx_text" style="font-size:80%;">value [s]</span></td>
</tr>
</table>
</th>
<th id="S5.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;">
<table id="S5.T1.1.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.2.2.4.1.1" class="ltx_tr">
<td id="S5.T1.1.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.4.1.1.1.1" class="ltx_text" style="font-size:80%;">IQR</span></td>
</tr>
<tr id="S5.T1.1.2.2.4.1.2" class="ltx_tr">
<td id="S5.T1.1.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.4.1.2.1.1" class="ltx_text" style="font-size:80%;">[s]</span></td>
</tr>
</table>
</th>
<th id="S5.T1.1.2.2.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;">
<table id="S5.T1.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.2.2.5.1.1" class="ltx_tr">
<td id="S5.T1.1.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.5.1.1.1.1" class="ltx_text" style="font-size:80%;">Selection</span></td>
</tr>
<tr id="S5.T1.1.2.2.5.1.2" class="ltx_tr">
<td id="S5.T1.1.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.5.1.2.1.1" class="ltx_text" style="font-size:80%;">ratio</span></td>
</tr>
</table>
</th>
<th id="S5.T1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;">
<table id="S5.T1.1.2.2.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.2.2.6.1.1" class="ltx_tr">
<td id="S5.T1.1.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.6.1.1.1.1" class="ltx_text" style="font-size:80%;">Median</span></td>
</tr>
<tr id="S5.T1.1.2.2.6.1.2" class="ltx_tr">
<td id="S5.T1.1.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.6.1.2.1.1" class="ltx_text" style="font-size:80%;">value [s]</span></td>
</tr>
</table>
</th>
<th id="S5.T1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;">
<table id="S5.T1.1.2.2.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.2.2.7.1.1" class="ltx_tr">
<td id="S5.T1.1.2.2.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.7.1.1.1.1" class="ltx_text" style="font-size:80%;">IQR</span></td>
</tr>
<tr id="S5.T1.1.2.2.7.1.2" class="ltx_tr">
<td id="S5.T1.1.2.2.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.2.2.7.1.2.1.1" class="ltx_text" style="font-size:80%;">[s]</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.3.1" class="ltx_tr">
<td id="S5.T1.1.3.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.1.1" class="ltx_text" style="font-size:80%;">1. Completely did not understand</span></td>
<td id="S5.T1.1.3.1.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.2.1" class="ltx_text" style="font-size:80%;">1%</span></td>
<td id="S5.T1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.3.1" class="ltx_text" style="font-size:80%;">3.249</span></td>
<td id="S5.T1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.4.1" class="ltx_text" style="font-size:80%;">0.929</span></td>
<td id="S5.T1.1.3.1.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.5.1" class="ltx_text" style="font-size:80%;">3.4%</span></td>
<td id="S5.T1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.6.1" class="ltx_text" style="font-size:80%;">6.156</span></td>
<td id="S5.T1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.7.1" class="ltx_text" style="font-size:80%;">2.329</span></td>
<td id="S5.T1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.3.1.8.1" class="ltx_text" style="font-size:80%;">2.907</span></td>
</tr>
<tr id="S5.T1.1.4.2" class="ltx_tr">
<td id="S5.T1.1.4.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.1.1" class="ltx_text" style="font-size:80%;">2. Did not understand much</span></td>
<td id="S5.T1.1.4.2.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.2.1" class="ltx_text" style="font-size:80%;">4.5%</span></td>
<td id="S5.T1.1.4.2.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.3.1" class="ltx_text" style="font-size:80%;">3.058</span></td>
<td id="S5.T1.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.4.1" class="ltx_text" style="font-size:80%;">2.459</span></td>
<td id="S5.T1.1.4.2.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.5.1" class="ltx_text" style="font-size:80%;">19.1%</span></td>
<td id="S5.T1.1.4.2.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.6.1" class="ltx_text" style="font-size:80%;">4.478</span></td>
<td id="S5.T1.1.4.2.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.7.1" class="ltx_text" style="font-size:80%;">4.058</span></td>
<td id="S5.T1.1.4.2.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.4.2.8.1" class="ltx_text" style="font-size:80%;">1.420</span></td>
</tr>
<tr id="S5.T1.1.5.3" class="ltx_tr">
<td id="S5.T1.1.5.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.1.1" class="ltx_text" style="font-size:80%;">3. Neutral</span></td>
<td id="S5.T1.1.5.3.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.2.1" class="ltx_text" style="font-size:80%;">15.2%</span></td>
<td id="S5.T1.1.5.3.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.3.1" class="ltx_text" style="font-size:80%;">2.750</span></td>
<td id="S5.T1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.4.1" class="ltx_text" style="font-size:80%;">1.901</span></td>
<td id="S5.T1.1.5.3.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.5.1" class="ltx_text" style="font-size:80%;">21.1%</span></td>
<td id="S5.T1.1.5.3.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.6.1" class="ltx_text" style="font-size:80%;">4.318</span></td>
<td id="S5.T1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.7.1" class="ltx_text" style="font-size:80%;">3.077</span></td>
<td id="S5.T1.1.5.3.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.5.3.8.1" class="ltx_text" style="font-size:80%;">1.568</span></td>
</tr>
<tr id="S5.T1.1.6.4" class="ltx_tr">
<td id="S5.T1.1.6.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.1.1" class="ltx_text" style="font-size:80%;">4. Mostly understood</span></td>
<td id="S5.T1.1.6.4.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.2.1" class="ltx_text" style="font-size:80%;">36.9%</span></td>
<td id="S5.T1.1.6.4.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.3.1" class="ltx_text" style="font-size:80%;">2.479</span></td>
<td id="S5.T1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.4.1" class="ltx_text" style="font-size:80%;">1.719</span></td>
<td id="S5.T1.1.6.4.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.5.1" class="ltx_text" style="font-size:80%;">44.1%</span></td>
<td id="S5.T1.1.6.4.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.6.1" class="ltx_text" style="font-size:80%;">3.885</span></td>
<td id="S5.T1.1.6.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.7.1" class="ltx_text" style="font-size:80%;">2.867</span></td>
<td id="S5.T1.1.6.4.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.6.4.8.1" class="ltx_text" style="font-size:80%;">1.406</span></td>
</tr>
<tr id="S5.T1.1.7.5" class="ltx_tr">
<td id="S5.T1.1.7.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.1.1" class="ltx_text" style="font-size:80%;">5. Fully understood</span></td>
<td id="S5.T1.1.7.5.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.2.1" class="ltx_text" style="font-size:80%;">42.4%</span></td>
<td id="S5.T1.1.7.5.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.3.1" class="ltx_text" style="font-size:80%;">1.650</span></td>
<td id="S5.T1.1.7.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.4.1" class="ltx_text" style="font-size:80%;">2.149</span></td>
<td id="S5.T1.1.7.5.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.5.1" class="ltx_text" style="font-size:80%;">12.3%</span></td>
<td id="S5.T1.1.7.5.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.6.1" class="ltx_text" style="font-size:80%;">2.179</span></td>
<td id="S5.T1.1.7.5.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.7.1" class="ltx_text" style="font-size:80%;">2.318</span></td>
<td id="S5.T1.1.7.5.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.7.5.8.1" class="ltx_text" style="font-size:80%;">0.529</span></td>
</tr>
<tr id="S5.T1.1.8.6" class="ltx_tr">
<td id="S5.T1.1.8.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.1.1" class="ltx_text" style="font-size:80%;">1. Very dangerous</span></td>
<td id="S5.T1.1.8.6.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.2.1" class="ltx_text" style="font-size:80%;">0.5%</span></td>
<td id="S5.T1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.3.1" class="ltx_text" style="font-size:80%;">2.798</span></td>
<td id="S5.T1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.4.1" class="ltx_text" style="font-size:80%;">0.000</span></td>
<td id="S5.T1.1.8.6.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.5.1" class="ltx_text" style="font-size:80%;">2.5%</span></td>
<td id="S5.T1.1.8.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.6.1" class="ltx_text" style="font-size:80%;">5.037</span></td>
<td id="S5.T1.1.8.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.7.1" class="ltx_text" style="font-size:80%;">1.899</span></td>
<td id="S5.T1.1.8.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.8.6.8.1" class="ltx_text" style="font-size:80%;">2.239</span></td>
</tr>
<tr id="S5.T1.1.9.7" class="ltx_tr">
<td id="S5.T1.1.9.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.1.1" class="ltx_text" style="font-size:80%;">2. Slightly dangerous</span></td>
<td id="S5.T1.1.9.7.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.2.1" class="ltx_text" style="font-size:80%;">8.1%</span></td>
<td id="S5.T1.1.9.7.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.3.1" class="ltx_text" style="font-size:80%;">3.069</span></td>
<td id="S5.T1.1.9.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.4.1" class="ltx_text" style="font-size:80%;">1.023</span></td>
<td id="S5.T1.1.9.7.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.5.1" class="ltx_text" style="font-size:80%;">10.3%</span></td>
<td id="S5.T1.1.9.7.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.6.1" class="ltx_text" style="font-size:80%;">5.479</span></td>
<td id="S5.T1.1.9.7.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.7.1" class="ltx_text" style="font-size:80%;">3.498</span></td>
<td id="S5.T1.1.9.7.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.9.7.8.1" class="ltx_text" style="font-size:80%;">2.410</span></td>
</tr>
<tr id="S5.T1.1.10.8" class="ltx_tr">
<td id="S5.T1.1.10.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.1.1" class="ltx_text" style="font-size:80%;">3. Neutral</span></td>
<td id="S5.T1.1.10.8.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.2.1" class="ltx_text" style="font-size:80%;">15.2%</span></td>
<td id="S5.T1.1.10.8.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.3.1" class="ltx_text" style="font-size:80%;">2.419</span></td>
<td id="S5.T1.1.10.8.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.4.1" class="ltx_text" style="font-size:80%;">1.709</span></td>
<td id="S5.T1.1.10.8.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.5.1" class="ltx_text" style="font-size:80%;">26.0%</span></td>
<td id="S5.T1.1.10.8.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.6.1" class="ltx_text" style="font-size:80%;">4.591</span></td>
<td id="S5.T1.1.10.8.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.7.1" class="ltx_text" style="font-size:80%;">2.957</span></td>
<td id="S5.T1.1.10.8.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.10.8.8.1" class="ltx_text" style="font-size:80%;">2.172</span></td>
</tr>
<tr id="S5.T1.1.11.9" class="ltx_tr">
<td id="S5.T1.1.11.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.1.1" class="ltx_text" style="font-size:80%;">4. Slightly safe</span></td>
<td id="S5.T1.1.11.9.2" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.2.1" class="ltx_text" style="font-size:80%;">32.8%</span></td>
<td id="S5.T1.1.11.9.3" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.3.1" class="ltx_text" style="font-size:80%;">2.799</span></td>
<td id="S5.T1.1.11.9.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.4.1" class="ltx_text" style="font-size:80%;">2.119</span></td>
<td id="S5.T1.1.11.9.5" class="ltx_td ltx_align_right" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.5.1" class="ltx_text" style="font-size:80%;">42.2%</span></td>
<td id="S5.T1.1.11.9.6" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.6.1" class="ltx_text" style="font-size:80%;">3.703</span></td>
<td id="S5.T1.1.11.9.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.7.1" class="ltx_text" style="font-size:80%;">2.773</span></td>
<td id="S5.T1.1.11.9.8" class="ltx_td ltx_align_center" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.11.9.8.1" class="ltx_text" style="font-size:80%;">0.904</span></td>
</tr>
<tr id="S5.T1.1.12.10" class="ltx_tr">
<td id="S5.T1.1.12.10.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.1.1" class="ltx_text" style="font-size:80%;">5. Very safe</span></td>
<td id="S5.T1.1.12.10.2" class="ltx_td ltx_align_right ltx_border_b" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.2.1" class="ltx_text" style="font-size:80%;">43.4%</span></td>
<td id="S5.T1.1.12.10.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.3.1" class="ltx_text" style="font-size:80%;">1.535</span></td>
<td id="S5.T1.1.12.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.4.1" class="ltx_text" style="font-size:80%;">2.019</span></td>
<td id="S5.T1.1.12.10.5" class="ltx_td ltx_align_right ltx_border_b" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.5.1" class="ltx_text" style="font-size:80%;">19.1%</span></td>
<td id="S5.T1.1.12.10.6" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.6.1" class="ltx_text" style="font-size:80%;">2.219</span></td>
<td id="S5.T1.1.12.10.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.7.1" class="ltx_text" style="font-size:80%;">2.379</span></td>
<td id="S5.T1.1.12.10.8" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:5.7pt;padding-right:5.7pt;"><span id="S5.T1.1.12.10.8.1" class="ltx_text" style="font-size:80%;">0.684</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Gaze durations for each subjective evaluation scale</h3>

<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:208.1pt;"><img src="/html/2003.00689/assets/x4.png" id="S5.F5.1.g1" class="ltx_graphics ltx_img_square" width="461" height="380" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Gaze durations for each subjective evaluation scale of understanding driving intentions.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:208.1pt;"><img src="/html/2003.00689/assets/x5.png" id="S5.F5.2.g1" class="ltx_graphics ltx_img_square" width="461" height="380" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Gaze durations for each subjective evaluation scale of the perception of safety.</figcaption>
</figure>
</div>
</div>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The differences in participant gaze durations on the MV and AV for different subjective evaluation scales were investigated.
Figs. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> show the probability density of gaze durations for two subjective evaluations, i.e., for the understanding of driving intentions and for the perception of safety.
The vertical axis and the horizontal axis indicate the probability and the gaze duration, respectively.
Note that the horizontal axis signifies the integration time because the gaze duration is the total time of all gazes on the vehicle in the interaction.
In those graphs, the green color indicates interaction with the MV and the red color indicates interaction with the AV.
Samples of each gaze duration are represented by short vertical lines on the horizontal axis.
The median values are represented by long dotted lines.
To infer their probability density, kernel density estimation with a Gaussian kernel was used in order to account for individual differences that are potentially included in the gaze durations.
The inferred probability density of gaze durations for the MV and the AV are represented by green and red curves in Figs. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Accroding to Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Subjective evaluation results ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the gaze durations for the AV were longer than that for the MV in terms of the median value of gaze durations corresponding to each scale of the evaluation for the understanding of driving intentions.
This showcased that if the participants did not understand the driving intention of the vehicle, then their gaze durations increased because they needed more time to observe the state of the vehicle and obtain information that could be used to infer the driving intention.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">Regarding each scale of the evaluation for the perception of safety, the median values of gaze durations on the AV were higher than on the MV, as shown in Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Subjective evaluation results ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
This shows that the gaze durations on the vehicle increased as the participants’ perception of safety in interactions decreased.
It also implies that the participants watched the vehicle more attentively when they felt that it was dangerous.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">Combining the results of these two subjective evaluations, we consider that the observation time (gaze duration) of the participants for the AV increases in order to prevent the AV becoming a danger to themselves when they did not understand the driving intention of the AV.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.1" class="ltx_p">Meanwhile, for both the evaluations of the understanding of driving intentions and the perception of safety, the interquartile ranges (IQR) of gaze durations on the AV were also higher than those on the MV, as shown in Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Subjective evaluation results ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
This indicates that the participants had greater individual differences in their strategy of observation for the AV than for the MV because they did not have much experience interacting with the AV, especially in real world situations.</p>
</div>
<figure id="S5.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F9.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:208.1pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2003.00689/assets/x6.png" id="S5.F9.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="461" height="157" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Ratios of 5 point Likert scales for the understanding of driving intentions in every 0.5 [s] interval of gaze duration on the MV.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2003.00689/assets/x7.png" id="S5.F9.2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="157" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Ratios of 5 point Likert scales for the understanding the driving intentions in every 0.5 [s] interval of gaze duration on the AV.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F9.4" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:208.1pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2003.00689/assets/x8.png" id="S5.F9.3.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="461" height="157" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Ratios of 5 point Likert scales for the perception of safety in every 0.5 [s] interval of gaze duration on the MV.
<br class="ltx_break"></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2003.00689/assets/x9.png" id="S5.F9.4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="157" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Ratios of 5 point Likert scales for the perception of safety in every 0.5 [s] interval of gaze duration on the AV.</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>What timing for an AV to make pedestrians understand its driving intentions after being noticed by them?</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">The ratios of 5 point Likert scales for the understanding of driving intentions were checked for occurrance in every 0.5 [s] interval of gaze durations as shown in Figs. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.
For the interaction between the participants and the MV, the ratios of <span id="S5.SS4.p1.1.1" class="ltx_text ltx_font_italic">4. Mostly understood</span> and <span id="S5.SS4.p1.1.2" class="ltx_text ltx_font_italic">5. Fully understood</span> were significantly higher than the others for most of the intervals, as shown in Fig. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.
In contrast, for the interaction with the AV, the ratios of <span id="S5.SS4.p1.1.3" class="ltx_text ltx_font_italic">1. Completely did not understand</span> and <span id="S5.SS4.p1.1.4" class="ltx_text ltx_font_italic">2. Did not understand much</span>, increased, and the ratios of <span id="S5.SS4.p1.1.5" class="ltx_text ltx_font_italic">4. Mostly understood</span> and <span id="S5.SS4.p1.1.6" class="ltx_text ltx_font_italic">5. Fully understood</span> decreased as the gaze duration increased, as shown in Fig. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<section id="S5.SS4.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.1 </span>Lower bound of the timing</h4>

<div id="S5.SS4.SSS1.p1" class="ltx_para">
<p id="S5.SS4.SSS1.p1.2" class="ltx_p">To determine the lower band of the timing that the AV should make the pedestrian understand its driving intentions after it is noticed,
we investigated the time range of gaze durations when the participants felt it difficult to understand the driving intention.
When the participants evaluated the AV’s driving intention as <span id="S5.SS4.SSS1.p1.2.1" class="ltx_text ltx_font_italic">2. Did not understand much</span>, the shortest gaze duration was more than <math id="S5.SS4.SSS1.p1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S5.SS4.SSS1.p1.1.m1.1a"><mn id="S5.SS4.SSS1.p1.1.m1.1.1" xref="S5.SS4.SSS1.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p1.1.m1.1b"><cn type="float" id="S5.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p1.1.m1.1c">0.5</annotation></semantics></math> [s].
Although it was a small ratio, it showed that the AV should make the pedestrian understand its driving intentions <math id="S5.SS4.SSS1.p1.2.m2.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S5.SS4.SSS1.p1.2.m2.1a"><mn id="S5.SS4.SSS1.p1.2.m2.1.1" xref="S5.SS4.SSS1.p1.2.m2.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p1.2.m2.1b"><cn type="float" id="S5.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS4.SSS1.p1.2.m2.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p1.2.m2.1c">0.5</annotation></semantics></math> [s] after it is noticed, such as sending information about the driving intentions to the pedestrian.</p>
</div>
</section>
<section id="S5.SS4.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.2 </span>Upper bound of the timing</h4>

<div id="S5.SS4.SSS2.p1" class="ltx_para">
<p id="S5.SS4.SSS2.p1.1" class="ltx_p">Each scale in the 5 point Likert scales has chance level of 20% to be chosen.
Thus, there is a 40% chance of choosing scales about “did not understood” (i.e., <span id="S5.SS4.SSS2.p1.1.1" class="ltx_text ltx_font_italic">1. Completely did not understand</span> and <span id="S5.SS4.SSS2.p1.1.2" class="ltx_text ltx_font_italic">2. Did not understand much</span>) or scales about “understood” (i.e., <span id="S5.SS4.SSS2.p1.1.3" class="ltx_text ltx_font_italic">4. Mostly understood</span> and <span id="S5.SS4.SSS2.p1.1.4" class="ltx_text ltx_font_italic">5. Fully understood</span>).
Therefore, a threshold for the evaluation ratio in 0.5 s intervals of gaze durations was set to 40%.
Figure <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows that only for interactions with the AV, the shortest gaze duration in the intervals that the participants did not understand the driving intentions in more than 40% trials was over 6.5 [s].
Therefore, we recommend that the AV is better to make the pedestrian understand its driving intentions accurately within the first 6.5 [s] while the pedestrian is gazing at it.</p>
</div>
</section>
</section>
<section id="S5.SS5" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>What timing for an AV to make pedestrians feel safe after being noticed by them?</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">We calculated the ratios of 5 point Likert scales for the perception of safety for occurrance in every 0.5 [s] interval of gaze durations as shown in Figs. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.
As shown in Fig. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, for the evaluation result of interacting with the MV, <span id="S5.SS5.p1.1.1" class="ltx_text ltx_font_italic">4. Slightly safe</span> and <span id="S5.SS5.p1.1.2" class="ltx_text ltx_font_italic">5. Very safe</span> were chosen in most of the intervals.
For the interaction with the AV, the ratios of <span id="S5.SS5.p1.1.3" class="ltx_text ltx_font_italic">1. Very dangerous</span> and <span id="S5.SS5.p1.1.4" class="ltx_text ltx_font_italic">2. Slightly dangerous</span> increased, and the ratios of <span id="S5.SS5.p1.1.5" class="ltx_text ltx_font_italic">4. Slightly safe</span> and <span id="S5.SS5.p1.1.6" class="ltx_text ltx_font_italic">5. Very safe</span> decreased as the gaze duration increased, as shown in Fig. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<section id="S5.SS5.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.1 </span>Lower bound of the timing</h4>

<div id="S5.SS5.SSS1.p1" class="ltx_para">
<p id="S5.SS5.SSS1.p1.1" class="ltx_p">We also investigated the shortest gaze duration when the pedestrians felt dangerous to determine the lower band of the timing that the AV should make the pedestrian feel safe after it is noticed.
Fig. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows that the shortest gaze duration when the participants chose <span id="S5.SS5.SSS1.p1.1.1" class="ltx_text ltx_font_italic">1. Very dangerous</span> was in the interval <math id="S5.SS5.SSS1.p1.1.m1.1" class="ltx_Math" alttext="0.5\sim 1.0" display="inline"><semantics id="S5.SS5.SSS1.p1.1.m1.1a"><mrow id="S5.SS5.SSS1.p1.1.m1.1.1" xref="S5.SS5.SSS1.p1.1.m1.1.1.cmml"><mn id="S5.SS5.SSS1.p1.1.m1.1.1.2" xref="S5.SS5.SSS1.p1.1.m1.1.1.2.cmml">0.5</mn><mo id="S5.SS5.SSS1.p1.1.m1.1.1.1" xref="S5.SS5.SSS1.p1.1.m1.1.1.1.cmml">∼</mo><mn id="S5.SS5.SSS1.p1.1.m1.1.1.3" xref="S5.SS5.SSS1.p1.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.SSS1.p1.1.m1.1b"><apply id="S5.SS5.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS5.SSS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS5.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS5.SSS1.p1.1.m1.1.1.1">similar-to</csymbol><cn type="float" id="S5.SS5.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS5.SSS1.p1.1.m1.1.1.2">0.5</cn><cn type="float" id="S5.SS5.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS5.SSS1.p1.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.SSS1.p1.1.m1.1c">0.5\sim 1.0</annotation></semantics></math> [s].
Thus, the AV is better to start to make the pedestrian feel safe 0.5 [s] after it is noticed.</p>
</div>
</section>
<section id="S5.SS5.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.2 </span>Upper bound of the timing</h4>

<div id="S5.SS5.SSS2.p1" class="ltx_para">
<p id="S5.SS5.SSS2.p1.1" class="ltx_p">Similarly, the total of <span id="S5.SS5.SSS2.p1.1.1" class="ltx_text ltx_font_italic">4. Slightly safe</span> and <span id="S5.SS5.SSS2.p1.1.2" class="ltx_text ltx_font_italic">5. Very safe</span> has a chance level of 40% to be chosen.
Thus, a threshold for the evaluation ratio of the perception of safety was set to 40%.
Referring to Fig. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, there were high ratios where the participants felt danger when interacting with the AV for their gaze durations of over 8.0 [s].
In particular, if the gaze duration was more than 8 seconds, there were no cases that were evaluated as <span id="S5.SS5.SSS2.p1.1.3" class="ltx_text ltx_font_italic">4. Slightly safe</span> or <span id="S5.SS5.SSS2.p1.1.4" class="ltx_text ltx_font_italic">5. Very safe</span>.
In other words, the AV is more likely to enable the pedestrian to feel safe within the first 8.0 [s] while the pedestrian is gazing at it, e.g., sending related information to the pedestrian.</p>
</div>
</section>
</section>
<section id="S5.SS6" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Discussion</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">We found a trend through Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> that the increase in gaze durations on the AV was gradually greater than the gaze durations on the MV as the participants understood the driving intention of the vehicle less.
For example, there was no clear difference between the probability densities of the gaze durations on the AV and the MV when the participants chose <span id="S5.SS6.p1.1.1" class="ltx_text ltx_font_italic">5. Fully understood</span>, but the difference for <span id="S5.SS6.p1.1.2" class="ltx_text ltx_font_italic">1. Completely did not understand</span> was large, as shown in Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Referring to the results of the perception of safety in Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, it also had the same trend.
Those trends are also shown in Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Subjective evaluation results ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> as the differences between median values of gaze durations on the AV and the MV for each evaluation scale.
The reason for this trend is speculated that the participants sufficiently trust in both AV and MV when they understood the vehicle’s driving intentions and felt safe.
As their understanding of driving intentions becomes ambiguous and the perception of danger increases, their trust in the vehicle may decline, while they increase the observation time of the vehicle to gain more information to protect themselves from danger.
An important factor to be considerd here is the participants potentially trust in the driver.
We speculate that this is also one of the reasons that the participants’ gaze duration on the MV was shorter than that on the AV when they understood the vehicle’s driving intentions and felt safe.</p>
</div>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.3" class="ltx_p">Besides, in Figs. <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#S5.F9" title="Figure 9 ‣ 5.3 Gaze durations for each subjective evaluation scale ‣ 5 EXPERIMENT RESULTS ‣ What Timing for an Automated Vehicle to Make Pedestrians Understand Its Driving Intentions for Improving Their Perception of Safety?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we found that when the participants interacted with the MV, the earliest occurrences of <span id="S5.SS6.p2.3.1" class="ltx_text ltx_font_italic">4. Mostly understood</span> and <span id="S5.SS6.p2.3.2" class="ltx_text ltx_font_italic">5. Fully understood</span> were earlier than when they interacted with the AV.
When the participants only observed the MV <math id="S5.SS6.p2.1.m1.1" class="ltx_Math" alttext="0.0\sim 0.5" display="inline"><semantics id="S5.SS6.p2.1.m1.1a"><mrow id="S5.SS6.p2.1.m1.1.1" xref="S5.SS6.p2.1.m1.1.1.cmml"><mn id="S5.SS6.p2.1.m1.1.1.2" xref="S5.SS6.p2.1.m1.1.1.2.cmml">0.0</mn><mo id="S5.SS6.p2.1.m1.1.1.1" xref="S5.SS6.p2.1.m1.1.1.1.cmml">∼</mo><mn id="S5.SS6.p2.1.m1.1.1.3" xref="S5.SS6.p2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.1.m1.1b"><apply id="S5.SS6.p2.1.m1.1.1.cmml" xref="S5.SS6.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS6.p2.1.m1.1.1.1.cmml" xref="S5.SS6.p2.1.m1.1.1.1">similar-to</csymbol><cn type="float" id="S5.SS6.p2.1.m1.1.1.2.cmml" xref="S5.SS6.p2.1.m1.1.1.2">0.0</cn><cn type="float" id="S5.SS6.p2.1.m1.1.1.3.cmml" xref="S5.SS6.p2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.1.m1.1c">0.0\sim 0.5</annotation></semantics></math> [s] during the interaction, there were cases that the MV’s driving intention was evaluated as <span id="S5.SS6.p2.3.3" class="ltx_text ltx_font_italic">2. Did not understand much</span>.
The same difference occurred in <span id="S5.SS6.p2.3.4" class="ltx_text ltx_font_italic">1. Completely did not understand</span>, where the earliest occurrences were at <math id="S5.SS6.p2.2.m2.1" class="ltx_Math" alttext="2.0\sim 2.5" display="inline"><semantics id="S5.SS6.p2.2.m2.1a"><mrow id="S5.SS6.p2.2.m2.1.1" xref="S5.SS6.p2.2.m2.1.1.cmml"><mn id="S5.SS6.p2.2.m2.1.1.2" xref="S5.SS6.p2.2.m2.1.1.2.cmml">2.0</mn><mo id="S5.SS6.p2.2.m2.1.1.1" xref="S5.SS6.p2.2.m2.1.1.1.cmml">∼</mo><mn id="S5.SS6.p2.2.m2.1.1.3" xref="S5.SS6.p2.2.m2.1.1.3.cmml">2.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.2.m2.1b"><apply id="S5.SS6.p2.2.m2.1.1.cmml" xref="S5.SS6.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.SS6.p2.2.m2.1.1.1.cmml" xref="S5.SS6.p2.2.m2.1.1.1">similar-to</csymbol><cn type="float" id="S5.SS6.p2.2.m2.1.1.2.cmml" xref="S5.SS6.p2.2.m2.1.1.2">2.0</cn><cn type="float" id="S5.SS6.p2.2.m2.1.1.3.cmml" xref="S5.SS6.p2.2.m2.1.1.3">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.2.m2.1c">2.0\sim 2.5</annotation></semantics></math> [s] for the MV and <math id="S5.SS6.p2.3.m3.1" class="ltx_Math" alttext="3.5\sim 4.0" display="inline"><semantics id="S5.SS6.p2.3.m3.1a"><mrow id="S5.SS6.p2.3.m3.1.1" xref="S5.SS6.p2.3.m3.1.1.cmml"><mn id="S5.SS6.p2.3.m3.1.1.2" xref="S5.SS6.p2.3.m3.1.1.2.cmml">3.5</mn><mo id="S5.SS6.p2.3.m3.1.1.1" xref="S5.SS6.p2.3.m3.1.1.1.cmml">∼</mo><mn id="S5.SS6.p2.3.m3.1.1.3" xref="S5.SS6.p2.3.m3.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.3.m3.1b"><apply id="S5.SS6.p2.3.m3.1.1.cmml" xref="S5.SS6.p2.3.m3.1.1"><csymbol cd="latexml" id="S5.SS6.p2.3.m3.1.1.1.cmml" xref="S5.SS6.p2.3.m3.1.1.1">similar-to</csymbol><cn type="float" id="S5.SS6.p2.3.m3.1.1.2.cmml" xref="S5.SS6.p2.3.m3.1.1.2">3.5</cn><cn type="float" id="S5.SS6.p2.3.m3.1.1.3.cmml" xref="S5.SS6.p2.3.m3.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.3.m3.1c">3.5\sim 4.0</annotation></semantics></math> [s] for the AV.
Based on the above results, we consider that the participants trusted the MV more than the AV because they successfully performed the trials even with a brief observation of the MV or unclear understanding of driving intentions of the MV.</p>
</div>
<div id="S5.SS6.p3" class="ltx_para">
<p id="S5.SS6.p3.1" class="ltx_p">On the basis of the above discussions, we assume that the underlying cause of this may be related to the pedestrians having less trust in the AV than in the human driver of the MV.
This may be the key factor that makes it difficult for AVs to achieve popularity in society.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>CONCLUSION</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.2" class="ltx_p">We designed an experiment of pedestrian–vehicle interaction to find a time range that an AV should make a pedestrian understand its driving intentions and feel safe in an interaction.
Thirteen participants were invited to interact with the MV and the AV.
The participants’ gaze information and their subjective evaluation for the understanding of driving intentions as well as their perception of safety were collected.
By analyzing the participants’ gaze duration on the vehicle with their subjective evaluations, we found that
1) the AV is better to enable the pedestrian to understand its driving intentions accurately within <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="0.5\sim 6.5" display="inline"><semantics id="S6.p1.1.m1.1a"><mrow id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mn id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2.cmml">0.5</mn><mo id="S6.p1.1.m1.1.1.1" xref="S6.p1.1.m1.1.1.1.cmml">∼</mo><mn id="S6.p1.1.m1.1.1.3" xref="S6.p1.1.m1.1.1.3.cmml">6.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1.1">similar-to</csymbol><cn type="float" id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">0.5</cn><cn type="float" id="S6.p1.1.m1.1.1.3.cmml" xref="S6.p1.1.m1.1.1.3">6.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">0.5\sim 6.5</annotation></semantics></math> [s] while the pedestrian is gazing at it, and
2) the AV is better to enable the pedestrian to feel safe within <math id="S6.p1.2.m2.1" class="ltx_Math" alttext="0.5\sim 8.0" display="inline"><semantics id="S6.p1.2.m2.1a"><mrow id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml"><mn id="S6.p1.2.m2.1.1.2" xref="S6.p1.2.m2.1.1.2.cmml">0.5</mn><mo id="S6.p1.2.m2.1.1.1" xref="S6.p1.2.m2.1.1.1.cmml">∼</mo><mn id="S6.p1.2.m2.1.1.3" xref="S6.p1.2.m2.1.1.3.cmml">8.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><apply id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.p1.2.m2.1.1.1.cmml" xref="S6.p1.2.m2.1.1.1">similar-to</csymbol><cn type="float" id="S6.p1.2.m2.1.1.2.cmml" xref="S6.p1.2.m2.1.1.2">0.5</cn><cn type="float" id="S6.p1.2.m2.1.1.3.cmml" xref="S6.p1.2.m2.1.1.3">8.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">0.5\sim 8.0</annotation></semantics></math> [s] while the pedestrian is gazing at it.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">A limitation of this paper is that the experimental results of this study can be applied to personal mobility vehicles or mobile robots running at low speed, but it may be difficult to apply them to an automated car running at high speed.
The reason is that the gaze duration of participants may depend on the speed of the vehicle.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">In future, we will use the same experimental method to study the interaction between pedestrians and an automated car.
We will also focus on establishing an eHMI for AVs that can quickly, clearly, and kindly convey driving intention to pedestrians, thus improving the acceptability of AVs.
Additionally, the results of this study indicate that the gaze behavior of pedestrians on the AV may depends on the trust that the pedestrians have.
Besides, some related work has also focused on the feeling of user safety and trust in using AV systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
User trust has to be taken into account in our future study.</p>
</div>
</section>
<section id="Sx1" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">ACKNOWLEDGMENT</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by JST-Mirai Program Grant Number JPMJMI17C6, and JSPS KAKENHI Grant Numbers JP19K12080, Japan.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
D. Jennings and M. Figliozzi, “Study of sidewalk autonomous delivery robots
and their potential impacts on freight efficiency and travel,” <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Transportation Research Record</span>, vol. 2673, no. 6, pp. 317–326, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
K. Niechwiadowicz and Z. Khan, “Robot based logistics system for
hospitals-survey,” in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">IDT Workshop on interesting results in computer
science and engineering</span>, 2008.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
P. A. Hancock, I. Nourbakhsh, and J. Stewart, “On the future of transportation
in an era of automated and autonomous vehicles,” <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the
National Academy of Sciences</span>, vol. 116, no. 16, pp. 7684–7691, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. Pettigrew, C. Worrall, Z. Talati, L. Fritschi, and R. Norman, “Dimensions
of attitudes to autonomous vehicles,” <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Urban, Planning and Transport
Research</span>, vol. 7, no. 1, pp. 19–33, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. McAllister, Y. Gal, A. Kendall, M. Van Der Wilk, A. Shah, R. Cipolla, and
A. Weller, “Concrete problems for autonomous vehicle safety: Advantages of
bayesian deep learning,” International Joint Conferences on Artificial
Intelligence, Inc., 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Habibovic, V. M. Lundgren, J. Andersson, M. KlingegÃ¥rd,
T. LagstrÃ¶m, A. Sirkka, J. FagerlÃ¶nn, C. Edgren,
R. Fredriksson, S. Krupenia, D. SaluÃ¤Ã¤r, and P. Larsson,
“Communicating intent of automated vehicles to pedestrians,” <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Frontiers
in Psychology</span>, vol. 9, p. 1336, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Rasouli and J. K. Tsotsos, “Autonomous vehicles that interact with
pedestrians: A survey of theory and practice,” <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on
Intelligent Transportation Systems</span>, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Stefanie and M. Baumann, “Yielding light signal evaluation for self-driving
vehicle and pedestrian interaction,” in <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Human Systems Engineering and
Design II</span> (T. Ahram, W. Karwowski, S. Pickl, and R. Taiar, eds.), (Cham),
pp. 189–194, Springer International Publishing, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
K. de Clercq, A. Dietrich, J. P. N. Velasco, J. de Winter, and R. Happee,
“External human-machine interfaces on automated vehicles: Effects on
pedestrian crossing decisions,” <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Human Factors</span>, vol. 61, no. 8,
pp. 1353–1370, 2019.

</span>
<span class="ltx_bibblock">PMID: 30912985.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
D. Dey, F. Walker, M. Martens, and J. Terken, “Gaze patterns in pedestrian
interaction with vehicles: towards effective design of external human-machine
interfaces for automated vehicles,” in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the 11th
International Conference on Automotive User Interfaces and Interactive
Vehicular Applications</span>, pp. 369–378, ACM, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Liu, T. Hirayama, L. Y. Morales, and H. Murase, “What is the gaze behavior
of pedestrians in interactions with an automated vehicle when they do not
understand its intentions?,” <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2001.01340</span>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. R. Endsley, “Toward a theory of situation awareness in dynamic systems,”
in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Situational Awareness</span>, pp. 9–42, Routledge, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
G. J. Wilde, “The theory of risk homeostasis: implications for safety and
health,” <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Risk analysis</span>, vol. 2, no. 4, pp. 209–225, 1982.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
H. Liu and T. Hiraoka, “Driving behavior model considering driver’s over-trust
in driving automation system,” in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the 11th International
Conference on Automotive User Interfaces and Interactive Vehicular
Applications: Adjunct Proceedings</span>, pp. 115–119, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. Holländer, P. Wintersberger, and A. Butz, “Overtrust in external cues
of automated vehicles: An experimental investigation,” in <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proceedings
of the 11th International Conference on Automotive User Interfaces and
Interactive Vehicular Applications</span>, pp. 211–221, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2003.00688" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2003.00689" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2003.00689">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2003.00689" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2003.00690" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 13:28:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
