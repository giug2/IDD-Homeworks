<article class="ltx_document ltx_pruned_first">
 <h1 class="ltx_title ltx_title_document">
  Why Solving Multi-agent Path Finding
  <br class="ltx_break"/>
  with Large Language Models has not Succeeded Yet
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Weizhe Chen
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Sven Koenig
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Bistra Dilkina
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id1.id1">
   With the explosive influence caused by the success of large language models (LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work showing that foundation models can be used to solve a large variety of tasks. However, there is very limited work that shares insights on multi-agent planning. Multi-agent planning is different from other domains by combining the difficulty of multi-agent coordination and planning, and making it hard to leverage external tools to facilitate the reasoning needed. In this paper, we focus on the problem of multi-agent path finding (MAPF), which is also known as multi-robot route planning, and study the performance of solving MAPF with LLMs. We first show the motivating success on an empty room map without obstacles, then the failure to plan on the harder room map and maze map of the standard MAPF benchmark. We present our position on why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis. Based on our results, we discussed how researchers with different backgrounds could help with this problem from different perspectives.
  </p>
 </div>
 <div class="ltx_keywords">
  Machine Learning, ICML
 </div>
 <div class="ltx_para" id="p2">
  <br class="ltx_break"/>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    In the past year since ChatGPT came out, large language models (LLMs) have been shown to go beyond strictly language-related tasks like translation, and to be a powerful tool in all kinds of domains. Training with very rich and diverse datasets, LLMs incorporate a large variety of knowledge and do not require fine-tuning before generating good solutions in many real-world applications. Over time, recent studies have shown that combining LLMs with different ways of prompting can help solve problems that have some aspects of reasoning, including examples from logical problems
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib38" title="">
      2022
     </a>
     ; Liu et al.,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2023b
     </a>
     )
    </cite>
    to controlling a robot dog without finetuning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al.,
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023a
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Motivated by the success of LLMs, some recent works studied the performance of LLMs on multi-agent problems and showed LLM can also help multi-agent coordination
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chen et al.,
     <a class="ltx_ref" href="#bib.bib3" title="">
      2023b
     </a>
     ; Agashe et al.,
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    . However, they barely cover multi-agent planning. In this paper, we consider the problem of multi-agent path finding (MAPF), also known as multi-agent route planning. MAPF is the problem of moving a group of agents from their respective start locations to their goal locations without collisions. MAPF can be used directly to formulate real-world applications like warehouse management
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sharon et al.,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2015
     </a>
     ; Han &amp; Yu,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2020
     </a>
     )
    </cite>
    , swarm control
    <cite class="ltx_cite ltx_citemacro_citep">
     (Li et al.,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2020
     </a>
     )
    </cite>
    , among others. In a typical warehouse scenario, around a thousand warehouse robots (agents) could be running simultaneously in one warehouse room (scenario), and each agent needs to plan its path, which could be as long as a hundred timesteps. Previous methods for MAPF can be classified into 1) classic methods like heuristic search and SAT
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sharon et al.,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2015
     </a>
     ; Han &amp; Yu,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2020
     </a>
     )
    </cite>
    , and 2) learning-based approaches that mostly use reinforcement learning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sartoretti et al.,
     <a class="ltx_ref" href="#bib.bib22" title="">
      2019
     </a>
     )
    </cite>
    . MAPF is a unique problem in multi-agent coordination in that coordination is required within the planning, so it is highly challenging to facilitate the reasoning of coordination by using LLMs to generate useful high-level guidance combined with a low-level path planner to ensure the solution is valid, an approach that will be parallel to this taken in the setting of overcooked
    <cite class="ltx_cite ltx_citemacro_citep">
     (Agashe et al.,
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    . On the other hand, path planning is one of the easiest parts of planning, and constraints only concern obstacles and moving continuity. Because of these unique challenges in the MAPF problem, it is unclear how good LLMs will be at solving MAPF.
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="173" id="S1.F1.g1" src="/html/2401.03630/assets/figs/llm_workflow.png" width="538"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">
      Figure 1
     </span>
     :
    </span>
    <span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">
     An illustration of our workflow.
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In this paper, we propose to use an LLM directly to solve MAPF without any additional heuristic guidance from solvers or any additional training. We give the scenario information to the LLM, and let the LLM recommend the actions for each agent every single timestep. We use a high-level checker that checks collisions between agents and obstacles to ensure the solution is valid in each step and provide error message to the LLM when violations occur, and iterate with the LLM until a valid solution is generated. We evaluate the performance of LLMs on the empty map, the room map, and the maze map, which are classic maps from the standard MAPF benchmark
    <cite class="ltx_cite ltx_citemacro_citep">
     (Stern et al.,
     <a class="ltx_ref" href="#bib.bib28" title="">
      2019
     </a>
     )
    </cite>
    . We show that LLMs can solve MAPF problems when the scenario is relatively easy and LLMs fail to generate any valid solution, no matter what the solution quality is when the scenario becomes harder. While LLMs are evolving extremely fast, and current failures may not apply to the next generation of LLMs, we elaborate on the current failing scenarios and give our position on three aspects as a breakdown of what kind of capability is currently missing in the LLM workflow, namely 1) the capability to understand the scenario, 2) the context length limit, and 3) the reasoning capability. We incorporate a list of experiments featuring various prominent prompt design alternatives, such as image-based and text-only inputs, and with or without single-step observation information, among others. Finally, we provide a discussion on the challenges of using LLMs for MAPF in the real world, and discuss how different researchers could contribute to the problem from different directions. We hope our work can serve as a building block for future research in foundation models for MAPF.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   LLMs for Multi-agent Path Finding
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Preliminary
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     The multi-agent path finding (MAPF) problem is the problem of finding a set of conflict-free paths for a set of agents in a known environment while minimizing their travel times. Specifically, in this paper, we consider the same problem as
     <cite class="ltx_cite ltx_citemacro_citep">
      (Stern et al.,
      <a class="ltx_ref" href="#bib.bib28" title="">
       2019
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2022
      </a>
      )
     </cite>
     , which is a four-connected grid map, where each agent is given a start cell and a goal cell. A scenario is defined as the combination of the description of the map, which is the size of the map, indication of which cells have obstacles, and the start cells and goal cells of each agent. At each timestep, an agent can move to an adjacent cell or stay in its current cell. A conflict happens if two agents end up in the same cell at the same timestep. Each agent remains at its goal cell after it arrives until all agents arrive at their goals. The objective is to minimize the makespan of the solution, i.e., minimize the time when the last agent arrives at its goal location.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     Large language models (LLMs) like ChatGPT, Claude, and Gemini have at least tens of billions of parameters and are trained with extremely large amounts of data collected on the internet. With the number of parameters exponentially larger than the degree of freedom in small problems, LLMs have the potential to solve some easy problems in reasoning with certain prompts
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2022
      </a>
      )
     </cite>
     , and break down harder problems into smaller ones to get suboptimal solutions
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yang et al.,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      )
     </cite>
     . When applying to MAPF, we hope LLMs can be an alternative model to the current MAPF reinforcement learning-based models without the need for any training. Unlike previous work with LLMs that solves the path-planning problem at the low level with existing heuristic solvers
     <cite class="ltx_cite ltx_citemacro_citep">
      (Agashe et al.,
      <a class="ltx_ref" href="#bib.bib1" title="">
       2023
      </a>
      )
     </cite>
     , MAPF is unique because it is extremely hard to decouple the high-level coordination from the path-planning process. The coordination needed is the deconflict that happens in each step and each step only, which forbids the use of a single-agent planner that cannot take coordination into account. And without the decoupling, we cannot leverage a path planner like previous work has done to reduce the difficulty in the reasoning.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Methods
   </h3>
   <figure class="ltx_figure" id="S2.F2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="S2.F2.2" style="border-color: #000000;">
     <span class="ltx_p" id="S2.F2.2.1">
      <span class="ltx_text" id="S2.F2.2.1.1" style="font-size:90%;color:#0000FF;">
       Agent 1 is currently in (0,2), and wants to go to (3,1).
       <span class="ltx_text" id="S2.F2.2.1.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.2">
      <span class="ltx_text" id="S2.F2.2.2.1" style="font-size:90%;color:#0000FF;">
       Agent 2 is currently in (1,3), and wants to go to (2,0).
       <span class="ltx_text" id="S2.F2.2.2.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.3">
      <span class="ltx_text" id="S2.F2.2.3.1" style="font-size:90%;">
       The map is as follows, where ’@’ denotes a cell with an obstacle that an agent cannot pass, and ’.’ denotes an empty cell that an agent can pass.
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.4">
      <span class="ltx_text" id="S2.F2.2.4.1" style="font-size:90%;color:#FF8000;">
       The bottom-left cell is (0,0) and the bottom-right cell is (31,0):
       <span class="ltx_text" id="S2.F2.2.4.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.5">
      <span class="ltx_text" id="S2.F2.2.5.1" style="font-size:90%;color:#FF8000;">
       ….
       <span class="ltx_text" id="S2.F2.2.5.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.6">
      <span class="ltx_text" id="S2.F2.2.6.1" style="font-size:90%;color:#FF8000;">
       …@
       <span class="ltx_text" id="S2.F2.2.6.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.7">
      <span class="ltx_text" id="S2.F2.2.7.1" style="font-size:90%;color:#FF8000;">
       ….
       <span class="ltx_text" id="S2.F2.2.7.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.8">
      <span class="ltx_text" id="S2.F2.2.8.1" style="font-size:90%;color:#FF8000;">
       .@..
       <span class="ltx_text" id="S2.F2.2.8.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.9">
      <span class="ltx_text" id="S2.F2.2.9.1" style="font-size:90%;color:#FF0000;">
       In the next step:
       <span class="ltx_text" id="S2.F2.2.9.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.10">
      <span class="ltx_text" id="S2.F2.2.10.1" style="font-size:90%;color:#BF0040;">
       Agent 1 can move [’stay at (0, 2)’, ’right to (1, 2)’, ’up to (0, 3)’, ’down to (0, 1)’].
       <span class="ltx_text" id="S2.F2.2.10.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F2.2.11">
      <span class="ltx_text" id="S2.F2.2.11.1" style="font-size:90%;color:#BF0040;">
       Agent 2 can move [’stay at (1, 3)’, ’left to (0, 3)’, ’right to (2, 3)’, ’down to (1, 2)’].
       <span class="ltx_text" id="S2.F2.2.11.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
    </span>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S2.F2.3.1.1" style="font-size:90%;">
       Figure 2
      </span>
      :
     </span>
     <span class="ltx_text" id="S2.F2.4.2" style="font-size:90%;">
      An example of the user prompt for describing the scenario. Text in blue is a scenario-specific prompt, while text in orange is a map-specific prompt. In the experiments on the empty map, only the first blue paragraph will be provided, and all text starting from the black paragraph is removed because there are no obstacles. The text in purple is the single-step observation (SSO) information.
     </span>
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S2.F3">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="S2.F3.2" style="border-color: #000000;">
     <span class="ltx_p" id="S2.F3.2.1">
      <span class="ltx_text" id="S2.F3.2.1.1" style="font-size:90%;">
       [[Success]]
      </span>
     </span>
     <span class="ltx_p" id="S2.F3.2.2">
      <span class="ltx_text" id="S2.F3.2.2.1" style="font-size:90%;color:#0000FF;">
       Good job. Keep moving. In the next step:
       <span class="ltx_text" id="S2.F3.2.2.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F3.2.3">
      <span class="ltx_text" id="S2.F3.2.3.1" style="font-size:90%;color:#0000FF;">
       Agent 1 can move [’stay at (0, 2)’, ’right to (1, 2)’, ’up to (0, 3)’, ’down to (0, 1)’].
       <span class="ltx_text" id="S2.F3.2.3.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F3.2.4">
      <span class="ltx_text" id="S2.F3.2.4.1" style="font-size:90%;color:#0000FF;">
       Agent 2 can move [’stay at (1, 3)’, ’left to (0, 3)’, ’right to (2, 3)’, ’down to (1, 2)’].
       <span class="ltx_text" id="S2.F3.2.4.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F3.2.5">
      <span class="ltx_text" id="S2.F3.2.5.1" style="font-size:90%;">
       [[Failure]]
      </span>
     </span>
     <span class="ltx_p" id="S2.F3.2.6">
      <span class="ltx_text" id="S2.F3.2.6.1" style="font-size:90%;color:#FF0000;">
       You are wrong. Agent (1,2), (4,5) are colliding with each other. Please correct the current step.
       <span class="ltx_text" id="S2.F3.2.6.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
     <span class="ltx_p" id="S2.F3.2.7">
      <span class="ltx_text" id="S2.F3.2.7.1" style="font-size:90%;color:#FF8000;">
       You are wrong. Agent 2,4 is colliding with obstacles. Please correct the current step.
       <span class="ltx_text" id="S2.F3.2.7.1.1" style="color:#000000;">
       </span>
      </span>
     </span>
    </span>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S2.F3.3.1.1" style="font-size:90%;">
       Figure 3
      </span>
      :
     </span>
     <span class="ltx_text" id="S2.F3.4.2" style="font-size:90%;">
      An example of the user prompt starting from the second step. While here we demonstrate a few options, only one of them, i.e., text in one color, will be provided to the LLM in one iteration.
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     In this paper, we focus on using LLMs to solve the MAPF problem directly.
However, it is quite obvious that current ML models cannot be perfect solvers in their first trial, and we introduce a high-level conflict checker to ensure the plan generated by the LLM is valid. We inform the LLM about the mistake in the solution, if any. Unlike some previous works
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2022
      </a>
      ; Yang et al.,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      )
     </cite>
     , our checker is not another LLM both because it is extremely easy and efficient to detect collisions by a rule-based detector in linear time, and also because the LLM fails to always correctly identify the collisions. In this checker, we not only check for agent-to-agent collisions but also correct the LLM for any collision with the fixed obstacles. We do not provide any additional guidance on how the LLM should deconflict the solution but just describe the conflicts.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     Following the common practice of LLMs, we build our workflow shown in Fig.
     <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . As existing learning-based approaches
     <cite class="ltx_cite ltx_citemacro_citep">
      (Damani et al.,
      <a class="ltx_ref" href="#bib.bib4" title="">
       2021
      </a>
      )
     </cite>
     , we give LLMs stepwise local information and let the LLM choose the actions of agents step-by-step. This step-by-step (SBS) generation is different from the popular chain-of-thoughts idea
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2022
      </a>
      )
     </cite>
     used in LLMs by not introducing more intermediate reasoning processes in the generation. Instead, it breaks down the whole planning task into smaller single-step tasks, so the LLM does not need to be fully correct before we can use some results from it. We start by giving the LLM the system prompt of becoming a solver for the MAPF problem. This part is fixed within each map, and different in the map description part in different maps. Then, we start the user prompt by providing the scenario information, which includes where the obstacles are, as well as the start location and the goal locations of each agent. We found that providing LLMs with specific local information about viable actions for the immediate next step significantly helps them avoid collisions with static obstacles, so we provide a single-step observation (SSO) in the prompt by default. See Figure
     <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2.2 Methods ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     for an example of the scenario description prompt. Then we start to read the output of the LLM, use the checker to determine whether the output of the LLM is valid, and either output the errors to let the LLM correct on the current step, or tell the LLM to move on to the next step with the information that is specifically for the next step. See Figure
     <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.2 Methods ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     for an example of the iteration-wise user prompts. To address the total token limit, we leverage the fact that MAPF is a Markov decision process where each state is independent of its previous states, and we restart the prompt from scratch, i.e., treat the current agent locations as their starting point, whenever we got a rate limit error.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Experiment Results on MAPF Benchmark
   </h3>
   <figure class="ltx_figure" id="S2.F4">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S2.F4.1">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="449" id="S2.F4.1.g1" src="/html/2401.03630/assets/figs/flip_room.png" width="449"/>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F4.2">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="449" id="S2.F4.2.g1" src="/html/2401.03630/assets/figs/maze-32-32-2.png" width="449"/>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S2.F4.6.1.1" style="font-size:90%;">
       Figure 4
      </span>
      :
     </span>
     <span class="ltx_text" id="S2.F4.7.2" style="font-size:90%;">
      The
      <span class="ltx_text ltx_font_smallcaps" id="S2.F4.7.2.1">
       room
      </span>
      -32-32-4 map (left) and the
      <span class="ltx_text ltx_font_smallcaps" id="S2.F4.7.2.2">
       maze
      </span>
      -32-32-2 map (right). The picture is vertically flipped to match the common knowledge that higher positions on the vertical axis indicate greater values.
     </span>
    </figcaption>
   </figure>
   <section class="ltx_subsubsection" id="S2.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.3.1
     </span>
     General Experiment Settings
    </h4>
    <div class="ltx_para" id="S2.SS3.SSS1.p1">
     <p class="ltx_p" id="S2.SS3.SSS1.p1.1">
      While we have introduced the high-level conflict detector, we define a solution generation to be successful if it does not fail because of any of the following:
     </p>
     <ol class="ltx_enumerate" id="S2.I1">
      <li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        1.
       </span>
       <div class="ltx_para" id="S2.I1.i1.p1">
        <p class="ltx_p" id="S2.I1.i1.p1.1">
         Fails to generate a plan whose number of steps is at most 3 times longer than the optimal plan.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        2.
       </span>
       <div class="ltx_para" id="S2.I1.i2.p1">
        <p class="ltx_p" id="S2.I1.i2.p1.1">
         Fails 5 consecutive times in a single step after we provided the first round of feedback, specifying whether the current solution is correct or not.
        </p>
       </div>
      </li>
     </ol>
    </div>
    <div class="ltx_para" id="S2.SS3.SSS1.p2">
     <p class="ltx_p" id="S2.SS3.SSS1.p2.1">
      Note that we do not consider any token limit error because allowing no more than 5 times in a single step guarantees that the message length in one step is within the token limit, and we already consider restarting at each step if the token limit is too long in our method.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS3.SSS1.p3">
     <p class="ltx_p" id="S2.SS3.SSS1.p3.1">
      By default, we are using the GPT-4-1106-preview model, also known as the GPT-4-turbo model, which is the state-of-the-art LLM that is publicly available. We set the temperature as
      <math alttext="1.0" class="ltx_Math" display="inline" id="S2.SS3.SSS1.p3.1.m1.1">
       <semantics id="S2.SS3.SSS1.p3.1.m1.1a">
        <mn id="S2.SS3.SSS1.p3.1.m1.1.1" xref="S2.SS3.SSS1.p3.1.m1.1.1.cmml">
         1.0
        </mn>
        <annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p3.1.m1.1b">
         <cn id="S2.SS3.SSS1.p3.1.m1.1.1.cmml" type="float" xref="S2.SS3.SSS1.p3.1.m1.1.1">
          1.0
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS3.SSS1.p3.1.m1.1c">
         1.0
        </annotation>
       </semantics>
      </math>
      and the seed as 42
      <span class="ltx_note ltx_role_footnote" id="footnote1">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          1
         </sup>
         <span class="ltx_tag ltx_tag_note">
          1
         </span>
         Note that we are testing using the API, where the behavior could be slightly different from the web version of GPT-4.
        </span>
       </span>
      </span>
      . We show an example of our user prompt in Fig.
      <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2.2 Methods ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      and Fig.
      <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.2 Methods ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      , and an example of the complete system prompt in the appendix. We will describe how each variant will change from this default prompt.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS3.SSS1.p4">
     <p class="ltx_p" id="S2.SS3.SSS1.p4.1">
      Each setting in the experiment is tested on 5 different scenarios in the standard MAPF benchmark, each different in terms of the start and goal location combinations of the agents on a given map.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.3.2
     </span>
     Results
    </h4>
    <div class="ltx_para" id="S2.SS3.SSS2.p1">
     <p class="ltx_p" id="S2.SS3.SSS2.p1.1">
      While it is unclear how well LLMs can solve MAPF problems, we start by showing that LLMs can be a promising solver in easy domains. We test the performance of LLMs on the
      <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.SSS2.p1.1.1">
       empty
      </span>
      map from the MAPF benchmark
      <cite class="ltx_cite ltx_citemacro_citep">
       (Stern et al.,
       <a class="ltx_ref" href="#bib.bib28" title="">
        2019
       </a>
       )
      </cite>
      , which has no obstacles at all and only requires the agents to not collide with each other. The results are shown in Table.
      <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.3.2 Results ‣ 2.3 Experiment Results on MAPF Benchmark ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      . We observe that for smaller-scale problems that has fewer agents, GPT-4 can successfully generate valid solutions. However, GPT-4 fails to generate valid solutions when there are more agents on the same map.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS3.SSS2.p2">
     <p class="ltx_p" id="S2.SS3.SSS2.p2.1">
      It has been shown that a step-by-step generation is better in many reasoning-related tasks, since it can guide the generated plan to create the chain of thoughts as a human rather than guessing a solution and then checking whether they are correct
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wei et al.,
       <a class="ltx_ref" href="#bib.bib36" title="">
        2022
       </a>
       )
      </cite>
      . However, it is not well-studied whether a step-by-step generation is also helpful in the planning since a complete plan will also require to be given in a step-by-step (SBS) way, and the LLM models need to decide every single step anyway. Therefore, we study a variant that generates the whole plan in one shot (OS) with the help of chain-of-thought prompts and show the comparison in Table.
      <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.3.2 Results ‣ 2.3 Experiment Results on MAPF Benchmark ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      . We observe that one-shot (OS) generation fails to generate solutions even in scenarios with 4 agents. This is because the whole plan is quite long, and the total number of possible failures is the product of possible failure at each step, making it inefficient to find a valid solution.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS3.SSS2.p3">
     <p class="ltx_p" id="S2.SS3.SSS2.p3.1">
      Motivated by the success on the
      <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.SSS2.p3.1.1">
       empty
      </span>
      map, we tested the same workflow on the
      <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.SSS2.p3.1.2">
       room
      </span>
      -32-32-1 map and the
      <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.SSS2.p3.1.3">
       maze
      </span>
      -32-32-2 map, which is shown in Fig.
      <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.3 Experiment Results on MAPF Benchmark ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      . The results are shown in Table.
      <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.3.2 Results ‣ 2.3 Experiment Results on MAPF Benchmark ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      . In this case, we found that LLMs fail to generate solutions when the number of agents is already quite small, and that LLMs completely fail on the
      <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.SSS2.p3.1.4">
       maze
      </span>
      -32-32- map even with only 2 agents.
     </p>
    </div>
    <figure class="ltx_table" id="S2.T1">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.2">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S2.T1.2.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.2.1.1.1" rowspan="2">
         <span class="ltx_text" id="S2.T1.2.1.1.1.1" style="font-size:90%;">
          Map
         </span>
        </th>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.1.1.2" rowspan="2">
         <span class="ltx_text" id="S2.T1.2.1.1.2.1" style="font-size:90%;">
          n
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" colspan="2" id="S2.T1.2.1.1.3">
         <span class="ltx_text" id="S2.T1.2.1.1.3.1" style="font-size:90%;">
          Success Rate (%)
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.2.2">
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.2.2.1">
         <span class="ltx_text" id="S2.T1.2.2.2.1.1" style="font-size:90%;">
          OS
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.2.2.2">
         <span class="ltx_text" id="S2.T1.2.2.2.2.1" style="font-size:90%;">
          SBS
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.3.3">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S2.T1.2.3.3.1">
        </th>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.3.3.2">
         <span class="ltx_text" id="S2.T1.2.3.3.2.1" style="font-size:90%;">
          2
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.3.3.3">
         <span class="ltx_text" id="S2.T1.2.3.3.3.1" style="font-size:90%;">
          10
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.3.3.4">
         <span class="ltx_text" id="S2.T1.2.3.3.4.1" style="font-size:90%;">
          100
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.4.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.2.4.4.1">
         <span class="ltx_text" id="S2.T1.2.4.4.1.1" style="font-size:90%;">
          Empty
         </span>
        </th>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.4.4.2">
         <span class="ltx_text" id="S2.T1.2.4.4.2.1" style="font-size:90%;">
          4
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.4.4.3">
         <span class="ltx_text" id="S2.T1.2.4.4.3.1" style="font-size:90%;">
          0
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.4.4.4">
         <span class="ltx_text" id="S2.T1.2.4.4.4.1" style="font-size:90%;">
          100
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.5.5">
        <th class="ltx_td ltx_th ltx_th_row" id="S2.T1.2.5.5.1">
        </th>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.5.5.2">
         <span class="ltx_text" id="S2.T1.2.5.5.2.1" style="font-size:90%;">
          8
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.5.5.3">
         <span class="ltx_text" id="S2.T1.2.5.5.3.1" style="font-size:90%;">
          0
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.5.5.4">
         <span class="ltx_text" id="S2.T1.2.5.5.4.1" style="font-size:90%;">
          100
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.6.6">
        <th class="ltx_td ltx_th ltx_th_row" id="S2.T1.2.6.6.1">
        </th>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.6.6.2">
         <span class="ltx_text" id="S2.T1.2.6.6.2.1" style="font-size:90%;">
          16
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.6.6.3">
         <span class="ltx_text" id="S2.T1.2.6.6.3.1" style="font-size:90%;">
          0
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.6.6.4">
         <span class="ltx_text" id="S2.T1.2.6.6.4.1" style="font-size:90%;">
          60
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.7.7">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S2.T1.2.7.7.1">
        </th>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.7.7.2">
         <span class="ltx_text" id="S2.T1.2.7.7.2.1" style="font-size:90%;">
          2
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.7.7.3">
         <span class="ltx_text" id="S2.T1.2.7.7.3.1" style="font-size:90%;">
          10
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.7.7.4">
         <span class="ltx_text" id="S2.T1.2.7.7.4.1" style="font-size:90%;">
          100
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.8.8">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.2.8.8.1">
         <span class="ltx_text" id="S2.T1.2.8.8.1.1" style="font-size:90%;">
          Room
         </span>
        </th>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.8.8.2">
         <span class="ltx_text" id="S2.T1.2.8.8.2.1" style="font-size:90%;">
          4
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.8.8.3">
         <span class="ltx_text" id="S2.T1.2.8.8.3.1" style="font-size:90%;">
          0
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.8.8.4">
         <span class="ltx_text" id="S2.T1.2.8.8.4.1" style="font-size:90%;">
          80
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.9.9">
        <th class="ltx_td ltx_th ltx_th_row" id="S2.T1.2.9.9.1">
        </th>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.9.9.2">
         <span class="ltx_text" id="S2.T1.2.9.9.2.1" style="font-size:90%;">
          8
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.9.9.3">
         <span class="ltx_text" id="S2.T1.2.9.9.3.1" style="font-size:90%;">
          0
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S2.T1.2.9.9.4">
         <span class="ltx_text" id="S2.T1.2.9.9.4.1" style="font-size:90%;">
          20
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S2.T1.2.10.10">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S2.T1.2.10.10.1">
         <span class="ltx_text" id="S2.T1.2.10.10.1.1" style="font-size:90%;">
          Maze
         </span>
        </th>
        <td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S2.T1.2.10.10.2">
         <span class="ltx_text" id="S2.T1.2.10.10.2.1" style="font-size:90%;">
          2
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S2.T1.2.10.10.3">
         <span class="ltx_text" id="S2.T1.2.10.10.3.1" style="font-size:90%;">
          0
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S2.T1.2.10.10.4">
         <span class="ltx_text" id="S2.T1.2.10.10.4.1" style="font-size:90%;">
          0
         </span>
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 1:
      </span>
      The success rate of solving MAPF with LLM on
      <span class="ltx_text ltx_font_smallcaps" id="S2.T1.11.1">
       empty
      </span>
      -8-8,
      <span class="ltx_text ltx_font_smallcaps" id="S2.T1.12.2">
       room
      </span>
      -32-32-4 and
      <span class="ltx_text ltx_font_smallcaps" id="S2.T1.13.3">
       maze
      </span>
      maps with varying numbers of agents (n).
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Cause of Failures
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    Because LLMs are evolving rapidly, it is unclear how long LLMs will still fail. Although our methods do not combine any external tools like low-level planning or external memory
    <cite class="ltx_cite ltx_citemacro_citep">
     (Agashe et al.,
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    , which could make LLMs much stronger, it is important for us to break down the failures and identify the cause of the failures so we can strategically choose the correct tools to overcome them in the future. We found that the cause of failing in MAPF is different from the cause of failing in general planning tasks where the generated plan is invalid, usually by breaking requisite constraints
    <cite class="ltx_cite ltx_citemacro_citep">
     (Valmeekam et al.,
     <a class="ltx_ref" href="#bib.bib33" title="">
      2023
     </a>
     )
    </cite>
    . In path planning, the only constraint is that one agent needs to move to an adjacent cell and cannot jump across the map. This is a very easy task for LLM to follow and thus, in our experiments, we never see the LLM failing due to that constraint, even if the only instruction about this constraint is ”in a 4-connected grid”. We observe that LLMs fail only once with 16 agents in the empty map because of consecutive failures in a single step, and all other times they fail because they use many more steps than they should. More specifically, we discovered that 77% of the failures occurred because the LLM agents began to oscillate in a specific area of the map, while the remaining failures were due to excessively long detours.
   </p>
  </div>
  <div class="ltx_para" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    Based on our observations, we break down the reasons into three deeper parts from the perspective of natural language models: limitation from the model, understanding, and reasoning. For simplicity, we first discuss the lack of reasoning capability, which is common in many tasks.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Reasoning Capability
   </h3>
   <figure class="ltx_figure" id="S3.F5">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S3.F5.sf1">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="433" id="S3.F5.sf1.g1" src="/html/2401.03630/assets/figs/sym_breaking_1.png" width="509"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S3.F5.sf1.2.1.1" style="font-size:90%;">
          (a)
         </span>
        </span>
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F5.sf2">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="433" id="S3.F5.sf2.g1" src="/html/2401.03630/assets/figs/sym_breaking_2.png" width="509"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S3.F5.sf2.2.1.1" style="font-size:90%;">
          (b)
         </span>
        </span>
       </figcaption>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F5.2.1.1" style="font-size:90%;">
       Figure 5
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F5.3.2" style="font-size:90%;">
      Two examples of symmetry breaking examples, originally from
      <cite class="ltx_cite ltx_citemacro_citet">
       Li et al. (
       <a class="ltx_ref" href="#bib.bib13" title="">
        2019
       </a>
       )
      </cite>
      . In
      <a class="ltx_ref" href="#S3.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        5(a)
       </span>
      </a>
      , every pair of shortest path will collide with each other. In
      <a class="ltx_ref" href="#S3.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        5(b)
       </span>
      </a>
      , every pair of shortest path will collide with each other in a fixed cell (1,2).
     </span>
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F6">
    <span class="ltx_inline-block ltx_align_center ltx_framed ltx_framed_rectangle" id="S3.F6.2" style="border-color: #000000;">
     <span class="ltx_p" id="S3.F6.2.1">
      <span class="ltx_text" id="S3.F6.2.1.1" style="font-size:90%;">
       Step 1:
       <br class="ltx_break"/>
       Agent 1:
       <br class="ltx_break"/>
       Current: (0,2)
       <br class="ltx_break"/>
       Goal: (3,1)
       <br class="ltx_break"/>
       Move: Right to (1,2)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       Agent 2:
       <br class="ltx_break"/>
       Current: (1,3)
       <br class="ltx_break"/>
       Goal: (2,0)
       <br class="ltx_break"/>
       Move: Down to (1,2)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       After the move, the coordinates of the agents are:
       <br class="ltx_break"/>
       Agent 1: (1,2)
       <br class="ltx_break"/>
       Agent 2: (1,2)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       There is a collision between Agent 1 and Agent 2. I will regenerate another solution immediately.
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       Step 1 (Regenerated):
       <br class="ltx_break"/>
       Agent 1:
       <br class="ltx_break"/>
       Current: (0,2)
       <br class="ltx_break"/>
       Goal: (3,1)
       <br class="ltx_break"/>
       Move: Down to (0,1)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       Agent 2:
       <br class="ltx_break"/>
       Current: (1,3)
       <br class="ltx_break"/>
       Goal: (2,0)
       <br class="ltx_break"/>
       Move: Left to (0,3)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       After the move, the coordinates of the agents are:
       <br class="ltx_break"/>
       Agent 1: (0,1)
       <br class="ltx_break"/>
       Agent 2: (0,3)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       There is no collision. Here is the validated solution:
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       Agent 1: (0,1)
       <br class="ltx_break"/>
       Agent 2: (0,3)
      </span>
     </span>
    </span>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F6.3.1.1" style="font-size:90%;">
       Figure 6
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F6.4.2" style="font-size:90%;">
      The output from GPT-4-turbo for the symmetry breaking example in Fig.
      <a class="ltx_ref" href="#S3.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
       <span class="ltx_text ltx_ref_tag">
        5(b)
       </span>
      </a>
      .
     </span>
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S3.T2">
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.2">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S3.T2.2.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.1.1.1" rowspan="2">
        <span class="ltx_text" id="S3.T2.2.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.1.1.2" rowspan="2">
        <span class="ltx_text" id="S3.T2.2.1.1.2.1" style="font-size:90%;">
         n
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T2.2.1.1.3">
        <span class="ltx_text" id="S3.T2.2.1.1.3.1" style="font-size:90%;">
         Success Rate
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T2.2.1.1.4">
        <span class="ltx_text" id="S3.T2.2.1.1.4.1" style="font-size:90%;">
         Avg. Iterations
        </span>
       </th>
      </tr>
      <tr class="ltx_tr" id="S3.T2.2.2.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.2.2.1">
        <span class="ltx_text" id="S3.T2.2.2.2.1.1" style="font-size:90%;">
         GO
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.2.2.2">
        <span class="ltx_text" id="S3.T2.2.2.2.2.1" style="font-size:90%;">
         GO+SSO
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.2.2.3">
        <span class="ltx_text" id="S3.T2.2.2.2.3.1" style="font-size:90%;">
         GO
        </span>
       </th>
       <th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.2.2.4">
        <span class="ltx_text" id="S3.T2.2.2.2.4.1" style="font-size:90%;">
         GO+SSO
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S3.T2.2.3.1">
       <td class="ltx_td ltx_border_t" id="S3.T2.2.3.1.1">
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.3.1.2">
        <span class="ltx_text" id="S3.T2.2.3.1.2.1" style="font-size:90%;">
         2
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.3.1.3">
        <span class="ltx_text" id="S3.T2.2.3.1.3.1" style="font-size:90%;">
         80
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.3.1.4">
        <span class="ltx_text" id="S3.T2.2.3.1.4.1" style="font-size:90%;">
         100
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.3.1.5">
        <span class="ltx_text" id="S3.T2.2.3.1.5.1" style="font-size:90%;">
         2.7
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S3.T2.2.3.1.6">
        <span class="ltx_text" id="S3.T2.2.3.1.6.1" style="font-size:90%;">
         1.6
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T2.2.4.2">
       <td class="ltx_td ltx_align_left" id="S3.T2.2.4.2.1">
        <span class="ltx_text" id="S3.T2.2.4.2.1.1" style="font-size:90%;">
         GPT-4-8K
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.4.2.2">
        <span class="ltx_text" id="S3.T2.2.4.2.2.1" style="font-size:90%;">
         4
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.4.2.3">
        <span class="ltx_text" id="S3.T2.2.4.2.3.1" style="font-size:90%;">
         20
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.4.2.4">
        <span class="ltx_text" id="S3.T2.2.4.2.4.1" style="font-size:90%;">
         60
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.4.2.5">
        <span class="ltx_text" id="S3.T2.2.4.2.5.1" style="font-size:90%;">
         3.0
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.2.4.2.6">
        <span class="ltx_text" id="S3.T2.2.4.2.6.1" style="font-size:90%;">
         2.3
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T2.2.5.3">
       <td class="ltx_td" id="S3.T2.2.5.3.1">
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.5.3.2">
        <span class="ltx_text" id="S3.T2.2.5.3.2.1" style="font-size:90%;">
         8
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.5.3.3">
        <span class="ltx_text" id="S3.T2.2.5.3.3.1" style="font-size:90%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.5.3.4">
        <span class="ltx_text" id="S3.T2.2.5.3.4.1" style="font-size:90%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.5.3.5">
        <span class="ltx_text" id="S3.T2.2.5.3.5.1" style="font-size:90%;">
         N/A
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.2.5.3.6">
        <span class="ltx_text" id="S3.T2.2.5.3.6.1" style="font-size:90%;">
         N/A
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T2.2.6.4">
       <td class="ltx_td ltx_border_t" id="S3.T2.2.6.4.1">
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.6.4.2">
        <span class="ltx_text" id="S3.T2.2.6.4.2.1" style="font-size:90%;">
         2
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.6.4.3">
        <span class="ltx_text" id="S3.T2.2.6.4.3.1" style="font-size:90%;">
         100
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.6.4.4">
        <span class="ltx_text" id="S3.T2.2.6.4.4.1" style="font-size:90%;">
         100
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.6.4.5">
        <span class="ltx_text" id="S3.T2.2.6.4.5.1" style="font-size:90%;">
         2.1
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S3.T2.2.6.4.6">
        <span class="ltx_text" id="S3.T2.2.6.4.6.1" style="font-size:90%;">
         1.2
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T2.2.7.5">
       <td class="ltx_td ltx_align_left" id="S3.T2.2.7.5.1">
        <span class="ltx_text" id="S3.T2.2.7.5.1.1" style="font-size:90%;">
         GPT-4-128K
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.7.5.2">
        <span class="ltx_text" id="S3.T2.2.7.5.2.1" style="font-size:90%;">
         4
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.7.5.3">
        <span class="ltx_text" id="S3.T2.2.7.5.3.1" style="font-size:90%;">
         60
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.7.5.4">
        <span class="ltx_text" id="S3.T2.2.7.5.4.1" style="font-size:90%;">
         80
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T2.2.7.5.5">
        <span class="ltx_text" id="S3.T2.2.7.5.5.1" style="font-size:90%;">
         2.7
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.2.7.5.6">
        <span class="ltx_text" id="S3.T2.2.7.5.6.1" style="font-size:90%;">
         1.4
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T2.2.8.6">
       <td class="ltx_td ltx_border_bb" id="S3.T2.2.8.6.1">
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.8.6.2">
        <span class="ltx_text" id="S3.T2.2.8.6.2.1" style="font-size:90%;">
         8
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.8.6.3">
        <span class="ltx_text" id="S3.T2.2.8.6.3.1" style="font-size:90%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.8.6.4">
        <span class="ltx_text" id="S3.T2.2.8.6.4.1" style="font-size:90%;">
         20
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.8.6.5">
        <span class="ltx_text" id="S3.T2.2.8.6.5.1" style="font-size:90%;">
         N/A
        </span>
       </td>
       <td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S3.T2.2.8.6.6">
        <span class="ltx_text" id="S3.T2.2.8.6.6.1" style="font-size:90%;">
         2.4
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     The success rates and average iterations per step used until proceed to next step in success scenarios for GPT-4 and GPT-4 Turbo, whose token limits are 8K and 128K respectively, on the room-32-32-4 map with different number of agents(n).
    </figcaption>
   </figure>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     In this paper, we focus on optimizing the makespan of the MAPF solution, and making the agents prefer to wait rather than detour in small scenarios that do not lead to endless waiting. We calculate the average ratio of makespan to the maximum length among the single agent shortest paths (a standard normalization practice in MAPF as this provides a valid lower bound on the optimal MAPF solution), and in scenarios that are successfully solved, this average is 1.5. This means that LLMs can mostly succeed in scenarios that do not need a lot of waiting, and in most steps, they only need to go in the two directions aligned with the goal’s direction. LLM fails in other scenarios because they need path finding in complex environments. A simple example of the failure of path finding is shown in Fig.
     <a class="ltx_ref" href="#S3.F5" title="Figure 5 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     , where we have the classic symmetry-breaking example. We provide the input of the scenario information and the output of the first step in Fig.
     <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.2 Methods ‣ 2 LLMs for Multi-agent Path Finding ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     and Fig.
     <a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . We observe that while waiting for one step can clearly lead to the optimal solution that has a makespan of 5, the LLM chose to move agent 2 to the left and resulting in a total makespan of 6. This example shows that LLM does not understand what makespan is and how a solution is optimized for makespan.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     On the other hand, when we look at the average number of iterations for prompts with both global obstacle observation in the first user prompt and single-step obstacle observations(GO+SSO) in Table.
     <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , it is still not very close to
     <math alttext="1" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1">
      <semantics id="S3.SS1.p2.1.m1.1a">
       <mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">
        1
       </mn>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b">
        <cn id="S3.SS1.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1">
         1
        </cn>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">
        1
       </annotation>
      </semantics>
     </math>
     which means no iterations at all. This is because even if we have explicitly let the LLM deconflict the agents by listing all the coordinates of agents, it does not have the capability to check the answers itself without the use of external tools. More specifically, LLM cannot tell whether a list of tuples of numbers has any duplicates. This is similar to the fact that LLM cannot sort a list of numbers without step-by-step instructions, which we do not allow the LLMs to do because we still do not want the LLM to use too many tokens in a single step. We also observe that the GPT-4-8k model takes more iterations than the latest GPT-4-turbo model. This could either contribute to forgetting earlier information or to the improved capacity of the new model.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     This lack of reasoning capabilities is usually solved with tool use in other domains, but MAPF itself is hard because MAPF requires the capability of path finding in a complex map and avoiding collisions between all pairs of agents strategically and efficiently. The coordination between agents is required in each step, and each step only. If we let the tool, in this case, a single-agent planner like A*, include the de-conflicting, the problem is already solved, while LLM did no help. On the other hand, the tools must know what kind of deconflict they need to do to add those constraints into the heuristic search algorithm. This paradox is making LLM with tool use in MAPF very hard.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p4">
    <p class="ltx_p" id="S3.SS1.p4.1">
     To potentially increase the reasoning capability, we have also tried a list of tricks. These kinds of tricks include breaking the big paragraph into bullet-point style instruction, removing some ’useless’ instruction, adding a whole example for in-context learning, and using the theory of mind to guess other agent’s intuitions
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al.,
      <a class="ltx_ref" href="#bib.bib12" title="">
       2023b
      </a>
      )
     </cite>
     . These tricks did not show any help in any scenarios, and even greatly harmed the performance of the GPT-4-8k model.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Context Length Limit
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     Because the underlying architecture of popular LLMs is transformers, which further rely on self-attention, a longer context in the input will significantly increase the computing complexity in the process. Therefore, in their training process, they set a maximum limit of tokens on the input and trained specifically on them. Current large language models released will also provide a context length limit, which is as long as 200K tokens, and any request with a longer context length will be rejected. This is a long enough length for many tasks and even able to read a textbook, and many users are satisfied with the length. However, recent studies have shown that long models like GPT4-turbo-128K are not a model whose capacity in 8K length also works when given a 128K-tokens input
     <span class="ltx_note ltx_role_footnote" id="footnote2">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         2
        </sup>
        <span class="ltx_tag ltx_tag_note">
         2
        </span>
        https://github.com/gkamradt/LLMTest_NeedleInAHaystack
       </span>
      </span>
     </span>
     . What is even worse is that in the real-world applications of MAPF, the total number of agents running in the environment could be up to a few thousand. Even in the ideal case that our prompt will grow linearly to the number of agents, an environment with a thousand agents will require a total context length of
     <math alttext="250(tokens/agent\ step)*50(steps)*1000(agents)=5M" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.3">
      <semantics id="S3.SS2.p1.1.m1.3a">
       <mrow id="S3.SS2.p1.1.m1.3.3" xref="S3.SS2.p1.1.m1.3.3.cmml">
        <mrow id="S3.SS2.p1.1.m1.3.3.3" xref="S3.SS2.p1.1.m1.3.3.3.cmml">
         <mrow id="S3.SS2.p1.1.m1.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml">
          <mrow id="S3.SS2.p1.1.m1.2.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.2.cmml">
           <mrow id="S3.SS2.p1.1.m1.1.1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.cmml">
            <mrow id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml">
             <mn id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml">
              250
             </mn>
             <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.2.cmml">
              ​
             </mo>
             <mrow id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">
              <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">
               (
              </mo>
              <mrow id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">
               <mrow id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">
                <mrow id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">
                 <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">
                  t
                 </mi>
                 <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">
                  ​
                 </mo>
                 <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">
                  o
                 </mi>
                 <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1a" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">
                  ​
                 </mo>
                 <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.4" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.4.cmml">
                  k
                 </mi>
                 <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1b" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">
                  ​
                 </mo>
                 <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.5" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.5.cmml">
                  e
                 </mi>
                 <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1c" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">
                  ​
                 </mo>
                 <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.6" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.6.cmml">
                  n
                 </mi>
                 <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1d" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">
                  ​
                 </mo>
                 <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.7" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.7.cmml">
                  s
                 </mi>
                </mrow>
                <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">
                 /
                </mo>
                <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">
                 a
                </mi>
               </mrow>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">
                g
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.4.cmml">
                e
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.5.cmml">
                n
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1c" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.6" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.6.cmml">
                t
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1d" lspace="0.500em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.7" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.7.cmml">
                s
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1e" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.8" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.8.cmml">
                t
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1f" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.9" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.9.cmml">
                e
               </mi>
               <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1g" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.10" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.10.cmml">
                p
               </mi>
              </mrow>
              <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="S3.SS2.p1.1.m1.1.1.1.1.1.1.2" rspace="0.222em" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.2.cmml">
             ∗
            </mo>
            <mn id="S3.SS2.p1.1.m1.1.1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.3.cmml">
             50
            </mn>
           </mrow>
           <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.3" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.2.2.2.2.2.3.cmml">
            ​
           </mo>
           <mrow id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.cmml">
            <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.2" stretchy="false" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.cmml">
             (
            </mo>
            <mrow id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.cmml">
             <mi id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.2" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.2.cmml">
              s
             </mi>
             <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1.cmml">
              ​
             </mo>
             <mi id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.3" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.3.cmml">
              t
             </mi>
             <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1a" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1.cmml">
              ​
             </mo>
             <mi id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.4" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.4.cmml">
              e
             </mi>
             <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1b" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1.cmml">
              ​
             </mo>
             <mi id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.5" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.5.cmml">
              p
             </mi>
             <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1c" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1.cmml">
              ​
             </mo>
             <mi id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.6" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.6.cmml">
              s
             </mi>
            </mrow>
            <mo id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.3" rspace="0.055em" stretchy="false" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <mo id="S3.SS2.p1.1.m1.2.2.2.2.3" rspace="0.222em" xref="S3.SS2.p1.1.m1.2.2.2.2.3.cmml">
           ∗
          </mo>
          <mn id="S3.SS2.p1.1.m1.2.2.2.2.4" xref="S3.SS2.p1.1.m1.2.2.2.2.4.cmml">
           1000
          </mn>
         </mrow>
         <mo id="S3.SS2.p1.1.m1.3.3.3.4" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.3.4.cmml">
          ​
         </mo>
         <mrow id="S3.SS2.p1.1.m1.3.3.3.3.1" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.cmml">
          <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.2" stretchy="false" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.cmml">
           (
          </mo>
          <mrow id="S3.SS2.p1.1.m1.3.3.3.3.1.1" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.cmml">
           <mi id="S3.SS2.p1.1.m1.3.3.3.3.1.1.2" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.2.cmml">
            a
           </mi>
           <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.1.cmml">
            ​
           </mo>
           <mi id="S3.SS2.p1.1.m1.3.3.3.3.1.1.3" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.3.cmml">
            g
           </mi>
           <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.1.1a" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.1.cmml">
            ​
           </mo>
           <mi id="S3.SS2.p1.1.m1.3.3.3.3.1.1.4" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.4.cmml">
            e
           </mi>
           <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.1.1b" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.1.cmml">
            ​
           </mo>
           <mi id="S3.SS2.p1.1.m1.3.3.3.3.1.1.5" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.5.cmml">
            n
           </mi>
           <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.1.1c" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.1.cmml">
            ​
           </mo>
           <mi id="S3.SS2.p1.1.m1.3.3.3.3.1.1.6" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.6.cmml">
            t
           </mi>
           <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.1.1d" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.1.cmml">
            ​
           </mo>
           <mi id="S3.SS2.p1.1.m1.3.3.3.3.1.1.7" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.7.cmml">
            s
           </mi>
          </mrow>
          <mo id="S3.SS2.p1.1.m1.3.3.3.3.1.3" stretchy="false" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="S3.SS2.p1.1.m1.3.3.4" xref="S3.SS2.p1.1.m1.3.3.4.cmml">
         =
        </mo>
        <mrow id="S3.SS2.p1.1.m1.3.3.5" xref="S3.SS2.p1.1.m1.3.3.5.cmml">
         <mn id="S3.SS2.p1.1.m1.3.3.5.2" xref="S3.SS2.p1.1.m1.3.3.5.2.cmml">
          5
         </mn>
         <mo id="S3.SS2.p1.1.m1.3.3.5.1" lspace="0em" rspace="0em" xref="S3.SS2.p1.1.m1.3.3.5.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.p1.1.m1.3.3.5.3" xref="S3.SS2.p1.1.m1.3.3.5.3.cmml">
          M
         </mi>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.3b">
        <apply id="S3.SS2.p1.1.m1.3.3.cmml" xref="S3.SS2.p1.1.m1.3.3">
         <eq id="S3.SS2.p1.1.m1.3.3.4.cmml" xref="S3.SS2.p1.1.m1.3.3.4">
         </eq>
         <apply id="S3.SS2.p1.1.m1.3.3.3.cmml" xref="S3.SS2.p1.1.m1.3.3.3">
          <times id="S3.SS2.p1.1.m1.3.3.3.4.cmml" xref="S3.SS2.p1.1.m1.3.3.3.4">
          </times>
          <apply id="S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2">
           <times id="S3.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.3">
           </times>
           <apply id="S3.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2">
            <times id="S3.SS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.3">
            </times>
            <apply id="S3.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1">
             <times id="S3.SS2.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.2">
             </times>
             <apply id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1">
              <times id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.2">
              </times>
              <cn id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.3">
               250
              </cn>
              <apply id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1">
               <times id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1">
               </times>
               <apply id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2">
                <divide id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.1">
                </divide>
                <apply id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2">
                 <times id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.1">
                 </times>
                 <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.2">
                  𝑡
                 </ci>
                 <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.3">
                  𝑜
                 </ci>
                 <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.4.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.4">
                  𝑘
                 </ci>
                 <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.5.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.5">
                  𝑒
                 </ci>
                 <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.6.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.6">
                  𝑛
                 </ci>
                 <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.7.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.2.7">
                  𝑠
                 </ci>
                </apply>
                <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.3">
                 𝑎
                </ci>
               </apply>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3">
                𝑔
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.4">
                𝑒
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.5">
                𝑛
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.6">
                𝑡
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.7.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.7">
                𝑠
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.8.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.8">
                𝑡
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.9.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.9">
                𝑒
               </ci>
               <ci id="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.10.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.10">
                𝑝
               </ci>
              </apply>
             </apply>
             <cn id="S3.SS2.p1.1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.1.1.1.1.3">
              50
             </cn>
            </apply>
            <apply id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1">
             <times id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.1">
             </times>
             <ci id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.2">
              𝑠
             </ci>
             <ci id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.3">
              𝑡
             </ci>
             <ci id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.4.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.4">
              𝑒
             </ci>
             <ci id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.5.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.5">
              𝑝
             </ci>
             <ci id="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.6.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.1.1.6">
              𝑠
             </ci>
            </apply>
           </apply>
           <cn id="S3.SS2.p1.1.m1.2.2.2.2.4.cmml" type="integer" xref="S3.SS2.p1.1.m1.2.2.2.2.4">
            1000
           </cn>
          </apply>
          <apply id="S3.SS2.p1.1.m1.3.3.3.3.1.1.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1">
           <times id="S3.SS2.p1.1.m1.3.3.3.3.1.1.1.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.1">
           </times>
           <ci id="S3.SS2.p1.1.m1.3.3.3.3.1.1.2.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.2">
            𝑎
           </ci>
           <ci id="S3.SS2.p1.1.m1.3.3.3.3.1.1.3.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.3">
            𝑔
           </ci>
           <ci id="S3.SS2.p1.1.m1.3.3.3.3.1.1.4.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.4">
            𝑒
           </ci>
           <ci id="S3.SS2.p1.1.m1.3.3.3.3.1.1.5.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.5">
            𝑛
           </ci>
           <ci id="S3.SS2.p1.1.m1.3.3.3.3.1.1.6.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.6">
            𝑡
           </ci>
           <ci id="S3.SS2.p1.1.m1.3.3.3.3.1.1.7.cmml" xref="S3.SS2.p1.1.m1.3.3.3.3.1.1.7">
            𝑠
           </ci>
          </apply>
         </apply>
         <apply id="S3.SS2.p1.1.m1.3.3.5.cmml" xref="S3.SS2.p1.1.m1.3.3.5">
          <times id="S3.SS2.p1.1.m1.3.3.5.1.cmml" xref="S3.SS2.p1.1.m1.3.3.5.1">
          </times>
          <cn id="S3.SS2.p1.1.m1.3.3.5.2.cmml" type="integer" xref="S3.SS2.p1.1.m1.3.3.5.2">
           5
          </cn>
          <ci id="S3.SS2.p1.1.m1.3.3.5.3.cmml" xref="S3.SS2.p1.1.m1.3.3.5.3">
           𝑀
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.3c">
        250(tokens/agent\ step)*50(steps)*1000(agents)=5M
       </annotation>
      </semantics>
     </math>
     tokens, which is much bigger than the current limit. Because the token limit is strict, we have introduced the restart mechanism in our methods, and in our current experiment scale, we have to restart the LLM around every 7-10 steps in large or complex scenarios. We also observed that the number of tokens used grows non-linearly with regard to the number of agents due to the increasing number of iterations, and we have put the numbers in the appendix.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     In table.
     <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , we show our results on the
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p2.1.1">
      room
     </span>
     map, and test with different GPT-4 models with different context lengths. We found that when the context length limit grows, the success rate also increases. This is especially helpful when the single-step observation information that tells what valid actions each agent has is not provided. The failures here are not direct failures by exceeding the context length limit, but from the forgetting in restart caused by reaching the context length limits. Because of these restarts, our models often completely forget that they have been to certain locations, and then go back and forth in certain areas with dead ends like the center room in the
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p2.1.2">
      room
     </span>
     map.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Understanding Obstacle Locations
   </h3>
   <figure class="ltx_table" id="S3.T3">
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.2">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S3.T3.2.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T3.2.1.1.1">
        <span class="ltx_text" id="S3.T3.2.1.1.1.1" style="font-size:90%;">
         n\Success Rate
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T3.2.1.1.2">
        <span class="ltx_text" id="S3.T3.2.1.1.2.1" style="font-size:90%;">
         MM
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T3.2.1.1.3">
        <span class="ltx_text" id="S3.T3.2.1.1.3.1" style="font-size:90%;">
         TOO
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T3.2.1.1.4">
        <span class="ltx_text" id="S3.T3.2.1.1.4.1" style="font-size:90%;">
         TOM
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S3.T3.2.2.1">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.2.2.1.1">
        <span class="ltx_text" id="S3.T3.2.2.1.1.1" style="font-size:90%;">
         2
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.2.2.1.2">
        <span class="ltx_text" id="S3.T3.2.2.1.2.1" style="font-size:90%;">
         100
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.2.2.1.3">
        <span class="ltx_text" id="S3.T3.2.2.1.3.1" style="font-size:90%;">
         100
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.2.2.1.4">
        <span class="ltx_text" id="S3.T3.2.2.1.4.1" style="font-size:90%;">
         100
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T3.2.3.2">
       <td class="ltx_td ltx_align_left" id="S3.T3.2.3.2.1">
        <span class="ltx_text" id="S3.T3.2.3.2.1.1" style="font-size:90%;">
         4
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T3.2.3.2.2">
        <span class="ltx_text" id="S3.T3.2.3.2.2.1" style="font-size:90%;">
         20
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T3.2.3.2.3">
        <span class="ltx_text" id="S3.T3.2.3.2.3.1" style="font-size:90%;">
         60
        </span>
       </td>
       <td class="ltx_td ltx_align_left" id="S3.T3.2.3.2.4">
        <span class="ltx_text" id="S3.T3.2.3.2.4.1" style="font-size:90%;">
         80
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T3.2.4.3">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.2.4.3.1">
        <span class="ltx_text" id="S3.T3.2.4.3.1.1" style="font-size:90%;">
         8
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.2.4.3.2">
        <span class="ltx_text" id="S3.T3.2.4.3.2.1" style="font-size:90%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.2.4.3.3">
        <span class="ltx_text" id="S3.T3.2.4.3.3.1" style="font-size:90%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.2.4.3.4">
        <span class="ltx_text" id="S3.T3.2.4.3.4.1" style="font-size:90%;">
         20
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     The success rate of different ways of inputting the map information to LLM on
     <span class="ltx_text ltx_font_smallcaps" id="S3.T3.7.1">
      Room
     </span>
     -32-32-4 map with different number of agents (n).
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F7">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="218" id="S3.F7.g1" src="/html/2401.03630/assets/figs/MM_TOO_TOM.png" width="509"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F7.2.1.1" style="font-size:90%;">
       Figure 7
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F7.3.2" style="font-size:90%;">
      An illustration of the difference between multimodal input (MM), text that describes the whole map (TOM), and text that describes the obstacles (TOO).
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     MAPF scenarios can be broken down into a pair of start location and goal locations, together with the map information. While understanding the coordinate version of start goal location pairs is relatively easy, understanding the map information is hard. Trained with publicly available text, LLM learns what a specific map means by finding similar contexts online, which mostly comes from other related fields in planning, like solving a maze. However, one problem is that people barely provide any such information online since people have the common knowledge of what to do with a map with code and preprocess the map information in the code rather than explicitly provide the set of where the obstacles are as the original input. Therefore, this leads to a lack of training data with related context about the information in the pictures or in a symbol-based input.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p2">
    <p class="ltx_p" id="S3.SS3.p2.1">
     Because of this lack of information, our main prompt included guidance on what action could be taken in the current step to increase the success rate a little bit. In Table.
     <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.1 Reasoning Capability ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , we provided the results of global observation (GO) only and the version with single-step observation (SSO) together. We discover that while global observation can also provide a good win rate with the help of our high-level checkers, it increases the average iterations in each step, and also fails in cases that could be successful with the help of SSO, which is killed by using much more total number of steps than it should. In general, LLMs fail in medium complexity maps like
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p2.1.1">
      room
     </span>
     , and completely fail in much harder maps like
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p2.1.2">
      maze
     </span>
     , even with the help of SSO.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p3">
    <p class="ltx_p" id="S3.SS3.p3.1">
     In all the experiments above, we use pure-text-based input because of the popularity and simplicity of pure-text input. However, this was not the case before: In earlier work of reinforcement learning for MAPF, people transformed the input into image-based input within the field of view and used neural networks like convolutional neural network (CNN) to read the information.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p4">
    <p class="ltx_p" id="S3.SS3.p4.1">
     Therefore, as shown in Fig.
     <a class="ltx_ref" href="#S3.F7" title="Figure 7 ‣ 3.3 Understanding Obstacle Locations ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     , we propose three different methods, which all share the same prompt of describing the problem definition and use different versions of the prompt describing the scenario:
    </p>
    <ol class="ltx_enumerate" id="S3.I1">
     <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="S3.I1.i1.p1">
       <p class="ltx_p" id="S3.I1.i1.p1.1">
        A multimodal-based method MM where we use an image to give the picture of the map, and text to describe the problem and the scenario.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="S3.I1.i2.p1">
       <p class="ltx_p" id="S3.I1.i2.p1.1">
        A text-only method that describes the map by listing all the coordinates of the obstacles, named TOO.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="S3.I1.i3.p1">
       <p class="ltx_p" id="S3.I1.i3.p1.1">
        A text-only method that describes the map by feeding the text version of the map with ’@’ denoting the obstacles and ’.’ denoting an empty space, named TOM.
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para" id="S3.SS3.p5">
    <p class="ltx_p" id="S3.SS3.p5.2">
     We test the performance of these three variants, and show the results in Table.
     <a class="ltx_ref" href="#S3.T3" title="Table 3 ‣ 3.3 Understanding Obstacle Locations ‣ 3 Cause of Failures ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . We found that with an image-based input, the results are even worse. For example, large models can only have a high-level idea that there is a wall in the middle area, rather than knowing there is a wall exactly from
     <math alttext="(3,10)" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.2">
      <semantics id="S3.SS3.p5.1.m1.2a">
       <mrow id="S3.SS3.p5.1.m1.2.3.2" xref="S3.SS3.p5.1.m1.2.3.1.cmml">
        <mo id="S3.SS3.p5.1.m1.2.3.2.1" stretchy="false" xref="S3.SS3.p5.1.m1.2.3.1.cmml">
         (
        </mo>
        <mn id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">
         3
        </mn>
        <mo id="S3.SS3.p5.1.m1.2.3.2.2" xref="S3.SS3.p5.1.m1.2.3.1.cmml">
         ,
        </mo>
        <mn id="S3.SS3.p5.1.m1.2.2" xref="S3.SS3.p5.1.m1.2.2.cmml">
         10
        </mn>
        <mo id="S3.SS3.p5.1.m1.2.3.2.3" stretchy="false" xref="S3.SS3.p5.1.m1.2.3.1.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.2b">
        <interval closure="open" id="S3.SS3.p5.1.m1.2.3.1.cmml" xref="S3.SS3.p5.1.m1.2.3.2">
         <cn id="S3.SS3.p5.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p5.1.m1.1.1">
          3
         </cn>
         <cn id="S3.SS3.p5.1.m1.2.2.cmml" type="integer" xref="S3.SS3.p5.1.m1.2.2">
          10
         </cn>
        </interval>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.2c">
        (3,10)
       </annotation>
      </semantics>
     </math>
     to
     <math alttext="(20,10)" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.2">
      <semantics id="S3.SS3.p5.2.m2.2a">
       <mrow id="S3.SS3.p5.2.m2.2.3.2" xref="S3.SS3.p5.2.m2.2.3.1.cmml">
        <mo id="S3.SS3.p5.2.m2.2.3.2.1" stretchy="false" xref="S3.SS3.p5.2.m2.2.3.1.cmml">
         (
        </mo>
        <mn id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">
         20
        </mn>
        <mo id="S3.SS3.p5.2.m2.2.3.2.2" xref="S3.SS3.p5.2.m2.2.3.1.cmml">
         ,
        </mo>
        <mn id="S3.SS3.p5.2.m2.2.2" xref="S3.SS3.p5.2.m2.2.2.cmml">
         10
        </mn>
        <mo id="S3.SS3.p5.2.m2.2.3.2.3" stretchy="false" xref="S3.SS3.p5.2.m2.2.3.1.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.2b">
        <interval closure="open" id="S3.SS3.p5.2.m2.2.3.1.cmml" xref="S3.SS3.p5.2.m2.2.3.2">
         <cn id="S3.SS3.p5.2.m2.1.1.cmml" type="integer" xref="S3.SS3.p5.2.m2.1.1">
          20
         </cn>
         <cn id="S3.SS3.p5.2.m2.2.2.cmml" type="integer" xref="S3.SS3.p5.2.m2.2.2">
          10
         </cn>
        </interval>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.2c">
        (20,10)
       </annotation>
      </semantics>
     </math>
     . The failure of TOO further indicates that LLMs do not know how to combine high-level intuitions of where obstacles are with concrete reasoning during path planning. Overall, in complex environments such as mazes and real-world city maps, LLMs cannot offer any form of guidance, not necessarily the specific action recommendations tested in this paper, until they can accurately comprehend the relationship between obstacles and the paths of agents.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Discussion
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    As we have shown in the previous section, there are three aspects that mainly limit the current capability of solving MAPF with LLMs. While there have been many works in the NLP that could solve one of them, e.g., extending the context length limit to up to 4M tokens or using a decentralized control, those methods will harm the reasoning capability and, therefore, are not preferable in our case.
   </p>
  </div>
  <div class="ltx_para" id="S4.p2">
   <p class="ltx_p" id="S4.p2.1">
    We would like to note that the methods in this paper are not designed to either outperform the state-of-the-art classic solvers or surpass the performance of learning-based solvers. Instead, the goal is to demonstrate that LLMs can solve small problems simply through prompting and discussing what is stopping them from solving larger ones.
   </p>
  </div>
  <div class="ltx_para" id="S4.p3">
   <p class="ltx_p" id="S4.p3.1">
    Moving on, we believe the three reasons for failures can each independently relate to different research directions. Improving capability in a long context is already a popular direction in NLP, and there are also many papers looking into improving the general reasoning capability. We believe that much ongoing research has the opportunity to improve the performance of LLMs on MAPF, and we are pleased to have more researchers test this unique problem. Also, the recent development of building foundation models that combine language and image generation could be potentially helpful for the reasoning in MAPF. Image generation models like stable diffusion
    <cite class="ltx_cite ltx_citemacro_citep">
     (Rombach et al.,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2022
     </a>
     )
    </cite>
    have shown to be a strong tool in single agent planning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Janner et al.,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2022
     </a>
     )
    </cite>
    . While these diffusion models are not designed for multi-agent planning and are even hard to apply to MAPF, strategically using them could partially help the lack of reasoning capability. Regarding the understanding of the obstacles, we believe more annotated data are needed to help foundation models connect the abstract description to concrete coordinate-level knowledge of where obstacles are. Future research could finetune using their data, or at least open their data to the general public, and let the next version of released models from industry companies include such data by automatically getting such data online. Hopefully, such data could help foundation models able to know position encodings are specifically more important in problems related to planning. However, a challenge for fine-tuning a customized model is that popular open-source models have smaller context length, like 4K in LLAMA-2, and 32K for Mixtral 8*7b, which will limit their performance on MAPF.
   </p>
  </div>
  <div class="ltx_para" id="S4.p4">
   <p class="ltx_p" id="S4.p4.1">
    Besides, although the success rate is one of the most important factors in measuring the performance of a solver, there are also other obstacles that need to be solved before using LLMs in real-world scenarios. First of all, success does not indicate anything about the solution quality. In our experiment, we found that the success scenarios usually come from easier scenarios that agents mostly only need to follow their direct shortest path. And when the planning is getting harder, the success rate is much worse. To improve the reasoning capability, future researchers and users could choose to make a dataset of scenarios and their good solutions publicly available on the internet, so when training with newer data, this specific problem could be directly included in the training set. Furthermore, the current workflow does not include any heuristics or tool use. While we are unclear on how such things should be included, this will be a very challenging but meaningful direction. For potential researchers going in this direction, we want to remind them to keep looking at the consistency of the deconflict of agents, which could be seen as moving obstacles, and the deconflict of the fixed obstacles on the map. A successful method should consider both difficulties in a similar manner.
   </p>
  </div>
  <div class="ltx_para" id="S4.p5">
   <p class="ltx_p" id="S4.p5.1">
    On the other hand, latency is always a problem for LLMs when used in real-world production. If one wants to use their own models, which is currently  500 tokens per second after using state-of-the-art system-wise optimization like vLLM
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kwon et al.,
     <a class="ltx_ref" href="#bib.bib10" title="">
      2023
     </a>
     )
    </cite>
    for LLAMA-2
    <cite class="ltx_cite ltx_citemacro_citep">
     (Touvron et al.,
     <a class="ltx_ref" href="#bib.bib31" title="">
      2023
     </a>
     )
    </cite>
    . However, this speed is not enough as a typical round of output will have 1500 tokens, and it may take a few rounds before the LLM generates a valid solution. If one wants to use models provided through API like GPT-4 from OpenAI, the latency of the models will depend on a list of factors like network connection and server availability. In our paper, we typically need to wait around 15-30 seconds for one step to get completed, where less than 0.1 seconds are used for local processing.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Related Works
  </h2>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    LLM for Reasoning
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     Since the release of GPT-3, researchers have studied the effect of how they are performing on diverse sets of problems. Starting with failure in general tasks
     <cite class="ltx_cite ltx_citemacro_citep">
      (Valmeekam et al.,
      <a class="ltx_ref" href="#bib.bib32" title="">
       2022
      </a>
      )
     </cite>
     , ideas like chain of thought
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2022
      </a>
      )
     </cite>
     , in context learning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ye et al.,
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     have been shown to significantly improve the performance of LLMs in different tasks related to reasoning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Fu et al.,
      <a class="ltx_ref" href="#bib.bib6" title="">
       2022
      </a>
      ; Shum et al.,
      <a class="ltx_ref" href="#bib.bib26" title="">
       2023
      </a>
      )
     </cite>
     . A recent line of work has been introduced to use natural language as feedback in the process to introduce iterations and give LLMs more than one chance to generate correct solutions, which has been shown to significantly help in code generation
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al.,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023
      </a>
      ; Chen et al.,
      <a class="ltx_ref" href="#bib.bib2" title="">
       2023a
      </a>
      ; Olausson et al.,
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      )
     </cite>
     , reasoning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2022
      </a>
      ; Yang et al.,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      ; Shinn et al.,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023
      </a>
      )
     </cite>
     , and reducing harmful information in LLMs
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ganguli et al.,
      <a class="ltx_ref" href="#bib.bib7" title="">
       2023
      </a>
      )
     </cite>
     . There is also a very popular line of work augmenting LLMs with external memory, belief, and tools. For example,
     <cite class="ltx_cite ltx_citemacro_citet">
      Liu et al. (
      <a class="ltx_ref" href="#bib.bib16" title="">
       2023a
      </a>
      )
     </cite>
     proposed to use LLMs to generate a PDDL description of the problem in classic planning benchmark domains like blocksworld and thermes.
     <cite class="ltx_cite ltx_citemacro_citet">
      Mao et al. (
      <a class="ltx_ref" href="#bib.bib19" title="">
       2023
      </a>
      )
     </cite>
     used external memory to match the previous experience and shows that the underlying knowledge in LLMs can make a novel tool that is more powerful than before in autonomous driving. In this paper, we use our high-level checker as the only tool in the process, and we hope the reasons for failure could later help researchers choose external tools.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    LLM for Multi-agent Systems
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     While there is extensive research on using LLMs for many different problems, there is little work that addresses the problem of LLM for multi-agent systems in the beginning. This is typically due to the context length limit that generally applies when the total number of agents is not too small. As time proceeds, there has been a list of works that promote research in social behavior by creating multi-agent environment powered by a lot of LLM agents
     <cite class="ltx_cite ltx_citemacro_citep">
      (Tan et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib11" title="">
       2023a
      </a>
      )
     </cite>
     , create dialogue-based games with LLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Schlangen,
      <a class="ltx_ref" href="#bib.bib23" title="">
       2023
      </a>
      )
     </cite>
     . Recent work has shown that dialogue between multiple agents can help accuracy and remove factual errors
     <cite class="ltx_cite ltx_citemacro_citep">
      (Du et al.,
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      ; Wang et al.,
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023b
      </a>
      )
     </cite>
     . When it comes to solving problems related to multi-agent system, there are a few works that are more in the multi-robot system.
     <cite class="ltx_cite ltx_citemacro_citet">
      Zhang et al. (
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     and
     <cite class="ltx_cite ltx_citemacro_citet">
      Mandi et al. (
      <a class="ltx_ref" href="#bib.bib18" title="">
       2023
      </a>
      )
     </cite>
     are two works that first extend LLMs to the domain, but they are limited to the scale of two to three agents.
     <cite class="ltx_cite ltx_citemacro_citet">
      Chen et al. (
      <a class="ltx_ref" href="#bib.bib3" title="">
       2023b
      </a>
      )
     </cite>
     studied whether using a more decentralized controller can help to solve the context length limit problem when the number of agents is higher.
     <cite class="ltx_cite ltx_citemacro_citet">
      Agashe et al. (
      <a class="ltx_ref" href="#bib.bib1" title="">
       2023
      </a>
      )
     </cite>
     evaluate the overall multi-agent coordination capability in three different domains and show that with proper tools, LLMs can even outperform MARL algorithms. While they succeed in their domains, in this paper, we specifically look at the problem of MAPF, and we are showing the cause of failure in the MAPF problem because of its unique challenges in MAPF.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Multi-agent Path Finding
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     Multi-agent path finding (MAPF) is a problem that has won much attention in recent years because of its close relationship to real-world applications like autonomous warehouses. It has previously been solved with more classic methods like heuristic search algorithms
     <cite class="ltx_cite ltx_citemacro_citep">
      (Sharon et al.,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2015
      </a>
      )
     </cite>
     , rule-based algorithms
     <cite class="ltx_cite ltx_citemacro_citep">
      (Han &amp; Yu,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2020
      </a>
      )
     </cite>
     , and reduction-based algorithms
     <cite class="ltx_cite ltx_citemacro_citep">
      (Surynek et al.,
      <a class="ltx_ref" href="#bib.bib29" title="">
       2016
      </a>
      )
     </cite>
     . While learning-based approaches have not yet outperformed classic approaches, they have also begun to win a lot more focus for their fast inference time and generalizability. PRIMAL
     <cite class="ltx_cite ltx_citemacro_citep">
      (Sartoretti et al.,
      <a class="ltx_ref" href="#bib.bib22" title="">
       2019
      </a>
      )
     </cite>
     proposed to learn a policy for MAPF using a combination of reinforcement learning and imitation learning. Following that, a group of works proposed a diverse set of methods from building curriculum
     <cite class="ltx_cite ltx_citemacro_citep">
      (Damani et al.,
      <a class="ltx_ref" href="#bib.bib4" title="">
       2021
      </a>
      )
     </cite>
     to follow guidance from classic methods in each step
     <cite class="ltx_cite ltx_citemacro_citep">
      (Skrynnik et al.,
      <a class="ltx_ref" href="#bib.bib27" title="">
       2023
      </a>
      )
     </cite>
     . In this paper, we focus on using LLM, which is a neural-network-based approach but is not specifically fine-tuned for MAPF problems.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this paper, we investigate the use of LLMs for solving the MAPF problem. We first show that LLMs could work in easy scenarios like a small number of agents in the empty map, while being unable to stably generate valid solutions when the problem gets harder. To make our work applicable to future models, we elaborate on the failures and show that they can be broken down into the problem of the context length limit of the model, the capability to understand and remember where obstacles are, and the capability of planning. We used extensive experiments to support our breakdown, and provided discussions on how the difficulties could be addressed by people with different backgrounds.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Impact Statement
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    This paper presents work whose goal is to express our position on how to advance the field of Machine Learning and Multi-agent Path Finding. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Agashe et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Agashe, S., Fan, Y., and Wang, X. E.
    </span>
    <span class="ltx_bibblock">
     Evaluating multi-agent coordination abilities in large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2310.03903
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Chen, X., Lin, M., Schärli, N., and Zhou, D.
    </span>
    <span class="ltx_bibblock">
     Teaching large language models to self-debug.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2304.05128
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Chen, Y., Arkin, J., Zhang, Y., Roy, N., and Fan, C.
    </span>
    <span class="ltx_bibblock">
     Scalable multi-robot collaboration with large language models:
Centralized or decentralized systems?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      arXiv preprint arXiv:2309.15943
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Damani et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Damani, M., Luo, Z., Wenzel, E., and Sartoretti, G.
    </span>
    <span class="ltx_bibblock">
     Primal$_2$: Pathfinding via reinforcement
and imitation multi-agent learning - lifelong.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      IEEE Robotics Autom. Lett.
     </em>
     , 6(2):2666–2673, 2021.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.1109/LRA.2021.3062803
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/LRA.2021.3062803" target="_blank" title="">
      https://doi.org/10.1109/LRA.2021.3062803
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., and Mordatch, I.
    </span>
    <span class="ltx_bibblock">
     Improving factuality and reasoning in language models through
multiagent debate.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      CoRR
     </em>
     , abs/2305.14325, 2023.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.48550/ARXIV.2305.14325
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.14325" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2305.14325
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Fu, Y., Peng, H., Sabharwal, A., Clark, P., and Khot, T.
    </span>
    <span class="ltx_bibblock">
     Complexity-based prompting for multi-step reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      arXiv preprint arXiv:2210.00720
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ganguli et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Ganguli, D., Askell, A., Schiefer, N., Liao, T., Lukošiūtė, K.,
Chen, A., Goldie, A., Mirhoseini, A., Olsson, C., Hernandez, D., et al.
    </span>
    <span class="ltx_bibblock">
     The capacity for moral self-correction in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2302.07459
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Han &amp; Yu (2020)
    </span>
    <span class="ltx_bibblock">
     Han, S. D. and Yu, J.
    </span>
    <span class="ltx_bibblock">
     DDM: fast near-optimal multi-robot path planning using
diversified-path and optimal sub-problem solution database heuristics.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      IEEE Robotics Autom. Lett.
     </em>
     , 2:1350–1357, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Janner et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Janner, M., Du, Y., Tenenbaum, J. B., and Levine, S.
    </span>
    <span class="ltx_bibblock">
     Planning with diffusion for flexible behavior synthesis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2205.09991
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kwon et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J. E.,
Zhang, H., and Stoica, I.
    </span>
    <span class="ltx_bibblock">
     Efficient memory management for large language model serving with
pagedattention.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Proceedings of the ACM SIGOPS 29th Symposium on Operating
Systems Principles
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., and Ghanem, B.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for” mind” exploration of large scale
language model society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2303.17760
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Li, H., Chong, Y. Q., Stepputtis, S., Campbell, J., Hughes, D. T., Lewis, C.,
and Sycara, K. P.
    </span>
    <span class="ltx_bibblock">
     Theory of mind for multi-agent collaboration via large language
models.
    </span>
    <span class="ltx_bibblock">
     In Bouamor, H., Pino, J., and Bali, K. (eds.),
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      Proceedings of
the 2023 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2023, Singapore, December 6-10, 2023
     </em>
     , pp.  180–192. Association
for Computational Linguistics, 2023b.
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.13" target="_blank" title="">
      https://aclanthology.org/2023.emnlp-main.13
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Li, J., Harabor, D., Stuckey, P. J., Ma, H., and Koenig, S.
    </span>
    <span class="ltx_bibblock">
     Symmetry-breaking constraints for grid-based multi-agent path
finding.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      Proceedings of the AAAI Conference on Artificial
Intelligence
     </em>
     , volume 33-01, pp.  6087–6095, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Li, J., Sun, K., Ma, H., Felner, A., Kumar, T. K. S., and Koenig, S.
    </span>
    <span class="ltx_bibblock">
     Moving agents in formation in congested environments.
    </span>
    <span class="ltx_bibblock">
     In Harabor, D. and Vallati, M. (eds.),
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      Proceedings of the
Thirteenth International Symposium on Combinatorial Search, SOCS 2020,
Online Conference [Vienna, Austria], 26-28 May 2020
     </em>
     , pp.  131–132. AAAI
Press, 2020.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.1609/SOCS.V11I1.18525
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/socs.v11i1.18525" target="_blank" title="">
      https://doi.org/10.1609/socs.v11i1.18525
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Li, J., Chen, Z., Harabor, D., Stuckey, P. J., and Koenig, S.
    </span>
    <span class="ltx_bibblock">
     MAPF-LNS2: fast repairing for multi-agent path finding via large
neighborhood search.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      Proceedings of the Thirty-Sixth Conference on Artificial
Intelligence (AAAI)
     </em>
     , pp.  10256–10265. AAAI Press, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Liu, B., Jiang, Y., Zhang, X., Liu, Q., Zhang, S., Biswas, J., and Stone, P.
    </span>
    <span class="ltx_bibblock">
     Llm+ p: Empowering large language models with optimal planning
proficiency.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2304.11477
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Liu, Z., Zhang, Y., Li, P., Liu, Y., and Yang, D.
    </span>
    <span class="ltx_bibblock">
     Dynamic llm-agent network: An llm-agent collaboration framework with
agent team optimization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:2310.02170
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mandi et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Mandi, Z., Jain, S., and Song, S.
    </span>
    <span class="ltx_bibblock">
     Roco: Dialectic multi-robot collaboration with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      arXiv preprint arXiv:2307.04738
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Mao, J., Ye, J., Qian, Y., Pavone, M., and Wang, Y.
    </span>
    <span class="ltx_bibblock">
     A language agent for autonomous driving.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:2311.10813
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Olausson et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Olausson, T. X., Inala, J. P., Wang, C., Gao, J., and Solar-Lezama, A.
    </span>
    <span class="ltx_bibblock">
     Demystifying gpt self-repair for code generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2306.09896
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rombach et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
    </span>
    <span class="ltx_bibblock">
     High-resolution image synthesis with latent diffusion models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition
     </em>
     , pp.  10684–10695, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sartoretti et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Sartoretti, G., Kerr, J., Shi, Y., Wagner, G., Kumar, T. K. S., Koenig, S., and
Choset, H.
    </span>
    <span class="ltx_bibblock">
     PRIMAL: pathfinding via reinforcement and imitation multi-agent
learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      IEEE Robotics Autom. Lett.
     </em>
     , 4(3):2378–2385, 2019.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.1109/LRA.2019.2903261
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/LRA.2019.2903261" target="_blank" title="">
      https://doi.org/10.1109/LRA.2019.2903261
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schlangen (2023)
    </span>
    <span class="ltx_bibblock">
     Schlangen, D.
    </span>
    <span class="ltx_bibblock">
     Dialogue games for benchmarking language understanding: Motivation,
taxonomy, strategy.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:2304.07007
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sharon et al. (2015)
    </span>
    <span class="ltx_bibblock">
     Sharon, G., Stern, R., Felner, A., and Sturtevant, N. R.
    </span>
    <span class="ltx_bibblock">
     Conflict-based search for optimal multi-agent pathfinding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      Artif. Intell.
     </em>
     , pp.  40–66, 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shinn, N., Labash, B., and Gopinath, A.
    </span>
    <span class="ltx_bibblock">
     Reflexion: an autonomous agent with dynamic memory and
self-reflection.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      arXiv preprint arXiv:2303.11366
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shum et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shum, K., Diao, S., and Zhang, T.
    </span>
    <span class="ltx_bibblock">
     Automatic prompt augmentation and selection with chain-of-thought
from labeled data.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:2302.12822
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Skrynnik et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Skrynnik, A., Andreychuk, A., Nesterova, M., Yakovlev, K., and Panov, A.
    </span>
    <span class="ltx_bibblock">
     Learn to follow: Decentralized lifelong multi-agent pathfinding via
planning and learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2310.01207
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Stern et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Stern, R., Sturtevant, N. R., Felner, A., Koenig, S., Ma, H., Walker, T. T.,
Li, J., Atzmon, D., Cohen, L., Kumar, T. K. S., Barták, R., and
Boyarski, E.
    </span>
    <span class="ltx_bibblock">
     Multi-agent pathfinding: Definitions, variants, and benchmarks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Proceedings of the Twelfth Annual Symposium on Combinatorial
Search (SoCS)
     </em>
     , pp.  151–159. AAAI Press, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Surynek et al. (2016)
    </span>
    <span class="ltx_bibblock">
     Surynek, P., Felner, A., Stern, R., and Boyarski, E.
    </span>
    <span class="ltx_bibblock">
     Efficient SAT approach to multi-agent path finding under the sum of
costs objective.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      22nd European Conference on Artificial Intelligence (ECAI)
     </em>
     ,
volume 285 of
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.2.2">
      Frontiers in Artificial Intelligence and Applications
     </em>
     ,
pp.  810–818. IOS Press, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tan, S., Ivanovic, B., Weng, X., Pavone, M., and Kraehenbuehl, P.
    </span>
    <span class="ltx_bibblock">
     Language conditioned traffic generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      arXiv preprint arXiv:2307.07947
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L.,
Canton-Ferrer, C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu,
J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A.,
Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M.,
Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M., Lavril, T., Lee, J.,
Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P.,
Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K.,
Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B.,
Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y.,
Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S.,
and Scialom, T.
    </span>
    <span class="ltx_bibblock">
     Llama 2: Open foundation and fine-tuned chat models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      CoRR
     </em>
     , abs/2307.09288, 2023.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.48550/ARXIV.2307.09288
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2307.09288" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2307.09288
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K., Hernandez, A. O., Sreedharan, S., and Kambhampati, S.
    </span>
    <span class="ltx_bibblock">
     Large language models still can’t plan (A benchmark for llms on
planning and reasoning about change).
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      CoRR
     </em>
     , abs/2206.10498, 2022.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.48550/ARXIV.2206.10498
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2206.10498" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2206.10498
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K., Marquez, M., Sreedharan, S., and Kambhampati, S.
    </span>
    <span class="ltx_bibblock">
     On the planning abilities of large language models–a critical
investigation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      arXiv preprint arXiv:2305.15771
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Wang, Y.-J., Zhang, B., Chen, J., and Sreenath, K.
    </span>
    <span class="ltx_bibblock">
     Prompt a robot to walk with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2309.09969
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Wang, Z., Mao, S., Wu, W., Ge, T., Wei, F., and Ji, H.
    </span>
    <span class="ltx_bibblock">
     Unleashing cognitive synergy in large language models: A
task-solving agent through multi-persona self-collaboration.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      CoRR
     </em>
     , abs/2307.05300, 2023b.
    </span>
    <span class="ltx_bibblock">
     doi:
     <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">
      10.48550/ARXIV.2307.05300
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2307.05300" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2307.05300
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H.,
Le, Q. V., and Zhou, D.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in large language
models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      NeurIPS
     </em>
     , 2022.
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html" target="_blank" title="">
      http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X.
    </span>
    <span class="ltx_bibblock">
     Large language models as optimizers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2309.03409
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2210.03629
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ye et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Ye, S., Hwang, H., Yang, S., Yun, H., Kim, Y., and Seo, M.
    </span>
    <span class="ltx_bibblock">
     In-context instruction learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2302.14691
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhang, H., Du, W., Shan, J., Zhou, Q., Du, Y., Tenenbaum, J. B., Shu, T., and
Gan, C.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2307.02485
     </em>
     , 2023.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Complete System Prompt
  </h2>
  <figure class="ltx_figure" id="A1.F8">
   <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="A1.F8.2" style="border-color: #000000;">
    <span class="ltx_p" id="A1.F8.2.1">
     <span class="ltx_text" id="A1.F8.2.1.1" style="font-size:90%;">
      You are a decision-maker in a warehouse system that is running as a 4-connected grid-based multi-agent path finding system of
      <span class="ltx_text" id="A1.F8.2.1.1.1" style="color:#0000FF;">
       [[Map Description]]
      </span>
      . You will be provided with the current scenario in which you need to choose actions for each agent, i.e., the detailed information that provides where the obstacles are, together with each agent’s current location and goal locations. The objective is to minimize the time of the agent who arrives at its goal location at the latest while keeping no agents from colliding with each other at any timestep. You only need to consider collision between two agents located in the same cell after each move. On each timestep, you could choose one action from moving up, moving down, moving left, moving right, and staying without moving. You should try to avoid collisions not only in the current timestep but also look ahead to a few timesteps if it is important to avoid future collisions. Remember that to avoid a collision, normally, only one agent needs to change their action from the original action. Nevertheless, your job is not to generate a whole path but to do it step-by-step, and the information on whether a specific action is valid or not is provided in each single step. Remember that the given action is based on the obstacles, so the available action will not change if the agent chooses to stay at the same location. You only need to give a single-step action for each agent to follow; do not give more steps until I tell you to.
First, give your solution in the same format as follows, with some explanation if the agent is not moving or moving in a direction that is not towards its goal. (This is not the actual scenario, but an example of the desired output format. You will be provided with the actual scenario later):
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.2">
     <span class="ltx_text" id="A1.F8.2.2.1" style="font-size:90%;">
      Step 1:
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.3">
     <span class="ltx_text" id="A1.F8.2.3.1" style="font-size:90%;">
      Agent 1:
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.4">
     <span class="ltx_text" id="A1.F8.2.4.1" style="font-size:90%;">
      Current: (1,0)
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.5">
     <span class="ltx_text" id="A1.F8.2.5.1" style="font-size:90%;">
      Goal: (1,0)
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.6">
     <span class="ltx_text" id="A1.F8.2.6.1" style="font-size:90%;">
      Move: Stay, as it has already reached its goal.
      <br class="ltx_break"/>
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.7">
     <span class="ltx_text" id="A1.F8.2.7.1" style="font-size:90%;">
      Agent 2:
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.8">
     <span class="ltx_text" id="A1.F8.2.8.1" style="font-size:90%;">
      Current: (5,4)
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.9">
     <span class="ltx_text" id="A1.F8.2.9.1" style="font-size:90%;">
      Goal: (5,6)
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.10">
     <span class="ltx_text" id="A1.F8.2.10.1" style="font-size:90%;">
      Move: Up to (5,5)
      <br class="ltx_break"/>
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.11">
     <span class="ltx_text" id="A1.F8.2.11.1" style="font-size:90%;">
      Agent 3:
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.12">
     <span class="ltx_text" id="A1.F8.2.12.1" style="font-size:90%;">
      Current: (0,7)
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.13">
     <span class="ltx_text" id="A1.F8.2.13.1" style="font-size:90%;">
      Goal: (6,4)
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.14">
     <span class="ltx_text" id="A1.F8.2.14.1" style="font-size:90%;">
      Move: Right to (1,7)
      <br class="ltx_break"/>
     </span>
    </span>
    <span class="ltx_p" id="A1.F8.2.15">
     <span class="ltx_text" id="A1.F8.2.15.1" style="font-size:90%;">
      Then, validate your solution by listing all the coordinates of the agents after the move and check if there is any pair of agents that have the same coordinates. If there is a collision by mistake, regenerate another solution immediately and validate again by listing the coordinates of all the agents until you get a collision-free solution. Finally, end your output with your validated solution in a new paragraph with the format of a sequence of : [[Agent_id]]: [[Coordinate]].
     </span>
    </span>
   </span>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A1.F8.3.1.1" style="font-size:90%;">
      Figure 8
     </span>
     :
    </span>
    <span class="ltx_text" id="A1.F8.4.2" style="font-size:90%;">
     An example of the system prompt to specify the MAPF system and the objective. The text highlight in blue will be replaced by map description. For example, in room-32-32-4, the prompt will be ’room-like map with size 32*32’.
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    In Fig.
    <a class="ltx_ref" href="#A1.F8" title="Figure 8 ‣ Appendix A Complete System Prompt ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    , we give our system prompt. Between different map, the only thing changed is the text highlighted in blue, and all others part are the same.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Token Length Grows
  </h2>
  <figure class="ltx_figure" id="A2.F9">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="287" id="A2.F9.g1" src="/html/2401.03630/assets/figs/avg_token.png" width="359"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A2.F9.2.1.1" style="font-size:90%;">
      Figure 9
     </span>
     :
    </span>
    <span class="ltx_text" id="A2.F9.3.2" style="font-size:90%;">
     Average token length per agent step on success scenarios.
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="A2.p1">
   <p class="ltx_p" id="A2.p1.1">
    In Fig.
    <a class="ltx_ref" href="#A2.F9" title="Figure 9 ‣ Appendix B Token Length Grows ‣ Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet">
     <span class="ltx_text ltx_ref_tag">
      9
     </span>
    </a>
    , we show the average prompt length per agent per step, which includes both the input and the output. We found that with the growing number of agents, this average is also growing, which means that the output length is growing faster than linear. This contributes to the fact that the more agents, the more complex the environment, and thus, the longer explanation and more iterations until a correct plan is needed. We also observe that on failing scenarios where the agents are going back and forth, the token length is generally shorter, given that they did not run into the iterative deconflict process, which takes a lot of tokens to solve.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
</article>
