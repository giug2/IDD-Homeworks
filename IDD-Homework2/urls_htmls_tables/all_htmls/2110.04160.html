<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2110.04160] Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions</title><meta property="og:description" content="Big data has remarkably evolved over the last few years to realize an enormous volume of data generated from newly emerging services and applications and a massive number of Internet-of-Things (IoT) devices. The potent…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2110.04160">

<!--Generated on Fri Mar  1 22:56:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Thippa Reddy Gadekallu, Quoc-Viet Pham, Thien Huynh-The,
<br class="ltx_break">Sweta Bhattacharya, Praveen Kumar Reddy Maddikunta, and Madhusanka Liyanage
</span><span class="ltx_author_notes">Thippa Reddy Gadekallu, Sweta Bhattacharya, Praveen Kumar Reddy Maddikunta are with School of Information Technology and Engineering, Vellore Institute of Technology, India (e-mail: {thippareddy.g, sweta.b, praveenkumarreddy}@vit.ac.in).Quoc-Viet Pham is with Korean Southeast Center for the 4th Industrial Revolution Leader Education, Pusan National University, Busan 46241, Korea (e-mail: vietpq@pusan.ac.kr).Thien Huynh-The is with ICT Convergence Research Center, Kumoh National Institute of Technology, Republic of Korea. (e-mail: thienht@kumoh.ac.kr).Madhusanka Liyanage is School of Computer Science, University Collage Dublin, Ireland and Centre for Wireless Communications, University of Oulu, Finland, Ireland (e-mail: madhusanka@ucd.ie and madhusanka.liyanage@oulu.fi).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text">Big data has remarkably evolved over the last few years to realize an enormous volume of data generated from newly emerging services and applications and a massive number of Internet-of-Things (IoT) devices. The potential of big data can be realized via analytic and learning techniques, in which the data from various sources is transferred to a central cloud for central storage, processing, and training. However, this conventional approach faces critical issues in terms of data privacy as the data may include sensitive data such as personal information, governments, banking accounts. To overcome this challenge, federated learning (FL) appeared to be a promising learning technique. However, a gap exists in the literature that a comprehensive survey on FL for big data services and applications is yet to be conducted. In this article, we present a survey on the use of FL for big data services and applications, aiming to provide general readers with an overview of FL, big data, and the motivations behind the use of FL for big data. In particular, we extensively review the use of FL for key big data services, including big data acquisition, big data storage, big data analytics, and big data privacy preservation. Subsequently, we review the potential of FL for big data applications, such as smart city, smart healthcare, smart transportation, smart grid, and social media. Further, we summarize a number of important projects on FL-big data and discuss key challenges of this interesting topic along with several promising solutions and directions.</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
<span id="id2.id1" class="ltx_text">
Big Data, Federated Learning, Smart City, Smart Healthcare, Smart Transportation
</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Due to the digitization and advancements in several information and communication technologies like Internet of Things (IoT), communication technologies, smart cities, industrial IoT, stock market, etc., an exponential growth is seen in the data traffic globally. It is expected that the big data market may reach around 230 billion $ by the year 2025. Almost all the verticals of industries like entertainment, retail, media, manufacturing, healthcare, social media, etc. benefit from the big data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Big data has attracted a great deal of attraction from from academia and industry in recent years. Big data has a potential to solve many of the challenging problems in several sectors. The big datasets can be analyzed to uncover patterns through data analytics that attracted the researchers. Some of the examples where big data can play a very important role include using the consumer data, radio frequencies, data from social media, and global position systems for improving several sectors in urban life such as energy, transportation, education, etc. in a smart city, predicting the patients with high risk of cardiac arrests and other health related risks in real time through predictive analytics using the large volumes of electronic health records, etc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Even though big data is used prominently in today’s world, there is still a vagueness in the definition of ”big data”. According to European Commission, big data is large quantity of several types of data generated from different sources like machines, people, or sensors. The data generated may be related to videos, posts in social media, digital images, satellite imagery, and climate information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Big data datasets are of tremendously large sizes with huge dimensions, that cannot be captured, stored, managed, or processed by traditional database technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Several characteristics of big data include volume, velocity, veracity, variety <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The true potential of big data can be realized only when the value is extracted from massive data by data analytics; where machine learning (ML) plays a very important role due to its ability to understand the patterns and provide insights by learning from the data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. ML algorithms can be categorized as supervised ML and unsupervised ML. In supervised ML, the algorithms know both the inputs as well as outputs in prior and the ML algorithms learn how to map inputs to the outputs. Classification and regression are examples of supervised ML. In unsupervised ML, the outputs are not known to the ML algorithms but they discover the patterns within the data on their own. Clustering is an example for unsupervised ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Traditionally, the data gathered from several big data sources is transferred to a central cloud, where the ML algorithms are trained to understand the patterns from the stored data. This approach of training the big data in a central cloud faces several challenges such as exposing of sensitive information (privacy preservation), incurring additional costs in terms of communication and resources, data management and increased latency which make the real-time analytics very difficult <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Among these challenges privacy and security are considered to be very important as sensitive data related to people, vehicles, governments, and organizations can be exposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated learning (FL) is a recent development in ML, where, instead of transferring of the raw data captures from several sources to the central model located at the server and then training the ML algorithms, the global ML algorithm itself is offloaded to the devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. In FL, only the parameters from the local devices are transferred to the central ML algorithm for global training and predictions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. This property of FL has a great potential to solve the aforementioned issues in big data. It is proven in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> that FL can be used as an efficient solution to address the challenges of big data.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.5.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.6.2" class="ltx_text ltx_font_italic">Motivation and Our Contributions</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Owing to the importance and practicality of FL and big data, there have been a number of surveys on these two topics. Several in-depth surveys on FL and its applications can be found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. For example, the applications of FL for wireless and IoT networks are discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. In particular, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> reviews FL-enabled solutions for resource allocations, reducing communications, mitigating privacy and security issues at mobile edge networks. A comprehensive survey of FL for IoT is presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, where FL is used to enable IoT services such as data sharing, data offloading, attack detection, localization, and mobile crowdsensing, and IoT applications such as smart city, smart industry, smart healthcare, and smart transportation. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> reviews the integration of FL with industrial IoT (IIoT) from three perspectives, including security, data management, and IIoT applications. There are several surveys that discuss the security, privacy, and threat issues of FL, for example, security and privacy issues in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and threats of FL in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. The use of FL is also reviewed for other applications such as healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, vehicular networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, and open banking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Although these surveys on FL are extensive and can provide various lessons and future directives for the use of FL, they are very limited from the big data perspective, where big data services and applications are important.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">In terms of big data, in-depth review articles can be found in many existing works. For example, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> provides a concise review on big data, including 1) relation of big data with enabling technologies such as IoT and cloud computing, 2) big data generation, acquisition, and storage, 2) big data applications such as social network, healthcare, and collective intelligence, and 4) a set of key issues and potential outlooks.
There are also survey that focus on characteristics, roles, and applications of big data for specific field applications such as intelligent transportation systems, smart building, smart girds, IoT, and mobile networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. In particular, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> first presents a framework of big data in intelligent transportation systems, in which how big data is generated, collected, and processed is explained in detail, and important use cases such as accident analysis, traffic flow prediction, public transportation services, traffic route planning, asset management, and road control and management.
The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> surveys big data for IoT. In particular, this work focuses on reviewing big data technologies and approaches for different IoT domains, including healthcare, energy, transportation, building automation, smart cities, agriculture, industry, and military. This work also focuses on comparing big data approaches for different IoT domains and summarizing key findings on the use of big data across IoT domains.
A recent survey in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> classifies big data deployment models and big data environments based on characteristics of the underlying network. First, four important features are presented from the deployment requirements, including resource management, security management, task management, and data management. Then, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> presents big data environments such as cloud computing, decentralizing computing, and hybrid computing (i.e., a set of computing paradigms such as cloud computing, fog computing, and edge computing).
Although the topic of big data has been well studied and reviewed in many surveys, the existing works only review artificial intelligence/machine learning for big data tasks, such as modeling, processing, and analytics, whereas the use of FL for big data has not been reviewed yet. The recent reviews on FL and big data are summarized in Table <a href="#S1.T1" title="Table I ‣ I-A Motivation and Our Contributions ‣ I Introduction ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table I: </span>Summary of related review papers on federated learning and big data.</figcaption>
<table id="S1.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.3.1.1" class="ltx_tr">
<th id="S1.T1.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.1.1.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ref</span></span>
</span>
</th>
<th id="S1.T1.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.1.1.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Contributions</span></span>
</span>
</th>
<th id="S1.T1.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.1.1.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.3.2.1" class="ltx_tr">
<td id="S1.T1.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.2.1.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.2.1.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.2.1.2.1.1.1" class="ltx_text" style="font-size:90%;">A preliminary to FL is presented, followed by a thorough review of FL-enabled solutions for privacy, resource allocation, and applications to mobile edge networks.</span></span>
</span>
</td>
<td id="S1.T1.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.2.1.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.2.1.3.1.1.1" class="ltx_text" style="font-size:90%;">This survey only focuses on the use of FL at mobile edge networks.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.3.2" class="ltx_tr">
<td id="S1.T1.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.3.2.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.3.2.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.3.2.2.1.1.1" class="ltx_text" style="font-size:90%;">A comprehensive survey of FL for IoT services and IoT applications is presented.</span></span>
</span>
</td>
<td id="S1.T1.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.3.2.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.3.2.3.1.1.1" class="ltx_text" style="font-size:90%;">This survey only presents the use of FL for IoT services and applications.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.4.3" class="ltx_tr">
<td id="S1.T1.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.4.3.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.4.3.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.4.3.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.4.3.2.1.1.1" class="ltx_text" style="font-size:90%;">A survey on fusion of FL and IIoT (e.g., background, data management, and IIoT applications) is presented.</span></span>
</span>
</td>
<td id="S1.T1.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.4.3.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.4.3.3.1.1.1" class="ltx_text" style="font-size:90%;">This survey does not focus on the use of FL for big data.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.5.4" class="ltx_tr">
<td id="S1.T1.3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.5.4.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.5.4.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.5.4.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.5.4.2.1.1.1" class="ltx_text" style="font-size:90%;">The sources of privacy/security/threat issues, types of attacks, unique features, and potential defensive solutions for FL.</span></span>
</span>
</td>
<td id="S1.T1.3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.5.4.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.5.4.3.1.1.1" class="ltx_text" style="font-size:90%;">These works are only limited to security/privacy/threat aspects of FL.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.6.5" class="ltx_tr">
<td id="S1.T1.3.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.6.5.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.6.5.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.6.5.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.6.5.2.1.1.1" class="ltx_text" style="font-size:90%;">The use of FL for particular applications, e.g., healthcare, vehicular IoT, and open bank are presented.</span></span>
</span>
</td>
<td id="S1.T1.3.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.6.5.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.6.5.3.1.1.1" class="ltx_text" style="font-size:90%;">These studies do not focus on the role of FL for big data services and applications.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.7.6" class="ltx_tr">
<td id="S1.T1.3.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.7.6.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.7.6.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.7.6.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.7.6.2.1.1.1" class="ltx_text" style="font-size:90%;">A concise review on background, key techniques, and important applications of big data</span></span>
</span>
</td>
<td id="S1.T1.3.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.7.6.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.7.6.3.1.1.1" class="ltx_text" style="font-size:90%;">This survey was done before the invention of FL, and thus lacks the role of FL for big data services and applications.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.8.7" class="ltx_tr">
<td id="S1.T1.3.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.8.7.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.8.7.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.8.7.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.8.7.2.1.1.1" class="ltx_text" style="font-size:90%;">A comprehensive survey of big data for intelligent transportation systems, including big data characteristics, applications, and platforms.</span></span>
</span>
</td>
<td id="S1.T1.3.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.8.7.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.8.7.3.1.1.1" class="ltx_text" style="font-size:90%;">This survey only focuses on machine learning for big data modeling and analytics, while the use of FL is ignored.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.9.8" class="ltx_tr">
<td id="S1.T1.3.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.9.8.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.9.8.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.9.8.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.9.8.2.1.1.1" class="ltx_text" style="font-size:90%;">This survey reviews the state-of-the-art big data technologies for different IoT domains and presents key findings when big data is used across IoT domains.</span></span>
</span>
</td>
<td id="S1.T1.3.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.9.8.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.9.8.3.1.1.1" class="ltx_text" style="font-size:90%;">The use of FL for big data services and applications is not presented.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.3.10.9" class="ltx_tr">
<td id="S1.T1.3.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;" rowspan="2">
<span id="S1.T1.3.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.10.9.1.1.1" class="ltx_p" style="width:37.0pt;"><span id="S1.T1.3.10.9.1.1.1.1" class="ltx_text" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite></span></span>
</span>
</td>
<td id="S1.T1.3.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.10.9.2.1.1" class="ltx_p" style="width:226.2pt;"><span id="S1.T1.3.10.9.2.1.1.1" class="ltx_text" style="font-size:90%;">This work presents two important aspects of big data: deployment requirements and network environments</span></span>
</span>
</td>
<td id="S1.T1.3.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S1.T1.3.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.3.10.9.3.1.1" class="ltx_p" style="width:213.4pt;"><span id="S1.T1.3.10.9.3.1.1.1" class="ltx_text" style="font-size:90%;">The use of AI and FL for big data services and applications is not presented.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">Despite a number of important review articles on FL and big data, a comprehensive survey on the use of FL for big data has not been done yet. To fill this research gap, we aim to provide a concise survey on FL for big data. In particular, we focus on highlighting the opportunities that FL brings to big data services and applications. In summary, contributions and features offered by our work can be summarized as follows.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">A preliminary to FL and big data</span>: Firstly, we present the fundamentals of FL and big data and discuss various motivations behind the use of FL for big data services and applications, such as mitigating security and privacy issues, reducing communication cost, handling the issue of data variety, easing the big data analysis, and improving the system scalability. We will detail this part in Section <a href="#S2" title="II Federated Learning and Big Data: An Overview ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">FL for big data services</span>: FL plays an important role in big data services such as big data acquisition, big data storage, big data analytics, and big data privacy preservation. We review the use of FL for these big data services in detail in Section <a href="#S3" title="III Federated Learning for For Big Data Services ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">FL for big data applications</span>: Next, we review FL-empowered big data in vertical domain applications, including smart city, smart healthcare, smart transportation, smart grid, online recommendation systems, social media, and several miscellaneous applications.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">A review of practical projects on FL-big data</span>: Several practical projects on FL-big data are reviewed so as to drive real implementations of the FL-big data solutions.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p"><span id="S1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Key challenges and promising directions on FL-big data</span>: Despite various advantages, the use of FL for big data also faces challenging problems such as bottleneck in communication efficiency, data heterogeneity, statistical heterogeneity, and privacy issues. These challenges will be explained in detail in Section <a href="#S6" title="VI Research Challenges and Future Directions ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> along with potential directions of FL-big data.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.5.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.6.2" class="ltx_text ltx_font_italic">The Survey Organization</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">The organization of this paper is as follows. In Section <a href="#S2" title="II Federated Learning and Big Data: An Overview ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we present the fundamental concepts of big data and FL, and the motivations behind their integration. Next, in Sections <a href="#S3" title="III Federated Learning for For Big Data Services ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> and <a href="#S4" title="IV Federated Learning enabled Big Data Applications ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, we present the use of FL for various big data services and applications, respectively. After that, we review a number of projects in Section <a href="#S5" title="V Federated Learning Big Data Projects ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> to show the practicality of the FL for big data. In Section <a href="#S6" title="VI Research Challenges and Future Directions ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>, we then discuss some research challenges and highlight promising future directions to further drive the use of FL for big data. Finally, we conclude the paper in Section <a href="#S7" title="VII Conclusions ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning and Big Data: An Overview</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we discover the fundamental concepts of FL and big data.
The motivations of their integration is given correspondingly.
</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Recognized as a new learning paradigm where statistical models are trained on multiple edge devices in a distributed network without sharing their training data, FL provides AI tools to train a model collaboratively by using a federated dataset of secure sources.
With the increasing computational power and storage capacity of smart devices (e.g., mobile phones, wearable devices, and autonomous vehicles), storing data and and processing data are executed at the edge locally in distributed networks, especially in this era when the information privacy is priority.
Transmitting raw data of mobile devices over wireless communications is so sensitive to cyberattacks, which in turn forces the rapid growth of FL.
Here we discover the operation of FL, give some common FL categories, and discuss its core challenges. A general FL architecture with processing flow is presented in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Federated Learning ‣ II Federated Learning and Big Data: An Overview ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2110.04160/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>General architecture of FL with processing flow.</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Taxonomy of FL</span>
Based on the examination of existing FL frameworks, we categorize FL regarding training data property and networking topology.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Data property</span>: This category can be divided into three sub-classes, including horizontal FL (HFL), vertical FL (VFL), and federated transfer learning (FTL), based on the properties of training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Horizontal FL: In HFL frameworks, the edge devices local train statistical models using their own datasets having the same feature space, but different sample space.
Due to this property of input training data, all devices should utilize a same AI model (e.g., support vector machine and deep neural networks).
For an example of HFL applications, the hospitals collect the health data of different patients with the electronic medical records having the same attributes.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Vertical FL: Different from HFL, VFL is introduced for the scenarios, in which the local datasets share the same samples but differ in features.
To collect overlapping data samples in different edge devices, an entity alignment mechanism is utilized.
For an example of VFL scenarios, different hospitals collect the health data of the same patient but differ in attributes, such as diabetic retinopathy in hospital A, cardiovascular disease in hospital B, and diabetic nephropathy in hospital C.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">Federated transfer learning: FTL is proposed for the unrelated learning scenarios, in which the local datasets totally differ in sample space and feature space.
In this framework, the knowledge of local models is transferred across domains by the FTL server.
For example, in the healthcare domains, disease diagnosis can be collaborated by multiple hospitals in different countries, where the electronic medical records of various tests are collected from different patients.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Network topology</span>: Based on the network topology of model communications, this category can be divided into two sub-classes: centralized FL and decentralized FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">In a centralized FL system, all devices transmit the trained parameters of local models to the FL server for updating the global model with a parameter aggregation algorithm. Afterwards the sever delivers the computed global model to all clients in a network for the next training iteration.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">In a decentralized FL system, all devices are connected over peer-to-peer communications. A device can transmit the model parameters, locally trained on its own dataset, to neighbors and receive their model updates to aggregate parameters.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Big Data</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Nowadays, a massive data volume are generated daily with unprecedentedly increasing rate from heterogeneous sources.
This is due to the emergence of the internet of things, the proliferation of the cloud computing, and the spread of smart devices.
In fundamental, big data refers to massive datasets with heterogeneous formats: structured, unstructured, and semi-structured data, which has three key characteristics: large volume with the incessant generation from millions of devices and applications, high velocity with the real-time data acquisition and processing, and high variety with various source and multiple formats.
<span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Taxonomy of big data</span>
Here we present a taxonomy of big data in various perspectives, including data domain, storage infrastructure, compute infrastructure, and AI-based data processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. This taxonomy is illustrated in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-B Big Data ‣ II Federated Learning and Big Data: An Overview ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Data domain</span>: Various domains, in which big data has being arisen in the last decade, can be determined based on the time span of processing and the degree of data structure.
For the time span of data processing analysis, data domain can be classified into three groups: batch (including bioinformatics, geosciences, forensics, and other large-scale sciences), near real-time (including retail and sensory data), and real-time (including finance, social networking, and network security) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
We can also classify various domains into three degrees of structure: structured data - containing relational databases and spreadsheets (including retail, finance, bioinformatics, and geosciences), unstructured data - containing raw signals from nature or data without pre-defined structural model (including voice, image, video, and sensory data), and semi-structured data - as the hybrid form of structured and unstructured data (including web logs, email, and documents).
Notably, relying on specific applications, the visual media domain with high-dimensional unstructured data can spread from batch to real-time of time span <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Storage infrastructure</span>: Numerous big data storage solutions have been introduced to engineers and developer when they build services and applications running with large datasets. In Fig. <a href="#S2.F2" title="Figure 2 ‣ II-B Big Data ‣ II Federated Learning and Big Data: An Overview ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we can find the taxonomy of different types of databases being used for big data storage. The storage platforms in the relational structured query language (SQL) group are with some features: speed over scale, large capacity for vertical scaling, good consistency over availability, and easy deployment.
Inspired by relational SQL, newSQL offers higher performance and scalability, thus enables high throughput online transaction processing requests while maintaining high-level language query capability.
In the nonSQL group, we have several database techniques for specific purposes, such as document oriented, graph oriented, key-value storage, and big table inspired.
Although numerous database platforms have been introduced for diversified services and applications with different data types, they should comply with some standards, for example ACID (atomicity-consistency-isolation-durability) and BASE (basically available-soft state-eventually consistent).</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_bold">Compute infrastructure</span>: Based on the time span metric, computing paradigms for big data can be classified into two primary categories: batch mode and real-time/near real-time mode.
For the batch mode with high processing latency, MapReduce and Bulk synchronous parallel are recommended for large parallel and distributed systems.
Whereas low-latency computing frameworks for streaming demand immediate response to every incoming event. Some popular frameworks in this group are Infosphere, Apache Storm, and Apache Spark.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p"><span id="S2.SS2.p5.1.1" class="ltx_text ltx_font_bold">AI-based data processing</span>: Artificial intelligence (AI) techniques and machine learning (ML) algorithms allows analyzing and processing data in automatic and scalable ways, in which the high-level information and meaningful context can be derived from raw data.
ML allows computers to learn complicated patterns automatically and make decisions of new incoming data events <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
Depending on data utilization of model learning, these algorithms can be categorized into four classes: supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.
Recently, deep learning has emerged with recurrent neural network, convolutional neural network, and self-organizing map, which has achieved remarkable success in various domains due to the great capability of dealing with large noisy-messy-confusing datasets.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2110.04160/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="297" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Taxonomy of big data technology.</figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Motivations of the Integration</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">With the unprecedented growth of IoT services and applications, traditional AI/ML techniques based on centralized computing platforms have exposed several issues: security, privacy, variety, communication, analysis, and scalability.
With the ability to train statistical models on own datasets of edge devices locally and then transfer model parameters to the centralized server for global model aggregation, FL is recognized as a promising solution to solve these above-mentioned problems of big data.
Along with the integration of FL and big data, the main motivations behind such kind of this integration are summarized as follows.
</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><span id="S2.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Security and data privacy</span>: To extract meaningful information and capture patterns of the data generated by edge devices, traditional AI and ML algorithms are usually adopted in the centralized server to train statistical learning models. To this end, the data should be transferred from devices to the server for training a model, which in turn exposes some security and privacy risks over cyberattacks. Instead of uploading data to the server, FL allows devices to train models with their datasets locally and transfer model parameters to the server for aggregation.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><span id="S2.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Communication cost</span>: A massive volume of raw sensory data and low-level informative data of clients should be transferred to the centralized server for processing, which consequently suffers a considerable communication cost, especially with high-dimensional unstructured data like images and videos. With FL, the communication cost reduces significantly owning to transferring trained statistical models to the FL server instead of the entire data.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p"><span id="S2.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Data variety</span>: In several integrated services and applications, the multimodal sensory data acquired from various sources has different types and structures (structured data vs unstructured data and time series data vs high-dimensional data), which in turn makes difficult to manage in the big data server deploying a specific storage platform. Besides, each data type characterized by various attributes will demand a specific computing infrastructure to achieve best performance of target services and applications. With FL, each devices and clients may take into consideration a specific data type locally, thus reducing the complexity of local data management at the FL server.</p>
</div>
</li>
<li id="S2.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i4.p1" class="ltx_para">
<p id="S2.I3.i4.p1.1" class="ltx_p"><span id="S2.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Analysis</span>: In many centralized computing systems, learning classification and regression models with the multimodality data can be accomplished using advanced methods (e.g., data-based, feature-based, and decision-based fusing mechanism), but its processing framework will be much more complicated. Whereas FL can offer a universal DL model to different data modalities of a same learning task.</p>
</div>
</li>
<li id="S2.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i5.p1" class="ltx_para">
<p id="S2.I3.i5.p1.1" class="ltx_p"><span id="S2.I3.i5.p1.1.1" class="ltx_text ltx_font_bold">Scalability</span>: In conventional centralized systems, the scalability of storage and computing infrastructures at the server is problematic because of the complex nature of big data with 5Vs. In the FL platforms, the server only performs an aggregation function with multiple locally trained models to modernize the global model, hence system scalability is capable of performing at edge devices. Intuitively, the scalability of FL is more flexible and convenient than that of centralized learning in the server.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning for For Big Data Services</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">FL can play a very crucial role in big data services such as acquisition of big data, storage of big data. big data analytics, and privacy preservation of big data. In this section, the role of FL for big data services is discussed along with recent state-of-the-art. Fig. <a href="#S3.F3" title="Figure 3 ‣ III-A Federated Learning for Big Data Acquisition ‣ III Federated Learning for For Big Data Services ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates FL for big data services.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Federated Learning for Big Data Acquisition</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The exponential growth of AI, ML, and Big data analytics has a major impact on a wide range of applications, including health care system, smart grid, smart cities, intelligent transport systems, and so on. Due to the rapid growth of the applications, large volumes of data are being generated at an exponential rate, encouraging the applications to generate the data at a rapid pace. Moreover, some companies and organisations employ advanced artificial intelligence (AI) approaches and big data analytics to quickly identify consumer behaviour in order to increase productivity, sales, and profits. Data sharing is a key problem in AL and ML to fulfil these requirements. Acquiring public data and performing data analytics, is not a perfect solution since public data has constraints such as poor data quality, inconsistency, and unstructured. Most of the companies prefer not to share their data for a variety of reasons and concerns, such data privacy, data sharing rules, and a lack of information.Some times the companies may occasionally share information with third parties in order to facilitate growth and mutual data cooperation agreements. The primary goal of FL is to train ML algorithms across other distributed devices using its own private and local data. The locally trained models are first transmitted to the server, and then all of the shared models are combined with other updates to build a better global model, which is then shared with all devices. The main advantage of FL is that the training data is held on the device, with no individual updates sent to the cloud.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2110.04160/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="111" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>FL for big data services.</figcaption>
</figure>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.5.1.1" class="ltx_text">III-A</span>1 </span>Federated Learning for Secure Big Data Collection</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">The most important aspect of FL is that it helps in training shared statistical on the basis of decentralized devices or servers in a local data set. Although the data scientists and researchers use similar model to train the data, the use of FL eliminates the need to upload private data to the cloud or the exchanging of data with other members in the scientific community. In case of traditional machine learning approaches wherein the data resides on a single server, FL reduces the challenges associated with achievement of data security and privacy by maintaining the storage of local data. FL has been extremely successful in handling the various challenges relevant to user privacy protection thereby achieving data security. In FL, the data provisioned at the end-user systems is decoupled and the machine learning models are aggregated ensuring involvement of network parameters in the implementation of deep learning at the centralized server. The primary objective of FL is to understand and learn the global model without compromising with the data privacy. IT has unique abilities to achieve data privacy while training the data in a dataset. In case of ”anonymized” dataset stored in a server, there are possibilities of client privacy getting compromised if the dataset is linked to other datasets in the framework. On the contrary, in case of FL the information transmitted using FL has minimum updates which contributes in improvement of accuracy in a machine learning model. One of the studies conducted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> used a Verifiable FL (VFL) to enable preservation of privacy for Big Data in an Industrial IoT setting. Although the traditional deep learning techniques have been quite successful, but in case of privacy preservation, the traditional data gathering based centralized learning fails to achieve privacy and security in industrial scenarios for the training of data. In a VFL setup, instead of gradient aggregation, Lagrange interpolation is used to set the interpolation points which helps to validate the accuracy of the aggregated gradients. The verification overhead of VFL thus remains constant inspite the number of participants which help in getting optimum level of accuracy. Another example of FL implementation in big data security is found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. It is a known fact that the credit card transaction datasets are generally skewed and the number of data relevant to fraudulant activities are quite less. Hence it becomes extremely difficult to understand and analyse patterns of frauds and later detect actual frauds. The study proposed a FL for Fraud Detection (FFD) framework which enabled the banks to learn the fraud detection model by training the data distributed in their localised database. The FDS is constructed by the aggregation of local computational updates of the fraud detection model. The banks thus can achieve data privacy without having to share the data or sensitive information of the card holders.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.5.1.1" class="ltx_text">III-A</span>2 </span>Federated Learning for Secure Big Data Sharing</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">Data sharing in big data applications helps in transferring data in a shared network in order to help end users access and use various applications. FL eliminates the process of sharing raw data and takes an alternative approach of sharing the learned results for preserving privacy and ensuring low latency of applications. The study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> discusses a integrated data sharing model implemented for industrial IoT systems. The data owners and requestors in the study are able to achieve fast and secure exchange of data within the involved decentralized parties. The FL scheme also addresses considers resource constraint issues of IoT systems. The study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> implemented a framework for a scenario based on industrial IoT, in which FL is used to achieve optimal level of security. In this work, various factories collaborate with the tensor mining to share their data which are encrypted using homomorphic encryption technique in the centralized server. FL can also be implemented to achieve distributed data sharing in vehicular networks. Towards this direction, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> presented an asynchronous federated data sharing architecture for internet of vehicles. In this case, the vehicle is an FL client used to share data with the aggregation server located at macro base station (MBS). The vehicles with various service requests pertinent to prediction of traffic or path detection post their requests to the MBS. The MBS implements computing tasks to resolve these requests using an actor-critic reinforcement learning framework. Thus, the system segregates good and bad nodes, enables secured and intelligent data sharing, decision making, thereby ensuring cost optimization.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Federated Learning Big Data Storage</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In this subsection, we discuss how FL can be used for storage of big data.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.5.1.1" class="ltx_text">III-B</span>1 </span>Federated Learning for Secure File Systems</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">In traditional FL, due to some reasons, if the central server becomes unavailable, the entire training process will be disrupted. The server should also have high-bandwidth and reliable communication links with the agents to transfer big data. Also, all the agents should trust the server. To overcome the aforementioned issues, a decentralized approach, where the model relies on the own resources of the node, can be used as an alternative to perform the training. Pappas et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> proposed a decentralized FL framework, called, interplanetary learning system, that is inspired by interplanetary file system. The proposed framework allows mobile agents to collaborate in the model’s training that doesn’t rely on any central server.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.5.1.1" class="ltx_text">III-B</span>2 </span>Federated Learning for Secure Data Management</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Due to the latest industrial revolution (Industry 4.0), the user equipments are distributed and widespread. Conventional network infrastructures are unsuitable for Industry 4.0 applications due to communication delays and transmission media costs. One of the major enablers of Industry 4.0 is Industrial IoT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. Several Industrial IoT applications like driverless cars, intelligent robots, smart medical systems, and smart grid are based on wireless networks that generate big data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Many researchers are working on efficient storage, usage, and management of big data generated from Industrial IoT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. The big data generated from Industrial IoT often contains private and sensitive information that should not be exposed as it is vulnerable to attacks from malware, heterogeneous equipments or heterogeneous networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. FL can address the aforementioned challenges in the management of big data generated from Industrial IoT devices as it preserves privacy of the users’ data by not allowing the global ML model to have access to the sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. FL can also maintain the heterogeneity of the data, hence reducing the deviation of training in ML model. To reduce the training rate of ML model on big data from Industrial IoT and to reduce the model aggregation’s communication cost, Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> proposed a framework based on FL assisted by deep reinforcement learning. In a similar work, Kim Sungwoork <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> proposed an incentive mechanism for attracting several owners of data for joining in the process of FL to preserve privacy and efficient management of data. The proposed approach adopts two concepts: mechanism design for designing incentives to achieve the objectives, and differential privacy for privacy preservation. Data management in real time is essential in remote monitoring of patients. To take the decisions in a timely manner, the processed data from the patients big data has to be provided to the care providers. Several issues, such as patient mobility and computational complexity may arise in processing the data in real time. FL can be used effectively in collaboration with technologies such as cloud computing and fog computing, ML based approaches to solve these issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">For handling the challenges and open issues in big data streams generated through IoT devices in smart cities in terms of processing of big data and networking, Imteaj et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> proposed a distributed sensing scheme that paves the way for FL for distributed decision making. In this scheme, a device can be identified by a token that can activate the user’s devices that are distributed for sending the data to the cloud dynamically and the data can be stored in the cloud in a proper format. The proposed approach ensures data collection remotely using the end-user devices that are available and hence the cost incurred in installing new sensors for IoT applications can be reduced.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS3.5.1.1" class="ltx_text">III-B</span>3 </span>Federated Learning for Data Storage Infrastructure</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">The standard machine learning techniques require training of the data in one machine or a data center. FL enables devices to learn from a shared prediction model ensuring that all the training data is stored in one device. It decouples the ability to implement machine learning based on the need to store data in the cloud. As an example, when a device downloads the current model, it improvises the same by learning from the data in the device and then summarizes the changes in the data as specific update to the model, which alone is sent to the cloud. In this process, encrypted communication technique is used wherein it gets immediately averaged with other updates that initiates improvement of the shared model. Thus all the training data remains on the local device and no updates get stored in the cloud. Thus it eliminates the need to store data in the cloud and also incorporates the use of ”Secure Aggregation Protocol” using cryptographic techniques such that a coordinating sever is able to decrypt only the average update when hundreds and thousands of users have participated. It does not allow any individual update to be inspected unless averaging is done <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Federated Learning for Big Data Analytics</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The growth in IoT based applications is resulting in generation of massive sensing data at a rapid pace. The generated data may contain important information that can be analyzed by understanding the patterns existing in the raw data. ML and allied technologies can be used effectively for big data analytics. Big data analytics require the participant sources to send their personal and sensitive data to a central sever to perform ML services, that may result in privacy concerns of the data sources such as mobile users. FL can be used efficiently to provide privacy reservation while providing big data analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. In this subsection, the application of FL for secure data training and securing the data in AI algorithms is discussed.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.5.1.1" class="ltx_text">III-C</span>1 </span>Federated Learning for Secure Data Training</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">The current approach of performing big data analytics in the cloud has concerns related to network cost and data privacy. FL can address these challenges by training the data in local devices and updating the global model with the local parameters without sharing the raw data. The recent state of the art FL for secured training of big data is presented below.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">Xu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> have proposed a novel framework based on FL, named FL-Pruning, Quantization and
Selective Updating (PQSU) to address the network connectivity issues and limited computational resources for performing big data analytics in IoT devices that slows down the training process. The proposed method consists of 3 phases, namely, structured pruning, quantization of weights and updating selective, that collaborate to reduce the storage, communication and computation costs, thereby fastening up of the training process of big data from IoT devices. In a similar work, to address the problem of leaking of sensitive information of the participants to the untrusted servers in big data analytics, Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> proposed PEFL, a privacy-enhanced FL approach for protecting gradients in a server which is untrusted. This is achieved by encrypting the local gradients of the participants by using paillier homomorphic cryptosystem. For reducing the cryptosystem’s costs of communication of the the authors have used a distributed selective stochastic gradient descent approach for achieving distributed encryption during the training phase. The encrypted gradients enable secured aggregation in server. Hence, the untrustred server can learn only the statistics of the participants that are aggregated, while preserving the privacy of the individuals. In another work, Doku et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> proposed a Fl and blockchain based model to retrieve relevant data from big data by using proof of common interest mechanism to segregate relevant data from big data. This data is then trained on a federated model on the edge devices. A shared model is then generated by aggregating the model along with other models in the network, which is then stored in the blockchain. The network members can download the aggregated model that can be used to provide edge intelligence to the users.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">In a smart grid environment, massive data is generated from the households and industries. Smart metering systems in smart grid have to perform data analytics quite frequently (may be once in every 15 minutes) to understand the patterns in consumption of electricity by the clients, that can enable coping up with the usage of electricity during peak times, seamless integrated of renewable sources of energy through coordinate consumption of electricity. Even the retailers can be benefited by big data analytics performed on the data generated by smart meters to have more transparency of consumer’s behavior in consuming electricity, through which personalized services can be provided to them. In the retail market, several retailers own the data from smart meters. They may not share the data to the central cloud for big data analytics due to privacy concerns. Hence, the identification of the characteristics of the consumers is difficult as full dataset can be accessed by the global ML models. To address this issue, Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> proposed a FL based approach to train the learning model on the local data residing at diversified clients without sharing the raw data to the global Ml model, thereby preserving the privacy of the data. In this work, principal component analysis is executed to extract the significant features form the consumer data. Artificial neural networks based ML algorithms are trained on the consumer data using FL approach for big data analytics. In a similar work, Zhai et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> proposed an FL framework, constrained by delay deadline that overcomes long delays due to training of big data generated in smart grids.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.5.1.1" class="ltx_text">III-C</span>2 </span>Federated Learning for Secure Data in AI Algorithms</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Due to strict regulations and protections of data security and privacy, traditional ML algorithms that get trained on the datasets that are located on central servers are facing significant challenges. Due to these reasons, conventional AI and ML based approaches are becoming impractical in several data-sensitive and mission critical scenarios, like health, government, finance sectors,etc. FL has received wide attention recently because of its ability to preserve privacy of users as it doesn’t send the raw data of the users to update the parameters of the global model. But, FL can still be vulnerable to several privacy and security threats as the attackers can use the shared gradients to derive the privacy of the participants. To solve this problem, several researchers have proposed various privacy preserving and secure FL approaches. Some of the recent state of the art in this direction are discussed below.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">Xu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> have proposed VerifyNet model that ensures security and verifiability of FL algorithms that train on big data. In this work, firstly, a double-masking protocol is used to ensure that the local gradients of the users are confidential during the FL. Later, to prove the correctness of the aggregated results to the users, the cloud server has to provide the proof. In a similar work, So et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> proposed a single-server Byzantine-resilient secure aggregation framework for a secured FL. The proposed approach is based on secure model aggregation, verifiable outlier detection, and integrated stochastic quantization to ensure privacy, convergence, and Byzantine resilience at the same time. In another interesting work, Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> proposed a novel Knowledge Federation framework, to preserve to preserve privacy and securing the training data, utilize all the data resources that are scattered across several units of organizations.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Federated Learning for Big Data Privacy Preservation</span>
</h3>

<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS1.5.1.1" class="ltx_text">III-D</span>1 </span>Federated Learning for Privacy Preservation in Big Data Processing</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">FL acts as a promising solution catering to solve problems associated with data islands, breaking of data barriers. It ensures protection of data privacy and security of big data. In a Distributed IoT framework, it is extremely essential for the users to collaboratively train the classification or regression model to achieve data prediction ensuring optimum level of privacy. Instead of preserving privacy in outsourced training, the users train the data locally using FL rather than submitting the same to the central server. The federated center remains responsible for only aggregation of gradient information which are uploaded by users during the distribution of global training model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS2.5.1.1" class="ltx_text">III-D</span>2 </span>Federated Learning for Privacy Preservation in Big Data Storage</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">In the present day and age, there exists multiple devices that help to connect with one another generating massive amount of data commonly termed as ”Big Data”. These devices include wearables, autonomous vehicles, mobile devices which require ever growing computational power and also has privacy concerns while storing or processing of the same. This pushes the storage mechanisms towards edge computing leaving cloud. Edge computing thus acts as a new paradigm used for the deployment of computationally intense applications and operation of the same. FL in such scenario is an emerging technique that enables privacy preservation while training the Deep Neural Network Model when data gets generated from multiple clients. It is a combination of distributed machine learning, cryptography, security and other incentive based techniques following the basic principles of economy and game theory. In FL, the machine learning based framework consists of many clients who collaboratively train a model with the support of a centralized server ensuring that the training data is decentralized. The machine learning algorithms in such case gets trained at various local datasets located in the local edge nodes. The FL based system keeps the raw data distributed in the client devices instead of aggregating the same to the centralized cloud data center to perform training. The shared model is trained on the server by the aggregating the computed updates present locally <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.5.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.6.2" class="ltx_text ltx_font_italic">Summary</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Due to the rapid growth of the applications, large volumes of data are being generated at an exponential rate, encouraging the applications to generate the data at a rapid pace. From the discussion above, it can be summarized that FL has a tremendous potential in addressing several challenges faced by big data services such as Big data acquisition, Big data storage, Big data analytics, Big data privacy preservation. However, several challenges such as many companies prefer not to share their data for a variety of reasons and concerns, such data privacy, data sharing rules, and a lack of information that can be solved using FL. Performing big data analytics in the cloud has concerns related to network cost and data privacy. Poor latency for data exchange among decentralized multiple parties. Leaking of sensitive information of the participants to the untrusted servers are addressed to realize the full potential of FL for big services. Table <a href="#S3.T2" title="Table II ‣ III-E Summary ‣ III Federated Learning for For Big Data Services ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> summarizes the benefits and challenges of FL for big data services.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table II: </span> Benefits and challenges of FL for big data services.</figcaption>
<div id="S3.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:418.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.0pt,41.5pt) scale(0.834371046916085,0.834371046916085) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Services</span></th>
<th id="S3.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Existing Challenges Faced</span></th>
<th id="S3.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Benefits of using FL</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.2.1" class="ltx_tr">
<td id="S3.T2.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.1.1.1" class="ltx_p" style="width:39.8pt;">Big Data 
<br class="ltx_break">Acquisition</span>
</span>
</td>
<td id="S3.T2.1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.2.1.1" class="ltx_p" style="width:187.8pt;">1) Most of the companies prefer not to share their data for a variety of reasons and concerns, such data privacy, data sharing rules, and a lack of information.</span>
<span id="S3.T2.1.1.2.1.2.1.2" class="ltx_p">2) Data security and privacy for maintaining the storage of local data.</span>
<span id="S3.T2.1.1.2.1.2.1.3" class="ltx_p">3) Difficult to understand and analyse data patterns of fraud transactions and later detect actual frauds.</span>
<span id="S3.T2.1.1.2.1.2.1.4" class="ltx_p">4) Poor latency time for data exchange among decentralized multiple parties.</span>
</span>
</td>
<td id="S3.T2.1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.3.1.1" class="ltx_p" style="width:256.1pt;">1) Training data is held on the device, with no individual updates sent to the cloud.</span>
<span id="S3.T2.1.1.2.1.3.1.2" class="ltx_p">2) To understand and learn the global model without compromising with the data privacy.</span>
<span id="S3.T2.1.1.2.1.3.1.3" class="ltx_p">3) Achieve data privacy without sharing the data or sensitive information of the users.</span>
<span id="S3.T2.1.1.2.1.3.1.4" class="ltx_p">4) Achieve secure and fast data exchange among decentralized multiple parties.</span>
<span id="S3.T2.1.1.2.1.3.1.5" class="ltx_p">5) FL with Blockchain build immutable data blocks which provides transparency and improves data ownership without the need of any central authority.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.3.2" class="ltx_tr">
<td id="S3.T2.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.2.1.1.1" class="ltx_p" style="width:39.8pt;">Big Data 
<br class="ltx_break">Storage</span>
</span>
</td>
<td id="S3.T2.1.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.2.2.1.1" class="ltx_p" style="width:187.8pt;">1) The central server becomes unavailable, the entire training process will be disrupted.</span>
<span id="S3.T2.1.1.3.2.2.1.2" class="ltx_p">2) The server have poor bandwidth and, unreliable communication links with the agents to transfer big data.</span>
<span id="S3.T2.1.1.3.2.2.1.3" class="ltx_p">3) Poor data storage infrastructure.</span>
<span id="S3.T2.1.1.3.2.2.1.4" class="ltx_p">4) Poor latency time for data exchange among decentralized multiple parties.</span>
</span>
</td>
<td id="S3.T2.1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.2.3.1.1" class="ltx_p" style="width:256.1pt;">1) FL provides a decentralized approach, where the model relies on the own resources of the node, can be used as an alternative to perform the training.</span>
<span id="S3.T2.1.1.3.2.3.1.2" class="ltx_p">2) FL allows mobile agents to collaborate in the models training that does not rely on any central server.</span>
<span id="S3.T2.1.1.3.2.3.1.3" class="ltx_p">3) Maintains the heterogeneity of the data, hence reducing the deviation of training in ML model.</span>
<span id="S3.T2.1.1.3.2.3.1.4" class="ltx_p">4) Decouples the ability to implement machine learning based on the need to store data in the cloud.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.4.3" class="ltx_tr">
<td id="S3.T2.1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.3.1.1.1" class="ltx_p" style="width:39.8pt;">Big Data 
<br class="ltx_break">Analytics</span>
</span>
</td>
<td id="S3.T2.1.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.3.2.1.1" class="ltx_p" style="width:187.8pt;">1) Big data analytics require the participant sources to send their personal and sensitive data to a central sever to perform ML services,that may result in privacy concerns of the data sources such as mobile users.</span>
<span id="S3.T2.1.1.4.3.2.1.2" class="ltx_p">2) Secure Data Training.</span>
<span id="S3.T2.1.1.4.3.2.1.3" class="ltx_p">3) Performing big data analytics in the cloud has concerns related to network cost and data privacy.</span>
<span id="S3.T2.1.1.4.3.2.1.4" class="ltx_p">4) Leaking of sensitive information of the participants to the untrusted servers.</span>
<span id="S3.T2.1.1.4.3.2.1.5" class="ltx_p">5) Conventional AI and ML based approaches are becoming impractical in several data-sensitive and mission critical scenarios, like health, government, finance sectors,etc.</span>
</span>
</td>
<td id="S3.T2.1.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.3.3.1.1" class="ltx_p" style="width:256.1pt;">1) FL provides privacy reservation while providing big data analysis.</span>
<span id="S3.T2.1.1.4.3.3.1.2" class="ltx_p">2) Addresses network connectivity issues and limited computational resources for performing big data analytics in IoT devices that slows down the training process.</span>
<span id="S3.T2.1.1.4.3.3.1.3" class="ltx_p">3) Fastening up of the training process of big data from IoT devices.</span>
<span id="S3.T2.1.1.4.3.3.1.4" class="ltx_p">4) The network members can download the aggregated model that can be used to provide edge intelligence to the users.</span>
<span id="S3.T2.1.1.4.3.3.1.5" class="ltx_p">5) Ensures security and verifiability of FL algorithms that train on big data.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.5.4" class="ltx_tr">
<td id="S3.T2.1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.4.1.1.1" class="ltx_p" style="width:39.8pt;">Big Data 
<br class="ltx_break">Privacy 
<br class="ltx_break">Preservation</span>
</span>
</td>
<td id="S3.T2.1.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.4.2.1.1" class="ltx_p" style="width:187.8pt;">1) Privacy Preservation in Big Data Processing.</span>
<span id="S3.T2.1.1.5.4.2.1.2" class="ltx_p">2) Privacy Preservation in Big Data Storage.</span>
<span id="S3.T2.1.1.5.4.2.1.3" class="ltx_p">3) Preserving privacy of sensitive information of users.</span>
<span id="S3.T2.1.1.5.4.2.1.4" class="ltx_p">4) Poor security and slow data exchange among decentralized multiple parties.</span>
</span>
</td>
<td id="S3.T2.1.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.4.3.1.1" class="ltx_p" style="width:256.1pt;">1) Solve problems associated with data islands, breaking of data barriers.</span>
<span id="S3.T2.1.1.5.4.3.1.2" class="ltx_p">2) Ensures protection of data privacy and security of big data.</span>
<span id="S3.T2.1.1.5.4.3.1.3" class="ltx_p">3) Keeps the raw data distributed in the client devices instead of aggregating the same to the centralized cloud data center to perform training.</span>
<span id="S3.T2.1.1.5.4.3.1.4" class="ltx_p">4) The shared model is trained on the server by the aggregating the computed updates present locally.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning enabled Big Data Applications</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, the advantages of FL for several big data applications are discussed along with recent state of the art literature.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Federated learning enabled big data in smart city</span>
</h3>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2110.04160/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="265" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Federated Learning Enabled Big Data in Smart City.</figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">A smart city improves the quality of life of the urban citizens by optimizing the functions of the cities and promotion of economic growth by making use of data analysis and smart technologies like IoT.
IoT sensors are placed throughout the smart cities to collect information regarding traffic, air quality, condition of the roads, garbage, etc. These sensors generate large volumes of data continuously and at a fast pace. Big data analytics along with ML based algorithms can effectively use these data to gain the insights. The insights gained can be used to effectively manage the services, resources, and assets in cities. Big data analytics can provide solutions to some of the important issues like healthcare, IoT, communication, transportation, garbage collection, disaster management, etc in smart cities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. However, most of the data generated from the sensors in smart cities is sensitive in nature which involves private data of its citizens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. So, the need of the hour is to preserve the private data generated in smart cities and efficient handling of network resources to handle the big data. Traditional ML based methods cannot handle these issues that can arise in the smart cities. FL, through its inherent characteristics, is a potential solution that can address the aforementioned issues in smart cities as depicted in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A Federated learning enabled big data in smart city ‣ IV Federated Learning enabled Big Data Applications ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. Recent studies on FL used for addressing the challenges of big data from smart cities are discussed below.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Prediction of traffic flow plays a significant tole in management of intelligent transportation in smart cities. By analyzing the patterns from the big data generated related to the traffic flow and making predictions can help in realizing several benefits like reducing traffic congestion, accidents, air pollution. However, as the driver’s information is tightly coupled with the location of the vehicle, the data collected from the vehicles may threaten the privacy of the driver. The attacker/malicious user can get hold of personal details of the driver like health condition, habits, religion, income, etc. based on the places visited frequently by the driver. Motivated by these issues, Qolomany et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> have proposed to use a FL model to preserve the privacy of the user. The authors have proposed to use a deep LSTM model to train the data locally. The parameters for the LSTM model are chosen by particle swarm optimization algorithm. Each client will only compute and share the update with the global model residing at the server. In this way the private and sensitive data will not be transferred to the central storage, preserving privacy of the drivers.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Safety monitoring system is a very important application (like monitoring of fire hazards) in a smart city.
Building models for object detection/recognition on large datasets that are stored centrally is a very challenging task due to high cost involved in transmitting video/image data and privacy issues. To overcome these challenges, Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> proposed a machine learning platform, namely, Fedvision, that leverages FL in computer vision related applications. Fedvision is deployed with the collaboration between Extreme Vision and WeBank for smart city applications that can be used by the customers in developing safety monitoring systems. One of the challenges in smart city applications is to process and get insights from large volumes of unlabelled data being generated at a very rapid rate. Also, the privacy of the data has to be preserved. To overcome these challenges, Albaseer et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> proposed a FL based semi-supervised method for real-time analytics at the edge networks, FedSem, for smart city applications.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">One of the primary goals of a smart city is to build a smarter and better healthcare infrastructure. Training large volumes of medical data in a central server involves several challenges such as preservation of privacy of patients, heterogeneous nature of data from different sources, etc.
To address these challenges in large volumes of medical data, Thwal et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> proposed a FL paradigm based on deep learning.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">When facing with crisis like COVID-19, city digital twin can face several challenges due to its reliance on high quality and long term data. To address these challenges, Pang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> proposed an FL based city digital twin to efficiently accumulate insights for heterogeneous sources of data.
The global model is trained iteratively at different city digital twins till the global model uncovers the patterns between the response plans and trends in infection. In this way, the proposed model can be used to manage the crisis in a city.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">Unmanned Aerial Vehicles (UAVs) play an important role in smart cities to monitor traffic, air pollution, movement of citizens during pandemics, and disaster management <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. However, the data acquired my the UAVs may be very sensitive and the privacy preservation of the data acquired is of paramount importance. Hence, UAV integrated with FL can preserve the privacy of the sensitive data, address several concerns like resource management, latency issues faced by UAVs. For forecasting and monitoring of air quality index in a smart city from spatial-temporal perspective, Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> proposed an aerial-ground air quality sensing framework with UAVs swarms based on FL that addresses the privacy concerns of sharing the air pollution related data. In a similar work, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> leveraged FL for UAVs in smart city monitoring for truthful reporting from UAVs and also to address heterogeneity of data generated from multiple UAVs.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data in Smart Healthcare</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">AI/ML techniques integrated with IoT have been extensively used over the past two decades in healthcare applications to assist the medical practitioners in diagnosing the diseases, drug discovery, remote patient monitoring, etc. Traditional ML approaches face several issues
like exposing the private and sensitive information of the hospital/patients, issues in sharing huge volumes of data, etc. With FL, the computation model itself will be executed at the data source; hence, FL has a huge potential in addressing the aforementioned issues in smart healthcare applications as depicted in Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-B Federated Learning enabled Big Data in Smart Healthcare ‣ IV Federated Learning enabled Big Data Applications ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. FL can enable large-scale precision medicine respecting individual privacy concerns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. The recent works on applications of FL for big data related to smart healthcare is presented in the rest of the subsection.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2110.04160/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="403" height="191" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Integration of FL and big data for medical and healthcare services.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Hakak et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> have proposed a edge assisted framework with FL for privacy preservation of sensitive healthcare data acquired through wearable devises. Apart from privacy preservation, the proposed framework helps in optimizing cloud resources when dealing with huge volumes of healthcare data generated by millions of wearable devices. In a similar work, Qayyam et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> proposed a edge assisted framework for automatic diagnosis of COVID-19 using clustered FL. The proposed framework can help in performing analytics for the large volumes of ultrasound and x-ray data related to COVID-19 patients at the FL enabled edge. Silva et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> have proposed a framework based on FL to train the ML models on databanks that contain brain images. The proposed approach is mainly aimed at privacy preservation of the sensitive information of the patients. Wu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> have proposed a novel framework, FedHome, that is based on FL for in-home monitoring of health. The authors aim to address the existing challenges of privacy preservation and transferring of large volumes of data that exist using the ML algorithms are used on the in-home patients’ data in a central server.
To get diverse and large datasets to train a deep learning model, multi institutional collaboration is need of the hour to generate diverse and large quantity of medical data. How to enable collaboration among multiple institutions without exposing the sensitive information of the patients is a challenge. To address this issue, Shellar et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> proposed a FL based deep learning model for privacy preservation in multi-institutional collaborations, where the proposed model is trained at all the participating individual institutions without the need to share the individual data among the institutions. In a similar work, Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> proposed a 5G-enabled architecture for auxiliary diagnosis of COVID-19 patients based on FL. In this architecture, multiple institutes can collaborate without compromising on the privacy concerns. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> have followed a similar approach for multi institutional collaboration in screening of COVID-19 patients based on chest X-ray images. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> have proposed an FL based framework for analysing the MRI images. The proposed work aims to reduce the time and communication cost involved in transmitting the MRI images from local sites to the central server for storing and training the ML based models.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Even though FL can address the privacy concerns and latency issues in transferring the data from the local devices to the central servers to train the ML models, transparency and tampering of the records still persist. To address these issues, blockchain can be integrated with FL for identifying the patterns from large volumes of medical data while preserving privacy and ensuring security. In this direction, El Rifai et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> have integrated FL and blockchain to train diabetes, kidney, and digestive datasets. FL is used to ensure that the privacy preservation is accomplished for sensitive data of patients and also to reduce the communication overhead involved in frequently transferring the patients’ data from local devices to the central server, whereas blockchain is used to ensure transparency and preventing alterations of the medical records. In a similar work, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> proposed a blockchain enabled FL framework to detect the COVID-19 from CT imaging. The data is authenticated by blockchain technology, whereas FL trains the model globally thereby achieving privacy preservation.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data in Smart Transportation</span>
</h3>

<figure id="S4.F6" class="ltx_figure"><img src="/html/2110.04160/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="235" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Federated learning enabled big data in smart transportation.</figcaption>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Some of the applications of smart transport systems such as intelligent transportation systems and cooperative autonomous involve sensitive data and large quantity of the devices where the storage, computing, and communication resources must be utilized efficiently.
In traditional systems, all the data generated from the vehicles will be transferred to the cloud and the machine learning or other predictive techniques are applied on the data stored centrally in the cloud. However, as the the cloud will be making decisions from the global information, large volumes of data from vehicles distributed across several locations have to be acquired and transferred to the cloud. This process needs a high bandwidth and also high delay will be incurred. Also, the decisions should me made based on the local scenarios rather than the global scenarios to take appropriate actions in specific locations. To address the aforementioned issues, FL can be a promising solution as depicted in Fig. <a href="#S4.F6" title="Figure 6 ‣ IV-C Federated Learning enabled Big Data in Smart Transportation ‣ IV Federated Learning enabled Big Data Applications ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. FL can be used to train the data from vehicles in a particular area collected and stored at edge devices in near proximity to analyze and extract the patterns from the local area to take immediate actions, preserving the privacy related to sensitive information of the vehicles such as driver details, location of the vehicle, etc. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Road surveillance is an essential application of ITS, where large number of videos generated at fast pace have to be analyzed in real time for the appropriate authorities to take necessary action regarding tasks such as traffic congestion prevention, immediate response to accidents, burglaries on highways, etc.
Even though edge computing is promising, new challenges emerge with it like fragmenting the decision models and coordination between the edge nodes distributed in different locations. To address the issues of edge based frameworks when dealing with real time video analytics of ITS, Sada et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> presented a FL based architecture for video analytics which is distributed. The proposed architecture enables distributed and real-time object detection apart from preserving the privacy of the model updates. In a similar work, Xu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> proposed a FL based traffic monitoring system to obtain the data related to the traffic in roads and other locations using remote sensing data for identifying traffic congestion. FL helps in preserving the privacy of sensitive data related to the vehicles, drivers, etc. In another work, Qi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> proposed a framework based on FL integrated with blockchain for traffic flow prediction. Even though FL helps in preserving the privacy, it has some serious security issues such as single point of failure of centralized model coordinator. To address this issue, the authors have proposed a consortium blockchain based approach that can provide reliable, secure and decentralized FL without the need for centralized model coordinator. In this work, the miners in the blockchain verify the updates from the models of decentralized vehicles that helps in preventing unreliable model updates.
Similarly, Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> proposed FedGRU, a FL-based gated recurrent unit neural network algorithm to predict the flow of traffic for protecting the privacy of large volumes of sensitive data generated from the vehicles.
Mowla et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite> proposed an FL based model for detecting on-device jamming attacks in flying ad-hoc networks. The proposed approach helps in reducing the power consumption, communication overhead issues faced by traditional jamming attack detection mechanisms, along with providing on time global updates in flying ah-hoc networks.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">In electrical vehicular networks, prediction of the demand of energy is of paramount significance as it ensures accurate charge planning and reliable routing. Saputra et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> proposed an FL based architecture to find the complex patterns in the electrical vehicular networks to improve the accuracy of energy demand prediction. To protect the privacy of sensitive data that will be frequently exchanged between the charging stations and the vehicles, and also to reduce the communication overhead, the authors have used FL that allows the charging stations to share the data without exposing the sensitive data. Similarly, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> applied an enhanced FL averaging algorithm that learns regression models and probabilistic neural networks in a privacy-preserving and communication-efficient manner to address the predictive uncertainty of traditional FL based models.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data in Smart Grid</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The electric grid concept is aging and the current electric grid infrastructure is finding it difficult to handle the things it is not designed for. Using cutting edge technologies like IoT, ML, communication networks, equipment in electric grids will ensure that the electricity is delivered more efficiently and reliably. The modernized electric grids, termed as smart grids, will result in reducing the frequent and long power outages, faster restoration of services when the outages occur, reduce the impacts of the storms on the electricity supply, etc.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Smart grids generate large quantity of data at a very rapid pace. ML algorithms can be used on this data to analyze the patterns and predict the electricity demand, power outages, stability of the smart grid, electricity theft, etc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>. However, the traditional approach of transferring the data from the smart grid to the central cloud and then applying ML algorithms involves several challenges such as increased latency, exposing of sensitive and private data of the customers/grid to the potential hackers, etc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. FL, through its inherent characteristic of training the global ML model in the local devices and sending only the model parameters to the central ML model for training, has a great potential to address these issues of the smart grid as depicted in Fig. <a href="#S4.F7" title="Figure 7 ‣ IV-D Federated Learning enabled Big Data in Smart Grid ‣ IV Federated Learning enabled Big Data Applications ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. The recent literature related to application of smart FL for smart grids is discussed in rest of the subsection.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2110.04160/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="143" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Federated learning enabled big data in smart drid.</figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">Deep learning models
can expose privacy sensitive data such as the data related to the appliances collected by a smart meter, that may reveal the consumer’s behavior at home based on the appliances used by them, that can raise serious security concerns. Also, the ML/deep learning models need large quantity of data to get trained. To address these issues, Taik et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> proposed a model based on FL and edge computing for household load forecasting that addresses the volume and diversity requirements of the deep learning models and also preserves the privacy of consumer data. In a similar work, Wang  et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> proposed a FL based method to identify the electricity characteristics of the distributed consumers that can preserve the privacy of the retailers.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">The future energy demand of a smart home can be predicted by training a deep learning model on the energy consumption data of a consumer. The data collection from the clients who are distributed for centralized model training incurs huge costs with respect to communication resources. To address this issue, Tun et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> proposed a FL based model, in which every client has to upload only the model updates generated by training the FL model on it local data and these updates are then aggregated into a global model at the centralized server.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p">Forecasting the load of a power system in short term play an important role in the efficient, stable management and dispatch of the electricity. The traditional model of centralized training of the ML based models for forecasting the load of the power system has issues regarding the privacy preservation and also the latency incurred due to the large volumes of data generated from distributed consumers. To address these issues for electric load prediction, Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> proposed an FL based approach for short-term load forecasting of the grid. In a similar work, Savi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> proposed a framework based on edge-computing and FL that use LSTM models for short-term consumption of energy of the consumers.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.5.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data for Online Recommender Systems</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Recommender systems are seen commonly these days in several online applications such as amazon, youtube, netflix, etc. Recommender systems suggest items that are relevant to the users, such as products to buy, text to read, movies to watch, songs to listen, etc. Typically. the recommender systems have to process large volumes of data related to the activities of the users to filter, rank and suggest/recommend the items based on their interests <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>. Users browse large volume of items on a daily basis. Analyzing this big data in a traditional approach, where the data is collected from the users and stored centrally for training an ML based model will incur heavy communication and privacy costs. FL can play a vital role in addressing the aforementioned issues related to big data from recommender systems. Some of the recent state-of-the-art on the application of FL for recommender systems that have to deal with the big data are discussed below.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">Amir et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite> proposed an FL-based model to improve the personalized recommendations to the users in a privacy preserving manner. The proposed system ensures that the ratings of the users on the items remain in their local device, and only the preference patterns are shared to the global model that reduces communication overhead.
In a similar work, Tan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> proposed an FL based approach that trains the data from several clients, while at the same time, preserving the privacy of each client. In another interesting work, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> used a FL based model to preserve privacy of the user’s preferences in a recommender system. The users have tested their proposed approach on Alibaba’s e-commerce recommendation and evaluated their model on Taobao user data collected over 30 days. The results proved that the proposed system’s scalability, reduced communication, storage and computational overhead, while preserving the privacy of the user’s data simultaneously.
Muhammed et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> presented a novel FL approach in which, a diverse set of sample data from different clients is trained on the federated model and the model updates are propagated to the other clients using an active aggregation technique. In this way, the users can benefit from the proposed approach with reduced communication costs and also the models which are more accurate and can be consumed by the users at even very early stages of training.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.5.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data for 5G and 6G</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">FL trains machine learning models with devices or relevant data centers and at the same time maintains these training datasets locally in the system avoiding the possibility of sharing raw data. This procedure of FL implementation is usually divided into three phases. The first phase is the initialization phase wherein the central aggregator represents the global model which is pre-trained on a public dataset to each of the devices. Then the devices use the 5G network to train and further improvise the global model on the dataset for each iteration. The local model updates get aggregated by the central aggregator in the aggregation phase followed by the update phase wherein a new global model gets generated to be used in the next iterations. This process is iterated until the optimum accuracy and convergence level is achieved by the global model. The model proves to be much secured with lesser risk of privacy leaks due the decoupling of the training of the model from access to raw data used during the training phase. It is due to the advent of fifth-generation (5G) cellular networks that the number of wireless devices will increase stupendously reaching the scale of trillions by the next decade. The advantages of 5G includes enhanced coverage, transmission bandwidth along with reduction in communication latency in versatile applications of smart homes, autonomous vehicles,UAVs and various others. The average 5G speed will soon be much higher than the average mobile connectivity and this has resulted in the announcement of over 81 billion dollar bidding for 280MHz licenses of aforementioned frequency. In order to use this valuable spectrum resource, the third generation partnership projects (3GPP) have been trying to standardize and enable 5G new radio services in unlicensed spectrum being part of LTE which is a Licensed Assisted Access intiative (LAA). FL acts as a hybrid technique involving centralized and decentralized learning. The model training is done using the decentralized technique and the data gets stored at its source. The raw data is stopped from being transferred to prevent communication overhead thereby optimizing performance and security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS7.5.1.1" class="ltx_text">IV-G</span> </span><span id="S4.SS7.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data for Industry 4.0/5.0</span>
</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">FL has evolved as an extremely successful solution for the development of cost effective and secured IIoT applications. The implementation of FL helps in attracting large dataset and computation resources from various IIoT devices for the training of the AI models. This improves the quality of IIoT training data which may not be possible to be achieved using the traditional AI approaches. The integration of FL with IIoT have various advantages. Firstly, as already discussed, in an FL system the local updates are only accessed by the central server but the local data are kept safe in the local devices. Hence as per the General Data Protection Regulation (GDPR), the FL successfully develops secured, sustainable and safe IIoT systems. Also, since offloading of stupendous data volumes to the server is avoided in FL, the communication gets significantly reduced thereby saving network spectrum resources in the IIoT networks. This motivates the use of FL in applications for mobile devices, manufacturing robots, industrial automation and various others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS8.5.1.1" class="ltx_text">IV-H</span> </span><span id="S4.SS8.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data for Social Media</span>
</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p">These days most of the people are spending great amount of their time on their mobile phones, especially, social media. In several social media apps such as Facebook, Instagram, Twitter, etc., the users will be posting photos, videos, tweeting their status, sharing their opinions, sharing other posts, etc., that results in generation of heterogeneous data at a very fast rate and of enormous proportions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>. Traditionally, the data from the mobile users used to be transferred to the central cloud to train the ML based models for gaining useful insights from these social media posts. However, this may expose the sensitive information of the users such as their preferences, location, etc. Also, large quantity of communication resources are required to share the data to the central cloud, that would in turn introduce latency. To address these issues, FL can be utilized to train ML models on the user’s mobile devices itself, that would result in privacy preservation of the social media users, optimize the resources, and improve the real-time analytics of the big data related to social media <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS9.5.1.1" class="ltx_text">IV-I</span> </span><span id="S4.SS9.6.2" class="ltx_text ltx_font_italic">Federated Learning enabled Big Data for Other Applications</span>
</h3>

<div id="S4.SS9.p1" class="ltx_para">
<p id="S4.SS9.p1.1" class="ltx_p">FL can be used for several other applications that are based on big data such as pollution control, defense etc. Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> proposed a novel FL based framework for monitoring and predicting the quality of the air. The proposed framework predicts the air quality index scale distribution by using a Dense-MobileNet model that learns the haze features from the images taken by Unmanned Aerial Vehicles (UAV) in the air. The traditional method of transferring the large volumes of the data generated by the UAVs incurs heavy communication overheads. Also, the generated data may include sensitive information that should not be exposed. The proposed FL enabled architecture ensures several organizations to learn collaboratively through a global model to monitor air quality index in a privacy preserving manner. The authors proposed a long short-term memory model based on graph convolutional neural networks for ground sensing systems to achieve real-time, accurate and future air quality index inference. FL enabled technologies can be effectively used by UAV’s in several big data applications such as predicting optimal routing path, forecasting the mobility patterns on the ground users, monitoring in crisis/disaster situations, defense etc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>, <a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>. FL enabled big data frameworks can also be used in several applications such as online shopping, insurance, credit card divisions etc., where the privacy of the personal information of the users has to be preserved.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table III: </span>Benefits and challenges of FL in big data applications.</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:361.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-82.7pt,69.0pt) scale(0.723926990818203,0.723926990818203) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Application</span></th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Existing Challenges Faced</span></th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Benefits of using FL</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.2.1" class="ltx_tr">
<td id="S4.T3.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.2.1.1.1.1" class="ltx_p" style="width:48.4pt;">Smart City</span>
</span>
</td>
<td id="S4.T3.1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.2.1.2.1.1" class="ltx_p" style="width:184.9pt;">1) Privacy Preservation of sensitive data of citizens, vehicles</span>
<span id="S4.T3.1.1.2.1.2.1.2" class="ltx_p">2) Resource Management</span>
<span id="S4.T3.1.1.2.1.2.1.3" class="ltx_p">3) Communication cost in transferring large volumes of data</span>
<span id="S4.T3.1.1.2.1.2.1.4" class="ltx_p">4) Providing specific solutions relevant to varied city demographics and needs is difficult to disseminate during emergency periods in real time</span>
</span>
</td>
<td id="S4.T3.1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.2.1.3.1.1" class="ltx_p" style="width:327.2pt;">1) Private data is not shared with the central server; instead model updates are shared</span>
<span id="S4.T3.1.1.2.1.3.1.2" class="ltx_p">2) Since the FL model is trained on local devices, burden of resource management in the central cloud is reduced</span>
<span id="S4.T3.1.1.2.1.3.1.3" class="ltx_p">3) As the data is trained locally by a federated model and only model updates are shared with the central ML model, cost of communication is significantly reduced</span>
<span id="S4.T3.1.1.2.1.3.1.4" class="ltx_p">4) Using FL, suitable solutions can be provided to the diverse needs in different areas of the city based on relevant data</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.1.3.2" class="ltx_tr">
<td id="S4.T3.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.3.2.1.1.1" class="ltx_p" style="width:48.4pt;">Smart Healthcare</span>
</span>
</td>
<td id="S4.T3.1.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.3.2.2.1.1" class="ltx_p" style="width:184.9pt;">1) Privacy preservation of the sensitive data of patients</span>
<span id="S4.T3.1.1.3.2.2.1.2" class="ltx_p">2) Real time analytics during pandemics</span>
<span id="S4.T3.1.1.3.2.2.1.3" class="ltx_p">3) Sharing large volumes of medical data from the sensors, wearables to the central cloud</span>
<span id="S4.T3.1.1.3.2.2.1.4" class="ltx_p">4) Generating diverse data from different medical institutions for effective training of ML models</span>
</span>
</td>
<td id="S4.T3.1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.3.2.3.1.1" class="ltx_p" style="width:327.2pt;">1) By using FL, the ML model can be executed in local devices, hence privacy of the data of patients can be preserved</span>
<span id="S4.T3.1.1.3.2.3.1.2" class="ltx_p">2) FL can provide analytics in near real time during pandemics as the local device need not wait for the arrival of data from other devices to perform the ML</span>
<span id="S4.T3.1.1.3.2.3.1.3" class="ltx_p">3) The FL models can reduce the communication overhead as only local updates are shared to the central server</span>
<span id="S4.T3.1.1.3.2.3.1.4" class="ltx_p">4) Collaboration between multiple hospitals without exposing the private and sensitive data of patients is possible through FL, where global model can be executed at individual hospitals without actually exposing the sensitive data of the patients</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.1.4.3" class="ltx_tr">
<td id="S4.T3.1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.4.3.1.1.1" class="ltx_p" style="width:48.4pt;">Smart Transportation</span>
</span>
</td>
<td id="S4.T3.1.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.4.3.2.1.1" class="ltx_p" style="width:184.9pt;">1) Preserving privacy of sensitive information of drivers, vehicles</span>
<span id="S4.T3.1.1.4.3.2.1.2" class="ltx_p">2) Latency and communication cost involved in transferring the large volumes of data from the vehicles to the cloud</span>
<span id="S4.T3.1.1.4.3.2.1.3" class="ltx_p">3) Customized decisions based on the traffic information in a particular area</span>
</span>
</td>
<td id="S4.T3.1.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.4.3.3.1.1" class="ltx_p" style="width:327.2pt;">1) FL can ensure privacy as only model parameters will be shared with the central server.</span>
<span id="S4.T3.1.1.4.3.3.1.2" class="ltx_p">2) As FL is executed in local devices/vehicles latency and communication cost issues will be resolved</span>
<span id="S4.T3.1.1.4.3.3.1.3" class="ltx_p">3) FL can enable personalized decisions based on the traffic information of that specific area as FL is trained based on the local data</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.1.5.4" class="ltx_tr">
<td id="S4.T3.1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.5.4.1.1.1" class="ltx_p" style="width:48.4pt;">Smart Grid</span>
</span>
</td>
<td id="S4.T3.1.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.5.4.2.1.1" class="ltx_p" style="width:184.9pt;">1) Privacy reservation of the consumers and appliances</span>
<span id="S4.T3.1.1.5.4.2.1.2" class="ltx_p">2) Increased latency and communication costs in transferring large volumes of the grid data to the central cloud</span>
<span id="S4.T3.1.1.5.4.2.1.3" class="ltx_p">3) Real time analytics on the smart grid data</span>
</span>
</td>
<td id="S4.T3.1.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.5.4.3.1.1" class="ltx_p" style="width:327.2pt;">1) Since only model parameters are shared by FL, privacy of sensitive information of the customers and the appliances remain protected</span>
<span id="S4.T3.1.1.5.4.3.1.2" class="ltx_p">2) The latency and communication costs involved in transferring large quantity of the consumer data are reduced as the FL models get executed in local devices at consumer location</span>
<span id="S4.T3.1.1.5.4.3.1.3" class="ltx_p">3) Since FL models are executed on local edge devices, it enables efficient and timely decisions without waiting for data from other locations</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.1.6.5" class="ltx_tr">
<td id="S4.T3.1.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.6.5.1.1.1" class="ltx_p" style="width:48.4pt;">Online Recommender Systems</span>
</span>
</td>
<td id="S4.T3.1.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.6.5.2.1.1" class="ltx_p" style="width:184.9pt;">1) Privacy preservation of the users</span>
<span id="S4.T3.1.1.6.5.2.1.2" class="ltx_p">2) Communication costs involved in transferring large volumes of data to the central cloud</span>
</span>
</td>
<td id="S4.T3.1.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.6.5.3.1.1" class="ltx_p" style="width:327.2pt;">1) The sensitive information of the online users will not be exposed as FL will be executed on local devices and only model updates are shared to the central server</span>
<span id="S4.T3.1.1.6.5.3.1.2" class="ltx_p">2) As FL is executed in local devices, and only model parameters are shared to the central server, the communication costs can be reduced</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.1.7.6" class="ltx_tr">
<td id="S4.T3.1.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.7.6.1.1.1" class="ltx_p" style="width:48.4pt;">Social Media</span>
</span>
</td>
<td id="S4.T3.1.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.7.6.2.1.1" class="ltx_p" style="width:184.9pt;">1) Privacy preservation of the sensitive data of the social media users</span>
<span id="S4.T3.1.1.7.6.2.1.2" class="ltx_p">2) Communication costs involved in sharing large volumes from social media at rapid pace</span>
</span>
</td>
<td id="S4.T3.1.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.7.6.3.1.1" class="ltx_p" style="width:327.2pt;">1) The sensitive data of social media users namely their patterns in posts, their moods, and location remain unexposed to the central server as model parameters alone are shared by the FL</span>
<span id="S4.T3.1.1.7.6.3.1.2" class="ltx_p">2) Since FL is executed in local devices, and only model parameters are shared to the central server reduction in communication costs can be observed.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS10" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS10.5.1.1" class="ltx_text">IV-J</span> </span><span id="S4.SS10.6.2" class="ltx_text ltx_font_italic">Summary</span>
</h3>

<div id="S4.SS10.p1" class="ltx_para">
<p id="S4.SS10.p1.1" class="ltx_p">From the discussion above, it can be summarized that FL has a tremendous potential in addressing several challenges faced by big data applications such as privacy preservation, management of resources to handle large volume of data, communication cost and latency issues involved in transferring large volumes of data at a rapid pace to the central server for training the ML algorithms, real time analytics, customized decisions based on geographical locations, and heterogeneity of the data. However, several challenges such as poisoning of ML models in local devices, presence of malicious terminals that may result in wrong training of FL models, and excess energy requirement at local devices have to be addressed to realize the full potential of FL in big data applications. Table <a href="#S4.T3" title="Table III ‣ IV-I Federated Learning enabled Big Data for Other Applications ‣ IV Federated Learning enabled Big Data Applications ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> summarizes the benefits and challenges of FL in big data applications.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning Big Data Projects</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section presents the key FL projects and platforms which are widely used for Big Data developments.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Flower: A Friendly Federated Learning Research Framework</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Flower is an open-source platform-independent FL framework<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://flower.dev/</span></span></span>. Flower framework is specifically designed to provide scalability, which is appropriate to handle big data applications. Flower framework has been used for many real-world applications, which can also support more than 10.000 clients. Moreover, Flower framework supports a wide range of devices, including Android mobiles, iOS devices, Raspberry Pi and Nvidia Jetson.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Key features of Flower framework are as follows<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>.</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Support for heterogeneous clients</span>: Flower can offer the same workload on clients running on different operating systems using different languages.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><span id="S5.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Provide High Scalability</span>: by allowing the workload to scale across thousands of machines.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p"><span id="S5.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Separation of Client-side and Server-side definition</span> which allows independent control over local client-side and global server-side computations.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p"><span id="S5.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Support of ML framework-agnostic libraries:</span> allows the users to use their favorite and experienced ML frameworks</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i5.p1" class="ltx_para">
<p id="S5.I1.i5.p1.1" class="ltx_p"><span id="S5.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Language-agnostic support:</span> allows users to implement FL clients in different languages and emerging embedded device platforms</p>
</div>
</li>
<li id="S5.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i6.p1" class="ltx_para">
<p id="S5.I1.i6.p1.1" class="ltx_p"><span id="S5.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Support for baselines:</span> allows fast comparison of the new FL algorithms with existing and well-known algorithms.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Pysyft</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">PySyft is one of the most popular open-source deep learning frameworks which offer privacy and support FL<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://blog.openmined.org/tag/pysyft/</span></span></span>. It is a Python library to perform secure and private deep learning methods<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>. Moreover, PySyft can be integrated with other deep learning frameworks such as PyTorch, Keras, or TensorFlow.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">PySyft framework is leveraging three main techniques, i.e., Secured Multi-Party Computations (sMPC), differential privacy, and FL. The use of sMPC in PySyft helps to protect the privacy of input data. sMPC can be used to perform computations over private inputs data. Differential privacy can reduce the statistical privacy leakages in large dataset. In addition, PySyft also supports Homomorphic Encryption (HE) to offer extra privacy.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Fate: An Industrial Grade Federated Learning Framework</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Fate is another open-source FL framework developed by Webank’s AI department<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://fate.fedai.org/</span></span></span>. Fate platform primarily supports big data collaboration according to the regulations. It was enabled by integrating multiple secure computation protocols in Fate framework. Fate platform uses several features such as a flexible scheduling system, a modular, scalable modeling pipeline, and clear visual interfaces to keep the scalability, user-friendliness, and improved operational performance.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Fate platform support different service modules such as</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<ul id="S5.I2" class="ltx_itemize">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p"><span id="S5.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">FederatedML</span>: supports common FL/ machine learning algorithms and tools such as DataIO, Intersect, Federated Sampling, Feature Scale, Hetero Feature Binning, OneHot Encoder, Hetero Feature Selection, Hetero LR, Hetero Poisson, Homo LR, Homo NN, and Hetero Secure Boosting.</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p"><span id="S5.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">FATE-Serving</span>: support high-performance FL algorithms.</p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p id="S5.I2.i3.p1.1" class="ltx_p"><span id="S5.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">FATE-Flow</span>: is an end-to-end pipeline platform to perform highly flexible and high-performance FL tasks.</p>
</div>
</li>
<li id="S5.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i4.p1" class="ltx_para">
<p id="S5.I2.i4.p1.1" class="ltx_p"><span id="S5.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">FATEBoard</span>: is a tool to visualize the FL models. It is useful to explore, improve and debug the FL models efficiently.</p>
</div>
</li>
<li id="S5.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i5.p1" class="ltx_para">
<p id="S5.I2.i5.p1.1" class="ltx_p"><span id="S5.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">FATE Network</span>: is designed to enable secure and efficient communications between FL parties.</p>
</div>
</li>
<li id="S5.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i6.p1" class="ltx_para">
<p id="S5.I2.i6.p1.1" class="ltx_p"><span id="S5.I2.i6.p1.1.1" class="ltx_text ltx_font_bold">KubeFATE</span>: manages the workload of FL tasks to achieve high scalability, high efficiency, and cost reduction.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">FedML: Federated Learning Library</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">FedML is an open research library and benchmark which supports the deployment of evaluation of novel FL algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>. FedML supports standalone simulation, distributed training, and mobile on-device training like many other FL platforms. FedML supports worker/client oriented programming to offer an easy user experience. Moreover, it enables end-to-end design pattern toolkits to compare and evaluate novel custom FL algorithms with existing known algorithms.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.5.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.6.2" class="ltx_text ltx_font_italic">TensorFlow</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">TensorFlow<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://www.tensorflow.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/</a></span></span></span> is also widely used open-source machine learning platform. The Google Brain team originally developed it for their internal use. TensorFlow supports a wide range of flexible tools which can be used to deploy ML-powered applications and build customized ML models.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">TensorFlow Federated (TFF) <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://www.tensorflow.org/federated" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/federated</a></span></span></span> is extension of TensorFlow platform. TFF is specifically designed to support decentralized data processing and FL. TFF contains a rich set of tools that users can use to run FL algorithms on their models and data. Moreover, TFF supports the experimentation of new FL algorithms.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.1" class="ltx_p">There are two layers in the TFF platform.</p>
</div>
<div id="S5.SS5.p4" class="ltx_para">
<ul id="S5.I3" class="ltx_itemize">
<li id="S5.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i1.p1" class="ltx_para">
<p id="S5.I3.i1.p1.1" class="ltx_p"><span id="S5.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">FL Layer</span>: It provides the interfaces to interconnect existing Keras or non-Keras machine learning models with the TFF platform. This layer supports the users in conducting basic FL tasks such as FL training and FL evaluation. Here, users do not need to be fully aware of the mechanism or structure of the FL algorithm to run the tests.</p>
</div>
</li>
<li id="S5.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i2.p1" class="ltx_para">
<p id="S5.I3.i2.p1.1" class="ltx_p"><span id="S5.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Federated Core (FC) Layer</span>: This layer support customizes user FL algorithms. It offers low-level interfaces which can be used to interconnect TensorFlow with distributed communication operators and perform custom FL algorithms.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS6.5.1.1" class="ltx_text">V-F</span> </span><span id="S5.SS6.6.2" class="ltx_text ltx_font_italic">LEAF: A Benchmark for Federated Settings</span>
</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">LEAF is a popular modular benchmark framework for FL settings. It supports the benchmark of FL’s different applications, including multi-task learning, meta-learning, and on-device learning<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://leaf.cmu.edu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://leaf.cmu.edu/</a></span></span></span>.</p>
</div>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.1" class="ltx_p">LEAF framework includes three main components<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>.</p>
</div>
<div id="S5.SS6.p3" class="ltx_para">
<ul id="S5.I4" class="ltx_itemize">
<li id="S5.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i1.p1" class="ltx_para">
<p id="S5.I4.i1.p1.1" class="ltx_p"><span id="S5.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">A suite of open-source datasets</span>: This is responsible of prepossess the data and covert to standardized fromat. LEAF support different well-know data sets such as Federated Extended MNIST (FEMNIST)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>, Sentiment140<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>, Shakespeare<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, CelebA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>, Reddit and a Synthetic dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite></p>
</div>
</li>
<li id="S5.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i2.p1" class="ltx_para">
<p id="S5.I4.i2.p1.1" class="ltx_p"><span id="S5.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">An array of statistical and systems metrics</span>: This contains the different evaluation metrics which can be used to assess the behaviour of learning solutions in federated scenarios.</p>
</div>
</li>
<li id="S5.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i3.p1" class="ltx_para">
<p id="S5.I4.i3.p1.1" class="ltx_p"><span id="S5.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">A set of reference implementations</span>: This contains a set of reference implementations such as Mocha<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>, FedAvg<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> and minibatch
SGD, which support FL.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS6.p4" class="ltx_para">
<p id="S5.SS6.p4.1" class="ltx_p">Thus, LEAF allows researchers in FL to benchmark their novel and customized FL solutions under realistic settings. The comparison the popular FL platforms is summarized in Table <a href="#S5.T4" title="Table IV ‣ V-F LEAF: A Benchmark for Federated Settings ‣ V Federated Learning Big Data Projects ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table IV: </span>Comparison of existing FL platforms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> </figcaption>
<table id="S5.T4.15" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.15.1.1" class="ltx_tr">
<th id="S5.T4.15.1.1.1" class="ltx_td ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"></th>
<th id="S5.T4.15.1.1.2" class="ltx_td ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"></th>
<th id="S5.T4.15.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;" colspan="6"><span id="S5.T4.15.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FL Platforms</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.15.2.1" class="ltx_tr">
<td id="S5.T4.15.2.1.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.2.1.2" class="ltx_td ltx_align_top ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.2.1.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.2.1.3.1.1.1" class="ltx_text" style="font-size:90%;">Flower</span></span>
</span>
</td>
<td id="S5.T4.15.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.2.1.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.2.1.4.1.1.1" class="ltx_text" style="font-size:90%;">Pysyft</span></span>
</span>
</td>
<td id="S5.T4.15.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.2.1.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.2.1.5.1.1.1" class="ltx_text" style="font-size:90%;">Fate</span></span>
</span>
</td>
<td id="S5.T4.15.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.2.1.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.2.1.6.1.1.1" class="ltx_text" style="font-size:90%;">FedML</span></span>
</span>
</td>
<td id="S5.T4.15.2.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.2.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.2.1.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.2.1.7.1.1.1" class="ltx_text" style="font-size:90%;">TFF</span></span>
</span>
</td>
<td id="S5.T4.15.2.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.2.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.2.1.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.2.1.8.1.1.1" class="ltx_text" style="font-size:90%;">LEAF</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.3.2" class="ltx_tr">
<td id="S5.T4.15.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T4.15.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Algorithms</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.3.2.2.1.1.1" class="ltx_text" style="font-size:90%;">SplitNN</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.3.2.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.3.2.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.3.2.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.3.2.6.1.1.1" class="ltx_text" style="font-size:90%;">yes</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.3.2.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.3.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.3.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.3.2.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.3.2.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.4.3" class="ltx_tr">
<td id="S5.T4.15.4.3.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.4.3.2.1.1.1" class="ltx_text" style="font-size:90%;">FedNAS</span></span>
</span>
</td>
<td id="S5.T4.15.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.4.3.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.4.3.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.4.3.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.4.3.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.4.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.4.3.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.4.3.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.4.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.4.3.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.4.3.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.5.4" class="ltx_tr">
<td id="S5.T4.15.5.4.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.5.4.2.1.1.1" class="ltx_text" style="font-size:90%;">FedAvg</span></span>
</span>
</td>
<td id="S5.T4.15.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.5.4.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.5.4.4.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.5.4.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.5.4.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.5.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.5.4.7.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.5.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.5.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.5.4.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.5.4.8.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.6.5" class="ltx_tr">
<td id="S5.T4.15.6.5.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.6.5.2.1.1.1" class="ltx_text" style="font-size:90%;">VFL</span></span>
</span>
</td>
<td id="S5.T4.15.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.6.5.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.6.5.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.6.5.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.6.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.6.5.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.6.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.6.5.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.6.5.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.6.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.6.5.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.6.5.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.7.6" class="ltx_tr">
<td id="S5.T4.15.7.6.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.7.6.2.1.1.1" class="ltx_text" style="font-size:90%;">decentralized FL</span></span>
</span>
</td>
<td id="S5.T4.15.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.7.6.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.7.6.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.7.6.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.7.6.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.7.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.7.6.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.7.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.7.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.7.6.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.7.6.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.8.7" class="ltx_tr">
<td id="S5.T4.15.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T4.15.8.7.1.1.1.1" class="ltx_text" style="font-size:90%;">Computing</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.8.7.2.1.1.1" class="ltx_text" style="font-size:90%;">On-Device</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.8.7.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.8.7.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.8.7.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.8.7.6.1.1.1" class="ltx_text" style="font-size:90%;">yes</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.8.7.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.8.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.8.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.8.7.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.8.7.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.9.8" class="ltx_tr">
<td id="S5.T4.15.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T4.15.9.8.1.1.1.1" class="ltx_text" style="font-size:90%;">Platform</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.9.8.2.1.1.1" class="ltx_text" style="font-size:90%;">Standalone</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.9.8.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.9.8.4.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.9.8.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.9.8.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.9.8.7.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.9.8.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.9.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.9.8.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.9.8.8.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.10.9" class="ltx_tr">
<td id="S5.T4.15.10.9.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.10.9.2.1.1.1" class="ltx_text" style="font-size:90%;">Distributed</span></span>
</span>
</td>
<td id="S5.T4.15.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.10.9.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.10.9.4.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.10.9.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.10.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.10.9.6.1.1.1" class="ltx_text" style="font-size:90%;">yes</span></span>
</span>
</td>
<td id="S5.T4.15.10.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.10.9.7.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.10.9.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.10.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.10.9.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.10.9.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.11.10" class="ltx_tr">
<td id="S5.T4.15.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T4.15.11.10.1.1.1.1" class="ltx_text" style="font-size:90%;">Benchmark</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.11.10.2.1.1.1" class="ltx_text" style="font-size:90%;">vertical FL</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.11.10.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.11.10.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.11.10.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.11.10.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.11.10.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.11.10.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.11.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.11.10.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.11.10.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.12.11" class="ltx_tr">
<td id="S5.T4.15.12.11.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.12.11.2.1.1.1" class="ltx_text" style="font-size:90%;">Shallow NN</span></span>
</span>
</td>
<td id="S5.T4.15.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.12.11.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.12.11.4.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.12.11.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.12.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.12.11.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.12.11.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.12.11.7.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.12.11.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.12.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.12.11.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.12.11.8.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.13.12" class="ltx_tr">
<td id="S5.T4.15.13.12.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.13.12.2.1.1.1" class="ltx_text" style="font-size:90%;">Model DNN</span></span>
</span>
</td>
<td id="S5.T4.15.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.13.12.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.13.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.13.12.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.13.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.13.12.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.13.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.13.12.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.13.12.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.13.12.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.13.12.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.13.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.13.12.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.13.12.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.14.13" class="ltx_tr">
<td id="S5.T4.15.14.13.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.14.13.2.1.1.1" class="ltx_text" style="font-size:90%;">Linear models</span></span>
</span>
</td>
<td id="S5.T4.15.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.14.13.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.14.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.14.13.4.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.14.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.14.13.5.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.14.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.14.13.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.14.13.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.14.13.7.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.14.13.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.14.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.14.13.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.14.13.8.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.15.14" class="ltx_tr">
<td id="S5.T4.15.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T4.15.15.14.1.1.1.1" class="ltx_text" style="font-size:90%;">API Design</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.15.14.2.1.1.1" class="ltx_text" style="font-size:90%;">Customizable typologies and message</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.15.14.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.15.14.4.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.15.14.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.15.14.6.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.15.14.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.15.14.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.15.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.15.14.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.15.14.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
<tr id="S5.T4.15.16.15" class="ltx_tr">
<td id="S5.T4.15.16.15.1" class="ltx_td ltx_align_top ltx_border_bb ltx_border_l ltx_border_r" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S5.T4.15.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T4.15.16.15.2.1.1.1" class="ltx_text" style="font-size:90%;">Message flow flexibility</span></span>
</span>
</td>
<td id="S5.T4.15.16.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.3.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.16.15.3.1.1.1" class="ltx_text" style="font-size:90%;">Yes</span></span>
</span>
</td>
<td id="S5.T4.15.16.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.4.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.16.15.4.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.16.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.5.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.16.15.5.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.16.15.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.6.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.16.15.6.1.1.1" class="ltx_text" style="font-size:90%;">yes</span></span>
</span>
</td>
<td id="S5.T4.15.16.15.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.7.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.16.15.7.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
<td id="S5.T4.15.16.15.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span id="S5.T4.15.16.15.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.15.16.15.8.1.1" class="ltx_p" style="width:17.1pt;"><span id="S5.T4.15.16.15.8.1.1.1" class="ltx_text" style="font-size:90%;">No</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Research Challenges and Future Directions</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">As already discussed, FL is a machine learning based technique wherein various clients collaboratively perform training of a model under the control of a centralized server but the training data remains decentralized. Machine learning algorithms, particularly deep neural networks get trained using multiple datasets being part of local edge nodes. The raw data in a traditional system gets aggregated to a centralized data centre for the purpose of training. But in case of FL the raw data is left distributed on the client devices being further trained as a shared model on the server through aggregation of local computed updates. There exists several research challenges associated with FL in big data applications. These challenges can be broadly dichotomized into two categories namely the training related challenges and security related challenges. The data training related challenges include communication overhead while performing multiple training iterations. It also includes issues relevant to heterogeneity of the devices used in learning and heterogeneity of the data used in training. On the other hand, security challenges include threats to privacy and security caused by adversaries starting from malicious clients in the local device to malicious users who has black-box access to a model.
In case of FL the private data remains inside the device instead of leaving and thus makes it easier for an unauthorized user to learn about the existence of data point used for the training in the local models. Security attacks are often introduced due to the manifestation of targeted or non-targeted malicious attacks in the learning process. In case of the targeted attacks, the adversary manipulates the labels of specific tasks. In case of non-targeted attacks, the attacker primarily intends to compromise the accuracy of the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>. Some of the core challenges in the implementation of FL in big data applications are discussed in the next sections as illustrated in Fig. <a href="#S6.F8" title="Figure 8 ‣ VI Research Challenges and Future Directions ‣ Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2110.04160/assets/x8.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="258" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Federated learning in big data-research challenges.</figcaption>
</figure>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.5.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.6.2" class="ltx_text ltx_font_italic">Bottleneck in Communication Efficiency</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Communication emerges as a bottleneck in the development of FL based systems. The primary reason for this is the inclusion of massive number of devices and communications in the network which could be slower than the local computation of other magnitude orders. FL basically sends small messages or model iteratively being part of the distributed training process instead of transporting the entire dataset over the network. he following strategies act as potential concepts to achieve communication efficient learning methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>. 
<br class="ltx_break"><span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_bold">Possible Solutions and Future Direction of Research:
<br class="ltx_break"></span>The first strategy is to use Local updating methods that allows variable number of local updates to be implemented on each machine in parallel during each communication round. This would help lessen the number of communication rounds. Secondly model compression mechanisms namely sparsification, subsampling and quantizations also helps to reduce the message sizes that get communicated at each update round. Thirdly, in case of FL the server connects to all remote devices in the setting. Hence decentralized topologies act as an alternative solution during the instances of bottlenecks while operating with low bandwidth and high latency networks.
<br class="ltx_break">Federated Optimization:There exists various questions relevant to federated optimization in dealing with IID data. There are research gaps between the upper and lower bounds of optimization in FL settings when using intermittent communication graphs which capture the local SGD approaches. But the convergence rates of these approaches do not tally with the relevant lower bounds. Although, majority of the schemes are able to successfully achieve the asymptotically dominant statistical term, but all of them fail to achieve the convergence rate of the accelerated mini-batch SGD. Hence there lies scope of research that would enable federated averaging algorithms to eliminate the gap between the optimization bounds <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>.
<br class="ltx_break"></p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.5.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.6.2" class="ltx_text ltx_font_italic">System and Data Heterogeneity</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The capability to store, compute and communicate using the devices being part of federated network vary significantly from one another. The reason behind such differences are related to hardware, network connection and power supply. Also only a small part of the data should be active at any point in time. Here each device has the possibility of being unreliable because it is quite common for edge computing devices from the network due to connectivity or energy based limitations. The non - identically distributed data collected from the various devices have significant effect on the performance of FL systems. The issues pertinent to system heterogeneity can be achieved implementing the following strategies. Firstly, the use of asynchronous communication to parallelize the functioning of iterative optimization algorithms. This also helps to eliminate straggles in heterogeneous environment. Active sampling of devices at each round while aggregating device updates within pre-defined window is a plausible solution to deal with heterogeneity. Ignoring of fault tolerance and inclusion of algorithmic redundancy as part of code computation also helps to achieve algorithmic redundancy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. 
<br class="ltx_break"><span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_bold">Possible Solution and Future Direction of Research:</span>
To avoid system heterogeneity, asynchronous communication technique is used which helps to run the iterative optimization algorithms in parallel. These act as a highly potential approach to eliminate possibilities of stragglers in the heterogeneous environment.
The second approach involves selection of participating devices at each round actively to ensure maximum aggregation of updates within a pre-defined window wherein only a small subset of devices participate at the end of each round of training. The third plausible approach is to avoid device failures leading to bias in the device sampling scheme when the failed devices have some specific characteristics of data. Also algorithmic redundancy could be introduced as part of coded computation technique to achieve fault tolerance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.5.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.6.2" class="ltx_text ltx_font_italic">Statistical Heterogeneity</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">As already mentioned, the various devices in the FL systems, collect data in a non-identically distributed manner across the network as per the varied types of uses by the end users. The data point counts thus may vary significantly due to the presence of underlying structure that captures the connectivity among the devices and their relevant distributions. The data generating paradigm increases the chances of having stragglers that add complexity in the modeling, analysis and evaluation in the system. The issues arise while training the federated models from the data that are non identically distributed both in terms of data modeling and analysis of the convergence behaviour relevant to associated training procedures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.
<br class="ltx_break"><span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_bold">Possible Solution and Future Direction of Research:
<br class="ltx_break"></span>Heterogeneous Diagnostics:There exists studies focusing on quantification of statistical heterogeneity using different metrics which are mostly calculated during the training phase. This motivates the need for developing simplistic diagnostic techniques for the quantification of statistical and system heterogeneity even before the training phase. Also there lies scope of research to identify ways to improve the convergence techniques involved in federated optimization methodologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS4.5.1.1" class="ltx_text">VI-D</span> </span><span id="S6.SS4.6.2" class="ltx_text ltx_font_italic">Privacy Issues</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">The privacy concerns persuades users to keep the raw data in each devices localised in the federated settings. But sharing of various other information included in the training process has the potential to disclose sensitive information to the third party of the centralized server. The secure multiparty computation (SMC) or differential privacy techniques contributes towards achieving privacy in FL. But there are associated challenges of deteriorated performance and efficiency in the model. The management of balancing all of these security trade-offs act as a significant challenge in achieving privacy in FL systems. In case of FL, the model updates alone namely the gradient information is shared which ensures data protection on each device. But in spite of such attempt, there are open possibilities of sensitive information being shared with third parties or the centralized server while processing the updates of the communication model. Most of the development in this regard emphasizes on the use of cryptography techniques or implementation of differential privacy. But these techniques also have their individual challenges which motivates further development of innovative methodologies to achieve data privacy. As an example, some studies include strategy in which all possible information about counter party’s data is acquired abiding to all the necessary protocols. There also exist techniques which allow involvement of malicious parties where they can tamper the system by feeding falsified input <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
<br class="ltx_break"><span id="S6.SS4.p1.1.1" class="ltx_text ltx_font_bold">Possible Solutions and Future Direction of Research:</span> 
<br class="ltx_break">The concept of privacy lies normally looked upon from the local or global level considering all devices in the network. The future direction of research lies in defining the concept of privacy at a much granular level as the various privacy related constraints differ at various devices or even the data points in a single device. The objective lies in developing privacy techniques capable of handling mixed privacy restrictions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS5.5.1.1" class="ltx_text">VI-E</span> </span><span id="S6.SS5.6.2" class="ltx_text ltx_font_italic">Security Issues</span>
</h3>

<section id="S6.SS5.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Poisoning:</h4>

<div id="S6.SS5.SSSx1.p1" class="ltx_para">
<p id="S6.SS5.SSSx1.p1.1" class="ltx_p">There exists possibilities of two types of poisoning namely Data Poisoning and Model Poisoning in FL systems. Data poisoning in FL based training process occurs when multiple clients participate in the contribution of their on-device training data. In such circumstances, it becomes immensely difficult to stop or detect malicious clients from sending falsified fake data. These fake data poison the training process and the model also gets poisoned. In case of Model poisoning, the malicious client tampers the gradient or parameters which further modifies the received model before being sent to the centralized server for integration of information. The entire global model gets poisoned during this aggregation process where invalid gradients get included. With the increase in model dimensionality the possibility of poisoning and backdoor attacks further increases. The plausible solution in this regard would be to share only prediction results or information which are less sensitive leading to achievement of a more robust and protected method ensuring optimum level of privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S6.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">Membership Inference Attacks:</h3>

<div id="S6.SSx1.p1" class="ltx_para">
<p id="S6.SSx1.p1.1" class="ltx_p">The raw data is usually stored in the local device yet there exists chances of inferring the training data in an FL based system. As an instance, the information regarding the training data can be inferred during the process of updating the model in its learning process. The defence technique actually focuses on achieving differential privacy in this regard. The most common approach adopted are focused on ensuring secured computation, differential privacy and development of a trusted execution environment. In the process of achieving secure computation, two main techniques are adopted namely - Secure Multiparty Computation (SMC) and Homomorphic Encryption. In case of SMC, it is agreed to perform the inputs by two or more number of parties and the output is revealed to only a subset of the participants. On the contrary, in case of homomorphic encryption, the computations are implemented on encrypted inputs before they getting them decrypted. In the process of implementing differential privacy scheme, the user’s contribution is masked. Noise is added to the clipped model parameters before integrating the model although it leads to compromising of the model accuracy. The trusted execution environment presents a secured platform to run the FL process in low computation overhead which is presently suitable only for CPU devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
<div id="S6.SSx1.p2" class="ltx_para">
<p id="S6.SSx1.p2.1" class="ltx_p">Model Inversion Attacks: In this type of attack the training data gets compromised. The potential attacker gets access to the target labels and queries the final trained model. The returned classification scores get exploited in order to reconstruct the remaining data.</p>
</div>
<div id="S6.SSx1.p3" class="ltx_para">
<p id="S6.SSx1.p3.1" class="ltx_p">Membership Inference Attacks: Here the attackers try to find out if some data has been part of the training. Shadow models are created exploiting the returned classification scores with similar classification boundaries as the original model which was subjected to attack</p>
</div>
<div id="S6.SSx1.p4" class="ltx_para">
<p id="S6.SSx1.p4.1" class="ltx_p">Model Encoding Attacks: In this case, the attacker having white-box access attempts to find the training data which had been memorised by the model weights. On the contrary, in case of a black-box situation the original training model gets over-fitted for getting unauthorized access to parts of the training labels.</p>
</div>
<div id="S6.SSx1.p5" class="ltx_para">
<p id="S6.SSx1.p5.1" class="ltx_p">Model Stealing Attacks: In case of model stealing attack, the attacker intends to steal the entire model. When the model is sent to the participants for the purpose of training, a duplicate model mimicking the original decision boundaries get created. Thus the attackers escape payment of usage fees to the ML experts of the original model or while selling the model to the third parties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. 
<br class="ltx_break"><span id="S6.SSx1.p5.1.1" class="ltx_text ltx_font_bold">Possible Solutions and Future Direction of Research:</span> One of the possible mitigation steps to security concerns is the implementation of differential privacy schemes. In this case, the user’s contribution before aggregating, is masked by the addition of noise to the clipped model parameters. Although the accuracy of the model gets negatively affected due to the noise, but it acts as a mathematical guarantee of achieving algorithmic output even when a particular data gets used for the training process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. 
<br class="ltx_break">The use of Secure Multi-Party Computation (SMPC) function allows multiple participants to derive a process mutually similar to the ML training procedure. In such case, only the outcome of the function gets disclosed to the participating members but not the relevant training information. The gradients and the parameters gets computed, updated and encrypted through a decentralized process. The custody of each data item are spit into shares that are sustained by the relevant participating entities. The SMPC although helps in achieving privacy during training period but remains vulnerable during the testing phase <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.
<br class="ltx_break">Homomorphic Encryption also acts as a mitigation technique wherein a complex cryptographic protocol is implemented that ensures mathematical derivation of the encrypted data and the generated outcome also remains encrypted. HE has the potential to ensure security in both training and testing phase. The possible future direction of research lies in making this intensive computation technique economical to be fit for application in real world scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS6.5.1.1" class="ltx_text">VI-F</span> </span><span id="S6.SS6.6.2" class="ltx_text ltx_font_italic">Trust Issues</span>
</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">In FL based frameworks, the ML model owners send their respective models to the data holders to implement training. Apparently this may seem to be secure but there exists trust issues. To highlight some of the examples, the ML model owners could alter their model and get information on their training data. Apart from this, in a FL setup although the data is not shared in the original format, it has risks of being reconstructed in case there exists lag in the protection of architecture and related parameters. There is also a possibility of FL exposing intermediate results namely the parameter updates from the optimization algorithms like stochastic gradient descent (SGD). The transmission of these gradients could also lead to leaking of private information when it gets exposed with image pixel data structure. Hence protection of parameters still remains to be an area of concern while striking a balance between privacy-security and achievement of system performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. 
<br class="ltx_break"><span id="S6.SS6.p1.1.1" class="ltx_text ltx_font_bold">Possible Solutions and Future Direction of Research:</span> The potential solution to the aforementioned trust issues could be the implementation of secure aggregator. Studies could be done in the development of automated middleware procedure or program which would aggregate all the trained models and send the updates to the ML model owners acting as a robust model against various trust compromising attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS7.5.1.1" class="ltx_text">VI-G</span> </span><span id="S6.SS7.6.2" class="ltx_text ltx_font_italic">Algorithmic and Technical Challenges</span>
</h3>

<div id="S6.SS7.p1" class="ltx_para">
<p id="S6.SS7.p1.1" class="ltx_p">The traditional approaches do not work well in the FL paradigm which triggers the proposition of new algorithms such as Federated Averaging (FedAvg) and Federated Stochastic Variance Reduced Gradient (FSVRG) and the Co-Operative machine learning model. In FedAvg the entire training process is controlled by the centralised server which encompasses the shared global model enabling overall communication. Stochastic Gradient Decent Method is used for optimization to be done on the clients locally. In case of the FSVRG technique, the full gradient computation is performed centrally and the other distribution updates are done at each client by performing random permutation on local data iteratively. The FedAvg and FSVRG approach both focus on updating the model undergoing a synchronized approach for model updation. On the contrary, the Co-operative machine learning model takes an asynchronous approach which integrates the received client model with the global model. Although all the three techniques mentioned work well in case of IID and non - IID but their potential in case of unevenly distributed data in real time environment is still unsure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. 
<br class="ltx_break"><span id="S6.SS7.p1.1.1" class="ltx_text ltx_font_bold">Possible Solution and Direction of Future Research
<br class="ltx_break"></span>Development of Innovative Models of Asynchrony: The two predominant communication schemes explored in distributed optimization are the bulk synchronous and asynchronous techniques. On the contrary, in case of federated networks, the devices often remain unassigned to the tasks in process hence most devices remain inactive during any of the iterations. Hence as part of future research there lies opportunity to develop device-centric communication models. These models work beyond the synchronous or asynchronous training schemes and individually each device decides on the time to interact with the server rather than being subjected to the workload <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.
<br class="ltx_break">Threshold level Communication Schemes:The knowledge on optimum level or threshold level of communication required in FL is still unexplored. There lies opportunities of research to acquire detailed theoretical and empirical idea relevant to one-shot and few-shot communication schemes in the implementations of massive statistically heterogeneous networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS8.5.1.1" class="ltx_text">VI-H</span> </span><span id="S6.SS8.6.2" class="ltx_text ltx_font_italic">Autonomy</span>
</h3>

<div id="S6.SS8.p1" class="ltx_para">
<p id="S6.SS8.p1.1" class="ltx_p">Generally in a FL environment, all communication devices tend to be autonomous. In this regard, Association Autonomy deals with the autonomy and willingness of the devices to join or drop out of the network and also provide independence to participate in one or more networks. In case of Communication Autonomy, the device has the freedom to decide on communicating with other participant devices and also the scale of data participation. Although FL is quite robust when communicating with any device while joining or leaving a system, but the devices may also choose to make agreements to seamlessly enter or exit from an FL system. The Google FL system and blockchain are examples that contribute to the same purpose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. 
<br class="ltx_break"><span id="S6.SS8.p1.1.1" class="ltx_text ltx_font_bold">Possible Solutions and Directions of Future Research:</span>
Adaptation of Centralized Training Workflows:The inclusion of centralized training workflows such hyper-parameter tuning, neural architectures, debugging and interpretability in the FL setting acts as a bottleneck in extensive adoption of FL in real time setting. Hence this acts as a potential area of future research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Due to the unprecedented growth of IoT and generated data, there are many big data services and applications. However, conventional approaches using traditional AI/ML techniques for big data face critical issues, such as, data privacy, data variety, communication efficiency, and scalability. In this context, FL is an AI breakthrough in the implementation of big data services and applications. As a result, this paper sets to provide a comprehensive survey on the use of FL for various big data services and applications. We have started by providing the fundamentals of big data and FL, and the motivations of the integration of FL into big data. Then, we have reviewed that FL is a promising AI technique to overcome the challenges in big data services and applications. Finally, from the extensive review, we have highlighted several key challenges of this topic and discussed a number of interesting directions.
</p>
</div>
<section id="S7.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">Acknowledgement</h3>

<div id="S7.SSx1.p1" class="ltx_para">
<p id="S7.SSx1.p1.1" class="ltx_p">We acknowledge the authors (Dinh, Fang, Pubudu) for the contribution of our (blockchain - big data) development.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Oussous, F.-Z. Benjelloun, A. A. Lahcen, and S. Belfkih, “Big data
technologies: A survey,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Journal of King Saud University-Computer and
Information Sciences</em>, vol. 30, no. 4, pp. 431–448, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
M. Favaretto, E. De Clercq, C. O. Schneble, and B. S. Elger, “What is your
definition of big data? researchers’ understanding of the phenomenon of the
decade,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">PloS one</em>, vol. 15, no. 2, p. e0228987, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Mostert, A. L. Bredenoord, M. C. Biesaart, and J. J. Van Delden, “Big data
in medical research and eu data protection law: challenges to the consent or
anonymise approach,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">European Journal of Human Genetics</em>, vol. 24,
no. 7, pp. 956–960, 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Mohamed, M. K. Najafabadi, Y. B. Wah, E. A. K. Zaman, and R. Maskat, “The
state of the art and taxonomy of big data analytics: view from new big data
framework,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>, vol. 53, no. 2, pp.
989–1037, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
B. Ristevski and M. Chen, “Big data analytics in medicine and healthcare,”
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Journal of integrative bioinformatics</em>, vol. 15, no. 3, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. L’heureux, K. Grolinger, H. F. Elyamany, and M. A. Capretz, “Machine
learning with big data: Challenges and approaches,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Ieee Access</em>,
vol. 5, pp. 7776–7797, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Cai, J. Luo, S. Wang, and S. Yang, “Feature selection in machine learning:
A new perspective,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, vol. 300, pp. 70–79, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. I. Baig, L. Shuib, and E. Yadegaridehkordi, “Big data adoption: State of
the art and research challenges,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Information Processing &amp;
Management</em>, vol. 56, no. 6, p. 102095, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
F. M. Awaysheh, M. Alazab, S. Garg, D. Niyato, and C. Verikoukis, “Big data
resource management &amp; networks: Taxonomy, survey, and future directions,”
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
C. Stergiou, K. E. Psannis, B. B. Gupta, and Y. Ishibashi, “Security, privacy
&amp; efficiency of sustainable cloud computing for big data &amp; IoT,”
<em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Sustainable Computing: Informatics and Systems</em>, vol. 19, pp. 174–184,
2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Q.-V. Pham, M. Zeng, R. Ruby, T. Huynh-The, and W.-J. Hwang, “UAV
communications for sustainable federated learning,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Vehicular Technology</em>, vol. 70, no. 4, pp. 3944–3948, 2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing
Magazine</em>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Zhang, B. Chen, S. Yu, and H. Deng, “Pefl: A privacy-enhanced federated
learning scheme for big data analytics,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Global
Communications Conference (GLOBECOM)</em>.   IEEE, 2019, pp. 1–6.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Fu, X. Zhang, N. Xiong, Y. Gao, H. Wang, and J. Zhang, “VFL: A verifiable
federated learning with privacy-preserving for big data in industrial
IoT,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>,
vol. 22, no. 3, pp. 2031–2063, Third Quarter 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and H. V. Poor,
“Federated learning for internet of things: A comprehensive survey,”
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M. Parimala, R. M. Swarna Priya, Q.-V. Pham, K. Dev, P. K. R. Maddikunta, T. R.
Gadekallu, and T. Huynh-The, “Fusion of federated learning and industrial
internet of things: A survey,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.00798</em>, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha, and
G. Srivastava, “A survey on security and privacy of federated learning,”
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 115, pp. 619–640, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Xu, B. S. Glicksberg, C. Su, P. Walker, J. Bian, and F. Wang, “Federated
learning for healthcare informatics,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Journal of Healthcare
Informatics Research</em>, vol. 5, no. 1, pp. 1–19, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Posner, L. Tseng, M. Aloqaily, and Y. Jararweh, “Federated learning in
vehicular networks: opportunities and solutions,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>,
vol. 35, no. 2, pp. 152–159, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G. Long, Y. Tan, J. Jiang, and C. Zhang, “Federated learning for open
banking,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Federated learning</em>.   Springer, 2020, pp. 240–254.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
M. Chen, S. Mao, and Y. Liu, “Big data: A survey,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Mobile networks and
applications</em>, vol. 19, no. 2, pp. 171–209, 2014.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
B. Qolomany, A. Al-Fuqaha, A. Gupta, D. Benhaddou, S. Alwajidi, J. Qadir, and
A. C. Fong, “Leveraging machine learning and big data for smart buildings: A
comprehensive survey,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp. 90 316–90 356,
2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
L. D. Xu and L. Duan, “Big data for cyber physical systems in industry 4.0: a
survey,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Enterprise Information Systems</em>, vol. 13, no. 2, pp.
148–169, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
L. Zhu, F. R. Yu, Y. Wang, B. Ning, and T. Tang, “Big data analytics in
intelligent transportation systems: A survey,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Intelligent Transportation Systems</em>, vol. 20, no. 1, pp. 383–398, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
M. Ge, H. Bangui, and B. Buhnova, “Big data for internet of things: a
survey,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Future generation computer systems</em>, vol. 87, pp. 601–614,
2018.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and H. V. Poor,
“Federated learning for internet of things: A comprehensive survey,”
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, pp. 1–1, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S. Abdulrahman, H. Tout, H. Ould-Slimane, A. Mourad, C. Talhi, and M. Guizani,
“A survey on federated learning: The journey from centralized to distributed
on-site learning and beyond,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>,
vol. 8, no. 7, pp. 5476–5497, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
R. Patgiri, “Taxonomy of big data: A survey,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1808.08474</em>, 2018.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
C.-H. Hua, T. Huynh-The, K. Kim, S.-Y. Yu, T. Le-Tien, G. H. Park, J. Bang,
W. A. Khan, S.-H. Bae, and S. Lee, “Bimodal learning via trilogy of
skip-connection deep networks for diabetic retinopathy risk progression
identification,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International Journal of Medical Informatics</em>, vol.
132, p. 103926, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
T. Huynh-The, C.-H. Hua, and D.-S. Kim, “Encoding pose features to images with
data augmentation for 3-D action recognition,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Industrial Informatics</em>, vol. 16, no. 5, pp. 3100–3111, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
N. A. Tu, T. Huynh-The, K. U. Khan, and Y.-K. Lee, “ML-HDP: A hierarchical
bayesian nonparametric model for recognizing human actions in video,”
<em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Circuits and Systems for Video Technology</em>,
vol. 29, no. 3, pp. 800–814, 2019.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
W. Yang, Y. Zhang, K. Ye, L. Li, and C.-Z. Xu, “Ffd: A federated learning
based method for credit card fraud detection,” in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">International
conference on big data</em>.   Springer,
2019, pp. 18–32.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, “Blockchain and federated
learning for privacy-preserved data sharing in industrial IoT,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Industrial Informatics</em>, vol. 16, no. 6, pp. 4177–4186,
2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
L. Kong, X.-Y. Liu, H. Sheng, P. Zeng, and G. Chen, “Federated tensor mining
for secure industrial internet of things,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Industrial Informatics</em>, vol. 16, no. 3, pp. 2144–2153, 2019.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, “Blockchain empowered
asynchronous federated learning for secure data sharing in internet of
vehicles,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Vehicular Technology</em>, vol. 69, no. 4,
pp. 4298–4311, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
C. Pappas, D. Chatzopoulos, S. Lalis, and M. Vavalis, “Ipls: A framework for
decentralized federated learning,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.01901</em>,
2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
M. Ghobakhloo, “Industry 4.0, digitization, and opportunities for
sustainability,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Journal of cleaner production</em>, vol. 252, p. 119869,
2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
J. Cheng, W. Chen, F. Tao, and C.-L. Lin, “Industrial IoT in 5G
environment towards smart manufacturing,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Journal of Industrial
Information Integration</em>, vol. 10, pp. 10–19, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
M. H. ur Rehman, E. Ahmed, I. Yaqoob, I. A. T. Hashem, M. Imran, and S. Ahmad,
“Big data analytics in industrial IoT using a concentric computing
model,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>, vol. 56, no. 2, pp. 37–43,
2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
P. C. M. Arachchige, P. Bertok, I. Khalil, D. Liu, S. Camtepe, and
M. Atiquzzaman, “A trustworthy privacy preserving framework for machine
learning in industrial IoT systems,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial
Informatics</em>, vol. 16, no. 9, pp. 6092–6102, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
S. Savazzi, M. Nicoli, and V. Rampa, “Federated learning with cooperating
devices: A consensus approach for massive IoT networks,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">IEEE
Internet of Things Journal</em>, vol. 7, no. 5, pp. 4641–4654, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
P. Zhang, C. Wang, C. Jiang, and Z. Han, “Deep reinforcement learning assisted
federated learning algorithm for data management of IIoT,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Industrial Informatics</em>, 2021.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
S. Kim, “Incentive design and differential privacy based federated learning: A
mechanism design perspective,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp.
187 317–187 325, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
L. C. FOURATI and A. Samiha, “Federated learning toward data preprocessing:
Covid-19 context,” in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on
Communications Workshops (ICC Workshops)</em>.   IEEE, 2021, pp. 1–6.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
A. Imteaj and M. H. Amini, “Distributed sensing using smart end-user devices:
pathway to federated learning for autonomous IoT,” in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">2019
International Conference on Computational Science and Computational
Intelligence (CSCI)</em>.   IEEE, 2019, pp.
1156–1161.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konečnỳ, S. Mazzocchi, H. B. McMahan <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Towards federated learning at scale: System design,” <em id="bib.bib48.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1902.01046</em>, 2019.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated
learning,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
W. Xu, W. Fang, Y. Ding, M. Zou, and N. Xiong, “Accelerating federated
learning for IoT in big data analytics with pruning, quantization and
selective updating,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 9, pp. 38 457–38 466, 2021.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
R. Doku and D. B. Rawat, “Iflbc: On the edge intelligence using federated
learning blockchain network,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">2020 IEEE 6th Intl Conference on Big
Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High
Performance and Smart Computing,(HPSC) and IEEE Intl Conference on
Intelligent Data and Security (IDS)</em>.   IEEE, 2020, pp. 221–226.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Y. Wang, I. L. Bennani, X. Liu, M. Sun, and Y. Zhou, “Electricity consumer
characteristics identification: A federated learning approach,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Smart Grid</em>, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
S. Zhai, X. Jin, L. Wei, H. Luo, and M. Cao, “Dynamic federated learning for
gmec with time-varying wireless link,” <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 9, pp.
10 400–10 412, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
G. Xu, H. Li, S. Liu, K. Yang, and X. Lin, “Verifynet: Secure and verifiable
federated learning,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and
Security</em>, vol. 15, pp. 911–926, 2019.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
J. So, B. Güler, and A. S. Avestimehr, “Byzantine-resilient secure
federated learning,” <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in
Communications</em>, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
H. Li, D. Meng, H. Wang, and X. Li, “Knowledge federation: A unified and
hierarchical privacy-preserving ai framework,” in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">2020 IEEE
International Conference on Knowledge Graph (ICKG)</em>.   IEEE, 2020, pp. 84–91.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Z. Ma, J. Ma, Y. Miao, X. Liu, K.-K. R. Choo, and R. Deng, “Pocket diagnosis:
Secure federated learning against poisoning attack in the cloud,” <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Services Computing</em>, 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Y. Khazbak, T. Tan, and G. Cao, “Mlguard: Mitigating poisoning attacks in
privacy preserving distributed collaborative learning,” in <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">2020 29th
International Conference on Computer Communications and Networks
(ICCCN)</em>.   IEEE, 2020, pp. 1–9.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Y. Shi, K. Davaslioglu, and Y. E. Sagduyu, “Over-the-air membership inference
attacks as privacy threats for deep learning-based wireless signal
classifiers,” in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd ACM Workshop on Wireless
Security and Machine Learning</em>, 2020, pp. 61–66.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
S. Bhattacharya, S. R. K. Somayaji, T. R. Gadekallu, M. Alazab, and P. K. R.
Maddikunta, “A review on deep learning for future smart cities,”
<em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Internet Technology Letters</em>, p. e187, 2020.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
X. Xiao and C. Xie, “Rational planning and urban governance based on smart
cities and big data,” <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Environmental Technology &amp; Innovation</em>,
vol. 21, p. 101381, 2021.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
C. de Alwis, H. K. Arachchi, A. Fernando, and M. Pourazad, “Content and
network-aware multicast over wireless networks,” in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">10th International
Conference on Heterogeneous Networking for Quality, Reliability, Security and
Robustness</em>.   IEEE, 2014, pp. 122–128.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
E. Ismagilova, L. Hughes, N. P. Rana, and Y. K. Dwivedi, “Security, privacy
and risks within smart cities: Literature review and development of a smart
city interaction framework,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Information Systems Frontiers</em>, pp.
1–22, 2020.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Z. Zheng, Y. Zhou, Y. Sun, Z. Wang, B. Liu, and K. Li, “Applications of
federated learning in smart cities: recent advances, taxonomy, and open
challenges,” <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Connection Science</em>, pp. 1–28, 2021.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
J. C. Jiang, B. Kantarci, S. Oktug, and T. Soyata, “Federated learning in
smart city sensing: Challenges and opportunities,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20,
no. 21, p. 6230, 2020.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
B. Qolomany, K. Ahmad, A. Al-Fuqaha, and J. Qadir, “Particle swarm optimized
federated learning for industrial IoT and smart city services,” in
<em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">GLOBECOM 2020-2020 IEEE Global Communications Conference</em>.   IEEE, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Y. Liu, A. Huang, Y. Luo, H. Huang, Y. Liu, Y. Chen, L. Feng, T. Chen, H. Yu,
and Q. Yang, “FedVision: An online visual object detection platform
powered by federated learning,” in <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference
on Artificial Intelligence</em>, New York, USA, 2020, pp. 13 172–13 179.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
A. Albaseer, B. S. Ciftler, M. Abdallah, and A. Al-Fuqaha, “Exploiting
unlabeled data in smart cities using federated edge learning,” in <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">2020
International Wireless Communications and Mobile Computing (IWCMC)</em>.   IEEE, 2020, pp. 1666–1671.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
C. M. Thwal, K. Thar, Y. L. Tun, and C. S. Hong, “Attention on personalized
clinical decision support system: Federated learning approach,” in
<em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Big Data and Smart Computing
(BigComp)</em>.   IEEE, 2021, pp. 141–147.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
J. Pang, Y. Huang, Z. Xie, J. Li, and Z. Cai, “Collaborative city digital twin
for the covid-19 pandemic: A federated learning solution,” <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Tsinghua
Science and Technology</em>, vol. 26, no. 5, pp. 759–771, 2021.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
P. Kumar, R. Kumar, G. Srivastava, G. P. Gupta, R. Tripathi, T. R. Gadekallu,
and N. Xiong, “PPSF: A privacy-preserving and secure framework using
blockchain-based machine-learning for IoT-driven smart cities,” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Network Science and Engineering</em>, 2021.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Y. Liu, X. Yuan, Z. Xiong, J. Kang, X. Wang, and D. Niyato, “Federated
learning for 6g communications: Challenges, methods, and future directions,”
<em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">China Communications</em>, vol. 17, no. 9, pp. 105–118, 2020.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, J. Huang, Z. Xiong, J. Kang, D. Niyato, X.-S. Hua, C. Leung, and
C. Miao, “Towards federated learning in uav-enabled internet of vehicles: A
multi-dimensional contract-matching approach,” <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Intelligent Transportation Systems</em>, 2021.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas,
M. N. Galtier, B. A. Landman, K. Maier-Hein <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “The future of
digital health with federated learning,” <em id="bib.bib74.2.2" class="ltx_emph ltx_font_italic">NPJ digital medicine</em>,
vol. 3, no. 1, pp. 1–7, 2020.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
S. Hakak, S. Ray, W. Z. Khan, and E. Scheme, “A framework for edge-assisted
healthcare data analytics using federated learning,” in <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">2020 IEEE
International Conference on Big Data (Big Data)</em>.   IEEE, 2020, pp. 3423–3427.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
A. Qayyum, K. Ahmad, M. A. Ahsan, A. Al-Fuqaha, and J. Qadir, “Collaborative
federated learning for healthcare: Multi-modal covid-19 diagnosis at the
edge,” <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.07511</em>, 2021.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
S. Silva, B. A. Gutman, E. Romero, P. M. Thompson, A. Altmann, and M. Lorenzi,
“Federated learning in distributed medical databases: Meta-analysis of
large-scale subcortical brain data,” in <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 16th international
symposium on biomedical imaging (ISBI 2019)</em>.   IEEE, 2019, pp. 270–274.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Q. Wu, X. Chen, Z. Zhou, and J. Zhang, “Fedhome: Cloud-edge based personalized
federated learning for in-home health monitoring,” <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Mobile Computing</em>, 2020.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
M. J. Sheller, B. Edwards, G. A. Reina, J. Martin, S. Pati, A. Kotrotsou,
M. Milchenko, W. Xu, D. Marcus, R. R. Colen <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated
learning in medicine: facilitating multi-institutional collaborations without
sharing patient data,” <em id="bib.bib79.2.2" class="ltx_emph ltx_font_italic">Scientific reports</em>, vol. 10, no. 1, pp. 1–12,
2020.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
R. Wang, J. Xu, Y. Ma, M. Talha, M. S. Al-Rakhami, and A. Ghoneim, “Auxiliary
diagnosis of covid-19 based on 5g-enabled federated learning,” <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">IEEE
Network</em>, vol. 35, no. 3, pp. 14–20, 2021.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
I. Feki, S. Ammar, Y. Kessentini, and K. Muhammad, “Federated learning for
covid-19 screening from chest x-ray images,” <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Applied Soft Computing</em>,
vol. 106, p. 107330, 2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
X. Li, Y. Gu, N. Dvornek, L. H. Staib, P. Ventola, and J. S. Duncan,
“Multi-site fmri analysis using privacy-preserving federated learning and
domain adaptation: Abide results,” <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">Medical Image Analysis</em>, vol. 65,
p. 101765, 2020.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
O. El Rifai, M. Biotteau, X. de Boissezon, I. Megdiche, F. Ravat, and O. Teste,
“Blockchain-based federated learning in medicine,” in <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">International
Conference on Artificial Intelligence in Medicine</em>.   Springer, 2020, pp. 214–224.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
R. Kumar, A. A. Khan, J. Kumar, A. Zakria, N. A. Golilarz, S. Zhang, Y. Ting,
C. Zheng, and W. Wang, “Blockchain-federated-learning and deep learning
models for covid-19 detection using ct imaging,” <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">IEEE Sensors
Journal</em>, 2021.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Z. Du, C. Wu, T. Yoshinaga, K.-L. A. Yau, Y. Ji, and J. Li, “Federated
learning for vehicular internet of things: Recent advances and open issues,”
<em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">IEEE Open Journal of the Computer Society</em>, vol. 1, pp. 45–61, 2020.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
A. B. Sada, M. A. Bouras, J. Ma, H. Runhe, and H. Ning, “A distributed video
analytics architecture based on edge-computing and federated learning,” in
<em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl
Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data
Computing, Intl Conf on Cyber Science and Technology Congress
(DASC/PiCom/CBDCom/CyberSciTech)</em>.   IEEE, 2019, pp. 215–220.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
C. Xu and Y. Mao, “An improved traffic congestion monitoring system based on
federated learning,” <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">Information</em>, vol. 11, no. 7, p. 365, 2020.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Y. Qi, M. S. Hossain, J. Nie, and X. Li, “Privacy-preserving blockchain-based
federated learning for traffic flow prediction,” <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Future Generation
Computer Systems</em>, vol. 117, pp. 328–337, 2021.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Y. Liu, J. James, J. Kang, D. Niyato, and S. Zhang, “Privacy-preserving
traffic flow prediction: A federated learning approach,” <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">IEEE Internet
of Things Journal</em>, vol. 7, no. 8, pp. 7751–7763, 2020.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
N. I. Mowla, N. H. Tran, I. Doh, and K. Chae, “Federated learning-based
cognitive detection of jamming attack in flying ad-hoc network,” <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 8, pp. 4338–4350, 2019.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Y. M. Saputra, D. T. Hoang, D. N. Nguyen, E. Dutkiewicz, M. D. Mueck, and
S. Srikanteswara, “Energy demand prediction with federated learning for
electric vehicle networks,” in <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Global Communications
Conference (GLOBECOM)</em>.   IEEE, 2019,
pp. 1–6.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
A. T. Thorgeirsson, S. Scheubner, S. Fünfgeld, and F. Gauterin,
“Probabilistic prediction of energy demand and driving range for electric
vehicles with federated learning,” <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">IEEE Open Journal of Vehicular
Technology</em>, vol. 2, pp. 151–161, 2021.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
A. K. Bashir, S. Khan, B. Prabadevi, N. Deepa, W. S. Alnumay, T. R. Gadekallu,
and P. K. R. Maddikunta, “Comparative analysis of machine learning
algorithms for prediction of smart grid stability,” <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">International
Transactions on Electrical Energy Systems</em>, p. e12706, 2021.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
A. Kumari, R. Gupta, S. Tanwar, S. Tyagi, and N. Kumar, “When blockchain meets
smart grid: Secure energy trading in demand response management,” <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">IEEE
Network</em>, vol. 34, no. 5, pp. 299–305, 2020.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
A. Taïk and S. Cherkaoui, “Electrical load forecasting using edge
computing and federated learning,” in <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International
Conference on Communications (ICC)</em>.   IEEE, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Y. L. Tun, K. Thar, C. M. Thwal, and C. S. Hong, “Federated learning based
energy demand prediction with clustered aggregation,” in <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">2021 IEEE
International Conference on Big Data and Smart Computing (BigComp)</em>.   IEEE, 2021, pp. 164–167.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
J. Li, Y. Ren, S. Fang, K. Li, and M. Sun, “Federated learning-based
ultra-short term load forecasting in power internet of things,” in
<em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Conference on Energy Internet (ICEI)</em>.   IEEE, 2020, pp. 63–68.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
M. Savi and F. Olivadese, “Short-term energy consumption forecasting at the
edge: A federated learning approach,” <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 2021.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Q. Guo, F. Zhuang, C. Qin, H. Zhu, X. Xie, H. Xiong, and Q. He, “A survey on
knowledge graph-based recommender systems,” <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Knowledge and Data Engineering</em>, 2020.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
A. Jalalirad, M. Scavuzzo, C. Capota, and M. Sprague, “A simple and efficient
federated recommender system,” in <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 6th IEEE/ACM
International Conference on Big Data Computing, Applications and
Technologies</em>, 2019, pp. 53–58.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
B. Tan, B. Liu, V. Zheng, and Q. Yang, “A federated recommender system for
online services,” in <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Fourteenth ACM Conference on Recommender
Systems</em>, 2020, pp. 579–581.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
C. Niu, F. Wu, S. Tang, L. Hua, R. Jia, C. Lv, Z. Wu, and G. Chen,
“Billion-scale federated learning on mobile clients: a submodel design with
tunable privacy,” in <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th Annual International
Conference on Mobile Computing and Networking</em>, 2020, pp. 1–14.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
K. Muhammad, Q. Wang, D. O’Reilly-Morgan, E. Tragos, B. Smyth, N. Hurley,
J. Geraci, and A. Lawlor, “Fedfast: Going beyond average for faster training
of federated recommender systems,” in <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th ACM
SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, 2020,
pp. 1234–1242.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
S. Niknam, H. S. Dhillon, and J. H. Reed, “Federated learning for wireless
communications: Motivation, opportunities, and challenges,” <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">IEEE
Communications Magazine</em>, vol. 58, no. 6, pp. 46–51, 2020.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Y. Liu, J. Peng, J. Kang, A. M. Iliyasu, D. Niyato, and A. A. Abd El-Latif, “A
secure federated learning framework for 5g networks,” <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol. 27, no. 4, pp. 24–31, 2020.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
J. Zhou, S. Zhang, Q. Lu, W. Dai, M. Chen, X. Liu, S. Pirttikangas, Y. Shi,
W. Zhang, and E. Herrera-Viedma, “A survey on federated learning and its
applications for accelerating industrial internet of things,” <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2104.10501</em>, 2021.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
A. K. Sangaiah, A. Goli, E. B. Tirkolaee, M. Ranjbar-Bourani, H. M. Pandey, and
W. Zhang, “Big data-driven cognitive computing system for optimization of
social media analytics,” <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">Ieee Access</em>, vol. 8, pp. 82 215–82 226,
2020.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
R. Doku, D. B. Rawat, and C. Liu, “Towards federated learning approach to
determine data relevance in big data,” in <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 20th International
Conference on Information Reuse and Integration for Data Science
(IRI)</em>.   IEEE, 2019, pp. 184–192.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
B. Brik, A. Ksentini, and M. Bouaziz, “Federated learning for uavs-enabled
wireless networks: Use cases, challenges, and open problems,” <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 8, pp. 53 841–53 849, 2020.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
P. K. Sharma, J. H. Park, and K. Cho, “Blockchain and federated learning-based
distributed computing defence framework for sustainable society,”
<em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Sustainable Cities and Society</em>, vol. 59, p. 102220, 2020.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, T. Parcollet, P. P. de Gusmão,
and N. D. Lane, “Flower: A friendly federated learning research framework,”
<em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14390</em>, 2020.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and
J. Passerat-Palmbach, “A generic framework for privacy preserving deep
learning,” <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
C. He, S. Li, J. So, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh,
H. Qiu, L. Shen, P. Zhao, Y. Kang, Y. Liu, R. Raskar, Q. Yang, M. Annavaram,
and S. Avestimehr, “Fedml: A research library and benchmark for federated
machine learning,” <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>, 2020.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan,
V. Smith, and A. Talwalkar, “Leaf: A benchmark for federated settings,”
<em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
Y. LeCun, “The mnist database of handwritten digits,” <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">http://yann.
lecun. com/exdb/mnist/</em>, 1998.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using
distant supervision,” <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">CS224N project report, Stanford</em>, vol. 1,
no. 12, p. 2009, 2009.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
W. Shakespeare, <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">The complete works of William Shakespeare</em>.   Wordsworth Editions, 2007.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Z. Liu, P. Luo, X. Wang, and X. Tang, “Deep learning face attributes in the
wild,” in <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, 2015, pp. 3730–3738.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
T. Li, M. Sanjabi, A. Beirami, and V. Smith, “Fair resource allocation in
federated learning,” <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.10497</em>, 2019.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, and A. Talwalkar, “Federated multi-task
learning,” <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1705.10467</em>, 2017.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
P. M. Mammen, “Federated learning: Opportunities and challenges,” <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2101.05428</em>, 2021.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
Q. Xia, W. Ye, Z. Tao, J. Wu, and Q. Li, “A survey of federated learning for
edge computing: Research problems and solutions,” <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">High-Confidence
Computing</em>, p. 100008, 2021.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances
and open problems in federated learning,” <em id="bib.bib124.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1912.04977</em>, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2110.04159" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2110.04160" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2110.04160">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2110.04160" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2110.04161" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 22:56:31 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
