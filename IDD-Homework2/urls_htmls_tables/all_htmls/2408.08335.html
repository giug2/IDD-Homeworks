<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Plan with Code: Comparing approaches for robust NL to DSL generation</title>
<!--Generated on Thu Aug 15 04:21:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.08335v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S1" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S2" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S2.SS1" title="In 2 Related Work ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Code Generation or Program Synthesis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S2.SS2" title="In 2 Related Work ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Reasoning and Tool Integration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S2.SS3" title="In 2 Related Work ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Contributions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS1" title="In 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Fine-Tuned NL2DSL Generation Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS2" title="In 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Grounding with dynamically selected few-shots</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS2.SSS1" title="In 3.2 Grounding with dynamically selected few-shots ‣ 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Pre-trained Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS2.SSS2" title="In 3.2 Grounding with dynamically selected few-shots ‣ 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>TST based BERT Fine-tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS3" title="In 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Grounding with API Metadata</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS3.SSS1" title="In 3.3 Grounding with API Metadata ‣ 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>API Function Definitions for Few-Shots</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS3.SSS2" title="In 3.3 Grounding with API Metadata ‣ 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Semantic Function Definitions</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment Design and Metrics Definition</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.SS1" title="In 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Dataset Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.SS2" title="In 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>DSL Generation Quality Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.SS2.SSS1" title="In 4.2 DSL Generation Quality Metrics ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Average Similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.SS2.SSS2" title="In 4.2 DSL Generation Quality Metrics ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Unparsed rate</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.SS2.SSS3" title="In 4.2 DSL Generation Quality Metrics ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Hallucination rate</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.SS1" title="In 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Impact of number of few-shots</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.SS2" title="In 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>TST vs Pre-trained Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.SS3" title="In 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Regular Function Definition vs Semantic Function Definitions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.SS4" title="In 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Out of Domain APIs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S6" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S7" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Ethical Considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S8" title="In Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Example Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S8.SS1" title="In 8 Example Appendix ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Sample with computed Average similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S8.SS2" title="In 8 Example Appendix ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>An example of API metdata</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Plan with Code: Comparing approaches for robust NL to DSL generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nastaran Bassamzadeh  Chhaya Methani
<br class="ltx_break"/>Microsoft Corporation
<br class="ltx_break"/>Redmond, USA
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Planning in code is considered a more reliable approach for many orchestration tasks. This is because code is more tractable than steps generated via Natural Language and make it easy to support more complex sequences by abstracting deterministic logic into functions. It also allows spotting issues with incorrect function names with the help of parsing checks that can be run on code. Progress in Code Generation methodologies, however, remains limited to general-purpose languages like C, C++, and Python. LLMs continue to face challenges with custom function names in Domain Specific Languages or DSLs, leading to higher hallucination rates and syntax errors. This is more common for custom function names, that are typically part of the plan. Moreover, keeping LLMs up-to-date with newer function names is an issue. This poses a challenge for scenarios like task planning over a large number of APIs, since the plan is represented as a DSL having custom API names. In this paper, we focus on workflow automation in RPA (Robotic Process Automation) domain as a special case of task planning. We present optimizations for using Retrieval Augmented Generation (or RAG) with LLMs for DSL generation along with an ablation study comparing these strategies with a fine-tuned model. Our results showed that the fine-tuned model scored the best on code similarity metric. However, with our optimizations, RAG approach is able to match the quality for in-domain API names in the test set. Additionally, it offers significant advantage for out-of-domain or unseen API names, outperforming Fine-Tuned model on similarity metric by 7 pts.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Plan with Code: Comparing approaches for robust NL to DSL generation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Nastaran Bassamzadeh  Chhaya Methani</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1">Microsoft Corporation</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1">Redmond, USA</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">There has been significant progress made in improving and quantifying the quality of Natural Language to Code Generation or NL2Code (<cite class="ltx_cite ltx_citemacro_citep">Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib3" title="">2021</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Nguyen and Nadi, <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib17" title="">2022</a></cite>). Recent improvements in models for general-purpose languages like Python, C++ and Java can be attributed to larger LLMs (<cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib2" title="">ChatGPT, </a></cite>, <cite class="ltx_cite ltx_citemacro_citep">GPT-, <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib8" title="">4</a></cite>) and the availability of Pre-trained open-source models (<cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib4" title="">Code Llama, </a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib1" title="">2024</a></cite>, <cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib5" title="">Codestral, </a></cite>) advancing the state-of-the-art. However, there hasn’t been a focus on improving quality of Natural Language to Domain Specific Languages or NL2DSL, which a lot of enterprise applications rely on.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Domain Specific Languages (or DSLs) are custom computer languages designed and optimized for specific applications. Examples of DSLs include SQL and industry-specific languages for formalizing API calls, often using formats like JSON or YAML to represent API sequences. In this paper, we focus on the task of generating a DSL used for authoring high-level automation workflows across thousands of web-scale APIs. These workflows support a variety of customer scenarios like invoice processing, sales lead integration with forms/emails etc. The automation DSL represents API names as functions and codifies a sequence of API calls (or a plan) along with conditional logic over the invocation of APIs. The syntax itself borrows from known languages like Javascript, however, the logic resembling the workflow along with the custom function names, make it unique. An example of the DSL is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Existing code generation methods are hard to adapt for this scenario due to the frequent hallucinations and syntax errors. This is largely due to the custom API names, high cardinality and diversity of APIs in public as well private domain along with the ever-changing API landscape. A typical workflow can choose among thousands of publicly available APIs (eg. Database connectors, Emails, Planner, Notifications etc.) as well as private APIs in tenant subscriptions and string them together to automate business processes.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we outline an end to end system architecture for NL2DSL generation with high response rate using selective improvements to RAG techniques (<cite class="ltx_cite ltx_citemacro_citep">Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib15" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Poesia et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib21" title="">2022</a></cite>) using OpenAI models. We focus on bench-marking the impact of different contexts used for grounding. We fine-tuned a Codex model for NL2DSL and show a comparative analysis of the impact of the approaches used to optimize RAG.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The remainder of this study is structured as follows. In Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S2" title="2 Related Work ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">2</span></a>, we present the NL2DSL problem formulation along with literature review. Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3" title="3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">3</span></a> lays out and describes the optimizations we made to RAG as discussed above along with the benchmark Fine-Tuned model. Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4" title="4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">4</span></a> discusses Data Generation, Metric definition and Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5" title="5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">5</span></a> shares our results and discussion followed by Conclusion in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S6" title="6 Conclusion ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>System Architecture to show e2e working of
our DSL generation methodology using RAG. TST based semantic mapping
retrieves the relevant code snippet as shown. This helps get the right syntax. However, it gets the correct function name for approval from the API metadata</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Code Generation or Program Synthesis</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Program Synthesis is a hard research problem (<cite class="ltx_cite ltx_citemacro_citep">Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib9" title="">2021</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib13" title="">2022</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib25" title="">2021</a></cite>). It has gained significant interest with many open-source models (<cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib4" title="">Code Llama, </a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib12" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib5" title="">Codestral, </a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib1" title="">2024</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib3" title="">2021</a></cite>) focusing on general programming languages. Many of these advancements have been achieved through pre-training language models for code generation with a focus on improving datasets (<cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib4" title="">Code Llama, </a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib1" title="">2024</a></cite>). However, for domain adaptation, <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">instruction fine-tuning</span> on top of a base model remains a popular approach (<cite class="ltx_cite ltx_citemacro_citep">Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib3" title="">2021</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib7" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Lewkowycz et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib11" title="">2022</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Patil et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib20" title="">2023</a></cite>).</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Prompting LLMs is an alternative technique for code generation (<cite class="ltx_cite ltx_citemacro_citep">Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib15" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">White et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib24" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib23" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib10" title="">2023</a></cite>). Most papers focus on metaprompt optimization and learning, while <cite class="ltx_cite ltx_citemacro_citep">Poesia et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib21" title="">2022</a></cite> focused on improving response quality by dynamically selecting few-shots for grounding the model.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Reasoning and Tool Integration</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">For modeling the problem of selecting a sequence of API calls, we need to consider formulating it as a <span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.1">planning</span> or <span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.2">reasoning</span> task. LLMs show remarkable reasoning capability, however, they also have limitations when it comes to staying up-to-date with recent knowledge, performing mathematical calculations etc. A popular way to overcome this has been granting the LLMs access to external tools. This framework gained significant popularity with OpenAI Code Interpreter’s success (<cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib18" title="">OpenAI Code Interpretor, </a></cite>).</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">External Tool Integration has been studied since with a focus on including specific tools such as web search (<cite class="ltx_cite ltx_citemacro_citep">Schick et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib22" title="">2023</a></cite>), python code interpreters (<cite class="ltx_cite ltx_citemacro_citep">Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib7" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib18" title="">OpenAI Code Interpretor, </a></cite>), adding calculators (<cite class="ltx_cite ltx_citemacro_citep">Parisi et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib19" title="">2022</a></cite> <cite class="ltx_cite ltx_citemacro_citep">Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib7" title="">2023</a></cite>) and so on. Expanding the tool set to a generic list of tools has been explored (<cite class="ltx_cite ltx_citemacro_citep">Schick et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib22" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Patil et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib20" title="">2023</a></cite>), but it remains limited and often predicts single tool instead of sequences needed for most enterprise scenarios. Tool Use has mostly been explored in the context of generating more accurate text outputs for Q&amp;A tasks with the help of external tools(<cite class="ltx_cite ltx_citemacro_citep">Schick et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib22" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Parisi et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib19" title="">2022</a></cite>).</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">There is an increase in focus on incorporating LLM’s code generation capabilities to reasoning and task orchestration making this an area of active research (<cite class="ltx_cite ltx_citemacro_citep">Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib7" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib14" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Patil et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib20" title="">2023</a></cite>). However, similar to Q&amp;A scenarios mentioned above, most of the research either limits the tools to a set of small well-documented APIs (<cite class="ltx_cite ltx_citemacro_citep">Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib7" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib14" title="">2023</a></cite>), or limited their scope to predicting a single output API (<cite class="ltx_cite ltx_citemacro_citep">Patil et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib20" title="">2023</a></cite>, <cite class="ltx_cite ltx_citemacro_citep">Schick et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib22" title="">2023</a></cite>).</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Posing the reasoning or orchestration task as a code generation problem is similar to the API sequence generation scenario highlighted in this paper. Improving the quality of Natural Language to DSL generation, is thus beneficial for both reasoning and plan generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Contributions</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">NL2DSL generation suffers from the hallucination and quality issues we discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S1" title="1 Introduction ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">1</span></a>. Few studies address the challenges of end-to-end DSL generation, specifically over a large set of custom APIs. In this paper, we present an end-to-end system architecture with improved strategies to add grounding context with known RAG techniques. We also present an ablation study showing improvements for DSL generation quality for enterprise settings. DSL samples in our test set consider API or tool selection sequences of 5-6 API calls, also referred to as chain of tools, which is a first to the best of our knowledge. We also consider the real-world scenarios of adding conditional logic with API calls as shown with an example in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Fine-Tuned NL2DSL Generation Model</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We took the Codex base model from OpenAI due to it’s pre-training with code samples and used LoRA-based fine-tuning approach. The training set consists of NL-DSL pairs, NL refers to the user query and the DSL represents the workflow that the user is looking to automate. The training set consists of a pool of 67k samples in the form of (prompt, flow) tuples with the NL generated synthetically (details in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.SS1" title="4.1 Dataset Generation ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">4.1</span></a>, examples of NL-DSL are shared in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">1</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S8" title="8 Example Appendix ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">8</span></a>).</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We ran many iterations on this model to improve performance on the test set, specifically for the body and tail connectors, and went through multiple rounds of data augmentation. We found that predicting the parameter keys was very challenging with the fine-tuned model due to limitation of high-quality data generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Grounding with dynamically selected few-shots</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">We tried two types of grounding information for RAG based DSL generation as described below. For each technique, we selected <math alttext="5" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn id="S3.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">5</annotation></semantics></math> and <math alttext="20" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><cn id="S3.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">20</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">20</annotation></semantics></math> few-shots dynamically, and compared performance impact driven by the approach used for sample selection.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Pre-trained Model</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">The first approach is using a vanilla Pre-trained model for determining the semantic similarity of NL-DSL samples based on the NL query. We computed the embeddings of NL queries using a Distil-RoBERTa Pre-trained model. We created a Faiss Index (<cite class="ltx_cite ltx_citemacro_citep">Douze et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib6" title="">2024</a></cite>) for these embeddings to help with search over the dense embedding space.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>TST based BERT Fine-tuning</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">In this approach, we fine-tuned the Pre-trained model to improve retrieval accuracy of few-shots similar to the work done by <cite class="ltx_cite ltx_citemacro_citep">Poesia et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib21" title="">2022</a></cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.2">To get positive and negative samples for fine-tuning, we generated embeddings for all NL queries in our dataset using a Pre-trained Tansformer model. A pair of tuples is considered a positive sample if the cosine similarity between their corresponding NL prompts is greater than <math alttext="0.7" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.1.m1.1"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mn id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">0.7</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><cn id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" type="float" xref="S3.SS2.SSS2.p2.1.m1.1.1">0.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">0.7</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.1.m1.1d">0.7</annotation></semantics></math> and negative otherwise. We generated <math alttext="100k" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.2.m2.1"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mrow id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml"><mn id="S3.SS2.SSS2.p2.2.m2.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml">100</mn><mo id="S3.SS2.SSS2.p2.2.m2.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.2.m2.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><apply id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1"><times id="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1"></times><cn id="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml" type="integer" xref="S3.SS2.SSS2.p2.2.m2.1.1.2">100</cn><ci id="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">100k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.2.m2.1d">100 italic_k</annotation></semantics></math> pairs this way and leveraged them as training data for our fine-tuned model.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.3">The loss function used by TST (Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.E1" title="In 3.2.2 TST based BERT Fine-tuning ‣ 3.2 Grounding with dynamically selected few-shots ‣ 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">1</span></a> from <cite class="ltx_cite ltx_citemacro_citep">Poesia et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib21" title="">2022</a></cite>) is minimizing the Mean-Squared Error between the vanilla loss functions comparing the utterances (<math alttext="u_{i},u_{j}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.1.m1.2"><semantics id="S3.SS2.SSS2.p3.1.m1.2a"><mrow id="S3.SS2.SSS2.p3.1.m1.2.2.2" xref="S3.SS2.SSS2.p3.1.m1.2.2.3.cmml"><msub id="S3.SS2.SSS2.p3.1.m1.1.1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.1.m1.1.1.1.1.2" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1.2.cmml">u</mi><mi id="S3.SS2.SSS2.p3.1.m1.1.1.1.1.3" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS2.p3.1.m1.2.2.2.3" xref="S3.SS2.SSS2.p3.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS2.p3.1.m1.2.2.2.2" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2.2.cmml">u</mi><mi id="S3.SS2.SSS2.p3.1.m1.2.2.2.2.3" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.2b"><list id="S3.SS2.SSS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.2.2"><apply id="S3.SS2.SSS2.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1.2">𝑢</ci><ci id="S3.SS2.SSS2.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS2.p3.1.m1.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2.2">𝑢</ci><ci id="S3.SS2.SSS2.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.2.2.2.3">𝑗</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.2c">u_{i},u_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.1.m1.2d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>) and the target programs (<math alttext="p_{i},p_{j}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.2.m2.2"><semantics id="S3.SS2.SSS2.p3.2.m2.2a"><mrow id="S3.SS2.SSS2.p3.2.m2.2.2.2" xref="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml"><msub id="S3.SS2.SSS2.p3.2.m2.1.1.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2.cmml">p</mi><mi id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS2.p3.2.m2.2.2.2.3" xref="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS2.p3.2.m2.2.2.2.2" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2.cmml">p</mi><mi id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.2b"><list id="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2"><apply id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2">𝑝</ci><ci id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2">𝑝</ci><ci id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3">𝑗</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.2c">p_{i},p_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.2.m2.2d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>). Program similarity is denoted by <math alttext="S" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.3.m3.1"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><mi id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><ci id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.3.m3.1d">italic_S</annotation></semantics></math>. We used a Jaccard score over lists of API function names as the similarity metric between programs.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{TST}(\theta):=E_{i,j~{}D}[f_{\theta}(u_{i},u_{j})-S(P_{i},p_{j})]^{2}" class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.4.4.3" xref="S3.E1.m1.4.4.3.cmml"><msub id="S3.E1.m1.4.4.3.2" xref="S3.E1.m1.4.4.3.2.cmml"><mi id="S3.E1.m1.4.4.3.2.2" xref="S3.E1.m1.4.4.3.2.2.cmml">L</mi><mrow id="S3.E1.m1.4.4.3.2.3" xref="S3.E1.m1.4.4.3.2.3.cmml"><mi id="S3.E1.m1.4.4.3.2.3.2" xref="S3.E1.m1.4.4.3.2.3.2.cmml">T</mi><mo id="S3.E1.m1.4.4.3.2.3.1" xref="S3.E1.m1.4.4.3.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.3.2.3.3" xref="S3.E1.m1.4.4.3.2.3.3.cmml">S</mi><mo id="S3.E1.m1.4.4.3.2.3.1a" xref="S3.E1.m1.4.4.3.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.3.2.3.4" xref="S3.E1.m1.4.4.3.2.3.4.cmml">T</mi></mrow></msub><mo id="S3.E1.m1.4.4.3.1" xref="S3.E1.m1.4.4.3.1.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.3.3.2" xref="S3.E1.m1.4.4.3.cmml"><mo id="S3.E1.m1.4.4.3.3.2.1" stretchy="false" xref="S3.E1.m1.4.4.3.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">θ</mi><mo id="S3.E1.m1.4.4.3.3.2.2" rspace="0.278em" stretchy="false" xref="S3.E1.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.2" rspace="0.278em" xref="S3.E1.m1.4.4.2.cmml">:=</mo><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.cmml"><msub id="S3.E1.m1.4.4.1.3" xref="S3.E1.m1.4.4.1.3.cmml"><mi id="S3.E1.m1.4.4.1.3.2" xref="S3.E1.m1.4.4.1.3.2.cmml">E</mi><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">i</mi><mo id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.1.cmml"><mi id="S3.E1.m1.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.1.2.cmml">j</mi><mo id="S3.E1.m1.2.2.2.2.1.1" lspace="0.230em" xref="S3.E1.m1.2.2.2.2.1.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.1.3.cmml">D</mi></mrow></mrow></msub><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.2.cmml">⁢</mo><msup id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.2.cmml"><mo id="S3.E1.m1.4.4.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.2.cmml"><msub id="S3.E1.m1.4.4.1.1.1.1.1.2.4" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.2.4.2" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4.2.cmml">f</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.2.4.3" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4.3.cmml">θ</mi></msub><mo id="S3.E1.m1.4.4.1.1.1.1.1.2.3" xref="S3.E1.m1.4.4.1.1.1.1.1.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.3.cmml"><mo id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml">u</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.4" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.2.cmml">u</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.1.1.1.5" xref="S3.E1.m1.4.4.1.1.1.1.1.5.cmml">−</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.4" xref="S3.E1.m1.4.4.1.1.1.1.1.4.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.4.4" xref="S3.E1.m1.4.4.1.1.1.1.1.4.4.cmml">S</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.4.3" xref="S3.E1.m1.4.4.1.1.1.1.1.4.3.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.3.cmml"><mo id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.3" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.3.cmml">(</mo><msub id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.2.cmml">P</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.4" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.3.cmml">,</mo><msub id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.2.cmml">p</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.3" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.5" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.4.4.1.1.1.2.1.cmml">]</mo></mrow><mn id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><csymbol cd="latexml" id="S3.E1.m1.4.4.2.cmml" xref="S3.E1.m1.4.4.2">assign</csymbol><apply id="S3.E1.m1.4.4.3.cmml" xref="S3.E1.m1.4.4.3"><times id="S3.E1.m1.4.4.3.1.cmml" xref="S3.E1.m1.4.4.3.1"></times><apply id="S3.E1.m1.4.4.3.2.cmml" xref="S3.E1.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.2.1.cmml" xref="S3.E1.m1.4.4.3.2">subscript</csymbol><ci id="S3.E1.m1.4.4.3.2.2.cmml" xref="S3.E1.m1.4.4.3.2.2">𝐿</ci><apply id="S3.E1.m1.4.4.3.2.3.cmml" xref="S3.E1.m1.4.4.3.2.3"><times id="S3.E1.m1.4.4.3.2.3.1.cmml" xref="S3.E1.m1.4.4.3.2.3.1"></times><ci id="S3.E1.m1.4.4.3.2.3.2.cmml" xref="S3.E1.m1.4.4.3.2.3.2">𝑇</ci><ci id="S3.E1.m1.4.4.3.2.3.3.cmml" xref="S3.E1.m1.4.4.3.2.3.3">𝑆</ci><ci id="S3.E1.m1.4.4.3.2.3.4.cmml" xref="S3.E1.m1.4.4.3.2.3.4">𝑇</ci></apply></apply><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝜃</ci></apply><apply id="S3.E1.m1.4.4.1.cmml" xref="S3.E1.m1.4.4.1"><times id="S3.E1.m1.4.4.1.2.cmml" xref="S3.E1.m1.4.4.1.2"></times><apply id="S3.E1.m1.4.4.1.3.cmml" xref="S3.E1.m1.4.4.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.3.1.cmml" xref="S3.E1.m1.4.4.1.3">subscript</csymbol><ci id="S3.E1.m1.4.4.1.3.2.cmml" xref="S3.E1.m1.4.4.1.3.2">𝐸</ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝑖</ci><apply id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1"></times><ci id="S3.E1.m1.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.2">𝑗</ci><ci id="S3.E1.m1.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.3">𝐷</ci></apply></list></apply><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1">superscript</csymbol><apply id="S3.E1.m1.4.4.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.4.4.1.1.1.2.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.4.4.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1"><minus id="S3.E1.m1.4.4.1.1.1.1.1.5.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.5"></minus><apply id="S3.E1.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2"><times id="S3.E1.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.3"></times><apply id="S3.E1.m1.4.4.1.1.1.1.1.2.4.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.2.4.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.2.4.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4.2">𝑓</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.2.4.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.4.3">𝜃</ci></apply><interval closure="open" id="S3.E1.m1.4.4.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2"><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.2">𝑢</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.2">𝑢</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.2.2.2.2.3">𝑗</ci></apply></interval></apply><apply id="S3.E1.m1.4.4.1.1.1.1.1.4.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4"><times id="S3.E1.m1.4.4.1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.3"></times><ci id="S3.E1.m1.4.4.1.1.1.1.1.4.4.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.4">𝑆</ci><interval closure="open" id="S3.E1.m1.4.4.1.1.1.1.1.4.2.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2"><apply id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.2">𝑃</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.3.1.1.1.3">𝑖</ci></apply><apply id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.2">𝑝</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.4.2.2.2.3">𝑗</ci></apply></interval></apply></apply></apply><cn id="S3.E1.m1.4.4.1.1.3.cmml" type="integer" xref="S3.E1.m1.4.4.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">L_{TST}(\theta):=E_{i,j~{}D}[f_{\theta}(u_{i},u_{j})-S(P_{i},p_{j})]^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">italic_L start_POSTSUBSCRIPT italic_T italic_S italic_T end_POSTSUBSCRIPT ( italic_θ ) := italic_E start_POSTSUBSCRIPT italic_i , italic_j italic_D end_POSTSUBSCRIPT [ italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) - italic_S ( italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Grounding with API Metadata</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In addition to few-shots, we appended the API metadata in the metaprompt. This metadata includes Function Description along with the parameter keys and their description (Example API Function Definition shared in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S8" title="8 Example Appendix ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">8</span></a>). We followed the below two approaches for selecting the metadata to be added.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>API Function Definitions for Few-Shots</h4>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">For few-shot samples selected using the methods described above, we extracted the metadata for <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS1.p1.1.1">each of</span> the functions present in those samples. This means that for the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.1.m1.1"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.1.m1.1d">italic_n</annotation></semantics></math> few-shot samples dynamically added to the metaprompt, we iterated over all the API function names in each of these flows and added their function definitions to the metaprompt.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Semantic Function Definitions</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">Another approach for selecting function definitions is to retrieve semantically similar functions from a vector database created with API metadata. This approach is similar to the one followed by (<cite class="ltx_cite ltx_citemacro_citep"><a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#bib.bib16" title="">LlamaIndex, </a></cite>). We created an index of all API definitions and used the input NL query for search. Please note that this is different from the faiss index created for few-shot samples in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3.SS2" title="3.2 Grounding with dynamically selected few-shots ‣ 3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.p2">
<p class="ltx_p" id="S3.SS3.SSS2.p2.1">We call this approach <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p2.1.1">Semantic Function Definition (SFD)</span> and will compare it with the <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p2.1.2">Regular FDs</span> described above. This approach can be specifically useful for tail-ish prompts where no few-shots might be retrieved.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment Design and Metrics Definition</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we outline the process of Dataset Generation and introduce the metrics we used for estimating the code quality. We then describe our experiments. We have used Azure AML pipelines and GPT-4 (16k token limit) for our experiments.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.12">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T1.12.13.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.12.13.1.2">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S4.T1.12.13.1.2.1" style="width:56.9pt;">
<span class="ltx_p" id="S4.T1.12.13.1.2.1.1">Num. of</span>
<span class="ltx_p" id="S4.T1.12.13.1.2.1.2">few-shots</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.12.13.1.3">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S4.T1.12.13.1.3.1" style="width:71.1pt;">
<span class="ltx_p" id="S4.T1.12.13.1.3.1.1">Avg. similarity</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.12.13.1.4">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S4.T1.12.13.1.4.1" style="width:56.9pt;">
<span class="ltx_p" id="S4.T1.12.13.1.4.1.1">%Unparsed flows</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.12.13.1.5">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S4.T1.12.13.1.5.1" style="width:56.9pt;">
<span class="ltx_p" id="S4.T1.12.13.1.5.1.1">%Made-up API names</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.12.13.1.6">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S4.T1.12.13.1.6.1" style="width:56.9pt;">
<span class="ltx_p" id="S4.T1.12.13.1.6.1.1">%Made-up parameters</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.5.1">Pre-trained wo FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.6">20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1"><math alttext="+0.03" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mrow id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T1.1.1.1.m1.1.1a" mathvariant="bold" xref="S4.T1.1.1.1.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S4.T1.1.1.1.m1.1.1.2" mathvariant="bold" xref="S4.T1.1.1.1.m1.1.1.2.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"><plus id="S4.T1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"></plus><cn id="S4.T1.1.1.1.m1.1.1.2.cmml" type="float" xref="S4.T1.1.1.1.m1.1.1.2">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">+0.03</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">bold_+ bold_0.03</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2"><math alttext="-3.37" class="ltx_Math" display="inline" id="S4.T1.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.m1.1a"><mrow id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T1.2.2.2.m1.1.1a" mathvariant="bold" xref="S4.T1.2.2.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S4.T1.2.2.2.m1.1.1.2" mathvariant="bold" xref="S4.T1.2.2.2.m1.1.1.2.cmml">3.37</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1"><minus id="S4.T1.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1"></minus><cn id="S4.T1.2.2.2.m1.1.1.2.cmml" type="float" xref="S4.T1.2.2.2.m1.1.1.2">3.37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">-3.37</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.m1.1d">bold_- bold_3.37</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.3"><math alttext="-7.34" class="ltx_Math" display="inline" id="S4.T1.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.m1.1a"><mrow id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml"><mo id="S4.T1.3.3.3.m1.1.1a" xref="S4.T1.3.3.3.m1.1.1.cmml">−</mo><mn id="S4.T1.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.m1.1.1.2.cmml">7.34</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"><minus id="S4.T1.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"></minus><cn id="S4.T1.3.3.3.m1.1.1.2.cmml" type="float" xref="S4.T1.3.3.3.m1.1.1.2">7.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">-7.34</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.m1.1d">- 7.34</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4"><math alttext="-15.17" class="ltx_Math" display="inline" id="S4.T1.4.4.4.m1.1"><semantics id="S4.T1.4.4.4.m1.1a"><mrow id="S4.T1.4.4.4.m1.1.1" xref="S4.T1.4.4.4.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T1.4.4.4.m1.1.1a" mathvariant="bold" xref="S4.T1.4.4.4.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S4.T1.4.4.4.m1.1.1.2" mathvariant="bold" xref="S4.T1.4.4.4.m1.1.1.2.cmml">15.17</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><apply id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1"><minus id="S4.T1.4.4.4.m1.1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1"></minus><cn id="S4.T1.4.4.4.m1.1.1.2.cmml" type="float" xref="S4.T1.4.4.4.m1.1.1.2">15.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">-15.17</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.4.m1.1d">bold_- bold_15.17</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.5.1">TST wo FD</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.6">5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.5.1"><math alttext="+0.02" class="ltx_Math" display="inline" id="S4.T1.5.5.1.m1.1"><semantics id="S4.T1.5.5.1.m1.1a"><mrow id="S4.T1.5.5.1.m1.1.1" xref="S4.T1.5.5.1.m1.1.1.cmml"><mo id="S4.T1.5.5.1.m1.1.1a" xref="S4.T1.5.5.1.m1.1.1.cmml">+</mo><mn id="S4.T1.5.5.1.m1.1.1.2" xref="S4.T1.5.5.1.m1.1.1.2.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.1.m1.1b"><apply id="S4.T1.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.1.m1.1.1"><plus id="S4.T1.5.5.1.m1.1.1.1.cmml" xref="S4.T1.5.5.1.m1.1.1"></plus><cn id="S4.T1.5.5.1.m1.1.1.2.cmml" type="float" xref="S4.T1.5.5.1.m1.1.1.2">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.1.m1.1c">+0.02</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.1.m1.1d">+ 0.02</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T1.6.6.2"><math alttext="-0.61" class="ltx_Math" display="inline" id="S4.T1.6.6.2.m1.1"><semantics id="S4.T1.6.6.2.m1.1a"><mrow id="S4.T1.6.6.2.m1.1.1" xref="S4.T1.6.6.2.m1.1.1.cmml"><mo id="S4.T1.6.6.2.m1.1.1a" xref="S4.T1.6.6.2.m1.1.1.cmml">−</mo><mn id="S4.T1.6.6.2.m1.1.1.2" xref="S4.T1.6.6.2.m1.1.1.2.cmml">0.61</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.2.m1.1b"><apply id="S4.T1.6.6.2.m1.1.1.cmml" xref="S4.T1.6.6.2.m1.1.1"><minus id="S4.T1.6.6.2.m1.1.1.1.cmml" xref="S4.T1.6.6.2.m1.1.1"></minus><cn id="S4.T1.6.6.2.m1.1.1.2.cmml" type="float" xref="S4.T1.6.6.2.m1.1.1.2">0.61</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.2.m1.1c">-0.61</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.2.m1.1d">- 0.61</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.7.3"><math alttext="-3.53" class="ltx_Math" display="inline" id="S4.T1.7.7.3.m1.1"><semantics id="S4.T1.7.7.3.m1.1a"><mrow id="S4.T1.7.7.3.m1.1.1" xref="S4.T1.7.7.3.m1.1.1.cmml"><mo id="S4.T1.7.7.3.m1.1.1a" xref="S4.T1.7.7.3.m1.1.1.cmml">−</mo><mn id="S4.T1.7.7.3.m1.1.1.2" xref="S4.T1.7.7.3.m1.1.1.2.cmml">3.53</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.3.m1.1b"><apply id="S4.T1.7.7.3.m1.1.1.cmml" xref="S4.T1.7.7.3.m1.1.1"><minus id="S4.T1.7.7.3.m1.1.1.1.cmml" xref="S4.T1.7.7.3.m1.1.1"></minus><cn id="S4.T1.7.7.3.m1.1.1.2.cmml" type="float" xref="S4.T1.7.7.3.m1.1.1.2">3.53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.3.m1.1c">-3.53</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.3.m1.1d">- 3.53</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.4"><math alttext="-1.04" class="ltx_Math" display="inline" id="S4.T1.8.8.4.m1.1"><semantics id="S4.T1.8.8.4.m1.1a"><mrow id="S4.T1.8.8.4.m1.1.1" xref="S4.T1.8.8.4.m1.1.1.cmml"><mo id="S4.T1.8.8.4.m1.1.1a" xref="S4.T1.8.8.4.m1.1.1.cmml">−</mo><mn id="S4.T1.8.8.4.m1.1.1.2" xref="S4.T1.8.8.4.m1.1.1.2.cmml">1.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.4.m1.1b"><apply id="S4.T1.8.8.4.m1.1.1.cmml" xref="S4.T1.8.8.4.m1.1.1"><minus id="S4.T1.8.8.4.m1.1.1.1.cmml" xref="S4.T1.8.8.4.m1.1.1"></minus><cn id="S4.T1.8.8.4.m1.1.1.2.cmml" type="float" xref="S4.T1.8.8.4.m1.1.1.2">1.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.4.m1.1c">-1.04</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.8.4.m1.1d">- 1.04</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T1.12.12.5"><span class="ltx_text ltx_font_bold" id="S4.T1.12.12.5.1">TST wo FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.12.12.6">20</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.9.9.1"><math alttext="+0.03" class="ltx_Math" display="inline" id="S4.T1.9.9.1.m1.1"><semantics id="S4.T1.9.9.1.m1.1a"><mrow id="S4.T1.9.9.1.m1.1.1" xref="S4.T1.9.9.1.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T1.9.9.1.m1.1.1a" mathvariant="bold" xref="S4.T1.9.9.1.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S4.T1.9.9.1.m1.1.1.2" mathvariant="bold" xref="S4.T1.9.9.1.m1.1.1.2.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.1.m1.1b"><apply id="S4.T1.9.9.1.m1.1.1.cmml" xref="S4.T1.9.9.1.m1.1.1"><plus id="S4.T1.9.9.1.m1.1.1.1.cmml" xref="S4.T1.9.9.1.m1.1.1"></plus><cn id="S4.T1.9.9.1.m1.1.1.2.cmml" type="float" xref="S4.T1.9.9.1.m1.1.1.2">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.1.m1.1c">+0.03</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.9.1.m1.1d">bold_+ bold_0.03</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.10.10.2"><math alttext="-2.85" class="ltx_Math" display="inline" id="S4.T1.10.10.2.m1.1"><semantics id="S4.T1.10.10.2.m1.1a"><mrow id="S4.T1.10.10.2.m1.1.1" xref="S4.T1.10.10.2.m1.1.1.cmml"><mo id="S4.T1.10.10.2.m1.1.1a" xref="S4.T1.10.10.2.m1.1.1.cmml">−</mo><mn id="S4.T1.10.10.2.m1.1.1.2" xref="S4.T1.10.10.2.m1.1.1.2.cmml">2.85</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.2.m1.1b"><apply id="S4.T1.10.10.2.m1.1.1.cmml" xref="S4.T1.10.10.2.m1.1.1"><minus id="S4.T1.10.10.2.m1.1.1.1.cmml" xref="S4.T1.10.10.2.m1.1.1"></minus><cn id="S4.T1.10.10.2.m1.1.1.2.cmml" type="float" xref="S4.T1.10.10.2.m1.1.1.2">2.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.2.m1.1c">-2.85</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.10.2.m1.1d">- 2.85</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.11.11.3"><math alttext="-8.49" class="ltx_Math" display="inline" id="S4.T1.11.11.3.m1.1"><semantics id="S4.T1.11.11.3.m1.1a"><mrow id="S4.T1.11.11.3.m1.1.1" xref="S4.T1.11.11.3.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T1.11.11.3.m1.1.1a" mathvariant="bold" xref="S4.T1.11.11.3.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S4.T1.11.11.3.m1.1.1.2" mathvariant="bold" xref="S4.T1.11.11.3.m1.1.1.2.cmml">8.49</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.3.m1.1b"><apply id="S4.T1.11.11.3.m1.1.1.cmml" xref="S4.T1.11.11.3.m1.1.1"><minus id="S4.T1.11.11.3.m1.1.1.1.cmml" xref="S4.T1.11.11.3.m1.1.1"></minus><cn id="S4.T1.11.11.3.m1.1.1.2.cmml" type="float" xref="S4.T1.11.11.3.m1.1.1.2">8.49</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.3.m1.1c">-8.49</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.11.3.m1.1d">bold_- bold_8.49</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.12.12.4"><math alttext="-14.58" class="ltx_Math" display="inline" id="S4.T1.12.12.4.m1.1"><semantics id="S4.T1.12.12.4.m1.1a"><mrow id="S4.T1.12.12.4.m1.1.1" xref="S4.T1.12.12.4.m1.1.1.cmml"><mo id="S4.T1.12.12.4.m1.1.1a" xref="S4.T1.12.12.4.m1.1.1.cmml">−</mo><mn id="S4.T1.12.12.4.m1.1.1.2" xref="S4.T1.12.12.4.m1.1.1.2.cmml">14.58</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.4.m1.1b"><apply id="S4.T1.12.12.4.m1.1.1.cmml" xref="S4.T1.12.12.4.m1.1.1"><minus id="S4.T1.12.12.4.m1.1.1.1.cmml" xref="S4.T1.12.12.4.m1.1.1"></minus><cn id="S4.T1.12.12.4.m1.1.1.2.cmml" type="float" xref="S4.T1.12.12.4.m1.1.1.2">14.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.4.m1.1c">-14.58</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.12.4.m1.1d">- 14.58</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Impact of selecting <span class="ltx_text ltx_font_bold" id="S4.T1.14.1">5 vs 20 few-shot</span> samples for TST and Pre-trained Model without adding API Function Definitions using GPT-4. The baseline uses Pre-trained Transformer Model with 5 few-shot samples. </figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset Generation</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our train and test set consists of a total of 67k and 1k samples, respectively. These samples are (prompt, flow) pairs with the workflows being created by users across a large set of APIs. We scrubbed PII from these automations and sampled workflows containing <math alttext="700" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">700</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn id="S4.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1">700</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">700</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">700</annotation></semantics></math> publicly available APIs. We synthetically generated the corresponding Natural Language prompts using GPT-4.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>DSL Generation Quality Metrics</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We defined 3 key metrics to focus on code generation quality as well as syntactic accuracy and hallucination rate.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Average Similarity</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">Average Similarity measures the similarity between predicted flow and the ground truth flow and is defined using the Longest Common Subsequence match (LCSS) metric. Each flow is reduced to a list of API sequences and then the LCSS is computed. The final metric is reported as an average over all test samples. Hallucination and Parser failures lead to the sample being discarded and is assigned a similarity score of 0.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textrm{Similarity}=\frac{\mathrm{LCSS}(A,B)}{max(|\mathrm{Actions}_{A}|,|%
\mathrm{Actions}_{B}|)}" class="ltx_Math" display="block" id="S4.E2.m1.4"><semantics id="S4.E2.m1.4a"><mrow id="S4.E2.m1.4.5" xref="S4.E2.m1.4.5.cmml"><mtext id="S4.E2.m1.4.5.2" xref="S4.E2.m1.4.5.2a.cmml">Similarity</mtext><mo id="S4.E2.m1.4.5.1" xref="S4.E2.m1.4.5.1.cmml">=</mo><mfrac id="S4.E2.m1.4.4" xref="S4.E2.m1.4.4.cmml"><mrow id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml"><mi id="S4.E2.m1.2.2.2.4" xref="S4.E2.m1.2.2.2.4.cmml">LCSS</mi><mo id="S4.E2.m1.2.2.2.3" xref="S4.E2.m1.2.2.2.3.cmml">⁢</mo><mrow id="S4.E2.m1.2.2.2.5.2" xref="S4.E2.m1.2.2.2.5.1.cmml"><mo id="S4.E2.m1.2.2.2.5.2.1" stretchy="false" xref="S4.E2.m1.2.2.2.5.1.cmml">(</mo><mi id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml">A</mi><mo id="S4.E2.m1.2.2.2.5.2.2" xref="S4.E2.m1.2.2.2.5.1.cmml">,</mo><mi id="S4.E2.m1.2.2.2.2" xref="S4.E2.m1.2.2.2.2.cmml">B</mi><mo id="S4.E2.m1.2.2.2.5.2.3" stretchy="false" xref="S4.E2.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow><mrow id="S4.E2.m1.4.4.4" xref="S4.E2.m1.4.4.4.cmml"><mi id="S4.E2.m1.4.4.4.4" xref="S4.E2.m1.4.4.4.4.cmml">m</mi><mo id="S4.E2.m1.4.4.4.3" xref="S4.E2.m1.4.4.4.3.cmml">⁢</mo><mi id="S4.E2.m1.4.4.4.5" xref="S4.E2.m1.4.4.4.5.cmml">a</mi><mo id="S4.E2.m1.4.4.4.3a" xref="S4.E2.m1.4.4.4.3.cmml">⁢</mo><mi id="S4.E2.m1.4.4.4.6" xref="S4.E2.m1.4.4.4.6.cmml">x</mi><mo id="S4.E2.m1.4.4.4.3b" xref="S4.E2.m1.4.4.4.3.cmml">⁢</mo><mrow id="S4.E2.m1.4.4.4.2.2" xref="S4.E2.m1.4.4.4.2.3.cmml"><mo id="S4.E2.m1.4.4.4.2.2.3" stretchy="false" xref="S4.E2.m1.4.4.4.2.3.cmml">(</mo><mrow id="S4.E2.m1.3.3.3.1.1.1.1" xref="S4.E2.m1.3.3.3.1.1.1.2.cmml"><mo id="S4.E2.m1.3.3.3.1.1.1.1.2" stretchy="false" xref="S4.E2.m1.3.3.3.1.1.1.2.1.cmml">|</mo><msub id="S4.E2.m1.3.3.3.1.1.1.1.1" xref="S4.E2.m1.3.3.3.1.1.1.1.1.cmml"><mi id="S4.E2.m1.3.3.3.1.1.1.1.1.2" xref="S4.E2.m1.3.3.3.1.1.1.1.1.2.cmml">Actions</mi><mi id="S4.E2.m1.3.3.3.1.1.1.1.1.3" xref="S4.E2.m1.3.3.3.1.1.1.1.1.3.cmml">A</mi></msub><mo id="S4.E2.m1.3.3.3.1.1.1.1.3" stretchy="false" xref="S4.E2.m1.3.3.3.1.1.1.2.1.cmml">|</mo></mrow><mo id="S4.E2.m1.4.4.4.2.2.4" xref="S4.E2.m1.4.4.4.2.3.cmml">,</mo><mrow id="S4.E2.m1.4.4.4.2.2.2.1" xref="S4.E2.m1.4.4.4.2.2.2.2.cmml"><mo id="S4.E2.m1.4.4.4.2.2.2.1.2" stretchy="false" xref="S4.E2.m1.4.4.4.2.2.2.2.1.cmml">|</mo><msub id="S4.E2.m1.4.4.4.2.2.2.1.1" xref="S4.E2.m1.4.4.4.2.2.2.1.1.cmml"><mi id="S4.E2.m1.4.4.4.2.2.2.1.1.2" xref="S4.E2.m1.4.4.4.2.2.2.1.1.2.cmml">Actions</mi><mi id="S4.E2.m1.4.4.4.2.2.2.1.1.3" xref="S4.E2.m1.4.4.4.2.2.2.1.1.3.cmml">B</mi></msub><mo id="S4.E2.m1.4.4.4.2.2.2.1.3" stretchy="false" xref="S4.E2.m1.4.4.4.2.2.2.2.1.cmml">|</mo></mrow><mo id="S4.E2.m1.4.4.4.2.2.5" stretchy="false" xref="S4.E2.m1.4.4.4.2.3.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.4b"><apply id="S4.E2.m1.4.5.cmml" xref="S4.E2.m1.4.5"><eq id="S4.E2.m1.4.5.1.cmml" xref="S4.E2.m1.4.5.1"></eq><ci id="S4.E2.m1.4.5.2a.cmml" xref="S4.E2.m1.4.5.2"><mtext id="S4.E2.m1.4.5.2.cmml" xref="S4.E2.m1.4.5.2">Similarity</mtext></ci><apply id="S4.E2.m1.4.4.cmml" xref="S4.E2.m1.4.4"><divide id="S4.E2.m1.4.4.5.cmml" xref="S4.E2.m1.4.4"></divide><apply id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2"><times id="S4.E2.m1.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.3"></times><ci id="S4.E2.m1.2.2.2.4.cmml" xref="S4.E2.m1.2.2.2.4">LCSS</ci><interval closure="open" id="S4.E2.m1.2.2.2.5.1.cmml" xref="S4.E2.m1.2.2.2.5.2"><ci id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1">𝐴</ci><ci id="S4.E2.m1.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2">𝐵</ci></interval></apply><apply id="S4.E2.m1.4.4.4.cmml" xref="S4.E2.m1.4.4.4"><times id="S4.E2.m1.4.4.4.3.cmml" xref="S4.E2.m1.4.4.4.3"></times><ci id="S4.E2.m1.4.4.4.4.cmml" xref="S4.E2.m1.4.4.4.4">𝑚</ci><ci id="S4.E2.m1.4.4.4.5.cmml" xref="S4.E2.m1.4.4.4.5">𝑎</ci><ci id="S4.E2.m1.4.4.4.6.cmml" xref="S4.E2.m1.4.4.4.6">𝑥</ci><interval closure="open" id="S4.E2.m1.4.4.4.2.3.cmml" xref="S4.E2.m1.4.4.4.2.2"><apply id="S4.E2.m1.3.3.3.1.1.1.2.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1"><abs id="S4.E2.m1.3.3.3.1.1.1.2.1.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.2"></abs><apply id="S4.E2.m1.3.3.3.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.3.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.3.3.3.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.1.2">Actions</ci><ci id="S4.E2.m1.3.3.3.1.1.1.1.1.3.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.1.3">𝐴</ci></apply></apply><apply id="S4.E2.m1.4.4.4.2.2.2.2.cmml" xref="S4.E2.m1.4.4.4.2.2.2.1"><abs id="S4.E2.m1.4.4.4.2.2.2.2.1.cmml" xref="S4.E2.m1.4.4.4.2.2.2.1.2"></abs><apply id="S4.E2.m1.4.4.4.2.2.2.1.1.cmml" xref="S4.E2.m1.4.4.4.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.4.2.2.2.1.1.1.cmml" xref="S4.E2.m1.4.4.4.2.2.2.1.1">subscript</csymbol><ci id="S4.E2.m1.4.4.4.2.2.2.1.1.2.cmml" xref="S4.E2.m1.4.4.4.2.2.2.1.1.2">Actions</ci><ci id="S4.E2.m1.4.4.4.2.2.2.1.1.3.cmml" xref="S4.E2.m1.4.4.4.2.2.2.1.1.3">𝐵</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.4c">\textrm{Similarity}=\frac{\mathrm{LCSS}(A,B)}{max(|\mathrm{Actions}_{A}|,|%
\mathrm{Actions}_{B}|)}</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.4d">Similarity = divide start_ARG roman_LCSS ( italic_A , italic_B ) end_ARG start_ARG italic_m italic_a italic_x ( | roman_Actions start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT | , | roman_Actions start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT | ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS1.p2.4">where <math alttext="|\textrm{Actions}_{A}|" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.1.m1.1"><semantics id="S4.SS2.SSS1.p2.1.m1.1a"><mrow id="S4.SS2.SSS1.p2.1.m1.1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.2.cmml"><mo id="S4.SS2.SSS1.p2.1.m1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS1.p2.1.m1.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS1.p2.1.m1.1.1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1.cmml"><mtext id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.2" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1.2a.cmml">Actions</mtext><mi id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.3" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1.3.cmml">A</mi></msub><mo id="S4.SS2.SSS1.p2.1.m1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS1.p2.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.1.m1.1b"><apply id="S4.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1"><abs id="S4.SS2.SSS1.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.2"></abs><apply id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.2a.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1.2"><mtext id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1.2">Actions</mtext></ci><ci id="S4.SS2.SSS1.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.1.3">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.1.m1.1c">|\textrm{Actions}_{A}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.1.m1.1d">| Actions start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of actions in flow <math alttext="A" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.2.m2.1"><semantics id="S4.SS2.SSS1.p2.2.m2.1a"><mi id="S4.SS2.SSS1.p2.2.m2.1.1" xref="S4.SS2.SSS1.p2.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.2.m2.1b"><ci id="S4.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p2.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.2.m2.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.2.m2.1d">italic_A</annotation></semantics></math> and <math alttext="|\textrm{Actions}_{B}|" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.3.m3.1"><semantics id="S4.SS2.SSS1.p2.3.m3.1a"><mrow id="S4.SS2.SSS1.p2.3.m3.1.1.1" xref="S4.SS2.SSS1.p2.3.m3.1.1.2.cmml"><mo id="S4.SS2.SSS1.p2.3.m3.1.1.1.2" stretchy="false" xref="S4.SS2.SSS1.p2.3.m3.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS1.p2.3.m3.1.1.1.1" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1.cmml"><mtext id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.2" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1.2a.cmml">Actions</mtext><mi id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.3" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1.3.cmml">B</mi></msub><mo id="S4.SS2.SSS1.p2.3.m3.1.1.1.3" stretchy="false" xref="S4.SS2.SSS1.p2.3.m3.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.3.m3.1b"><apply id="S4.SS2.SSS1.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1"><abs id="S4.SS2.SSS1.p2.3.m3.1.1.2.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.2"></abs><apply id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.2a.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1.2"><mtext id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1.2">Actions</mtext></ci><ci id="S4.SS2.SSS1.p2.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.1.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.3.m3.1c">|\textrm{Actions}_{B}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.3.m3.1d">| Actions start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of actions in flow <math alttext="B" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.4.m4.1"><semantics id="S4.SS2.SSS1.p2.4.m4.1a"><mi id="S4.SS2.SSS1.p2.4.m4.1.1" xref="S4.SS2.SSS1.p2.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.4.m4.1b"><ci id="S4.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S4.SS2.SSS1.p2.4.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.4.m4.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.4.m4.1d">italic_B</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.12">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T2.12.13.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.12.13.1.2">Avg. Similarity</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.12.13.1.3">%Unparsed flows</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.12.13.1.4">%Made-up API names</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.12.13.1.5">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S4.T2.12.13.1.5.1" style="width:71.1pt;">
<span class="ltx_p" id="S4.T2.12.13.1.5.1.1">%Made-up API parameters</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.5.1">Pre-trained + FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1"><math alttext="0" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mn id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><cn id="S4.T2.1.1.1.m1.1.1.cmml" type="integer" xref="S4.T2.1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.2"><math alttext="+2.75" class="ltx_Math" display="inline" id="S4.T2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.m1.1.1.cmml"><mo id="S4.T2.2.2.2.m1.1.1a" xref="S4.T2.2.2.2.m1.1.1.cmml">+</mo><mn id="S4.T2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.m1.1.1.2.cmml">2.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1"><plus id="S4.T2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1"></plus><cn id="S4.T2.2.2.2.m1.1.1.2.cmml" type="float" xref="S4.T2.2.2.2.m1.1.1.2">2.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">+2.75</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.m1.1d">+ 2.75</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.3"><math alttext="-4.3" class="ltx_Math" display="inline" id="S4.T2.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mo id="S4.T2.3.3.3.m1.1.1a" xref="S4.T2.3.3.3.m1.1.1.cmml">−</mo><mn id="S4.T2.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.m1.1.1.2.cmml">4.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><minus id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"></minus><cn id="S4.T2.3.3.3.m1.1.1.2.cmml" type="float" xref="S4.T2.3.3.3.m1.1.1.2">4.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">-4.3</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.m1.1d">- 4.3</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.4.4"><math alttext="-20.16" class="ltx_Math" display="inline" id="S4.T2.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.m1.1a"><mrow id="S4.T2.4.4.4.m1.1.1" xref="S4.T2.4.4.4.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T2.4.4.4.m1.1.1a" mathvariant="bold" xref="S4.T2.4.4.4.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S4.T2.4.4.4.m1.1.1.2" mathvariant="bold" xref="S4.T2.4.4.4.m1.1.1.2.cmml">20.16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1"><minus id="S4.T2.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1"></minus><cn id="S4.T2.4.4.4.m1.1.1.2.cmml" type="float" xref="S4.T2.4.4.4.m1.1.1.2">20.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">-20.16</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.m1.1d">bold_- bold_20.16</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.5.1">TST wo FD</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.1"><math alttext="+0.02" class="ltx_Math" display="inline" id="S4.T2.5.5.1.m1.1"><semantics id="S4.T2.5.5.1.m1.1a"><mrow id="S4.T2.5.5.1.m1.1.1" xref="S4.T2.5.5.1.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T2.5.5.1.m1.1.1a" mathvariant="bold" xref="S4.T2.5.5.1.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S4.T2.5.5.1.m1.1.1.2" mathvariant="bold" xref="S4.T2.5.5.1.m1.1.1.2.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.m1.1b"><apply id="S4.T2.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1"><plus id="S4.T2.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1"></plus><cn id="S4.T2.5.5.1.m1.1.1.2.cmml" type="float" xref="S4.T2.5.5.1.m1.1.1.2">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.m1.1c">+0.02</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.1.m1.1d">bold_+ bold_0.02</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.2"><math alttext="-0.61" class="ltx_Math" display="inline" id="S4.T2.6.6.2.m1.1"><semantics id="S4.T2.6.6.2.m1.1a"><mrow id="S4.T2.6.6.2.m1.1.1" xref="S4.T2.6.6.2.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T2.6.6.2.m1.1.1a" mathvariant="bold" xref="S4.T2.6.6.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S4.T2.6.6.2.m1.1.1.2" mathvariant="bold" xref="S4.T2.6.6.2.m1.1.1.2.cmml">0.61</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.2.m1.1b"><apply id="S4.T2.6.6.2.m1.1.1.cmml" xref="S4.T2.6.6.2.m1.1.1"><minus id="S4.T2.6.6.2.m1.1.1.1.cmml" xref="S4.T2.6.6.2.m1.1.1"></minus><cn id="S4.T2.6.6.2.m1.1.1.2.cmml" type="float" xref="S4.T2.6.6.2.m1.1.1.2">0.61</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.2.m1.1c">-0.61</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.2.m1.1d">bold_- bold_0.61</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.7.3"><math alttext="-3.53" class="ltx_Math" display="inline" id="S4.T2.7.7.3.m1.1"><semantics id="S4.T2.7.7.3.m1.1a"><mrow id="S4.T2.7.7.3.m1.1.1" xref="S4.T2.7.7.3.m1.1.1.cmml"><mo id="S4.T2.7.7.3.m1.1.1a" xref="S4.T2.7.7.3.m1.1.1.cmml">−</mo><mn id="S4.T2.7.7.3.m1.1.1.2" xref="S4.T2.7.7.3.m1.1.1.2.cmml">3.53</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.3.m1.1b"><apply id="S4.T2.7.7.3.m1.1.1.cmml" xref="S4.T2.7.7.3.m1.1.1"><minus id="S4.T2.7.7.3.m1.1.1.1.cmml" xref="S4.T2.7.7.3.m1.1.1"></minus><cn id="S4.T2.7.7.3.m1.1.1.2.cmml" type="float" xref="S4.T2.7.7.3.m1.1.1.2">3.53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.3.m1.1c">-3.53</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.7.3.m1.1d">- 3.53</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.4"><math alttext="-1.04" class="ltx_Math" display="inline" id="S4.T2.8.8.4.m1.1"><semantics id="S4.T2.8.8.4.m1.1a"><mrow id="S4.T2.8.8.4.m1.1.1" xref="S4.T2.8.8.4.m1.1.1.cmml"><mo id="S4.T2.8.8.4.m1.1.1a" xref="S4.T2.8.8.4.m1.1.1.cmml">−</mo><mn id="S4.T2.8.8.4.m1.1.1.2" xref="S4.T2.8.8.4.m1.1.1.2.cmml">1.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.4.m1.1b"><apply id="S4.T2.8.8.4.m1.1.1.cmml" xref="S4.T2.8.8.4.m1.1.1"><minus id="S4.T2.8.8.4.m1.1.1.1.cmml" xref="S4.T2.8.8.4.m1.1.1"></minus><cn id="S4.T2.8.8.4.m1.1.1.2.cmml" type="float" xref="S4.T2.8.8.4.m1.1.1.2">1.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.4.m1.1c">-1.04</annotation><annotation encoding="application/x-llamapun" id="S4.T2.8.8.4.m1.1d">- 1.04</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T2.12.12.5"><span class="ltx_text ltx_font_bold" id="S4.T2.12.12.5.1">TST + FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.9.9.1"><math alttext="+0.02" class="ltx_Math" display="inline" id="S4.T2.9.9.1.m1.1"><semantics id="S4.T2.9.9.1.m1.1a"><mrow id="S4.T2.9.9.1.m1.1.1" xref="S4.T2.9.9.1.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T2.9.9.1.m1.1.1a" mathvariant="bold" xref="S4.T2.9.9.1.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S4.T2.9.9.1.m1.1.1.2" mathvariant="bold" xref="S4.T2.9.9.1.m1.1.1.2.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.1.m1.1b"><apply id="S4.T2.9.9.1.m1.1.1.cmml" xref="S4.T2.9.9.1.m1.1.1"><plus id="S4.T2.9.9.1.m1.1.1.1.cmml" xref="S4.T2.9.9.1.m1.1.1"></plus><cn id="S4.T2.9.9.1.m1.1.1.2.cmml" type="float" xref="S4.T2.9.9.1.m1.1.1.2">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.1.m1.1c">+0.02</annotation><annotation encoding="application/x-llamapun" id="S4.T2.9.9.1.m1.1d">bold_+ bold_0.02</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.10.10.2"><math alttext="+0.68" class="ltx_Math" display="inline" id="S4.T2.10.10.2.m1.1"><semantics id="S4.T2.10.10.2.m1.1a"><mrow id="S4.T2.10.10.2.m1.1.1" xref="S4.T2.10.10.2.m1.1.1.cmml"><mo id="S4.T2.10.10.2.m1.1.1a" xref="S4.T2.10.10.2.m1.1.1.cmml">+</mo><mn id="S4.T2.10.10.2.m1.1.1.2" xref="S4.T2.10.10.2.m1.1.1.2.cmml">0.68</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.2.m1.1b"><apply id="S4.T2.10.10.2.m1.1.1.cmml" xref="S4.T2.10.10.2.m1.1.1"><plus id="S4.T2.10.10.2.m1.1.1.1.cmml" xref="S4.T2.10.10.2.m1.1.1"></plus><cn id="S4.T2.10.10.2.m1.1.1.2.cmml" type="float" xref="S4.T2.10.10.2.m1.1.1.2">0.68</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.2.m1.1c">+0.68</annotation><annotation encoding="application/x-llamapun" id="S4.T2.10.10.2.m1.1d">+ 0.68</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.11.11.3"><math alttext="-6.29" class="ltx_Math" display="inline" id="S4.T2.11.11.3.m1.1"><semantics id="S4.T2.11.11.3.m1.1a"><mrow id="S4.T2.11.11.3.m1.1.1" xref="S4.T2.11.11.3.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S4.T2.11.11.3.m1.1.1a" mathvariant="bold" xref="S4.T2.11.11.3.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S4.T2.11.11.3.m1.1.1.2" mathvariant="bold" xref="S4.T2.11.11.3.m1.1.1.2.cmml">6.29</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.3.m1.1b"><apply id="S4.T2.11.11.3.m1.1.1.cmml" xref="S4.T2.11.11.3.m1.1.1"><minus id="S4.T2.11.11.3.m1.1.1.1.cmml" xref="S4.T2.11.11.3.m1.1.1"></minus><cn id="S4.T2.11.11.3.m1.1.1.2.cmml" type="float" xref="S4.T2.11.11.3.m1.1.1.2">6.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.3.m1.1c">-6.29</annotation><annotation encoding="application/x-llamapun" id="S4.T2.11.11.3.m1.1d">bold_- bold_6.29</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.12.12.4"><math alttext="-19.99" class="ltx_Math" display="inline" id="S4.T2.12.12.4.m1.1"><semantics id="S4.T2.12.12.4.m1.1a"><mrow id="S4.T2.12.12.4.m1.1.1" xref="S4.T2.12.12.4.m1.1.1.cmml"><mo id="S4.T2.12.12.4.m1.1.1a" xref="S4.T2.12.12.4.m1.1.1.cmml">−</mo><mn id="S4.T2.12.12.4.m1.1.1.2" xref="S4.T2.12.12.4.m1.1.1.2.cmml">19.99</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.4.m1.1b"><apply id="S4.T2.12.12.4.m1.1.1.cmml" xref="S4.T2.12.12.4.m1.1.1"><minus id="S4.T2.12.12.4.m1.1.1.1.cmml" xref="S4.T2.12.12.4.m1.1.1"></minus><cn id="S4.T2.12.12.4.m1.1.1.2.cmml" type="float" xref="S4.T2.12.12.4.m1.1.1.2">19.99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.4.m1.1c">-19.99</annotation><annotation encoding="application/x-llamapun" id="S4.T2.12.12.4.m1.1d">- 19.99</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Impact of selecting <span class="ltx_text ltx_font_bold" id="S4.T2.14.1">5 few-shot</span> samples using TST vs. Pre-trained Model with and without API Function Definitions using GPT4 model. The baseline uses Pre-trained Transformer Model without API Function Definitions.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Unparsed rate</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">This metric captures the rate of syntactic errors. A flow that cannot be parsed by the parser is considered not usable for the purpose of similarity metric computation. Unparsed rate is computed as follow:</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\%\mathrm{unparsed\ flows}=\frac{|\mathrm{Flows}_{\mathrm{unparsed}}|}{|%
\mathrm{Flows}_{\mathrm{total}}|}" class="ltx_math_unparsed" display="block" id="S4.E3.m1.2"><semantics id="S4.E3.m1.2a"><mrow id="S4.E3.m1.2b"><mo id="S4.E3.m1.2.3">%</mo><mi id="S4.E3.m1.2.4">unparsed</mi><mi id="S4.E3.m1.2.5">flows</mi><mo id="S4.E3.m1.2.6">=</mo><mfrac id="S4.E3.m1.2.2"><mrow id="S4.E3.m1.1.1.1.1"><mo id="S4.E3.m1.1.1.1.1.2" stretchy="false">|</mo><msub id="S4.E3.m1.1.1.1.1.1"><mi id="S4.E3.m1.1.1.1.1.1.2">Flows</mi><mi id="S4.E3.m1.1.1.1.1.1.3">unparsed</mi></msub><mo id="S4.E3.m1.1.1.1.1.3" stretchy="false">|</mo></mrow><mrow id="S4.E3.m1.2.2.2.1"><mo id="S4.E3.m1.2.2.2.1.2" stretchy="false">|</mo><msub id="S4.E3.m1.2.2.2.1.1"><mi id="S4.E3.m1.2.2.2.1.1.2">Flows</mi><mi id="S4.E3.m1.2.2.2.1.1.3">total</mi></msub><mo id="S4.E3.m1.2.2.2.1.3" stretchy="false">|</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex" id="S4.E3.m1.2c">\%\mathrm{unparsed\ flows}=\frac{|\mathrm{Flows}_{\mathrm{unparsed}}|}{|%
\mathrm{Flows}_{\mathrm{total}}|}</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.2d">% roman_unparsed roman_flows = divide start_ARG | roman_Flows start_POSTSUBSCRIPT roman_unparsed end_POSTSUBSCRIPT | end_ARG start_ARG | roman_Flows start_POSTSUBSCRIPT roman_total end_POSTSUBSCRIPT | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS2.p2.2">where, <math alttext="|\mathrm{Flows}_{\mathrm{unparsed}}|" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p2.1.m1.1"><semantics id="S4.SS2.SSS2.p2.1.m1.1a"><mrow id="S4.SS2.SSS2.p2.1.m1.1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.2.cmml"><mo id="S4.SS2.SSS2.p2.1.m1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS2.p2.1.m1.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS2.p2.1.m1.1.1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.2" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1.2.cmml">Flows</mi><mi id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.3" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1.3.cmml">unparsed</mi></msub><mo id="S4.SS2.SSS2.p2.1.m1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS2.p2.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.1b"><apply id="S4.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1"><abs id="S4.SS2.SSS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.2"></abs><apply id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1.2">Flows</ci><ci id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1.3">unparsed</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.1c">|\mathrm{Flows}_{\mathrm{unparsed}}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p2.1.m1.1d">| roman_Flows start_POSTSUBSCRIPT roman_unparsed end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of flows that were not parsed and <math alttext="|\mathrm{Flows}_{\mathrm{total}}|" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p2.2.m2.1"><semantics id="S4.SS2.SSS2.p2.2.m2.1a"><mrow id="S4.SS2.SSS2.p2.2.m2.1.1.1" xref="S4.SS2.SSS2.p2.2.m2.1.1.2.cmml"><mo id="S4.SS2.SSS2.p2.2.m2.1.1.1.2" stretchy="false" xref="S4.SS2.SSS2.p2.2.m2.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS2.p2.2.m2.1.1.1.1" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p2.2.m2.1.1.1.1.2" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1.2.cmml">Flows</mi><mi id="S4.SS2.SSS2.p2.2.m2.1.1.1.1.3" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1.3.cmml">total</mi></msub><mo id="S4.SS2.SSS2.p2.2.m2.1.1.1.3" stretchy="false" xref="S4.SS2.SSS2.p2.2.m2.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.2.m2.1b"><apply id="S4.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1.1"><abs id="S4.SS2.SSS2.p2.2.m2.1.1.2.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.2"></abs><apply id="S4.SS2.SSS2.p2.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p2.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p2.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1.2">Flows</ci><ci id="S4.SS2.SSS2.p2.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1.1.1.3">total</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.2.m2.1c">|\mathrm{Flows}_{\mathrm{total}}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p2.2.m2.1d">| roman_Flows start_POSTSUBSCRIPT roman_total end_POSTSUBSCRIPT |</annotation></semantics></math>is the total number of flows in the sample set.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Hallucination rate</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">This metric captures the rate of made-up APIs and made-up parameter keys in the generated code. Predicting a flow with a hallucinated API name is counted as a failure and leads to the code being considered invalid. However, hallucinated parameter keys would only lead to run-time errors which can be fixed down the line. Fixing these run-time errors is beyond the scope of this paper.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\%\mathrm{made-up\ APIs}=\frac{|\mathrm{Flows}_{h}|}{|\mathrm{Flows}_{\mathrm{%
parsed}}|}*100" class="ltx_math_unparsed" display="block" id="S4.E4.m1.2"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2b"><mo id="S4.E4.m1.2.3">%</mo><mi id="S4.E4.m1.2.4">made</mi><mo id="S4.E4.m1.2.5">−</mo><mi id="S4.E4.m1.2.6">up</mi><mi id="S4.E4.m1.2.7">APIs</mi><mo id="S4.E4.m1.2.8">=</mo><mfrac id="S4.E4.m1.2.2"><mrow id="S4.E4.m1.1.1.1.1"><mo id="S4.E4.m1.1.1.1.1.2" stretchy="false">|</mo><msub id="S4.E4.m1.1.1.1.1.1"><mi id="S4.E4.m1.1.1.1.1.1.2">Flows</mi><mi id="S4.E4.m1.1.1.1.1.1.3">h</mi></msub><mo id="S4.E4.m1.1.1.1.1.3" stretchy="false">|</mo></mrow><mrow id="S4.E4.m1.2.2.2.1"><mo id="S4.E4.m1.2.2.2.1.2" stretchy="false">|</mo><msub id="S4.E4.m1.2.2.2.1.1"><mi id="S4.E4.m1.2.2.2.1.1.2">Flows</mi><mi id="S4.E4.m1.2.2.2.1.1.3">parsed</mi></msub><mo id="S4.E4.m1.2.2.2.1.3" stretchy="false">|</mo></mrow></mfrac><mo id="S4.E4.m1.2.9" lspace="0.222em" rspace="0.222em">∗</mo><mn id="S4.E4.m1.2.10">100</mn></mrow><annotation encoding="application/x-tex" id="S4.E4.m1.2c">\%\mathrm{made-up\ APIs}=\frac{|\mathrm{Flows}_{h}|}{|\mathrm{Flows}_{\mathrm{%
parsed}}|}*100</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.2d">% roman_made - roman_up roman_APIs = divide start_ARG | roman_Flows start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT | end_ARG start_ARG | roman_Flows start_POSTSUBSCRIPT roman_parsed end_POSTSUBSCRIPT | end_ARG ∗ 100</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p3">
<table class="ltx_equation ltx_eqn_table" id="S4.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\%\mathrm{made-up\ parameters}=\frac{|\mathrm{Flows}_{hp}|}{|\mathrm{Flows}_{%
\mathrm{parsed}}|}*100" class="ltx_math_unparsed" display="block" id="S4.E5.m1.2"><semantics id="S4.E5.m1.2a"><mrow id="S4.E5.m1.2b"><mo id="S4.E5.m1.2.3">%</mo><mi id="S4.E5.m1.2.4">made</mi><mo id="S4.E5.m1.2.5">−</mo><mi id="S4.E5.m1.2.6">up</mi><mi id="S4.E5.m1.2.7">parameters</mi><mo id="S4.E5.m1.2.8">=</mo><mfrac id="S4.E5.m1.2.2"><mrow id="S4.E5.m1.1.1.1.1"><mo id="S4.E5.m1.1.1.1.1.2" stretchy="false">|</mo><msub id="S4.E5.m1.1.1.1.1.1"><mi id="S4.E5.m1.1.1.1.1.1.2">Flows</mi><mrow id="S4.E5.m1.1.1.1.1.1.3"><mi id="S4.E5.m1.1.1.1.1.1.3.2">h</mi><mo id="S4.E5.m1.1.1.1.1.1.3.1">⁢</mo><mi id="S4.E5.m1.1.1.1.1.1.3.3">p</mi></mrow></msub><mo id="S4.E5.m1.1.1.1.1.3" stretchy="false">|</mo></mrow><mrow id="S4.E5.m1.2.2.2.1"><mo id="S4.E5.m1.2.2.2.1.2" stretchy="false">|</mo><msub id="S4.E5.m1.2.2.2.1.1"><mi id="S4.E5.m1.2.2.2.1.1.2">Flows</mi><mi id="S4.E5.m1.2.2.2.1.1.3">parsed</mi></msub><mo id="S4.E5.m1.2.2.2.1.3" stretchy="false">|</mo></mrow></mfrac><mo id="S4.E5.m1.2.9" lspace="0.222em" rspace="0.222em">∗</mo><mn id="S4.E5.m1.2.10">100</mn></mrow><annotation encoding="application/x-tex" id="S4.E5.m1.2c">\%\mathrm{made-up\ parameters}=\frac{|\mathrm{Flows}_{hp}|}{|\mathrm{Flows}_{%
\mathrm{parsed}}|}*100</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.2d">% roman_made - roman_up roman_parameters = divide start_ARG | roman_Flows start_POSTSUBSCRIPT italic_h italic_p end_POSTSUBSCRIPT | end_ARG start_ARG | roman_Flows start_POSTSUBSCRIPT roman_parsed end_POSTSUBSCRIPT | end_ARG ∗ 100</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS3.p3.3">where <math alttext="|\mathrm{Flows}_{h}|" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p3.1.m1.1"><semantics id="S4.SS2.SSS3.p3.1.m1.1a"><mrow id="S4.SS2.SSS3.p3.1.m1.1.1.1" xref="S4.SS2.SSS3.p3.1.m1.1.1.2.cmml"><mo id="S4.SS2.SSS3.p3.1.m1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS3.p3.1.m1.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS3.p3.1.m1.1.1.1.1" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p3.1.m1.1.1.1.1.2" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1.2.cmml">Flows</mi><mi id="S4.SS2.SSS3.p3.1.m1.1.1.1.1.3" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1.3.cmml">h</mi></msub><mo id="S4.SS2.SSS3.p3.1.m1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS3.p3.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.1.m1.1b"><apply id="S4.SS2.SSS3.p3.1.m1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1"><abs id="S4.SS2.SSS3.p3.1.m1.1.1.2.1.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.2"></abs><apply id="S4.SS2.SSS3.p3.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p3.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p3.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1.2">Flows</ci><ci id="S4.SS2.SSS3.p3.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p3.1.m1.1.1.1.1.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.1.m1.1c">|\mathrm{Flows}_{h}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p3.1.m1.1d">| roman_Flows start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of flows with hallucinated API names, <math alttext="|\mathrm{Flows}_{hp}|" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p3.2.m2.1"><semantics id="S4.SS2.SSS3.p3.2.m2.1a"><mrow id="S4.SS2.SSS3.p3.2.m2.1.1.1" xref="S4.SS2.SSS3.p3.2.m2.1.1.2.cmml"><mo id="S4.SS2.SSS3.p3.2.m2.1.1.1.2" stretchy="false" xref="S4.SS2.SSS3.p3.2.m2.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS3.p3.2.m2.1.1.1.1" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.2" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.2.cmml">Flows</mi><mrow id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.cmml"><mi id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.2" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.2.cmml">h</mi><mo id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.1" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.3" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.3.cmml">p</mi></mrow></msub><mo id="S4.SS2.SSS3.p3.2.m2.1.1.1.3" stretchy="false" xref="S4.SS2.SSS3.p3.2.m2.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.2.m2.1b"><apply id="S4.SS2.SSS3.p3.2.m2.1.1.2.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1"><abs id="S4.SS2.SSS3.p3.2.m2.1.1.2.1.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.2"></abs><apply id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.2">Flows</ci><apply id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3"><times id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.1.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.1"></times><ci id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.2.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.2">ℎ</ci><ci id="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.3.cmml" xref="S4.SS2.SSS3.p3.2.m2.1.1.1.1.3.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.2.m2.1c">|\mathrm{Flows}_{hp}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p3.2.m2.1d">| roman_Flows start_POSTSUBSCRIPT italic_h italic_p end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of flows with hallucinated parameter key names and <math alttext="|\mathrm{Flows}_{\mathrm{parsed}}|" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p3.3.m3.1"><semantics id="S4.SS2.SSS3.p3.3.m3.1a"><mrow id="S4.SS2.SSS3.p3.3.m3.1.1.1" xref="S4.SS2.SSS3.p3.3.m3.1.1.2.cmml"><mo id="S4.SS2.SSS3.p3.3.m3.1.1.1.2" stretchy="false" xref="S4.SS2.SSS3.p3.3.m3.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS3.p3.3.m3.1.1.1.1" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p3.3.m3.1.1.1.1.2" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1.2.cmml">Flows</mi><mi id="S4.SS2.SSS3.p3.3.m3.1.1.1.1.3" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1.3.cmml">parsed</mi></msub><mo id="S4.SS2.SSS3.p3.3.m3.1.1.1.3" stretchy="false" xref="S4.SS2.SSS3.p3.3.m3.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p3.3.m3.1b"><apply id="S4.SS2.SSS3.p3.3.m3.1.1.2.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1.1"><abs id="S4.SS2.SSS3.p3.3.m3.1.1.2.1.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.2"></abs><apply id="S4.SS2.SSS3.p3.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p3.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p3.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1.2">Flows</ci><ci id="S4.SS2.SSS3.p3.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p3.3.m3.1.1.1.1.3">parsed</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p3.3.m3.1c">|\mathrm{Flows}_{\mathrm{parsed}}|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p3.3.m3.1d">| roman_Flows start_POSTSUBSCRIPT roman_parsed end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of flows that were parsed correctly.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.2">In this section, we present the results of the above approaches on a test set of 1000 NL-DSL pairs. The test set is split in <math alttext="864" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mn id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">864</mn><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><cn id="S5.p1.1.m1.1.1.cmml" type="integer" xref="S5.p1.1.m1.1.1">864</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">864</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">864</annotation></semantics></math> in-domain samples and <math alttext="136" class="ltx_Math" display="inline" id="S5.p1.2.m2.1"><semantics id="S5.p1.2.m2.1a"><mn id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">136</mn><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><cn id="S5.p1.2.m2.1.1.cmml" type="integer" xref="S5.p1.2.m2.1.1">136</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">136</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.1d">136</annotation></semantics></math> out-of-domain samples. The NL component in these samples, while generated synthetically, has been evaluated by human judges for quality. They were also sampled to represent the distribution of APIs in actual product usage.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.3">We compare the impact of each ablation in sections below. Please note that in the following sections all the results are presented as <math alttext="\Delta" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" mathvariant="normal" xref="S5.p2.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">roman_Δ</annotation></semantics></math> change compared to a baseline scenario where the higher <math alttext="\Delta" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><mi id="S5.p2.2.m2.1.1" mathvariant="normal" xref="S5.p2.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><ci id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">roman_Δ</annotation></semantics></math> is better for Avg. similarity and lower <math alttext="\Delta" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><mi id="S5.p2.3.m3.1.1" mathvariant="normal" xref="S5.p2.3.m3.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><ci id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">roman_Δ</annotation></semantics></math> is better for the rest of metrics capturing failures.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Impact of number of few-shots</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2">We compare the impact of number of code samples added to the meta prompt with two different settings i.e. <math alttext="5" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn id="S5.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">5</annotation></semantics></math> few-shots vs <math alttext="20" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn id="S5.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">20</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">20</annotation></semantics></math> few-shots. We measured the results for both Pre-trained model as well as TST model. Results are shared in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.T1" title="Table 1 ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Looking at rows 2 and 4 having 20 few-shot samples, we can see that adding more few-shots improves the performance of both the Pre-trained as well as the TST model on all metrics. The gain is particularly pronounced for reducing the number of made-up API names as well as reducing the number of made-up API parameter keys.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.12">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T3.12.13.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.12.13.1.2">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S5.T3.12.13.1.2.1" style="width:71.1pt;">
<span class="ltx_p" id="S5.T3.12.13.1.2.1.1">Avg. Similarity</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.12.13.1.3">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S5.T3.12.13.1.3.1" style="width:85.4pt;">
<span class="ltx_p" id="S5.T3.12.13.1.3.1.1">%Unparsed flows</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.12.13.1.4">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S5.T3.12.13.1.4.1" style="width:78.2pt;">
<span class="ltx_p" id="S5.T3.12.13.1.4.1.1">%Made-up API names</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.12.13.1.5">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S5.T3.12.13.1.5.1" style="width:78.2pt;">
<span class="ltx_p" id="S5.T3.12.13.1.5.1.1">%Made-up API parameters</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.5.1">Pre-trained + FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1"><math alttext="-0.01" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.m1.1a"><mrow id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml"><mo id="S5.T3.1.1.1.m1.1.1a" xref="S5.T3.1.1.1.m1.1.1.cmml">−</mo><mn id="S5.T3.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.m1.1.1.2.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1"><minus id="S5.T3.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1"></minus><cn id="S5.T3.1.1.1.m1.1.1.2.cmml" type="float" xref="S5.T3.1.1.1.m1.1.1.2">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">-0.01</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">- 0.01</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.2"><math alttext="+2.29" class="ltx_Math" display="inline" id="S5.T3.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.m1.1a"><mrow id="S5.T3.2.2.2.m1.1.1" xref="S5.T3.2.2.2.m1.1.1.cmml"><mo id="S5.T3.2.2.2.m1.1.1a" xref="S5.T3.2.2.2.m1.1.1.cmml">+</mo><mn id="S5.T3.2.2.2.m1.1.1.2" xref="S5.T3.2.2.2.m1.1.1.2.cmml">2.29</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.m1.1b"><apply id="S5.T3.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1"><plus id="S5.T3.2.2.2.m1.1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1"></plus><cn id="S5.T3.2.2.2.m1.1.1.2.cmml" type="float" xref="S5.T3.2.2.2.m1.1.1.2">2.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.m1.1c">+2.29</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.m1.1d">+ 2.29</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.3.3.3"><math alttext="-2.17" class="ltx_Math" display="inline" id="S5.T3.3.3.3.m1.1"><semantics id="S5.T3.3.3.3.m1.1a"><mrow id="S5.T3.3.3.3.m1.1.1" xref="S5.T3.3.3.3.m1.1.1.cmml"><mo id="S5.T3.3.3.3.m1.1.1a" xref="S5.T3.3.3.3.m1.1.1.cmml">−</mo><mn id="S5.T3.3.3.3.m1.1.1.2" xref="S5.T3.3.3.3.m1.1.1.2.cmml">2.17</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.m1.1b"><apply id="S5.T3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1"><minus id="S5.T3.3.3.3.m1.1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1"></minus><cn id="S5.T3.3.3.3.m1.1.1.2.cmml" type="float" xref="S5.T3.3.3.3.m1.1.1.2">2.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.m1.1c">-2.17</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.m1.1d">- 2.17</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4"><math alttext="-6.93" class="ltx_Math" display="inline" id="S5.T3.4.4.4.m1.1"><semantics id="S5.T3.4.4.4.m1.1a"><mrow id="S5.T3.4.4.4.m1.1.1" xref="S5.T3.4.4.4.m1.1.1.cmml"><mo id="S5.T3.4.4.4.m1.1.1a" xref="S5.T3.4.4.4.m1.1.1.cmml">−</mo><mn id="S5.T3.4.4.4.m1.1.1.2" xref="S5.T3.4.4.4.m1.1.1.2.cmml">6.93</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.m1.1b"><apply id="S5.T3.4.4.4.m1.1.1.cmml" xref="S5.T3.4.4.4.m1.1.1"><minus id="S5.T3.4.4.4.m1.1.1.1.cmml" xref="S5.T3.4.4.4.m1.1.1"></minus><cn id="S5.T3.4.4.4.m1.1.1.2.cmml" type="float" xref="S5.T3.4.4.4.m1.1.1.2">6.93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.m1.1c">-6.93</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.4.m1.1d">- 6.93</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T3.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.8.8.5"><span class="ltx_text ltx_font_bold" id="S5.T3.8.8.5.1">TST wo FD</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.5.5.1"><math alttext="0" class="ltx_Math" display="inline" id="S5.T3.5.5.1.m1.1"><semantics id="S5.T3.5.5.1.m1.1a"><mn id="S5.T3.5.5.1.m1.1.1" xref="S5.T3.5.5.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.1.m1.1b"><cn id="S5.T3.5.5.1.m1.1.1.cmml" type="integer" xref="S5.T3.5.5.1.m1.1.1">0</cn></annotation-xml></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T3.6.6.2"><math alttext="+0.52" class="ltx_Math" display="inline" id="S5.T3.6.6.2.m1.1"><semantics id="S5.T3.6.6.2.m1.1a"><mrow id="S5.T3.6.6.2.m1.1.1" xref="S5.T3.6.6.2.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T3.6.6.2.m1.1.1a" mathvariant="bold" xref="S5.T3.6.6.2.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S5.T3.6.6.2.m1.1.1.2" mathvariant="bold" xref="S5.T3.6.6.2.m1.1.1.2.cmml">0.52</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.2.m1.1b"><apply id="S5.T3.6.6.2.m1.1.1.cmml" xref="S5.T3.6.6.2.m1.1.1"><plus id="S5.T3.6.6.2.m1.1.1.1.cmml" xref="S5.T3.6.6.2.m1.1.1"></plus><cn id="S5.T3.6.6.2.m1.1.1.2.cmml" type="float" xref="S5.T3.6.6.2.m1.1.1.2">0.52</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.2.m1.1c">+0.52</annotation><annotation encoding="application/x-llamapun" id="S5.T3.6.6.2.m1.1d">bold_+ bold_0.52</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.7.3"><math alttext="-1.15" class="ltx_Math" display="inline" id="S5.T3.7.7.3.m1.1"><semantics id="S5.T3.7.7.3.m1.1a"><mrow id="S5.T3.7.7.3.m1.1.1" xref="S5.T3.7.7.3.m1.1.1.cmml"><mo id="S5.T3.7.7.3.m1.1.1a" xref="S5.T3.7.7.3.m1.1.1.cmml">−</mo><mn id="S5.T3.7.7.3.m1.1.1.2" xref="S5.T3.7.7.3.m1.1.1.2.cmml">1.15</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.3.m1.1b"><apply id="S5.T3.7.7.3.m1.1.1.cmml" xref="S5.T3.7.7.3.m1.1.1"><minus id="S5.T3.7.7.3.m1.1.1.1.cmml" xref="S5.T3.7.7.3.m1.1.1"></minus><cn id="S5.T3.7.7.3.m1.1.1.2.cmml" type="float" xref="S5.T3.7.7.3.m1.1.1.2">1.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.3.m1.1c">-1.15</annotation><annotation encoding="application/x-llamapun" id="S5.T3.7.7.3.m1.1d">- 1.15</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T3.8.8.4"><math alttext="+0.52" class="ltx_Math" display="inline" id="S5.T3.8.8.4.m1.1"><semantics id="S5.T3.8.8.4.m1.1a"><mrow id="S5.T3.8.8.4.m1.1.1" xref="S5.T3.8.8.4.m1.1.1.cmml"><mo id="S5.T3.8.8.4.m1.1.1a" xref="S5.T3.8.8.4.m1.1.1.cmml">+</mo><mn id="S5.T3.8.8.4.m1.1.1.2" xref="S5.T3.8.8.4.m1.1.1.2.cmml">0.52</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.4.m1.1b"><apply id="S5.T3.8.8.4.m1.1.1.cmml" xref="S5.T3.8.8.4.m1.1.1"><plus id="S5.T3.8.8.4.m1.1.1.1.cmml" xref="S5.T3.8.8.4.m1.1.1"></plus><cn id="S5.T3.8.8.4.m1.1.1.2.cmml" type="float" xref="S5.T3.8.8.4.m1.1.1.2">0.52</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.4.m1.1c">+0.52</annotation><annotation encoding="application/x-llamapun" id="S5.T3.8.8.4.m1.1d">+ 0.52</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T3.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S5.T3.12.12.5"><span class="ltx_text ltx_font_bold" id="S5.T3.12.12.5.1">TST + FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.9.9.1"><math alttext="+0.02" class="ltx_Math" display="inline" id="S5.T3.9.9.1.m1.1"><semantics id="S5.T3.9.9.1.m1.1a"><mrow id="S5.T3.9.9.1.m1.1.1" xref="S5.T3.9.9.1.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T3.9.9.1.m1.1.1a" mathvariant="bold" xref="S5.T3.9.9.1.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S5.T3.9.9.1.m1.1.1.2" mathvariant="bold" xref="S5.T3.9.9.1.m1.1.1.2.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.1.m1.1b"><apply id="S5.T3.9.9.1.m1.1.1.cmml" xref="S5.T3.9.9.1.m1.1.1"><plus id="S5.T3.9.9.1.m1.1.1.1.cmml" xref="S5.T3.9.9.1.m1.1.1"></plus><cn id="S5.T3.9.9.1.m1.1.1.2.cmml" type="float" xref="S5.T3.9.9.1.m1.1.1.2">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.1.m1.1c">+0.02</annotation><annotation encoding="application/x-llamapun" id="S5.T3.9.9.1.m1.1d">bold_+ bold_0.02</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.10.10.2"><math alttext="+0.83" class="ltx_Math" display="inline" id="S5.T3.10.10.2.m1.1"><semantics id="S5.T3.10.10.2.m1.1a"><mrow id="S5.T3.10.10.2.m1.1.1" xref="S5.T3.10.10.2.m1.1.1.cmml"><mo id="S5.T3.10.10.2.m1.1.1a" xref="S5.T3.10.10.2.m1.1.1.cmml">+</mo><mn id="S5.T3.10.10.2.m1.1.1.2" xref="S5.T3.10.10.2.m1.1.1.2.cmml">0.83</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.2.m1.1b"><apply id="S5.T3.10.10.2.m1.1.1.cmml" xref="S5.T3.10.10.2.m1.1.1"><plus id="S5.T3.10.10.2.m1.1.1.1.cmml" xref="S5.T3.10.10.2.m1.1.1"></plus><cn id="S5.T3.10.10.2.m1.1.1.2.cmml" type="float" xref="S5.T3.10.10.2.m1.1.1.2">0.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.2.m1.1c">+0.83</annotation><annotation encoding="application/x-llamapun" id="S5.T3.10.10.2.m1.1d">+ 0.83</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.11.11.3"><math alttext="-2.7" class="ltx_Math" display="inline" id="S5.T3.11.11.3.m1.1"><semantics id="S5.T3.11.11.3.m1.1a"><mrow id="S5.T3.11.11.3.m1.1.1" xref="S5.T3.11.11.3.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T3.11.11.3.m1.1.1a" mathvariant="bold" xref="S5.T3.11.11.3.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S5.T3.11.11.3.m1.1.1.2" mathvariant="bold" xref="S5.T3.11.11.3.m1.1.1.2.cmml">2.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.11.11.3.m1.1b"><apply id="S5.T3.11.11.3.m1.1.1.cmml" xref="S5.T3.11.11.3.m1.1.1"><minus id="S5.T3.11.11.3.m1.1.1.1.cmml" xref="S5.T3.11.11.3.m1.1.1"></minus><cn id="S5.T3.11.11.3.m1.1.1.2.cmml" type="float" xref="S5.T3.11.11.3.m1.1.1.2">2.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.11.3.m1.1c">-2.7</annotation><annotation encoding="application/x-llamapun" id="S5.T3.11.11.3.m1.1d">bold_- bold_2.7</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.12.12.4"><math alttext="-7.06" class="ltx_Math" display="inline" id="S5.T3.12.12.4.m1.1"><semantics id="S5.T3.12.12.4.m1.1a"><mrow id="S5.T3.12.12.4.m1.1.1" xref="S5.T3.12.12.4.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T3.12.12.4.m1.1.1a" mathvariant="bold" xref="S5.T3.12.12.4.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S5.T3.12.12.4.m1.1.1.2" mathvariant="bold" xref="S5.T3.12.12.4.m1.1.1.2.cmml">7.06</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.12.12.4.m1.1b"><apply id="S5.T3.12.12.4.m1.1.1.cmml" xref="S5.T3.12.12.4.m1.1.1"><minus id="S5.T3.12.12.4.m1.1.1.1.cmml" xref="S5.T3.12.12.4.m1.1.1"></minus><cn id="S5.T3.12.12.4.m1.1.1.2.cmml" type="float" xref="S5.T3.12.12.4.m1.1.1.2">7.06</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.12.4.m1.1c">-7.06</annotation><annotation encoding="application/x-llamapun" id="S5.T3.12.12.4.m1.1d">bold_- bold_7.06</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Impact of selecting <span class="ltx_text ltx_font_bold" id="S5.T3.14.1">20 few-shot</span> samples using TST vs. Pre-trained Model with and without Function Definitions using GPT4 model. The baseline uses Pre-trained Transformer Model without API Function Definitions.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.12">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T4.12.13.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.12.13.1.2">Avg. Similarity</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.12.13.1.3">%Unparsed flows</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.12.13.1.4">%Made-up API names</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.12.13.1.5">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S5.T4.12.13.1.5.1" style="width:71.1pt;">
<span class="ltx_p" id="S5.T4.12.13.1.5.1.1">%Made-up API parameters</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.4.4.5"><span class="ltx_text ltx_font_bold" id="S5.T4.4.4.5.1">TST + FD</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1"><math alttext="0" class="ltx_Math" display="inline" id="S5.T4.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.m1.1a"><mn id="S5.T4.1.1.1.m1.1.1" xref="S5.T4.1.1.1.m1.1.1.cmml">𝟎</mn><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b"><cn id="S5.T4.1.1.1.m1.1.1.cmml" type="integer" xref="S5.T4.1.1.1.m1.1.1">0</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.m1.1c">bold_0</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.2"><math alttext="-5.3" class="ltx_Math" display="inline" id="S5.T4.2.2.2.m1.1"><semantics id="S5.T4.2.2.2.m1.1a"><mrow id="S5.T4.2.2.2.m1.1.1" xref="S5.T4.2.2.2.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T4.2.2.2.m1.1.1a" mathvariant="bold" xref="S5.T4.2.2.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S5.T4.2.2.2.m1.1.1.2" mathvariant="bold" xref="S5.T4.2.2.2.m1.1.1.2.cmml">5.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.m1.1b"><apply id="S5.T4.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1"><minus id="S5.T4.2.2.2.m1.1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1"></minus><cn id="S5.T4.2.2.2.m1.1.1.2.cmml" type="float" xref="S5.T4.2.2.2.m1.1.1.2">5.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.m1.1c">-5.3</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.m1.1d">bold_- bold_5.3</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.3.3"><math alttext="+1.7" class="ltx_Math" display="inline" id="S5.T4.3.3.3.m1.1"><semantics id="S5.T4.3.3.3.m1.1a"><mrow id="S5.T4.3.3.3.m1.1.1" xref="S5.T4.3.3.3.m1.1.1.cmml"><mo id="S5.T4.3.3.3.m1.1.1a" xref="S5.T4.3.3.3.m1.1.1.cmml">+</mo><mn id="S5.T4.3.3.3.m1.1.1.2" xref="S5.T4.3.3.3.m1.1.1.2.cmml">1.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.m1.1b"><apply id="S5.T4.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.m1.1.1"><plus id="S5.T4.3.3.3.m1.1.1.1.cmml" xref="S5.T4.3.3.3.m1.1.1"></plus><cn id="S5.T4.3.3.3.m1.1.1.2.cmml" type="float" xref="S5.T4.3.3.3.m1.1.1.2">1.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.m1.1c">+1.7</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.3.3.m1.1d">+ 1.7</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.4.4.4"><math alttext="+1.11" class="ltx_Math" display="inline" id="S5.T4.4.4.4.m1.1"><semantics id="S5.T4.4.4.4.m1.1a"><mrow id="S5.T4.4.4.4.m1.1.1" xref="S5.T4.4.4.4.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T4.4.4.4.m1.1.1a" mathvariant="bold" xref="S5.T4.4.4.4.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S5.T4.4.4.4.m1.1.1.2" mathvariant="bold" xref="S5.T4.4.4.4.m1.1.1.2.cmml">1.11</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.m1.1b"><apply id="S5.T4.4.4.4.m1.1.1.cmml" xref="S5.T4.4.4.4.m1.1.1"><plus id="S5.T4.4.4.4.m1.1.1.1.cmml" xref="S5.T4.4.4.4.m1.1.1"></plus><cn id="S5.T4.4.4.4.m1.1.1.2.cmml" type="float" xref="S5.T4.4.4.4.m1.1.1.2">1.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.m1.1c">+1.11</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.4.4.m1.1d">bold_+ bold_1.11</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.8.8.5"><span class="ltx_text ltx_font_bold" id="S5.T4.8.8.5.1">TST + SFD</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.5.5.1"><math alttext="-0.01" class="ltx_Math" display="inline" id="S5.T4.5.5.1.m1.1"><semantics id="S5.T4.5.5.1.m1.1a"><mrow id="S5.T4.5.5.1.m1.1.1" xref="S5.T4.5.5.1.m1.1.1.cmml"><mo id="S5.T4.5.5.1.m1.1.1a" xref="S5.T4.5.5.1.m1.1.1.cmml">−</mo><mn id="S5.T4.5.5.1.m1.1.1.2" xref="S5.T4.5.5.1.m1.1.1.2.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.1.m1.1b"><apply id="S5.T4.5.5.1.m1.1.1.cmml" xref="S5.T4.5.5.1.m1.1.1"><minus id="S5.T4.5.5.1.m1.1.1.1.cmml" xref="S5.T4.5.5.1.m1.1.1"></minus><cn id="S5.T4.5.5.1.m1.1.1.2.cmml" type="float" xref="S5.T4.5.5.1.m1.1.1.2">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.1.m1.1c">-0.01</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.5.1.m1.1d">- 0.01</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.6.2"><math alttext="-1.43" class="ltx_Math" display="inline" id="S5.T4.6.6.2.m1.1"><semantics id="S5.T4.6.6.2.m1.1a"><mrow id="S5.T4.6.6.2.m1.1.1" xref="S5.T4.6.6.2.m1.1.1.cmml"><mo id="S5.T4.6.6.2.m1.1.1a" xref="S5.T4.6.6.2.m1.1.1.cmml">−</mo><mn id="S5.T4.6.6.2.m1.1.1.2" xref="S5.T4.6.6.2.m1.1.1.2.cmml">1.43</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.2.m1.1b"><apply id="S5.T4.6.6.2.m1.1.1.cmml" xref="S5.T4.6.6.2.m1.1.1"><minus id="S5.T4.6.6.2.m1.1.1.1.cmml" xref="S5.T4.6.6.2.m1.1.1"></minus><cn id="S5.T4.6.6.2.m1.1.1.2.cmml" type="float" xref="S5.T4.6.6.2.m1.1.1.2">1.43</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.2.m1.1c">-1.43</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.6.2.m1.1d">- 1.43</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T4.7.7.3"><math alttext="+1.21" class="ltx_Math" display="inline" id="S5.T4.7.7.3.m1.1"><semantics id="S5.T4.7.7.3.m1.1a"><mrow id="S5.T4.7.7.3.m1.1.1" xref="S5.T4.7.7.3.m1.1.1.cmml"><mo id="S5.T4.7.7.3.m1.1.1a" xref="S5.T4.7.7.3.m1.1.1.cmml">+</mo><mn id="S5.T4.7.7.3.m1.1.1.2" xref="S5.T4.7.7.3.m1.1.1.2.cmml">1.21</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.7.7.3.m1.1b"><apply id="S5.T4.7.7.3.m1.1.1.cmml" xref="S5.T4.7.7.3.m1.1.1"><plus id="S5.T4.7.7.3.m1.1.1.1.cmml" xref="S5.T4.7.7.3.m1.1.1"></plus><cn id="S5.T4.7.7.3.m1.1.1.2.cmml" type="float" xref="S5.T4.7.7.3.m1.1.1.2">1.21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.7.3.m1.1c">+1.21</annotation><annotation encoding="application/x-llamapun" id="S5.T4.7.7.3.m1.1d">+ 1.21</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.8.4"><math alttext="+6.76" class="ltx_Math" display="inline" id="S5.T4.8.8.4.m1.1"><semantics id="S5.T4.8.8.4.m1.1a"><mrow id="S5.T4.8.8.4.m1.1.1" xref="S5.T4.8.8.4.m1.1.1.cmml"><mo id="S5.T4.8.8.4.m1.1.1a" xref="S5.T4.8.8.4.m1.1.1.cmml">+</mo><mn id="S5.T4.8.8.4.m1.1.1.2" xref="S5.T4.8.8.4.m1.1.1.2.cmml">6.76</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.8.8.4.m1.1b"><apply id="S5.T4.8.8.4.m1.1.1.cmml" xref="S5.T4.8.8.4.m1.1.1"><plus id="S5.T4.8.8.4.m1.1.1.1.cmml" xref="S5.T4.8.8.4.m1.1.1"></plus><cn id="S5.T4.8.8.4.m1.1.1.2.cmml" type="float" xref="S5.T4.8.8.4.m1.1.1.2">6.76</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.8.4.m1.1c">+6.76</annotation><annotation encoding="application/x-llamapun" id="S5.T4.8.8.4.m1.1d">+ 6.76</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T4.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S5.T4.12.12.5"><span class="ltx_text ltx_font_bold" id="S5.T4.12.12.5.1">TST + FD + SFD</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.9.9.1"><math alttext="0" class="ltx_Math" display="inline" id="S5.T4.9.9.1.m1.1"><semantics id="S5.T4.9.9.1.m1.1a"><mn id="S5.T4.9.9.1.m1.1.1" xref="S5.T4.9.9.1.m1.1.1.cmml">𝟎</mn><annotation-xml encoding="MathML-Content" id="S5.T4.9.9.1.m1.1b"><cn id="S5.T4.9.9.1.m1.1.1.cmml" type="integer" xref="S5.T4.9.9.1.m1.1.1">0</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S5.T4.9.9.1.m1.1c">bold_0</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.10.10.2"><math alttext="-2.74" class="ltx_Math" display="inline" id="S5.T4.10.10.2.m1.1"><semantics id="S5.T4.10.10.2.m1.1a"><mrow id="S5.T4.10.10.2.m1.1.1" xref="S5.T4.10.10.2.m1.1.1.cmml"><mo id="S5.T4.10.10.2.m1.1.1a" xref="S5.T4.10.10.2.m1.1.1.cmml">−</mo><mn id="S5.T4.10.10.2.m1.1.1.2" xref="S5.T4.10.10.2.m1.1.1.2.cmml">2.74</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.10.10.2.m1.1b"><apply id="S5.T4.10.10.2.m1.1.1.cmml" xref="S5.T4.10.10.2.m1.1.1"><minus id="S5.T4.10.10.2.m1.1.1.1.cmml" xref="S5.T4.10.10.2.m1.1.1"></minus><cn id="S5.T4.10.10.2.m1.1.1.2.cmml" type="float" xref="S5.T4.10.10.2.m1.1.1.2">2.74</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.10.10.2.m1.1c">-2.74</annotation><annotation encoding="application/x-llamapun" id="S5.T4.10.10.2.m1.1d">- 2.74</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.11.11.3"><math alttext="+0.94" class="ltx_Math" display="inline" id="S5.T4.11.11.3.m1.1"><semantics id="S5.T4.11.11.3.m1.1a"><mrow id="S5.T4.11.11.3.m1.1.1" xref="S5.T4.11.11.3.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T4.11.11.3.m1.1.1a" mathvariant="bold" xref="S5.T4.11.11.3.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S5.T4.11.11.3.m1.1.1.2" mathvariant="bold" xref="S5.T4.11.11.3.m1.1.1.2.cmml">0.94</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.11.11.3.m1.1b"><apply id="S5.T4.11.11.3.m1.1.1.cmml" xref="S5.T4.11.11.3.m1.1.1"><plus id="S5.T4.11.11.3.m1.1.1.1.cmml" xref="S5.T4.11.11.3.m1.1.1"></plus><cn id="S5.T4.11.11.3.m1.1.1.2.cmml" type="float" xref="S5.T4.11.11.3.m1.1.1.2">0.94</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.11.11.3.m1.1c">+0.94</annotation><annotation encoding="application/x-llamapun" id="S5.T4.11.11.3.m1.1d">bold_+ bold_0.94</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.12.12.4"><math alttext="+2.03" class="ltx_Math" display="inline" id="S5.T4.12.12.4.m1.1"><semantics id="S5.T4.12.12.4.m1.1a"><mrow id="S5.T4.12.12.4.m1.1.1" xref="S5.T4.12.12.4.m1.1.1.cmml"><mo id="S5.T4.12.12.4.m1.1.1a" xref="S5.T4.12.12.4.m1.1.1.cmml">+</mo><mn id="S5.T4.12.12.4.m1.1.1.2" xref="S5.T4.12.12.4.m1.1.1.2.cmml">2.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.12.12.4.m1.1b"><apply id="S5.T4.12.12.4.m1.1.1.cmml" xref="S5.T4.12.12.4.m1.1.1"><plus id="S5.T4.12.12.4.m1.1.1.1.cmml" xref="S5.T4.12.12.4.m1.1.1"></plus><cn id="S5.T4.12.12.4.m1.1.1.2.cmml" type="float" xref="S5.T4.12.12.4.m1.1.1.2">2.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.12.12.4.m1.1c">+2.03</annotation><annotation encoding="application/x-llamapun" id="S5.T4.12.12.4.m1.1d">+ 2.03</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Impact of adding API or tool related metadata on performance (with GPT-4 model and 20 few-shots). FD refers to including only metadata for APIs present in few-shots. SFD refers to extracting APIs similar to the input query (refer to Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3" title="3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">3</span></a>) for details. The baseline uses fine-tuned Codex model.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T5">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T5.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T5.8.9.1.1">Test set</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.8.9.1.2">Avg. Similarity</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.8.9.1.3">%Unparsed flows</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.8.9.1.4">%Made-up API names</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.8.9.1.5">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="S5.T5.8.9.1.5.1" style="width:89.6pt;">
<span class="ltx_p" id="S5.T5.8.9.1.5.1.1">%Made-up API</span>
<span class="ltx_p" id="S5.T5.8.9.1.5.1.2">parameters</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.4.4.5"><span class="ltx_text ltx_font_bold" id="S5.T5.4.4.5.1">OOD test set</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1"><math alttext="+0.07" class="ltx_Math" display="inline" id="S5.T5.1.1.1.m1.1"><semantics id="S5.T5.1.1.1.m1.1a"><mrow id="S5.T5.1.1.1.m1.1.1" xref="S5.T5.1.1.1.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T5.1.1.1.m1.1.1a" mathvariant="bold" xref="S5.T5.1.1.1.m1.1.1.cmml">+</mo><mn class="ltx_mathvariant_bold" id="S5.T5.1.1.1.m1.1.1.2" mathvariant="bold" xref="S5.T5.1.1.1.m1.1.1.2.cmml">0.07</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.m1.1b"><apply id="S5.T5.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1"><plus id="S5.T5.1.1.1.m1.1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1"></plus><cn id="S5.T5.1.1.1.m1.1.1.2.cmml" type="float" xref="S5.T5.1.1.1.m1.1.1.2">0.07</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.m1.1c">+0.07</annotation><annotation encoding="application/x-llamapun" id="S5.T5.1.1.1.m1.1d">bold_+ bold_0.07</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.2.2.2"><math alttext="+12.23" class="ltx_Math" display="inline" id="S5.T5.2.2.2.m1.1"><semantics id="S5.T5.2.2.2.m1.1a"><mrow id="S5.T5.2.2.2.m1.1.1" xref="S5.T5.2.2.2.m1.1.1.cmml"><mo id="S5.T5.2.2.2.m1.1.1a" xref="S5.T5.2.2.2.m1.1.1.cmml">+</mo><mn id="S5.T5.2.2.2.m1.1.1.2" xref="S5.T5.2.2.2.m1.1.1.2.cmml">12.23</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.m1.1b"><apply id="S5.T5.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.m1.1.1"><plus id="S5.T5.2.2.2.m1.1.1.1.cmml" xref="S5.T5.2.2.2.m1.1.1"></plus><cn id="S5.T5.2.2.2.m1.1.1.2.cmml" type="float" xref="S5.T5.2.2.2.m1.1.1.2">12.23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.m1.1c">+12.23</annotation><annotation encoding="application/x-llamapun" id="S5.T5.2.2.2.m1.1d">+ 12.23</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.3.3.3"><math alttext="-1.98" class="ltx_Math" display="inline" id="S5.T5.3.3.3.m1.1"><semantics id="S5.T5.3.3.3.m1.1a"><mrow id="S5.T5.3.3.3.m1.1.1" xref="S5.T5.3.3.3.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T5.3.3.3.m1.1.1a" mathvariant="bold" xref="S5.T5.3.3.3.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S5.T5.3.3.3.m1.1.1.2" mathvariant="bold" xref="S5.T5.3.3.3.m1.1.1.2.cmml">1.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.m1.1b"><apply id="S5.T5.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.m1.1.1"><minus id="S5.T5.3.3.3.m1.1.1.1.cmml" xref="S5.T5.3.3.3.m1.1.1"></minus><cn id="S5.T5.3.3.3.m1.1.1.2.cmml" type="float" xref="S5.T5.3.3.3.m1.1.1.2">1.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.m1.1c">-1.98</annotation><annotation encoding="application/x-llamapun" id="S5.T5.3.3.3.m1.1d">bold_- bold_1.98</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.4.4"><math alttext="+13.11" class="ltx_Math" display="inline" id="S5.T5.4.4.4.m1.1"><semantics id="S5.T5.4.4.4.m1.1a"><mrow id="S5.T5.4.4.4.m1.1.1" xref="S5.T5.4.4.4.m1.1.1.cmml"><mo id="S5.T5.4.4.4.m1.1.1a" xref="S5.T5.4.4.4.m1.1.1.cmml">+</mo><mn id="S5.T5.4.4.4.m1.1.1.2" xref="S5.T5.4.4.4.m1.1.1.2.cmml">13.11</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.4.m1.1b"><apply id="S5.T5.4.4.4.m1.1.1.cmml" xref="S5.T5.4.4.4.m1.1.1"><plus id="S5.T5.4.4.4.m1.1.1.1.cmml" xref="S5.T5.4.4.4.m1.1.1"></plus><cn id="S5.T5.4.4.4.m1.1.1.2.cmml" type="float" xref="S5.T5.4.4.4.m1.1.1.2">13.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.4.m1.1c">+13.11</annotation><annotation encoding="application/x-llamapun" id="S5.T5.4.4.4.m1.1d">+ 13.11</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T5.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S5.T5.8.8.5"><span class="ltx_text ltx_font_bold" id="S5.T5.8.8.5.1">Full test set</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.5.5.1"><math alttext="0" class="ltx_Math" display="inline" id="S5.T5.5.5.1.m1.1"><semantics id="S5.T5.5.5.1.m1.1a"><mn id="S5.T5.5.5.1.m1.1.1" xref="S5.T5.5.5.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.T5.5.5.1.m1.1b"><cn id="S5.T5.5.5.1.m1.1.1.cmml" type="integer" xref="S5.T5.5.5.1.m1.1.1">0</cn></annotation-xml></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.6.6.2"><math alttext="+1.06" class="ltx_Math" display="inline" id="S5.T5.6.6.2.m1.1"><semantics id="S5.T5.6.6.2.m1.1a"><mrow id="S5.T5.6.6.2.m1.1.1" xref="S5.T5.6.6.2.m1.1.1.cmml"><mo id="S5.T5.6.6.2.m1.1.1a" xref="S5.T5.6.6.2.m1.1.1.cmml">+</mo><mn id="S5.T5.6.6.2.m1.1.1.2" xref="S5.T5.6.6.2.m1.1.1.2.cmml">1.06</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.6.6.2.m1.1b"><apply id="S5.T5.6.6.2.m1.1.1.cmml" xref="S5.T5.6.6.2.m1.1.1"><plus id="S5.T5.6.6.2.m1.1.1.1.cmml" xref="S5.T5.6.6.2.m1.1.1"></plus><cn id="S5.T5.6.6.2.m1.1.1.2.cmml" type="float" xref="S5.T5.6.6.2.m1.1.1.2">1.06</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.6.2.m1.1c">+1.06</annotation><annotation encoding="application/x-llamapun" id="S5.T5.6.6.2.m1.1d">+ 1.06</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.7.7.3"><math alttext="-0.48" class="ltx_Math" display="inline" id="S5.T5.7.7.3.m1.1"><semantics id="S5.T5.7.7.3.m1.1a"><mrow id="S5.T5.7.7.3.m1.1.1" xref="S5.T5.7.7.3.m1.1.1.cmml"><mo class="ltx_mathvariant_bold" id="S5.T5.7.7.3.m1.1.1a" mathvariant="bold" xref="S5.T5.7.7.3.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" id="S5.T5.7.7.3.m1.1.1.2" mathvariant="bold" xref="S5.T5.7.7.3.m1.1.1.2.cmml">0.48</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.7.7.3.m1.1b"><apply id="S5.T5.7.7.3.m1.1.1.cmml" xref="S5.T5.7.7.3.m1.1.1"><minus id="S5.T5.7.7.3.m1.1.1.1.cmml" xref="S5.T5.7.7.3.m1.1.1"></minus><cn id="S5.T5.7.7.3.m1.1.1.2.cmml" type="float" xref="S5.T5.7.7.3.m1.1.1.2">0.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.7.7.3.m1.1c">-0.48</annotation><annotation encoding="application/x-llamapun" id="S5.T5.7.7.3.m1.1d">bold_- bold_0.48</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.8.8.4"><math alttext="+3.88" class="ltx_Math" display="inline" id="S5.T5.8.8.4.m1.1"><semantics id="S5.T5.8.8.4.m1.1a"><mrow id="S5.T5.8.8.4.m1.1.1" xref="S5.T5.8.8.4.m1.1.1.cmml"><mo id="S5.T5.8.8.4.m1.1.1a" xref="S5.T5.8.8.4.m1.1.1.cmml">+</mo><mn id="S5.T5.8.8.4.m1.1.1.2" xref="S5.T5.8.8.4.m1.1.1.2.cmml">3.88</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.8.8.4.m1.1b"><apply id="S5.T5.8.8.4.m1.1.1.cmml" xref="S5.T5.8.8.4.m1.1.1"><plus id="S5.T5.8.8.4.m1.1.1.1.cmml" xref="S5.T5.8.8.4.m1.1.1"></plus><cn id="S5.T5.8.8.4.m1.1.1.2.cmml" type="float" xref="S5.T5.8.8.4.m1.1.1.2">3.88</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.8.8.4.m1.1c">+3.88</annotation><annotation encoding="application/x-llamapun" id="S5.T5.8.8.4.m1.1d">+ 3.88</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of RAG based model (TST + FD + SFD) on out of domain (OOD) and full test sets (with GPT-4 model and 20 few-shots). The baseline is fine-tuned Codex model on updated training data.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>TST vs Pre-trained Model</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">To compare the impact of selecting samples using TST vs Pre-trained model, we look at the impact with and without the presence of API Function Definitions (see Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.T2" title="Table 2 ‣ 4.2.1 Average Similarity ‣ 4.2 DSL Generation Quality Metrics ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T3" title="Table 3 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">3</span></a>). Here, we have used GPT4 model with 5 and 20 few-shots, respectively. TST with FD setting performs overall better than all other options with values close to the best in every metric.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">This leads us to conclude that the presence of few-shot examples is supported by adding their API functions definitions (as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S3" title="3 Methodology ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">3</span></a>). The addition predominantly helps reducing the hallucination rate for API names and parameters, which improves the overall response rate of NL2DSL generation. This supports our initial premise: adding tool descriptions (like it is done in planning tasks) along with few-shot code samples helps improve reliability of plan generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Regular Function Definition vs Semantic Function Definitions</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We used a Fine-Tuned model as baseline for this experiment (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T4" title="Table 4 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">4</span></a>). Based on the insights from the previous step, we used 20 few-shots for TST along with including FDs.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.2">Looking at metrics in columns for <math alttext="\%" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mo id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">%</annotation></semantics></math> made-up API names and <math alttext="\%" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><mo id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.2.m2.1d">%</annotation></semantics></math> made-up parameter keys, we see that the hallucination rate is, in general, increasing for RAG based approach. However, we need to keep in mind that a fine-tuned model on the function names is hard to beat as it has been trained on 67,000 samples compared to only 20 few-shots that have been added to the RAG model.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">Within the RAG approaches, comparing rows 1 and 2 ("TST + FD" vs "TST + SFD"), SFD results in a slight drop in average similarity and an increase in the unparsed rate and hallucination rate for parameters. This indicates that the approach to simply add semantically similar API metadata for a query is not useful for DSL generation. We get better similarity, and reduced hallucination rate, when we include the API Function Definitions for the samples selected by TST (as shown in Row 1).</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Out of Domain APIs</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">To compare the impact of RAG on unseen APIs, not available for fine-tuning, we created an out of domain test set. We selected 10 APIs, and discarded the flows containing these APIs from the train set. The test set contains 136 (NL, flow) pairs having these APIs.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">We share the results in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T5" title="Table 5 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">5</span></a>. The baseline is a fine-tuned Codex model with the updated training data. The RAG-based approach notably enhances average similarity (by 7 pts) and reduces API hallucinations (by 1.5 pts) for out of domain APIs. This indicates that when samples are not present in the train set, grounding with RAG context can provide the LLM support for improving code quality.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">However, fine-tuned model outperforms RAG model in terms of syntactic errors and parameter key hallucinations. The role of few-shots in informing the syntax of the output code cannot be substituted with just adding function definitions. Since, it is hard to obtain the examples for unseen APIs, we need to find alternate ways to improve syntactic errors. We will look into improving this as future work.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Based on the presented results, we see that the role of dynamically selected few-shot samples is very important in making RAG useful for syntactically correct generation of DSL as well as improving code similarity (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T4" title="Table 4 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">4</span></a>). This could be due to the fact that few-shot examples have been successfully teaching the correct syntax to the LLM model. The positive role of relevant few-shot samples in improving RAG’s syntactic accuracy is further confirmed by the drop seen for out of domain data. In absence of relevant few-shots for unseen APIs, we chose examples with low similarity, directly impacting the syntactic accuracy (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T5" title="Table 5 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Counter intuitively, with the exception of out-of-domain data, this benefit does not transfer to hallucinated API names and their parameter keys where the fine-tuned model holds the advantage (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T4" title="Table 4 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">4</span></a>). Among RAG approaches (Tables <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.T2" title="Table 2 ‣ 4.2.1 Average Similarity ‣ 4.2 DSL Generation Quality Metrics ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T3" title="Table 3 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">3</span></a>), TST + Regular Function Definitions reduced hallucinations the most. Adding Semantic Function Definitions to TST + FD did not confer any advantage for in-domain APIs, but greatly improved code similarity for out-of domain APIs.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Overall, we were able to significantly improve the performance of RAG for DSL generation, with hallucination rate for API names dropping by 6.29 pts. and by 20 pts for parameter keys (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S4.T2" title="Table 2 ‣ 4.2.1 Average Similarity ‣ 4.2 DSL Generation Quality Metrics ‣ 4 Experiment Design and Metrics Definition ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">2</span></a>). The performance of RAG is now comparable to that of fine-tuned model (see Avg. Similarity in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08335v1#S5.T4" title="Table 4 ‣ 5.1 Impact of number of few-shots ‣ 5 Results ‣ Plan with Code: Comparing approaches for robust NL to DSL generation"><span class="ltx_text ltx_ref_tag">4</span></a>), with better performance for unseen APIs. This reduces the need to fine-tune the model frequently for new APIs saving compute and resources.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Ethical Considerations</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We used instructions in meta prompt to not respond to harmful queries. This is supplemented with a harms classifier on the input prompt. The Fine-tuned model was shown examples where it should not generate an output and consequently learnt not to respond to queries considered harmful.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdin et al. (2024)</span>
<span class="ltx_bibblock">
Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, Sébastien Bubeck, Qin Cai, Martin Cai, Caio César Teodoro Mendes, Weizhu Chen, Vishrav Chaudhary, Dong Chen, Dongdong Chen, Yen-Chun Chen, Yi-Ling Chen, Parul Chopra, Xiyang Dai, Allie Del Giorno, Gustavo de Rosa, Matthew Dixon, Ronen Eldan, Victor Fragoso, Dan Iter, Mei Gao, Min Gao, Jianfeng Gao, Amit Garg, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J. Hewett, Jamie Huynh, Mojan Javaheripi, Xin Jin, Piero Kauffmann, Nikos Karampatziakis, Dongwoo Kim, Mahoud Khademi, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li, Yunsheng Li, Chen Liang, Lars Liden, Ce Liu, Mengchen Liu, Weishung Liu, Eric Lin, Zeqi Lin, Chong Luo, Piyush Madan, Matt Mazzola, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang
Qin, Marko Radmilac, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Swadheen Shukla, Xia Song, Masahiro Tanaka, Andrea Tupini, Xin Wang, Lijuan Wang, Chunyu Wang, Yu Wang, Rachel Ward, Guanhua Wang, Philipp Witte, Haiping Wu, Michael Wyatt, Bin Xiao, Can Xu, Jiahang Xu, Weijian Xu, Sonali Yadav, Fan Yang, Jianwei Yang, Ziyi Yang, Yifan Yang, Donghan Yu, Lu Yuan, Chengruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, and Xiren Zhou. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2404.14219" title="">Phi-3 technical report: A highly capable language model locally on your phone</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Preprint</em>, arXiv:2404.14219.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
ChatGPT. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openai.com/blog/chatgpt" title="">Chatgpt</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2107.03374" title="">Evaluating large language models trained on code</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arXiv:2107.03374.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
Code Llama. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2308.12950" title="">Code llama: Open foundation models for code</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Codestral. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://mistral.ai/news/codestral/" title="">Codestral</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Douze et al. (2024)</span>
<span class="ltx_bibblock">
Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.08281" title="">The faiss library</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Preprint</em>, arXiv:2401.08281.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2211.10435" title="">Pal: Program-aided language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Preprint</em>, arXiv:2211.10435.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GPT- (4)</span>
<span class="ltx_bibblock">
GPT-4. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://cdn.openai.com/papers/gpt-4.pdf" title="">Gpt-4 technical report</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. (2021)</span>
<span class="ltx_bibblock">
Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram Rajamani, and Rahul Sharma. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2112.02969" title="">Jigsaw: Large language models meet program synthesis</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Preprint</em>, arXiv:2112.02969.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2023)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2205.11916" title="">Large language models are zero-shot reasoners</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Preprint</em>, arXiv:2205.11916.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewkowycz et al. (2022)</span>
<span class="ltx_bibblock">
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2206.14858" title="">Solving quantitative reasoning problems with language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint</em>, arXiv:2206.14858.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von
Werra, and Harm de Vries. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.06161" title="">Starcoder: may the source be with you!</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Preprint</em>, arXiv:2305.06161.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d’Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1126/science.abq1158" title="">Competition-level code generation with alphacode</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Science</em>, 378(6624):1092–1097.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2023)</span>
<span class="ltx_bibblock">
Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, and Nan Duan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.16434" title="">Taskmatrix.ai: Completing tasks by connecting foundation models with millions of apis</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Preprint</em>, arXiv:2303.16434.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Chao Liu, Xuanlin Bao, Hongyu Zhang, Neng Zhang, Haibo Hu, Xiaohong Zhang, and Meng Yan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.08360" title="">Improving chatgpt prompt for code generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint</em>, arXiv:2305.08360.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
LlamaIndex. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://llama.meta.com/docs/integration-guides/llamaindex/" title="">Llamaindex</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen and Nadi (2022)</span>
<span class="ltx_bibblock">
Nhan Nguyen and Sarah Nadi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3524842.3528470" title="">An empirical evaluation of github copilot’s code suggestions</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)</em>, pages 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
OpenAI Code Interpretor. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/assistants/tools/code-interpreter" title="">Openai code interpretor</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parisi et al. (2022)</span>
<span class="ltx_bibblock">
Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2205.12255" title="">Talm: Tool augmented language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Preprint</em>, arXiv:2205.12255.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil et al. (2023)</span>
<span class="ltx_bibblock">
Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.15334" title="">Gorilla: Large language model connected with massive apis</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Preprint</em>, arXiv:2305.15334.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poesia et al. (2022)</span>
<span class="ltx_bibblock">
Gabriel Poesia, Oleksandr Polozov, Vu Le, Ashish Tiwari, Gustavo Soares, Christopher Meek, and Sumit Gulwani. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2201.11227" title="">Synchromesh: Reliable code generation from pre-trained language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arXiv:2201.11227.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick et al. (2023)</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2302.04761" title="">Toolformer: Language models can teach themselves to use tools</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Preprint</em>, arXiv:2302.04761.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2201.11903" title="">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Preprint</em>, arXiv:2201.11903.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">White et al. (2023)</span>
<span class="ltx_bibblock">
Jules White, Sam Hays, Quchen Fu, Jesse Spencer-Smith, and Douglas C. Schmidt. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.07839" title="">Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Preprint</em>, arXiv:2303.07839.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2021)</span>
<span class="ltx_bibblock">
Frank F. Xu, Bogdan Vasilescu, and Graham Neubig. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2101.11149" title="">In-ide code generation from natural language: Promise and challenges</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2101.11149.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Example Appendix</h2>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1 </span>Sample with computed Average similarity</h3>
<div class="ltx_para" id="S8.SS1.p1">
<p class="ltx_p" id="S8.SS1.p1.1">Sample showing how flow similarity is computed for two flows Flow A and Flow B.</p>
</div>
<div class="ltx_para" id="S8.SS1.p2">
<pre class="ltx_verbatim ltx_font_typewriter" id="S8.SS1.p2.1">

Query = "Post a message in the channel of teams,
when a new form is created in the forms"

Ground Truth = "triggerOutputs=
await shared_microsoftforms.
CreateFormWebhook({});
outputs_shared_teams_PostMessageToConversation
=shared_teams.PostMessageToConversation(
{ \"poster\": \"User\"});"

prediction:"triggerOutputs=
awaitshared_microsoftforms.
CreateFormWebhook({});
outputs_Get_my_profile_V2 =
shared_office365users.MyProfile_V2({});
outputs_shared_teams_PostMessage
= shared_teams.PostMessageToConversation(
{\"poster\": \"User\",\"location\":
\"Channel\"});"

API Functions list in ground_truth =
[shared_microsoftforms.CreateFormWebhook,
shared_teams.PostMessageToConversation]


API function list in model generation=
[shared_microsoftforms.CreateFormWebhook,
shared_office365users.MyProfile_V2,
shared_teams.PostMessageToConversation]

Similarity Score = 2/3 = 0.666

Since the functions shared_microsoftforms.
CreateFormWebhook and shared_teams.
PostMessageToConversation are found
in the ground truth.
</pre>
</div>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2 </span>An example of API metdata</h3>
<div class="ltx_para" id="S8.SS2.p1">
<p class="ltx_p" id="S8.SS2.p1.1">We share a sample of API metadata to highlight the details included in the API description provided to the metaprompt.</p>
</div>
<div class="ltx_para" id="S8.SS2.p2">
<pre class="ltx_verbatim ltx_font_typewriter" id="S8.SS2.p2.1">

"shared_outlook.SendEmailV2": {
    "FunctionName": "shared_outlook.
                    SendEmailV2",
    "Description": "This operation sends
                     an email message.",
    "IsInTrainingSet": false,
    "DisplayName": "Send an email (V2)",
        "ParametersInfo": [
            {
                "Key": "emailMessage/To",
                "Type": "String",
                "Summary": "To",
                "Format": "email",
                "Description": "Specify
                    email addresses
                    separated by semicolons
                    like someone@contoso.com"
            }, .
                        ],
        "ResponseSchema": [],
        "IsTrigger": false
    }

</pre>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Aug 15 04:21:00 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
