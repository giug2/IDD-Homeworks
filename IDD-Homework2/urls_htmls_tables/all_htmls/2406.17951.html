<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.17951] Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks</title><meta property="og:description" content="Federated learning offers a compelling solution to the challenges of networking and data privacy within aerial and space networks by utilizing vast private edge data and computing capabilities accessible through drones…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.17951">

<!--Generated on Fri Jul  5 19:29:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
federated learning,  heterogeneity,  class imbalance,  battery
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Fan Dong1, Henry Leung1, Steve Drew1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
1Department of Electrical and Software Engineering, University of Calgary, Calgary, AB, Canada 
<br class="ltx_break">{fan.dong, leungh, steve.drew}@ucalgary.ca
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning offers a compelling solution to the challenges of networking and data privacy within aerial and space networks by utilizing vast private edge data and computing capabilities accessible through drones, balloons, and satellites. While current research has focused on optimizing the learning process, computing efficiency, and minimizing communication overhead, the issue of heterogeneity and class imbalance remains a significant barrier to rapid model convergence.
In our study, we explore the influence of heterogeneity on class imbalance, which diminishes performance in ASN-based federated learning. We illustrate the correlation between heterogeneity and class imbalance within grouped data and show how constraints such as battery life exacerbate the class imbalance challenge. Our findings indicate that ASN-based FL faces heightened class imbalance issues even with similar levels of heterogeneity compared to other scenarios.
Finally, we analyze the impact of varying degrees of heterogeneity on FL training and evaluate the efficacy of current state-of-the-art algorithms under these conditions. Our results reveal that the heterogeneity challenge is more pronounced in ASN-based federated learning and that prevailing algorithms often fail to effectively address high levels of heterogeneity.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
federated learning, heterogeneity, class imbalance, battery

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Aerial and Space Networks (ASNs) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> represent a novel type of network that integrates aerial and space assets, including drones, balloons, and satellites. These assets are interconnected, enabling the collection and relay of diverse sensing data across various-speed and universal data networks. Additionally, the computational capabilities of these assets in ASNs can facilitate edge computing, allowing for complex machine-learning tasks to be performed locally <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
However, the heterogeneous nature of these devices, limited bandwidth, and differing ownerships present significant challenges for data processing and the centralized training of predictive models in ASNs. The primary challenges include limited bandwidth, privacy concerns, and single-point failure.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Federated learning (FL) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> has emerged as a promising solution, where distributed clients train their models locally and only send the model parameters to a central server. However, data heterogeneity remains a significant challenge in this context. Data distributed across IoT devices and edge servers or nodes leads to each participant owning a unique local dataset. These datasets can vary significantly in size, feature space, and label distribution, resulting in discrepancies in local model performance, and consequently, in the aggregated global model’s performance.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Moreover, data heterogeneity can slow down the convergence of FL. Variations in local data distributions can cause local models to diverge significantly, complicating the aggregation into a robust global model. Addressing data heterogeneity often requires more communication rounds between the central server and the nodes to achieve acceptable model performance, which incurs higher bandwidth usage, particularly costly in resource-constrained edge IoT environments with limited connectivity. Effectively managing data heterogeneity also necessitates more sophisticated methods to aggregate local models or to carefully train and adapt local models to diverse data distributions.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.17951/assets/pics/drones.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="243" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Different devices would possess various data concerning their active locations.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Without exception, ASN-based edge devices are designed to complete diverse tasks with various intensities, resulting in high data heterogeneity. For instance, in the low-altitude economy era, drones capture images of different types of buildings in the city. As shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, drones will confront various surroundings like office buildings, residential buildings, houses, and factories. And corresponding flight strategies will also be developed to cope with these varying conditions. Due to the variety of the aviation environment, different drones will collect heterogeneous data accordingly.
These issues, combined with the existing uneven distribution of data, may further increase the severity of data heterogeneity due to</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Statistical Heterogeneity</h4>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">Statistical heterogeneity occurs when the data distributions across different devices or nodes vary significantly. In FL settings, each ASN node may collect data under different conditions, leading to non-independently and identically distributed (non-IID) data. This heterogeneity can lead to biased models that perform well on some nodes but poorly on others, as the global model might not generalize well across diverse datasets.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">System Heterogeneity</h4>

<div id="S1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px2.p1.1" class="ltx_p">This refers to differences in hardware, network connectivity, and computational power among devices participating in federated learning. Some devices may be able to compute updates faster and more frequently than others. This discrepancy can lead to slower convergence of the global model, as updates from less capable devices might be received less frequently or could be outdated.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Communication Heterogeneity</h4>

<div id="S1.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px3.p1.1" class="ltx_p">Variations in network speed and bandwidth across devices can affect the efficiency of data transmission in federated learning. Devices with slower network connections may take longer to upload their updates, leading to delays in model aggregation and potentially outdated model updates being incorporated into the global model.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Label Distribution Skew</h4>

<div id="S1.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px4.p1.1" class="ltx_p">In some cases, the distribution of labels (outcomes of interest) can differ significantly across devices. For example, in a healthcare application, data collected from different hospitals might show different disease prevalence rates. This skew can lead to a model biased towards the data characteristics of more frequently represented labels or devices.</p>
</div>
<div id="S1.SS0.SSS0.Px4.p2" class="ltx_para">
<p id="S1.SS0.SSS0.Px4.p2.1" class="ltx_p">In this paper, we illustrated how heterogeneity impacts the class imbalance issue, hence leading to a degraded performance in ASNs-based FL. Specifically, we visualize the relationship between heterogeneity and class imbalance of grouped data. We demonstrate how the battery life constraint exacerbates the class imbalance issue from two angles: (a) by limiting the number of devices available for FL training, and (b) by restricting the selection of devices to a smaller pool, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ Label Distribution Skew ‣ I Introduction ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We conclude that ASNs-based FL is experiencing more severe class imbalance issues even under the same degree of heterogeneity. Finally, we study how different degrees of heterogeneity affect the FL training and the performance of current state-of-the-art algorithms on different degrees of heterogeneity.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2406.17951/assets/pics/battery_queue.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="318" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Only select devices with enough battery percentage.</figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> presents a promising avenue for training models that require substantial data volumes, all without the necessity of centralizing client data. Instead of transmitting raw data, FL employs a process where model parameters are communicated with edge devices during training. This method circumvents the significant communication overhead while upholding user privacy. While FL facilitates privacy-preserving distributed machine learning across myriad devices, it contends with persistent challenges, such as heterogeneity, within current methodologies. Heterogeneity manifests in various forms throughout FL training, adding complexity to the process. Additionally, the issue of class imbalance presents another formidable hurdle for FL, particularly when compounded with heterogeneity.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">There are different types of heterogeneity issues, including statistical heterogeneity, system heterogeneity, communication heterogeneity, etc <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Statistical heterogeneity is mostly caused by the fact that the distributions vary among different clients, including label distribution and feature distribution, which causes the local models to converge towards different directions and the global model to converge slowly.
System heterogeneity mainly refers to the differences in hardware, network connectivity, and computational power among devices participating in federated learning.
Communication heterogeneity is variations in network speed and bandwidth across devices can affect the efficiency of model transmission in federated learning, because of which, straggles may occur. There is already some research like <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> focusing on tackling the straggler issue in FL to improve the overall performance.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2406.17951/assets/x1.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Grouped dataset (10 devices selected out of 100 devices) imbalance degree (<math id="S2.F3.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.F3.3.m1.1b"><mi id="S2.F3.3.m1.1.1" xref="S2.F3.3.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.F3.3.m1.1c"><ci id="S2.F3.3.m1.1.1.cmml" xref="S2.F3.3.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.3.m1.1d">\alpha</annotation></semantics></math>) with various heterogeneity degrees under Dirichlet distribution. The smaller <math id="S2.F3.4.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.F3.4.m2.1b"><mi id="S2.F3.4.m2.1.1" xref="S2.F3.4.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.F3.4.m2.1c"><ci id="S2.F3.4.m2.1.1.cmml" xref="S2.F3.4.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.4.m2.1d">\alpha</annotation></semantics></math> is, the more heterogeneous the distribution among devices will be.</figcaption>
</figure>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">We focus more on the statistical heterogeneity in this paper.
The impact of statistical heterogeneity was theoretically analyzed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Plenty of research has been trying to mitigate the heterogeneity impact.
FedProx <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> introduced an additional proximal term to the local objection to refraining from overfitting local training. Despite that tuning the hyperparameter <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S2.p3.1.m1.1a"><mi id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><ci id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">\mu</annotation></semantics></math> in FedProx could be a challenge, the introduced proximal term may also slow the convergence speed. FedProx is also capable of tackling the stragglers caused by communication heterogeneity.
Scaffold <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> maintained control variates to rectify the local training to mitigate the heterogeneity effect. However, as shown in our experiments in Section V, Scaffold fails to outperform FedAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> when the heterogeneity degree is too high.
FedMix <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> relaxes the limitation of accessing others’ raw data and performs data augmentation with the assistance of other clients’ data. By this strategy, FedMix could accommodate FL with different levels of privacy depending on applications and achieve better performance.
MOON <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> used the similarity between model representations to correct for local training. On the contrary, relying on previous local models reduced its effectiveness when selecting a small portion of clients from a vast pool.
WeiAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> adopted weighted averaging to highlight updates from high-diversity clients under the diversity heterogeneity distribution. However, this will not work when the heterogeneity does not lie in diversity.
Despite these efforts, there is still significant room for improvement in addressing heterogeneity. While adding additional regularization terms <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> to local objective functions requires longer computation time. Algorithms like Scaffold <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> could not even outperform FedAvg under highly heterogeneous distribution.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Class imbalance has long been an issue in the field of machine learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Resampling, re-weighting, and cost modification methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> have been proposed to mitigate its detriment. However, these techniques could not be applied to FL directly. Recently, <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> pointed out that the class imbalance is the cause of performance degradation under non-IID settings.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Heterogeneity and Imbalance</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Heterogeneity, specifically statistical heterogeneity, is caused by the distribution discrepancy among participating devices. This discrepancy leads to the grouped dataset’s imbalance. It was noted in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> that the imbalance of the grouped dataset in FL leads to the degradation of model performance.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.3" class="ltx_p">For a classification problem, suppose there are <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">B</annotation></semantics></math> classes. For each global round, we select a set of devices to participate in the FL training. We can group the dataset across these selected devices together to obtain the grouped dataset in each global round. The distribution of the grouped dataset will be like <math id="S3.p2.2.m2.4" class="ltx_Math" alttext="p=[p_{1},p_{2},\cdots,p_{B}]" display="inline"><semantics id="S3.p2.2.m2.4a"><mrow id="S3.p2.2.m2.4.4" xref="S3.p2.2.m2.4.4.cmml"><mi id="S3.p2.2.m2.4.4.5" xref="S3.p2.2.m2.4.4.5.cmml">p</mi><mo id="S3.p2.2.m2.4.4.4" xref="S3.p2.2.m2.4.4.4.cmml">=</mo><mrow id="S3.p2.2.m2.4.4.3.3" xref="S3.p2.2.m2.4.4.3.4.cmml"><mo stretchy="false" id="S3.p2.2.m2.4.4.3.3.4" xref="S3.p2.2.m2.4.4.3.4.cmml">[</mo><msub id="S3.p2.2.m2.2.2.1.1.1" xref="S3.p2.2.m2.2.2.1.1.1.cmml"><mi id="S3.p2.2.m2.2.2.1.1.1.2" xref="S3.p2.2.m2.2.2.1.1.1.2.cmml">p</mi><mn id="S3.p2.2.m2.2.2.1.1.1.3" xref="S3.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p2.2.m2.4.4.3.3.5" xref="S3.p2.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.p2.2.m2.3.3.2.2.2" xref="S3.p2.2.m2.3.3.2.2.2.cmml"><mi id="S3.p2.2.m2.3.3.2.2.2.2" xref="S3.p2.2.m2.3.3.2.2.2.2.cmml">p</mi><mn id="S3.p2.2.m2.3.3.2.2.2.3" xref="S3.p2.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.p2.2.m2.4.4.3.3.6" xref="S3.p2.2.m2.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">⋯</mi><mo id="S3.p2.2.m2.4.4.3.3.7" xref="S3.p2.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.p2.2.m2.4.4.3.3.3" xref="S3.p2.2.m2.4.4.3.3.3.cmml"><mi id="S3.p2.2.m2.4.4.3.3.3.2" xref="S3.p2.2.m2.4.4.3.3.3.2.cmml">p</mi><mi id="S3.p2.2.m2.4.4.3.3.3.3" xref="S3.p2.2.m2.4.4.3.3.3.3.cmml">B</mi></msub><mo stretchy="false" id="S3.p2.2.m2.4.4.3.3.8" xref="S3.p2.2.m2.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.4b"><apply id="S3.p2.2.m2.4.4.cmml" xref="S3.p2.2.m2.4.4"><eq id="S3.p2.2.m2.4.4.4.cmml" xref="S3.p2.2.m2.4.4.4"></eq><ci id="S3.p2.2.m2.4.4.5.cmml" xref="S3.p2.2.m2.4.4.5">𝑝</ci><list id="S3.p2.2.m2.4.4.3.4.cmml" xref="S3.p2.2.m2.4.4.3.3"><apply id="S3.p2.2.m2.2.2.1.1.1.cmml" xref="S3.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.p2.2.m2.2.2.1.1.1.2.cmml" xref="S3.p2.2.m2.2.2.1.1.1.2">𝑝</ci><cn type="integer" id="S3.p2.2.m2.2.2.1.1.1.3.cmml" xref="S3.p2.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S3.p2.2.m2.3.3.2.2.2.cmml" xref="S3.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.p2.2.m2.3.3.2.2.2.2">𝑝</ci><cn type="integer" id="S3.p2.2.m2.3.3.2.2.2.3.cmml" xref="S3.p2.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">⋯</ci><apply id="S3.p2.2.m2.4.4.3.3.3.cmml" xref="S3.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.p2.2.m2.4.4.3.3.3.1.cmml" xref="S3.p2.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S3.p2.2.m2.4.4.3.3.3.2.cmml" xref="S3.p2.2.m2.4.4.3.3.3.2">𝑝</ci><ci id="S3.p2.2.m2.4.4.3.3.3.3.cmml" xref="S3.p2.2.m2.4.4.3.3.3.3">𝐵</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.4c">p=[p_{1},p_{2},\cdots,p_{B}]</annotation></semantics></math>. The imbalance degree of the grouped dataset could be represented as <math id="S3.p2.3.m3.2" class="ltx_Math" alttext="\Delta=max(p)-min(p)" display="inline"><semantics id="S3.p2.3.m3.2a"><mrow id="S3.p2.3.m3.2.3" xref="S3.p2.3.m3.2.3.cmml"><mi mathvariant="normal" id="S3.p2.3.m3.2.3.2" xref="S3.p2.3.m3.2.3.2.cmml">Δ</mi><mo id="S3.p2.3.m3.2.3.1" xref="S3.p2.3.m3.2.3.1.cmml">=</mo><mrow id="S3.p2.3.m3.2.3.3" xref="S3.p2.3.m3.2.3.3.cmml"><mrow id="S3.p2.3.m3.2.3.3.2" xref="S3.p2.3.m3.2.3.3.2.cmml"><mi id="S3.p2.3.m3.2.3.3.2.2" xref="S3.p2.3.m3.2.3.3.2.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.3.2.1" xref="S3.p2.3.m3.2.3.3.2.1.cmml">​</mo><mi id="S3.p2.3.m3.2.3.3.2.3" xref="S3.p2.3.m3.2.3.3.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.3.2.1a" xref="S3.p2.3.m3.2.3.3.2.1.cmml">​</mo><mi id="S3.p2.3.m3.2.3.3.2.4" xref="S3.p2.3.m3.2.3.3.2.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.3.2.1b" xref="S3.p2.3.m3.2.3.3.2.1.cmml">​</mo><mrow id="S3.p2.3.m3.2.3.3.2.5.2" xref="S3.p2.3.m3.2.3.3.2.cmml"><mo stretchy="false" id="S3.p2.3.m3.2.3.3.2.5.2.1" xref="S3.p2.3.m3.2.3.3.2.cmml">(</mo><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">p</mi><mo stretchy="false" id="S3.p2.3.m3.2.3.3.2.5.2.2" xref="S3.p2.3.m3.2.3.3.2.cmml">)</mo></mrow></mrow><mo id="S3.p2.3.m3.2.3.3.1" xref="S3.p2.3.m3.2.3.3.1.cmml">−</mo><mrow id="S3.p2.3.m3.2.3.3.3" xref="S3.p2.3.m3.2.3.3.3.cmml"><mi id="S3.p2.3.m3.2.3.3.3.2" xref="S3.p2.3.m3.2.3.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.3.3.1" xref="S3.p2.3.m3.2.3.3.3.1.cmml">​</mo><mi id="S3.p2.3.m3.2.3.3.3.3" xref="S3.p2.3.m3.2.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.3.3.1a" xref="S3.p2.3.m3.2.3.3.3.1.cmml">​</mo><mi id="S3.p2.3.m3.2.3.3.3.4" xref="S3.p2.3.m3.2.3.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.3.3.1b" xref="S3.p2.3.m3.2.3.3.3.1.cmml">​</mo><mrow id="S3.p2.3.m3.2.3.3.3.5.2" xref="S3.p2.3.m3.2.3.3.3.cmml"><mo stretchy="false" id="S3.p2.3.m3.2.3.3.3.5.2.1" xref="S3.p2.3.m3.2.3.3.3.cmml">(</mo><mi id="S3.p2.3.m3.2.2" xref="S3.p2.3.m3.2.2.cmml">p</mi><mo stretchy="false" id="S3.p2.3.m3.2.3.3.3.5.2.2" xref="S3.p2.3.m3.2.3.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.2b"><apply id="S3.p2.3.m3.2.3.cmml" xref="S3.p2.3.m3.2.3"><eq id="S3.p2.3.m3.2.3.1.cmml" xref="S3.p2.3.m3.2.3.1"></eq><ci id="S3.p2.3.m3.2.3.2.cmml" xref="S3.p2.3.m3.2.3.2">Δ</ci><apply id="S3.p2.3.m3.2.3.3.cmml" xref="S3.p2.3.m3.2.3.3"><minus id="S3.p2.3.m3.2.3.3.1.cmml" xref="S3.p2.3.m3.2.3.3.1"></minus><apply id="S3.p2.3.m3.2.3.3.2.cmml" xref="S3.p2.3.m3.2.3.3.2"><times id="S3.p2.3.m3.2.3.3.2.1.cmml" xref="S3.p2.3.m3.2.3.3.2.1"></times><ci id="S3.p2.3.m3.2.3.3.2.2.cmml" xref="S3.p2.3.m3.2.3.3.2.2">𝑚</ci><ci id="S3.p2.3.m3.2.3.3.2.3.cmml" xref="S3.p2.3.m3.2.3.3.2.3">𝑎</ci><ci id="S3.p2.3.m3.2.3.3.2.4.cmml" xref="S3.p2.3.m3.2.3.3.2.4">𝑥</ci><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">𝑝</ci></apply><apply id="S3.p2.3.m3.2.3.3.3.cmml" xref="S3.p2.3.m3.2.3.3.3"><times id="S3.p2.3.m3.2.3.3.3.1.cmml" xref="S3.p2.3.m3.2.3.3.3.1"></times><ci id="S3.p2.3.m3.2.3.3.3.2.cmml" xref="S3.p2.3.m3.2.3.3.3.2">𝑚</ci><ci id="S3.p2.3.m3.2.3.3.3.3.cmml" xref="S3.p2.3.m3.2.3.3.3.3">𝑖</ci><ci id="S3.p2.3.m3.2.3.3.3.4.cmml" xref="S3.p2.3.m3.2.3.3.3.4">𝑛</ci><ci id="S3.p2.3.m3.2.2.cmml" xref="S3.p2.3.m3.2.2">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.2c">\Delta=max(p)-min(p)</annotation></semantics></math>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.2" class="ltx_p">We simulate the how different heterogeneity degree impact the imbalance degree of the grouped dataset. We select 10 devices out of 100 clients then group the dataset together and repeat this process 100 times to get a robust average result. As shown in Fig. <a href="#S2.F3" title="Figure 3 ‣ II Related Work ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the more heterogeneous the distribution is, the more imbalance of the grouped dataset will be. The imbalance degree <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S3.p3.1.m1.1a"><mi mathvariant="normal" id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\Delta</annotation></semantics></math> of grouped dataset is 0.0897, 0.2117, and 0.2589 for <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="alpha" display="inline"><semantics id="S3.p3.2.m2.1a"><mrow id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml"><mi id="S3.p3.2.m2.1.1.2" xref="S3.p3.2.m2.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.p3.2.m2.1.1.1" xref="S3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.p3.2.m2.1.1.3" xref="S3.p3.2.m2.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.p3.2.m2.1.1.1a" xref="S3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.p3.2.m2.1.1.4" xref="S3.p3.2.m2.1.1.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.p3.2.m2.1.1.1b" xref="S3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.p3.2.m2.1.1.5" xref="S3.p3.2.m2.1.1.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.p3.2.m2.1.1.1c" xref="S3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.p3.2.m2.1.1.6" xref="S3.p3.2.m2.1.1.6.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><apply id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1"><times id="S3.p3.2.m2.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1"></times><ci id="S3.p3.2.m2.1.1.2.cmml" xref="S3.p3.2.m2.1.1.2">𝑎</ci><ci id="S3.p3.2.m2.1.1.3.cmml" xref="S3.p3.2.m2.1.1.3">𝑙</ci><ci id="S3.p3.2.m2.1.1.4.cmml" xref="S3.p3.2.m2.1.1.4">𝑝</ci><ci id="S3.p3.2.m2.1.1.5.cmml" xref="S3.p3.2.m2.1.1.5">ℎ</ci><ci id="S3.p3.2.m2.1.1.6.cmml" xref="S3.p3.2.m2.1.1.6">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">alpha</annotation></semantics></math> being 1, 0.1, and 0.01 respectively.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">However, heterogeneity is not the only issue that could cause the imbalance among grouped dataset. In the next section, we will explain how device selection could also be a perpetrator.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2406.17951/assets/x2.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="249" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Grouped dataset imbalance degree with various number of clients select.</figcaption>
</figure>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2406.17951/assets/x3.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="249" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Imbalance degree under different pool size.</figcaption>
</figure>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2406.17951/assets/x4.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Imbalance degree under different window sizes with different pool size.</figcaption>
</figure>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2406.17951/assets/x5.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Imbalance degree under different step sizes with different window sizes.</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">How Battery Life Constraint Aggravates the Imbalance Issue</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Compared with other IoT scenarios, FL training with aerial and space devices are often constrained by the battery life. In the near future, there is not likely to be a big step in terms of the energy density of lithium batteries <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. For example, the maximum flight time for a typical DJI drone is around 30 minutes.
And the first priority of these devices should be finishing specific tasks or returning back.
This constraint will limit the choices when we select devices to participate in the FL training. The impact is twofold. On one hand, we may only be able to select fewer devices compared to other FL scenarios. On the other hand, we can only choose devices from a subset of all available devices, as those with low battery levels need to prioritize basic operations such as returning.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Selecting fewer devices</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In the experiments, we simulate that we select different number of devices to see how it would affect the imbalance pattern. Each time we select a certain amount of devices, we group their local data together to see how imbalanced the grouped dataset is. We use the same distribution for different settings. We repeat 10,000 times and average the test results for a robust conclusion.
According to Fig. <a href="#S3.F4" title="Figure 4 ‣ III Heterogeneity and Imbalance ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, there is a clear trend showing that when fewer devices are selected in each round, the imbalance issue will aggravate.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Selecting devices from a smaller pool</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Since the priority of aerial and space devices should be maintaining their normal operations, so once the battery percentage of some devices is below some threshold, we should not select them for FL training before they are recharged.
In our training process, we can maintain a queue according to each device’s battery percentage. We only select those top devices with the highest battery percentage. Those low-battery devices will also be recharged after a while and will enter the queue, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ Label Distribution Skew ‣ I Introduction ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Under this setting, our choice would be limited to a smaller amount of devices when selecting devices to participate in the local training. However, after the low-battery devices are recharged, the choice pool will also be updated.
To see more details of the imbalance issue, we merge the grouped dataset across several global rounds together to see the imbalance degree. Because we hope even if the ratio of a certain type of label is small in this global round, this situation will not last.
As shown in Fig. <a href="#S3.F5" title="Figure 5 ‣ III Heterogeneity and Imbalance ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, when we can only select devices from a smaller device pool, the imbalance issue will aggravate, no matter what window size we choose.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2406.17951/assets/x6.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Average distribution on each client with different settings.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We further test the impact of the different choice of window sizes on imbalance degree <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi mathvariant="normal" id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\Delta</annotation></semantics></math>.
We choose the pool size to be 30, 50, and 70. As shown in Fig. <a href="#S3.F6" title="Figure 6 ‣ III Heterogeneity and Imbalance ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, a smaller device pool consistently aggravates the imbalance issue under different observation window sizes.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Charging speed or updating speed of the pool will also impact the imbalance degree. In above analysis, we adopted the same updating speed, which is in each global round, which will be one device entering the available pool. We test different updating speeds with each round updating 0.2, 0.5, 1, 2, and 5 devices respectively. As shown in Fig. <a href="#S3.F7" title="Figure 7 ‣ III Heterogeneity and Imbalance ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, a smaller pool size consistently increases the imbalance degree of the grouped dataset across different observation window sizes.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">With the analysis above, we can conclude that the battery constraint of aerial and space devices aggravates the imbalance issue. This exacerbates the existing heterogeneity problem even further. While previous research also studies the heterogeneity issue <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, the distributions they use are often not heterogeneous enough. In the next section, we study the impact of different heterogeneity degrees on FL training.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Experiments of CIFAR10 dataset under Dirichlet distribution with different <math id="S4.T1.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T1.2.m1.1b"><mi id="S4.T1.2.m1.1.1" xref="S4.T1.2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.T1.2.m1.1c"><ci id="S4.T1.2.m1.1.1.cmml" xref="S4.T1.2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.m1.1d">\alpha</annotation></semantics></math>.</figcaption>
<table id="S4.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.5.3" class="ltx_tr">
<th id="S4.T1.5.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T1.5.3.4.1" class="ltx_text">Algorithms</span></th>
<th id="S4.T1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Dirichlet(<math id="S4.T1.3.1.1.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S4.T1.3.1.1.m1.1a"><mrow id="S4.T1.3.1.1.m1.1.1" xref="S4.T1.3.1.1.m1.1.1.cmml"><mi id="S4.T1.3.1.1.m1.1.1.2" xref="S4.T1.3.1.1.m1.1.1.2.cmml">α</mi><mo id="S4.T1.3.1.1.m1.1.1.1" xref="S4.T1.3.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.3.1.1.m1.1.1.3" xref="S4.T1.3.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.1.m1.1b"><apply id="S4.T1.3.1.1.m1.1.1.cmml" xref="S4.T1.3.1.1.m1.1.1"><eq id="S4.T1.3.1.1.m1.1.1.1.cmml" xref="S4.T1.3.1.1.m1.1.1.1"></eq><ci id="S4.T1.3.1.1.m1.1.1.2.cmml" xref="S4.T1.3.1.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S4.T1.3.1.1.m1.1.1.3.cmml" xref="S4.T1.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.1.m1.1c">\alpha=1</annotation></semantics></math>)</th>
<th id="S4.T1.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Dirichlet(<math id="S4.T1.4.2.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.T1.4.2.2.m1.1a"><mrow id="S4.T1.4.2.2.m1.1.1" xref="S4.T1.4.2.2.m1.1.1.cmml"><mi id="S4.T1.4.2.2.m1.1.1.2" xref="S4.T1.4.2.2.m1.1.1.2.cmml">α</mi><mo id="S4.T1.4.2.2.m1.1.1.1" xref="S4.T1.4.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T1.4.2.2.m1.1.1.3" xref="S4.T1.4.2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.2.m1.1b"><apply id="S4.T1.4.2.2.m1.1.1.cmml" xref="S4.T1.4.2.2.m1.1.1"><eq id="S4.T1.4.2.2.m1.1.1.1.cmml" xref="S4.T1.4.2.2.m1.1.1.1"></eq><ci id="S4.T1.4.2.2.m1.1.1.2.cmml" xref="S4.T1.4.2.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.T1.4.2.2.m1.1.1.3.cmml" xref="S4.T1.4.2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.2.m1.1c">\alpha=0.1</annotation></semantics></math>)</th>
<th id="S4.T1.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Dirichlet(<math id="S4.T1.5.3.3.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S4.T1.5.3.3.m1.1a"><mrow id="S4.T1.5.3.3.m1.1.1" xref="S4.T1.5.3.3.m1.1.1.cmml"><mi id="S4.T1.5.3.3.m1.1.1.2" xref="S4.T1.5.3.3.m1.1.1.2.cmml">α</mi><mo id="S4.T1.5.3.3.m1.1.1.1" xref="S4.T1.5.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T1.5.3.3.m1.1.1.3" xref="S4.T1.5.3.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.3.3.m1.1b"><apply id="S4.T1.5.3.3.m1.1.1.cmml" xref="S4.T1.5.3.3.m1.1.1"><eq id="S4.T1.5.3.3.m1.1.1.1.cmml" xref="S4.T1.5.3.3.m1.1.1.1"></eq><ci id="S4.T1.5.3.3.m1.1.1.2.cmml" xref="S4.T1.5.3.3.m1.1.1.2">𝛼</ci><cn type="float" id="S4.T1.5.3.3.m1.1.1.3.cmml" xref="S4.T1.5.3.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.3.3.m1.1c">\alpha=0.01</annotation></semantics></math>)</th>
</tr>
<tr id="S4.T1.5.4.1" class="ltx_tr">
<th id="S4.T1.5.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">TestAcc(std)</th>
<th id="S4.T1.5.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Rounds</th>
<th id="S4.T1.5.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">TestAcc(std)</th>
<th id="S4.T1.5.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Rounds</th>
<th id="S4.T1.5.4.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">TestAcc(std)</th>
<th id="S4.T1.5.4.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Rounds</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.5.5.1" class="ltx_tr">
<td id="S4.T1.5.5.1.1" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S4.T1.5.5.1.2" class="ltx_td ltx_align_center ltx_border_t">0.6315(0.0051)</td>
<td id="S4.T1.5.5.1.3" class="ltx_td ltx_align_center ltx_border_t">380</td>
<td id="S4.T1.5.5.1.4" class="ltx_td ltx_align_center ltx_border_t">0.5936(0.0248)</td>
<td id="S4.T1.5.5.1.5" class="ltx_td ltx_align_center ltx_border_t">418</td>
<td id="S4.T1.5.5.1.6" class="ltx_td ltx_align_center ltx_border_t">0.3966(0.0578)</td>
<td id="S4.T1.5.5.1.7" class="ltx_td ltx_align_center ltx_border_t">490</td>
</tr>
<tr id="S4.T1.5.6.2" class="ltx_tr">
<td id="S4.T1.5.6.2.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S4.T1.5.6.2.2" class="ltx_td ltx_align_center">0.6310(0.0051)</td>
<td id="S4.T1.5.6.2.3" class="ltx_td ltx_align_center">450</td>
<td id="S4.T1.5.6.2.4" class="ltx_td ltx_align_center">0.5943(0.0218)</td>
<td id="S4.T1.5.6.2.5" class="ltx_td ltx_align_center">418</td>
<td id="S4.T1.5.6.2.6" class="ltx_td ltx_align_center">0.4193(0.0536)</td>
<td id="S4.T1.5.6.2.7" class="ltx_td ltx_align_center">417</td>
</tr>
<tr id="S4.T1.5.7.3" class="ltx_tr">
<td id="S4.T1.5.7.3.1" class="ltx_td ltx_align_center">MOON</td>
<td id="S4.T1.5.7.3.2" class="ltx_td ltx_align_center">0.6288(0.0073)</td>
<td id="S4.T1.5.7.3.3" class="ltx_td ltx_align_center">383</td>
<td id="S4.T1.5.7.3.4" class="ltx_td ltx_align_center">0.5896(0.0232)</td>
<td id="S4.T1.5.7.3.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.5.7.3.6" class="ltx_td ltx_align_center">0.3847(0.0710)</td>
<td id="S4.T1.5.7.3.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.5.8.4" class="ltx_tr">
<td id="S4.T1.5.8.4.1" class="ltx_td ltx_align_center ltx_border_bb">Scaffold</td>
<td id="S4.T1.5.8.4.2" class="ltx_td ltx_align_center ltx_border_bb">0.6977(0.0048)</td>
<td id="S4.T1.5.8.4.3" class="ltx_td ltx_align_center ltx_border_bb">59</td>
<td id="S4.T1.5.8.4.4" class="ltx_td ltx_align_center ltx_border_bb">0.6462(0.0153)</td>
<td id="S4.T1.5.8.4.5" class="ltx_td ltx_align_center ltx_border_bb">153</td>
<td id="S4.T1.5.8.4.6" class="ltx_td ltx_align_center ltx_border_bb">0.2346(0.0828)</td>
<td id="S4.T1.5.8.4.7" class="ltx_td ltx_align_center ltx_border_bb">-</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">How Degree of Heterogeneity Affects FL Training</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">As observed in the paper <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, the essential reason resulting in FL performance degradation is the
class imbalance of the grouped dataset. Since different levels of heterogeneity degree <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\alpha</annotation></semantics></math> result in different levels of imbalance degree <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S5.p1.2.m2.1a"><mi mathvariant="normal" id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><ci id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\Delta</annotation></semantics></math>, hence resulting in different performance of the FL model, we can skip the intermediate steps and directly study the relationship between heterogeneity degree and FL model performance.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.3" class="ltx_p">As shown in Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-B Selecting devices from a smaller pool ‣ IV How Battery Life Constraint Aggravates the Imbalance Issue ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we visualize how <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\alpha</annotation></semantics></math> affects the level of heterogeneity. We derive the visualization by following procedures: We sort each client’s label distribution in descending order at first. Then we average the sorted label distribution among the clients to get a more stable result. So the more heterogeneous the distribution is, the more the barplot would be skewed.
When <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p2.2.m2.1a"><mi id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><ci id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">\alpha</annotation></semantics></math> equals 0.01, each client almost contains only one class of samples, as shown in Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-B Selecting devices from a smaller pool ‣ IV How Battery Life Constraint Aggravates the Imbalance Issue ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> (a). Note that the x-ticks do not denote the exact class label since we sort each client’s distribution based on frequency in descending order before averaging them. With <math id="S5.p2.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p2.3.m3.1a"><mi id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><ci id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">\alpha</annotation></semantics></math> increasing, the distribution becomes more uniform among all class labels.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">FedAvg Performance Under Different Heterogeneity Degrees</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.10" class="ltx_p">We demonstrate how different degrees of heterogeneity would affect FL training in the CIFAR10 dataset as shown in Fig. <a href="#S5.F9" title="Figure 9 ‣ V-A FedAvg Performance Under Different Heterogeneity Degrees ‣ V How Degree of Heterogeneity Affects FL Training ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We set <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mi id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\alpha</annotation></semantics></math> to <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="10^{15}" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><msup id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mn id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">10</mn><mn id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">15</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">superscript</csymbol><cn type="integer" id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">10</cn><cn type="integer" id="S5.SS1.p1.2.m2.1.1.3.cmml" xref="S5.SS1.p1.2.m2.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">10^{15}</annotation></semantics></math> to simulate the homogeneous distribution, where each class exactly accounts for <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><mrow id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml"><mn id="S5.SS1.p1.3.m3.1.1.2" xref="S5.SS1.p1.3.m3.1.1.2.cmml">10</mn><mo id="S5.SS1.p1.3.m3.1.1.1" xref="S5.SS1.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><apply id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.SS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.p1.3.m3.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">10\%</annotation></semantics></math> of the samples. All the experiments in Fig. <a href="#S5.F9" title="Figure 9 ‣ V-A FedAvg Performance Under Different Heterogeneity Degrees ‣ V How Degree of Heterogeneity Affects FL Training ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> are based on the FedAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> algorithm. The only difference is the label distribution of each client. We conduct each experiment with different random seeds, then average them together to obtain a smoother and more solid test accuracy line. From Fig. <a href="#S5.F9" title="Figure 9 ‣ V-A FedAvg Performance Under Different Heterogeneity Degrees ‣ V How Degree of Heterogeneity Affects FL Training ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we can derive that under the Dirichlet distribution with <math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><mrow id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml"><mi id="S5.SS1.p1.4.m4.1.1.2" xref="S5.SS1.p1.4.m4.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.4.m4.1.1.1" xref="S5.SS1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.4.m4.1.1.3" xref="S5.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><apply id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1"><eq id="S5.SS1.p1.4.m4.1.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1.1"></eq><ci id="S5.SS1.p1.4.m4.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.2">𝛼</ci><cn type="integer" id="S5.SS1.p1.4.m4.1.1.3.cmml" xref="S5.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">\alpha=1</annotation></semantics></math>, the test accuracy line is very close to that of a homogeneous distribution.
While other research often takes <math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><mrow id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml"><mi id="S5.SS1.p1.5.m5.1.1.2" xref="S5.SS1.p1.5.m5.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.5.m5.1.1.1" xref="S5.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.5.m5.1.1.3" xref="S5.SS1.p1.5.m5.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><apply id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1"><eq id="S5.SS1.p1.5.m5.1.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1.1"></eq><ci id="S5.SS1.p1.5.m5.1.1.2.cmml" xref="S5.SS1.p1.5.m5.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.p1.5.m5.1.1.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">\alpha=0.1</annotation></semantics></math> as the indication of heterogeneity, we show that <math id="S5.SS1.p1.6.m6.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S5.SS1.p1.6.m6.1a"><mrow id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml"><mi id="S5.SS1.p1.6.m6.1.1.2" xref="S5.SS1.p1.6.m6.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.6.m6.1.1.1" xref="S5.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.6.m6.1.1.3" xref="S5.SS1.p1.6.m6.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><apply id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1"><eq id="S5.SS1.p1.6.m6.1.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1.1"></eq><ci id="S5.SS1.p1.6.m6.1.1.2.cmml" xref="S5.SS1.p1.6.m6.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.p1.6.m6.1.1.3.cmml" xref="S5.SS1.p1.6.m6.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">\alpha=0.1</annotation></semantics></math> is far from heterogeneous enough compared with <math id="S5.SS1.p1.7.m7.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S5.SS1.p1.7.m7.1a"><mrow id="S5.SS1.p1.7.m7.1.1" xref="S5.SS1.p1.7.m7.1.1.cmml"><mi id="S5.SS1.p1.7.m7.1.1.2" xref="S5.SS1.p1.7.m7.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.7.m7.1.1.1" xref="S5.SS1.p1.7.m7.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.7.m7.1.1.3" xref="S5.SS1.p1.7.m7.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m7.1b"><apply id="S5.SS1.p1.7.m7.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1"><eq id="S5.SS1.p1.7.m7.1.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1.1"></eq><ci id="S5.SS1.p1.7.m7.1.1.2.cmml" xref="S5.SS1.p1.7.m7.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.p1.7.m7.1.1.3.cmml" xref="S5.SS1.p1.7.m7.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m7.1c">\alpha=0.01</annotation></semantics></math>.
In the following part, we may denote the Dirichlet distribution with <math id="S5.SS1.p1.8.m8.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S5.SS1.p1.8.m8.1a"><mrow id="S5.SS1.p1.8.m8.1.1" xref="S5.SS1.p1.8.m8.1.1.cmml"><mi id="S5.SS1.p1.8.m8.1.1.2" xref="S5.SS1.p1.8.m8.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.8.m8.1.1.1" xref="S5.SS1.p1.8.m8.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.8.m8.1.1.3" xref="S5.SS1.p1.8.m8.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.8.m8.1b"><apply id="S5.SS1.p1.8.m8.1.1.cmml" xref="S5.SS1.p1.8.m8.1.1"><eq id="S5.SS1.p1.8.m8.1.1.1.cmml" xref="S5.SS1.p1.8.m8.1.1.1"></eq><ci id="S5.SS1.p1.8.m8.1.1.2.cmml" xref="S5.SS1.p1.8.m8.1.1.2">𝛼</ci><cn type="integer" id="S5.SS1.p1.8.m8.1.1.3.cmml" xref="S5.SS1.p1.8.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.8.m8.1c">\alpha=1</annotation></semantics></math> as close to homogeneity, <math id="S5.SS1.p1.9.m9.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S5.SS1.p1.9.m9.1a"><mrow id="S5.SS1.p1.9.m9.1.1" xref="S5.SS1.p1.9.m9.1.1.cmml"><mi id="S5.SS1.p1.9.m9.1.1.2" xref="S5.SS1.p1.9.m9.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.9.m9.1.1.1" xref="S5.SS1.p1.9.m9.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.9.m9.1.1.3" xref="S5.SS1.p1.9.m9.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.9.m9.1b"><apply id="S5.SS1.p1.9.m9.1.1.cmml" xref="S5.SS1.p1.9.m9.1.1"><eq id="S5.SS1.p1.9.m9.1.1.1.cmml" xref="S5.SS1.p1.9.m9.1.1.1"></eq><ci id="S5.SS1.p1.9.m9.1.1.2.cmml" xref="S5.SS1.p1.9.m9.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.p1.9.m9.1.1.3.cmml" xref="S5.SS1.p1.9.m9.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.9.m9.1c">\alpha=0.1</annotation></semantics></math> as low heterogeneity, and <math id="S5.SS1.p1.10.m10.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S5.SS1.p1.10.m10.1a"><mrow id="S5.SS1.p1.10.m10.1.1" xref="S5.SS1.p1.10.m10.1.1.cmml"><mi id="S5.SS1.p1.10.m10.1.1.2" xref="S5.SS1.p1.10.m10.1.1.2.cmml">α</mi><mo id="S5.SS1.p1.10.m10.1.1.1" xref="S5.SS1.p1.10.m10.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.10.m10.1.1.3" xref="S5.SS1.p1.10.m10.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.10.m10.1b"><apply id="S5.SS1.p1.10.m10.1.1.cmml" xref="S5.SS1.p1.10.m10.1.1"><eq id="S5.SS1.p1.10.m10.1.1.1.cmml" xref="S5.SS1.p1.10.m10.1.1.1"></eq><ci id="S5.SS1.p1.10.m10.1.1.2.cmml" xref="S5.SS1.p1.10.m10.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.p1.10.m10.1.1.3.cmml" xref="S5.SS1.p1.10.m10.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.10.m10.1c">\alpha=0.01</annotation></semantics></math> as high heterogeneity.</p>
</div>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2406.17951/assets/x7.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>How the test accuracy lines look like under different levels of heterogeneity.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">State-of-the-art FL Algorithms Performance Under Different Heterogeneity Degrees</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We run several state-of-the-art algorithms under different degrees of heterogeneity. As shown in the experiment results in Table <a href="#S4.T1" title="TABLE I ‣ IV-B Selecting devices from a smaller pool ‣ IV How Battery Life Constraint Aggravates the Imbalance Issue ‣ Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, FedProx <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> could only marginally improve the performance, while MOON is even beaten by FedAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Scaffold <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> performs pretty well under homogeneous and low-heterogeneity distribution but fails to outperform FedAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> under high heterogeneity.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we identify a specific constraint of ASNs-based FL compared with other scenarios, which is the battery constraint. We then analyzed the impact of the battery constraint on FL training. We point out that the battery constraint will aggravate the heterogeneity and class imbalance issues from various perspectives, hence necessitating the FL optimization under high heterogeneity. Finally, we demonstrate that current state-of-the-art algorithms can not perform well under high heterogeneity. In future research, we will focus on FL optimization under highly heterogeneous distribution.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2018]</span>
<span class="ltx_bibblock">
J. Liu, Y. Shi, Z. M. Fadlullah, and N. Kato, “Space-air-ground integrated network: A survey,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, vol. 20, no. 4, pp. 2714–2741, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022]</span>
<span class="ltx_bibblock">
Y. Zhang, C. Chen, L. Liu, D. Lan, H. Jiang, and S. Wan, “Aerial edge computing on orbit: A task offloading and allocation scheme,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and Engineering</em>, vol. 10, no. 1, pp. 275–285, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. [2023]</span>
<span class="ltx_bibblock">
M. Ye, X. Fang, B. Du, P. C. Yuen, and D. Tao, “Heterogeneous federated learning: State-of-the-art and research challenges,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, vol. 56, no. 3, pp. 1–44, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2020]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith, “Federated optimization in heterogeneous networks,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine learning and systems</em>, vol. 2, pp. 429–450, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reisizadeh et al. [2022]</span>
<span class="ltx_bibblock">
A. Reisizadeh, I. Tziotis, H. Hassani, A. Mokhtari, and R. Pedarsani, “Straggler-resilient federated learning: Leveraging the interplay between statistical accuracy and system heterogeneity,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Information Theory</em>, vol. 3, no. 2, pp. 197–205, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2019]</span>
<span class="ltx_bibblock">
X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang, “On the convergence of fedavg on non-iid data,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.02189</em>, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al. [2020]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh, “Scaffold: Stochastic controlled averaging for federated learning,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2020, pp. 5132–5143.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon et al. [2021]</span>
<span class="ltx_bibblock">
T. Yoon, S. Shin, S. J. Hwang, and E. Yang, “Fedmix: Approximation of mixup under mean augmented federated learning,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.00233</em>, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2021]</span>
<span class="ltx_bibblock">
Q. Li, B. He, and D. Song, “Model-contrastive federated learning,” in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2021, pp. 10 713–10 722.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. [2023]</span>
<span class="ltx_bibblock">
F. Dong, A. Abbasi, S. Drew, H. Leung, X. Wang, and J. Zhou, “Weiavg: Federated learning model aggregation promoting data diversity,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.16351</em>, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Japkowicz and Stephen [2002]</span>
<span class="ltx_bibblock">
N. Japkowicz and S. Stephen, “The class imbalance problem: A systematic study,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Intelligent data analysis</em>, vol. 6, no. 5, pp. 429–449, 2002.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al. [2019]</span>
<span class="ltx_bibblock">
Y. Cui, M. Jia, T.-Y. Lin, Y. Song, and S. Belongie, “Class-balanced loss based on effective number of samples,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2019, pp. 9268–9277.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023]</span>
<span class="ltx_bibblock">
J. Zhang, A. Li, M. Tang, J. Sun, X. Chen, F. Zhang, C. Chen, Y. Chen, and H. Li, “Fed-cbs: A heterogeneity-aware client sampling mechanism for federated learning via class-imbalance reduction,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2023, pp. 41 354–41 381.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang [2021]</span>
<span class="ltx_bibblock">
H. Fang, “Challenges with the ultimate energy density with li-ion batteries,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IOP Conference Series: Earth and Environmental Science</em>, vol. 781, no. 4.   IOP Publishing, 2021, p. 042023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al. [2020]</span>
<span class="ltx_bibblock">
Y. J. Cho, J. Wang, and G. Joshi, “Client selection in federated learning: Convergence analysis and power-of-choice selection strategies,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01243</em>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. [2023]</span>
<span class="ltx_bibblock">
L. Yu, X. Sun, R. Albelaihi, and C. Yi, “Latency-aware semi-synchronous client selection and model aggregation for wireless federated learning,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Future Internet</em>, vol. 15, no. 11, p. 352, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.17950" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.17951" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.17951">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.17951" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.17952" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 19:29:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
