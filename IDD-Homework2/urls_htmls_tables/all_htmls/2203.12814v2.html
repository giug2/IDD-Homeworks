<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2203.12814] Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering</title><meta property="og:description" content="Recent advances in Transformer architectures [1] have brought remarkable improvements to visual question answering (VQA). Nevertheless, Transformer-based VQA models are usually deep and wide to guarantee good performan…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2203.12814">

<!--Generated on Mon Mar 11 06:44:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Visual question answering,  Slimmable network,  Transformer,  Multimodal learning,  Efficient deep learning.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\UseRawInputEncoding</span>
</div>
<h1 class="ltx_title ltx_title_document">Bilaterally Slimmable Transformer for 
<br class="ltx_break">Elastic and Efficient Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhou Yu, , 
Zitian Jin, 
Jun Yu, , 
Mingliang Xu, 
Hongbo Wang, 
Jianping Fan
</span><span class="ltx_author_notes">This work was supported in part by the Zhejiang Provincial Natural Science Foundation of China under Grant LR22F020001, in part by the National Natural Science Foundation of China under Grants 62125201, 62072147, 62020106007 and 61836002, and in part by the Zhejiang Provincial Natural Science Foundation of China under Grant DT23F020007. (Corresponding authors: Jun Yu and Hongbo Wang.)Z. Yu, J. Yu, and H. Wang are with School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China (e-mail: yuz@hdu.edu.cn; yujun@hdu.edu.cn; whongbo@hdu.edu.cn).Z. Jin is with HDU-ITMO Joint Institute, Hangzhou Dianzi University, 310018, China (e-mail: jinzt@hdu.edu.cn).M. Xu is with School of Computer and Artificial Intelligence Zhengzhou University, 450001, China (e-mail: iexumingliang@zzu.edu.cn).J. Fan is with AI Lab at Lenovo Research, 100094, China (e-mail: jfan1@ Lenovo.com).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.4" class="ltx_p">Recent advances in Transformer architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> have brought remarkable improvements to visual question answering (VQA). Nevertheless, Transformer-based VQA models are usually deep and wide to guarantee good performance, so they can only run on powerful GPU servers and cannot run on capacity-restricted platforms such as mobile phones. Therefore, it is desirable to learn an elastic VQA model that supports adaptive pruning at runtime to meet the efficiency constraints of different platforms. To this end, we present the bilaterally slimmable Transformer (BST), a general framework that can be seamlessly integrated into arbitrary Transformer-based VQA models to train a single model once and obtain various slimmed submodels of different widths and depths. To verify the effectiveness and generality of this method, we integrate the proposed BST framework with three typical Transformer-based VQA approaches, namely MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and conduct extensive experiments on two commonly-used benchmark datasets. In particular, one slimmed MCAN<sub id="id4.4.1" class="ltx_sub"><span id="id4.4.1.1" class="ltx_text ltx_font_sansserif">BST</span></sub> submodel achieves comparable accuracy on VQA-v2, while being 0.38<math id="id2.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id2.2.m2.1a"><mo id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><times id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\times</annotation></semantics></math> smaller in model size and having 0.27<math id="id3.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id3.3.m3.1a"><mo id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><times id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">\times</annotation></semantics></math> fewer FLOPs than the reference MCAN model. The smallest MCAN<sub id="id4.4.2" class="ltx_sub"><span id="id4.4.2.1" class="ltx_text ltx_font_sansserif">BST</span></sub> submodel only has 9M parameters and 0.16G FLOPs during inference, making it possible to deploy it on a mobile device with less than 60 ms latency.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Visual question answering, Slimmable network, Transformer, Multimodal learning, Efficient deep learning.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Thanks to recent progress on deep neural networks, machines are able to address complicated multimodal tasks that require a fine-grained understanding of both vision and language cues, such as image-text matching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, visual captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, visual grounding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, and visual question answering (VQA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Among these tasks, VQA is challenging because it requires performing visual reasoning over multimodal data to predict an accurate answer.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Current state-of-the-art VQA approaches can be roughly categorized into two lines of research based on whether they are trained from scratch (<em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and MUAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> in Fig. <a href="#S1.F1.sf1" title="In Figure 1 ‣ I Introduction ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>) or pretrained with external multimodal data (<em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, LXMERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and ALBEF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> in Fig. <a href="#S1.F1.sf2" title="In Figure 1 ‣ I Introduction ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>). Although these two lines of research use different training paradigms, they share the same model architecture, <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">i.e.</em>, Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, which was initially proposed for language modeling and has since become the foundational architecture for the VQA task.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.12814/assets/fig1a.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="682" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">From-scratch training</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.12814/assets/fig1b.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="598" height="682" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">vision-language pretraining</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.12.4.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.6.3" class="ltx_text" style="font-size:90%;">Accuracy <span id="S1.F1.6.3.1" class="ltx_text ltx_font_italic">vs</span>. number of model parameters on the VQA-v2 <span id="S1.F1.6.3.2" class="ltx_text ltx_font_typewriter">test-dev</span> split to compare with the state-of-the-art methods. The methods are split into two classes depending on whether they are (a) trained from scratch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> or (b) pretrained with external data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. By integrating the BST framework with three typical VQA models, namely MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, the resulted slimmable MCAN<math id="S1.F1.4.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S1.F1.4.1.m1.1b"><msub id="S1.F1.4.1.m1.1.1" xref="S1.F1.4.1.m1.1.1.cmml"><mi id="S1.F1.4.1.m1.1.1b" xref="S1.F1.4.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S1.F1.4.1.m1.1.1.1" xref="S1.F1.4.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.F1.4.1.m1.1c"><apply id="S1.F1.4.1.m1.1.1.cmml" xref="S1.F1.4.1.m1.1.1"><ci id="S1.F1.4.1.m1.1.1.1a.cmml" xref="S1.F1.4.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S1.F1.4.1.m1.1.1.1.cmml" xref="S1.F1.4.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.1.m1.1d">{}_{\texttt{BST}}</annotation></semantics></math>, UNITER<math id="S1.F1.5.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S1.F1.5.2.m2.1b"><msub id="S1.F1.5.2.m2.1.1" xref="S1.F1.5.2.m2.1.1.cmml"><mi id="S1.F1.5.2.m2.1.1b" xref="S1.F1.5.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S1.F1.5.2.m2.1.1.1" xref="S1.F1.5.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.F1.5.2.m2.1c"><apply id="S1.F1.5.2.m2.1.1.cmml" xref="S1.F1.5.2.m2.1.1"><ci id="S1.F1.5.2.m2.1.1.1a.cmml" xref="S1.F1.5.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S1.F1.5.2.m2.1.1.1.cmml" xref="S1.F1.5.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.5.2.m2.1d">{}_{\texttt{BST}}</annotation></semantics></math> and CLIP-ViL<math id="S1.F1.6.3.m3.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S1.F1.6.3.m3.1b"><msub id="S1.F1.6.3.m3.1.1" xref="S1.F1.6.3.m3.1.1.cmml"><mi id="S1.F1.6.3.m3.1.1b" xref="S1.F1.6.3.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S1.F1.6.3.m3.1.1.1" xref="S1.F1.6.3.m3.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.F1.6.3.m3.1c"><apply id="S1.F1.6.3.m3.1.1.cmml" xref="S1.F1.6.3.m3.1.1"><ci id="S1.F1.6.3.m3.1.1.1a.cmml" xref="S1.F1.6.3.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S1.F1.6.3.m3.1.1.1.cmml" xref="S1.F1.6.3.m3.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.3.m3.1d">{}_{\texttt{BST}}</annotation></semantics></math> models (marked with red lines) either outperform their counterparts with similar model sizes or achieve comparable performance with smaller model sizes, showing the <em id="S1.F1.6.3.3" class="ltx_emph ltx_font_italic">efficiency</em> of our framework. Each red hexagon in the line represents a submodel sharing a portion of parameters of its full model (the rightmost one), showing the <em id="S1.F1.6.3.4" class="ltx_emph ltx_font_italic">elasticity</em> of our framework.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Despite the effectiveness of the Transformer-based VQA methods described above, they typically require large models (<em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p3.1.m1.1a"><mo id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><csymbol cd="latexml" id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\sim</annotation></semantics></math>200M) to guarantee good performance. This severely limits their applicability in capacity-constrained platforms with specific efficiency constraints (<em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, FLOPs and model size).
To address this issue, a series of model compression strategies have been investigated to learn <em id="S1.p3.1.3" class="ltx_emph ltx_font_italic">efficient</em> Transformer architectures, including low-rank decomposition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, weight sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, model pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, and knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. However, these approaches focus on only one specific scenario and obtain one compact model. In practice, there are a wide variety of hardware platforms, <em id="S1.p3.1.4" class="ltx_emph ltx_font_italic">e.g.</em>, GPUs, CPUs, and mobile devices. To meet the efficiency requirements of different platforms, compression methods need to redesign the model architectures and then retrain the models, which is both engineer-expensive and computation-expensive. This motivates us to devise an <em id="S1.p3.1.5" class="ltx_emph ltx_font_italic">elastic-and-efficient</em> framework that supports training a single Transformer-based VQA model, and then adaptively pruning the model to fit different platforms <em id="S1.p3.1.6" class="ltx_emph ltx_font_italic">without retraining</em>. Compared with the aforementioned model compression approaches, the introduced framework has the following two advantages: 1) it reduces the model design costs as the submodels of different sizes can naturally meet the requirements of different platforms; 2) it also reduces the training cost as the model is trained once and adaptive slimming can be performed at inference time.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2203.12814/assets/x1.png" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.5.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.6.2" class="ltx_text" style="font-size:90%;">The schematic diagram of the proposed Bilaterally Slimmable Transformer (BST) framework. The BST framework is general enough to be seamlessly applied to arbitrary Transformer-based VQA models that supports training a <em id="S1.F2.6.2.1" class="ltx_emph ltx_font_italic">single</em> BST-based VQA model only once and then pruning it to obtain <em id="S1.F2.6.2.2" class="ltx_emph ltx_font_italic">multiple</em> efficient submodels to meet the requirements of different platforms at inference time.</span></figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.3" class="ltx_p">Inspired by the slimmable neural network that trains an elastic CNN model with multiple width multipliers to fit different efficiency constraints at runtime <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, we present a bilaterally slimmable Transformer (BST) framework to support model slimming in both the width and depth directions of the Transformer, where the width is the hidden dimensionality of each layer and the depth is the number of layers. As shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the BST framework can generally be seamlessly integrated with arbitrary Transformer-based VQA models to support training a single model only once and then pruning it to obtain multiple efficient submodels of various widths and depths at inference time. It is worth noting that each resulting submodel directly inherits a specific portion of the parameters of the full model and does not require further model finetuning. We take three typical Transformer-based VQA approaches, <em id="S1.p4.3.1" class="ltx_emph ltx_font_italic">i.e.</em>, MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, as the reference models to incorporate into the BST framework, resulting in the slimmable MCAN<math id="S1.p4.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S1.p4.1.m1.1a"><msub id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml"><mi id="S1.p4.1.m1.1.1a" xref="S1.p4.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S1.p4.1.m1.1.1.1" xref="S1.p4.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"><ci id="S1.p4.1.m1.1.1.1a.cmml" xref="S1.p4.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>, UNITER<math id="S1.p4.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S1.p4.2.m2.1a"><msub id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1a" xref="S1.p4.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><ci id="S1.p4.2.m2.1.1.1a.cmml" xref="S1.p4.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">{}_{\texttt{BST}}</annotation></semantics></math>, and CLIP-ViL<math id="S1.p4.3.m3.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S1.p4.3.m3.1a"><msub id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml"><mi id="S1.p4.3.m3.1.1a" xref="S1.p4.3.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S1.p4.3.m3.1.1.1" xref="S1.p4.3.m3.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><apply id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1"><ci id="S1.p4.3.m3.1.1.1a.cmml" xref="S1.p4.3.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S1.p4.3.m3.1.1.1.cmml" xref="S1.p4.3.m3.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">{}_{\texttt{BST}}</annotation></semantics></math> models, respectively. As shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the resulting slimmable models either outperform their existing state-of-the-art counterparts at similar model sizes or achieve comparable performance at much smaller model sizes.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To the best of our knowledge, our study is the first attempt to explore efficient and elastic models for VQA. The most closely related studies to our work is the DynaBERT approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and the RWSAN approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. DynaBERT also investigates slimmable Transformer architectures. In contrast to our BST framework, which supports arbitrary Transformer-based architectures for VQA, DynaBERT focuses on pretrained BERT model for NLP tasks. In terms of methodology, our BST is different from DynaBERT in terms of the slimming strategy and training strategy, resulting in better model performance and less training time. RWSAN investigates lightweight VQA models by introducing residual weight-sharing attention (RWSA) layers, resulting in a VQA model with many fewer parameters. In contrast to our BST framework, RWSAN cannot reduce computational costs and fit the efficiency constraints of different platforms adaptively.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our main contributions are summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Regarding the motivation, orthogonal to the pursuit of model accuracy, we introduce a new direction to the VQA research to learn an <em id="S1.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">efficient and elastic</em> model once and obtain various efficient submodels that can be adaptively fit different platforms.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Regarding the methodology, we present a general bilaterally slimmable Transformer (BST) framework which can transform any Transformer-based VQA model into a slimmable model to adjust the width and depth at runtime. Compared with DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> which introduces a slimmable BERT model for NLP tasks, our BST framework differs in terms of slimming strategies and training strategy.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Regarding effectiveness and generality, we integrate the BST framework with three typical VQA models and conduct extensive experiments on two commonly used VQA datasets. The results show that the slimmed submodels either outperform the state-of-the-art approaches with similar model sizes or achieve comparable performance with smaller model sizes.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Regarding practicability, this study is the first attempt to explore efficient VQA models on different hardware platforms including mobile devices. In particular. our smallest submodel can run on a non-latest mobile device with less than 60 ms latency, showing its potential in a wide range of applications such as robotics, automatic driving, and assistance for visually impaired people.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we first briefly review previous studies on VQA, especially the approaches with Transformer architectures. After that, we discuss related work on efficient neural networks and slimmable neural networks.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Visual Question Answering (VQA).</span> The VQA task, which aims to answer a free-form question in natural language with respect to a given image, has attracted increasing interest over the last few years. The core of VQA lies in two lines of research, namely multimodal fusion and attention learning. For multimodal fusion, early methods used linear models with elementwise summation or multiplication to fuse features from different modalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. To better characterize the second-order interactions between multimodal features, Fukui <em id="S2.p2.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, Kim <em id="S2.p2.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, and Yu <em id="S2.p2.1.4" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> devised different multimodal bilinear pooling models. For attention learning, question-guided visual attention over image regions became a standard component of many early VQA approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Yang <em id="S2.p2.1.5" class="ltx_emph ltx_font_italic">et al.</em> proposed a stacked attention network to iteratively learn visual attention on different levels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. More recently, co-attention models that consider both textual and visual attention have been proposed. Lu <em id="S2.p2.1.6" class="ltx_emph ltx_font_italic">et al.</em> introduced a hierarchical co-attention learning paradigm to learn image attention and question attention iteratively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. Yu <em id="S2.p2.1.7" class="ltx_emph ltx_font_italic">et al.</em> decoupled the co-attention learning into a question self-attention stage and a question-conditioned visual attention stage and optimized the two stages in an end-to-end manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. The aforementioned co-attention models are <em id="S2.p2.1.8" class="ltx_emph ltx_font_italic">coarse-grained</em> in that they neglect the multimodal interactions at a fine-grained level (<em id="S2.p2.1.9" class="ltx_emph ltx_font_italic">i.e.</em>, word-region pairs). To this end, Nguyen <em id="S2.p2.1.10" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, Kim <em id="S2.p2.1.11" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and Liu <em id="S2.p2.1.12" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> introduced dense co-attention models that establish dense interactions among word-region pairs.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Transformer-Based VQA.</span> The Transformer architecture is initially proposed for machine translation in the NLP community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. It consists of a sequence of self-attention modules to model complex and dense interactions within a group of input features. This architecture is general enough to be used in various unimodal tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and multimodal tasks in image <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and video domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. For the VQA task, Gao <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> and Yu <em id="S2.p3.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> devised models based on the Transformer architecture and deliver new state-of-the-art performance on VQA benchmark datasets at the time of their publication.
Besides these studies on general-purpose VQA, there is also a growing trend towards exploring more granular VQA tasks with specific reasoning skills, <em id="S2.p3.1.4" class="ltx_emph ltx_font_italic">e.g.</em>, scene-text understanding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, casual reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, knowledge utilization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">More recently, a BERT model that integrates the Transformer architecture with a self-supervised pretraining paradigm has shown great success in a wide range of NLP tasks. Mirroring the success of BERT, recent studies have naturally extended its framework to the multimodal domain to perform vision-language pretraining (VLP) to learn generic multimodal representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. In particular, they first pretrain Transformer-based models on large image-text corpora to learn task-agnostic representations, and then finetune the models on downstream tasks such as VQA. Early VLP approaches designed different pretraining tasks to learn multimodal Transformers on top of preextracted region-based visual features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. Motivated by the success of pretrained visual backbones, <em id="S2.p4.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, ViT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, recent VLP methods tend to exploit these visual backbones to obtain grid-based visual features and perform multimodal pretraining from raw image and language inputs in an end-to-end manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.
To summarize, Transformer-based approaches dominate the VQA task at present, due to their excellent capability for modeling the complex interactions among multimodal input features. However, Transformer-based VQA models are usually computationally expensive (<em id="S2.p4.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, have a large number of parameters and FLOPs), hindering their deployment on mobile devices with limited memory and computation consumption. This motivates us to explore efficient Transformer architectures for VQA.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Efficient Neural Networks.</span> There has been broad interest in building efficient neural networks in the literature. Existing approaches can be generally categorized as either compressing pretrained networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> or training efficient networks directly <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. The efficient neural networks above mainly focus on ConvNet architectures. Due to the popularity of Transformer in recent years, efficient Transformer architectures have been investigated in different respects, <em id="S2.p5.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, low-rank decomposition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, weight sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, model pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, and knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Low-rank decomposition methods decompose a full-rank parameter matrix into low-dimensional matrices while weight sharing approaches reuse one parameter matrix in different layers of the network. Model pruning methods aim to cut out redundant parameters in the model to obtain a smaller model, and knowledge distillation techniques aim to transfer knowledge from a large teacher model to a small student model. Despite the success of these approaches, their efficient models are dedicated to one specific scenario, and cannot adapt to different efficiency constraints or different hardware platforms at runtime.</p>
</div>
<div id="S2.p6" class="ltx_para ltx_noindent">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">Slimmable Neural Networks.</span> Orthogonal to the approaches to efficient neural networks above, slimmable neural networks aim to design <em id="S2.p6.1.2" class="ltx_emph ltx_font_italic">dynamic</em> models that can adaptively fit different efficiency constraints at runtime. Given a deep neural network, network slimming can be performed on both the depth and width dimensions. For depth slimming, the methods of Wu <em id="S2.p6.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>, Liu <em id="S2.p6.1.4" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, and Huang <em id="S2.p6.1.5" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> learn controllers or gating modules to adaptively drop layers from deep ConvNets. For width slimming, Yu <em id="S2.p6.1.6" class="ltx_emph ltx_font_italic">et al.</em> introduced a general framework for a family of ConvNets (<em id="S2.p6.1.7" class="ltx_emph ltx_font_italic">e.g.</em>, ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> or MobileNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>) that supports a predefined set of width multipliers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. After that, they further improved the framework to support model slimming with arbitrary widths <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. To take a further step, Cai <em id="S2.p6.1.8" class="ltx_emph ltx_font_italic">et al.</em> introduced a once-for-all (OFA) method to support width and depth slimming simultaneously in a unified framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. All of the methods above are only for ConvNet architectures, and their strategies cannot be directly applied to Transformer architectures.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">The most closely related study to our work is DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, which also investigates slimmable Transformer architectures. In contrast to our BST framework, which supports arbitrary Transformer-based architectures for VQA, DynaBERT focuses on pretrained BERT model for NLP tasks. Regarding the methodology, our BST is different from DynaBERT in terms of slimming strategy and training strategy, obtaining significant advantages in terms of a higher compression ratio and less training time.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Bilaterally Slimmable Transformer (BST)</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the bilaterally slimmable Transformer (BST) framework in detail. Before presenting the BST framework, we first revisit the core components of the Transformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Then, we introduce the BST framework, including the slimming strategies for width and depth. We take three typical VQA models, MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> as examples and integrate then with the proposed BST framework. Without loss of generality, our BST framework can be applied to arbitrary VQA models of Transformer-based architectures. After that, we introduce the BST training strategy which consists of submodel architecture selection strategy and a knowledge distillation training stage. Finally, we provide in-depth comparisons to DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> in terms of methodology.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Preliminaries</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.8" class="ltx_p">Transformer is a multi-layer network in which each layer consists of the multi-head attention (MHA) and feed-forward network (FFN) modules <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.

<br class="ltx_break"><span id="S3.SS1.p1.8.1" class="ltx_text ltx_font_bold">Multi-Head Attention.</span> Denote <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">m</annotation></semantics></math> query features and <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">n</annotation></semantics></math> key-value paired features as <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="Q\in\mathbb{R}^{m\times D}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">Q</mi><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.3.2" xref="S3.SS1.p1.3.m3.1.1.3.3.2.cmml">m</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.3.m3.1.1.3.3.1" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><in id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></in><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑄</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3"><times id="S3.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.2">𝑚</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">Q\in\mathbb{R}^{m\times D}</annotation></semantics></math>, <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="K\in\mathbb{R}^{n\times D}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">K</mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.3.2" xref="S3.SS1.p1.4.m4.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.4.m4.1.1.3.3.1" xref="S3.SS1.p1.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.4.m4.1.1.3.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><in id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></in><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝐾</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3"><times id="S3.SS1.p1.4.m4.1.1.3.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.1"></times><ci id="S3.SS1.p1.4.m4.1.1.3.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.2">𝑛</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">K\in\mathbb{R}^{n\times D}</annotation></semantics></math>, and <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="V\in\mathbb{R}^{n\times D}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">V</mi><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.5.m5.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.3.2" xref="S3.SS1.p1.5.m5.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.5.m5.1.1.3.3.1" xref="S3.SS1.p1.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.5.m5.1.1.3.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><in id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></in><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝑉</ci><apply id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3"><times id="S3.SS1.p1.5.m5.1.1.3.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.1"></times><ci id="S3.SS1.p1.5.m5.1.1.3.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2">𝑛</ci><ci id="S3.SS1.p1.5.m5.1.1.3.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">V\in\mathbb{R}^{n\times D}</annotation></semantics></math>, where <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">D</annotation></semantics></math> is the hidden dimensionality of these features. The multi-head attention module calculates the attended features <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="F\in\mathbb{R}^{m\times D}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">F</mi><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.3.2" xref="S3.SS1.p1.7.m7.1.1.3.3.2.cmml">m</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.7.m7.1.1.3.3.1" xref="S3.SS1.p1.7.m7.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.7.m7.1.1.3.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><in id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></in><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝐹</ci><apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3"><times id="S3.SS1.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.1"></times><ci id="S3.SS1.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2">𝑚</ci><ci id="S3.SS1.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">F\in\mathbb{R}^{m\times D}</annotation></semantics></math> by using <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">H</annotation></semantics></math> paralleled attention functions as follows:</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.Ex1.m1.3" class="ltx_Math" alttext="\displaystyle F=\texttt{MHA}(Q,K,V)" display="inline"><semantics id="S3.Ex1.m1.3a"><mrow id="S3.Ex1.m1.3.4" xref="S3.Ex1.m1.3.4.cmml"><mi id="S3.Ex1.m1.3.4.2" xref="S3.Ex1.m1.3.4.2.cmml">F</mi><mo id="S3.Ex1.m1.3.4.1" xref="S3.Ex1.m1.3.4.1.cmml">=</mo><mrow id="S3.Ex1.m1.3.4.3" xref="S3.Ex1.m1.3.4.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.Ex1.m1.3.4.3.2" xref="S3.Ex1.m1.3.4.3.2a.cmml">MHA</mtext><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.4.3.1" xref="S3.Ex1.m1.3.4.3.1.cmml">​</mo><mrow id="S3.Ex1.m1.3.4.3.3.2" xref="S3.Ex1.m1.3.4.3.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.3.4.3.3.2.1" xref="S3.Ex1.m1.3.4.3.3.1.cmml">(</mo><mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">Q</mi><mo id="S3.Ex1.m1.3.4.3.3.2.2" xref="S3.Ex1.m1.3.4.3.3.1.cmml">,</mo><mi id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml">K</mi><mo id="S3.Ex1.m1.3.4.3.3.2.3" xref="S3.Ex1.m1.3.4.3.3.1.cmml">,</mo><mi id="S3.Ex1.m1.3.3" xref="S3.Ex1.m1.3.3.cmml">V</mi><mo stretchy="false" id="S3.Ex1.m1.3.4.3.3.2.4" xref="S3.Ex1.m1.3.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.3b"><apply id="S3.Ex1.m1.3.4.cmml" xref="S3.Ex1.m1.3.4"><eq id="S3.Ex1.m1.3.4.1.cmml" xref="S3.Ex1.m1.3.4.1"></eq><ci id="S3.Ex1.m1.3.4.2.cmml" xref="S3.Ex1.m1.3.4.2">𝐹</ci><apply id="S3.Ex1.m1.3.4.3.cmml" xref="S3.Ex1.m1.3.4.3"><times id="S3.Ex1.m1.3.4.3.1.cmml" xref="S3.Ex1.m1.3.4.3.1"></times><ci id="S3.Ex1.m1.3.4.3.2a.cmml" xref="S3.Ex1.m1.3.4.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.Ex1.m1.3.4.3.2.cmml" xref="S3.Ex1.m1.3.4.3.2">MHA</mtext></ci><vector id="S3.Ex1.m1.3.4.3.3.1.cmml" xref="S3.Ex1.m1.3.4.3.3.2"><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">𝑄</ci><ci id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2">𝐾</ci><ci id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3">𝑉</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.3c">\displaystyle F=\texttt{MHA}(Q,K,V)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.Ex1.m2.4" class="ltx_Math" alttext="\displaystyle=[\mathrm{head}_{1},\mathrm{head}_{2},...,\mathrm{head}_{H}]W^{o}" display="inline"><semantics id="S3.Ex1.m2.4a"><mrow id="S3.Ex1.m2.4.4" xref="S3.Ex1.m2.4.4.cmml"><mi id="S3.Ex1.m2.4.4.5" xref="S3.Ex1.m2.4.4.5.cmml"></mi><mo id="S3.Ex1.m2.4.4.4" xref="S3.Ex1.m2.4.4.4.cmml">=</mo><mrow id="S3.Ex1.m2.4.4.3" xref="S3.Ex1.m2.4.4.3.cmml"><mrow id="S3.Ex1.m2.4.4.3.3.3" xref="S3.Ex1.m2.4.4.3.3.4.cmml"><mo stretchy="false" id="S3.Ex1.m2.4.4.3.3.3.4" xref="S3.Ex1.m2.4.4.3.3.4.cmml">[</mo><msub id="S3.Ex1.m2.2.2.1.1.1.1" xref="S3.Ex1.m2.2.2.1.1.1.1.cmml"><mi id="S3.Ex1.m2.2.2.1.1.1.1.2" xref="S3.Ex1.m2.2.2.1.1.1.1.2.cmml">head</mi><mn id="S3.Ex1.m2.2.2.1.1.1.1.3" xref="S3.Ex1.m2.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.Ex1.m2.4.4.3.3.3.5" xref="S3.Ex1.m2.4.4.3.3.4.cmml">,</mo><msub id="S3.Ex1.m2.3.3.2.2.2.2" xref="S3.Ex1.m2.3.3.2.2.2.2.cmml"><mi id="S3.Ex1.m2.3.3.2.2.2.2.2" xref="S3.Ex1.m2.3.3.2.2.2.2.2.cmml">head</mi><mn id="S3.Ex1.m2.3.3.2.2.2.2.3" xref="S3.Ex1.m2.3.3.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.Ex1.m2.4.4.3.3.3.6" xref="S3.Ex1.m2.4.4.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.Ex1.m2.1.1" xref="S3.Ex1.m2.1.1.cmml">…</mi><mo id="S3.Ex1.m2.4.4.3.3.3.7" xref="S3.Ex1.m2.4.4.3.3.4.cmml">,</mo><msub id="S3.Ex1.m2.4.4.3.3.3.3" xref="S3.Ex1.m2.4.4.3.3.3.3.cmml"><mi id="S3.Ex1.m2.4.4.3.3.3.3.2" xref="S3.Ex1.m2.4.4.3.3.3.3.2.cmml">head</mi><mi id="S3.Ex1.m2.4.4.3.3.3.3.3" xref="S3.Ex1.m2.4.4.3.3.3.3.3.cmml">H</mi></msub><mo stretchy="false" id="S3.Ex1.m2.4.4.3.3.3.8" xref="S3.Ex1.m2.4.4.3.3.4.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m2.4.4.3.4" xref="S3.Ex1.m2.4.4.3.4.cmml">​</mo><msup id="S3.Ex1.m2.4.4.3.5" xref="S3.Ex1.m2.4.4.3.5.cmml"><mi id="S3.Ex1.m2.4.4.3.5.2" xref="S3.Ex1.m2.4.4.3.5.2.cmml">W</mi><mi id="S3.Ex1.m2.4.4.3.5.3" xref="S3.Ex1.m2.4.4.3.5.3.cmml">o</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m2.4b"><apply id="S3.Ex1.m2.4.4.cmml" xref="S3.Ex1.m2.4.4"><eq id="S3.Ex1.m2.4.4.4.cmml" xref="S3.Ex1.m2.4.4.4"></eq><csymbol cd="latexml" id="S3.Ex1.m2.4.4.5.cmml" xref="S3.Ex1.m2.4.4.5">absent</csymbol><apply id="S3.Ex1.m2.4.4.3.cmml" xref="S3.Ex1.m2.4.4.3"><times id="S3.Ex1.m2.4.4.3.4.cmml" xref="S3.Ex1.m2.4.4.3.4"></times><list id="S3.Ex1.m2.4.4.3.3.4.cmml" xref="S3.Ex1.m2.4.4.3.3.3"><apply id="S3.Ex1.m2.2.2.1.1.1.1.cmml" xref="S3.Ex1.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m2.2.2.1.1.1.1.1.cmml" xref="S3.Ex1.m2.2.2.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m2.2.2.1.1.1.1.2.cmml" xref="S3.Ex1.m2.2.2.1.1.1.1.2">head</ci><cn type="integer" id="S3.Ex1.m2.2.2.1.1.1.1.3.cmml" xref="S3.Ex1.m2.2.2.1.1.1.1.3">1</cn></apply><apply id="S3.Ex1.m2.3.3.2.2.2.2.cmml" xref="S3.Ex1.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m2.3.3.2.2.2.2.1.cmml" xref="S3.Ex1.m2.3.3.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m2.3.3.2.2.2.2.2.cmml" xref="S3.Ex1.m2.3.3.2.2.2.2.2">head</ci><cn type="integer" id="S3.Ex1.m2.3.3.2.2.2.2.3.cmml" xref="S3.Ex1.m2.3.3.2.2.2.2.3">2</cn></apply><ci id="S3.Ex1.m2.1.1.cmml" xref="S3.Ex1.m2.1.1">…</ci><apply id="S3.Ex1.m2.4.4.3.3.3.3.cmml" xref="S3.Ex1.m2.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S3.Ex1.m2.4.4.3.3.3.3.1.cmml" xref="S3.Ex1.m2.4.4.3.3.3.3">subscript</csymbol><ci id="S3.Ex1.m2.4.4.3.3.3.3.2.cmml" xref="S3.Ex1.m2.4.4.3.3.3.3.2">head</ci><ci id="S3.Ex1.m2.4.4.3.3.3.3.3.cmml" xref="S3.Ex1.m2.4.4.3.3.3.3.3">𝐻</ci></apply></list><apply id="S3.Ex1.m2.4.4.3.5.cmml" xref="S3.Ex1.m2.4.4.3.5"><csymbol cd="ambiguous" id="S3.Ex1.m2.4.4.3.5.1.cmml" xref="S3.Ex1.m2.4.4.3.5">superscript</csymbol><ci id="S3.Ex1.m2.4.4.3.5.2.cmml" xref="S3.Ex1.m2.4.4.3.5.2">𝑊</ci><ci id="S3.Ex1.m2.4.4.3.5.3.cmml" xref="S3.Ex1.m2.4.4.3.5.3">𝑜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m2.4c">\displaystyle=[\mathrm{head}_{1},\mathrm{head}_{2},...,\mathrm{head}_{H}]W^{o}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{head}_{j}" display="inline"><semantics id="S3.E1.m1.1a"><msub id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mi id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">head</mi><mi id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">head</ci><ci id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle\mathrm{head}_{j}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.m2.3" class="ltx_Math" alttext="\displaystyle=\texttt{ATT}(QW_{j}^{Q},KW_{j}^{K},VW_{j}^{V})" display="inline"><semantics id="S3.E1.m2.3a"><mrow id="S3.E1.m2.3.3" xref="S3.E1.m2.3.3.cmml"><mi id="S3.E1.m2.3.3.5" xref="S3.E1.m2.3.3.5.cmml"></mi><mo id="S3.E1.m2.3.3.4" xref="S3.E1.m2.3.3.4.cmml">=</mo><mrow id="S3.E1.m2.3.3.3" xref="S3.E1.m2.3.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m2.3.3.3.5" xref="S3.E1.m2.3.3.3.5a.cmml">ATT</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m2.3.3.3.4" xref="S3.E1.m2.3.3.3.4.cmml">​</mo><mrow id="S3.E1.m2.3.3.3.3.3" xref="S3.E1.m2.3.3.3.3.4.cmml"><mo stretchy="false" id="S3.E1.m2.3.3.3.3.3.4" xref="S3.E1.m2.3.3.3.3.4.cmml">(</mo><mrow id="S3.E1.m2.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.2" xref="S3.E1.m2.1.1.1.1.1.1.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.1.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.cmml">​</mo><msubsup id="S3.E1.m2.1.1.1.1.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.3.2.2" xref="S3.E1.m2.1.1.1.1.1.1.3.2.2.cmml">W</mi><mi id="S3.E1.m2.1.1.1.1.1.1.3.2.3" xref="S3.E1.m2.1.1.1.1.1.1.3.2.3.cmml">j</mi><mi id="S3.E1.m2.1.1.1.1.1.1.3.3" xref="S3.E1.m2.1.1.1.1.1.1.3.3.cmml">Q</mi></msubsup></mrow><mo id="S3.E1.m2.3.3.3.3.3.5" xref="S3.E1.m2.3.3.3.3.4.cmml">,</mo><mrow id="S3.E1.m2.2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m2.2.2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.2.2.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.2.2.2.2.2.2.1" xref="S3.E1.m2.2.2.2.2.2.2.1.cmml">​</mo><msubsup id="S3.E1.m2.2.2.2.2.2.2.3" xref="S3.E1.m2.2.2.2.2.2.2.3.cmml"><mi id="S3.E1.m2.2.2.2.2.2.2.3.2.2" xref="S3.E1.m2.2.2.2.2.2.2.3.2.2.cmml">W</mi><mi id="S3.E1.m2.2.2.2.2.2.2.3.2.3" xref="S3.E1.m2.2.2.2.2.2.2.3.2.3.cmml">j</mi><mi id="S3.E1.m2.2.2.2.2.2.2.3.3" xref="S3.E1.m2.2.2.2.2.2.2.3.3.cmml">K</mi></msubsup></mrow><mo id="S3.E1.m2.3.3.3.3.3.6" xref="S3.E1.m2.3.3.3.3.4.cmml">,</mo><mrow id="S3.E1.m2.3.3.3.3.3.3" xref="S3.E1.m2.3.3.3.3.3.3.cmml"><mi id="S3.E1.m2.3.3.3.3.3.3.2" xref="S3.E1.m2.3.3.3.3.3.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.3.3.3.3.3.3.1" xref="S3.E1.m2.3.3.3.3.3.3.1.cmml">​</mo><msubsup id="S3.E1.m2.3.3.3.3.3.3.3" xref="S3.E1.m2.3.3.3.3.3.3.3.cmml"><mi id="S3.E1.m2.3.3.3.3.3.3.3.2.2" xref="S3.E1.m2.3.3.3.3.3.3.3.2.2.cmml">W</mi><mi id="S3.E1.m2.3.3.3.3.3.3.3.2.3" xref="S3.E1.m2.3.3.3.3.3.3.3.2.3.cmml">j</mi><mi id="S3.E1.m2.3.3.3.3.3.3.3.3" xref="S3.E1.m2.3.3.3.3.3.3.3.3.cmml">V</mi></msubsup></mrow><mo stretchy="false" id="S3.E1.m2.3.3.3.3.3.7" xref="S3.E1.m2.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m2.3b"><apply id="S3.E1.m2.3.3.cmml" xref="S3.E1.m2.3.3"><eq id="S3.E1.m2.3.3.4.cmml" xref="S3.E1.m2.3.3.4"></eq><csymbol cd="latexml" id="S3.E1.m2.3.3.5.cmml" xref="S3.E1.m2.3.3.5">absent</csymbol><apply id="S3.E1.m2.3.3.3.cmml" xref="S3.E1.m2.3.3.3"><times id="S3.E1.m2.3.3.3.4.cmml" xref="S3.E1.m2.3.3.3.4"></times><ci id="S3.E1.m2.3.3.3.5a.cmml" xref="S3.E1.m2.3.3.3.5"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m2.3.3.3.5.cmml" xref="S3.E1.m2.3.3.3.5">ATT</mtext></ci><vector id="S3.E1.m2.3.3.3.3.4.cmml" xref="S3.E1.m2.3.3.3.3.3"><apply id="S3.E1.m2.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1"><times id="S3.E1.m2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1"></times><ci id="S3.E1.m2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2">𝑄</ci><apply id="S3.E1.m2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E1.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3.2.2">𝑊</ci><ci id="S3.E1.m2.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3.2.3">𝑗</ci></apply><ci id="S3.E1.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3.3">𝑄</ci></apply></apply><apply id="S3.E1.m2.2.2.2.2.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2"><times id="S3.E1.m2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m2.2.2.2.2.2.2.1"></times><ci id="S3.E1.m2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2.2">𝐾</ci><apply id="S3.E1.m2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m2.2.2.2.2.2.2.3.1.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3">superscript</csymbol><apply id="S3.E1.m2.2.2.2.2.2.2.3.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m2.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E1.m2.2.2.2.2.2.2.3.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3.2.2">𝑊</ci><ci id="S3.E1.m2.2.2.2.2.2.2.3.2.3.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3.2.3">𝑗</ci></apply><ci id="S3.E1.m2.2.2.2.2.2.2.3.3.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3.3">𝐾</ci></apply></apply><apply id="S3.E1.m2.3.3.3.3.3.3.cmml" xref="S3.E1.m2.3.3.3.3.3.3"><times id="S3.E1.m2.3.3.3.3.3.3.1.cmml" xref="S3.E1.m2.3.3.3.3.3.3.1"></times><ci id="S3.E1.m2.3.3.3.3.3.3.2.cmml" xref="S3.E1.m2.3.3.3.3.3.3.2">𝑉</ci><apply id="S3.E1.m2.3.3.3.3.3.3.3.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m2.3.3.3.3.3.3.3.1.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3">superscript</csymbol><apply id="S3.E1.m2.3.3.3.3.3.3.3.2.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m2.3.3.3.3.3.3.3.2.1.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3">subscript</csymbol><ci id="S3.E1.m2.3.3.3.3.3.3.3.2.2.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3.2.2">𝑊</ci><ci id="S3.E1.m2.3.3.3.3.3.3.3.2.3.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3.2.3">𝑗</ci></apply><ci id="S3.E1.m2.3.3.3.3.3.3.3.3.cmml" xref="S3.E1.m2.3.3.3.3.3.3.3.3">𝑉</ci></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m2.3c">\displaystyle=\texttt{ATT}(QW_{j}^{Q},KW_{j}^{K},VW_{j}^{V})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.14" class="ltx_p">where <math id="S3.SS1.p1.9.m1.3" class="ltx_Math" alttext="W_{j}^{Q},W_{j}^{K},W_{j}^{V}\in\mathbb{R}^{D\times D_{H}}" display="inline"><semantics id="S3.SS1.p1.9.m1.3a"><mrow id="S3.SS1.p1.9.m1.3.3" xref="S3.SS1.p1.9.m1.3.3.cmml"><mrow id="S3.SS1.p1.9.m1.3.3.3.3" xref="S3.SS1.p1.9.m1.3.3.3.4.cmml"><msubsup id="S3.SS1.p1.9.m1.1.1.1.1.1" xref="S3.SS1.p1.9.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.9.m1.1.1.1.1.1.2.2" xref="S3.SS1.p1.9.m1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S3.SS1.p1.9.m1.1.1.1.1.1.2.3" xref="S3.SS1.p1.9.m1.1.1.1.1.1.2.3.cmml">j</mi><mi id="S3.SS1.p1.9.m1.1.1.1.1.1.3" xref="S3.SS1.p1.9.m1.1.1.1.1.1.3.cmml">Q</mi></msubsup><mo id="S3.SS1.p1.9.m1.3.3.3.3.4" xref="S3.SS1.p1.9.m1.3.3.3.4.cmml">,</mo><msubsup id="S3.SS1.p1.9.m1.2.2.2.2.2" xref="S3.SS1.p1.9.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.9.m1.2.2.2.2.2.2.2" xref="S3.SS1.p1.9.m1.2.2.2.2.2.2.2.cmml">W</mi><mi id="S3.SS1.p1.9.m1.2.2.2.2.2.2.3" xref="S3.SS1.p1.9.m1.2.2.2.2.2.2.3.cmml">j</mi><mi id="S3.SS1.p1.9.m1.2.2.2.2.2.3" xref="S3.SS1.p1.9.m1.2.2.2.2.2.3.cmml">K</mi></msubsup><mo id="S3.SS1.p1.9.m1.3.3.3.3.5" xref="S3.SS1.p1.9.m1.3.3.3.4.cmml">,</mo><msubsup id="S3.SS1.p1.9.m1.3.3.3.3.3" xref="S3.SS1.p1.9.m1.3.3.3.3.3.cmml"><mi id="S3.SS1.p1.9.m1.3.3.3.3.3.2.2" xref="S3.SS1.p1.9.m1.3.3.3.3.3.2.2.cmml">W</mi><mi id="S3.SS1.p1.9.m1.3.3.3.3.3.2.3" xref="S3.SS1.p1.9.m1.3.3.3.3.3.2.3.cmml">j</mi><mi id="S3.SS1.p1.9.m1.3.3.3.3.3.3" xref="S3.SS1.p1.9.m1.3.3.3.3.3.3.cmml">V</mi></msubsup></mrow><mo id="S3.SS1.p1.9.m1.3.3.4" xref="S3.SS1.p1.9.m1.3.3.4.cmml">∈</mo><msup id="S3.SS1.p1.9.m1.3.3.5" xref="S3.SS1.p1.9.m1.3.3.5.cmml"><mi id="S3.SS1.p1.9.m1.3.3.5.2" xref="S3.SS1.p1.9.m1.3.3.5.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.9.m1.3.3.5.3" xref="S3.SS1.p1.9.m1.3.3.5.3.cmml"><mi id="S3.SS1.p1.9.m1.3.3.5.3.2" xref="S3.SS1.p1.9.m1.3.3.5.3.2.cmml">D</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.9.m1.3.3.5.3.1" xref="S3.SS1.p1.9.m1.3.3.5.3.1.cmml">×</mo><msub id="S3.SS1.p1.9.m1.3.3.5.3.3" xref="S3.SS1.p1.9.m1.3.3.5.3.3.cmml"><mi id="S3.SS1.p1.9.m1.3.3.5.3.3.2" xref="S3.SS1.p1.9.m1.3.3.5.3.3.2.cmml">D</mi><mi id="S3.SS1.p1.9.m1.3.3.5.3.3.3" xref="S3.SS1.p1.9.m1.3.3.5.3.3.3.cmml">H</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m1.3b"><apply id="S3.SS1.p1.9.m1.3.3.cmml" xref="S3.SS1.p1.9.m1.3.3"><in id="S3.SS1.p1.9.m1.3.3.4.cmml" xref="S3.SS1.p1.9.m1.3.3.4"></in><list id="S3.SS1.p1.9.m1.3.3.3.4.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3"><apply id="S3.SS1.p1.9.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.9.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1.2.2">𝑊</ci><ci id="S3.SS1.p1.9.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1.2.3">𝑗</ci></apply><ci id="S3.SS1.p1.9.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.9.m1.1.1.1.1.1.3">𝑄</ci></apply><apply id="S3.SS1.p1.9.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p1.9.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.9.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2.2.2">𝑊</ci><ci id="S3.SS1.p1.9.m1.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2.2.3">𝑗</ci></apply><ci id="S3.SS1.p1.9.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.9.m1.2.2.2.2.2.3">𝐾</ci></apply><apply id="S3.SS1.p1.9.m1.3.3.3.3.3.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.3.3.3.3.3.1.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3">superscript</csymbol><apply id="S3.SS1.p1.9.m1.3.3.3.3.3.2.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.3.3.3.3.3.2.1.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.9.m1.3.3.3.3.3.2.2.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3.2.2">𝑊</ci><ci id="S3.SS1.p1.9.m1.3.3.3.3.3.2.3.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3.2.3">𝑗</ci></apply><ci id="S3.SS1.p1.9.m1.3.3.3.3.3.3.cmml" xref="S3.SS1.p1.9.m1.3.3.3.3.3.3">𝑉</ci></apply></list><apply id="S3.SS1.p1.9.m1.3.3.5.cmml" xref="S3.SS1.p1.9.m1.3.3.5"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.3.3.5.1.cmml" xref="S3.SS1.p1.9.m1.3.3.5">superscript</csymbol><ci id="S3.SS1.p1.9.m1.3.3.5.2.cmml" xref="S3.SS1.p1.9.m1.3.3.5.2">ℝ</ci><apply id="S3.SS1.p1.9.m1.3.3.5.3.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3"><times id="S3.SS1.p1.9.m1.3.3.5.3.1.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3.1"></times><ci id="S3.SS1.p1.9.m1.3.3.5.3.2.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3.2">𝐷</ci><apply id="S3.SS1.p1.9.m1.3.3.5.3.3.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.3.3.5.3.3.1.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3.3">subscript</csymbol><ci id="S3.SS1.p1.9.m1.3.3.5.3.3.2.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3.3.2">𝐷</ci><ci id="S3.SS1.p1.9.m1.3.3.5.3.3.3.cmml" xref="S3.SS1.p1.9.m1.3.3.5.3.3.3">𝐻</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m1.3c">W_{j}^{Q},W_{j}^{K},W_{j}^{V}\in\mathbb{R}^{D\times D_{H}}</annotation></semantics></math> are the projection matrices for the <math id="S3.SS1.p1.10.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS1.p1.10.m2.1a"><mi id="S3.SS1.p1.10.m2.1.1" xref="S3.SS1.p1.10.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m2.1b"><ci id="S3.SS1.p1.10.m2.1.1.cmml" xref="S3.SS1.p1.10.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m2.1c">j</annotation></semantics></math>-th head, and <math id="S3.SS1.p1.11.m3.1" class="ltx_Math" alttext="D_{H}" display="inline"><semantics id="S3.SS1.p1.11.m3.1a"><msub id="S3.SS1.p1.11.m3.1.1" xref="S3.SS1.p1.11.m3.1.1.cmml"><mi id="S3.SS1.p1.11.m3.1.1.2" xref="S3.SS1.p1.11.m3.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.11.m3.1.1.3" xref="S3.SS1.p1.11.m3.1.1.3.cmml">H</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m3.1b"><apply id="S3.SS1.p1.11.m3.1.1.cmml" xref="S3.SS1.p1.11.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m3.1.1.1.cmml" xref="S3.SS1.p1.11.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m3.1.1.2.cmml" xref="S3.SS1.p1.11.m3.1.1.2">𝐷</ci><ci id="S3.SS1.p1.11.m3.1.1.3.cmml" xref="S3.SS1.p1.11.m3.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m3.1c">D_{H}</annotation></semantics></math> is the dimensionality of the features from each head. <math id="S3.SS1.p1.12.m4.1" class="ltx_Math" alttext="W^{o}\in\mathbb{R}^{H\cdot D_{H}\times D}" display="inline"><semantics id="S3.SS1.p1.12.m4.1a"><mrow id="S3.SS1.p1.12.m4.1.1" xref="S3.SS1.p1.12.m4.1.1.cmml"><msup id="S3.SS1.p1.12.m4.1.1.2" xref="S3.SS1.p1.12.m4.1.1.2.cmml"><mi id="S3.SS1.p1.12.m4.1.1.2.2" xref="S3.SS1.p1.12.m4.1.1.2.2.cmml">W</mi><mi id="S3.SS1.p1.12.m4.1.1.2.3" xref="S3.SS1.p1.12.m4.1.1.2.3.cmml">o</mi></msup><mo id="S3.SS1.p1.12.m4.1.1.1" xref="S3.SS1.p1.12.m4.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.12.m4.1.1.3" xref="S3.SS1.p1.12.m4.1.1.3.cmml"><mi id="S3.SS1.p1.12.m4.1.1.3.2" xref="S3.SS1.p1.12.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.12.m4.1.1.3.3" xref="S3.SS1.p1.12.m4.1.1.3.3.cmml"><mrow id="S3.SS1.p1.12.m4.1.1.3.3.2" xref="S3.SS1.p1.12.m4.1.1.3.3.2.cmml"><mi id="S3.SS1.p1.12.m4.1.1.3.3.2.2" xref="S3.SS1.p1.12.m4.1.1.3.3.2.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.12.m4.1.1.3.3.2.1" xref="S3.SS1.p1.12.m4.1.1.3.3.2.1.cmml">⋅</mo><msub id="S3.SS1.p1.12.m4.1.1.3.3.2.3" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3.cmml"><mi id="S3.SS1.p1.12.m4.1.1.3.3.2.3.2" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3.2.cmml">D</mi><mi id="S3.SS1.p1.12.m4.1.1.3.3.2.3.3" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3.3.cmml">H</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.12.m4.1.1.3.3.1" xref="S3.SS1.p1.12.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.12.m4.1.1.3.3.3" xref="S3.SS1.p1.12.m4.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m4.1b"><apply id="S3.SS1.p1.12.m4.1.1.cmml" xref="S3.SS1.p1.12.m4.1.1"><in id="S3.SS1.p1.12.m4.1.1.1.cmml" xref="S3.SS1.p1.12.m4.1.1.1"></in><apply id="S3.SS1.p1.12.m4.1.1.2.cmml" xref="S3.SS1.p1.12.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m4.1.1.2.1.cmml" xref="S3.SS1.p1.12.m4.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.12.m4.1.1.2.2.cmml" xref="S3.SS1.p1.12.m4.1.1.2.2">𝑊</ci><ci id="S3.SS1.p1.12.m4.1.1.2.3.cmml" xref="S3.SS1.p1.12.m4.1.1.2.3">𝑜</ci></apply><apply id="S3.SS1.p1.12.m4.1.1.3.cmml" xref="S3.SS1.p1.12.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m4.1.1.3.1.cmml" xref="S3.SS1.p1.12.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.12.m4.1.1.3.2.cmml" xref="S3.SS1.p1.12.m4.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.12.m4.1.1.3.3.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3"><times id="S3.SS1.p1.12.m4.1.1.3.3.1.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.1"></times><apply id="S3.SS1.p1.12.m4.1.1.3.3.2.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2"><ci id="S3.SS1.p1.12.m4.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2.1">⋅</ci><ci id="S3.SS1.p1.12.m4.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2.2">𝐻</ci><apply id="S3.SS1.p1.12.m4.1.1.3.3.2.3.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m4.1.1.3.3.2.3.1.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3">subscript</csymbol><ci id="S3.SS1.p1.12.m4.1.1.3.3.2.3.2.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3.2">𝐷</ci><ci id="S3.SS1.p1.12.m4.1.1.3.3.2.3.3.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.2.3.3">𝐻</ci></apply></apply><ci id="S3.SS1.p1.12.m4.1.1.3.3.3.cmml" xref="S3.SS1.p1.12.m4.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m4.1c">W^{o}\in\mathbb{R}^{H\cdot D_{H}\times D}</annotation></semantics></math> is the projection matrix used to aggregate the output features from different heads. We set <math id="S3.SS1.p1.13.m5.1" class="ltx_Math" alttext="D_{H}=D/H" display="inline"><semantics id="S3.SS1.p1.13.m5.1a"><mrow id="S3.SS1.p1.13.m5.1.1" xref="S3.SS1.p1.13.m5.1.1.cmml"><msub id="S3.SS1.p1.13.m5.1.1.2" xref="S3.SS1.p1.13.m5.1.1.2.cmml"><mi id="S3.SS1.p1.13.m5.1.1.2.2" xref="S3.SS1.p1.13.m5.1.1.2.2.cmml">D</mi><mi id="S3.SS1.p1.13.m5.1.1.2.3" xref="S3.SS1.p1.13.m5.1.1.2.3.cmml">H</mi></msub><mo id="S3.SS1.p1.13.m5.1.1.1" xref="S3.SS1.p1.13.m5.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.13.m5.1.1.3" xref="S3.SS1.p1.13.m5.1.1.3.cmml"><mi id="S3.SS1.p1.13.m5.1.1.3.2" xref="S3.SS1.p1.13.m5.1.1.3.2.cmml">D</mi><mo id="S3.SS1.p1.13.m5.1.1.3.1" xref="S3.SS1.p1.13.m5.1.1.3.1.cmml">/</mo><mi id="S3.SS1.p1.13.m5.1.1.3.3" xref="S3.SS1.p1.13.m5.1.1.3.3.cmml">H</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m5.1b"><apply id="S3.SS1.p1.13.m5.1.1.cmml" xref="S3.SS1.p1.13.m5.1.1"><eq id="S3.SS1.p1.13.m5.1.1.1.cmml" xref="S3.SS1.p1.13.m5.1.1.1"></eq><apply id="S3.SS1.p1.13.m5.1.1.2.cmml" xref="S3.SS1.p1.13.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m5.1.1.2.1.cmml" xref="S3.SS1.p1.13.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.13.m5.1.1.2.2.cmml" xref="S3.SS1.p1.13.m5.1.1.2.2">𝐷</ci><ci id="S3.SS1.p1.13.m5.1.1.2.3.cmml" xref="S3.SS1.p1.13.m5.1.1.2.3">𝐻</ci></apply><apply id="S3.SS1.p1.13.m5.1.1.3.cmml" xref="S3.SS1.p1.13.m5.1.1.3"><divide id="S3.SS1.p1.13.m5.1.1.3.1.cmml" xref="S3.SS1.p1.13.m5.1.1.3.1"></divide><ci id="S3.SS1.p1.13.m5.1.1.3.2.cmml" xref="S3.SS1.p1.13.m5.1.1.3.2">𝐷</ci><ci id="S3.SS1.p1.13.m5.1.1.3.3.cmml" xref="S3.SS1.p1.13.m5.1.1.3.3">𝐻</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m5.1c">D_{H}=D/H</annotation></semantics></math> so that the model sizes remain constant as <math id="S3.SS1.p1.14.m6.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p1.14.m6.1a"><mi id="S3.SS1.p1.14.m6.1.1" xref="S3.SS1.p1.14.m6.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m6.1b"><ci id="S3.SS1.p1.14.m6.1.1.cmml" xref="S3.SS1.p1.14.m6.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m6.1c">H</annotation></semantics></math> varies. The attention function for each head is defined as the scaled dot-product of the query with all keys:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.4" class="ltx_Math" alttext="\texttt{ATT}(Q,K,V)=\mathrm{softmax}(\frac{QK^{T}}{\sqrt{D_{H}}})V" display="block"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.5" xref="S3.E2.m1.4.5.cmml"><mrow id="S3.E2.m1.4.5.2" xref="S3.E2.m1.4.5.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.4.5.2.2" xref="S3.E2.m1.4.5.2.2a.cmml">ATT</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1" xref="S3.E2.m1.4.5.2.1.cmml">​</mo><mrow id="S3.E2.m1.4.5.2.3.2" xref="S3.E2.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.5.2.3.2.1" xref="S3.E2.m1.4.5.2.3.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">Q</mi><mo id="S3.E2.m1.4.5.2.3.2.2" xref="S3.E2.m1.4.5.2.3.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">K</mi><mo id="S3.E2.m1.4.5.2.3.2.3" xref="S3.E2.m1.4.5.2.3.1.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">V</mi><mo stretchy="false" id="S3.E2.m1.4.5.2.3.2.4" xref="S3.E2.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.5.1" xref="S3.E2.m1.4.5.1.cmml">=</mo><mrow id="S3.E2.m1.4.5.3" xref="S3.E2.m1.4.5.3.cmml"><mi id="S3.E2.m1.4.5.3.2" xref="S3.E2.m1.4.5.3.2.cmml">softmax</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1" xref="S3.E2.m1.4.5.3.1.cmml">​</mo><mrow id="S3.E2.m1.4.5.3.3.2" xref="S3.E2.m1.4.4.cmml"><mo stretchy="false" id="S3.E2.m1.4.5.3.3.2.1" xref="S3.E2.m1.4.4.cmml">(</mo><mfrac id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mrow id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml"><mi id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.2.1" xref="S3.E2.m1.4.4.2.1.cmml">​</mo><msup id="S3.E2.m1.4.4.2.3" xref="S3.E2.m1.4.4.2.3.cmml"><mi id="S3.E2.m1.4.4.2.3.2" xref="S3.E2.m1.4.4.2.3.2.cmml">K</mi><mi id="S3.E2.m1.4.4.2.3.3" xref="S3.E2.m1.4.4.2.3.3.cmml">T</mi></msup></mrow><msqrt id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><msub id="S3.E2.m1.4.4.3.2" xref="S3.E2.m1.4.4.3.2.cmml"><mi id="S3.E2.m1.4.4.3.2.2" xref="S3.E2.m1.4.4.3.2.2.cmml">D</mi><mi id="S3.E2.m1.4.4.3.2.3" xref="S3.E2.m1.4.4.3.2.3.cmml">H</mi></msub></msqrt></mfrac><mo stretchy="false" id="S3.E2.m1.4.5.3.3.2.2" xref="S3.E2.m1.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1a" xref="S3.E2.m1.4.5.3.1.cmml">​</mo><mi id="S3.E2.m1.4.5.3.4" xref="S3.E2.m1.4.5.3.4.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.5.cmml" xref="S3.E2.m1.4.5"><eq id="S3.E2.m1.4.5.1.cmml" xref="S3.E2.m1.4.5.1"></eq><apply id="S3.E2.m1.4.5.2.cmml" xref="S3.E2.m1.4.5.2"><times id="S3.E2.m1.4.5.2.1.cmml" xref="S3.E2.m1.4.5.2.1"></times><ci id="S3.E2.m1.4.5.2.2a.cmml" xref="S3.E2.m1.4.5.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E2.m1.4.5.2.2.cmml" xref="S3.E2.m1.4.5.2.2">ATT</mtext></ci><vector id="S3.E2.m1.4.5.2.3.1.cmml" xref="S3.E2.m1.4.5.2.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑄</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝐾</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝑉</ci></vector></apply><apply id="S3.E2.m1.4.5.3.cmml" xref="S3.E2.m1.4.5.3"><times id="S3.E2.m1.4.5.3.1.cmml" xref="S3.E2.m1.4.5.3.1"></times><ci id="S3.E2.m1.4.5.3.2.cmml" xref="S3.E2.m1.4.5.3.2">softmax</ci><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.5.3.3.2"><divide id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.5.3.3.2"></divide><apply id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"><times id="S3.E2.m1.4.4.2.1.cmml" xref="S3.E2.m1.4.4.2.1"></times><ci id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2">𝑄</ci><apply id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.3.1.cmml" xref="S3.E2.m1.4.4.2.3">superscript</csymbol><ci id="S3.E2.m1.4.4.2.3.2.cmml" xref="S3.E2.m1.4.4.2.3.2">𝐾</ci><ci id="S3.E2.m1.4.4.2.3.3.cmml" xref="S3.E2.m1.4.4.2.3.3">𝑇</ci></apply></apply><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><root id="S3.E2.m1.4.4.3a.cmml" xref="S3.E2.m1.4.4.3"></root><apply id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.2.1.cmml" xref="S3.E2.m1.4.4.3.2">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.2.cmml" xref="S3.E2.m1.4.4.3.2.2">𝐷</ci><ci id="S3.E2.m1.4.4.3.2.3.cmml" xref="S3.E2.m1.4.4.3.2.3">𝐻</ci></apply></apply></apply><ci id="S3.E2.m1.4.5.3.4.cmml" xref="S3.E2.m1.4.5.3.4">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\texttt{ATT}(Q,K,V)=\mathrm{softmax}(\frac{QK^{T}}{\sqrt{D_{H}}})V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.16" class="ltx_p">which calculates the scaled dot-product of each query with all keys to obtain the attention weights, and then performs weighted summation over the values.

<br class="ltx_break"><span id="S3.SS1.p1.16.1" class="ltx_text ltx_font_bold">Feed-Forward Network.</span> The feed-forward network module is a two-layer MLP model applied to the output features of the MHA module to perform a pointwise nonlinear transformation. Given input features <math id="S3.SS1.p1.15.m1.1" class="ltx_Math" alttext="X\in\mathbb{R}^{n\times D}" display="inline"><semantics id="S3.SS1.p1.15.m1.1a"><mrow id="S3.SS1.p1.15.m1.1.1" xref="S3.SS1.p1.15.m1.1.1.cmml"><mi id="S3.SS1.p1.15.m1.1.1.2" xref="S3.SS1.p1.15.m1.1.1.2.cmml">X</mi><mo id="S3.SS1.p1.15.m1.1.1.1" xref="S3.SS1.p1.15.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.15.m1.1.1.3" xref="S3.SS1.p1.15.m1.1.1.3.cmml"><mi id="S3.SS1.p1.15.m1.1.1.3.2" xref="S3.SS1.p1.15.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.15.m1.1.1.3.3" xref="S3.SS1.p1.15.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.15.m1.1.1.3.3.2" xref="S3.SS1.p1.15.m1.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.15.m1.1.1.3.3.1" xref="S3.SS1.p1.15.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.15.m1.1.1.3.3.3" xref="S3.SS1.p1.15.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m1.1b"><apply id="S3.SS1.p1.15.m1.1.1.cmml" xref="S3.SS1.p1.15.m1.1.1"><in id="S3.SS1.p1.15.m1.1.1.1.cmml" xref="S3.SS1.p1.15.m1.1.1.1"></in><ci id="S3.SS1.p1.15.m1.1.1.2.cmml" xref="S3.SS1.p1.15.m1.1.1.2">𝑋</ci><apply id="S3.SS1.p1.15.m1.1.1.3.cmml" xref="S3.SS1.p1.15.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m1.1.1.3.1.cmml" xref="S3.SS1.p1.15.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.15.m1.1.1.3.2.cmml" xref="S3.SS1.p1.15.m1.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.15.m1.1.1.3.3.cmml" xref="S3.SS1.p1.15.m1.1.1.3.3"><times id="S3.SS1.p1.15.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.15.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.15.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.15.m1.1.1.3.3.2">𝑛</ci><ci id="S3.SS1.p1.15.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.15.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m1.1c">X\in\mathbb{R}^{n\times D}</annotation></semantics></math>, the transformed features <math id="S3.SS1.p1.16.m2.1" class="ltx_Math" alttext="F\in\mathbb{R}^{n\times D}" display="inline"><semantics id="S3.SS1.p1.16.m2.1a"><mrow id="S3.SS1.p1.16.m2.1.1" xref="S3.SS1.p1.16.m2.1.1.cmml"><mi id="S3.SS1.p1.16.m2.1.1.2" xref="S3.SS1.p1.16.m2.1.1.2.cmml">F</mi><mo id="S3.SS1.p1.16.m2.1.1.1" xref="S3.SS1.p1.16.m2.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.16.m2.1.1.3" xref="S3.SS1.p1.16.m2.1.1.3.cmml"><mi id="S3.SS1.p1.16.m2.1.1.3.2" xref="S3.SS1.p1.16.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.16.m2.1.1.3.3" xref="S3.SS1.p1.16.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.16.m2.1.1.3.3.2" xref="S3.SS1.p1.16.m2.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.16.m2.1.1.3.3.1" xref="S3.SS1.p1.16.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.16.m2.1.1.3.3.3" xref="S3.SS1.p1.16.m2.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m2.1b"><apply id="S3.SS1.p1.16.m2.1.1.cmml" xref="S3.SS1.p1.16.m2.1.1"><in id="S3.SS1.p1.16.m2.1.1.1.cmml" xref="S3.SS1.p1.16.m2.1.1.1"></in><ci id="S3.SS1.p1.16.m2.1.1.2.cmml" xref="S3.SS1.p1.16.m2.1.1.2">𝐹</ci><apply id="S3.SS1.p1.16.m2.1.1.3.cmml" xref="S3.SS1.p1.16.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.16.m2.1.1.3.1.cmml" xref="S3.SS1.p1.16.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.16.m2.1.1.3.2.cmml" xref="S3.SS1.p1.16.m2.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.16.m2.1.1.3.3.cmml" xref="S3.SS1.p1.16.m2.1.1.3.3"><times id="S3.SS1.p1.16.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.16.m2.1.1.3.3.1"></times><ci id="S3.SS1.p1.16.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.16.m2.1.1.3.3.2">𝑛</ci><ci id="S3.SS1.p1.16.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.16.m2.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m2.1c">F\in\mathbb{R}^{n\times D}</annotation></semantics></math> are obtained as follows:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="F=\texttt{FFN}(X)=\mathrm{ReLU}(XW_{1}+b_{1})W_{2}^{T}+b_{2}" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><mi id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">F</mi><mo id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml">=</mo><mrow id="S3.E3.m1.2.2.5" xref="S3.E3.m1.2.2.5.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.2.2.5.2" xref="S3.E3.m1.2.2.5.2a.cmml">FFN</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.5.1" xref="S3.E3.m1.2.2.5.1.cmml">​</mo><mrow id="S3.E3.m1.2.2.5.3.2" xref="S3.E3.m1.2.2.5.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.5.3.2.1" xref="S3.E3.m1.2.2.5.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">X</mi><mo stretchy="false" id="S3.E3.m1.2.2.5.3.2.2" xref="S3.E3.m1.2.2.5.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.6" xref="S3.E3.m1.2.2.6.cmml">=</mo><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml">ReLU</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">​</mo><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2.1" xref="S3.E3.m1.2.2.1.1.1.1.1.2.1.cmml">​</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.2.3" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.2.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3.2.cmml">W</mi><mn id="S3.E3.m1.2.2.1.1.1.1.1.2.3.3" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.cmml">+</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.3.2.cmml">b</mi><mn id="S3.E3.m1.2.2.1.1.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2a" xref="S3.E3.m1.2.2.1.1.2.cmml">​</mo><msubsup id="S3.E3.m1.2.2.1.1.4" xref="S3.E3.m1.2.2.1.1.4.cmml"><mi id="S3.E3.m1.2.2.1.1.4.2.2" xref="S3.E3.m1.2.2.1.1.4.2.2.cmml">W</mi><mn id="S3.E3.m1.2.2.1.1.4.2.3" xref="S3.E3.m1.2.2.1.1.4.2.3.cmml">2</mn><mi id="S3.E3.m1.2.2.1.1.4.3" xref="S3.E3.m1.2.2.1.1.4.3.cmml">T</mi></msubsup></mrow><mo id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.2.cmml">+</mo><msub id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.2.2.1.3.cmml"><mi id="S3.E3.m1.2.2.1.3.2" xref="S3.E3.m1.2.2.1.3.2.cmml">b</mi><mn id="S3.E3.m1.2.2.1.3.3" xref="S3.E3.m1.2.2.1.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><and id="S3.E3.m1.2.2a.cmml" xref="S3.E3.m1.2.2"></and><apply id="S3.E3.m1.2.2b.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"></eq><ci id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3">𝐹</ci><apply id="S3.E3.m1.2.2.5.cmml" xref="S3.E3.m1.2.2.5"><times id="S3.E3.m1.2.2.5.1.cmml" xref="S3.E3.m1.2.2.5.1"></times><ci id="S3.E3.m1.2.2.5.2a.cmml" xref="S3.E3.m1.2.2.5.2"><mtext class="ltx_mathvariant_monospace" id="S3.E3.m1.2.2.5.2.cmml" xref="S3.E3.m1.2.2.5.2">FFN</mtext></ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑋</ci></apply></apply><apply id="S3.E3.m1.2.2c.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.6.cmml" xref="S3.E3.m1.2.2.6"></eq><share href="#S3.E3.m1.2.2.5.cmml" id="S3.E3.m1.2.2d.cmml" xref="S3.E3.m1.2.2"></share><apply id="S3.E3.m1.2.2.1.cmml" xref="S3.E3.m1.2.2.1"><plus id="S3.E3.m1.2.2.1.2.cmml" xref="S3.E3.m1.2.2.1.2"></plus><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><times id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2"></times><ci id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3">ReLU</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1"><plus id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"></plus><apply id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2"><times id="S3.E3.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.1"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2">𝑋</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3.2">𝑊</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3.2">𝑏</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.1.cmml" xref="S3.E3.m1.2.2.1.1.4">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.2.2">𝑊</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.4.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.2.3">2</cn></apply><ci id="S3.E3.m1.2.2.1.1.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.3">𝑇</ci></apply></apply><apply id="S3.E3.m1.2.2.1.3.cmml" xref="S3.E3.m1.2.2.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.3.1.cmml" xref="S3.E3.m1.2.2.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.3.2.cmml" xref="S3.E3.m1.2.2.1.3.2">𝑏</ci><cn type="integer" id="S3.E3.m1.2.2.1.3.3.cmml" xref="S3.E3.m1.2.2.1.3.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">F=\texttt{FFN}(X)=\mathrm{ReLU}(XW_{1}+b_{1})W_{2}^{T}+b_{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.17" class="ltx_p">where <math id="S3.SS1.p1.17.m1.2" class="ltx_Math" alttext="W_{1},W_{2}\in\mathbb{R}^{D\times 4D}" display="inline"><semantics id="S3.SS1.p1.17.m1.2a"><mrow id="S3.SS1.p1.17.m1.2.2" xref="S3.SS1.p1.17.m1.2.2.cmml"><mrow id="S3.SS1.p1.17.m1.2.2.2.2" xref="S3.SS1.p1.17.m1.2.2.2.3.cmml"><msub id="S3.SS1.p1.17.m1.1.1.1.1.1" xref="S3.SS1.p1.17.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.17.m1.1.1.1.1.1.2" xref="S3.SS1.p1.17.m1.1.1.1.1.1.2.cmml">W</mi><mn id="S3.SS1.p1.17.m1.1.1.1.1.1.3" xref="S3.SS1.p1.17.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.17.m1.2.2.2.2.3" xref="S3.SS1.p1.17.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.17.m1.2.2.2.2.2" xref="S3.SS1.p1.17.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.17.m1.2.2.2.2.2.2" xref="S3.SS1.p1.17.m1.2.2.2.2.2.2.cmml">W</mi><mn id="S3.SS1.p1.17.m1.2.2.2.2.2.3" xref="S3.SS1.p1.17.m1.2.2.2.2.2.3.cmml">2</mn></msub></mrow><mo id="S3.SS1.p1.17.m1.2.2.3" xref="S3.SS1.p1.17.m1.2.2.3.cmml">∈</mo><msup id="S3.SS1.p1.17.m1.2.2.4" xref="S3.SS1.p1.17.m1.2.2.4.cmml"><mi id="S3.SS1.p1.17.m1.2.2.4.2" xref="S3.SS1.p1.17.m1.2.2.4.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.17.m1.2.2.4.3" xref="S3.SS1.p1.17.m1.2.2.4.3.cmml"><mrow id="S3.SS1.p1.17.m1.2.2.4.3.2" xref="S3.SS1.p1.17.m1.2.2.4.3.2.cmml"><mi id="S3.SS1.p1.17.m1.2.2.4.3.2.2" xref="S3.SS1.p1.17.m1.2.2.4.3.2.2.cmml">D</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.17.m1.2.2.4.3.2.1" xref="S3.SS1.p1.17.m1.2.2.4.3.2.1.cmml">×</mo><mn id="S3.SS1.p1.17.m1.2.2.4.3.2.3" xref="S3.SS1.p1.17.m1.2.2.4.3.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p1.17.m1.2.2.4.3.1" xref="S3.SS1.p1.17.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.SS1.p1.17.m1.2.2.4.3.3" xref="S3.SS1.p1.17.m1.2.2.4.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.17.m1.2b"><apply id="S3.SS1.p1.17.m1.2.2.cmml" xref="S3.SS1.p1.17.m1.2.2"><in id="S3.SS1.p1.17.m1.2.2.3.cmml" xref="S3.SS1.p1.17.m1.2.2.3"></in><list id="S3.SS1.p1.17.m1.2.2.2.3.cmml" xref="S3.SS1.p1.17.m1.2.2.2.2"><apply id="S3.SS1.p1.17.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.17.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.17.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.17.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.17.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.17.m1.1.1.1.1.1.2">𝑊</ci><cn type="integer" id="S3.SS1.p1.17.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.17.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.17.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.17.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.17.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.17.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.17.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.17.m1.2.2.2.2.2.2">𝑊</ci><cn type="integer" id="S3.SS1.p1.17.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.17.m1.2.2.2.2.2.3">2</cn></apply></list><apply id="S3.SS1.p1.17.m1.2.2.4.cmml" xref="S3.SS1.p1.17.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.17.m1.2.2.4.1.cmml" xref="S3.SS1.p1.17.m1.2.2.4">superscript</csymbol><ci id="S3.SS1.p1.17.m1.2.2.4.2.cmml" xref="S3.SS1.p1.17.m1.2.2.4.2">ℝ</ci><apply id="S3.SS1.p1.17.m1.2.2.4.3.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3"><times id="S3.SS1.p1.17.m1.2.2.4.3.1.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3.1"></times><apply id="S3.SS1.p1.17.m1.2.2.4.3.2.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3.2"><times id="S3.SS1.p1.17.m1.2.2.4.3.2.1.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3.2.1"></times><ci id="S3.SS1.p1.17.m1.2.2.4.3.2.2.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3.2.2">𝐷</ci><cn type="integer" id="S3.SS1.p1.17.m1.2.2.4.3.2.3.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3.2.3">4</cn></apply><ci id="S3.SS1.p1.17.m1.2.2.4.3.3.cmml" xref="S3.SS1.p1.17.m1.2.2.4.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.17.m1.2c">W_{1},W_{2}\in\mathbb{R}^{D\times 4D}</annotation></semantics></math>.


<br class="ltx_break"><span id="S3.SS1.p1.17.1" class="ltx_text ltx_font_bold">Transformer Layer.</span> A typical Transformer layer usually consists of a MHA module and an FFN module as follows:</p>
<table id="S3.E4" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E4X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle{F}" display="inline"><semantics id="S3.E4X.2.1.1.m1.1a"><mi id="S3.E4X.2.1.1.m1.1.1" xref="S3.E4X.2.1.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.E4X.2.1.1.m1.1b"><ci id="S3.E4X.2.1.1.m1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.E4X.2.1.1.m1.1c">\displaystyle{F}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4X.3.2.2.m1.1" class="ltx_Math" alttext="\displaystyle=\texttt{Transformer-layer}(X)" display="inline"><semantics id="S3.E4X.3.2.2.m1.1a"><mrow id="S3.E4X.3.2.2.m1.1.2" xref="S3.E4X.3.2.2.m1.1.2.cmml"><mi id="S3.E4X.3.2.2.m1.1.2.2" xref="S3.E4X.3.2.2.m1.1.2.2.cmml"></mi><mo id="S3.E4X.3.2.2.m1.1.2.1" xref="S3.E4X.3.2.2.m1.1.2.1.cmml">=</mo><mrow id="S3.E4X.3.2.2.m1.1.2.3" xref="S3.E4X.3.2.2.m1.1.2.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E4X.3.2.2.m1.1.2.3.2" xref="S3.E4X.3.2.2.m1.1.2.3.2a.cmml">Transformer-layer</mtext><mo lspace="0em" rspace="0em" id="S3.E4X.3.2.2.m1.1.2.3.1" xref="S3.E4X.3.2.2.m1.1.2.3.1.cmml">​</mo><mrow id="S3.E4X.3.2.2.m1.1.2.3.3.2" xref="S3.E4X.3.2.2.m1.1.2.3.cmml"><mo stretchy="false" id="S3.E4X.3.2.2.m1.1.2.3.3.2.1" xref="S3.E4X.3.2.2.m1.1.2.3.cmml">(</mo><mi id="S3.E4X.3.2.2.m1.1.1" xref="S3.E4X.3.2.2.m1.1.1.cmml">X</mi><mo stretchy="false" id="S3.E4X.3.2.2.m1.1.2.3.3.2.2" xref="S3.E4X.3.2.2.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4X.3.2.2.m1.1b"><apply id="S3.E4X.3.2.2.m1.1.2.cmml" xref="S3.E4X.3.2.2.m1.1.2"><eq id="S3.E4X.3.2.2.m1.1.2.1.cmml" xref="S3.E4X.3.2.2.m1.1.2.1"></eq><csymbol cd="latexml" id="S3.E4X.3.2.2.m1.1.2.2.cmml" xref="S3.E4X.3.2.2.m1.1.2.2">absent</csymbol><apply id="S3.E4X.3.2.2.m1.1.2.3.cmml" xref="S3.E4X.3.2.2.m1.1.2.3"><times id="S3.E4X.3.2.2.m1.1.2.3.1.cmml" xref="S3.E4X.3.2.2.m1.1.2.3.1"></times><ci id="S3.E4X.3.2.2.m1.1.2.3.2a.cmml" xref="S3.E4X.3.2.2.m1.1.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.E4X.3.2.2.m1.1.2.3.2.cmml" xref="S3.E4X.3.2.2.m1.1.2.3.2">Transformer-layer</mtext></ci><ci id="S3.E4X.3.2.2.m1.1.1.cmml" xref="S3.E4X.3.2.2.m1.1.1">𝑋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4X.3.2.2.m1.1c">\displaystyle=\texttt{Transformer-layer}(X)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
<tr id="S3.E4Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4Xa.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle=\texttt{LN}(\texttt{FFN}(\hat{F})+\hat{F})" display="inline"><semantics id="S3.E4Xa.2.1.1.m1.2a"><mrow id="S3.E4Xa.2.1.1.m1.2.2" xref="S3.E4Xa.2.1.1.m1.2.2.cmml"><mi id="S3.E4Xa.2.1.1.m1.2.2.3" xref="S3.E4Xa.2.1.1.m1.2.2.3.cmml"></mi><mo id="S3.E4Xa.2.1.1.m1.2.2.2" xref="S3.E4Xa.2.1.1.m1.2.2.2.cmml">=</mo><mrow id="S3.E4Xa.2.1.1.m1.2.2.1" xref="S3.E4Xa.2.1.1.m1.2.2.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xa.2.1.1.m1.2.2.1.3" xref="S3.E4Xa.2.1.1.m1.2.2.1.3a.cmml">LN</mtext><mo lspace="0em" rspace="0em" id="S3.E4Xa.2.1.1.m1.2.2.1.2" xref="S3.E4Xa.2.1.1.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E4Xa.2.1.1.m1.2.2.1.1.1" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.2" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.2" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.2a.cmml">FFN</mtext><mo lspace="0em" rspace="0em" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.1" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.3.2" xref="S3.E4Xa.2.1.1.m1.1.1.cmml"><mo stretchy="false" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.3.2.1" xref="S3.E4Xa.2.1.1.m1.1.1.cmml">(</mo><mover accent="true" id="S3.E4Xa.2.1.1.m1.1.1" xref="S3.E4Xa.2.1.1.m1.1.1.cmml"><mi id="S3.E4Xa.2.1.1.m1.1.1.2" xref="S3.E4Xa.2.1.1.m1.1.1.2.cmml">F</mi><mo id="S3.E4Xa.2.1.1.m1.1.1.1" xref="S3.E4Xa.2.1.1.m1.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.3.2.2" xref="S3.E4Xa.2.1.1.m1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.1" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.1.cmml">+</mo><mover accent="true" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.2" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.2.cmml">F</mi><mo id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.1" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.3" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4Xa.2.1.1.m1.2b"><apply id="S3.E4Xa.2.1.1.m1.2.2.cmml" xref="S3.E4Xa.2.1.1.m1.2.2"><eq id="S3.E4Xa.2.1.1.m1.2.2.2.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.2"></eq><csymbol cd="latexml" id="S3.E4Xa.2.1.1.m1.2.2.3.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.3">absent</csymbol><apply id="S3.E4Xa.2.1.1.m1.2.2.1.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1"><times id="S3.E4Xa.2.1.1.m1.2.2.1.2.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.2"></times><ci id="S3.E4Xa.2.1.1.m1.2.2.1.3a.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.3"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xa.2.1.1.m1.2.2.1.3.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.3">LN</mtext></ci><apply id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1"><plus id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.1"></plus><apply id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2"><times id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.1"></times><ci id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.2a.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.2">FFN</mtext></ci><apply id="S3.E4Xa.2.1.1.m1.1.1.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.2.3.2"><ci id="S3.E4Xa.2.1.1.m1.1.1.1.cmml" xref="S3.E4Xa.2.1.1.m1.1.1.1">^</ci><ci id="S3.E4Xa.2.1.1.m1.1.1.2.cmml" xref="S3.E4Xa.2.1.1.m1.1.1.2">𝐹</ci></apply></apply><apply id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3"><ci id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.1">^</ci><ci id="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E4Xa.2.1.1.m1.2.2.1.1.1.1.3.2">𝐹</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4Xa.2.1.1.m1.2c">\displaystyle=\texttt{LN}(\texttt{FFN}(\hat{F})+\hat{F})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S3.E4Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4Xb.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\hat{F}" display="inline"><semantics id="S3.E4Xb.2.1.1.m1.1a"><mover accent="true" id="S3.E4Xb.2.1.1.m1.1.1" xref="S3.E4Xb.2.1.1.m1.1.1.cmml"><mi id="S3.E4Xb.2.1.1.m1.1.1.2" xref="S3.E4Xb.2.1.1.m1.1.1.2.cmml">F</mi><mo id="S3.E4Xb.2.1.1.m1.1.1.1" xref="S3.E4Xb.2.1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.E4Xb.2.1.1.m1.1b"><apply id="S3.E4Xb.2.1.1.m1.1.1.cmml" xref="S3.E4Xb.2.1.1.m1.1.1"><ci id="S3.E4Xb.2.1.1.m1.1.1.1.cmml" xref="S3.E4Xb.2.1.1.m1.1.1.1">^</ci><ci id="S3.E4Xb.2.1.1.m1.1.1.2.cmml" xref="S3.E4Xb.2.1.1.m1.1.1.2">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4Xb.2.1.1.m1.1c">\displaystyle\hat{F}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4Xb.3.2.2.m1.4" class="ltx_Math" alttext="\displaystyle=\texttt{LN}(\texttt{MHA}(X,X,X)+X)" display="inline"><semantics id="S3.E4Xb.3.2.2.m1.4a"><mrow id="S3.E4Xb.3.2.2.m1.4.4" xref="S3.E4Xb.3.2.2.m1.4.4.cmml"><mi id="S3.E4Xb.3.2.2.m1.4.4.3" xref="S3.E4Xb.3.2.2.m1.4.4.3.cmml"></mi><mo id="S3.E4Xb.3.2.2.m1.4.4.2" xref="S3.E4Xb.3.2.2.m1.4.4.2.cmml">=</mo><mrow id="S3.E4Xb.3.2.2.m1.4.4.1" xref="S3.E4Xb.3.2.2.m1.4.4.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xb.3.2.2.m1.4.4.1.3" xref="S3.E4Xb.3.2.2.m1.4.4.1.3a.cmml">LN</mtext><mo lspace="0em" rspace="0em" id="S3.E4Xb.3.2.2.m1.4.4.1.2" xref="S3.E4Xb.3.2.2.m1.4.4.1.2.cmml">​</mo><mrow id="S3.E4Xb.3.2.2.m1.4.4.1.1.1" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.2" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.cmml"><mrow id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.2" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.2a.cmml">MHA</mtext><mo lspace="0em" rspace="0em" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.1" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.2" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.2.1" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.1.cmml">(</mo><mi id="S3.E4Xb.3.2.2.m1.1.1" xref="S3.E4Xb.3.2.2.m1.1.1.cmml">X</mi><mo id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.2.2" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.1.cmml">,</mo><mi id="S3.E4Xb.3.2.2.m1.2.2" xref="S3.E4Xb.3.2.2.m1.2.2.cmml">X</mi><mo id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.2.3" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.1.cmml">,</mo><mi id="S3.E4Xb.3.2.2.m1.3.3" xref="S3.E4Xb.3.2.2.m1.3.3.cmml">X</mi><mo stretchy="false" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.2.4" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.1" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.1.cmml">+</mo><mi id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.3" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.3.cmml">X</mi></mrow><mo stretchy="false" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.3" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4Xb.3.2.2.m1.4b"><apply id="S3.E4Xb.3.2.2.m1.4.4.cmml" xref="S3.E4Xb.3.2.2.m1.4.4"><eq id="S3.E4Xb.3.2.2.m1.4.4.2.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.2"></eq><csymbol cd="latexml" id="S3.E4Xb.3.2.2.m1.4.4.3.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.3">absent</csymbol><apply id="S3.E4Xb.3.2.2.m1.4.4.1.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1"><times id="S3.E4Xb.3.2.2.m1.4.4.1.2.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.2"></times><ci id="S3.E4Xb.3.2.2.m1.4.4.1.3a.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.3"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xb.3.2.2.m1.4.4.1.3.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.3">LN</mtext></ci><apply id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1"><plus id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.1.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.1"></plus><apply id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2"><times id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.1.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.1"></times><ci id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.2a.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.2.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.2">MHA</mtext></ci><vector id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.1.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.2.3.2"><ci id="S3.E4Xb.3.2.2.m1.1.1.cmml" xref="S3.E4Xb.3.2.2.m1.1.1">𝑋</ci><ci id="S3.E4Xb.3.2.2.m1.2.2.cmml" xref="S3.E4Xb.3.2.2.m1.2.2">𝑋</ci><ci id="S3.E4Xb.3.2.2.m1.3.3.cmml" xref="S3.E4Xb.3.2.2.m1.3.3">𝑋</ci></vector></apply><ci id="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.3.cmml" xref="S3.E4Xb.3.2.2.m1.4.4.1.1.1.1.3">𝑋</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4Xb.3.2.2.m1.4c">\displaystyle=\texttt{LN}(\texttt{MHA}(X,X,X)+X)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S3.SS1.p1.19" class="ltx_p">where residual connection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> and layer normalization (LN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> are applied after the MHA and FFN modules. The LN module takes a <math id="S3.SS1.p1.18.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p1.18.m1.1a"><mi id="S3.SS1.p1.18.m1.1.1" xref="S3.SS1.p1.18.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.18.m1.1b"><ci id="S3.SS1.p1.18.m1.1.1.cmml" xref="S3.SS1.p1.18.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.18.m1.1c">D</annotation></semantics></math>-dimensional feature <math id="S3.SS1.p1.19.m2.1" class="ltx_Math" alttext="x\in X" display="inline"><semantics id="S3.SS1.p1.19.m2.1a"><mrow id="S3.SS1.p1.19.m2.1.1" xref="S3.SS1.p1.19.m2.1.1.cmml"><mi id="S3.SS1.p1.19.m2.1.1.2" xref="S3.SS1.p1.19.m2.1.1.2.cmml">x</mi><mo id="S3.SS1.p1.19.m2.1.1.1" xref="S3.SS1.p1.19.m2.1.1.1.cmml">∈</mo><mi id="S3.SS1.p1.19.m2.1.1.3" xref="S3.SS1.p1.19.m2.1.1.3.cmml">X</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.19.m2.1b"><apply id="S3.SS1.p1.19.m2.1.1.cmml" xref="S3.SS1.p1.19.m2.1.1"><in id="S3.SS1.p1.19.m2.1.1.1.cmml" xref="S3.SS1.p1.19.m2.1.1.1"></in><ci id="S3.SS1.p1.19.m2.1.1.2.cmml" xref="S3.SS1.p1.19.m2.1.1.2">𝑥</ci><ci id="S3.SS1.p1.19.m2.1.1.3.cmml" xref="S3.SS1.p1.19.m2.1.1.3">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.19.m2.1c">x\in X</annotation></semantics></math> as its input and performs normalization as follows to obtain the output feature:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="y=\texttt{LN}(x)=\gamma\frac{x-\mu}{\sqrt{\sigma^{2}-\epsilon}}+\beta" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.2" xref="S3.E5.m1.1.2.cmml"><mi id="S3.E5.m1.1.2.2" xref="S3.E5.m1.1.2.2.cmml">y</mi><mo id="S3.E5.m1.1.2.3" xref="S3.E5.m1.1.2.3.cmml">=</mo><mrow id="S3.E5.m1.1.2.4" xref="S3.E5.m1.1.2.4.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E5.m1.1.2.4.2" xref="S3.E5.m1.1.2.4.2a.cmml">LN</mtext><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.2.4.1" xref="S3.E5.m1.1.2.4.1.cmml">​</mo><mrow id="S3.E5.m1.1.2.4.3.2" xref="S3.E5.m1.1.2.4.cmml"><mo stretchy="false" id="S3.E5.m1.1.2.4.3.2.1" xref="S3.E5.m1.1.2.4.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E5.m1.1.2.4.3.2.2" xref="S3.E5.m1.1.2.4.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.1.2.5" xref="S3.E5.m1.1.2.5.cmml">=</mo><mrow id="S3.E5.m1.1.2.6" xref="S3.E5.m1.1.2.6.cmml"><mrow id="S3.E5.m1.1.2.6.2" xref="S3.E5.m1.1.2.6.2.cmml"><mi id="S3.E5.m1.1.2.6.2.2" xref="S3.E5.m1.1.2.6.2.2.cmml">γ</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.2.6.2.1" xref="S3.E5.m1.1.2.6.2.1.cmml">​</mo><mfrac id="S3.E5.m1.1.2.6.2.3" xref="S3.E5.m1.1.2.6.2.3.cmml"><mrow id="S3.E5.m1.1.2.6.2.3.2" xref="S3.E5.m1.1.2.6.2.3.2.cmml"><mi id="S3.E5.m1.1.2.6.2.3.2.2" xref="S3.E5.m1.1.2.6.2.3.2.2.cmml">x</mi><mo id="S3.E5.m1.1.2.6.2.3.2.1" xref="S3.E5.m1.1.2.6.2.3.2.1.cmml">−</mo><mi id="S3.E5.m1.1.2.6.2.3.2.3" xref="S3.E5.m1.1.2.6.2.3.2.3.cmml">μ</mi></mrow><msqrt id="S3.E5.m1.1.2.6.2.3.3" xref="S3.E5.m1.1.2.6.2.3.3.cmml"><mrow id="S3.E5.m1.1.2.6.2.3.3.2" xref="S3.E5.m1.1.2.6.2.3.3.2.cmml"><msup id="S3.E5.m1.1.2.6.2.3.3.2.2" xref="S3.E5.m1.1.2.6.2.3.3.2.2.cmml"><mi id="S3.E5.m1.1.2.6.2.3.3.2.2.2" xref="S3.E5.m1.1.2.6.2.3.3.2.2.2.cmml">σ</mi><mn id="S3.E5.m1.1.2.6.2.3.3.2.2.3" xref="S3.E5.m1.1.2.6.2.3.3.2.2.3.cmml">2</mn></msup><mo id="S3.E5.m1.1.2.6.2.3.3.2.1" xref="S3.E5.m1.1.2.6.2.3.3.2.1.cmml">−</mo><mi id="S3.E5.m1.1.2.6.2.3.3.2.3" xref="S3.E5.m1.1.2.6.2.3.3.2.3.cmml">ϵ</mi></mrow></msqrt></mfrac></mrow><mo id="S3.E5.m1.1.2.6.1" xref="S3.E5.m1.1.2.6.1.cmml">+</mo><mi id="S3.E5.m1.1.2.6.3" xref="S3.E5.m1.1.2.6.3.cmml">β</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.2.cmml" xref="S3.E5.m1.1.2"><and id="S3.E5.m1.1.2a.cmml" xref="S3.E5.m1.1.2"></and><apply id="S3.E5.m1.1.2b.cmml" xref="S3.E5.m1.1.2"><eq id="S3.E5.m1.1.2.3.cmml" xref="S3.E5.m1.1.2.3"></eq><ci id="S3.E5.m1.1.2.2.cmml" xref="S3.E5.m1.1.2.2">𝑦</ci><apply id="S3.E5.m1.1.2.4.cmml" xref="S3.E5.m1.1.2.4"><times id="S3.E5.m1.1.2.4.1.cmml" xref="S3.E5.m1.1.2.4.1"></times><ci id="S3.E5.m1.1.2.4.2a.cmml" xref="S3.E5.m1.1.2.4.2"><mtext class="ltx_mathvariant_monospace" id="S3.E5.m1.1.2.4.2.cmml" xref="S3.E5.m1.1.2.4.2">LN</mtext></ci><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑥</ci></apply></apply><apply id="S3.E5.m1.1.2c.cmml" xref="S3.E5.m1.1.2"><eq id="S3.E5.m1.1.2.5.cmml" xref="S3.E5.m1.1.2.5"></eq><share href="#S3.E5.m1.1.2.4.cmml" id="S3.E5.m1.1.2d.cmml" xref="S3.E5.m1.1.2"></share><apply id="S3.E5.m1.1.2.6.cmml" xref="S3.E5.m1.1.2.6"><plus id="S3.E5.m1.1.2.6.1.cmml" xref="S3.E5.m1.1.2.6.1"></plus><apply id="S3.E5.m1.1.2.6.2.cmml" xref="S3.E5.m1.1.2.6.2"><times id="S3.E5.m1.1.2.6.2.1.cmml" xref="S3.E5.m1.1.2.6.2.1"></times><ci id="S3.E5.m1.1.2.6.2.2.cmml" xref="S3.E5.m1.1.2.6.2.2">𝛾</ci><apply id="S3.E5.m1.1.2.6.2.3.cmml" xref="S3.E5.m1.1.2.6.2.3"><divide id="S3.E5.m1.1.2.6.2.3.1.cmml" xref="S3.E5.m1.1.2.6.2.3"></divide><apply id="S3.E5.m1.1.2.6.2.3.2.cmml" xref="S3.E5.m1.1.2.6.2.3.2"><minus id="S3.E5.m1.1.2.6.2.3.2.1.cmml" xref="S3.E5.m1.1.2.6.2.3.2.1"></minus><ci id="S3.E5.m1.1.2.6.2.3.2.2.cmml" xref="S3.E5.m1.1.2.6.2.3.2.2">𝑥</ci><ci id="S3.E5.m1.1.2.6.2.3.2.3.cmml" xref="S3.E5.m1.1.2.6.2.3.2.3">𝜇</ci></apply><apply id="S3.E5.m1.1.2.6.2.3.3.cmml" xref="S3.E5.m1.1.2.6.2.3.3"><root id="S3.E5.m1.1.2.6.2.3.3a.cmml" xref="S3.E5.m1.1.2.6.2.3.3"></root><apply id="S3.E5.m1.1.2.6.2.3.3.2.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2"><minus id="S3.E5.m1.1.2.6.2.3.3.2.1.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2.1"></minus><apply id="S3.E5.m1.1.2.6.2.3.3.2.2.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.2.6.2.3.3.2.2.1.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2.2">superscript</csymbol><ci id="S3.E5.m1.1.2.6.2.3.3.2.2.2.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2.2.2">𝜎</ci><cn type="integer" id="S3.E5.m1.1.2.6.2.3.3.2.2.3.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2.2.3">2</cn></apply><ci id="S3.E5.m1.1.2.6.2.3.3.2.3.cmml" xref="S3.E5.m1.1.2.6.2.3.3.2.3">italic-ϵ</ci></apply></apply></apply></apply><ci id="S3.E5.m1.1.2.6.3.cmml" xref="S3.E5.m1.1.2.6.3">𝛽</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">y=\texttt{LN}(x)=\gamma\frac{x-\mu}{\sqrt{\sigma^{2}-\epsilon}}+\beta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.22" class="ltx_p">where <math id="S3.SS1.p1.20.m1.2" class="ltx_Math" alttext="\mu,\sigma^{2}\in\mathbb{R}" display="inline"><semantics id="S3.SS1.p1.20.m1.2a"><mrow id="S3.SS1.p1.20.m1.2.2" xref="S3.SS1.p1.20.m1.2.2.cmml"><mrow id="S3.SS1.p1.20.m1.2.2.1.1" xref="S3.SS1.p1.20.m1.2.2.1.2.cmml"><mi id="S3.SS1.p1.20.m1.1.1" xref="S3.SS1.p1.20.m1.1.1.cmml">μ</mi><mo id="S3.SS1.p1.20.m1.2.2.1.1.2" xref="S3.SS1.p1.20.m1.2.2.1.2.cmml">,</mo><msup id="S3.SS1.p1.20.m1.2.2.1.1.1" xref="S3.SS1.p1.20.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.20.m1.2.2.1.1.1.2" xref="S3.SS1.p1.20.m1.2.2.1.1.1.2.cmml">σ</mi><mn id="S3.SS1.p1.20.m1.2.2.1.1.1.3" xref="S3.SS1.p1.20.m1.2.2.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.SS1.p1.20.m1.2.2.2" xref="S3.SS1.p1.20.m1.2.2.2.cmml">∈</mo><mi id="S3.SS1.p1.20.m1.2.2.3" xref="S3.SS1.p1.20.m1.2.2.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.20.m1.2b"><apply id="S3.SS1.p1.20.m1.2.2.cmml" xref="S3.SS1.p1.20.m1.2.2"><in id="S3.SS1.p1.20.m1.2.2.2.cmml" xref="S3.SS1.p1.20.m1.2.2.2"></in><list id="S3.SS1.p1.20.m1.2.2.1.2.cmml" xref="S3.SS1.p1.20.m1.2.2.1.1"><ci id="S3.SS1.p1.20.m1.1.1.cmml" xref="S3.SS1.p1.20.m1.1.1">𝜇</ci><apply id="S3.SS1.p1.20.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.20.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.20.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.20.m1.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.20.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.20.m1.2.2.1.1.1.2">𝜎</ci><cn type="integer" id="S3.SS1.p1.20.m1.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.20.m1.2.2.1.1.1.3">2</cn></apply></list><ci id="S3.SS1.p1.20.m1.2.2.3.cmml" xref="S3.SS1.p1.20.m1.2.2.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.20.m1.2c">\mu,\sigma^{2}\in\mathbb{R}</annotation></semantics></math> are the mean and variance calculated on <math id="S3.SS1.p1.21.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p1.21.m2.1a"><mi id="S3.SS1.p1.21.m2.1.1" xref="S3.SS1.p1.21.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.21.m2.1b"><ci id="S3.SS1.p1.21.m2.1.1.cmml" xref="S3.SS1.p1.21.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.21.m2.1c">x</annotation></semantics></math>. <math id="S3.SS1.p1.22.m3.2" class="ltx_Math" alttext="\gamma,\beta\in\mathbb{R}^{D}" display="inline"><semantics id="S3.SS1.p1.22.m3.2a"><mrow id="S3.SS1.p1.22.m3.2.3" xref="S3.SS1.p1.22.m3.2.3.cmml"><mrow id="S3.SS1.p1.22.m3.2.3.2.2" xref="S3.SS1.p1.22.m3.2.3.2.1.cmml"><mi id="S3.SS1.p1.22.m3.1.1" xref="S3.SS1.p1.22.m3.1.1.cmml">γ</mi><mo id="S3.SS1.p1.22.m3.2.3.2.2.1" xref="S3.SS1.p1.22.m3.2.3.2.1.cmml">,</mo><mi id="S3.SS1.p1.22.m3.2.2" xref="S3.SS1.p1.22.m3.2.2.cmml">β</mi></mrow><mo id="S3.SS1.p1.22.m3.2.3.1" xref="S3.SS1.p1.22.m3.2.3.1.cmml">∈</mo><msup id="S3.SS1.p1.22.m3.2.3.3" xref="S3.SS1.p1.22.m3.2.3.3.cmml"><mi id="S3.SS1.p1.22.m3.2.3.3.2" xref="S3.SS1.p1.22.m3.2.3.3.2.cmml">ℝ</mi><mi id="S3.SS1.p1.22.m3.2.3.3.3" xref="S3.SS1.p1.22.m3.2.3.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.22.m3.2b"><apply id="S3.SS1.p1.22.m3.2.3.cmml" xref="S3.SS1.p1.22.m3.2.3"><in id="S3.SS1.p1.22.m3.2.3.1.cmml" xref="S3.SS1.p1.22.m3.2.3.1"></in><list id="S3.SS1.p1.22.m3.2.3.2.1.cmml" xref="S3.SS1.p1.22.m3.2.3.2.2"><ci id="S3.SS1.p1.22.m3.1.1.cmml" xref="S3.SS1.p1.22.m3.1.1">𝛾</ci><ci id="S3.SS1.p1.22.m3.2.2.cmml" xref="S3.SS1.p1.22.m3.2.2">𝛽</ci></list><apply id="S3.SS1.p1.22.m3.2.3.3.cmml" xref="S3.SS1.p1.22.m3.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.22.m3.2.3.3.1.cmml" xref="S3.SS1.p1.22.m3.2.3.3">superscript</csymbol><ci id="S3.SS1.p1.22.m3.2.3.3.2.cmml" xref="S3.SS1.p1.22.m3.2.3.3.2">ℝ</ci><ci id="S3.SS1.p1.22.m3.2.3.3.3.cmml" xref="S3.SS1.p1.22.m3.2.3.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.22.m3.2c">\gamma,\beta\in\mathbb{R}^{D}</annotation></semantics></math> are the learnable parameters of the scale and shift terms, respectively.

<br class="ltx_break"><span id="S3.SS1.p1.22.1" class="ltx_text ltx_font_bold">Transformer Architectures.</span> Depending on the composition strategies of the Transformer layers above, existing Transformer architectures can be categorized into three classes, namely encoders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>, decoders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>, and encoder-decoders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.12814/assets/x2.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="233" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">The general BST framework supports both width and depth slimming</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.12814/assets/x3.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="408" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Integration of BST into existing VQA models</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">(a) The overall diagram of the proposed Bilaterally Slimmable Transformer (BST) framework, which consists of width slimming and depth slimming. (b) The integration of the BST framework and three typical Transformer-based VQA models, namely MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, respectively. The parameters in the input and output embedding layers (yellow background) are not slimmable as dimensionality of the input and output features remains the same.</span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Taking a sequence of input tokens, the original Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> adopts an encoder-decoder architecture. The encoder is composed of a cascade of Transformer layers in depth to obtain the bidirectional representations by jointly conditioning on both the left and right contexts, and the decoder takes the representations from the last encoder layer as input to guide the learning of unidirectional representations by conditioning only on the left context. After that, pure encoder architectures (<em id="S3.SS1.p2.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>) and pure decoder architectures (<em id="S3.SS1.p2.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, GPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>) are introduced and integrated with the self-supervised pretraining paradigm, which has been used in a wide range of NLP tasks.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">The BST Framework</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">Let an <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">L</annotation></semantics></math>-layer Transformer with hidden dimensionality <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">D</annotation></semantics></math> be the reference model, where <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">D</annotation></semantics></math> and <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">L</annotation></semantics></math> denote the width and depth of the model, respectively. The goal of BST is to obtain a single <em id="S3.SS2.p1.4.1" class="ltx_emph ltx_font_italic">slimmable</em> Transformer model that can adaptively adjust to a set of submodels of different widths and depths in the inference stage. In the following, we introduce the width slimming and depth slimming strategies. An overview of the BST framework is shown in Fig. <a href="#S3.F3.sf1" title="In Figure 3 ‣ III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.2" class="ltx_p"><span id="S3.SS2.p2.2.1" class="ltx_text ltx_font_bold">Width Slimming.</span> With width slimming, we aim to make each Transformer layer adapt to a set of width slimming ratios with respect to the hidden dimensionality <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">d</annotation></semantics></math> of the reference model. To achieve this goal, we split the parameters of the reference model into different submodels, with each sharing a specific portion of its model parameters. As shown in Eqs.(<a href="#S3.Ex1" title="III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>), (<a href="#S3.E3" title="In III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), and (<a href="#S3.E5" title="In III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), the learnable parameters in the MHA and FFN modules are all linear projections, which can be simply split into submatrices with respect to the given ratios. Inspired by the settings in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we define the candidate width set as <math id="S3.SS2.p2.2.m2.4" class="ltx_Math" alttext="\mathcal{D}=\{{1}/{4}D,{1}/{2}D,{3}/{4}D,D\}" display="inline"><semantics id="S3.SS2.p2.2.m2.4a"><mrow id="S3.SS2.p2.2.m2.4.4" xref="S3.SS2.p2.2.m2.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.2.m2.4.4.5" xref="S3.SS2.p2.2.m2.4.4.5.cmml">𝒟</mi><mo id="S3.SS2.p2.2.m2.4.4.4" xref="S3.SS2.p2.2.m2.4.4.4.cmml">=</mo><mrow id="S3.SS2.p2.2.m2.4.4.3.3" xref="S3.SS2.p2.2.m2.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS2.p2.2.m2.4.4.3.3.4" xref="S3.SS2.p2.2.m2.4.4.3.4.cmml">{</mo><mrow id="S3.SS2.p2.2.m2.2.2.1.1.1" xref="S3.SS2.p2.2.m2.2.2.1.1.1.cmml"><mrow id="S3.SS2.p2.2.m2.2.2.1.1.1.2" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.cmml"><mn id="S3.SS2.p2.2.m2.2.2.1.1.1.2.2" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.2.cmml">1</mn><mo id="S3.SS2.p2.2.m2.2.2.1.1.1.2.1" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.1.cmml">/</mo><mn id="S3.SS2.p2.2.m2.2.2.1.1.1.2.3" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.2.2.1.1.1.1" xref="S3.SS2.p2.2.m2.2.2.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p2.2.m2.2.2.1.1.1.3" xref="S3.SS2.p2.2.m2.2.2.1.1.1.3.cmml">D</mi></mrow><mo id="S3.SS2.p2.2.m2.4.4.3.3.5" xref="S3.SS2.p2.2.m2.4.4.3.4.cmml">,</mo><mrow id="S3.SS2.p2.2.m2.3.3.2.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.2.cmml"><mrow id="S3.SS2.p2.2.m2.3.3.2.2.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.cmml"><mn id="S3.SS2.p2.2.m2.3.3.2.2.2.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.2.cmml">1</mn><mo id="S3.SS2.p2.2.m2.3.3.2.2.2.2.1" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.1.cmml">/</mo><mn id="S3.SS2.p2.2.m2.3.3.2.2.2.2.3" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.3.cmml">2</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.3.3.2.2.2.1" xref="S3.SS2.p2.2.m2.3.3.2.2.2.1.cmml">​</mo><mi id="S3.SS2.p2.2.m2.3.3.2.2.2.3" xref="S3.SS2.p2.2.m2.3.3.2.2.2.3.cmml">D</mi></mrow><mo id="S3.SS2.p2.2.m2.4.4.3.3.6" xref="S3.SS2.p2.2.m2.4.4.3.4.cmml">,</mo><mrow id="S3.SS2.p2.2.m2.4.4.3.3.3" xref="S3.SS2.p2.2.m2.4.4.3.3.3.cmml"><mrow id="S3.SS2.p2.2.m2.4.4.3.3.3.2" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.cmml"><mn id="S3.SS2.p2.2.m2.4.4.3.3.3.2.2" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.2.cmml">3</mn><mo id="S3.SS2.p2.2.m2.4.4.3.3.3.2.1" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.1.cmml">/</mo><mn id="S3.SS2.p2.2.m2.4.4.3.3.3.2.3" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.4.4.3.3.3.1" xref="S3.SS2.p2.2.m2.4.4.3.3.3.1.cmml">​</mo><mi id="S3.SS2.p2.2.m2.4.4.3.3.3.3" xref="S3.SS2.p2.2.m2.4.4.3.3.3.3.cmml">D</mi></mrow><mo id="S3.SS2.p2.2.m2.4.4.3.3.7" xref="S3.SS2.p2.2.m2.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">D</mi><mo stretchy="false" id="S3.SS2.p2.2.m2.4.4.3.3.8" xref="S3.SS2.p2.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.4b"><apply id="S3.SS2.p2.2.m2.4.4.cmml" xref="S3.SS2.p2.2.m2.4.4"><eq id="S3.SS2.p2.2.m2.4.4.4.cmml" xref="S3.SS2.p2.2.m2.4.4.4"></eq><ci id="S3.SS2.p2.2.m2.4.4.5.cmml" xref="S3.SS2.p2.2.m2.4.4.5">𝒟</ci><set id="S3.SS2.p2.2.m2.4.4.3.4.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3"><apply id="S3.SS2.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1"><times id="S3.SS2.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.1"></times><apply id="S3.SS2.p2.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2"><divide id="S3.SS2.p2.2.m2.2.2.1.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.1"></divide><cn type="integer" id="S3.SS2.p2.2.m2.2.2.1.1.1.2.2.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.2">1</cn><cn type="integer" id="S3.SS2.p2.2.m2.2.2.1.1.1.2.3.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.3">4</cn></apply><ci id="S3.SS2.p2.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.3">𝐷</ci></apply><apply id="S3.SS2.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2"><times id="S3.SS2.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.1"></times><apply id="S3.SS2.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2"><divide id="S3.SS2.p2.2.m2.3.3.2.2.2.2.1.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.1"></divide><cn type="integer" id="S3.SS2.p2.2.m2.3.3.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.2">1</cn><cn type="integer" id="S3.SS2.p2.2.m2.3.3.2.2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.3">2</cn></apply><ci id="S3.SS2.p2.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.3">𝐷</ci></apply><apply id="S3.SS2.p2.2.m2.4.4.3.3.3.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3"><times id="S3.SS2.p2.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.1"></times><apply id="S3.SS2.p2.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2"><divide id="S3.SS2.p2.2.m2.4.4.3.3.3.2.1.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.1"></divide><cn type="integer" id="S3.SS2.p2.2.m2.4.4.3.3.3.2.2.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.2">3</cn><cn type="integer" id="S3.SS2.p2.2.m2.4.4.3.3.3.2.3.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.3">4</cn></apply><ci id="S3.SS2.p2.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.3">𝐷</ci></apply><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝐷</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.4c">\mathcal{D}=\{{1}/{4}D,{1}/{2}D,{3}/{4}D,D\}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.16" class="ltx_p">Given a slimmed width <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="d\in\mathcal{D}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">d</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><in id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></in><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑑</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">d\in\mathcal{D}</annotation></semantics></math>, we need to prune the model parameters in the MHA, FFN, and LN modules according to <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">d</annotation></semantics></math>. In the MHA module, the query, key, and value parameters over <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">H</annotation></semantics></math> heads can be represented as tiled matrices <math id="S3.SS2.p3.4.m4.3" class="ltx_Math" alttext="W^{Q},W^{K},W^{V}\in\mathbb{R}^{D\times D_{H}*H}" display="inline"><semantics id="S3.SS2.p3.4.m4.3a"><mrow id="S3.SS2.p3.4.m4.3.3" xref="S3.SS2.p3.4.m4.3.3.cmml"><mrow id="S3.SS2.p3.4.m4.3.3.3.3" xref="S3.SS2.p3.4.m4.3.3.3.4.cmml"><msup id="S3.SS2.p3.4.m4.1.1.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.1.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.1.1.1.1.1.3.cmml">Q</mi></msup><mo id="S3.SS2.p3.4.m4.3.3.3.3.4" xref="S3.SS2.p3.4.m4.3.3.3.4.cmml">,</mo><msup id="S3.SS2.p3.4.m4.2.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.4.m4.2.2.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.2.2.2.cmml">W</mi><mi id="S3.SS2.p3.4.m4.2.2.2.2.2.3" xref="S3.SS2.p3.4.m4.2.2.2.2.2.3.cmml">K</mi></msup><mo id="S3.SS2.p3.4.m4.3.3.3.3.5" xref="S3.SS2.p3.4.m4.3.3.3.4.cmml">,</mo><msup id="S3.SS2.p3.4.m4.3.3.3.3.3" xref="S3.SS2.p3.4.m4.3.3.3.3.3.cmml"><mi id="S3.SS2.p3.4.m4.3.3.3.3.3.2" xref="S3.SS2.p3.4.m4.3.3.3.3.3.2.cmml">W</mi><mi id="S3.SS2.p3.4.m4.3.3.3.3.3.3" xref="S3.SS2.p3.4.m4.3.3.3.3.3.3.cmml">V</mi></msup></mrow><mo id="S3.SS2.p3.4.m4.3.3.4" xref="S3.SS2.p3.4.m4.3.3.4.cmml">∈</mo><msup id="S3.SS2.p3.4.m4.3.3.5" xref="S3.SS2.p3.4.m4.3.3.5.cmml"><mi id="S3.SS2.p3.4.m4.3.3.5.2" xref="S3.SS2.p3.4.m4.3.3.5.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.4.m4.3.3.5.3" xref="S3.SS2.p3.4.m4.3.3.5.3.cmml"><mrow id="S3.SS2.p3.4.m4.3.3.5.3.2" xref="S3.SS2.p3.4.m4.3.3.5.3.2.cmml"><mi id="S3.SS2.p3.4.m4.3.3.5.3.2.2" xref="S3.SS2.p3.4.m4.3.3.5.3.2.2.cmml">D</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.4.m4.3.3.5.3.2.1" xref="S3.SS2.p3.4.m4.3.3.5.3.2.1.cmml">×</mo><msub id="S3.SS2.p3.4.m4.3.3.5.3.2.3" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3.cmml"><mi id="S3.SS2.p3.4.m4.3.3.5.3.2.3.2" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3.2.cmml">D</mi><mi id="S3.SS2.p3.4.m4.3.3.5.3.2.3.3" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3.3.cmml">H</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.4.m4.3.3.5.3.1" xref="S3.SS2.p3.4.m4.3.3.5.3.1.cmml">∗</mo><mi id="S3.SS2.p3.4.m4.3.3.5.3.3" xref="S3.SS2.p3.4.m4.3.3.5.3.3.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.3b"><apply id="S3.SS2.p3.4.m4.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3"><in id="S3.SS2.p3.4.m4.3.3.4.cmml" xref="S3.SS2.p3.4.m4.3.3.4"></in><list id="S3.SS2.p3.4.m4.3.3.3.4.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3"><apply id="S3.SS2.p3.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.3">𝑄</ci></apply><apply id="S3.SS2.p3.4.m4.2.2.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2">superscript</csymbol><ci id="S3.SS2.p3.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2.2">𝑊</ci><ci id="S3.SS2.p3.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2.3">𝐾</ci></apply><apply id="S3.SS2.p3.4.m4.3.3.3.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.3.3.3.3.3.1.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3.3">superscript</csymbol><ci id="S3.SS2.p3.4.m4.3.3.3.3.3.2.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3.3.2">𝑊</ci><ci id="S3.SS2.p3.4.m4.3.3.3.3.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3.3.3">𝑉</ci></apply></list><apply id="S3.SS2.p3.4.m4.3.3.5.cmml" xref="S3.SS2.p3.4.m4.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.3.3.5.1.cmml" xref="S3.SS2.p3.4.m4.3.3.5">superscript</csymbol><ci id="S3.SS2.p3.4.m4.3.3.5.2.cmml" xref="S3.SS2.p3.4.m4.3.3.5.2">ℝ</ci><apply id="S3.SS2.p3.4.m4.3.3.5.3.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3"><times id="S3.SS2.p3.4.m4.3.3.5.3.1.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.1"></times><apply id="S3.SS2.p3.4.m4.3.3.5.3.2.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2"><times id="S3.SS2.p3.4.m4.3.3.5.3.2.1.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2.1"></times><ci id="S3.SS2.p3.4.m4.3.3.5.3.2.2.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2.2">𝐷</ci><apply id="S3.SS2.p3.4.m4.3.3.5.3.2.3.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.3.3.5.3.2.3.1.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3">subscript</csymbol><ci id="S3.SS2.p3.4.m4.3.3.5.3.2.3.2.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3.2">𝐷</ci><ci id="S3.SS2.p3.4.m4.3.3.5.3.2.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.2.3.3">𝐻</ci></apply></apply><ci id="S3.SS2.p3.4.m4.3.3.5.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3.5.3.3">𝐻</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.3c">W^{Q},W^{K},W^{V}\in\mathbb{R}^{D\times D_{H}*H}</annotation></semantics></math>. Given the slimmed width <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">d</annotation></semantics></math>, we keep <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="D_{H}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">D</mi><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">H</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝐷</ci><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">D_{H}</annotation></semantics></math> as a constant and adjust the input dimensionality <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">D</annotation></semantics></math> and the number of heads <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><mi id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><ci id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">H</annotation></semantics></math> accordingly. This results in the slimmed model parameters <math id="S3.SS2.p3.9.m9.1" class="ltx_Math" alttext="\in\mathbb{R}^{d\times D_{H}*\hat{H}}" display="inline"><semantics id="S3.SS2.p3.9.m9.1a"><mrow id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml"></mi><mo id="S3.SS2.p3.9.m9.1.1.1" xref="S3.SS2.p3.9.m9.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml"><mi id="S3.SS2.p3.9.m9.1.1.3.2" xref="S3.SS2.p3.9.m9.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.9.m9.1.1.3.3" xref="S3.SS2.p3.9.m9.1.1.3.3.cmml"><mrow id="S3.SS2.p3.9.m9.1.1.3.3.2" xref="S3.SS2.p3.9.m9.1.1.3.3.2.cmml"><mi id="S3.SS2.p3.9.m9.1.1.3.3.2.2" xref="S3.SS2.p3.9.m9.1.1.3.3.2.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.9.m9.1.1.3.3.2.1" xref="S3.SS2.p3.9.m9.1.1.3.3.2.1.cmml">×</mo><msub id="S3.SS2.p3.9.m9.1.1.3.3.2.3" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3.cmml"><mi id="S3.SS2.p3.9.m9.1.1.3.3.2.3.2" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3.2.cmml">D</mi><mi id="S3.SS2.p3.9.m9.1.1.3.3.2.3.3" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3.3.cmml">H</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.9.m9.1.1.3.3.1" xref="S3.SS2.p3.9.m9.1.1.3.3.1.cmml">∗</mo><mover accent="true" id="S3.SS2.p3.9.m9.1.1.3.3.3" xref="S3.SS2.p3.9.m9.1.1.3.3.3.cmml"><mi id="S3.SS2.p3.9.m9.1.1.3.3.3.2" xref="S3.SS2.p3.9.m9.1.1.3.3.3.2.cmml">H</mi><mo id="S3.SS2.p3.9.m9.1.1.3.3.3.1" xref="S3.SS2.p3.9.m9.1.1.3.3.3.1.cmml">^</mo></mover></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><in id="S3.SS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1.1"></in><csymbol cd="latexml" id="S3.SS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.2">absent</csymbol><apply id="S3.SS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m9.1.1.3.1.cmml" xref="S3.SS2.p3.9.m9.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.9.m9.1.1.3.2.cmml" xref="S3.SS2.p3.9.m9.1.1.3.2">ℝ</ci><apply id="S3.SS2.p3.9.m9.1.1.3.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3"><times id="S3.SS2.p3.9.m9.1.1.3.3.1.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.1"></times><apply id="S3.SS2.p3.9.m9.1.1.3.3.2.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2"><times id="S3.SS2.p3.9.m9.1.1.3.3.2.1.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2.1"></times><ci id="S3.SS2.p3.9.m9.1.1.3.3.2.2.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2.2">𝑑</ci><apply id="S3.SS2.p3.9.m9.1.1.3.3.2.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m9.1.1.3.3.2.3.1.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3">subscript</csymbol><ci id="S3.SS2.p3.9.m9.1.1.3.3.2.3.2.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3.2">𝐷</ci><ci id="S3.SS2.p3.9.m9.1.1.3.3.2.3.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.2.3.3">𝐻</ci></apply></apply><apply id="S3.SS2.p3.9.m9.1.1.3.3.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.3"><ci id="S3.SS2.p3.9.m9.1.1.3.3.3.1.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.3.1">^</ci><ci id="S3.SS2.p3.9.m9.1.1.3.3.3.2.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3.3.2">𝐻</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">\in\mathbb{R}^{d\times D_{H}*\hat{H}}</annotation></semantics></math>, where <math id="S3.SS2.p3.10.m10.1" class="ltx_Math" alttext="\hat{H}=H*d/D" display="inline"><semantics id="S3.SS2.p3.10.m10.1a"><mrow id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml"><mover accent="true" id="S3.SS2.p3.10.m10.1.1.2" xref="S3.SS2.p3.10.m10.1.1.2.cmml"><mi id="S3.SS2.p3.10.m10.1.1.2.2" xref="S3.SS2.p3.10.m10.1.1.2.2.cmml">H</mi><mo id="S3.SS2.p3.10.m10.1.1.2.1" xref="S3.SS2.p3.10.m10.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS2.p3.10.m10.1.1.1" xref="S3.SS2.p3.10.m10.1.1.1.cmml">=</mo><mrow id="S3.SS2.p3.10.m10.1.1.3" xref="S3.SS2.p3.10.m10.1.1.3.cmml"><mrow id="S3.SS2.p3.10.m10.1.1.3.2" xref="S3.SS2.p3.10.m10.1.1.3.2.cmml"><mi id="S3.SS2.p3.10.m10.1.1.3.2.2" xref="S3.SS2.p3.10.m10.1.1.3.2.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.10.m10.1.1.3.2.1" xref="S3.SS2.p3.10.m10.1.1.3.2.1.cmml">∗</mo><mi id="S3.SS2.p3.10.m10.1.1.3.2.3" xref="S3.SS2.p3.10.m10.1.1.3.2.3.cmml">d</mi></mrow><mo id="S3.SS2.p3.10.m10.1.1.3.1" xref="S3.SS2.p3.10.m10.1.1.3.1.cmml">/</mo><mi id="S3.SS2.p3.10.m10.1.1.3.3" xref="S3.SS2.p3.10.m10.1.1.3.3.cmml">D</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><apply id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1"><eq id="S3.SS2.p3.10.m10.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1.1"></eq><apply id="S3.SS2.p3.10.m10.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2"><ci id="S3.SS2.p3.10.m10.1.1.2.1.cmml" xref="S3.SS2.p3.10.m10.1.1.2.1">^</ci><ci id="S3.SS2.p3.10.m10.1.1.2.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2.2">𝐻</ci></apply><apply id="S3.SS2.p3.10.m10.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3"><divide id="S3.SS2.p3.10.m10.1.1.3.1.cmml" xref="S3.SS2.p3.10.m10.1.1.3.1"></divide><apply id="S3.SS2.p3.10.m10.1.1.3.2.cmml" xref="S3.SS2.p3.10.m10.1.1.3.2"><times id="S3.SS2.p3.10.m10.1.1.3.2.1.cmml" xref="S3.SS2.p3.10.m10.1.1.3.2.1"></times><ci id="S3.SS2.p3.10.m10.1.1.3.2.2.cmml" xref="S3.SS2.p3.10.m10.1.1.3.2.2">𝐻</ci><ci id="S3.SS2.p3.10.m10.1.1.3.2.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3.2.3">𝑑</ci></apply><ci id="S3.SS2.p3.10.m10.1.1.3.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">\hat{H}=H*d/D</annotation></semantics></math> refers to the reduced number of heads with the last few heads neglected. The model parameters <math id="S3.SS2.p3.11.m11.1" class="ltx_Math" alttext="W^{o}" display="inline"><semantics id="S3.SS2.p3.11.m11.1a"><msup id="S3.SS2.p3.11.m11.1.1" xref="S3.SS2.p3.11.m11.1.1.cmml"><mi id="S3.SS2.p3.11.m11.1.1.2" xref="S3.SS2.p3.11.m11.1.1.2.cmml">W</mi><mi id="S3.SS2.p3.11.m11.1.1.3" xref="S3.SS2.p3.11.m11.1.1.3.cmml">o</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m11.1b"><apply id="S3.SS2.p3.11.m11.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m11.1.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1">superscript</csymbol><ci id="S3.SS2.p3.11.m11.1.1.2.cmml" xref="S3.SS2.p3.11.m11.1.1.2">𝑊</ci><ci id="S3.SS2.p3.11.m11.1.1.3.cmml" xref="S3.SS2.p3.11.m11.1.1.3">𝑜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m11.1c">W^{o}</annotation></semantics></math>, <math id="S3.SS2.p3.12.m12.1" class="ltx_Math" alttext="W_{1}" display="inline"><semantics id="S3.SS2.p3.12.m12.1a"><msub id="S3.SS2.p3.12.m12.1.1" xref="S3.SS2.p3.12.m12.1.1.cmml"><mi id="S3.SS2.p3.12.m12.1.1.2" xref="S3.SS2.p3.12.m12.1.1.2.cmml">W</mi><mn id="S3.SS2.p3.12.m12.1.1.3" xref="S3.SS2.p3.12.m12.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m12.1b"><apply id="S3.SS2.p3.12.m12.1.1.cmml" xref="S3.SS2.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m12.1.1.1.cmml" xref="S3.SS2.p3.12.m12.1.1">subscript</csymbol><ci id="S3.SS2.p3.12.m12.1.1.2.cmml" xref="S3.SS2.p3.12.m12.1.1.2">𝑊</ci><cn type="integer" id="S3.SS2.p3.12.m12.1.1.3.cmml" xref="S3.SS2.p3.12.m12.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m12.1c">W_{1}</annotation></semantics></math>, <math id="S3.SS2.p3.13.m13.1" class="ltx_Math" alttext="W_{2}" display="inline"><semantics id="S3.SS2.p3.13.m13.1a"><msub id="S3.SS2.p3.13.m13.1.1" xref="S3.SS2.p3.13.m13.1.1.cmml"><mi id="S3.SS2.p3.13.m13.1.1.2" xref="S3.SS2.p3.13.m13.1.1.2.cmml">W</mi><mn id="S3.SS2.p3.13.m13.1.1.3" xref="S3.SS2.p3.13.m13.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m13.1b"><apply id="S3.SS2.p3.13.m13.1.1.cmml" xref="S3.SS2.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m13.1.1.1.cmml" xref="S3.SS2.p3.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.p3.13.m13.1.1.2.cmml" xref="S3.SS2.p3.13.m13.1.1.2">𝑊</ci><cn type="integer" id="S3.SS2.p3.13.m13.1.1.3.cmml" xref="S3.SS2.p3.13.m13.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m13.1c">W_{2}</annotation></semantics></math>, <math id="S3.SS2.p3.14.m14.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS2.p3.14.m14.1a"><mi id="S3.SS2.p3.14.m14.1.1" xref="S3.SS2.p3.14.m14.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m14.1b"><ci id="S3.SS2.p3.14.m14.1.1.cmml" xref="S3.SS2.p3.14.m14.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m14.1c">\gamma</annotation></semantics></math>, and <math id="S3.SS2.p3.15.m15.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS2.p3.15.m15.1a"><mi id="S3.SS2.p3.15.m15.1.1" xref="S3.SS2.p3.15.m15.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.15.m15.1b"><ci id="S3.SS2.p3.15.m15.1.1.cmml" xref="S3.SS2.p3.15.m15.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.15.m15.1c">\beta</annotation></semantics></math> in the FFN and LN modules are adjusted in a similar manner by slimming the dimensionality of the input and output features to <math id="S3.SS2.p3.16.m16.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p3.16.m16.1a"><mi id="S3.SS2.p3.16.m16.1.1" xref="S3.SS2.p3.16.m16.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.16.m16.1b"><ci id="S3.SS2.p3.16.m16.1.1.cmml" xref="S3.SS2.p3.16.m16.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.16.m16.1c">d</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">In addition to the strategy introduced above, another width slimming strategy was investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. In contrast to our <em id="S3.SS2.p4.1.1" class="ltx_emph ltx_font_italic">slim-all</em> strategy that slims the dimensionality of the input, output, and intermediate representations simultaneously, they introduced an alternative <em id="S3.SS2.p4.1.2" class="ltx_emph ltx_font_italic">slim-intermediate</em> strategy that slims the dimensionality of the intermediate representation while keeping the rest unchanged. The <em id="S3.SS2.p4.1.3" class="ltx_emph ltx_font_italic">slim-intermediate</em> strategy results in a <em id="S3.SS2.p4.1.4" class="ltx_emph ltx_font_italic">bottleneck</em> structure with a low dimensional intermediate representation. This may break the carefully-designed structure of the Transformer (<em id="S3.SS2.p4.1.5" class="ltx_emph ltx_font_italic">e.g.</em>, the <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="D\rightarrow 4D\rightarrow D" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mrow id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">D</mi><mo stretchy="false" id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml">→</mo><mrow id="S3.SS2.p4.1.m1.1.1.4" xref="S3.SS2.p4.1.m1.1.1.4.cmml"><mn id="S3.SS2.p4.1.m1.1.1.4.2" xref="S3.SS2.p4.1.m1.1.1.4.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.4.1" xref="S3.SS2.p4.1.m1.1.1.4.1.cmml">​</mo><mi id="S3.SS2.p4.1.m1.1.1.4.3" xref="S3.SS2.p4.1.m1.1.1.4.3.cmml">D</mi></mrow><mo stretchy="false" id="S3.SS2.p4.1.m1.1.1.5" xref="S3.SS2.p4.1.m1.1.1.5.cmml">→</mo><mi id="S3.SS2.p4.1.m1.1.1.6" xref="S3.SS2.p4.1.m1.1.1.6.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><and id="S3.SS2.p4.1.m1.1.1a.cmml" xref="S3.SS2.p4.1.m1.1.1"></and><apply id="S3.SS2.p4.1.m1.1.1b.cmml" xref="S3.SS2.p4.1.m1.1.1"><ci id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">→</ci><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">𝐷</ci><apply id="S3.SS2.p4.1.m1.1.1.4.cmml" xref="S3.SS2.p4.1.m1.1.1.4"><times id="S3.SS2.p4.1.m1.1.1.4.1.cmml" xref="S3.SS2.p4.1.m1.1.1.4.1"></times><cn type="integer" id="S3.SS2.p4.1.m1.1.1.4.2.cmml" xref="S3.SS2.p4.1.m1.1.1.4.2">4</cn><ci id="S3.SS2.p4.1.m1.1.1.4.3.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3">𝐷</ci></apply></apply><apply id="S3.SS2.p4.1.m1.1.1c.cmml" xref="S3.SS2.p4.1.m1.1.1"><ci id="S3.SS2.p4.1.m1.1.1.5.cmml" xref="S3.SS2.p4.1.m1.1.1.5">→</ci><share href="#S3.SS2.p4.1.m1.1.1.4.cmml" id="S3.SS2.p4.1.m1.1.1d.cmml" xref="S3.SS2.p4.1.m1.1.1"></share><ci id="S3.SS2.p4.1.m1.1.1.6.cmml" xref="S3.SS2.p4.1.m1.1.1.6">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">D\rightarrow 4D\rightarrow D</annotation></semantics></math> structure in FFN).</p>
</div>
<div id="S3.SS2.p5" class="ltx_para ltx_noindent">
<p id="S3.SS2.p5.1" class="ltx_p"><span id="S3.SS2.p5.1.1" class="ltx_text ltx_font_bold">Depth Slimming.</span> With depth slimming, we aim to make the slimmed submodels adapt to a set of depth slimming ratios with respect to the maximum depth of the reference model. As the depth of a typical Transformer model is usually set to a multiple of 6, we define the candidate depth set as <math id="S3.SS2.p5.1.m1.4" class="ltx_Math" alttext="\mathcal{L}=\{{1}/{6}L,{1}/{3}L,{2}/{3}L,L\}" display="inline"><semantics id="S3.SS2.p5.1.m1.4a"><mrow id="S3.SS2.p5.1.m1.4.4" xref="S3.SS2.p5.1.m1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p5.1.m1.4.4.5" xref="S3.SS2.p5.1.m1.4.4.5.cmml">ℒ</mi><mo id="S3.SS2.p5.1.m1.4.4.4" xref="S3.SS2.p5.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS2.p5.1.m1.4.4.3.3" xref="S3.SS2.p5.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS2.p5.1.m1.4.4.3.3.4" xref="S3.SS2.p5.1.m1.4.4.3.4.cmml">{</mo><mrow id="S3.SS2.p5.1.m1.2.2.1.1.1" xref="S3.SS2.p5.1.m1.2.2.1.1.1.cmml"><mrow id="S3.SS2.p5.1.m1.2.2.1.1.1.2" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.cmml"><mn id="S3.SS2.p5.1.m1.2.2.1.1.1.2.2" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.2.cmml">1</mn><mo id="S3.SS2.p5.1.m1.2.2.1.1.1.2.1" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.1.cmml">/</mo><mn id="S3.SS2.p5.1.m1.2.2.1.1.1.2.3" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.3.cmml">6</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p5.1.m1.2.2.1.1.1.1" xref="S3.SS2.p5.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p5.1.m1.2.2.1.1.1.3" xref="S3.SS2.p5.1.m1.2.2.1.1.1.3.cmml">L</mi></mrow><mo id="S3.SS2.p5.1.m1.4.4.3.3.5" xref="S3.SS2.p5.1.m1.4.4.3.4.cmml">,</mo><mrow id="S3.SS2.p5.1.m1.3.3.2.2.2" xref="S3.SS2.p5.1.m1.3.3.2.2.2.cmml"><mrow id="S3.SS2.p5.1.m1.3.3.2.2.2.2" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.cmml"><mn id="S3.SS2.p5.1.m1.3.3.2.2.2.2.2" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.2.cmml">1</mn><mo id="S3.SS2.p5.1.m1.3.3.2.2.2.2.1" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.1.cmml">/</mo><mn id="S3.SS2.p5.1.m1.3.3.2.2.2.2.3" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.3.cmml">3</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p5.1.m1.3.3.2.2.2.1" xref="S3.SS2.p5.1.m1.3.3.2.2.2.1.cmml">​</mo><mi id="S3.SS2.p5.1.m1.3.3.2.2.2.3" xref="S3.SS2.p5.1.m1.3.3.2.2.2.3.cmml">L</mi></mrow><mo id="S3.SS2.p5.1.m1.4.4.3.3.6" xref="S3.SS2.p5.1.m1.4.4.3.4.cmml">,</mo><mrow id="S3.SS2.p5.1.m1.4.4.3.3.3" xref="S3.SS2.p5.1.m1.4.4.3.3.3.cmml"><mrow id="S3.SS2.p5.1.m1.4.4.3.3.3.2" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.cmml"><mn id="S3.SS2.p5.1.m1.4.4.3.3.3.2.2" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.2.cmml">2</mn><mo id="S3.SS2.p5.1.m1.4.4.3.3.3.2.1" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.1.cmml">/</mo><mn id="S3.SS2.p5.1.m1.4.4.3.3.3.2.3" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.3.cmml">3</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p5.1.m1.4.4.3.3.3.1" xref="S3.SS2.p5.1.m1.4.4.3.3.3.1.cmml">​</mo><mi id="S3.SS2.p5.1.m1.4.4.3.3.3.3" xref="S3.SS2.p5.1.m1.4.4.3.3.3.3.cmml">L</mi></mrow><mo id="S3.SS2.p5.1.m1.4.4.3.3.7" xref="S3.SS2.p5.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">L</mi><mo stretchy="false" id="S3.SS2.p5.1.m1.4.4.3.3.8" xref="S3.SS2.p5.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.4b"><apply id="S3.SS2.p5.1.m1.4.4.cmml" xref="S3.SS2.p5.1.m1.4.4"><eq id="S3.SS2.p5.1.m1.4.4.4.cmml" xref="S3.SS2.p5.1.m1.4.4.4"></eq><ci id="S3.SS2.p5.1.m1.4.4.5.cmml" xref="S3.SS2.p5.1.m1.4.4.5">ℒ</ci><set id="S3.SS2.p5.1.m1.4.4.3.4.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3"><apply id="S3.SS2.p5.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1"><times id="S3.SS2.p5.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1.1"></times><apply id="S3.SS2.p5.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2"><divide id="S3.SS2.p5.1.m1.2.2.1.1.1.2.1.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.1"></divide><cn type="integer" id="S3.SS2.p5.1.m1.2.2.1.1.1.2.2.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.2">1</cn><cn type="integer" id="S3.SS2.p5.1.m1.2.2.1.1.1.2.3.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1.2.3">6</cn></apply><ci id="S3.SS2.p5.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.2.2.1.1.1.3">𝐿</ci></apply><apply id="S3.SS2.p5.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2"><times id="S3.SS2.p5.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2.1"></times><apply id="S3.SS2.p5.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2"><divide id="S3.SS2.p5.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.1"></divide><cn type="integer" id="S3.SS2.p5.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.2">1</cn><cn type="integer" id="S3.SS2.p5.1.m1.3.3.2.2.2.2.3.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2.2.3">3</cn></apply><ci id="S3.SS2.p5.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS2.p5.1.m1.3.3.2.2.2.3">𝐿</ci></apply><apply id="S3.SS2.p5.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3"><times id="S3.SS2.p5.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3.1"></times><apply id="S3.SS2.p5.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2"><divide id="S3.SS2.p5.1.m1.4.4.3.3.3.2.1.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.1"></divide><cn type="integer" id="S3.SS2.p5.1.m1.4.4.3.3.3.2.2.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.2">2</cn><cn type="integer" id="S3.SS2.p5.1.m1.4.4.3.3.3.2.3.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3.2.3">3</cn></apply><ci id="S3.SS2.p5.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS2.p5.1.m1.4.4.3.3.3.3">𝐿</ci></apply><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">𝐿</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.4c">\mathcal{L}=\{{1}/{6}L,{1}/{3}L,{2}/{3}L,L\}</annotation></semantics></math>. Compared with the settings in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we explore the submodels with much shallow depth, resulting in more compact submodels suitable for mobile devices.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.2" class="ltx_p">To perform depth slimming, we first need to determine which layers are to be slimmed given a specific slimming depth <math id="S3.SS2.p6.1.m1.1" class="ltx_Math" alttext="l\in\mathcal{L}" display="inline"><semantics id="S3.SS2.p6.1.m1.1a"><mrow id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml"><mi id="S3.SS2.p6.1.m1.1.1.2" xref="S3.SS2.p6.1.m1.1.1.2.cmml">l</mi><mo id="S3.SS2.p6.1.m1.1.1.1" xref="S3.SS2.p6.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p6.1.m1.1.1.3" xref="S3.SS2.p6.1.m1.1.1.3.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><apply id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1"><in id="S3.SS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1.1"></in><ci id="S3.SS2.p6.1.m1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.1.1.2">𝑙</ci><ci id="S3.SS2.p6.1.m1.1.1.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">l\in\mathcal{L}</annotation></semantics></math>. As shown on the right side of Fig. <a href="#S3.F3.sf1" title="In Figure 3 ‣ III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>, we first assign an importance score to each layer using certain scoring strategies. After that, we select the top-<math id="S3.SS2.p6.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">l</annotation></semantics></math> layers with the largest scores and keep their original order. Here, we introduce three scoring strategies, which result in three types of slimming strategies: 1) the <em id="S3.SS2.p6.2.1" class="ltx_emph ltx_font_italic">slim-random</em> strategy is the most straightforward strategy, as it simply sets the importance scores to random values; 2) the <em id="S3.SS2.p6.2.2" class="ltx_emph ltx_font_italic">slim-first</em> (or <em id="S3.SS2.p6.2.3" class="ltx_emph ltx_font_italic">slim-last</em>) strategy sets the importance scores in ascending (or descending) order; 3) the <em id="S3.SS2.p6.2.4" class="ltx_emph ltx_font_italic">slim-middle</em> strategy sets the smallest scores to the middlemost layer and gradually increases the scores as it move toward the top and bottom layers. This strategy was inspired by the empirical studies in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>, in which the layers closer to the input and output are more important than the middle layers in the Transformer. We use the slim-middle strategy as the default option.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Integrating BST with Off-the-Shelf VQA Models</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">BST is a general framework that can be integrated with arbitrary Transformer-based VQA models in theory. In this paper, we choose three typical Transformer-based models, <em id="S3.SS3.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and CLIP-ViL<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, shown in Fig. <a href="#S3.F3.sf2" title="In Figure 3 ‣ III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>, to integrate with the proposed BST framework. Without loss of generality, the BST framework can also be applied to other Transformer-based models beyond the VQA task. Due to space limitations, we will not expand the description further.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.4" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">MCAN<math id="S3.SS3.p2.1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S3.SS3.p2.1.1.m1.1a"><msub id="S3.SS3.p2.1.1.m1.1.1" xref="S3.SS3.p2.1.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.1.m1.1.1a" xref="S3.SS3.p2.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p2.1.1.m1.1.1.1" xref="S3.SS3.p2.1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.1.m1.1b"><apply id="S3.SS3.p2.1.1.m1.1.1.cmml" xref="S3.SS3.p2.1.1.m1.1.1"><ci id="S3.SS3.p2.1.1.m1.1.1.1a.cmml" xref="S3.SS3.p2.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS3.p2.1.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>.</span> MCAN was the winning solution in the VQA Challenge 2019. It introduces an encoder-decoder-based Transformer architecture to model complex multimodal interactions and perform accurate visual reasoning. Specifically, the input question is encoded as a sequence of word embeddings using pretrained GloVE embeddings followed by an LSTM network. The input image is encoded as a group of object embeddings using a pretrained object detector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. After that, the multimodal embeddings are passed through an <math id="S3.SS3.p2.2.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p2.2.m1.1a"><mi id="S3.SS3.p2.2.m1.1.1" xref="S3.SS3.p2.2.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m1.1b"><ci id="S3.SS3.p2.2.m1.1.1.cmml" xref="S3.SS3.p2.2.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m1.1c">L</annotation></semantics></math>-layer encoder-decoder to obtain the attended output features. In the <math id="S3.SS3.p2.3.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p2.3.m2.1a"><mi id="S3.SS3.p2.3.m2.1.1" xref="S3.SS3.p2.3.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m2.1b"><ci id="S3.SS3.p2.3.m2.1.1.cmml" xref="S3.SS3.p2.3.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m2.1c">L</annotation></semantics></math>-layer question encoder, the word embeddings are transformed with a self-attention mechanism to obtain the attended question features of the same word length. The attended word features and visual embeddings are further fed into an <math id="S3.SS3.p2.4.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p2.4.m3.1a"><mi id="S3.SS3.p2.4.m3.1.1" xref="S3.SS3.p2.4.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m3.1b"><ci id="S3.SS3.p2.4.m3.1.1.cmml" xref="S3.SS3.p2.4.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m3.1c">L</annotation></semantics></math>-layer image decoder to obtain the attended image features with a guided-attention mechanism. On top of the attended question features and image features, two attentional reduction modules are devised to obtain a question feature and an image feature, respectively. Finally, the two feature vectors are simply fused and then fed to a linear classifier to predict the answer. The MCAN model can be trained from scratch in an end-to-end manner on a specific VQA dataset such as VQA-v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Since MCAN’s core components are the standard Transformer layers, the model can be seamlessly integrated with the BST framework to obtain a slimmable MCAN<math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1a" xref="S3.SS3.p3.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><ci id="S3.SS3.p3.1.m1.1.1.1a.cmml" xref="S3.SS3.p3.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> model. The width slimming strategy can be directly applied to each encoder and decoder layer in MCAN, and different depth slimming strategies can also be applied to drop a portion of the encoder and decoder layers simultaneously. Furthermore, the model parameters in the attention reduction module on top of the encoder-decoder are derived from two-layer MLPs, which can also be slimmed in width.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.4" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">UNITER<math id="S3.SS3.p4.1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S3.SS3.p4.1.1.m1.1a"><msub id="S3.SS3.p4.1.1.m1.1.1" xref="S3.SS3.p4.1.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.1.m1.1.1a" xref="S3.SS3.p4.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p4.1.1.m1.1.1.1" xref="S3.SS3.p4.1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.1.m1.1b"><apply id="S3.SS3.p4.1.1.m1.1.1.cmml" xref="S3.SS3.p4.1.1.m1.1.1"><ci id="S3.SS3.p4.1.1.m1.1.1.1a.cmml" xref="S3.SS3.p4.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS3.p4.1.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>.</span> UNITER is a representative vision-and-language pretraining (VLP) approach with an <math id="S3.SS3.p4.2.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p4.2.m1.1a"><mi id="S3.SS3.p4.2.m1.1.1" xref="S3.SS3.p4.2.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m1.1b"><ci id="S3.SS3.p4.2.m1.1.1.cmml" xref="S3.SS3.p4.2.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m1.1c">L</annotation></semantics></math>-layer Transformer encoder as its backbone. In contrast to MCAN’s <em id="S3.SS3.p4.4.2" class="ltx_emph ltx_font_italic">training-from-scratch</em> mechanism, UNITER utilizes a <em id="S3.SS3.p4.4.3" class="ltx_emph ltx_font_italic">vision-language pretraining</em> strategy to learn a generalized backbone model from massive image-text pairs, and then finetunes the backbone to adapt to different multimodal tasks. Specifically, for the VQA task, a task-specific head is appended on top of the backbone so that the representation of the predefined [<span id="S3.SS3.p4.4.4" class="ltx_text ltx_markedasmath ltx_font_typewriter">cls</span>] token is fed to a linear classifier to predict the answer. Based on the finetuned UNITER model for VQA, both width slimming and depth slimming are applied to its backbone to transform it into UNITER<math id="S3.SS3.p4.4.m3.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S3.SS3.p4.4.m3.1a"><msub id="S3.SS3.p4.4.m3.1.1" xref="S3.SS3.p4.4.m3.1.1.cmml"><mi id="S3.SS3.p4.4.m3.1.1a" xref="S3.SS3.p4.4.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p4.4.m3.1.1.1" xref="S3.SS3.p4.4.m3.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m3.1b"><apply id="S3.SS3.p4.4.m3.1.1.cmml" xref="S3.SS3.p4.4.m3.1.1"><ci id="S3.SS3.p4.4.m3.1.1.1a.cmml" xref="S3.SS3.p4.4.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS3.p4.4.m3.1.1.1.cmml" xref="S3.SS3.p4.4.m3.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m3.1c">{}_{\texttt{BST}}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para ltx_noindent">
<p id="S3.SS3.p5.2" class="ltx_p"><span id="S3.SS3.p5.1.1" class="ltx_text ltx_font_bold">CLIP-ViL<math id="S3.SS3.p5.1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S3.SS3.p5.1.1.m1.1a"><msub id="S3.SS3.p5.1.1.m1.1.1" xref="S3.SS3.p5.1.1.m1.1.1.cmml"><mi id="S3.SS3.p5.1.1.m1.1.1a" xref="S3.SS3.p5.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p5.1.1.m1.1.1.1" xref="S3.SS3.p5.1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.1.m1.1b"><apply id="S3.SS3.p5.1.1.m1.1.1.cmml" xref="S3.SS3.p5.1.1.m1.1.1"><ci id="S3.SS3.p5.1.1.m1.1.1.1a.cmml" xref="S3.SS3.p5.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS3.p5.1.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>.</span> CLIP-ViL shares the same Transformer architecture with UNITER but introduces a more powerful visual encoder to extract visual representations. Specifically, its visual encoder corresponds to a pretrained ResNet-50<math id="S3.SS3.p5.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS3.p5.2.m1.1a"><mo id="S3.SS3.p5.2.m1.1.1" xref="S3.SS3.p5.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m1.1b"><times id="S3.SS3.p5.2.m1.1.1.cmml" xref="S3.SS3.p5.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m1.1c">\times</annotation></semantics></math>4 model, which is pretrained on 400M image-text pairs by CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p">Note that the embedding layers in the above models are not slimmable, making the input dimensionality of the first Transformer layer unadjustable. This contradicts our width-slimming strategy. To address this issue, we insert a slimmable linear layer <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="W_{\mathrm{emb}}\in\mathbb{R}^{D\times D}" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><mrow id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><msub id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml"><mi id="S3.SS3.p6.1.m1.1.1.2.2" xref="S3.SS3.p6.1.m1.1.1.2.2.cmml">W</mi><mi id="S3.SS3.p6.1.m1.1.1.2.3" xref="S3.SS3.p6.1.m1.1.1.2.3.cmml">emb</mi></msub><mo id="S3.SS3.p6.1.m1.1.1.1" xref="S3.SS3.p6.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml"><mi id="S3.SS3.p6.1.m1.1.1.3.2" xref="S3.SS3.p6.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p6.1.m1.1.1.3.3" xref="S3.SS3.p6.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.p6.1.m1.1.1.3.3.2" xref="S3.SS3.p6.1.m1.1.1.3.3.2.cmml">D</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p6.1.m1.1.1.3.3.1" xref="S3.SS3.p6.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p6.1.m1.1.1.3.3.3" xref="S3.SS3.p6.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><in id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1.1"></in><apply id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.2.1.cmml" xref="S3.SS3.p6.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2.2">𝑊</ci><ci id="S3.SS3.p6.1.m1.1.1.2.3.cmml" xref="S3.SS3.p6.1.m1.1.1.2.3">emb</ci></apply><apply id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.3.1.cmml" xref="S3.SS3.p6.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.3.2.cmml" xref="S3.SS3.p6.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.p6.1.m1.1.1.3.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3.3"><times id="S3.SS3.p6.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p6.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.p6.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p6.1.m1.1.1.3.3.2">𝐷</ci><ci id="S3.SS3.p6.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">W_{\mathrm{emb}}\in\mathbb{R}^{D\times D}</annotation></semantics></math> between the embedder and backbone, and make it slimmable in width to adapt to the BST framework<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>For the UNITER<math id="footnote1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="footnote1.m1.1b"><msub id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml"><mi id="footnote1.m1.1.1b" xref="footnote1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="footnote1.m1.1.1.1" xref="footnote1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><apply id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1"><ci id="footnote1.m1.1.1.1a.cmml" xref="footnote1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="footnote1.m1.1.1.1.cmml" xref="footnote1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">{}_{\texttt{BST}}</annotation></semantics></math> and CLIP-ViL<math id="footnote1.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="footnote1.m2.1b"><msub id="footnote1.m2.1.1" xref="footnote1.m2.1.1.cmml"><mi id="footnote1.m2.1.1b" xref="footnote1.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="footnote1.m2.1.1.1" xref="footnote1.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="footnote1.m2.1c"><apply id="footnote1.m2.1.1.cmml" xref="footnote1.m2.1.1"><ci id="footnote1.m2.1.1.1a.cmml" xref="footnote1.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="footnote1.m2.1.1.1.cmml" xref="footnote1.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m2.1d">{}_{\texttt{BST}}</annotation></semantics></math> models with pretrained model parameters, <math id="footnote1.m3.1" class="ltx_Math" alttext="W_{\mathrm{emb}}" display="inline"><semantics id="footnote1.m3.1b"><msub id="footnote1.m3.1.1" xref="footnote1.m3.1.1.cmml"><mi id="footnote1.m3.1.1.2" xref="footnote1.m3.1.1.2.cmml">W</mi><mi id="footnote1.m3.1.1.3" xref="footnote1.m3.1.1.3.cmml">emb</mi></msub><annotation-xml encoding="MathML-Content" id="footnote1.m3.1c"><apply id="footnote1.m3.1.1.cmml" xref="footnote1.m3.1.1"><csymbol cd="ambiguous" id="footnote1.m3.1.1.1.cmml" xref="footnote1.m3.1.1">subscript</csymbol><ci id="footnote1.m3.1.1.2.cmml" xref="footnote1.m3.1.1.2">𝑊</ci><ci id="footnote1.m3.1.1.3.cmml" xref="footnote1.m3.1.1.3">emb</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m3.1d">W_{\mathrm{emb}}</annotation></semantics></math> is initialized with an identity matrix and updated with the entire model in an end-to-end manner.</span></span></span>.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para ltx_noindent">
<p id="S3.SS3.p7.6" class="ltx_p"><span id="S3.SS3.p7.6.1" class="ltx_text ltx_font_bold">Submodel Complexity Analysis.</span> Given a reference MCAN (UNITER or CLIP-ViL) model of width <math id="S3.SS3.p7.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS3.p7.1.m1.1a"><mi id="S3.SS3.p7.1.m1.1.1" xref="S3.SS3.p7.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.1.m1.1b"><ci id="S3.SS3.p7.1.m1.1.1.cmml" xref="S3.SS3.p7.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.1.m1.1c">D</annotation></semantics></math> and depth <math id="S3.SS3.p7.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p7.2.m2.1a"><mi id="S3.SS3.p7.2.m2.1.1" xref="S3.SS3.p7.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.2.m2.1b"><ci id="S3.SS3.p7.2.m2.1.1.cmml" xref="S3.SS3.p7.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.2.m2.1c">L</annotation></semantics></math>, its model size and FLOPs are both approximately proportional to <math id="S3.SS3.p7.3.m3.1" class="ltx_Math" alttext="O(D^{2}L)" display="inline"><semantics id="S3.SS3.p7.3.m3.1a"><mrow id="S3.SS3.p7.3.m3.1.1" xref="S3.SS3.p7.3.m3.1.1.cmml"><mi id="S3.SS3.p7.3.m3.1.1.3" xref="S3.SS3.p7.3.m3.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p7.3.m3.1.1.2" xref="S3.SS3.p7.3.m3.1.1.2.cmml">​</mo><mrow id="S3.SS3.p7.3.m3.1.1.1.1" xref="S3.SS3.p7.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p7.3.m3.1.1.1.1.2" xref="S3.SS3.p7.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p7.3.m3.1.1.1.1.1" xref="S3.SS3.p7.3.m3.1.1.1.1.1.cmml"><msup id="S3.SS3.p7.3.m3.1.1.1.1.1.2" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p7.3.m3.1.1.1.1.1.2.2" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2.2.cmml">D</mi><mn id="S3.SS3.p7.3.m3.1.1.1.1.1.2.3" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S3.SS3.p7.3.m3.1.1.1.1.1.1" xref="S3.SS3.p7.3.m3.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p7.3.m3.1.1.1.1.1.3" xref="S3.SS3.p7.3.m3.1.1.1.1.1.3.cmml">L</mi></mrow><mo stretchy="false" id="S3.SS3.p7.3.m3.1.1.1.1.3" xref="S3.SS3.p7.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.3.m3.1b"><apply id="S3.SS3.p7.3.m3.1.1.cmml" xref="S3.SS3.p7.3.m3.1.1"><times id="S3.SS3.p7.3.m3.1.1.2.cmml" xref="S3.SS3.p7.3.m3.1.1.2"></times><ci id="S3.SS3.p7.3.m3.1.1.3.cmml" xref="S3.SS3.p7.3.m3.1.1.3">𝑂</ci><apply id="S3.SS3.p7.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1"><times id="S3.SS3.p7.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1.1.1"></times><apply id="S3.SS3.p7.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p7.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2">superscript</csymbol><ci id="S3.SS3.p7.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2.2">𝐷</ci><cn type="integer" id="S3.SS3.p7.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1.1.2.3">2</cn></apply><ci id="S3.SS3.p7.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p7.3.m3.1.1.1.1.1.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.3.m3.1c">O(D^{2}L)</annotation></semantics></math> . This indicates that the computational cost of the smallest submodel <math id="S3.SS3.p7.4.m4.1" class="ltx_math_unparsed" alttext="a({1}/{4}D" display="inline"><semantics id="S3.SS3.p7.4.m4.1a"><mrow id="S3.SS3.p7.4.m4.1b"><mi id="S3.SS3.p7.4.m4.1.1">a</mi><mrow id="S3.SS3.p7.4.m4.1.2"><mo stretchy="false" id="S3.SS3.p7.4.m4.1.2.1">(</mo><mn id="S3.SS3.p7.4.m4.1.2.2">1</mn><mo id="S3.SS3.p7.4.m4.1.2.3">/</mo><mn id="S3.SS3.p7.4.m4.1.2.4">4</mn><mi id="S3.SS3.p7.4.m4.1.2.5">D</mi></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS3.p7.4.m4.1c">a({1}/{4}D</annotation></semantics></math>,<math id="S3.SS3.p7.5.m5.1" class="ltx_math_unparsed" alttext="{1}/{6}L)" display="inline"><semantics id="S3.SS3.p7.5.m5.1a"><mrow id="S3.SS3.p7.5.m5.1b"><mn id="S3.SS3.p7.5.m5.1.1">1</mn><mo id="S3.SS3.p7.5.m5.1.2">/</mo><mn id="S3.SS3.p7.5.m5.1.3">6</mn><mi id="S3.SS3.p7.5.m5.1.4">L</mi><mo stretchy="false" id="S3.SS3.p7.5.m5.1.5">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS3.p7.5.m5.1c">{1}/{6}L)</annotation></semantics></math> can be up to 96<math id="S3.SS3.p7.6.m6.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS3.p7.6.m6.1a"><mo id="S3.SS3.p7.6.m6.1.1" xref="S3.SS3.p7.6.m6.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.6.m6.1b"><times id="S3.SS3.p7.6.m6.1.1.cmml" xref="S3.SS3.p7.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.6.m6.1c">\times</annotation></semantics></math> smaller than that of the reference model. In practice, the scaling ratio between the submodels and the reference model is not that large. As shown in Fig. <a href="#S3.F3.sf2" title="In Figure 3 ‣ III-A Preliminaries ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>, the slimming strategies are only performed in the backbone while the embedders and the classifier are not involved. Their existence introduces an inescapable cost for all the slimmed submodels, limiting the computational overhead of the small submodels. More detailed results are given and analyzed in section <a href="#S4" title="IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Training Strategy for BST Models</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The training procedures of BST consists of a <em id="S3.SS4.p1.1.1" class="ltx_emph ltx_font_italic">submodel architecture selection</em> stage and a <em id="S3.SS4.p1.1.2" class="ltx_emph ltx_font_italic">knowledge distillation training</em> stage.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS4.p2.3" class="ltx_p"><span id="S3.SS4.p2.3.1" class="ltx_text ltx_font_bold">Submodel Architecture Selection.</span> By combining each width in <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">\mathcal{D}</annotation></semantics></math> with each depth in <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><ci id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">\mathcal{L}</annotation></semantics></math>, we obtain a set of submodel architectures <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><ci id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">\mathcal{A}</annotation></semantics></math> of different widths and depths as follows:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.2" class="ltx_Math" alttext="\mathcal{A}=\texttt{combination}(\mathcal{D},\mathcal{L})" display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.3" xref="S3.E6.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.2.3.2" xref="S3.E6.m1.2.3.2.cmml">𝒜</mi><mo id="S3.E6.m1.2.3.1" xref="S3.E6.m1.2.3.1.cmml">=</mo><mrow id="S3.E6.m1.2.3.3" xref="S3.E6.m1.2.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E6.m1.2.3.3.2" xref="S3.E6.m1.2.3.3.2a.cmml">combination</mtext><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.3.3.1" xref="S3.E6.m1.2.3.3.1.cmml">​</mo><mrow id="S3.E6.m1.2.3.3.3.2" xref="S3.E6.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.3.3.3.2.1" xref="S3.E6.m1.2.3.3.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">𝒟</mi><mo id="S3.E6.m1.2.3.3.3.2.2" xref="S3.E6.m1.2.3.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml">ℒ</mi><mo stretchy="false" id="S3.E6.m1.2.3.3.3.2.3" xref="S3.E6.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.3.cmml" xref="S3.E6.m1.2.3"><eq id="S3.E6.m1.2.3.1.cmml" xref="S3.E6.m1.2.3.1"></eq><ci id="S3.E6.m1.2.3.2.cmml" xref="S3.E6.m1.2.3.2">𝒜</ci><apply id="S3.E6.m1.2.3.3.cmml" xref="S3.E6.m1.2.3.3"><times id="S3.E6.m1.2.3.3.1.cmml" xref="S3.E6.m1.2.3.3.1"></times><ci id="S3.E6.m1.2.3.3.2a.cmml" xref="S3.E6.m1.2.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.E6.m1.2.3.3.2.cmml" xref="S3.E6.m1.2.3.3.2">combination</mtext></ci><interval closure="open" id="S3.E6.m1.2.3.3.3.1.cmml" xref="S3.E6.m1.2.3.3.3.2"><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">𝒟</ci><ci id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2">ℒ</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">\mathcal{A}=\texttt{combination}(\mathcal{D},\mathcal{L})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p2.8" class="ltx_p">where <math id="S3.SS4.p2.4.m1.2" class="ltx_Math" alttext="|\mathcal{A}|=|\mathcal{D}|" display="inline"><semantics id="S3.SS4.p2.4.m1.2a"><mrow id="S3.SS4.p2.4.m1.2.3" xref="S3.SS4.p2.4.m1.2.3.cmml"><mrow id="S3.SS4.p2.4.m1.2.3.2.2" xref="S3.SS4.p2.4.m1.2.3.2.1.cmml"><mo stretchy="false" id="S3.SS4.p2.4.m1.2.3.2.2.1" xref="S3.SS4.p2.4.m1.2.3.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.4.m1.1.1" xref="S3.SS4.p2.4.m1.1.1.cmml">𝒜</mi><mo stretchy="false" id="S3.SS4.p2.4.m1.2.3.2.2.2" xref="S3.SS4.p2.4.m1.2.3.2.1.1.cmml">|</mo></mrow><mo id="S3.SS4.p2.4.m1.2.3.1" xref="S3.SS4.p2.4.m1.2.3.1.cmml">=</mo><mrow id="S3.SS4.p2.4.m1.2.3.3.2" xref="S3.SS4.p2.4.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p2.4.m1.2.3.3.2.1" xref="S3.SS4.p2.4.m1.2.3.3.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.4.m1.2.2" xref="S3.SS4.p2.4.m1.2.2.cmml">𝒟</mi><mo stretchy="false" id="S3.SS4.p2.4.m1.2.3.3.2.2" xref="S3.SS4.p2.4.m1.2.3.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m1.2b"><apply id="S3.SS4.p2.4.m1.2.3.cmml" xref="S3.SS4.p2.4.m1.2.3"><eq id="S3.SS4.p2.4.m1.2.3.1.cmml" xref="S3.SS4.p2.4.m1.2.3.1"></eq><apply id="S3.SS4.p2.4.m1.2.3.2.1.cmml" xref="S3.SS4.p2.4.m1.2.3.2.2"><abs id="S3.SS4.p2.4.m1.2.3.2.1.1.cmml" xref="S3.SS4.p2.4.m1.2.3.2.2.1"></abs><ci id="S3.SS4.p2.4.m1.1.1.cmml" xref="S3.SS4.p2.4.m1.1.1">𝒜</ci></apply><apply id="S3.SS4.p2.4.m1.2.3.3.1.cmml" xref="S3.SS4.p2.4.m1.2.3.3.2"><abs id="S3.SS4.p2.4.m1.2.3.3.1.1.cmml" xref="S3.SS4.p2.4.m1.2.3.3.2.1"></abs><ci id="S3.SS4.p2.4.m1.2.2.cmml" xref="S3.SS4.p2.4.m1.2.2">𝒟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m1.2c">|\mathcal{A}|=|\mathcal{D}|</annotation></semantics></math>*<math id="S3.SS4.p2.5.m2.1" class="ltx_Math" alttext="|\mathcal{L}|" display="inline"><semantics id="S3.SS4.p2.5.m2.1a"><mrow id="S3.SS4.p2.5.m2.1.2.2" xref="S3.SS4.p2.5.m2.1.2.1.cmml"><mo stretchy="false" id="S3.SS4.p2.5.m2.1.2.2.1" xref="S3.SS4.p2.5.m2.1.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.5.m2.1.1" xref="S3.SS4.p2.5.m2.1.1.cmml">ℒ</mi><mo stretchy="false" id="S3.SS4.p2.5.m2.1.2.2.2" xref="S3.SS4.p2.5.m2.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m2.1b"><apply id="S3.SS4.p2.5.m2.1.2.1.cmml" xref="S3.SS4.p2.5.m2.1.2.2"><abs id="S3.SS4.p2.5.m2.1.2.1.1.cmml" xref="S3.SS4.p2.5.m2.1.2.2.1"></abs><ci id="S3.SS4.p2.5.m2.1.1.cmml" xref="S3.SS4.p2.5.m2.1.1">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m2.1c">|\mathcal{L}|</annotation></semantics></math>. Each architecture <math id="S3.SS4.p2.6.m3.2" class="ltx_Math" alttext="a(d,l)\in\mathcal{A}" display="inline"><semantics id="S3.SS4.p2.6.m3.2a"><mrow id="S3.SS4.p2.6.m3.2.3" xref="S3.SS4.p2.6.m3.2.3.cmml"><mrow id="S3.SS4.p2.6.m3.2.3.2" xref="S3.SS4.p2.6.m3.2.3.2.cmml"><mi id="S3.SS4.p2.6.m3.2.3.2.2" xref="S3.SS4.p2.6.m3.2.3.2.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.6.m3.2.3.2.1" xref="S3.SS4.p2.6.m3.2.3.2.1.cmml">​</mo><mrow id="S3.SS4.p2.6.m3.2.3.2.3.2" xref="S3.SS4.p2.6.m3.2.3.2.3.1.cmml"><mo stretchy="false" id="S3.SS4.p2.6.m3.2.3.2.3.2.1" xref="S3.SS4.p2.6.m3.2.3.2.3.1.cmml">(</mo><mi id="S3.SS4.p2.6.m3.1.1" xref="S3.SS4.p2.6.m3.1.1.cmml">d</mi><mo id="S3.SS4.p2.6.m3.2.3.2.3.2.2" xref="S3.SS4.p2.6.m3.2.3.2.3.1.cmml">,</mo><mi id="S3.SS4.p2.6.m3.2.2" xref="S3.SS4.p2.6.m3.2.2.cmml">l</mi><mo stretchy="false" id="S3.SS4.p2.6.m3.2.3.2.3.2.3" xref="S3.SS4.p2.6.m3.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.SS4.p2.6.m3.2.3.1" xref="S3.SS4.p2.6.m3.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.6.m3.2.3.3" xref="S3.SS4.p2.6.m3.2.3.3.cmml">𝒜</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m3.2b"><apply id="S3.SS4.p2.6.m3.2.3.cmml" xref="S3.SS4.p2.6.m3.2.3"><in id="S3.SS4.p2.6.m3.2.3.1.cmml" xref="S3.SS4.p2.6.m3.2.3.1"></in><apply id="S3.SS4.p2.6.m3.2.3.2.cmml" xref="S3.SS4.p2.6.m3.2.3.2"><times id="S3.SS4.p2.6.m3.2.3.2.1.cmml" xref="S3.SS4.p2.6.m3.2.3.2.1"></times><ci id="S3.SS4.p2.6.m3.2.3.2.2.cmml" xref="S3.SS4.p2.6.m3.2.3.2.2">𝑎</ci><interval closure="open" id="S3.SS4.p2.6.m3.2.3.2.3.1.cmml" xref="S3.SS4.p2.6.m3.2.3.2.3.2"><ci id="S3.SS4.p2.6.m3.1.1.cmml" xref="S3.SS4.p2.6.m3.1.1">𝑑</ci><ci id="S3.SS4.p2.6.m3.2.2.cmml" xref="S3.SS4.p2.6.m3.2.2">𝑙</ci></interval></apply><ci id="S3.SS4.p2.6.m3.2.3.3.cmml" xref="S3.SS4.p2.6.m3.2.3.3">𝒜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m3.2c">a(d,l)\in\mathcal{A}</annotation></semantics></math> corresponds to a combination of a specific width <math id="S3.SS4.p2.7.m4.1" class="ltx_Math" alttext="d\in\mathcal{D}" display="inline"><semantics id="S3.SS4.p2.7.m4.1a"><mrow id="S3.SS4.p2.7.m4.1.1" xref="S3.SS4.p2.7.m4.1.1.cmml"><mi id="S3.SS4.p2.7.m4.1.1.2" xref="S3.SS4.p2.7.m4.1.1.2.cmml">d</mi><mo id="S3.SS4.p2.7.m4.1.1.1" xref="S3.SS4.p2.7.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.7.m4.1.1.3" xref="S3.SS4.p2.7.m4.1.1.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m4.1b"><apply id="S3.SS4.p2.7.m4.1.1.cmml" xref="S3.SS4.p2.7.m4.1.1"><in id="S3.SS4.p2.7.m4.1.1.1.cmml" xref="S3.SS4.p2.7.m4.1.1.1"></in><ci id="S3.SS4.p2.7.m4.1.1.2.cmml" xref="S3.SS4.p2.7.m4.1.1.2">𝑑</ci><ci id="S3.SS4.p2.7.m4.1.1.3.cmml" xref="S3.SS4.p2.7.m4.1.1.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m4.1c">d\in\mathcal{D}</annotation></semantics></math> and depth <math id="S3.SS4.p2.8.m5.1" class="ltx_Math" alttext="l\in\mathcal{L}" display="inline"><semantics id="S3.SS4.p2.8.m5.1a"><mrow id="S3.SS4.p2.8.m5.1.1" xref="S3.SS4.p2.8.m5.1.1.cmml"><mi id="S3.SS4.p2.8.m5.1.1.2" xref="S3.SS4.p2.8.m5.1.1.2.cmml">l</mi><mo id="S3.SS4.p2.8.m5.1.1.1" xref="S3.SS4.p2.8.m5.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.8.m5.1.1.3" xref="S3.SS4.p2.8.m5.1.1.3.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.8.m5.1b"><apply id="S3.SS4.p2.8.m5.1.1.cmml" xref="S3.SS4.p2.8.m5.1.1"><in id="S3.SS4.p2.8.m5.1.1.1.cmml" xref="S3.SS4.p2.8.m5.1.1.1"></in><ci id="S3.SS4.p2.8.m5.1.1.2.cmml" xref="S3.SS4.p2.8.m5.1.1.2">𝑙</ci><ci id="S3.SS4.p2.8.m5.1.1.3.cmml" xref="S3.SS4.p2.8.m5.1.1.3">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.8.m5.1c">l\in\mathcal{L}</annotation></semantics></math>. In contrast to previous works that maintain all possible submodel architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we hypothesize that not every submodel architecture is effective. By the effectiveness of a submodel architecture, we mean the extent to which its computational cost (<em id="S3.SS4.p2.8.1" class="ltx_emph ltx_font_italic">e.g.</em>, in terms of FLOPs or model size) matches its delivered performance after model training. Therefore, devising a heuristic strategy to eliminate such ineffective architectures before BST training can reduce the training costs while improving the performance of the remaining submodels.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">According to previous studies on designing efficient Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, <em id="S3.SS4.p3.1.1" class="ltx_emph ltx_font_italic">deep and narrow</em> architectures usually deliver better performance than <em id="S3.SS4.p3.1.2" class="ltx_emph ltx_font_italic">shallow and wide</em> architectures under constrained computational costs. This principle can be explained in two ways: 1) The Transformer requires a relatively deep model to guarantee good performance; and 2) the computational cost of a Transformer model is proportional to <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="O(LD^{2})" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><mrow id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">​</mo><mrow id="S3.SS4.p3.1.m1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p3.1.m1.1.1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS4.p3.1.m1.1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.1.m1.1.1.1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.1.cmml">​</mo><msup id="S3.SS4.p3.1.m1.1.1.1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.1.m1.1.1.1.1.1.3.2" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.2.cmml">D</mi><mn id="S3.SS4.p3.1.m1.1.1.1.1.1.3.3" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.3.cmml">2</mn></msup></mrow><mo stretchy="false" id="S3.SS4.p3.1.m1.1.1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><times id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2"></times><ci id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3">𝑂</ci><apply id="S3.SS4.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1"><times id="S3.SS4.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.1"></times><ci id="S3.SS4.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.2">𝐿</ci><apply id="S3.SS4.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.2">𝐷</ci><cn type="integer" id="S3.SS4.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">O(LD^{2})</annotation></semantics></math>, suggesting that increasing depth is more economical than increasing width.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.7" class="ltx_p">To quantize this deep-and-narrow principle, we introduce a simple <em id="S3.SS4.p4.7.1" class="ltx_emph ltx_font_italic">triangle selection strategy</em> to filter out the shallow and wide submodel architectures. As shown in Fig. <a href="#S3.F4" title="Figure 4 ‣ III-D Training Strategy for BST Models ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we introduce a 2-D indicator matrix <math id="S3.SS4.p4.1.m1.4" class="ltx_Math" alttext="I\in\{0,1\}^{|\mathcal{D}|\times|\mathcal{L}|}" display="inline"><semantics id="S3.SS4.p4.1.m1.4a"><mrow id="S3.SS4.p4.1.m1.4.5" xref="S3.SS4.p4.1.m1.4.5.cmml"><mi id="S3.SS4.p4.1.m1.4.5.2" xref="S3.SS4.p4.1.m1.4.5.2.cmml">I</mi><mo id="S3.SS4.p4.1.m1.4.5.1" xref="S3.SS4.p4.1.m1.4.5.1.cmml">∈</mo><msup id="S3.SS4.p4.1.m1.4.5.3" xref="S3.SS4.p4.1.m1.4.5.3.cmml"><mrow id="S3.SS4.p4.1.m1.4.5.3.2.2" xref="S3.SS4.p4.1.m1.4.5.3.2.1.cmml"><mo stretchy="false" id="S3.SS4.p4.1.m1.4.5.3.2.2.1" xref="S3.SS4.p4.1.m1.4.5.3.2.1.cmml">{</mo><mn id="S3.SS4.p4.1.m1.3.3" xref="S3.SS4.p4.1.m1.3.3.cmml">0</mn><mo id="S3.SS4.p4.1.m1.4.5.3.2.2.2" xref="S3.SS4.p4.1.m1.4.5.3.2.1.cmml">,</mo><mn id="S3.SS4.p4.1.m1.4.4" xref="S3.SS4.p4.1.m1.4.4.cmml">1</mn><mo stretchy="false" id="S3.SS4.p4.1.m1.4.5.3.2.2.3" xref="S3.SS4.p4.1.m1.4.5.3.2.1.cmml">}</mo></mrow><mrow id="S3.SS4.p4.1.m1.2.2.2" xref="S3.SS4.p4.1.m1.2.2.2.cmml"><mrow id="S3.SS4.p4.1.m1.2.2.2.4.2" xref="S3.SS4.p4.1.m1.2.2.2.4.1.cmml"><mo stretchy="false" id="S3.SS4.p4.1.m1.2.2.2.4.2.1" xref="S3.SS4.p4.1.m1.2.2.2.4.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p4.1.m1.1.1.1.1" xref="S3.SS4.p4.1.m1.1.1.1.1.cmml">𝒟</mi><mo rspace="0.055em" stretchy="false" id="S3.SS4.p4.1.m1.2.2.2.4.2.2" xref="S3.SS4.p4.1.m1.2.2.2.4.1.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S3.SS4.p4.1.m1.2.2.2.3" xref="S3.SS4.p4.1.m1.2.2.2.3.cmml">×</mo><mrow id="S3.SS4.p4.1.m1.2.2.2.5.2" xref="S3.SS4.p4.1.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.SS4.p4.1.m1.2.2.2.5.2.1" xref="S3.SS4.p4.1.m1.2.2.2.5.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p4.1.m1.2.2.2.2" xref="S3.SS4.p4.1.m1.2.2.2.2.cmml">ℒ</mi><mo stretchy="false" id="S3.SS4.p4.1.m1.2.2.2.5.2.2" xref="S3.SS4.p4.1.m1.2.2.2.5.1.1.cmml">|</mo></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.4b"><apply id="S3.SS4.p4.1.m1.4.5.cmml" xref="S3.SS4.p4.1.m1.4.5"><in id="S3.SS4.p4.1.m1.4.5.1.cmml" xref="S3.SS4.p4.1.m1.4.5.1"></in><ci id="S3.SS4.p4.1.m1.4.5.2.cmml" xref="S3.SS4.p4.1.m1.4.5.2">𝐼</ci><apply id="S3.SS4.p4.1.m1.4.5.3.cmml" xref="S3.SS4.p4.1.m1.4.5.3"><csymbol cd="ambiguous" id="S3.SS4.p4.1.m1.4.5.3.1.cmml" xref="S3.SS4.p4.1.m1.4.5.3">superscript</csymbol><set id="S3.SS4.p4.1.m1.4.5.3.2.1.cmml" xref="S3.SS4.p4.1.m1.4.5.3.2.2"><cn type="integer" id="S3.SS4.p4.1.m1.3.3.cmml" xref="S3.SS4.p4.1.m1.3.3">0</cn><cn type="integer" id="S3.SS4.p4.1.m1.4.4.cmml" xref="S3.SS4.p4.1.m1.4.4">1</cn></set><apply id="S3.SS4.p4.1.m1.2.2.2.cmml" xref="S3.SS4.p4.1.m1.2.2.2"><times id="S3.SS4.p4.1.m1.2.2.2.3.cmml" xref="S3.SS4.p4.1.m1.2.2.2.3"></times><apply id="S3.SS4.p4.1.m1.2.2.2.4.1.cmml" xref="S3.SS4.p4.1.m1.2.2.2.4.2"><abs id="S3.SS4.p4.1.m1.2.2.2.4.1.1.cmml" xref="S3.SS4.p4.1.m1.2.2.2.4.2.1"></abs><ci id="S3.SS4.p4.1.m1.1.1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1.1.1">𝒟</ci></apply><apply id="S3.SS4.p4.1.m1.2.2.2.5.1.cmml" xref="S3.SS4.p4.1.m1.2.2.2.5.2"><abs id="S3.SS4.p4.1.m1.2.2.2.5.1.1.cmml" xref="S3.SS4.p4.1.m1.2.2.2.5.2.1"></abs><ci id="S3.SS4.p4.1.m1.2.2.2.2.cmml" xref="S3.SS4.p4.1.m1.2.2.2.2">ℒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.4c">I\in\{0,1\}^{|\mathcal{D}|\times|\mathcal{L}|}</annotation></semantics></math> to track the selection status for all the submodel architectures <math id="S3.SS4.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS4.p4.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p4.2.m2.1.1" xref="S3.SS4.p4.2.m2.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.2.m2.1b"><ci id="S3.SS4.p4.2.m2.1.1.cmml" xref="S3.SS4.p4.2.m2.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.2.m2.1c">\mathcal{A}</annotation></semantics></math>. <math id="S3.SS4.p4.3.m3.2" class="ltx_Math" alttext="I(d,l)=1" display="inline"><semantics id="S3.SS4.p4.3.m3.2a"><mrow id="S3.SS4.p4.3.m3.2.3" xref="S3.SS4.p4.3.m3.2.3.cmml"><mrow id="S3.SS4.p4.3.m3.2.3.2" xref="S3.SS4.p4.3.m3.2.3.2.cmml"><mi id="S3.SS4.p4.3.m3.2.3.2.2" xref="S3.SS4.p4.3.m3.2.3.2.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p4.3.m3.2.3.2.1" xref="S3.SS4.p4.3.m3.2.3.2.1.cmml">​</mo><mrow id="S3.SS4.p4.3.m3.2.3.2.3.2" xref="S3.SS4.p4.3.m3.2.3.2.3.1.cmml"><mo stretchy="false" id="S3.SS4.p4.3.m3.2.3.2.3.2.1" xref="S3.SS4.p4.3.m3.2.3.2.3.1.cmml">(</mo><mi id="S3.SS4.p4.3.m3.1.1" xref="S3.SS4.p4.3.m3.1.1.cmml">d</mi><mo id="S3.SS4.p4.3.m3.2.3.2.3.2.2" xref="S3.SS4.p4.3.m3.2.3.2.3.1.cmml">,</mo><mi id="S3.SS4.p4.3.m3.2.2" xref="S3.SS4.p4.3.m3.2.2.cmml">l</mi><mo stretchy="false" id="S3.SS4.p4.3.m3.2.3.2.3.2.3" xref="S3.SS4.p4.3.m3.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.SS4.p4.3.m3.2.3.1" xref="S3.SS4.p4.3.m3.2.3.1.cmml">=</mo><mn id="S3.SS4.p4.3.m3.2.3.3" xref="S3.SS4.p4.3.m3.2.3.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.3.m3.2b"><apply id="S3.SS4.p4.3.m3.2.3.cmml" xref="S3.SS4.p4.3.m3.2.3"><eq id="S3.SS4.p4.3.m3.2.3.1.cmml" xref="S3.SS4.p4.3.m3.2.3.1"></eq><apply id="S3.SS4.p4.3.m3.2.3.2.cmml" xref="S3.SS4.p4.3.m3.2.3.2"><times id="S3.SS4.p4.3.m3.2.3.2.1.cmml" xref="S3.SS4.p4.3.m3.2.3.2.1"></times><ci id="S3.SS4.p4.3.m3.2.3.2.2.cmml" xref="S3.SS4.p4.3.m3.2.3.2.2">𝐼</ci><interval closure="open" id="S3.SS4.p4.3.m3.2.3.2.3.1.cmml" xref="S3.SS4.p4.3.m3.2.3.2.3.2"><ci id="S3.SS4.p4.3.m3.1.1.cmml" xref="S3.SS4.p4.3.m3.1.1">𝑑</ci><ci id="S3.SS4.p4.3.m3.2.2.cmml" xref="S3.SS4.p4.3.m3.2.2">𝑙</ci></interval></apply><cn type="integer" id="S3.SS4.p4.3.m3.2.3.3.cmml" xref="S3.SS4.p4.3.m3.2.3.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.3.m3.2c">I(d,l)=1</annotation></semantics></math> indicates that the submodel architecture <math id="S3.SS4.p4.4.m4.2" class="ltx_Math" alttext="a(d,l)" display="inline"><semantics id="S3.SS4.p4.4.m4.2a"><mrow id="S3.SS4.p4.4.m4.2.3" xref="S3.SS4.p4.4.m4.2.3.cmml"><mi id="S3.SS4.p4.4.m4.2.3.2" xref="S3.SS4.p4.4.m4.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p4.4.m4.2.3.1" xref="S3.SS4.p4.4.m4.2.3.1.cmml">​</mo><mrow id="S3.SS4.p4.4.m4.2.3.3.2" xref="S3.SS4.p4.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p4.4.m4.2.3.3.2.1" xref="S3.SS4.p4.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS4.p4.4.m4.1.1" xref="S3.SS4.p4.4.m4.1.1.cmml">d</mi><mo id="S3.SS4.p4.4.m4.2.3.3.2.2" xref="S3.SS4.p4.4.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS4.p4.4.m4.2.2" xref="S3.SS4.p4.4.m4.2.2.cmml">l</mi><mo stretchy="false" id="S3.SS4.p4.4.m4.2.3.3.2.3" xref="S3.SS4.p4.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.4.m4.2b"><apply id="S3.SS4.p4.4.m4.2.3.cmml" xref="S3.SS4.p4.4.m4.2.3"><times id="S3.SS4.p4.4.m4.2.3.1.cmml" xref="S3.SS4.p4.4.m4.2.3.1"></times><ci id="S3.SS4.p4.4.m4.2.3.2.cmml" xref="S3.SS4.p4.4.m4.2.3.2">𝑎</ci><interval closure="open" id="S3.SS4.p4.4.m4.2.3.3.1.cmml" xref="S3.SS4.p4.4.m4.2.3.3.2"><ci id="S3.SS4.p4.4.m4.1.1.cmml" xref="S3.SS4.p4.4.m4.1.1">𝑑</ci><ci id="S3.SS4.p4.4.m4.2.2.cmml" xref="S3.SS4.p4.4.m4.2.2">𝑙</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.4.m4.2c">a(d,l)</annotation></semantics></math> is selected, and it is 0 otherwise. The indicator matrix <math id="S3.SS4.p4.5.m5.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS4.p4.5.m5.1a"><mi id="S3.SS4.p4.5.m5.1.1" xref="S3.SS4.p4.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.5.m5.1b"><ci id="S3.SS4.p4.5.m5.1.1.cmml" xref="S3.SS4.p4.5.m5.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.5.m5.1c">I</annotation></semantics></math> is first initialized with all-one values and then converted to an <em id="S3.SS4.p4.7.2" class="ltx_emph ltx_font_italic">upper-triangle</em> matrix. This strategy allows us to obtain <em id="S3.SS4.p4.7.3" class="ltx_emph ltx_font_italic">six</em> shallow and wide submodel architectures, which correspond to the matrix elements above the main diagonal. The submodel architectures <math id="S3.SS4.p4.6.m6.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S3.SS4.p4.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p4.6.m6.1.1" xref="S3.SS4.p4.6.m6.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.6.m6.1b"><ci id="S3.SS4.p4.6.m6.1.1.cmml" xref="S3.SS4.p4.6.m6.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.6.m6.1c">\mathcal{S}</annotation></semantics></math> selected from <math id="S3.SS4.p4.7.m7.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS4.p4.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p4.7.m7.1.1" xref="S3.SS4.p4.7.m7.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.7.m7.1b"><ci id="S3.SS4.p4.7.m7.1.1.cmml" xref="S3.SS4.p4.7.m7.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.7.m7.1c">\mathcal{A}</annotation></semantics></math> are defined as follows:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.7" class="ltx_Math" alttext="{\mathcal{S}}=\texttt{upper-triangle}(\mathcal{A})=\{a(d,l)|I(d,l)=1\}" display="block"><semantics id="S3.E7.m1.7a"><mrow id="S3.E7.m1.7.7" xref="S3.E7.m1.7.7.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.7.7.4" xref="S3.E7.m1.7.7.4.cmml">𝒮</mi><mo id="S3.E7.m1.7.7.5" xref="S3.E7.m1.7.7.5.cmml">=</mo><mrow id="S3.E7.m1.7.7.6" xref="S3.E7.m1.7.7.6.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E7.m1.7.7.6.2" xref="S3.E7.m1.7.7.6.2a.cmml">upper-triangle</mtext><mo lspace="0em" rspace="0em" id="S3.E7.m1.7.7.6.1" xref="S3.E7.m1.7.7.6.1.cmml">​</mo><mrow id="S3.E7.m1.7.7.6.3.2" xref="S3.E7.m1.7.7.6.cmml"><mo stretchy="false" id="S3.E7.m1.7.7.6.3.2.1" xref="S3.E7.m1.7.7.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml">𝒜</mi><mo stretchy="false" id="S3.E7.m1.7.7.6.3.2.2" xref="S3.E7.m1.7.7.6.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.7.7.7" xref="S3.E7.m1.7.7.7.cmml">=</mo><mrow id="S3.E7.m1.7.7.2.2" xref="S3.E7.m1.7.7.2.3.cmml"><mo stretchy="false" id="S3.E7.m1.7.7.2.2.3" xref="S3.E7.m1.7.7.2.3.1.cmml">{</mo><mrow id="S3.E7.m1.6.6.1.1.1" xref="S3.E7.m1.6.6.1.1.1.cmml"><mi id="S3.E7.m1.6.6.1.1.1.2" xref="S3.E7.m1.6.6.1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.6.6.1.1.1.1" xref="S3.E7.m1.6.6.1.1.1.1.cmml">​</mo><mrow id="S3.E7.m1.6.6.1.1.1.3.2" xref="S3.E7.m1.6.6.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E7.m1.6.6.1.1.1.3.2.1" xref="S3.E7.m1.6.6.1.1.1.3.1.cmml">(</mo><mi id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml">d</mi><mo id="S3.E7.m1.6.6.1.1.1.3.2.2" xref="S3.E7.m1.6.6.1.1.1.3.1.cmml">,</mo><mi id="S3.E7.m1.3.3" xref="S3.E7.m1.3.3.cmml">l</mi><mo stretchy="false" id="S3.E7.m1.6.6.1.1.1.3.2.3" xref="S3.E7.m1.6.6.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E7.m1.7.7.2.2.4" xref="S3.E7.m1.7.7.2.3.1.cmml">|</mo><mrow id="S3.E7.m1.7.7.2.2.2" xref="S3.E7.m1.7.7.2.2.2.cmml"><mrow id="S3.E7.m1.7.7.2.2.2.2" xref="S3.E7.m1.7.7.2.2.2.2.cmml"><mi id="S3.E7.m1.7.7.2.2.2.2.2" xref="S3.E7.m1.7.7.2.2.2.2.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.7.7.2.2.2.2.1" xref="S3.E7.m1.7.7.2.2.2.2.1.cmml">​</mo><mrow id="S3.E7.m1.7.7.2.2.2.2.3.2" xref="S3.E7.m1.7.7.2.2.2.2.3.1.cmml"><mo stretchy="false" id="S3.E7.m1.7.7.2.2.2.2.3.2.1" xref="S3.E7.m1.7.7.2.2.2.2.3.1.cmml">(</mo><mi id="S3.E7.m1.4.4" xref="S3.E7.m1.4.4.cmml">d</mi><mo id="S3.E7.m1.7.7.2.2.2.2.3.2.2" xref="S3.E7.m1.7.7.2.2.2.2.3.1.cmml">,</mo><mi id="S3.E7.m1.5.5" xref="S3.E7.m1.5.5.cmml">l</mi><mo stretchy="false" id="S3.E7.m1.7.7.2.2.2.2.3.2.3" xref="S3.E7.m1.7.7.2.2.2.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.7.7.2.2.2.1" xref="S3.E7.m1.7.7.2.2.2.1.cmml">=</mo><mn id="S3.E7.m1.7.7.2.2.2.3" xref="S3.E7.m1.7.7.2.2.2.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E7.m1.7.7.2.2.5" xref="S3.E7.m1.7.7.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.7b"><apply id="S3.E7.m1.7.7.cmml" xref="S3.E7.m1.7.7"><and id="S3.E7.m1.7.7a.cmml" xref="S3.E7.m1.7.7"></and><apply id="S3.E7.m1.7.7b.cmml" xref="S3.E7.m1.7.7"><eq id="S3.E7.m1.7.7.5.cmml" xref="S3.E7.m1.7.7.5"></eq><ci id="S3.E7.m1.7.7.4.cmml" xref="S3.E7.m1.7.7.4">𝒮</ci><apply id="S3.E7.m1.7.7.6.cmml" xref="S3.E7.m1.7.7.6"><times id="S3.E7.m1.7.7.6.1.cmml" xref="S3.E7.m1.7.7.6.1"></times><ci id="S3.E7.m1.7.7.6.2a.cmml" xref="S3.E7.m1.7.7.6.2"><mtext class="ltx_mathvariant_monospace" id="S3.E7.m1.7.7.6.2.cmml" xref="S3.E7.m1.7.7.6.2">upper-triangle</mtext></ci><ci id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1">𝒜</ci></apply></apply><apply id="S3.E7.m1.7.7c.cmml" xref="S3.E7.m1.7.7"><eq id="S3.E7.m1.7.7.7.cmml" xref="S3.E7.m1.7.7.7"></eq><share href="#S3.E7.m1.7.7.6.cmml" id="S3.E7.m1.7.7d.cmml" xref="S3.E7.m1.7.7"></share><apply id="S3.E7.m1.7.7.2.3.cmml" xref="S3.E7.m1.7.7.2.2"><csymbol cd="latexml" id="S3.E7.m1.7.7.2.3.1.cmml" xref="S3.E7.m1.7.7.2.2.3">conditional-set</csymbol><apply id="S3.E7.m1.6.6.1.1.1.cmml" xref="S3.E7.m1.6.6.1.1.1"><times id="S3.E7.m1.6.6.1.1.1.1.cmml" xref="S3.E7.m1.6.6.1.1.1.1"></times><ci id="S3.E7.m1.6.6.1.1.1.2.cmml" xref="S3.E7.m1.6.6.1.1.1.2">𝑎</ci><interval closure="open" id="S3.E7.m1.6.6.1.1.1.3.1.cmml" xref="S3.E7.m1.6.6.1.1.1.3.2"><ci id="S3.E7.m1.2.2.cmml" xref="S3.E7.m1.2.2">𝑑</ci><ci id="S3.E7.m1.3.3.cmml" xref="S3.E7.m1.3.3">𝑙</ci></interval></apply><apply id="S3.E7.m1.7.7.2.2.2.cmml" xref="S3.E7.m1.7.7.2.2.2"><eq id="S3.E7.m1.7.7.2.2.2.1.cmml" xref="S3.E7.m1.7.7.2.2.2.1"></eq><apply id="S3.E7.m1.7.7.2.2.2.2.cmml" xref="S3.E7.m1.7.7.2.2.2.2"><times id="S3.E7.m1.7.7.2.2.2.2.1.cmml" xref="S3.E7.m1.7.7.2.2.2.2.1"></times><ci id="S3.E7.m1.7.7.2.2.2.2.2.cmml" xref="S3.E7.m1.7.7.2.2.2.2.2">𝐼</ci><interval closure="open" id="S3.E7.m1.7.7.2.2.2.2.3.1.cmml" xref="S3.E7.m1.7.7.2.2.2.2.3.2"><ci id="S3.E7.m1.4.4.cmml" xref="S3.E7.m1.4.4">𝑑</ci><ci id="S3.E7.m1.5.5.cmml" xref="S3.E7.m1.5.5">𝑙</ci></interval></apply><cn type="integer" id="S3.E7.m1.7.7.2.2.2.3.cmml" xref="S3.E7.m1.7.7.2.2.2.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.7c">{\mathcal{S}}=\texttt{upper-triangle}(\mathcal{A})=\{a(d,l)|I(d,l)=1\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2203.12814/assets/x4.png" id="S3.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.4.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.5.2" class="ltx_text" style="font-size:90%;">The diagram of submodel architecture selection by using the triangle selection filtering strategy. The selected submodel architectures (highlighted with yellow background) follow the <em id="S3.F4.5.2.1" class="ltx_emph ltx_font_italic">deep-and-narrow</em> principle, which is considered to be more effective than the rest (white background).</span></figcaption>
</figure>
<div id="S3.SS4.p5" class="ltx_para ltx_noindent">
<p id="S3.SS4.p5.7" class="ltx_p"><span id="S3.SS4.p5.7.1" class="ltx_text ltx_font_bold">Knowledge Distillation Training.</span> After obtaining the selected submodel architectures <math id="S3.SS4.p5.1.m1.1" class="ltx_Math" alttext="{\mathcal{S}}" display="inline"><semantics id="S3.SS4.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p5.1.m1.1.1" xref="S3.SS4.p5.1.m1.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.1.m1.1b"><ci id="S3.SS4.p5.1.m1.1.1.cmml" xref="S3.SS4.p5.1.m1.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.1.m1.1c">{\mathcal{S}}</annotation></semantics></math>, we train a slimmable model <math id="S3.SS4.p5.2.m2.1" class="ltx_Math" alttext="M_{\texttt{BST}}" display="inline"><semantics id="S3.SS4.p5.2.m2.1a"><msub id="S3.SS4.p5.2.m2.1.1" xref="S3.SS4.p5.2.m2.1.1.cmml"><mi id="S3.SS4.p5.2.m2.1.1.2" xref="S3.SS4.p5.2.m2.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p5.2.m2.1.1.3" xref="S3.SS4.p5.2.m2.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.2.m2.1b"><apply id="S3.SS4.p5.2.m2.1.1.cmml" xref="S3.SS4.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p5.2.m2.1.1.1.cmml" xref="S3.SS4.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p5.2.m2.1.1.2.cmml" xref="S3.SS4.p5.2.m2.1.1.2">𝑀</ci><ci id="S3.SS4.p5.2.m2.1.1.3a.cmml" xref="S3.SS4.p5.2.m2.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p5.2.m2.1.1.3.cmml" xref="S3.SS4.p5.2.m2.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.2.m2.1c">M_{\texttt{BST}}</annotation></semantics></math> that can elastically adapt to any submodel architecture <math id="S3.SS4.p5.3.m3.1" class="ltx_Math" alttext="a\in\mathcal{S}" display="inline"><semantics id="S3.SS4.p5.3.m3.1a"><mrow id="S3.SS4.p5.3.m3.1.1" xref="S3.SS4.p5.3.m3.1.1.cmml"><mi id="S3.SS4.p5.3.m3.1.1.2" xref="S3.SS4.p5.3.m3.1.1.2.cmml">a</mi><mo id="S3.SS4.p5.3.m3.1.1.1" xref="S3.SS4.p5.3.m3.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p5.3.m3.1.1.3" xref="S3.SS4.p5.3.m3.1.1.3.cmml">𝒮</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.3.m3.1b"><apply id="S3.SS4.p5.3.m3.1.1.cmml" xref="S3.SS4.p5.3.m3.1.1"><in id="S3.SS4.p5.3.m3.1.1.1.cmml" xref="S3.SS4.p5.3.m3.1.1.1"></in><ci id="S3.SS4.p5.3.m3.1.1.2.cmml" xref="S3.SS4.p5.3.m3.1.1.2">𝑎</ci><ci id="S3.SS4.p5.3.m3.1.1.3.cmml" xref="S3.SS4.p5.3.m3.1.1.3">𝒮</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.3.m3.1c">a\in\mathcal{S}</annotation></semantics></math>, where <math id="S3.SS4.p5.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS4.p5.4.m4.1a"><mi id="S3.SS4.p5.4.m4.1.1" xref="S3.SS4.p5.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.4.m4.1b"><ci id="S3.SS4.p5.4.m4.1.1.cmml" xref="S3.SS4.p5.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.4.m4.1c">M</annotation></semantics></math> refers to any of the above VQA models. Given the BST model <math id="S3.SS4.p5.5.m5.1" class="ltx_Math" alttext="M_{\texttt{BST}}" display="inline"><semantics id="S3.SS4.p5.5.m5.1a"><msub id="S3.SS4.p5.5.m5.1.1" xref="S3.SS4.p5.5.m5.1.1.cmml"><mi id="S3.SS4.p5.5.m5.1.1.2" xref="S3.SS4.p5.5.m5.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p5.5.m5.1.1.3" xref="S3.SS4.p5.5.m5.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.5.m5.1b"><apply id="S3.SS4.p5.5.m5.1.1.cmml" xref="S3.SS4.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p5.5.m5.1.1.1.cmml" xref="S3.SS4.p5.5.m5.1.1">subscript</csymbol><ci id="S3.SS4.p5.5.m5.1.1.2.cmml" xref="S3.SS4.p5.5.m5.1.1.2">𝑀</ci><ci id="S3.SS4.p5.5.m5.1.1.3a.cmml" xref="S3.SS4.p5.5.m5.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p5.5.m5.1.1.3.cmml" xref="S3.SS4.p5.5.m5.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.5.m5.1c">M_{\texttt{BST}}</annotation></semantics></math> and a submodel architecture <math id="S3.SS4.p5.6.m6.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.SS4.p5.6.m6.1a"><mi id="S3.SS4.p5.6.m6.1.1" xref="S3.SS4.p5.6.m6.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.6.m6.1b"><ci id="S3.SS4.p5.6.m6.1.1.cmml" xref="S3.SS4.p5.6.m6.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.6.m6.1c">a</annotation></semantics></math>, the obtained submodel is denoted as <math id="S3.SS4.p5.7.m7.1" class="ltx_Math" alttext="M_{\texttt{BST}}^{(a)}" display="inline"><semantics id="S3.SS4.p5.7.m7.1a"><msubsup id="S3.SS4.p5.7.m7.1.2" xref="S3.SS4.p5.7.m7.1.2.cmml"><mi id="S3.SS4.p5.7.m7.1.2.2.2" xref="S3.SS4.p5.7.m7.1.2.2.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p5.7.m7.1.2.2.3" xref="S3.SS4.p5.7.m7.1.2.2.3a.cmml">BST</mtext><mrow id="S3.SS4.p5.7.m7.1.1.1.3" xref="S3.SS4.p5.7.m7.1.2.cmml"><mo stretchy="false" id="S3.SS4.p5.7.m7.1.1.1.3.1" xref="S3.SS4.p5.7.m7.1.2.cmml">(</mo><mi id="S3.SS4.p5.7.m7.1.1.1.1" xref="S3.SS4.p5.7.m7.1.1.1.1.cmml">a</mi><mo stretchy="false" id="S3.SS4.p5.7.m7.1.1.1.3.2" xref="S3.SS4.p5.7.m7.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.7.m7.1b"><apply id="S3.SS4.p5.7.m7.1.2.cmml" xref="S3.SS4.p5.7.m7.1.2"><csymbol cd="ambiguous" id="S3.SS4.p5.7.m7.1.2.1.cmml" xref="S3.SS4.p5.7.m7.1.2">superscript</csymbol><apply id="S3.SS4.p5.7.m7.1.2.2.cmml" xref="S3.SS4.p5.7.m7.1.2"><csymbol cd="ambiguous" id="S3.SS4.p5.7.m7.1.2.2.1.cmml" xref="S3.SS4.p5.7.m7.1.2">subscript</csymbol><ci id="S3.SS4.p5.7.m7.1.2.2.2.cmml" xref="S3.SS4.p5.7.m7.1.2.2.2">𝑀</ci><ci id="S3.SS4.p5.7.m7.1.2.2.3a.cmml" xref="S3.SS4.p5.7.m7.1.2.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p5.7.m7.1.2.2.3.cmml" xref="S3.SS4.p5.7.m7.1.2.2.3">BST</mtext></ci></apply><ci id="S3.SS4.p5.7.m7.1.1.1.1.cmml" xref="S3.SS4.p5.7.m7.1.1.1.1">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.7.m7.1c">M_{\texttt{BST}}^{(a)}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p id="S3.SS4.p6.5" class="ltx_p">To obtain the BST model, we introduce a knowledge-distillation (KD) training mechanism as follows. In general, we first train an ordinary model <math id="S3.SS4.p6.1.m1.1" class="ltx_Math" alttext="{M_{\texttt{teacher}}}" display="inline"><semantics id="S3.SS4.p6.1.m1.1a"><msub id="S3.SS4.p6.1.m1.1.1" xref="S3.SS4.p6.1.m1.1.1.cmml"><mi id="S3.SS4.p6.1.m1.1.1.2" xref="S3.SS4.p6.1.m1.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p6.1.m1.1.1.3" xref="S3.SS4.p6.1.m1.1.1.3a.cmml">teacher</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.1.m1.1b"><apply id="S3.SS4.p6.1.m1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p6.1.m1.1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p6.1.m1.1.1.2.cmml" xref="S3.SS4.p6.1.m1.1.1.2">𝑀</ci><ci id="S3.SS4.p6.1.m1.1.1.3a.cmml" xref="S3.SS4.p6.1.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p6.1.m1.1.1.3.cmml" xref="S3.SS4.p6.1.m1.1.1.3">teacher</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.1.m1.1c">{M_{\texttt{teacher}}}</annotation></semantics></math> as the teacher model without model slimming and freeze its model parameters. After that, the BST model <math id="S3.SS4.p6.2.m2.1" class="ltx_Math" alttext="M_{\texttt{BST}}" display="inline"><semantics id="S3.SS4.p6.2.m2.1a"><msub id="S3.SS4.p6.2.m2.1.1" xref="S3.SS4.p6.2.m2.1.1.cmml"><mi id="S3.SS4.p6.2.m2.1.1.2" xref="S3.SS4.p6.2.m2.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p6.2.m2.1.1.3" xref="S3.SS4.p6.2.m2.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.2.m2.1b"><apply id="S3.SS4.p6.2.m2.1.1.cmml" xref="S3.SS4.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p6.2.m2.1.1.1.cmml" xref="S3.SS4.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p6.2.m2.1.1.2.cmml" xref="S3.SS4.p6.2.m2.1.1.2">𝑀</ci><ci id="S3.SS4.p6.2.m2.1.1.3a.cmml" xref="S3.SS4.p6.2.m2.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p6.2.m2.1.1.3.cmml" xref="S3.SS4.p6.2.m2.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.2.m2.1c">M_{\texttt{BST}}</annotation></semantics></math> is initialized with the model parameters from <math id="S3.SS4.p6.3.m3.1" class="ltx_Math" alttext="{M_{\texttt{teacher}}}" display="inline"><semantics id="S3.SS4.p6.3.m3.1a"><msub id="S3.SS4.p6.3.m3.1.1" xref="S3.SS4.p6.3.m3.1.1.cmml"><mi id="S3.SS4.p6.3.m3.1.1.2" xref="S3.SS4.p6.3.m3.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p6.3.m3.1.1.3" xref="S3.SS4.p6.3.m3.1.1.3a.cmml">teacher</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.3.m3.1b"><apply id="S3.SS4.p6.3.m3.1.1.cmml" xref="S3.SS4.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p6.3.m3.1.1.1.cmml" xref="S3.SS4.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p6.3.m3.1.1.2.cmml" xref="S3.SS4.p6.3.m3.1.1.2">𝑀</ci><ci id="S3.SS4.p6.3.m3.1.1.3a.cmml" xref="S3.SS4.p6.3.m3.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p6.3.m3.1.1.3.cmml" xref="S3.SS4.p6.3.m3.1.1.3">teacher</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.3.m3.1c">{M_{\texttt{teacher}}}</annotation></semantics></math>, and it can be viewed as the student model. Each slimmed submodel <math id="S3.SS4.p6.4.m4.1" class="ltx_Math" alttext="M_{\texttt{BST}}^{(a)}" display="inline"><semantics id="S3.SS4.p6.4.m4.1a"><msubsup id="S3.SS4.p6.4.m4.1.2" xref="S3.SS4.p6.4.m4.1.2.cmml"><mi id="S3.SS4.p6.4.m4.1.2.2.2" xref="S3.SS4.p6.4.m4.1.2.2.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p6.4.m4.1.2.2.3" xref="S3.SS4.p6.4.m4.1.2.2.3a.cmml">BST</mtext><mrow id="S3.SS4.p6.4.m4.1.1.1.3" xref="S3.SS4.p6.4.m4.1.2.cmml"><mo stretchy="false" id="S3.SS4.p6.4.m4.1.1.1.3.1" xref="S3.SS4.p6.4.m4.1.2.cmml">(</mo><mi id="S3.SS4.p6.4.m4.1.1.1.1" xref="S3.SS4.p6.4.m4.1.1.1.1.cmml">a</mi><mo stretchy="false" id="S3.SS4.p6.4.m4.1.1.1.3.2" xref="S3.SS4.p6.4.m4.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.4.m4.1b"><apply id="S3.SS4.p6.4.m4.1.2.cmml" xref="S3.SS4.p6.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS4.p6.4.m4.1.2.1.cmml" xref="S3.SS4.p6.4.m4.1.2">superscript</csymbol><apply id="S3.SS4.p6.4.m4.1.2.2.cmml" xref="S3.SS4.p6.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS4.p6.4.m4.1.2.2.1.cmml" xref="S3.SS4.p6.4.m4.1.2">subscript</csymbol><ci id="S3.SS4.p6.4.m4.1.2.2.2.cmml" xref="S3.SS4.p6.4.m4.1.2.2.2">𝑀</ci><ci id="S3.SS4.p6.4.m4.1.2.2.3a.cmml" xref="S3.SS4.p6.4.m4.1.2.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p6.4.m4.1.2.2.3.cmml" xref="S3.SS4.p6.4.m4.1.2.2.3">BST</mtext></ci></apply><ci id="S3.SS4.p6.4.m4.1.1.1.1.cmml" xref="S3.SS4.p6.4.m4.1.1.1.1">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.4.m4.1c">M_{\texttt{BST}}^{(a)}</annotation></semantics></math> shares a specific portion of the model parameters from <math id="S3.SS4.p6.5.m5.1" class="ltx_Math" alttext="M_{\texttt{BST}}" display="inline"><semantics id="S3.SS4.p6.5.m5.1a"><msub id="S3.SS4.p6.5.m5.1.1" xref="S3.SS4.p6.5.m5.1.1.cmml"><mi id="S3.SS4.p6.5.m5.1.1.2" xref="S3.SS4.p6.5.m5.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS4.p6.5.m5.1.1.3" xref="S3.SS4.p6.5.m5.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.5.m5.1b"><apply id="S3.SS4.p6.5.m5.1.1.cmml" xref="S3.SS4.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p6.5.m5.1.1.1.cmml" xref="S3.SS4.p6.5.m5.1.1">subscript</csymbol><ci id="S3.SS4.p6.5.m5.1.1.2.cmml" xref="S3.SS4.p6.5.m5.1.1.2">𝑀</ci><ci id="S3.SS4.p6.5.m5.1.1.3a.cmml" xref="S3.SS4.p6.5.m5.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS4.p6.5.m5.1.1.3.cmml" xref="S3.SS4.p6.5.m5.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.5.m5.1c">M_{\texttt{BST}}</annotation></semantics></math> and is trained with the supervision of the teacher model using the KD strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. Specifically, given a training sample, we feed it through the teacher model and each slimmed submodel simultaneously. The predicted answer distribution from the teacher model is regarded as a soft label, and a proper loss function is imposed on the soft label and each submodel prediction to train the corresponding model<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Different loss functions (<em id="footnote2.1" class="ltx_emph ltx_font_italic">e.g.</em>, BCE and KL-divergence) can be used as the KD loss flexibly, depending on the loss function used in the teacher model.</span></span></span>.</p>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p id="S3.SS4.p7.9" class="ltx_p">Unlike the existing approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> that decouple the width slimming and depth slimming into two training stages, we use a simpler one-stage training paradigm for BST with standard mini-batch SGD. In each iteration, we select <math id="S3.SS4.p7.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.1.m1.1a"><mi id="S3.SS4.p7.1.m1.1.1" xref="S3.SS4.p7.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.1.m1.1b"><ci id="S3.SS4.p7.1.m1.1.1.cmml" xref="S3.SS4.p7.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.1.m1.1c">K</annotation></semantics></math> submodel architectures from <math id="S3.SS4.p7.2.m2.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S3.SS4.p7.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p7.2.m2.1.1" xref="S3.SS4.p7.2.m2.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.2.m2.1b"><ci id="S3.SS4.p7.2.m2.1.1.cmml" xref="S3.SS4.p7.2.m2.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.2.m2.1c">\mathcal{S}</annotation></semantics></math> and feed the same input samples to both the teacher model and the selected <math id="S3.SS4.p7.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.3.m3.1a"><mi id="S3.SS4.p7.3.m3.1.1" xref="S3.SS4.p7.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.3.m3.1b"><ci id="S3.SS4.p7.3.m3.1.1.cmml" xref="S3.SS4.p7.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.3.m3.1c">K</annotation></semantics></math> submodels to obtain (<math id="S3.SS4.p7.4.m4.1" class="ltx_Math" alttext="K+1" display="inline"><semantics id="S3.SS4.p7.4.m4.1a"><mrow id="S3.SS4.p7.4.m4.1.1" xref="S3.SS4.p7.4.m4.1.1.cmml"><mi id="S3.SS4.p7.4.m4.1.1.2" xref="S3.SS4.p7.4.m4.1.1.2.cmml">K</mi><mo id="S3.SS4.p7.4.m4.1.1.1" xref="S3.SS4.p7.4.m4.1.1.1.cmml">+</mo><mn id="S3.SS4.p7.4.m4.1.1.3" xref="S3.SS4.p7.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.4.m4.1b"><apply id="S3.SS4.p7.4.m4.1.1.cmml" xref="S3.SS4.p7.4.m4.1.1"><plus id="S3.SS4.p7.4.m4.1.1.1.cmml" xref="S3.SS4.p7.4.m4.1.1.1"></plus><ci id="S3.SS4.p7.4.m4.1.1.2.cmml" xref="S3.SS4.p7.4.m4.1.1.2">𝐾</ci><cn type="integer" id="S3.SS4.p7.4.m4.1.1.3.cmml" xref="S3.SS4.p7.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.4.m4.1c">K+1</annotation></semantics></math>) predictions in total. After that, we apply the KD loss between the predictions of the teacher and each of the <math id="S3.SS4.p7.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.5.m5.1a"><mi id="S3.SS4.p7.5.m5.1.1" xref="S3.SS4.p7.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.5.m5.1b"><ci id="S3.SS4.p7.5.m5.1.1.cmml" xref="S3.SS4.p7.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.5.m5.1c">K</annotation></semantics></math> student models and use the accumulated back-propagated gradients to update the model parameters of <math id="S3.SS4.p7.6.m6.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.6.m6.1a"><mi id="S3.SS4.p7.6.m6.1.1" xref="S3.SS4.p7.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.6.m6.1b"><ci id="S3.SS4.p7.6.m6.1.1.cmml" xref="S3.SS4.p7.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.6.m6.1c">K</annotation></semantics></math>. To stabilize the BST training, the <math id="S3.SS4.p7.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.7.m7.1a"><mi id="S3.SS4.p7.7.m7.1.1" xref="S3.SS4.p7.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.7.m7.1b"><ci id="S3.SS4.p7.7.m7.1.1.cmml" xref="S3.SS4.p7.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.7.m7.1c">K</annotation></semantics></math> selected submodels consist of two determined submodels (the smallest one and the largest one) and another (<math id="S3.SS4.p7.8.m8.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.8.m8.1a"><mi id="S3.SS4.p7.8.m8.1.1" xref="S3.SS4.p7.8.m8.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.8.m8.1b"><ci id="S3.SS4.p7.8.m8.1.1.cmml" xref="S3.SS4.p7.8.m8.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.8.m8.1c">K</annotation></semantics></math>-2) randomly sampled submodels. We use <math id="S3.SS4.p7.9.m9.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p7.9.m9.1a"><mi id="S3.SS4.p7.9.m9.1.1" xref="S3.SS4.p7.9.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.9.m9.1b"><ci id="S3.SS4.p7.9.m9.1.1.cmml" xref="S3.SS4.p7.9.m9.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.9.m9.1c">K</annotation></semantics></math>=4 as the default setting in our experiments.</p>
</div>
<div id="S3.SS4.p8" class="ltx_para">
<p id="S3.SS4.p8.1" class="ltx_p">The whole BST training process is shown in Algorithm <a href="#algorithm1" title="In III-D Training Strategy for BST Models ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="algorithm1" class="ltx_float ltx_algorithm">
<div id="algorithm1.35" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm1.9.9" class="ltx_listingline">
<span id="algorithm1.9.9.10" class="ltx_text" style="font-size:90%;"><span id="algorithm1.9.9.10.1" class="ltx_text ltx_font_bold">Input:</span> </span><span id="algorithm1.9.9.9" class="ltx_text" style="font-size:90%;">A reference Transformer architecture with width <math id="algorithm1.1.1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="algorithm1.1.1.1.m1.1a"><mi id="algorithm1.1.1.1.m1.1.1" xref="algorithm1.1.1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.1.m1.1b"><ci id="algorithm1.1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.1.m1.1c">D</annotation></semantics></math> and depth <math id="algorithm1.2.2.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="algorithm1.2.2.2.m2.1a"><mi id="algorithm1.2.2.2.m2.1.1" xref="algorithm1.2.2.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.2.m2.1b"><ci id="algorithm1.2.2.2.m2.1.1.cmml" xref="algorithm1.2.2.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.2.m2.1c">L</annotation></semantics></math>. Two predefined sets <math id="algorithm1.3.3.3.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="algorithm1.3.3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.3.m3.1.1" xref="algorithm1.3.3.3.m3.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.3.m3.1b"><ci id="algorithm1.3.3.3.m3.1.1.cmml" xref="algorithm1.3.3.3.m3.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.3.m3.1c">\mathcal{D}</annotation></semantics></math> and <math id="algorithm1.4.4.4.m4.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="algorithm1.4.4.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="algorithm1.4.4.4.m4.1.1" xref="algorithm1.4.4.4.m4.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.4.m4.1b"><ci id="algorithm1.4.4.4.m4.1.1.cmml" xref="algorithm1.4.4.4.m4.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.4.m4.1c">\mathcal{L}</annotation></semantics></math> define the slimming widths and depths w.r.t. <math id="algorithm1.5.5.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="algorithm1.5.5.5.m5.1a"><mi id="algorithm1.5.5.5.m5.1.1" xref="algorithm1.5.5.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.5.m5.1b"><ci id="algorithm1.5.5.5.m5.1.1.cmml" xref="algorithm1.5.5.5.m5.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.5.m5.1c">D</annotation></semantics></math> and <math id="algorithm1.6.6.6.m6.1" class="ltx_Math" alttext="L" display="inline"><semantics id="algorithm1.6.6.6.m6.1a"><mi id="algorithm1.6.6.6.m6.1.1" xref="algorithm1.6.6.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.6.m6.1b"><ci id="algorithm1.6.6.6.m6.1.1.cmml" xref="algorithm1.6.6.6.m6.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.6.m6.1c">L</annotation></semantics></math>, resp. The number of sampled submodel architectures <math id="algorithm1.7.7.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="algorithm1.7.7.7.m7.1a"><mi id="algorithm1.7.7.7.m7.1.1" xref="algorithm1.7.7.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.7.m7.1b"><ci id="algorithm1.7.7.7.m7.1.1.cmml" xref="algorithm1.7.7.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.7.m7.1c">K</annotation></semantics></math> per training iteration. <math id="algorithm1.8.8.8.m8.1" class="ltx_Math" alttext="a_{s}" display="inline"><semantics id="algorithm1.8.8.8.m8.1a"><msub id="algorithm1.8.8.8.m8.1.1" xref="algorithm1.8.8.8.m8.1.1.cmml"><mi id="algorithm1.8.8.8.m8.1.1.2" xref="algorithm1.8.8.8.m8.1.1.2.cmml">a</mi><mi id="algorithm1.8.8.8.m8.1.1.3" xref="algorithm1.8.8.8.m8.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.8.m8.1b"><apply id="algorithm1.8.8.8.m8.1.1.cmml" xref="algorithm1.8.8.8.m8.1.1"><csymbol cd="ambiguous" id="algorithm1.8.8.8.m8.1.1.1.cmml" xref="algorithm1.8.8.8.m8.1.1">subscript</csymbol><ci id="algorithm1.8.8.8.m8.1.1.2.cmml" xref="algorithm1.8.8.8.m8.1.1.2">𝑎</ci><ci id="algorithm1.8.8.8.m8.1.1.3.cmml" xref="algorithm1.8.8.8.m8.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.8.m8.1c">a_{s}</annotation></semantics></math> and <math id="algorithm1.9.9.9.m9.1" class="ltx_Math" alttext="a_{l}" display="inline"><semantics id="algorithm1.9.9.9.m9.1a"><msub id="algorithm1.9.9.9.m9.1.1" xref="algorithm1.9.9.9.m9.1.1.cmml"><mi id="algorithm1.9.9.9.m9.1.1.2" xref="algorithm1.9.9.9.m9.1.1.2.cmml">a</mi><mi id="algorithm1.9.9.9.m9.1.1.3" xref="algorithm1.9.9.9.m9.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.9.m9.1b"><apply id="algorithm1.9.9.9.m9.1.1.cmml" xref="algorithm1.9.9.9.m9.1.1"><csymbol cd="ambiguous" id="algorithm1.9.9.9.m9.1.1.1.cmml" xref="algorithm1.9.9.9.m9.1.1">subscript</csymbol><ci id="algorithm1.9.9.9.m9.1.1.2.cmml" xref="algorithm1.9.9.9.m9.1.1.2">𝑎</ci><ci id="algorithm1.9.9.9.m9.1.1.3.cmml" xref="algorithm1.9.9.9.m9.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.9.m9.1c">a_{l}</annotation></semantics></math> refer to the smallest and largest submodel architectures, respectively.</span>
</div>
<div id="algorithm1.10.10" class="ltx_listingline">
<span id="algorithm1.10.10.1" class="ltx_text" style="font-size:90%;">
</span><span id="algorithm1.10.10.2" class="ltx_text" style="font-size:90%;"><span id="algorithm1.10.10.2.1" class="ltx_text ltx_font_bold">Output:</span> </span><span id="algorithm1.10.10.3" class="ltx_text" style="font-size:90%;">An optimized BST model </span><math id="algorithm1.10.10.m1.1" class="ltx_Math" alttext="M_{\mathrm{BST}}" display="inline"><semantics id="algorithm1.10.10.m1.1a"><msub id="algorithm1.10.10.m1.1.1" xref="algorithm1.10.10.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.10.10.m1.1.1.2" xref="algorithm1.10.10.m1.1.1.2.cmml">M</mi><mi mathsize="90%" id="algorithm1.10.10.m1.1.1.3" xref="algorithm1.10.10.m1.1.1.3.cmml">BST</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.m1.1b"><apply id="algorithm1.10.10.m1.1.1.cmml" xref="algorithm1.10.10.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.10.10.m1.1.1.1.cmml" xref="algorithm1.10.10.m1.1.1">subscript</csymbol><ci id="algorithm1.10.10.m1.1.1.2.cmml" xref="algorithm1.10.10.m1.1.1.2">𝑀</ci><ci id="algorithm1.10.10.m1.1.1.3.cmml" xref="algorithm1.10.10.m1.1.1.3">BST</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.m1.1c">M_{\mathrm{BST}}</annotation></semantics></math><span id="algorithm1.10.10.4" class="ltx_text" style="font-size:90%;">.</span>
</div>
<div id="algorithm1.35.36" class="ltx_listingline">
<span id="algorithm1.35.36.1" class="ltx_text" style="font-size:90%;">
</span><em id="algorithm1.35.36.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Stage I: Submodel Architectures Selection</em><span id="algorithm1.35.36.3" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.11.11" class="ltx_listingline">
<span id="algorithm1.11.11.1" class="ltx_text" style="font-size:90%;">
</span><math id="algorithm1.11.11.m1.2" class="ltx_Math" alttext="\mathcal{A}=\texttt{combination}(\mathcal{D},\mathcal{L})" display="inline"><semantics id="algorithm1.11.11.m1.2a"><mrow id="algorithm1.11.11.m1.2.3" xref="algorithm1.11.11.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="algorithm1.11.11.m1.2.3.2" xref="algorithm1.11.11.m1.2.3.2.cmml">𝒜</mi><mo mathsize="90%" id="algorithm1.11.11.m1.2.3.1" xref="algorithm1.11.11.m1.2.3.1.cmml">=</mo><mrow id="algorithm1.11.11.m1.2.3.3" xref="algorithm1.11.11.m1.2.3.3.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.11.11.m1.2.3.3.2" xref="algorithm1.11.11.m1.2.3.3.2a.cmml">combination</mtext><mo lspace="0em" rspace="0em" id="algorithm1.11.11.m1.2.3.3.1" xref="algorithm1.11.11.m1.2.3.3.1.cmml">​</mo><mrow id="algorithm1.11.11.m1.2.3.3.3.2" xref="algorithm1.11.11.m1.2.3.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.11.11.m1.2.3.3.3.2.1" xref="algorithm1.11.11.m1.2.3.3.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="algorithm1.11.11.m1.1.1" xref="algorithm1.11.11.m1.1.1.cmml">𝒟</mi><mo mathsize="90%" id="algorithm1.11.11.m1.2.3.3.3.2.2" xref="algorithm1.11.11.m1.2.3.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="algorithm1.11.11.m1.2.2" xref="algorithm1.11.11.m1.2.2.cmml">ℒ</mi><mo maxsize="90%" minsize="90%" id="algorithm1.11.11.m1.2.3.3.3.2.3" xref="algorithm1.11.11.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.m1.2b"><apply id="algorithm1.11.11.m1.2.3.cmml" xref="algorithm1.11.11.m1.2.3"><eq id="algorithm1.11.11.m1.2.3.1.cmml" xref="algorithm1.11.11.m1.2.3.1"></eq><ci id="algorithm1.11.11.m1.2.3.2.cmml" xref="algorithm1.11.11.m1.2.3.2">𝒜</ci><apply id="algorithm1.11.11.m1.2.3.3.cmml" xref="algorithm1.11.11.m1.2.3.3"><times id="algorithm1.11.11.m1.2.3.3.1.cmml" xref="algorithm1.11.11.m1.2.3.3.1"></times><ci id="algorithm1.11.11.m1.2.3.3.2a.cmml" xref="algorithm1.11.11.m1.2.3.3.2"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.11.11.m1.2.3.3.2.cmml" xref="algorithm1.11.11.m1.2.3.3.2">combination</mtext></ci><interval closure="open" id="algorithm1.11.11.m1.2.3.3.3.1.cmml" xref="algorithm1.11.11.m1.2.3.3.3.2"><ci id="algorithm1.11.11.m1.1.1.cmml" xref="algorithm1.11.11.m1.1.1">𝒟</ci><ci id="algorithm1.11.11.m1.2.2.cmml" xref="algorithm1.11.11.m1.2.2">ℒ</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.m1.2c">\mathcal{A}=\texttt{combination}(\mathcal{D},\mathcal{L})</annotation></semantics></math><span id="algorithm1.11.11.2" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.13.13" class="ltx_listingline">
<span id="algorithm1.13.13.1" class="ltx_text" style="font-size:90%;">
</span><math id="algorithm1.12.12.m1.1" class="ltx_Math" alttext="{\mathcal{S}}" display="inline"><semantics id="algorithm1.12.12.m1.1a"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="algorithm1.12.12.m1.1.1" xref="algorithm1.12.12.m1.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.m1.1b"><ci id="algorithm1.12.12.m1.1.1.cmml" xref="algorithm1.12.12.m1.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.m1.1c">{\mathcal{S}}</annotation></semantics></math><span id="algorithm1.13.13.2" class="ltx_text" style="font-size:90%;"> = </span><math id="algorithm1.13.13.m2.1" class="ltx_Math" alttext="\texttt{upper-triangle}(\mathcal{A})" display="inline"><semantics id="algorithm1.13.13.m2.1a"><mrow id="algorithm1.13.13.m2.1.2" xref="algorithm1.13.13.m2.1.2.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.13.13.m2.1.2.2" xref="algorithm1.13.13.m2.1.2.2a.cmml">upper-triangle</mtext><mo lspace="0em" rspace="0em" id="algorithm1.13.13.m2.1.2.1" xref="algorithm1.13.13.m2.1.2.1.cmml">​</mo><mrow id="algorithm1.13.13.m2.1.2.3.2" xref="algorithm1.13.13.m2.1.2.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.13.13.m2.1.2.3.2.1" xref="algorithm1.13.13.m2.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="algorithm1.13.13.m2.1.1" xref="algorithm1.13.13.m2.1.1.cmml">𝒜</mi><mo maxsize="90%" minsize="90%" id="algorithm1.13.13.m2.1.2.3.2.2" xref="algorithm1.13.13.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.m2.1b"><apply id="algorithm1.13.13.m2.1.2.cmml" xref="algorithm1.13.13.m2.1.2"><times id="algorithm1.13.13.m2.1.2.1.cmml" xref="algorithm1.13.13.m2.1.2.1"></times><ci id="algorithm1.13.13.m2.1.2.2a.cmml" xref="algorithm1.13.13.m2.1.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.13.13.m2.1.2.2.cmml" xref="algorithm1.13.13.m2.1.2.2">upper-triangle</mtext></ci><ci id="algorithm1.13.13.m2.1.1.cmml" xref="algorithm1.13.13.m2.1.1">𝒜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.m2.1c">\texttt{upper-triangle}(\mathcal{A})</annotation></semantics></math><span id="algorithm1.13.13.3" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.35.37" class="ltx_listingline">
<span id="algorithm1.35.37.1" class="ltx_text" style="font-size:90%;">
</span><em id="algorithm1.35.37.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Stage II: Knowledge Distillation Training</em><span id="algorithm1.35.37.3" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.15.15" class="ltx_listingline">
<span id="algorithm1.15.15.1" class="ltx_text" style="font-size:90%;">
Train </span><math id="algorithm1.14.14.m1.1" class="ltx_Math" alttext="M_{\texttt{teacher}}" display="inline"><semantics id="algorithm1.14.14.m1.1a"><msub id="algorithm1.14.14.m1.1.1" xref="algorithm1.14.14.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.14.14.m1.1.1.2" xref="algorithm1.14.14.m1.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.14.14.m1.1.1.3" xref="algorithm1.14.14.m1.1.1.3a.cmml">teacher</mtext></msub><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.m1.1b"><apply id="algorithm1.14.14.m1.1.1.cmml" xref="algorithm1.14.14.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.1.1.1.cmml" xref="algorithm1.14.14.m1.1.1">subscript</csymbol><ci id="algorithm1.14.14.m1.1.1.2.cmml" xref="algorithm1.14.14.m1.1.1.2">𝑀</ci><ci id="algorithm1.14.14.m1.1.1.3a.cmml" xref="algorithm1.14.14.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.14.14.m1.1.1.3.cmml" xref="algorithm1.14.14.m1.1.1.3">teacher</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.m1.1c">M_{\texttt{teacher}}</annotation></semantics></math><span id="algorithm1.15.15.2" class="ltx_text" style="font-size:90%;"> to obtain its optimized model parameters </span><math id="algorithm1.15.15.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="algorithm1.15.15.m2.1a"><mi mathsize="90%" id="algorithm1.15.15.m2.1.1" xref="algorithm1.15.15.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="algorithm1.15.15.m2.1b"><ci id="algorithm1.15.15.m2.1.1.cmml" xref="algorithm1.15.15.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.15.15.m2.1c">\theta</annotation></semantics></math><span id="algorithm1.15.15.3" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.18.18" class="ltx_listingline">
<span id="algorithm1.18.18.1" class="ltx_text" style="font-size:90%;">
Initialize the model parameters </span><math id="algorithm1.16.16.m1.1" class="ltx_Math" alttext="\theta_{\texttt{BST}}" display="inline"><semantics id="algorithm1.16.16.m1.1a"><msub id="algorithm1.16.16.m1.1.1" xref="algorithm1.16.16.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.16.16.m1.1.1.2" xref="algorithm1.16.16.m1.1.1.2.cmml">θ</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.16.16.m1.1.1.3" xref="algorithm1.16.16.m1.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="algorithm1.16.16.m1.1b"><apply id="algorithm1.16.16.m1.1.1.cmml" xref="algorithm1.16.16.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.16.16.m1.1.1.1.cmml" xref="algorithm1.16.16.m1.1.1">subscript</csymbol><ci id="algorithm1.16.16.m1.1.1.2.cmml" xref="algorithm1.16.16.m1.1.1.2">𝜃</ci><ci id="algorithm1.16.16.m1.1.1.3a.cmml" xref="algorithm1.16.16.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.16.16.m1.1.1.3.cmml" xref="algorithm1.16.16.m1.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.16.16.m1.1c">\theta_{\texttt{BST}}</annotation></semantics></math><span id="algorithm1.18.18.2" class="ltx_text" style="font-size:90%;"> for </span><math id="algorithm1.17.17.m2.1" class="ltx_Math" alttext="M_{\texttt{BST}}" display="inline"><semantics id="algorithm1.17.17.m2.1a"><msub id="algorithm1.17.17.m2.1.1" xref="algorithm1.17.17.m2.1.1.cmml"><mi mathsize="90%" id="algorithm1.17.17.m2.1.1.2" xref="algorithm1.17.17.m2.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.17.17.m2.1.1.3" xref="algorithm1.17.17.m2.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="algorithm1.17.17.m2.1b"><apply id="algorithm1.17.17.m2.1.1.cmml" xref="algorithm1.17.17.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.17.17.m2.1.1.1.cmml" xref="algorithm1.17.17.m2.1.1">subscript</csymbol><ci id="algorithm1.17.17.m2.1.1.2.cmml" xref="algorithm1.17.17.m2.1.1.2">𝑀</ci><ci id="algorithm1.17.17.m2.1.1.3a.cmml" xref="algorithm1.17.17.m2.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.17.17.m2.1.1.3.cmml" xref="algorithm1.17.17.m2.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.17.17.m2.1c">M_{\texttt{BST}}</annotation></semantics></math><span id="algorithm1.18.18.3" class="ltx_text" style="font-size:90%;"> with </span><math id="algorithm1.18.18.m3.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="algorithm1.18.18.m3.1a"><mi mathsize="90%" id="algorithm1.18.18.m3.1.1" xref="algorithm1.18.18.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="algorithm1.18.18.m3.1b"><ci id="algorithm1.18.18.m3.1.1.cmml" xref="algorithm1.18.18.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.18.18.m3.1c">\theta</annotation></semantics></math><span id="algorithm1.18.18.4" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.19.19" class="ltx_listingline">
<span id="algorithm1.19.19.2" class="ltx_text" style="font-size:90%;">
</span><span id="algorithm1.19.19.3" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="algorithm1.19.19.4" class="ltx_text" style="font-size:90%;"> </span><em id="algorithm1.19.19.1" class="ltx_emph ltx_font_italic" style="font-size:90%;"><math id="algorithm1.19.19.1.m1.1" class="ltx_Math" alttext="i=1" display="inline"><semantics id="algorithm1.19.19.1.m1.1a"><mrow id="algorithm1.19.19.1.m1.1.1" xref="algorithm1.19.19.1.m1.1.1.cmml"><mi id="algorithm1.19.19.1.m1.1.1.2" xref="algorithm1.19.19.1.m1.1.1.2.cmml">i</mi><mo id="algorithm1.19.19.1.m1.1.1.1" xref="algorithm1.19.19.1.m1.1.1.1.cmml">=</mo><mn id="algorithm1.19.19.1.m1.1.1.3" xref="algorithm1.19.19.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.19.19.1.m1.1b"><apply id="algorithm1.19.19.1.m1.1.1.cmml" xref="algorithm1.19.19.1.m1.1.1"><eq id="algorithm1.19.19.1.m1.1.1.1.cmml" xref="algorithm1.19.19.1.m1.1.1.1"></eq><ci id="algorithm1.19.19.1.m1.1.1.2.cmml" xref="algorithm1.19.19.1.m1.1.1.2">𝑖</ci><cn type="integer" id="algorithm1.19.19.1.m1.1.1.3.cmml" xref="algorithm1.19.19.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.19.19.1.m1.1c">i=1</annotation></semantics></math> <span id="algorithm1.19.19.1.1" class="ltx_text ltx_font_bold ltx_font_upright">to</span> <em id="algorithm1.19.19.1.2" class="ltx_emph">max-iter</em></em><span id="algorithm1.19.19.5" class="ltx_text" style="font-size:90%;"> </span><span id="algorithm1.19.19.6" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="algorithm1.19.19.7" class="ltx_text" style="font-size:90%;"> </span>
</div>
<div id="algorithm1.20.20" class="ltx_listingline">
<span id="algorithm1.20.20.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.20.20.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.20.20.3" class="ltx_text" style="font-size:90%;">
Randomly sample a mini-batch of data </span><math id="algorithm1.20.20.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="algorithm1.20.20.m1.1a"><mi mathsize="90%" id="algorithm1.20.20.m1.1.1" xref="algorithm1.20.20.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.20.20.m1.1b"><ci id="algorithm1.20.20.m1.1.1.cmml" xref="algorithm1.20.20.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.20.20.m1.1c">x</annotation></semantics></math><span id="algorithm1.20.20.4" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.21.21" class="ltx_listingline">
<span id="algorithm1.21.21.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.21.21.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.21.21.3" class="ltx_text" style="font-size:90%;">
Initialize the sampled architecture set </span><math id="algorithm1.21.21.m1.1" class="ltx_Math" alttext="\Omega=\emptyset" display="inline"><semantics id="algorithm1.21.21.m1.1a"><mrow id="algorithm1.21.21.m1.1.1" xref="algorithm1.21.21.m1.1.1.cmml"><mi mathsize="90%" mathvariant="normal" id="algorithm1.21.21.m1.1.1.2" xref="algorithm1.21.21.m1.1.1.2.cmml">Ω</mi><mo mathsize="90%" id="algorithm1.21.21.m1.1.1.1" xref="algorithm1.21.21.m1.1.1.1.cmml">=</mo><mi mathsize="90%" mathvariant="normal" id="algorithm1.21.21.m1.1.1.3" xref="algorithm1.21.21.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.21.21.m1.1b"><apply id="algorithm1.21.21.m1.1.1.cmml" xref="algorithm1.21.21.m1.1.1"><eq id="algorithm1.21.21.m1.1.1.1.cmml" xref="algorithm1.21.21.m1.1.1.1"></eq><ci id="algorithm1.21.21.m1.1.1.2.cmml" xref="algorithm1.21.21.m1.1.1.2">Ω</ci><emptyset id="algorithm1.21.21.m1.1.1.3.cmml" xref="algorithm1.21.21.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.21.21.m1.1c">\Omega=\emptyset</annotation></semantics></math><span id="algorithm1.21.21.4" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.35.38" class="ltx_listingline">
<span id="algorithm1.35.38.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.38.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.35.38.3" class="ltx_text" style="font-size:90%;">
# add the smallest and largest submodel architectures.</span>
</div>
<div id="algorithm1.22.22" class="ltx_listingline">
<span id="algorithm1.22.22.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.22.22.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.22.22.3" class="ltx_text" style="font-size:90%;">
</span><math id="algorithm1.22.22.m1.2" class="ltx_Math" alttext="\Omega\leftarrow\Omega\cup\{a_{s},a_{l}\}" display="inline"><semantics id="algorithm1.22.22.m1.2a"><mrow id="algorithm1.22.22.m1.2.2" xref="algorithm1.22.22.m1.2.2.cmml"><mi mathsize="90%" mathvariant="normal" id="algorithm1.22.22.m1.2.2.4" xref="algorithm1.22.22.m1.2.2.4.cmml">Ω</mi><mo mathsize="90%" stretchy="false" id="algorithm1.22.22.m1.2.2.3" xref="algorithm1.22.22.m1.2.2.3.cmml">←</mo><mrow id="algorithm1.22.22.m1.2.2.2" xref="algorithm1.22.22.m1.2.2.2.cmml"><mi mathsize="90%" mathvariant="normal" id="algorithm1.22.22.m1.2.2.2.4" xref="algorithm1.22.22.m1.2.2.2.4.cmml">Ω</mi><mo mathsize="90%" id="algorithm1.22.22.m1.2.2.2.3" xref="algorithm1.22.22.m1.2.2.2.3.cmml">∪</mo><mrow id="algorithm1.22.22.m1.2.2.2.2.2" xref="algorithm1.22.22.m1.2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.22.22.m1.2.2.2.2.2.3" xref="algorithm1.22.22.m1.2.2.2.2.3.cmml">{</mo><msub id="algorithm1.22.22.m1.1.1.1.1.1.1" xref="algorithm1.22.22.m1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="algorithm1.22.22.m1.1.1.1.1.1.1.2" xref="algorithm1.22.22.m1.1.1.1.1.1.1.2.cmml">a</mi><mi mathsize="90%" id="algorithm1.22.22.m1.1.1.1.1.1.1.3" xref="algorithm1.22.22.m1.1.1.1.1.1.1.3.cmml">s</mi></msub><mo mathsize="90%" id="algorithm1.22.22.m1.2.2.2.2.2.4" xref="algorithm1.22.22.m1.2.2.2.2.3.cmml">,</mo><msub id="algorithm1.22.22.m1.2.2.2.2.2.2" xref="algorithm1.22.22.m1.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="algorithm1.22.22.m1.2.2.2.2.2.2.2" xref="algorithm1.22.22.m1.2.2.2.2.2.2.2.cmml">a</mi><mi mathsize="90%" id="algorithm1.22.22.m1.2.2.2.2.2.2.3" xref="algorithm1.22.22.m1.2.2.2.2.2.2.3.cmml">l</mi></msub><mo maxsize="90%" minsize="90%" id="algorithm1.22.22.m1.2.2.2.2.2.5" xref="algorithm1.22.22.m1.2.2.2.2.3.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.22.22.m1.2b"><apply id="algorithm1.22.22.m1.2.2.cmml" xref="algorithm1.22.22.m1.2.2"><ci id="algorithm1.22.22.m1.2.2.3.cmml" xref="algorithm1.22.22.m1.2.2.3">←</ci><ci id="algorithm1.22.22.m1.2.2.4.cmml" xref="algorithm1.22.22.m1.2.2.4">Ω</ci><apply id="algorithm1.22.22.m1.2.2.2.cmml" xref="algorithm1.22.22.m1.2.2.2"><union id="algorithm1.22.22.m1.2.2.2.3.cmml" xref="algorithm1.22.22.m1.2.2.2.3"></union><ci id="algorithm1.22.22.m1.2.2.2.4.cmml" xref="algorithm1.22.22.m1.2.2.2.4">Ω</ci><set id="algorithm1.22.22.m1.2.2.2.2.3.cmml" xref="algorithm1.22.22.m1.2.2.2.2.2"><apply id="algorithm1.22.22.m1.1.1.1.1.1.1.cmml" xref="algorithm1.22.22.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.22.22.m1.1.1.1.1.1.1.1.cmml" xref="algorithm1.22.22.m1.1.1.1.1.1.1">subscript</csymbol><ci id="algorithm1.22.22.m1.1.1.1.1.1.1.2.cmml" xref="algorithm1.22.22.m1.1.1.1.1.1.1.2">𝑎</ci><ci id="algorithm1.22.22.m1.1.1.1.1.1.1.3.cmml" xref="algorithm1.22.22.m1.1.1.1.1.1.1.3">𝑠</ci></apply><apply id="algorithm1.22.22.m1.2.2.2.2.2.2.cmml" xref="algorithm1.22.22.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="algorithm1.22.22.m1.2.2.2.2.2.2.1.cmml" xref="algorithm1.22.22.m1.2.2.2.2.2.2">subscript</csymbol><ci id="algorithm1.22.22.m1.2.2.2.2.2.2.2.cmml" xref="algorithm1.22.22.m1.2.2.2.2.2.2.2">𝑎</ci><ci id="algorithm1.22.22.m1.2.2.2.2.2.2.3.cmml" xref="algorithm1.22.22.m1.2.2.2.2.2.2.3">𝑙</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.22.22.m1.2c">\Omega\leftarrow\Omega\cup\{a_{s},a_{l}\}</annotation></semantics></math><span id="algorithm1.22.22.4" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.23.23" class="ltx_listingline">
<span id="algorithm1.23.23.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.23.23.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.23.23.3" class="ltx_text" style="font-size:90%;">
# add another </span><math id="algorithm1.23.23.m1.1" class="ltx_Math" alttext="K-2" display="inline"><semantics id="algorithm1.23.23.m1.1a"><mrow id="algorithm1.23.23.m1.1.1" xref="algorithm1.23.23.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.23.23.m1.1.1.2" xref="algorithm1.23.23.m1.1.1.2.cmml">K</mi><mo mathsize="90%" id="algorithm1.23.23.m1.1.1.1" xref="algorithm1.23.23.m1.1.1.1.cmml">−</mo><mn mathsize="90%" id="algorithm1.23.23.m1.1.1.3" xref="algorithm1.23.23.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.23.23.m1.1b"><apply id="algorithm1.23.23.m1.1.1.cmml" xref="algorithm1.23.23.m1.1.1"><minus id="algorithm1.23.23.m1.1.1.1.cmml" xref="algorithm1.23.23.m1.1.1.1"></minus><ci id="algorithm1.23.23.m1.1.1.2.cmml" xref="algorithm1.23.23.m1.1.1.2">𝐾</ci><cn type="integer" id="algorithm1.23.23.m1.1.1.3.cmml" xref="algorithm1.23.23.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.23.23.m1.1c">K-2</annotation></semantics></math><span id="algorithm1.23.23.4" class="ltx_text" style="font-size:90%;"> architectures via random sampling.</span>
</div>
<div id="algorithm1.25.25" class="ltx_listingline">
<span id="algorithm1.25.25.3" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.25.25.4" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.25.25.5" class="ltx_text" style="font-size:90%;">
</span><span id="algorithm1.25.25.6" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="algorithm1.25.25.7" class="ltx_text" style="font-size:90%;"> </span><em id="algorithm1.25.25.2" class="ltx_emph ltx_font_italic" style="font-size:90%;"><math id="algorithm1.24.24.1.m1.1" class="ltx_Math" alttext="j=1" display="inline"><semantics id="algorithm1.24.24.1.m1.1a"><mrow id="algorithm1.24.24.1.m1.1.1" xref="algorithm1.24.24.1.m1.1.1.cmml"><mi id="algorithm1.24.24.1.m1.1.1.2" xref="algorithm1.24.24.1.m1.1.1.2.cmml">j</mi><mo id="algorithm1.24.24.1.m1.1.1.1" xref="algorithm1.24.24.1.m1.1.1.1.cmml">=</mo><mn id="algorithm1.24.24.1.m1.1.1.3" xref="algorithm1.24.24.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.24.24.1.m1.1b"><apply id="algorithm1.24.24.1.m1.1.1.cmml" xref="algorithm1.24.24.1.m1.1.1"><eq id="algorithm1.24.24.1.m1.1.1.1.cmml" xref="algorithm1.24.24.1.m1.1.1.1"></eq><ci id="algorithm1.24.24.1.m1.1.1.2.cmml" xref="algorithm1.24.24.1.m1.1.1.2">𝑗</ci><cn type="integer" id="algorithm1.24.24.1.m1.1.1.3.cmml" xref="algorithm1.24.24.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.24.24.1.m1.1c">j=1</annotation></semantics></math> <span id="algorithm1.25.25.2.1" class="ltx_text ltx_font_bold ltx_font_upright">to</span> <math id="algorithm1.25.25.2.m2.1" class="ltx_Math" alttext="K-2" display="inline"><semantics id="algorithm1.25.25.2.m2.1a"><mrow id="algorithm1.25.25.2.m2.1.1" xref="algorithm1.25.25.2.m2.1.1.cmml"><mi id="algorithm1.25.25.2.m2.1.1.2" xref="algorithm1.25.25.2.m2.1.1.2.cmml">K</mi><mo id="algorithm1.25.25.2.m2.1.1.1" xref="algorithm1.25.25.2.m2.1.1.1.cmml">−</mo><mn id="algorithm1.25.25.2.m2.1.1.3" xref="algorithm1.25.25.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.25.25.2.m2.1b"><apply id="algorithm1.25.25.2.m2.1.1.cmml" xref="algorithm1.25.25.2.m2.1.1"><minus id="algorithm1.25.25.2.m2.1.1.1.cmml" xref="algorithm1.25.25.2.m2.1.1.1"></minus><ci id="algorithm1.25.25.2.m2.1.1.2.cmml" xref="algorithm1.25.25.2.m2.1.1.2">𝐾</ci><cn type="integer" id="algorithm1.25.25.2.m2.1.1.3.cmml" xref="algorithm1.25.25.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.25.25.2.m2.1c">K-2</annotation></semantics></math></em><span id="algorithm1.25.25.8" class="ltx_text" style="font-size:90%;"> </span><span id="algorithm1.25.25.9" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="algorithm1.25.25.10" class="ltx_text" style="font-size:90%;"> </span>
</div>
<div id="algorithm1.26.26" class="ltx_listingline">
<span id="algorithm1.26.26.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.26.26.2" class="ltx_text" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.26.26.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.26.26.4" class="ltx_text" style="font-size:90%;">
Randomly sample a submodel architecture </span><math id="algorithm1.26.26.m1.1" class="ltx_Math" alttext="a\sim\mathcal{S}_{\backslash{\Omega}}" display="inline"><semantics id="algorithm1.26.26.m1.1a"><mrow id="algorithm1.26.26.m1.1.1" xref="algorithm1.26.26.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.26.26.m1.1.1.2" xref="algorithm1.26.26.m1.1.1.2.cmml">a</mi><mo mathsize="90%" id="algorithm1.26.26.m1.1.1.1" xref="algorithm1.26.26.m1.1.1.1.cmml">∼</mo><msub id="algorithm1.26.26.m1.1.1.3" xref="algorithm1.26.26.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="algorithm1.26.26.m1.1.1.3.2" xref="algorithm1.26.26.m1.1.1.3.2.cmml">𝒮</mi><mrow id="algorithm1.26.26.m1.1.1.3.3" xref="algorithm1.26.26.m1.1.1.3.3.cmml"><mi id="algorithm1.26.26.m1.1.1.3.3.2" xref="algorithm1.26.26.m1.1.1.3.3.2.cmml"></mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="algorithm1.26.26.m1.1.1.3.3.1" xref="algorithm1.26.26.m1.1.1.3.3.1.cmml">\</mo><mi mathsize="90%" mathvariant="normal" id="algorithm1.26.26.m1.1.1.3.3.3" xref="algorithm1.26.26.m1.1.1.3.3.3.cmml">Ω</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.26.26.m1.1b"><apply id="algorithm1.26.26.m1.1.1.cmml" xref="algorithm1.26.26.m1.1.1"><csymbol cd="latexml" id="algorithm1.26.26.m1.1.1.1.cmml" xref="algorithm1.26.26.m1.1.1.1">similar-to</csymbol><ci id="algorithm1.26.26.m1.1.1.2.cmml" xref="algorithm1.26.26.m1.1.1.2">𝑎</ci><apply id="algorithm1.26.26.m1.1.1.3.cmml" xref="algorithm1.26.26.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.26.26.m1.1.1.3.1.cmml" xref="algorithm1.26.26.m1.1.1.3">subscript</csymbol><ci id="algorithm1.26.26.m1.1.1.3.2.cmml" xref="algorithm1.26.26.m1.1.1.3.2">𝒮</ci><apply id="algorithm1.26.26.m1.1.1.3.3.cmml" xref="algorithm1.26.26.m1.1.1.3.3"><ci id="algorithm1.26.26.m1.1.1.3.3.1.cmml" xref="algorithm1.26.26.m1.1.1.3.3.1">\</ci><csymbol cd="latexml" id="algorithm1.26.26.m1.1.1.3.3.2.cmml" xref="algorithm1.26.26.m1.1.1.3.3.2">absent</csymbol><ci id="algorithm1.26.26.m1.1.1.3.3.3.cmml" xref="algorithm1.26.26.m1.1.1.3.3.3">Ω</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.26.26.m1.1c">a\sim\mathcal{S}_{\backslash{\Omega}}</annotation></semantics></math><span id="algorithm1.26.26.5" class="ltx_text" style="font-size:90%;"> ;</span>
</div>
<div id="algorithm1.27.27" class="ltx_listingline">
<span id="algorithm1.27.27.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.27.27.2" class="ltx_text" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.27.27.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.27.27.4" class="ltx_text" style="font-size:90%;">
</span><math id="algorithm1.27.27.m1.1" class="ltx_Math" alttext="\Omega\leftarrow\Omega\cup a" display="inline"><semantics id="algorithm1.27.27.m1.1a"><mrow id="algorithm1.27.27.m1.1.1" xref="algorithm1.27.27.m1.1.1.cmml"><mi mathsize="90%" mathvariant="normal" id="algorithm1.27.27.m1.1.1.2" xref="algorithm1.27.27.m1.1.1.2.cmml">Ω</mi><mo mathsize="90%" stretchy="false" id="algorithm1.27.27.m1.1.1.1" xref="algorithm1.27.27.m1.1.1.1.cmml">←</mo><mrow id="algorithm1.27.27.m1.1.1.3" xref="algorithm1.27.27.m1.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="algorithm1.27.27.m1.1.1.3.2" xref="algorithm1.27.27.m1.1.1.3.2.cmml">Ω</mi><mo mathsize="90%" id="algorithm1.27.27.m1.1.1.3.1" xref="algorithm1.27.27.m1.1.1.3.1.cmml">∪</mo><mi mathsize="90%" id="algorithm1.27.27.m1.1.1.3.3" xref="algorithm1.27.27.m1.1.1.3.3.cmml">a</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.27.27.m1.1b"><apply id="algorithm1.27.27.m1.1.1.cmml" xref="algorithm1.27.27.m1.1.1"><ci id="algorithm1.27.27.m1.1.1.1.cmml" xref="algorithm1.27.27.m1.1.1.1">←</ci><ci id="algorithm1.27.27.m1.1.1.2.cmml" xref="algorithm1.27.27.m1.1.1.2">Ω</ci><apply id="algorithm1.27.27.m1.1.1.3.cmml" xref="algorithm1.27.27.m1.1.1.3"><union id="algorithm1.27.27.m1.1.1.3.1.cmml" xref="algorithm1.27.27.m1.1.1.3.1"></union><ci id="algorithm1.27.27.m1.1.1.3.2.cmml" xref="algorithm1.27.27.m1.1.1.3.2">Ω</ci><ci id="algorithm1.27.27.m1.1.1.3.3.cmml" xref="algorithm1.27.27.m1.1.1.3.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.27.27.m1.1c">\Omega\leftarrow\Omega\cup a</annotation></semantics></math><span id="algorithm1.27.27.5" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="algorithm1.35.39" class="ltx_listingline">
<span id="algorithm1.35.39.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.39.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.35.39.3" class="ltx_text" style="font-size:90%;"> end for</span>
</div>
<div id="algorithm1.35.40" class="ltx_listingline">
<span id="algorithm1.35.40.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.40.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.35.40.3" class="ltx_text" style="font-size:90%;"># submodel training using knowledge distillation.</span>
</div>
<div id="algorithm1.28.28" class="ltx_listingline">
<span id="algorithm1.28.28.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.28.28.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.28.28.3" class="ltx_text" style="font-size:90%;">
Feed-forward the teacher model: </span><math id="algorithm1.28.28.m1.1" class="ltx_Math" alttext="y=M_{\texttt{teacher}}(x)" display="inline"><semantics id="algorithm1.28.28.m1.1a"><mrow id="algorithm1.28.28.m1.1.2" xref="algorithm1.28.28.m1.1.2.cmml"><mi mathsize="90%" id="algorithm1.28.28.m1.1.2.2" xref="algorithm1.28.28.m1.1.2.2.cmml">y</mi><mo mathsize="90%" id="algorithm1.28.28.m1.1.2.1" xref="algorithm1.28.28.m1.1.2.1.cmml">=</mo><mrow id="algorithm1.28.28.m1.1.2.3" xref="algorithm1.28.28.m1.1.2.3.cmml"><msub id="algorithm1.28.28.m1.1.2.3.2" xref="algorithm1.28.28.m1.1.2.3.2.cmml"><mi mathsize="90%" id="algorithm1.28.28.m1.1.2.3.2.2" xref="algorithm1.28.28.m1.1.2.3.2.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.28.28.m1.1.2.3.2.3" xref="algorithm1.28.28.m1.1.2.3.2.3a.cmml">teacher</mtext></msub><mo lspace="0em" rspace="0em" id="algorithm1.28.28.m1.1.2.3.1" xref="algorithm1.28.28.m1.1.2.3.1.cmml">​</mo><mrow id="algorithm1.28.28.m1.1.2.3.3.2" xref="algorithm1.28.28.m1.1.2.3.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.28.28.m1.1.2.3.3.2.1" xref="algorithm1.28.28.m1.1.2.3.cmml">(</mo><mi mathsize="90%" id="algorithm1.28.28.m1.1.1" xref="algorithm1.28.28.m1.1.1.cmml">x</mi><mo maxsize="90%" minsize="90%" id="algorithm1.28.28.m1.1.2.3.3.2.2" xref="algorithm1.28.28.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.28.28.m1.1b"><apply id="algorithm1.28.28.m1.1.2.cmml" xref="algorithm1.28.28.m1.1.2"><eq id="algorithm1.28.28.m1.1.2.1.cmml" xref="algorithm1.28.28.m1.1.2.1"></eq><ci id="algorithm1.28.28.m1.1.2.2.cmml" xref="algorithm1.28.28.m1.1.2.2">𝑦</ci><apply id="algorithm1.28.28.m1.1.2.3.cmml" xref="algorithm1.28.28.m1.1.2.3"><times id="algorithm1.28.28.m1.1.2.3.1.cmml" xref="algorithm1.28.28.m1.1.2.3.1"></times><apply id="algorithm1.28.28.m1.1.2.3.2.cmml" xref="algorithm1.28.28.m1.1.2.3.2"><csymbol cd="ambiguous" id="algorithm1.28.28.m1.1.2.3.2.1.cmml" xref="algorithm1.28.28.m1.1.2.3.2">subscript</csymbol><ci id="algorithm1.28.28.m1.1.2.3.2.2.cmml" xref="algorithm1.28.28.m1.1.2.3.2.2">𝑀</ci><ci id="algorithm1.28.28.m1.1.2.3.2.3a.cmml" xref="algorithm1.28.28.m1.1.2.3.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.28.28.m1.1.2.3.2.3.cmml" xref="algorithm1.28.28.m1.1.2.3.2.3">teacher</mtext></ci></apply><ci id="algorithm1.28.28.m1.1.1.cmml" xref="algorithm1.28.28.m1.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.28.28.m1.1c">y=M_{\texttt{teacher}}(x)</annotation></semantics></math><span id="algorithm1.28.28.4" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.30.30" class="ltx_listingline">
<span id="algorithm1.30.30.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.30.30.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.30.30.3" class="ltx_text" style="font-size:90%;">
Freeze </span><math id="algorithm1.29.29.m1.1" class="ltx_Math" alttext="M_{\texttt{teacher}}" display="inline"><semantics id="algorithm1.29.29.m1.1a"><msub id="algorithm1.29.29.m1.1.1" xref="algorithm1.29.29.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.29.29.m1.1.1.2" xref="algorithm1.29.29.m1.1.1.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.29.29.m1.1.1.3" xref="algorithm1.29.29.m1.1.1.3a.cmml">teacher</mtext></msub><annotation-xml encoding="MathML-Content" id="algorithm1.29.29.m1.1b"><apply id="algorithm1.29.29.m1.1.1.cmml" xref="algorithm1.29.29.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.29.29.m1.1.1.1.cmml" xref="algorithm1.29.29.m1.1.1">subscript</csymbol><ci id="algorithm1.29.29.m1.1.1.2.cmml" xref="algorithm1.29.29.m1.1.1.2">𝑀</ci><ci id="algorithm1.29.29.m1.1.1.3a.cmml" xref="algorithm1.29.29.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.29.29.m1.1.1.3.cmml" xref="algorithm1.29.29.m1.1.1.3">teacher</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.29.29.m1.1c">M_{\texttt{teacher}}</annotation></semantics></math><span id="algorithm1.30.30.4" class="ltx_text" style="font-size:90%;"> by stopping gradients: </span><math id="algorithm1.30.30.m2.2" class="ltx_Math" alttext="y.\texttt{detach}()" display="inline"><semantics id="algorithm1.30.30.m2.2a"><mrow id="algorithm1.30.30.m2.2.2.1" xref="algorithm1.30.30.m2.2.2.2.cmml"><mi mathsize="90%" id="algorithm1.30.30.m2.1.1" xref="algorithm1.30.30.m2.1.1.cmml">y</mi><mo lspace="0em" mathsize="90%" rspace="0.167em" id="algorithm1.30.30.m2.2.2.1.2" xref="algorithm1.30.30.m2.2.2.2a.cmml">.</mo><mrow id="algorithm1.30.30.m2.2.2.1.1" xref="algorithm1.30.30.m2.2.2.1.1.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.30.30.m2.2.2.1.1.2" xref="algorithm1.30.30.m2.2.2.1.1.2a.cmml">detach</mtext><mo lspace="0em" rspace="0em" id="algorithm1.30.30.m2.2.2.1.1.1" xref="algorithm1.30.30.m2.2.2.1.1.1.cmml">​</mo><mrow id="algorithm1.30.30.m2.2.2.1.1.3.2" xref="algorithm1.30.30.m2.2.2.1.1.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.30.30.m2.2.2.1.1.3.2.1" xref="algorithm1.30.30.m2.2.2.1.1.3.1.cmml">(</mo><mo maxsize="90%" minsize="90%" id="algorithm1.30.30.m2.2.2.1.1.3.2.2" xref="algorithm1.30.30.m2.2.2.1.1.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.30.30.m2.2b"><apply id="algorithm1.30.30.m2.2.2.2.cmml" xref="algorithm1.30.30.m2.2.2.1"><csymbol cd="ambiguous" id="algorithm1.30.30.m2.2.2.2a.cmml" xref="algorithm1.30.30.m2.2.2.1.2">formulae-sequence</csymbol><ci id="algorithm1.30.30.m2.1.1.cmml" xref="algorithm1.30.30.m2.1.1">𝑦</ci><apply id="algorithm1.30.30.m2.2.2.1.1.cmml" xref="algorithm1.30.30.m2.2.2.1.1"><times id="algorithm1.30.30.m2.2.2.1.1.1.cmml" xref="algorithm1.30.30.m2.2.2.1.1.1"></times><ci id="algorithm1.30.30.m2.2.2.1.1.2a.cmml" xref="algorithm1.30.30.m2.2.2.1.1.2"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.30.30.m2.2.2.1.1.2.cmml" xref="algorithm1.30.30.m2.2.2.1.1.2">detach</mtext></ci><list id="algorithm1.30.30.m2.2.2.1.1.3.1.cmml" xref="algorithm1.30.30.m2.2.2.1.1.3.2.1"></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.30.30.m2.2c">y.\texttt{detach}()</annotation></semantics></math><span id="algorithm1.30.30.5" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.31.31" class="ltx_listingline">
<span id="algorithm1.31.31.2" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.31.31.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.31.31.4" class="ltx_text" style="font-size:90%;">
</span><span id="algorithm1.31.31.5" class="ltx_text ltx_font_bold" style="font-size:90%;">foreach</span><span id="algorithm1.31.31.6" class="ltx_text" style="font-size:90%;"> </span><em id="algorithm1.31.31.1" class="ltx_emph ltx_font_italic" style="font-size:90%;"><math id="algorithm1.31.31.1.m1.1" class="ltx_Math" alttext="a\in\Omega" display="inline"><semantics id="algorithm1.31.31.1.m1.1a"><mrow id="algorithm1.31.31.1.m1.1.1" xref="algorithm1.31.31.1.m1.1.1.cmml"><mi id="algorithm1.31.31.1.m1.1.1.2" xref="algorithm1.31.31.1.m1.1.1.2.cmml">a</mi><mo id="algorithm1.31.31.1.m1.1.1.1" xref="algorithm1.31.31.1.m1.1.1.1.cmml">∈</mo><mi mathvariant="normal" id="algorithm1.31.31.1.m1.1.1.3" xref="algorithm1.31.31.1.m1.1.1.3.cmml">Ω</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.31.31.1.m1.1b"><apply id="algorithm1.31.31.1.m1.1.1.cmml" xref="algorithm1.31.31.1.m1.1.1"><in id="algorithm1.31.31.1.m1.1.1.1.cmml" xref="algorithm1.31.31.1.m1.1.1.1"></in><ci id="algorithm1.31.31.1.m1.1.1.2.cmml" xref="algorithm1.31.31.1.m1.1.1.2">𝑎</ci><ci id="algorithm1.31.31.1.m1.1.1.3.cmml" xref="algorithm1.31.31.1.m1.1.1.3">Ω</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.31.31.1.m1.1c">a\in\Omega</annotation></semantics></math></em><span id="algorithm1.31.31.7" class="ltx_text" style="font-size:90%;"> </span><span id="algorithm1.31.31.8" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="algorithm1.31.31.9" class="ltx_text" style="font-size:90%;"> </span>
</div>
<div id="algorithm1.32.32" class="ltx_listingline">
<span id="algorithm1.32.32.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.32.32.2" class="ltx_text" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.32.32.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.32.32.4" class="ltx_text" style="font-size:90%;">
Feed-forward the submodel: </span><math id="algorithm1.32.32.m1.2" class="ltx_Math" alttext="\hat{y}=M_{\texttt{BST}}^{(a)}(x)" display="inline"><semantics id="algorithm1.32.32.m1.2a"><mrow id="algorithm1.32.32.m1.2.3" xref="algorithm1.32.32.m1.2.3.cmml"><mover accent="true" id="algorithm1.32.32.m1.2.3.2" xref="algorithm1.32.32.m1.2.3.2.cmml"><mi mathsize="90%" id="algorithm1.32.32.m1.2.3.2.2" xref="algorithm1.32.32.m1.2.3.2.2.cmml">y</mi><mo mathsize="90%" id="algorithm1.32.32.m1.2.3.2.1" xref="algorithm1.32.32.m1.2.3.2.1.cmml">^</mo></mover><mo mathsize="90%" id="algorithm1.32.32.m1.2.3.1" xref="algorithm1.32.32.m1.2.3.1.cmml">=</mo><mrow id="algorithm1.32.32.m1.2.3.3" xref="algorithm1.32.32.m1.2.3.3.cmml"><msubsup id="algorithm1.32.32.m1.2.3.3.2" xref="algorithm1.32.32.m1.2.3.3.2.cmml"><mi mathsize="90%" id="algorithm1.32.32.m1.2.3.3.2.2.2" xref="algorithm1.32.32.m1.2.3.3.2.2.2.cmml">M</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.32.32.m1.2.3.3.2.2.3" xref="algorithm1.32.32.m1.2.3.3.2.2.3a.cmml">BST</mtext><mrow id="algorithm1.32.32.m1.1.1.1.3" xref="algorithm1.32.32.m1.2.3.3.2.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.32.32.m1.1.1.1.3.1" xref="algorithm1.32.32.m1.2.3.3.2.cmml">(</mo><mi mathsize="90%" id="algorithm1.32.32.m1.1.1.1.1" xref="algorithm1.32.32.m1.1.1.1.1.cmml">a</mi><mo maxsize="90%" minsize="90%" id="algorithm1.32.32.m1.1.1.1.3.2" xref="algorithm1.32.32.m1.2.3.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="algorithm1.32.32.m1.2.3.3.1" xref="algorithm1.32.32.m1.2.3.3.1.cmml">​</mo><mrow id="algorithm1.32.32.m1.2.3.3.3.2" xref="algorithm1.32.32.m1.2.3.3.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.32.32.m1.2.3.3.3.2.1" xref="algorithm1.32.32.m1.2.3.3.cmml">(</mo><mi mathsize="90%" id="algorithm1.32.32.m1.2.2" xref="algorithm1.32.32.m1.2.2.cmml">x</mi><mo maxsize="90%" minsize="90%" id="algorithm1.32.32.m1.2.3.3.3.2.2" xref="algorithm1.32.32.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.32.32.m1.2b"><apply id="algorithm1.32.32.m1.2.3.cmml" xref="algorithm1.32.32.m1.2.3"><eq id="algorithm1.32.32.m1.2.3.1.cmml" xref="algorithm1.32.32.m1.2.3.1"></eq><apply id="algorithm1.32.32.m1.2.3.2.cmml" xref="algorithm1.32.32.m1.2.3.2"><ci id="algorithm1.32.32.m1.2.3.2.1.cmml" xref="algorithm1.32.32.m1.2.3.2.1">^</ci><ci id="algorithm1.32.32.m1.2.3.2.2.cmml" xref="algorithm1.32.32.m1.2.3.2.2">𝑦</ci></apply><apply id="algorithm1.32.32.m1.2.3.3.cmml" xref="algorithm1.32.32.m1.2.3.3"><times id="algorithm1.32.32.m1.2.3.3.1.cmml" xref="algorithm1.32.32.m1.2.3.3.1"></times><apply id="algorithm1.32.32.m1.2.3.3.2.cmml" xref="algorithm1.32.32.m1.2.3.3.2"><csymbol cd="ambiguous" id="algorithm1.32.32.m1.2.3.3.2.1.cmml" xref="algorithm1.32.32.m1.2.3.3.2">superscript</csymbol><apply id="algorithm1.32.32.m1.2.3.3.2.2.cmml" xref="algorithm1.32.32.m1.2.3.3.2"><csymbol cd="ambiguous" id="algorithm1.32.32.m1.2.3.3.2.2.1.cmml" xref="algorithm1.32.32.m1.2.3.3.2">subscript</csymbol><ci id="algorithm1.32.32.m1.2.3.3.2.2.2.cmml" xref="algorithm1.32.32.m1.2.3.3.2.2.2">𝑀</ci><ci id="algorithm1.32.32.m1.2.3.3.2.2.3a.cmml" xref="algorithm1.32.32.m1.2.3.3.2.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.32.32.m1.2.3.3.2.2.3.cmml" xref="algorithm1.32.32.m1.2.3.3.2.2.3">BST</mtext></ci></apply><ci id="algorithm1.32.32.m1.1.1.1.1.cmml" xref="algorithm1.32.32.m1.1.1.1.1">𝑎</ci></apply><ci id="algorithm1.32.32.m1.2.2.cmml" xref="algorithm1.32.32.m1.2.2">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.32.32.m1.2c">\hat{y}=M_{\texttt{BST}}^{(a)}(x)</annotation></semantics></math><span id="algorithm1.32.32.5" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.33.33" class="ltx_listingline">
<span id="algorithm1.33.33.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.33.33.2" class="ltx_text" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.33.33.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.33.33.4" class="ltx_text" style="font-size:90%;">
Compute loss: </span><math id="algorithm1.33.33.m1.2" class="ltx_Math" alttext="loss=\texttt{KD}(y,\hat{y})" display="inline"><semantics id="algorithm1.33.33.m1.2a"><mrow id="algorithm1.33.33.m1.2.3" xref="algorithm1.33.33.m1.2.3.cmml"><mrow id="algorithm1.33.33.m1.2.3.2" xref="algorithm1.33.33.m1.2.3.2.cmml"><mi mathsize="90%" id="algorithm1.33.33.m1.2.3.2.2" xref="algorithm1.33.33.m1.2.3.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="algorithm1.33.33.m1.2.3.2.1" xref="algorithm1.33.33.m1.2.3.2.1.cmml">​</mo><mi mathsize="90%" id="algorithm1.33.33.m1.2.3.2.3" xref="algorithm1.33.33.m1.2.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="algorithm1.33.33.m1.2.3.2.1a" xref="algorithm1.33.33.m1.2.3.2.1.cmml">​</mo><mi mathsize="90%" id="algorithm1.33.33.m1.2.3.2.4" xref="algorithm1.33.33.m1.2.3.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="algorithm1.33.33.m1.2.3.2.1b" xref="algorithm1.33.33.m1.2.3.2.1.cmml">​</mo><mi mathsize="90%" id="algorithm1.33.33.m1.2.3.2.5" xref="algorithm1.33.33.m1.2.3.2.5.cmml">s</mi></mrow><mo mathsize="90%" id="algorithm1.33.33.m1.2.3.1" xref="algorithm1.33.33.m1.2.3.1.cmml">=</mo><mrow id="algorithm1.33.33.m1.2.3.3" xref="algorithm1.33.33.m1.2.3.3.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.33.33.m1.2.3.3.2" xref="algorithm1.33.33.m1.2.3.3.2a.cmml">KD</mtext><mo lspace="0em" rspace="0em" id="algorithm1.33.33.m1.2.3.3.1" xref="algorithm1.33.33.m1.2.3.3.1.cmml">​</mo><mrow id="algorithm1.33.33.m1.2.3.3.3.2" xref="algorithm1.33.33.m1.2.3.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.33.33.m1.2.3.3.3.2.1" xref="algorithm1.33.33.m1.2.3.3.3.1.cmml">(</mo><mi mathsize="90%" id="algorithm1.33.33.m1.1.1" xref="algorithm1.33.33.m1.1.1.cmml">y</mi><mo mathsize="90%" id="algorithm1.33.33.m1.2.3.3.3.2.2" xref="algorithm1.33.33.m1.2.3.3.3.1.cmml">,</mo><mover accent="true" id="algorithm1.33.33.m1.2.2" xref="algorithm1.33.33.m1.2.2.cmml"><mi mathsize="90%" id="algorithm1.33.33.m1.2.2.2" xref="algorithm1.33.33.m1.2.2.2.cmml">y</mi><mo mathsize="90%" id="algorithm1.33.33.m1.2.2.1" xref="algorithm1.33.33.m1.2.2.1.cmml">^</mo></mover><mo maxsize="90%" minsize="90%" id="algorithm1.33.33.m1.2.3.3.3.2.3" xref="algorithm1.33.33.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.33.33.m1.2b"><apply id="algorithm1.33.33.m1.2.3.cmml" xref="algorithm1.33.33.m1.2.3"><eq id="algorithm1.33.33.m1.2.3.1.cmml" xref="algorithm1.33.33.m1.2.3.1"></eq><apply id="algorithm1.33.33.m1.2.3.2.cmml" xref="algorithm1.33.33.m1.2.3.2"><times id="algorithm1.33.33.m1.2.3.2.1.cmml" xref="algorithm1.33.33.m1.2.3.2.1"></times><ci id="algorithm1.33.33.m1.2.3.2.2.cmml" xref="algorithm1.33.33.m1.2.3.2.2">𝑙</ci><ci id="algorithm1.33.33.m1.2.3.2.3.cmml" xref="algorithm1.33.33.m1.2.3.2.3">𝑜</ci><ci id="algorithm1.33.33.m1.2.3.2.4.cmml" xref="algorithm1.33.33.m1.2.3.2.4">𝑠</ci><ci id="algorithm1.33.33.m1.2.3.2.5.cmml" xref="algorithm1.33.33.m1.2.3.2.5">𝑠</ci></apply><apply id="algorithm1.33.33.m1.2.3.3.cmml" xref="algorithm1.33.33.m1.2.3.3"><times id="algorithm1.33.33.m1.2.3.3.1.cmml" xref="algorithm1.33.33.m1.2.3.3.1"></times><ci id="algorithm1.33.33.m1.2.3.3.2a.cmml" xref="algorithm1.33.33.m1.2.3.3.2"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.33.33.m1.2.3.3.2.cmml" xref="algorithm1.33.33.m1.2.3.3.2">KD</mtext></ci><interval closure="open" id="algorithm1.33.33.m1.2.3.3.3.1.cmml" xref="algorithm1.33.33.m1.2.3.3.3.2"><ci id="algorithm1.33.33.m1.1.1.cmml" xref="algorithm1.33.33.m1.1.1">𝑦</ci><apply id="algorithm1.33.33.m1.2.2.cmml" xref="algorithm1.33.33.m1.2.2"><ci id="algorithm1.33.33.m1.2.2.1.cmml" xref="algorithm1.33.33.m1.2.2.1">^</ci><ci id="algorithm1.33.33.m1.2.2.2.cmml" xref="algorithm1.33.33.m1.2.2.2">𝑦</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.33.33.m1.2c">loss=\texttt{KD}(y,\hat{y})</annotation></semantics></math><span id="algorithm1.33.33.5" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.34.34" class="ltx_listingline">
<span id="algorithm1.34.34.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.34.34.2" class="ltx_text" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.34.34.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.34.34.4" class="ltx_text" style="font-size:90%;">
Accumulate backward gradients: </span><math id="algorithm1.34.34.m1.2" class="ltx_Math" alttext="loss.\texttt{backward}()" display="inline"><semantics id="algorithm1.34.34.m1.2a"><mrow id="algorithm1.34.34.m1.2.2.2" xref="algorithm1.34.34.m1.2.2.3.cmml"><mrow id="algorithm1.34.34.m1.1.1.1.1" xref="algorithm1.34.34.m1.1.1.1.1.cmml"><mi mathsize="90%" id="algorithm1.34.34.m1.1.1.1.1.2" xref="algorithm1.34.34.m1.1.1.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="algorithm1.34.34.m1.1.1.1.1.1" xref="algorithm1.34.34.m1.1.1.1.1.1.cmml">​</mo><mi mathsize="90%" id="algorithm1.34.34.m1.1.1.1.1.3" xref="algorithm1.34.34.m1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="algorithm1.34.34.m1.1.1.1.1.1a" xref="algorithm1.34.34.m1.1.1.1.1.1.cmml">​</mo><mi mathsize="90%" id="algorithm1.34.34.m1.1.1.1.1.4" xref="algorithm1.34.34.m1.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="algorithm1.34.34.m1.1.1.1.1.1b" xref="algorithm1.34.34.m1.1.1.1.1.1.cmml">​</mo><mi mathsize="90%" id="algorithm1.34.34.m1.1.1.1.1.5" xref="algorithm1.34.34.m1.1.1.1.1.5.cmml">s</mi></mrow><mo lspace="0em" mathsize="90%" rspace="0.167em" id="algorithm1.34.34.m1.2.2.2.3" xref="algorithm1.34.34.m1.2.2.3a.cmml">.</mo><mrow id="algorithm1.34.34.m1.2.2.2.2" xref="algorithm1.34.34.m1.2.2.2.2.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.34.34.m1.2.2.2.2.2" xref="algorithm1.34.34.m1.2.2.2.2.2a.cmml">backward</mtext><mo lspace="0em" rspace="0em" id="algorithm1.34.34.m1.2.2.2.2.1" xref="algorithm1.34.34.m1.2.2.2.2.1.cmml">​</mo><mrow id="algorithm1.34.34.m1.2.2.2.2.3.2" xref="algorithm1.34.34.m1.2.2.2.2.cmml"><mo maxsize="90%" minsize="90%" id="algorithm1.34.34.m1.2.2.2.2.3.2.1" xref="algorithm1.34.34.m1.2.2.2.2.3.1.cmml">(</mo><mo maxsize="90%" minsize="90%" id="algorithm1.34.34.m1.2.2.2.2.3.2.2" xref="algorithm1.34.34.m1.2.2.2.2.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.34.34.m1.2b"><apply id="algorithm1.34.34.m1.2.2.3.cmml" xref="algorithm1.34.34.m1.2.2.2"><csymbol cd="ambiguous" id="algorithm1.34.34.m1.2.2.3a.cmml" xref="algorithm1.34.34.m1.2.2.2.3">formulae-sequence</csymbol><apply id="algorithm1.34.34.m1.1.1.1.1.cmml" xref="algorithm1.34.34.m1.1.1.1.1"><times id="algorithm1.34.34.m1.1.1.1.1.1.cmml" xref="algorithm1.34.34.m1.1.1.1.1.1"></times><ci id="algorithm1.34.34.m1.1.1.1.1.2.cmml" xref="algorithm1.34.34.m1.1.1.1.1.2">𝑙</ci><ci id="algorithm1.34.34.m1.1.1.1.1.3.cmml" xref="algorithm1.34.34.m1.1.1.1.1.3">𝑜</ci><ci id="algorithm1.34.34.m1.1.1.1.1.4.cmml" xref="algorithm1.34.34.m1.1.1.1.1.4">𝑠</ci><ci id="algorithm1.34.34.m1.1.1.1.1.5.cmml" xref="algorithm1.34.34.m1.1.1.1.1.5">𝑠</ci></apply><apply id="algorithm1.34.34.m1.2.2.2.2.cmml" xref="algorithm1.34.34.m1.2.2.2.2"><times id="algorithm1.34.34.m1.2.2.2.2.1.cmml" xref="algorithm1.34.34.m1.2.2.2.2.1"></times><ci id="algorithm1.34.34.m1.2.2.2.2.2a.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.34.34.m1.2.2.2.2.2.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2">backward</mtext></ci><list id="algorithm1.34.34.m1.2.2.2.2.3.1.cmml" xref="algorithm1.34.34.m1.2.2.2.2.3.2.1"></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.34.34.m1.2c">loss.\texttt{backward}()</annotation></semantics></math><span id="algorithm1.34.34.5" class="ltx_text" style="font-size:90%;">;</span>
</div>
<div id="algorithm1.35.41" class="ltx_listingline">
<span id="algorithm1.35.41.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.41.2" class="ltx_text" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.41.3" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.35.41.4" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="algorithm1.35.42" class="ltx_listingline">
<span id="algorithm1.35.42.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.42.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.35.42.3" class="ltx_text" style="font-size:90%;"> end foreach</span>
</div>
<div id="algorithm1.35.35" class="ltx_listingline">
<span id="algorithm1.35.35.1" class="ltx_text" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="algorithm1.35.35.2" class="ltx_text" style="font-size:90%;">   </span><span id="algorithm1.35.35.3" class="ltx_text" style="font-size:90%;">Update model parameters </span><math id="algorithm1.35.35.m1.1" class="ltx_Math" alttext="\theta_{\texttt{BST}}" display="inline"><semantics id="algorithm1.35.35.m1.1a"><msub id="algorithm1.35.35.m1.1.1" xref="algorithm1.35.35.m1.1.1.cmml"><mi mathsize="90%" id="algorithm1.35.35.m1.1.1.2" xref="algorithm1.35.35.m1.1.1.2.cmml">θ</mi><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="algorithm1.35.35.m1.1.1.3" xref="algorithm1.35.35.m1.1.1.3a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="algorithm1.35.35.m1.1b"><apply id="algorithm1.35.35.m1.1.1.cmml" xref="algorithm1.35.35.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.35.35.m1.1.1.1.cmml" xref="algorithm1.35.35.m1.1.1">subscript</csymbol><ci id="algorithm1.35.35.m1.1.1.2.cmml" xref="algorithm1.35.35.m1.1.1.2">𝜃</ci><ci id="algorithm1.35.35.m1.1.1.3a.cmml" xref="algorithm1.35.35.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="63%" id="algorithm1.35.35.m1.1.1.3.cmml" xref="algorithm1.35.35.m1.1.1.3">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.35.35.m1.1c">\theta_{\texttt{BST}}</annotation></semantics></math><span id="algorithm1.35.35.4" class="ltx_text" style="font-size:90%;">.
</span>
</div>
<div id="algorithm1.35.43" class="ltx_listingline">
<span id="algorithm1.35.43.1" class="ltx_text" style="font-size:90%;"> end for</span>
</div>
<div id="algorithm1.35.44" class="ltx_listingline">
<span id="algorithm1.35.44.1" class="ltx_text" style="font-size:90%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span id="algorithm1.39.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>Training procedure for BST.</figcaption>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.4.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.5.2" class="ltx_text ltx_font_italic">In-Depth Comparison of BST and DynaBERT</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">As mentioned above, our BST framework has close connections with DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. We conduct an in-depth comparison and describe their differences in terms of methodology.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">In terms of the width-slimming strategy, DynaBERT adopts a <em id="S3.SS5.p2.1.1" class="ltx_emph ltx_font_italic">slim-intermediate</em> strategy that only reduces the dimensionality of the intermediate representation while keeping the input and output representations unchanged, which may break the carefully designed bottleneck structure in the original Transformer architecture. In contrast, we use a <em id="S3.SS5.p2.1.2" class="ltx_emph ltx_font_italic">slim-all</em> strategy that reduces all the dimensionalities, keeping the bottleneck structure to achieve better performance.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.1" class="ltx_p">In terms of the depth-slimming strategy, DynaBERT uses a simple slimming strategy by slimming the layers uniformly. In contrast, BST introduces a <em id="S3.SS5.p3.1.1" class="ltx_emph ltx_font_italic">slim-middle</em> strategy that considers the layer importance and prefers to slim the middlemost layers first, which facilitates model performance.</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p id="S3.SS5.p4.1" class="ltx_p">In terms of the training strategy, DynaBERT uses a two-stage training paradigm in which the width and depth slimming are learned separately, with all submodels being updated in each training step. In contrast, BST uses a simpler one-stage training paradigm to learn width and depth slimming simultaneously and sample a small number of submodels in each step, which significantly improves the training efficiency. Moreover, DynaBERT maintains the submodel architectures of all the width-height combination during training which may include redundant ones. In contrast, BST additionally introduces a submodel selection strategy to remove ineffective submodel architectures before training. This strategy not only reduces the training costs but also improves the performance of the remaining submodels</p>
</div>
<div id="S3.SS5.p5" class="ltx_para">
<p id="S3.SS5.p5.1" class="ltx_p">To summarize, BST has advantages over DynaBERT in terms of training efficiency and model performance. More quantitative comparisons are provided in section <a href="#S4" title="IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental Results</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present experiments to evaluate the performance of our BST framework on two benchmark VQA datasets, namely, VQA-v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and GQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>. As mentioned above, we integrate BST with three typical Transformer-based VQA models, namely, MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, to demonstrate the effectiveness and generality of BST. Furthermore, we conduct extensive ablation experiments on VQA-v2 to explore the effects of different components.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.34.3.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S4.T1.4.2" class="ltx_text" style="font-size:90%;">Comparison to the state-of-the-art approaches on VQA-v2. For a fair comparison, the compared methods are split into two groups depending on whether they are trained from scratch or pretrained on external data (separated by a double-line). The number of parameters is calculated from an entire model, including the backbone, input and output embedding layers. The number of FLOPs is calculated from one single sample. <sup id="S4.T1.4.2.1" class="ltx_sup"><span id="S4.T1.4.2.1.1" class="ltx_text ltx_font_italic">†</span></sup>: the UNITER<math id="S4.T1.4.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{DYN}}" display="inline"><semantics id="S4.T1.4.2.m2.1b"><msub id="S4.T1.4.2.m2.1.1" xref="S4.T1.4.2.m2.1.1.cmml"><mi id="S4.T1.4.2.m2.1.1b" xref="S4.T1.4.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.T1.4.2.m2.1.1.1" xref="S4.T1.4.2.m2.1.1.1a.cmml">DYN</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.m2.1c"><apply id="S4.T1.4.2.m2.1.1.cmml" xref="S4.T1.4.2.m2.1.1"><ci id="S4.T1.4.2.m2.1.1.1a.cmml" xref="S4.T1.4.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.T1.4.2.m2.1.1.1.cmml" xref="S4.T1.4.2.m2.1.1.1">DYN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.m2.1d">{}_{\texttt{DYN}}</annotation></semantics></math> model refers to another slimmable model that integrates UNITER and DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, which is reimplemented by ourselves.</span></figcaption>
<table id="S4.T1.31" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.31.28" class="ltx_tr">
<td id="S4.T1.31.28.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T1.31.28.1.1" class="ltx_text">#</span></td>
<td id="S4.T1.31.28.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="3"><span id="S4.T1.31.28.2.1" class="ltx_text">model</span></td>
<td id="S4.T1.31.28.3" class="ltx_td ltx_align_right ltx_border_tt" rowspan="3"><span id="S4.T1.31.28.3.1" class="ltx_text">#params</span></td>
<td id="S4.T1.31.28.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" rowspan="3"><span id="S4.T1.31.28.4.1" class="ltx_text">#FLOPs</span></td>
<td id="S4.T1.31.28.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span id="S4.T1.31.28.5.1" class="ltx_text ltx_font_typewriter">test-dev</span></td>
<td id="S4.T1.31.28.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S4.T1.31.28.6.1" class="ltx_text ltx_font_typewriter">test-std</span></td>
</tr>
<tr id="S4.T1.31.29" class="ltx_tr">
<td id="S4.T1.31.29.1" class="ltx_td ltx_align_center ltx_border_t">All</td>
<td id="S4.T1.31.29.2" class="ltx_td ltx_align_center ltx_border_t">Y/N</td>
<td id="S4.T1.31.29.3" class="ltx_td ltx_align_center ltx_border_t">Num</td>
<td id="S4.T1.31.29.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Other</td>
<td id="S4.T1.31.29.5" class="ltx_td ltx_align_center ltx_border_t">All</td>
<td id="S4.T1.31.29.6" class="ltx_td ltx_align_center ltx_border_t">Y/N</td>
<td id="S4.T1.31.29.7" class="ltx_td ltx_align_center ltx_border_t">Num</td>
<td id="S4.T1.31.29.8" class="ltx_td ltx_align_center ltx_border_t">Other</td>
</tr>
<tr id="S4.T1.31.30" class="ltx_tr">
<td id="S4.T1.31.30.1" class="ltx_td ltx_align_left ltx_border_t" colspan="12"><em id="S4.T1.31.30.1.1" class="ltx_emph ltx_font_italic">From-scratch training with augmented Visual Genome data</em></td>
</tr>
<tr id="S4.T1.31.31" class="ltx_tr">
<td id="S4.T1.31.31.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S4.T1.31.31.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T1.31.31.3" class="ltx_td ltx_align_right ltx_border_t">22M</td>
<td id="S4.T1.31.31.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">1.1G</td>
<td id="S4.T1.31.31.5" class="ltx_td ltx_align_center ltx_border_t">65.32</td>
<td id="S4.T1.31.31.6" class="ltx_td ltx_align_center ltx_border_t">81.82</td>
<td id="S4.T1.31.31.7" class="ltx_td ltx_align_center ltx_border_t">44.21</td>
<td id="S4.T1.31.31.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.05</td>
<td id="S4.T1.31.31.9" class="ltx_td ltx_align_center ltx_border_t">65.67</td>
<td id="S4.T1.31.31.10" class="ltx_td ltx_align_center ltx_border_t">82.20</td>
<td id="S4.T1.31.31.11" class="ltx_td ltx_align_center ltx_border_t">43.90</td>
<td id="S4.T1.31.31.12" class="ltx_td ltx_align_center ltx_border_t">56.26</td>
</tr>
<tr id="S4.T1.31.32" class="ltx_tr">
<td id="S4.T1.31.32.1" class="ltx_td ltx_align_center ltx_border_r">2</td>
<td id="S4.T1.31.32.2" class="ltx_td ltx_align_left ltx_border_r">MFB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S4.T1.31.32.3" class="ltx_td ltx_align_right">68M</td>
<td id="S4.T1.31.32.4" class="ltx_td ltx_align_right ltx_border_r">2.4G</td>
<td id="S4.T1.31.32.5" class="ltx_td ltx_align_center">68.40</td>
<td id="S4.T1.31.32.6" class="ltx_td ltx_align_center">84.78</td>
<td id="S4.T1.31.32.7" class="ltx_td ltx_align_center">49.05</td>
<td id="S4.T1.31.32.8" class="ltx_td ltx_align_center ltx_border_r">58.82</td>
<td id="S4.T1.31.32.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.32.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.32.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.32.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.33" class="ltx_tr">
<td id="S4.T1.31.33.1" class="ltx_td ltx_align_center ltx_border_r">3</td>
<td id="S4.T1.31.33.2" class="ltx_td ltx_align_left ltx_border_r">MFH <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</td>
<td id="S4.T1.31.33.3" class="ltx_td ltx_align_right">102M</td>
<td id="S4.T1.31.33.4" class="ltx_td ltx_align_right ltx_border_r">2.5G</td>
<td id="S4.T1.31.33.5" class="ltx_td ltx_align_center">68.76</td>
<td id="S4.T1.31.33.6" class="ltx_td ltx_align_center">84.27</td>
<td id="S4.T1.31.33.7" class="ltx_td ltx_align_center">49.56</td>
<td id="S4.T1.31.33.8" class="ltx_td ltx_align_center ltx_border_r">59.89</td>
<td id="S4.T1.31.33.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.33.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.33.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.33.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.34" class="ltx_tr">
<td id="S4.T1.31.34.1" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T1.31.34.2" class="ltx_td ltx_align_left ltx_border_r">BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T1.31.34.3" class="ltx_td ltx_align_right">112M</td>
<td id="S4.T1.31.34.4" class="ltx_td ltx_align_right ltx_border_r">12.3G</td>
<td id="S4.T1.31.34.5" class="ltx_td ltx_align_center">69.66</td>
<td id="S4.T1.31.34.6" class="ltx_td ltx_align_center">85.46</td>
<td id="S4.T1.31.34.7" class="ltx_td ltx_align_center">50.66</td>
<td id="S4.T1.31.34.8" class="ltx_td ltx_align_center ltx_border_r">60.50</td>
<td id="S4.T1.31.34.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.34.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.34.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.34.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.35" class="ltx_tr">
<td id="S4.T1.31.35.1" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T1.31.35.2" class="ltx_td ltx_align_left ltx_border_r">MUAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S4.T1.31.35.3" class="ltx_td ltx_align_right">83M</td>
<td id="S4.T1.31.35.4" class="ltx_td ltx_align_right ltx_border_r">17.3G</td>
<td id="S4.T1.31.35.5" class="ltx_td ltx_align_center">70.82</td>
<td id="S4.T1.31.35.6" class="ltx_td ltx_align_center">86.77</td>
<td id="S4.T1.31.35.7" class="ltx_td ltx_align_center"><span id="S4.T1.31.35.7.1" class="ltx_text ltx_font_bold">54.40</span></td>
<td id="S4.T1.31.35.8" class="ltx_td ltx_align_center ltx_border_r">60.89</td>
<td id="S4.T1.31.35.9" class="ltx_td ltx_align_center">71.10</td>
<td id="S4.T1.31.35.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.35.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.35.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.6.2" class="ltx_tr">
<td id="S4.T1.6.2.3" class="ltx_td ltx_align_center ltx_border_r">6</td>
<td id="S4.T1.6.2.2" class="ltx_td ltx_align_left ltx_border_r">MCAN(<math id="S4.T1.5.1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.T1.5.1.1.m1.1a"><mi id="S4.T1.5.1.1.m1.1.1" xref="S4.T1.5.1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.T1.5.1.1.m1.1b"><ci id="S4.T1.5.1.1.m1.1.1.cmml" xref="S4.T1.5.1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.1.1.m1.1c">D</annotation></semantics></math>=512,<math id="S4.T1.6.2.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.T1.6.2.2.m2.1a"><mi id="S4.T1.6.2.2.m2.1.1" xref="S4.T1.6.2.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T1.6.2.2.m2.1b"><ci id="S4.T1.6.2.2.m2.1.1.cmml" xref="S4.T1.6.2.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.2.2.m2.1c">L</annotation></semantics></math>=6) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S4.T1.6.2.4" class="ltx_td ltx_align_right">58M</td>
<td id="S4.T1.6.2.5" class="ltx_td ltx_align_right ltx_border_r">5.5G</td>
<td id="S4.T1.6.2.6" class="ltx_td ltx_align_center">70.63</td>
<td id="S4.T1.6.2.7" class="ltx_td ltx_align_center">86.82</td>
<td id="S4.T1.6.2.8" class="ltx_td ltx_align_center">53.26</td>
<td id="S4.T1.6.2.9" class="ltx_td ltx_align_center ltx_border_r">60.72</td>
<td id="S4.T1.6.2.10" class="ltx_td ltx_align_center">70.90</td>
<td id="S4.T1.6.2.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.6.2.12" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.6.2.13" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.7.3" class="ltx_tr">
<td id="S4.T1.7.3.2" class="ltx_td ltx_align_center ltx_border_r">7</td>
<td id="S4.T1.7.3.1" class="ltx_td ltx_align_left ltx_border_r">MCAN(<math id="S4.T1.7.3.1.m1.1" class="ltx_math_unparsed" alttext="{1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.7.3.1.m1.1a"><mrow id="S4.T1.7.3.1.m1.1b"><mn id="S4.T1.7.3.1.m1.1.1">1</mn><mo id="S4.T1.7.3.1.m1.1.2">/</mo><mn id="S4.T1.7.3.1.m1.1.3">4</mn><mi id="S4.T1.7.3.1.m1.1.4">D</mi><mo id="S4.T1.7.3.1.m1.1.5">,</mo><mn id="S4.T1.7.3.1.m1.1.6">1</mn><mo id="S4.T1.7.3.1.m1.1.7">/</mo><mn id="S4.T1.7.3.1.m1.1.8">3</mn><mi id="S4.T1.7.3.1.m1.1.9">L</mi><mo stretchy="false" id="S4.T1.7.3.1.m1.1.10">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T1.7.3.1.m1.1c">{1}/{4}D,{1}/{3}L)</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S4.T1.7.3.3" class="ltx_td ltx_align_right">10M</td>
<td id="S4.T1.7.3.4" class="ltx_td ltx_align_right ltx_border_r">0.2G</td>
<td id="S4.T1.7.3.5" class="ltx_td ltx_align_center">67.19</td>
<td id="S4.T1.7.3.6" class="ltx_td ltx_align_center">83.38</td>
<td id="S4.T1.7.3.7" class="ltx_td ltx_align_center">49.75</td>
<td id="S4.T1.7.3.8" class="ltx_td ltx_align_center ltx_border_r">57.31</td>
<td id="S4.T1.7.3.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.7.3.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.7.3.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.7.3.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.36" class="ltx_tr">
<td id="S4.T1.31.36.1" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T1.31.36.2" class="ltx_td ltx_align_left ltx_border_r">RWSAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
<td id="S4.T1.31.36.3" class="ltx_td ltx_align_right">20M</td>
<td id="S4.T1.31.36.4" class="ltx_td ltx_align_right ltx_border_r">6.5G</td>
<td id="S4.T1.31.36.5" class="ltx_td ltx_align_center">70.19</td>
<td id="S4.T1.31.36.6" class="ltx_td ltx_align_center">86.45</td>
<td id="S4.T1.31.36.7" class="ltx_td ltx_align_center">52.18</td>
<td id="S4.T1.31.36.8" class="ltx_td ltx_align_center ltx_border_r">60.38</td>
<td id="S4.T1.31.36.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.36.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.36.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.36.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.8.4" class="ltx_tr">
<td id="S4.T1.8.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9</td>
<td id="S4.T1.8.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MCAN<math id="S4.T1.8.4.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}(D,L)" display="inline"><semantics id="S4.T1.8.4.1.m1.1a"><mmultiscripts id="S4.T1.8.4.1.m1.1.1"><mrow id="S4.T1.8.4.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.8.4.1.m1.1.1.2.1">(</mo><mi id="S4.T1.8.4.1.m1.1.1.2.2">D</mi><mo id="S4.T1.8.4.1.m1.1.1.2.3">,</mo><mi id="S4.T1.8.4.1.m1.1.1.2.4">L</mi><mo stretchy="false" id="S4.T1.8.4.1.m1.1.1.2.5">)</mo></mrow><mprescripts id="S4.T1.8.4.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.8.4.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.8.4.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.8.4.1.m1.1b">{}_{\texttt{BST}}(D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.8.4.3" class="ltx_td ltx_align_right ltx_border_t">58M</td>
<td id="S4.T1.8.4.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">5.5G</td>
<td id="S4.T1.8.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.4.5.1" class="ltx_text ltx_font_bold">71.05</span></td>
<td id="S4.T1.8.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.4.6.1" class="ltx_text ltx_font_bold">87.39</span></td>
<td id="S4.T1.8.4.7" class="ltx_td ltx_align_center ltx_border_t">52.96</td>
<td id="S4.T1.8.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.8.4.8.1" class="ltx_text ltx_font_bold">61.19</span></td>
<td id="S4.T1.8.4.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.4.9.1" class="ltx_text ltx_font_bold">71.28</span></td>
<td id="S4.T1.8.4.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.4.10.1" class="ltx_text ltx_font_bold">87.36</span></td>
<td id="S4.T1.8.4.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.4.11.1" class="ltx_text ltx_font_bold">52.77</span></td>
<td id="S4.T1.8.4.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.4.12.1" class="ltx_text ltx_font_bold">61.52</span></td>
</tr>
<tr id="S4.T1.9.5" class="ltx_tr">
<td id="S4.T1.9.5.2" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="S4.T1.9.5.1" class="ltx_td ltx_align_left ltx_border_r">MCAN<math id="S4.T1.9.5.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,L)" display="inline"><semantics id="S4.T1.9.5.1.m1.1a"><mmultiscripts id="S4.T1.9.5.1.m1.1.1"><mrow id="S4.T1.9.5.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.9.5.1.m1.1.1.2.1">(</mo><mn id="S4.T1.9.5.1.m1.1.1.2.2">1</mn><mo id="S4.T1.9.5.1.m1.1.1.2.3">/</mo><mn id="S4.T1.9.5.1.m1.1.1.2.4">2</mn><mi id="S4.T1.9.5.1.m1.1.1.2.5">D</mi><mo id="S4.T1.9.5.1.m1.1.1.2.6">,</mo><mi id="S4.T1.9.5.1.m1.1.1.2.7">L</mi><mo stretchy="false" id="S4.T1.9.5.1.m1.1.1.2.8">)</mo></mrow><mprescripts id="S4.T1.9.5.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.9.5.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.9.5.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.9.5.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.9.5.3" class="ltx_td ltx_align_right">22M</td>
<td id="S4.T1.9.5.4" class="ltx_td ltx_align_right ltx_border_r">1.5G</td>
<td id="S4.T1.9.5.5" class="ltx_td ltx_align_center">70.45</td>
<td id="S4.T1.9.5.6" class="ltx_td ltx_align_center">86.84</td>
<td id="S4.T1.9.5.7" class="ltx_td ltx_align_center">52.89</td>
<td id="S4.T1.9.5.8" class="ltx_td ltx_align_center ltx_border_r">60.43</td>
<td id="S4.T1.9.5.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.9.5.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.9.5.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.9.5.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.10.6" class="ltx_tr">
<td id="S4.T1.10.6.2" class="ltx_td ltx_align_center ltx_border_r">11</td>
<td id="S4.T1.10.6.1" class="ltx_td ltx_align_left ltx_border_r">MCAN<math id="S4.T1.10.6.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.10.6.1.m1.1a"><mmultiscripts id="S4.T1.10.6.1.m1.1.1"><mrow id="S4.T1.10.6.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.10.6.1.m1.1.1.2.1">(</mo><mn id="S4.T1.10.6.1.m1.1.1.2.2">1</mn><mo id="S4.T1.10.6.1.m1.1.1.2.3">/</mo><mn id="S4.T1.10.6.1.m1.1.1.2.4">2</mn><mi id="S4.T1.10.6.1.m1.1.1.2.5">D</mi><mo id="S4.T1.10.6.1.m1.1.1.2.6">,</mo><mn id="S4.T1.10.6.1.m1.1.1.2.7">1</mn><mo id="S4.T1.10.6.1.m1.1.1.2.8">/</mo><mn id="S4.T1.10.6.1.m1.1.1.2.9">3</mn><mi id="S4.T1.10.6.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.10.6.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.10.6.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.10.6.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.10.6.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.10.6.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)</annotation></semantics></math>
</td>
<td id="S4.T1.10.6.3" class="ltx_td ltx_align_right">14M</td>
<td id="S4.T1.10.6.4" class="ltx_td ltx_align_right ltx_border_r">0.6G</td>
<td id="S4.T1.10.6.5" class="ltx_td ltx_align_center">69.42</td>
<td id="S4.T1.10.6.6" class="ltx_td ltx_align_center">85.68</td>
<td id="S4.T1.10.6.7" class="ltx_td ltx_align_center">51.96</td>
<td id="S4.T1.10.6.8" class="ltx_td ltx_align_center ltx_border_r">59.48</td>
<td id="S4.T1.10.6.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.10.6.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.10.6.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.10.6.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.11.7" class="ltx_tr">
<td id="S4.T1.11.7.2" class="ltx_td ltx_align_center ltx_border_r">12</td>
<td id="S4.T1.11.7.1" class="ltx_td ltx_align_left ltx_border_r">MCAN<math id="S4.T1.11.7.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.11.7.1.m1.1a"><mmultiscripts id="S4.T1.11.7.1.m1.1.1"><mrow id="S4.T1.11.7.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.11.7.1.m1.1.1.2.1">(</mo><mn id="S4.T1.11.7.1.m1.1.1.2.2">1</mn><mo id="S4.T1.11.7.1.m1.1.1.2.3">/</mo><mn id="S4.T1.11.7.1.m1.1.1.2.4">4</mn><mi id="S4.T1.11.7.1.m1.1.1.2.5">D</mi><mo id="S4.T1.11.7.1.m1.1.1.2.6">,</mo><mn id="S4.T1.11.7.1.m1.1.1.2.7">1</mn><mo id="S4.T1.11.7.1.m1.1.1.2.8">/</mo><mn id="S4.T1.11.7.1.m1.1.1.2.9">3</mn><mi id="S4.T1.11.7.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.11.7.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.11.7.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.11.7.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.11.7.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.11.7.1.m1.1b">{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)</annotation></semantics></math>
</td>
<td id="S4.T1.11.7.3" class="ltx_td ltx_align_right">10M</td>
<td id="S4.T1.11.7.4" class="ltx_td ltx_align_right ltx_border_r">0.2G</td>
<td id="S4.T1.11.7.5" class="ltx_td ltx_align_center">68.16</td>
<td id="S4.T1.11.7.6" class="ltx_td ltx_align_center">84.84</td>
<td id="S4.T1.11.7.7" class="ltx_td ltx_align_center">50.27</td>
<td id="S4.T1.11.7.8" class="ltx_td ltx_align_center ltx_border_r">57.95</td>
<td id="S4.T1.11.7.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.11.7.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.11.7.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.11.7.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.37" class="ltx_tr">
<td id="S4.T1.31.37.1" class="ltx_td ltx_align_left ltx_border_tt" colspan="12"><em id="S4.T1.31.37.1.1" class="ltx_emph ltx_font_italic">Vision-language pretraining with massive external data</em></td>
</tr>
<tr id="S4.T1.31.38" class="ltx_tr">
<td id="S4.T1.31.38.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13</td>
<td id="S4.T1.31.38.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">ViLBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S4.T1.31.38.3" class="ltx_td ltx_align_right ltx_border_t">221M</td>
<td id="S4.T1.31.38.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">18.7G</td>
<td id="S4.T1.31.38.5" class="ltx_td ltx_align_center ltx_border_t">70.55</td>
<td id="S4.T1.31.38.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.31.38.7" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.31.38.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T1.31.38.9" class="ltx_td ltx_align_center ltx_border_t">70.92</td>
<td id="S4.T1.31.38.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.31.38.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.31.38.12" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T1.31.39" class="ltx_tr">
<td id="S4.T1.31.39.1" class="ltx_td ltx_align_center ltx_border_r">14</td>
<td id="S4.T1.31.39.2" class="ltx_td ltx_align_left ltx_border_r">VLBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S4.T1.31.39.3" class="ltx_td ltx_align_right">116M</td>
<td id="S4.T1.31.39.4" class="ltx_td ltx_align_right ltx_border_r">20.7G</td>
<td id="S4.T1.31.39.5" class="ltx_td ltx_align_center">71.16</td>
<td id="S4.T1.31.39.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.39.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.39.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T1.31.39.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.39.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.39.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.39.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.40" class="ltx_tr">
<td id="S4.T1.31.40.1" class="ltx_td ltx_align_center ltx_border_r">15</td>
<td id="S4.T1.31.40.2" class="ltx_td ltx_align_left ltx_border_r">LXMERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</td>
<td id="S4.T1.31.40.3" class="ltx_td ltx_align_right">183M</td>
<td id="S4.T1.31.40.4" class="ltx_td ltx_align_right ltx_border_r">20.3G</td>
<td id="S4.T1.31.40.5" class="ltx_td ltx_align_center">72.42</td>
<td id="S4.T1.31.40.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.40.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.40.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T1.31.40.9" class="ltx_td ltx_align_center">72.54</td>
<td id="S4.T1.31.40.10" class="ltx_td ltx_align_center">88.20</td>
<td id="S4.T1.31.40.11" class="ltx_td ltx_align_center">54.20</td>
<td id="S4.T1.31.40.12" class="ltx_td ltx_align_center">63.10</td>
</tr>
<tr id="S4.T1.31.41" class="ltx_tr">
<td id="S4.T1.31.41.1" class="ltx_td ltx_align_center ltx_border_r">16</td>
<td id="S4.T1.31.41.2" class="ltx_td ltx_align_left ltx_border_r">OSCAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="S4.T1.31.41.3" class="ltx_td ltx_align_right">116M</td>
<td id="S4.T1.31.41.4" class="ltx_td ltx_align_right ltx_border_r">38.6G</td>
<td id="S4.T1.31.41.5" class="ltx_td ltx_align_center">73.16</td>
<td id="S4.T1.31.41.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.41.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.41.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T1.31.41.9" class="ltx_td ltx_align_center">73.44</td>
<td id="S4.T1.31.41.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.41.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.41.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.42" class="ltx_tr">
<td id="S4.T1.31.42.1" class="ltx_td ltx_align_center ltx_border_r">17</td>
<td id="S4.T1.31.42.2" class="ltx_td ltx_align_left ltx_border_r">ALBEF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</td>
<td id="S4.T1.31.42.3" class="ltx_td ltx_align_right">210M</td>
<td id="S4.T1.31.42.4" class="ltx_td ltx_align_right ltx_border_r">77.9G</td>
<td id="S4.T1.31.42.5" class="ltx_td ltx_align_center">75.84</td>
<td id="S4.T1.31.42.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.42.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.31.42.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T1.31.42.9" class="ltx_td ltx_align_center">76.05</td>
<td id="S4.T1.31.42.10" class="ltx_td ltx_align_center"><span id="S4.T1.31.42.10.1" class="ltx_text ltx_font_bold">91.67</span></td>
<td id="S4.T1.31.42.11" class="ltx_td ltx_align_center">55.43</td>
<td id="S4.T1.31.42.12" class="ltx_td ltx_align_center">67.19</td>
</tr>
<tr id="S4.T1.13.9" class="ltx_tr">
<td id="S4.T1.13.9.3" class="ltx_td ltx_align_center ltx_border_r">18</td>
<td id="S4.T1.13.9.2" class="ltx_td ltx_align_left ltx_border_r">UNITER(<math id="S4.T1.12.8.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.T1.12.8.1.m1.1a"><mi id="S4.T1.12.8.1.m1.1.1" xref="S4.T1.12.8.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.T1.12.8.1.m1.1b"><ci id="S4.T1.12.8.1.m1.1.1.cmml" xref="S4.T1.12.8.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.8.1.m1.1c">D</annotation></semantics></math>=768,<math id="S4.T1.13.9.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.T1.13.9.2.m2.1a"><mi id="S4.T1.13.9.2.m2.1.1" xref="S4.T1.13.9.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T1.13.9.2.m2.1b"><ci id="S4.T1.13.9.2.m2.1.1.cmml" xref="S4.T1.13.9.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.9.2.m2.1c">L</annotation></semantics></math>=12) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S4.T1.13.9.4" class="ltx_td ltx_align_right">117M</td>
<td id="S4.T1.13.9.5" class="ltx_td ltx_align_right ltx_border_r">20.2G</td>
<td id="S4.T1.13.9.6" class="ltx_td ltx_align_center">72.70</td>
<td id="S4.T1.13.9.7" class="ltx_td ltx_align_center">88.86</td>
<td id="S4.T1.13.9.8" class="ltx_td ltx_align_center">55.10</td>
<td id="S4.T1.13.9.9" class="ltx_td ltx_align_center ltx_border_r">62.87</td>
<td id="S4.T1.13.9.10" class="ltx_td ltx_align_center">72.95</td>
<td id="S4.T1.13.9.11" class="ltx_td ltx_align_center">89.00</td>
<td id="S4.T1.13.9.12" class="ltx_td ltx_align_center">55.37</td>
<td id="S4.T1.13.9.13" class="ltx_td ltx_align_center">63.01</td>
</tr>
<tr id="S4.T1.14.10" class="ltx_tr">
<td id="S4.T1.14.10.2" class="ltx_td ltx_align_center ltx_border_r">19</td>
<td id="S4.T1.14.10.1" class="ltx_td ltx_align_left ltx_border_r">UNITER(<math id="S4.T1.14.10.1.m1.1" class="ltx_math_unparsed" alttext="{1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.14.10.1.m1.1a"><mrow id="S4.T1.14.10.1.m1.1b"><mn id="S4.T1.14.10.1.m1.1.1">1</mn><mo id="S4.T1.14.10.1.m1.1.2">/</mo><mn id="S4.T1.14.10.1.m1.1.3">4</mn><mi id="S4.T1.14.10.1.m1.1.4">D</mi><mo id="S4.T1.14.10.1.m1.1.5">,</mo><mn id="S4.T1.14.10.1.m1.1.6">1</mn><mo id="S4.T1.14.10.1.m1.1.7">/</mo><mn id="S4.T1.14.10.1.m1.1.8">3</mn><mi id="S4.T1.14.10.1.m1.1.9">L</mi><mo stretchy="false" id="S4.T1.14.10.1.m1.1.10">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T1.14.10.1.m1.1c">{1}/{4}D,{1}/{3}L)</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S4.T1.14.10.3" class="ltx_td ltx_align_right">33M</td>
<td id="S4.T1.14.10.4" class="ltx_td ltx_align_right ltx_border_r">0.8G</td>
<td id="S4.T1.14.10.5" class="ltx_td ltx_align_center">66.89</td>
<td id="S4.T1.14.10.6" class="ltx_td ltx_align_center">83.25</td>
<td id="S4.T1.14.10.7" class="ltx_td ltx_align_center">49.97</td>
<td id="S4.T1.14.10.8" class="ltx_td ltx_align_center ltx_border_r">56.74</td>
<td id="S4.T1.14.10.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.14.10.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.14.10.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.14.10.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.16.12" class="ltx_tr">
<td id="S4.T1.16.12.3" class="ltx_td ltx_align_center ltx_border_r">20</td>
<td id="S4.T1.16.12.2" class="ltx_td ltx_align_left ltx_border_r">CLIP-ViL(<math id="S4.T1.15.11.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.T1.15.11.1.m1.1a"><mi id="S4.T1.15.11.1.m1.1.1" xref="S4.T1.15.11.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.T1.15.11.1.m1.1b"><ci id="S4.T1.15.11.1.m1.1.1.cmml" xref="S4.T1.15.11.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.11.1.m1.1c">D</annotation></semantics></math>=768,<math id="S4.T1.16.12.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.T1.16.12.2.m2.1a"><mi id="S4.T1.16.12.2.m2.1.1" xref="S4.T1.16.12.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T1.16.12.2.m2.1b"><ci id="S4.T1.16.12.2.m2.1.1.cmml" xref="S4.T1.16.12.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.12.2.m2.1c">L</annotation></semantics></math>=12) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S4.T1.16.12.4" class="ltx_td ltx_align_right">237M</td>
<td id="S4.T1.16.12.5" class="ltx_td ltx_align_right ltx_border_r">82.1G</td>
<td id="S4.T1.16.12.6" class="ltx_td ltx_align_center"><span id="S4.T1.16.12.6.1" class="ltx_text ltx_font_bold">76.44</span></td>
<td id="S4.T1.16.12.7" class="ltx_td ltx_align_center">91.38</td>
<td id="S4.T1.16.12.8" class="ltx_td ltx_align_center">58.12</td>
<td id="S4.T1.16.12.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.16.12.9.1" class="ltx_text ltx_font_bold">67.86</span></td>
<td id="S4.T1.16.12.10" class="ltx_td ltx_align_center"><span id="S4.T1.16.12.10.1" class="ltx_text ltx_font_bold">76.74</span></td>
<td id="S4.T1.16.12.11" class="ltx_td ltx_align_center">91.60</td>
<td id="S4.T1.16.12.12" class="ltx_td ltx_align_center">58.09</td>
<td id="S4.T1.16.12.13" class="ltx_td ltx_align_center"><span id="S4.T1.16.12.13.1" class="ltx_text ltx_font_bold">68.07</span></td>
</tr>
<tr id="S4.T1.17.13" class="ltx_tr">
<td id="S4.T1.17.13.2" class="ltx_td ltx_align_center ltx_border_r">21</td>
<td id="S4.T1.17.13.1" class="ltx_td ltx_align_left ltx_border_r">CLIP-ViL(<math id="S4.T1.17.13.1.m1.1" class="ltx_math_unparsed" alttext="{1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.17.13.1.m1.1a"><mrow id="S4.T1.17.13.1.m1.1b"><mn id="S4.T1.17.13.1.m1.1.1">1</mn><mo id="S4.T1.17.13.1.m1.1.2">/</mo><mn id="S4.T1.17.13.1.m1.1.3">4</mn><mi id="S4.T1.17.13.1.m1.1.4">D</mi><mo id="S4.T1.17.13.1.m1.1.5">,</mo><mn id="S4.T1.17.13.1.m1.1.6">1</mn><mo id="S4.T1.17.13.1.m1.1.7">/</mo><mn id="S4.T1.17.13.1.m1.1.8">3</mn><mi id="S4.T1.17.13.1.m1.1.9">L</mi><mo stretchy="false" id="S4.T1.17.13.1.m1.1.10">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T1.17.13.1.m1.1c">{1}/{4}D,{1}/{3}L)</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S4.T1.17.13.3" class="ltx_td ltx_align_right">153M</td>
<td id="S4.T1.17.13.4" class="ltx_td ltx_align_right ltx_border_r">59.3G</td>
<td id="S4.T1.17.13.5" class="ltx_td ltx_align_center">70.32</td>
<td id="S4.T1.17.13.6" class="ltx_td ltx_align_center">85.40</td>
<td id="S4.T1.17.13.7" class="ltx_td ltx_align_center">52.12</td>
<td id="S4.T1.17.13.8" class="ltx_td ltx_align_center ltx_border_r">61.59</td>
<td id="S4.T1.17.13.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.17.13.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.17.13.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.17.13.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.19.15" class="ltx_tr">
<td id="S4.T1.19.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22</td>
<td id="S4.T1.19.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<sup id="S4.T1.19.15.2.1" class="ltx_sup"><span id="S4.T1.19.15.2.1.1" class="ltx_text ltx_font_italic">†</span></sup>UNITER<math id="S4.T1.19.15.2.m2.1" class="ltx_math_unparsed" alttext="{}_{\texttt{DYN}}(D,L)" display="inline"><semantics id="S4.T1.19.15.2.m2.1a"><mmultiscripts id="S4.T1.19.15.2.m2.1.1"><mrow id="S4.T1.19.15.2.m2.1.1.2"><mo stretchy="false" id="S4.T1.19.15.2.m2.1.1.2.1">(</mo><mi id="S4.T1.19.15.2.m2.1.1.2.2">D</mi><mo id="S4.T1.19.15.2.m2.1.1.2.3">,</mo><mi id="S4.T1.19.15.2.m2.1.1.2.4">L</mi><mo stretchy="false" id="S4.T1.19.15.2.m2.1.1.2.5">)</mo></mrow><mprescripts id="S4.T1.19.15.2.m2.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.19.15.2.m2.1.1.3">DYN</mtext><mrow id="S4.T1.19.15.2.m2.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.19.15.2.m2.1b">{}_{\texttt{DYN}}(D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.19.15.4" class="ltx_td ltx_align_right ltx_border_t">117M</td>
<td id="S4.T1.19.15.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">20.2G</td>
<td id="S4.T1.19.15.6" class="ltx_td ltx_align_center ltx_border_t">73.19</td>
<td id="S4.T1.19.15.7" class="ltx_td ltx_align_center ltx_border_t">89.02</td>
<td id="S4.T1.19.15.8" class="ltx_td ltx_align_center ltx_border_t">56.39</td>
<td id="S4.T1.19.15.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.46</td>
<td id="S4.T1.19.15.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.19.15.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.19.15.12" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T1.19.15.13" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T1.21.17" class="ltx_tr">
<td id="S4.T1.21.17.3" class="ltx_td ltx_align_center ltx_border_r">23</td>
<td id="S4.T1.21.17.2" class="ltx_td ltx_align_left ltx_border_r">
<sup id="S4.T1.21.17.2.1" class="ltx_sup"><span id="S4.T1.21.17.2.1.1" class="ltx_text ltx_font_italic">†</span></sup>UNITER<math id="S4.T1.21.17.2.m2.1" class="ltx_math_unparsed" alttext="{}_{\texttt{DYN}}(3/4D,1/2L)" display="inline"><semantics id="S4.T1.21.17.2.m2.1a"><mmultiscripts id="S4.T1.21.17.2.m2.1.1"><mrow id="S4.T1.21.17.2.m2.1.1.2"><mo stretchy="false" id="S4.T1.21.17.2.m2.1.1.2.1">(</mo><mn id="S4.T1.21.17.2.m2.1.1.2.2">3</mn><mo id="S4.T1.21.17.2.m2.1.1.2.3">/</mo><mn id="S4.T1.21.17.2.m2.1.1.2.4">4</mn><mi id="S4.T1.21.17.2.m2.1.1.2.5">D</mi><mo id="S4.T1.21.17.2.m2.1.1.2.6">,</mo><mn id="S4.T1.21.17.2.m2.1.1.2.7">1</mn><mo id="S4.T1.21.17.2.m2.1.1.2.8">/</mo><mn id="S4.T1.21.17.2.m2.1.1.2.9">2</mn><mi id="S4.T1.21.17.2.m2.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.21.17.2.m2.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.21.17.2.m2.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.21.17.2.m2.1.1.3">DYN</mtext><mrow id="S4.T1.21.17.2.m2.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.21.17.2.m2.1b">{}_{\texttt{DYN}}(3/4D,1/2L)</annotation></semantics></math>
</td>
<td id="S4.T1.21.17.4" class="ltx_td ltx_align_right">64M</td>
<td id="S4.T1.21.17.5" class="ltx_td ltx_align_right ltx_border_r">8.1G</td>
<td id="S4.T1.21.17.6" class="ltx_td ltx_align_center">71.99</td>
<td id="S4.T1.21.17.7" class="ltx_td ltx_align_center">87.87</td>
<td id="S4.T1.21.17.8" class="ltx_td ltx_align_center">54.76</td>
<td id="S4.T1.21.17.9" class="ltx_td ltx_align_center ltx_border_r">62.34</td>
<td id="S4.T1.21.17.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.21.17.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.21.17.12" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.21.17.13" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.23.19" class="ltx_tr">
<td id="S4.T1.23.19.3" class="ltx_td ltx_align_center ltx_border_r">24</td>
<td id="S4.T1.23.19.2" class="ltx_td ltx_align_left ltx_border_r">
<sup id="S4.T1.23.19.2.1" class="ltx_sup"><span id="S4.T1.23.19.2.1.1" class="ltx_text ltx_font_italic">†</span></sup>UNITER<math id="S4.T1.23.19.2.m2.1" class="ltx_math_unparsed" alttext="{}_{\texttt{DYN}}(1/4D,1/2L)" display="inline"><semantics id="S4.T1.23.19.2.m2.1a"><mmultiscripts id="S4.T1.23.19.2.m2.1.1"><mrow id="S4.T1.23.19.2.m2.1.1.2"><mo stretchy="false" id="S4.T1.23.19.2.m2.1.1.2.1">(</mo><mn id="S4.T1.23.19.2.m2.1.1.2.2">1</mn><mo id="S4.T1.23.19.2.m2.1.1.2.3">/</mo><mn id="S4.T1.23.19.2.m2.1.1.2.4">4</mn><mi id="S4.T1.23.19.2.m2.1.1.2.5">D</mi><mo id="S4.T1.23.19.2.m2.1.1.2.6">,</mo><mn id="S4.T1.23.19.2.m2.1.1.2.7">1</mn><mo id="S4.T1.23.19.2.m2.1.1.2.8">/</mo><mn id="S4.T1.23.19.2.m2.1.1.2.9">2</mn><mi id="S4.T1.23.19.2.m2.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.23.19.2.m2.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.23.19.2.m2.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.23.19.2.m2.1.1.3">DYN</mtext><mrow id="S4.T1.23.19.2.m2.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.23.19.2.m2.1b">{}_{\texttt{DYN}}(1/4D,1/2L)</annotation></semantics></math>
</td>
<td id="S4.T1.23.19.4" class="ltx_td ltx_align_right">43M</td>
<td id="S4.T1.23.19.5" class="ltx_td ltx_align_right ltx_border_r">3.1G</td>
<td id="S4.T1.23.19.6" class="ltx_td ltx_align_center">70.48</td>
<td id="S4.T1.23.19.7" class="ltx_td ltx_align_center">86.37</td>
<td id="S4.T1.23.19.8" class="ltx_td ltx_align_center">52.72</td>
<td id="S4.T1.23.19.9" class="ltx_td ltx_align_center ltx_border_r">60.93</td>
<td id="S4.T1.23.19.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.23.19.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.23.19.12" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.23.19.13" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.24.20" class="ltx_tr">
<td id="S4.T1.24.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25</td>
<td id="S4.T1.24.20.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">UNITER<math id="S4.T1.24.20.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}(D,L)" display="inline"><semantics id="S4.T1.24.20.1.m1.1a"><mmultiscripts id="S4.T1.24.20.1.m1.1.1"><mrow id="S4.T1.24.20.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.24.20.1.m1.1.1.2.1">(</mo><mi id="S4.T1.24.20.1.m1.1.1.2.2">D</mi><mo id="S4.T1.24.20.1.m1.1.1.2.3">,</mo><mi id="S4.T1.24.20.1.m1.1.1.2.4">L</mi><mo stretchy="false" id="S4.T1.24.20.1.m1.1.1.2.5">)</mo></mrow><mprescripts id="S4.T1.24.20.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.24.20.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.24.20.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.24.20.1.m1.1b">{}_{\texttt{BST}}(D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.24.20.3" class="ltx_td ltx_align_right ltx_border_t">117M</td>
<td id="S4.T1.24.20.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">20.2G</td>
<td id="S4.T1.24.20.5" class="ltx_td ltx_align_center ltx_border_t">73.27</td>
<td id="S4.T1.24.20.6" class="ltx_td ltx_align_center ltx_border_t">89.01</td>
<td id="S4.T1.24.20.7" class="ltx_td ltx_align_center ltx_border_t">56.73</td>
<td id="S4.T1.24.20.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="S4.T1.24.20.9" class="ltx_td ltx_align_center ltx_border_t">73.46</td>
<td id="S4.T1.24.20.10" class="ltx_td ltx_align_center ltx_border_t">89.17</td>
<td id="S4.T1.24.20.11" class="ltx_td ltx_align_center ltx_border_t">56.28</td>
<td id="S4.T1.24.20.12" class="ltx_td ltx_align_center ltx_border_t">63.73</td>
</tr>
<tr id="S4.T1.25.21" class="ltx_tr">
<td id="S4.T1.25.21.2" class="ltx_td ltx_align_center ltx_border_r">26</td>
<td id="S4.T1.25.21.1" class="ltx_td ltx_align_left ltx_border_r">UNITER<math id="S4.T1.25.21.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,L)" display="inline"><semantics id="S4.T1.25.21.1.m1.1a"><mmultiscripts id="S4.T1.25.21.1.m1.1.1"><mrow id="S4.T1.25.21.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.25.21.1.m1.1.1.2.1">(</mo><mn id="S4.T1.25.21.1.m1.1.1.2.2">1</mn><mo id="S4.T1.25.21.1.m1.1.1.2.3">/</mo><mn id="S4.T1.25.21.1.m1.1.1.2.4">2</mn><mi id="S4.T1.25.21.1.m1.1.1.2.5">D</mi><mo id="S4.T1.25.21.1.m1.1.1.2.6">,</mo><mi id="S4.T1.25.21.1.m1.1.1.2.7">L</mi><mo stretchy="false" id="S4.T1.25.21.1.m1.1.1.2.8">)</mo></mrow><mprescripts id="S4.T1.25.21.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.25.21.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.25.21.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.25.21.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.25.21.3" class="ltx_td ltx_align_right">53M</td>
<td id="S4.T1.25.21.4" class="ltx_td ltx_align_right ltx_border_r">5.6G</td>
<td id="S4.T1.25.21.5" class="ltx_td ltx_align_center">72.11</td>
<td id="S4.T1.25.21.6" class="ltx_td ltx_align_center">87.83</td>
<td id="S4.T1.25.21.7" class="ltx_td ltx_align_center">55.59</td>
<td id="S4.T1.25.21.8" class="ltx_td ltx_align_center ltx_border_r">62.42</td>
<td id="S4.T1.25.21.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.25.21.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.25.21.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.25.21.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.26.22" class="ltx_tr">
<td id="S4.T1.26.22.2" class="ltx_td ltx_align_center ltx_border_r">27</td>
<td id="S4.T1.26.22.1" class="ltx_td ltx_align_left ltx_border_r">UNITER<math id="S4.T1.26.22.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.26.22.1.m1.1a"><mmultiscripts id="S4.T1.26.22.1.m1.1.1"><mrow id="S4.T1.26.22.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.26.22.1.m1.1.1.2.1">(</mo><mn id="S4.T1.26.22.1.m1.1.1.2.2">1</mn><mo id="S4.T1.26.22.1.m1.1.1.2.3">/</mo><mn id="S4.T1.26.22.1.m1.1.1.2.4">2</mn><mi id="S4.T1.26.22.1.m1.1.1.2.5">D</mi><mo id="S4.T1.26.22.1.m1.1.1.2.6">,</mo><mn id="S4.T1.26.22.1.m1.1.1.2.7">1</mn><mo id="S4.T1.26.22.1.m1.1.1.2.8">/</mo><mn id="S4.T1.26.22.1.m1.1.1.2.9">3</mn><mi id="S4.T1.26.22.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.26.22.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.26.22.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.26.22.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.26.22.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.26.22.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)</annotation></semantics></math>
</td>
<td id="S4.T1.26.22.3" class="ltx_td ltx_align_right">39M</td>
<td id="S4.T1.26.22.4" class="ltx_td ltx_align_right ltx_border_r">2.2G</td>
<td id="S4.T1.26.22.5" class="ltx_td ltx_align_center">70.65</td>
<td id="S4.T1.26.22.6" class="ltx_td ltx_align_center">86.47</td>
<td id="S4.T1.26.22.7" class="ltx_td ltx_align_center">53.47</td>
<td id="S4.T1.26.22.8" class="ltx_td ltx_align_center ltx_border_r">61.02</td>
<td id="S4.T1.26.22.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.26.22.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.26.22.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.26.22.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.27.23" class="ltx_tr">
<td id="S4.T1.27.23.2" class="ltx_td ltx_align_center ltx_border_r">28</td>
<td id="S4.T1.27.23.1" class="ltx_td ltx_align_left ltx_border_r">UNITER<math id="S4.T1.27.23.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.T1.27.23.1.m1.1a"><mmultiscripts id="S4.T1.27.23.1.m1.1.1"><mrow id="S4.T1.27.23.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.27.23.1.m1.1.1.2.1">(</mo><mn id="S4.T1.27.23.1.m1.1.1.2.2">1</mn><mo id="S4.T1.27.23.1.m1.1.1.2.3">/</mo><mn id="S4.T1.27.23.1.m1.1.1.2.4">4</mn><mi id="S4.T1.27.23.1.m1.1.1.2.5">D</mi><mo id="S4.T1.27.23.1.m1.1.1.2.6">,</mo><mn id="S4.T1.27.23.1.m1.1.1.2.7">1</mn><mo id="S4.T1.27.23.1.m1.1.1.2.8">/</mo><mn id="S4.T1.27.23.1.m1.1.1.2.9">3</mn><mi id="S4.T1.27.23.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.27.23.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.27.23.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.27.23.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.27.23.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.27.23.1.m1.1b">{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)</annotation></semantics></math>
</td>
<td id="S4.T1.27.23.3" class="ltx_td ltx_align_right">33M</td>
<td id="S4.T1.27.23.4" class="ltx_td ltx_align_right ltx_border_r">0.8G</td>
<td id="S4.T1.27.23.5" class="ltx_td ltx_align_center">69.68</td>
<td id="S4.T1.27.23.6" class="ltx_td ltx_align_center">85.49</td>
<td id="S4.T1.27.23.7" class="ltx_td ltx_align_center">52.26</td>
<td id="S4.T1.27.23.8" class="ltx_td ltx_align_center ltx_border_r">60.12</td>
<td id="S4.T1.27.23.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.27.23.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.27.23.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.27.23.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.28.24" class="ltx_tr">
<td id="S4.T1.28.24.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29</td>
<td id="S4.T1.28.24.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CLIP-VIL<math id="S4.T1.28.24.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}(D,L)" display="inline"><semantics id="S4.T1.28.24.1.m1.1a"><mmultiscripts id="S4.T1.28.24.1.m1.1.1"><mrow id="S4.T1.28.24.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.28.24.1.m1.1.1.2.1">(</mo><mi id="S4.T1.28.24.1.m1.1.1.2.2">D</mi><mo id="S4.T1.28.24.1.m1.1.1.2.3">,</mo><mi id="S4.T1.28.24.1.m1.1.1.2.4">L</mi><mo stretchy="false" id="S4.T1.28.24.1.m1.1.1.2.5">)</mo></mrow><mprescripts id="S4.T1.28.24.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.28.24.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.28.24.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.28.24.1.m1.1b">{}_{\texttt{BST}}(D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.28.24.3" class="ltx_td ltx_align_right ltx_border_t">237M</td>
<td id="S4.T1.28.24.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">82.1G</td>
<td id="S4.T1.28.24.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.28.24.5.1" class="ltx_text ltx_font_bold">76.44</span></td>
<td id="S4.T1.28.24.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.28.24.6.1" class="ltx_text ltx_font_bold">91.44</span></td>
<td id="S4.T1.28.24.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.28.24.7.1" class="ltx_text ltx_font_bold">58.27</span></td>
<td id="S4.T1.28.24.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.78</td>
<td id="S4.T1.28.24.9" class="ltx_td ltx_align_center ltx_border_t">76.70</td>
<td id="S4.T1.28.24.10" class="ltx_td ltx_align_center ltx_border_t">91.54</td>
<td id="S4.T1.28.24.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.28.24.11.1" class="ltx_text ltx_font_bold">58.71</span></td>
<td id="S4.T1.28.24.12" class="ltx_td ltx_align_center ltx_border_t">67.90</td>
</tr>
<tr id="S4.T1.29.25" class="ltx_tr">
<td id="S4.T1.29.25.2" class="ltx_td ltx_align_center ltx_border_r">30</td>
<td id="S4.T1.29.25.1" class="ltx_td ltx_align_left ltx_border_r">CLIP-VIL<math id="S4.T1.29.25.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,L)" display="inline"><semantics id="S4.T1.29.25.1.m1.1a"><mmultiscripts id="S4.T1.29.25.1.m1.1.1"><mrow id="S4.T1.29.25.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.29.25.1.m1.1.1.2.1">(</mo><mn id="S4.T1.29.25.1.m1.1.1.2.2">1</mn><mo id="S4.T1.29.25.1.m1.1.1.2.3">/</mo><mn id="S4.T1.29.25.1.m1.1.1.2.4">2</mn><mi id="S4.T1.29.25.1.m1.1.1.2.5">D</mi><mo id="S4.T1.29.25.1.m1.1.1.2.6">,</mo><mi id="S4.T1.29.25.1.m1.1.1.2.7">L</mi><mo stretchy="false" id="S4.T1.29.25.1.m1.1.1.2.8">)</mo></mrow><mprescripts id="S4.T1.29.25.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.29.25.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.29.25.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.29.25.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,L)</annotation></semantics></math>
</td>
<td id="S4.T1.29.25.3" class="ltx_td ltx_align_right">172M</td>
<td id="S4.T1.29.25.4" class="ltx_td ltx_align_right ltx_border_r">64.9G</td>
<td id="S4.T1.29.25.5" class="ltx_td ltx_align_center">75.17</td>
<td id="S4.T1.29.25.6" class="ltx_td ltx_align_center">90.29</td>
<td id="S4.T1.29.25.7" class="ltx_td ltx_align_center">57.31</td>
<td id="S4.T1.29.25.8" class="ltx_td ltx_align_center ltx_border_r">66.30</td>
<td id="S4.T1.29.25.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.29.25.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.29.25.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.29.25.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.30.26" class="ltx_tr">
<td id="S4.T1.30.26.2" class="ltx_td ltx_align_center ltx_border_r">31</td>
<td id="S4.T1.30.26.1" class="ltx_td ltx_align_left ltx_border_r">CLIP-VIL<math id="S4.T1.30.26.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,1/3L)" display="inline"><semantics id="S4.T1.30.26.1.m1.1a"><mmultiscripts id="S4.T1.30.26.1.m1.1.1"><mrow id="S4.T1.30.26.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.30.26.1.m1.1.1.2.1">(</mo><mn id="S4.T1.30.26.1.m1.1.1.2.2">1</mn><mo id="S4.T1.30.26.1.m1.1.1.2.3">/</mo><mn id="S4.T1.30.26.1.m1.1.1.2.4">2</mn><mi id="S4.T1.30.26.1.m1.1.1.2.5">D</mi><mo id="S4.T1.30.26.1.m1.1.1.2.6">,</mo><mn id="S4.T1.30.26.1.m1.1.1.2.7">1</mn><mo id="S4.T1.30.26.1.m1.1.1.2.8">/</mo><mn id="S4.T1.30.26.1.m1.1.1.2.9">3</mn><mi id="S4.T1.30.26.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.30.26.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.30.26.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.30.26.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.30.26.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.30.26.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,1/3L)</annotation></semantics></math>
</td>
<td id="S4.T1.30.26.3" class="ltx_td ltx_align_right">158M</td>
<td id="S4.T1.30.26.4" class="ltx_td ltx_align_right ltx_border_r">60.8G</td>
<td id="S4.T1.30.26.5" class="ltx_td ltx_align_center">73.86</td>
<td id="S4.T1.30.26.6" class="ltx_td ltx_align_center">89.20</td>
<td id="S4.T1.30.26.7" class="ltx_td ltx_align_center">55.43</td>
<td id="S4.T1.30.26.8" class="ltx_td ltx_align_center ltx_border_r">64.95</td>
<td id="S4.T1.30.26.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.30.26.10" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.30.26.11" class="ltx_td ltx_align_center">-</td>
<td id="S4.T1.30.26.12" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T1.31.27" class="ltx_tr">
<td id="S4.T1.31.27.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">32</td>
<td id="S4.T1.31.27.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">CLIP-VIL<math id="S4.T1.31.27.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,1/3L)" display="inline"><semantics id="S4.T1.31.27.1.m1.1a"><mmultiscripts id="S4.T1.31.27.1.m1.1.1"><mrow id="S4.T1.31.27.1.m1.1.1.2"><mo stretchy="false" id="S4.T1.31.27.1.m1.1.1.2.1">(</mo><mn id="S4.T1.31.27.1.m1.1.1.2.2">1</mn><mo id="S4.T1.31.27.1.m1.1.1.2.3">/</mo><mn id="S4.T1.31.27.1.m1.1.1.2.4">4</mn><mi id="S4.T1.31.27.1.m1.1.1.2.5">D</mi><mo id="S4.T1.31.27.1.m1.1.1.2.6">,</mo><mn id="S4.T1.31.27.1.m1.1.1.2.7">1</mn><mo id="S4.T1.31.27.1.m1.1.1.2.8">/</mo><mn id="S4.T1.31.27.1.m1.1.1.2.9">3</mn><mi id="S4.T1.31.27.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T1.31.27.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T1.31.27.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T1.31.27.1.m1.1.1.3">BST</mtext><mrow id="S4.T1.31.27.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T1.31.27.1.m1.1b">{}_{\texttt{BST}}({1}/{4}D,1/3L)</annotation></semantics></math>
</td>
<td id="S4.T1.31.27.3" class="ltx_td ltx_align_right ltx_border_bb">153M</td>
<td id="S4.T1.31.27.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r">59.3G</td>
<td id="S4.T1.31.27.5" class="ltx_td ltx_align_center ltx_border_bb">72.34</td>
<td id="S4.T1.31.27.6" class="ltx_td ltx_align_center ltx_border_bb">87.41</td>
<td id="S4.T1.31.27.7" class="ltx_td ltx_align_center ltx_border_bb">54.11</td>
<td id="S4.T1.31.27.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.63</td>
<td id="S4.T1.31.27.9" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T1.31.27.10" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T1.31.27.11" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T1.31.27.12" class="ltx_td ltx_align_center ltx_border_bb">-</td>
</tr>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Datasets</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">VQA-v2</span> is the most commonly used VQA dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. It contains human-annotated QA pairs for MS-COCO images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. The dataset is split into three sets: <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_typewriter">train</span> (80k images with 444k questions); <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">val</span> (40k images with 214k questions); and <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_typewriter">test</span> (80k images with 448k questions). The <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_typewriter">test</span> set is further split into <span id="S4.SS1.p1.1.6" class="ltx_text ltx_font_typewriter">test-dev</span> and <span id="S4.SS1.p1.1.7" class="ltx_text ltx_font_typewriter">test-std</span> sets. The reported results include three per-type accuracies (yes/no, number, and other), as well as an overall accuracy.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">To make a fair comparison among the compared models, we follow the dataset splitting strategy in UNITER that further splits the <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">val</span> set into a <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">minival</span> subset of 5k images and a <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">trainval</span> subset of the remaining 35k images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. All the results reported in the experiments come from the models that are trained on the augmented <span id="S4.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">train+trainval+vg</span> sets, where <span id="S4.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">vg</span> denotes the augmented VQA samples from Visual Genome <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. The obtained models are validated on the <span id="S4.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">minival</span> set offline, and evaluated on the <span id="S4.SS1.p2.1.7" class="ltx_text ltx_font_typewriter">test-dev</span> and <span id="S4.SS1.p2.1.8" class="ltx_text ltx_font_typewriter">test-std</span> sets online.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">GQA</span> is a challenging VQA dataset that requires more complex reasoning skills <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>. It consists of 113K images and 1.2M balanced question-answer pairs of assorted types and varying compositionality degrees, measuring performance on an array of reasoning skills such as object and attribute recognition, spatial reasoning, logical inference, and comparisons. The dataset is split into the following four sets: <span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">train</span> (72k images with 943k questions), <span id="S4.SS1.p3.1.3" class="ltx_text ltx_font_typewriter">val</span> (10k images with 132k questions), <span id="S4.SS1.p3.1.4" class="ltx_text ltx_font_typewriter">test-dev</span> (398 images with 12k questions), and undisclosed <span id="S4.SS1.p3.1.5" class="ltx_text ltx_font_typewriter">test-challenge</span> (1.6k images with 50k questions). Following the suggestions in the official GQA guideline<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://cs.stanford.edu/people/dorarad/gqa/evaluate.html</span></span></span></span>, all the models are trained on the <span id="S4.SS1.p3.1.6" class="ltx_text ltx_font_typewriter">train+val</span> sets and evaluated on the <span id="S4.SS1.p3.1.7" class="ltx_text ltx_font_typewriter">test-dev</span> set.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Experimental Setup</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">The model architectures and training hyperparameters of the MCAN<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1a" xref="S4.SS2.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><ci id="S4.SS2.p1.1.m1.1.1.1a.cmml" xref="S4.SS2.p1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>, UNITER<math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1a" xref="S4.SS2.p1.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><ci id="S4.SS2.p1.2.m2.1.1.1a.cmml" xref="S4.SS2.p1.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">{}_{\texttt{BST}}</annotation></semantics></math>, and CLIP-ViL<math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msub id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1a" xref="S4.SS2.p1.3.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><ci id="S4.SS2.p1.3.m3.1.1.1a.cmml" xref="S4.SS2.p1.3.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">{}_{\texttt{BST}}</annotation></semantics></math> models are the same as those in their original models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, respectively.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.5" class="ltx_p">For MCAN<math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1a" xref="S4.SS2.p2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><ci id="S4.SS2.p2.1.m1.1.1.1a.cmml" xref="S4.SS2.p2.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>, the hidden dimensionality <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">D</annotation></semantics></math>, number of heads <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mi id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><ci id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">H</annotation></semantics></math>, and number of layers <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mi id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><ci id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">L</annotation></semantics></math> are set to 512, 8, and 6, respectively. The MCAN<math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><msub id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mi id="S4.SS2.p2.5.m5.1.1a" xref="S4.SS2.p2.5.m5.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p2.5.m5.1.1.1" xref="S4.SS2.p2.5.m5.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><ci id="S4.SS2.p2.5.m5.1.1.1a.cmml" xref="S4.SS2.p2.5.m5.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">{}_{\texttt{BST}}</annotation></semantics></math> models are trained on the VQA-v2 and GQA datasets using slightly different settings. On VQA-v2, binary cross-entropy (BCE) is used as the loss function for both the teacher and the BST model, and both models are trained for up to 15 epochs with a batch size of 64 and a base learning rate of 1e-4. The learning rate is warmed-up for 3 epochs and decays by 1/5 every 2 epochs after 10 epochs. On GQA, the learning rate and batch size are the same as those on VQA-v2. KL-divergence is used as the loss function and the teacher and BST models are trained for 11 epochs. The learning rate is warmed-up for 2 epochs and decays by 1/5 every 2 epochs after 8 epochs.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.9" class="ltx_p">For UNITER<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><msub id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1a" xref="S4.SS2.p3.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><ci id="S4.SS2.p3.1.m1.1.1.1a.cmml" xref="S4.SS2.p3.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> and CLIP-ViL<math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><msub id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1a" xref="S4.SS2.p3.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><ci id="S4.SS2.p3.2.m2.1.1.1a.cmml" xref="S4.SS2.p3.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">{}_{\texttt{BST}}</annotation></semantics></math>, we adopt the network architecture from the BERT-base model with <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="D=768" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mrow id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mi id="S4.SS2.p3.3.m3.1.1.2" xref="S4.SS2.p3.3.m3.1.1.2.cmml">D</mi><mo id="S4.SS2.p3.3.m3.1.1.1" xref="S4.SS2.p3.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.3.m3.1.1.3" xref="S4.SS2.p3.3.m3.1.1.3.cmml">768</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><eq id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1.1"></eq><ci id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">𝐷</ci><cn type="integer" id="S4.SS2.p3.3.m3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3">768</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">D=768</annotation></semantics></math>, <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="H=12" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mrow id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mi id="S4.SS2.p3.4.m4.1.1.2" xref="S4.SS2.p3.4.m4.1.1.2.cmml">H</mi><mo id="S4.SS2.p3.4.m4.1.1.1" xref="S4.SS2.p3.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.4.m4.1.1.3" xref="S4.SS2.p3.4.m4.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><eq id="S4.SS2.p3.4.m4.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1.1"></eq><ci id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2">𝐻</ci><cn type="integer" id="S4.SS2.p3.4.m4.1.1.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">H=12</annotation></semantics></math>, and <math id="S4.SS2.p3.5.m5.1" class="ltx_Math" alttext="L=12" display="inline"><semantics id="S4.SS2.p3.5.m5.1a"><mrow id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml"><mi id="S4.SS2.p3.5.m5.1.1.2" xref="S4.SS2.p3.5.m5.1.1.2.cmml">L</mi><mo id="S4.SS2.p3.5.m5.1.1.1" xref="S4.SS2.p3.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.5.m5.1.1.3" xref="S4.SS2.p3.5.m5.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><apply id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1"><eq id="S4.SS2.p3.5.m5.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1.1"></eq><ci id="S4.SS2.p3.5.m5.1.1.2.cmml" xref="S4.SS2.p3.5.m5.1.1.2">𝐿</ci><cn type="integer" id="S4.SS2.p3.5.m5.1.1.3.cmml" xref="S4.SS2.p3.5.m5.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">L=12</annotation></semantics></math>. Given a model the finetuned on VQA-v2 as the teacher, UNITER<math id="S4.SS2.p3.6.m6.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p3.6.m6.1a"><msub id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml"><mi id="S4.SS2.p3.6.m6.1.1a" xref="S4.SS2.p3.6.m6.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.6.m6.1.1.1" xref="S4.SS2.p3.6.m6.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><apply id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1"><ci id="S4.SS2.p3.6.m6.1.1.1a.cmml" xref="S4.SS2.p3.6.m6.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p3.6.m6.1.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">{}_{\texttt{BST}}</annotation></semantics></math> and CLIP-ViL<math id="S4.SS2.p3.7.m7.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p3.7.m7.1a"><msub id="S4.SS2.p3.7.m7.1.1" xref="S4.SS2.p3.7.m7.1.1.cmml"><mi id="S4.SS2.p3.7.m7.1.1a" xref="S4.SS2.p3.7.m7.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.7.m7.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.7.m7.1b"><apply id="S4.SS2.p3.7.m7.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1"><ci id="S4.SS2.p3.7.m7.1.1.1a.cmml" xref="S4.SS2.p3.7.m7.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p3.7.m7.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.7.m7.1c">{}_{\texttt{BST}}</annotation></semantics></math> are initialized from their corresponding teacher models and trained using the AdamW optimizer. UNITER<math id="S4.SS2.p3.8.m8.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p3.8.m8.1a"><msub id="S4.SS2.p3.8.m8.1.1" xref="S4.SS2.p3.8.m8.1.1.cmml"><mi id="S4.SS2.p3.8.m8.1.1a" xref="S4.SS2.p3.8.m8.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.8.m8.1.1.1" xref="S4.SS2.p3.8.m8.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.8.m8.1b"><apply id="S4.SS2.p3.8.m8.1.1.cmml" xref="S4.SS2.p3.8.m8.1.1"><ci id="S4.SS2.p3.8.m8.1.1.1a.cmml" xref="S4.SS2.p3.8.m8.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p3.8.m8.1.1.1.cmml" xref="S4.SS2.p3.8.m8.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.8.m8.1c">{}_{\texttt{BST}}</annotation></semantics></math> is trained for up to 130k iterations with a batch size of 5,120 and a base learning rate of 1.5e-4. CLIP-ViL<math id="S4.SS2.p3.9.m9.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS2.p3.9.m9.1a"><msub id="S4.SS2.p3.9.m9.1.1" xref="S4.SS2.p3.9.m9.1.1.cmml"><mi id="S4.SS2.p3.9.m9.1.1a" xref="S4.SS2.p3.9.m9.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.9.m9.1.1.1" xref="S4.SS2.p3.9.m9.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.9.m9.1b"><apply id="S4.SS2.p3.9.m9.1.1.cmml" xref="S4.SS2.p3.9.m9.1.1"><ci id="S4.SS2.p3.9.m9.1.1.1a.cmml" xref="S4.SS2.p3.9.m9.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS2.p3.9.m9.1.1.1.cmml" xref="S4.SS2.p3.9.m9.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.9.m9.1c">{}_{\texttt{BST}}</annotation></semantics></math> is trained for up to 15 epochs with a batch size of 32 and a base learning rate of 2e-4. To reduce the usage of GPU memory, we freeze the model parameters in the visual encoder during BST training.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.9.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S4.T2.10.2" class="ltx_text" style="font-size:90%;">Accuracies of the state-of-the-art methods on GQA. All entries use the officially provided object features for images and are evaluated on the <span id="S4.T2.10.2.1" class="ltx_text ltx_font_typewriter">test-dev</span> split.</span></figcaption>
<table id="S4.T2.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.6.7" class="ltx_tr">
<td id="S4.T2.6.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">model</td>
<td id="S4.T2.6.7.2" class="ltx_td ltx_align_right ltx_border_tt">#params</td>
<td id="S4.T2.6.7.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_tt">#FLOPs</td>
<td id="S4.T2.6.7.4" class="ltx_td ltx_align_center ltx_border_tt">accuracy</td>
</tr>
<tr id="S4.T2.6.8" class="ltx_tr">
<td id="S4.T2.6.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T2.6.8.2" class="ltx_td ltx_align_right ltx_border_t">30M</td>
<td id="S4.T2.6.8.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">2.8G</td>
<td id="S4.T2.6.8.4" class="ltx_td ltx_align_center ltx_border_t">51.62</td>
</tr>
<tr id="S4.T2.6.9" class="ltx_tr">
<td id="S4.T2.6.9.1" class="ltx_td ltx_align_left ltx_border_r">BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T2.6.9.2" class="ltx_td ltx_align_right">120M</td>
<td id="S4.T2.6.9.3" class="ltx_td ltx_align_right ltx_border_r">14.9G</td>
<td id="S4.T2.6.9.4" class="ltx_td ltx_align_center">55.81</td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_left ltx_border_r">MCAN(<math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mi id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">D</annotation></semantics></math>=512,<math id="S4.T2.2.2.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.T2.2.2.2.m2.1a"><mi id="S4.T2.2.2.2.m2.1.1" xref="S4.T2.2.2.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m2.1b"><ci id="S4.T2.2.2.2.m2.1.1.cmml" xref="S4.T2.2.2.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m2.1c">L</annotation></semantics></math>=6) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_right">59M</td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_align_right ltx_border_r">6.5G</td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_align_center">56.64</td>
</tr>
<tr id="S4.T2.3.3" class="ltx_tr">
<td id="S4.T2.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MCAN<math id="S4.T2.3.3.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}(D,L)" display="inline"><semantics id="S4.T2.3.3.1.m1.1a"><mmultiscripts id="S4.T2.3.3.1.m1.1.1"><mrow id="S4.T2.3.3.1.m1.1.1.2"><mo stretchy="false" id="S4.T2.3.3.1.m1.1.1.2.1">(</mo><mi id="S4.T2.3.3.1.m1.1.1.2.2">D</mi><mo id="S4.T2.3.3.1.m1.1.1.2.3">,</mo><mi id="S4.T2.3.3.1.m1.1.1.2.4">L</mi><mo stretchy="false" id="S4.T2.3.3.1.m1.1.1.2.5">)</mo></mrow><mprescripts id="S4.T2.3.3.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T2.3.3.1.m1.1.1.3">BST</mtext><mrow id="S4.T2.3.3.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T2.3.3.1.m1.1b">{}_{\texttt{BST}}(D,L)</annotation></semantics></math>
</td>
<td id="S4.T2.3.3.2" class="ltx_td ltx_align_right ltx_border_t">59M</td>
<td id="S4.T2.3.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">6.5G</td>
<td id="S4.T2.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.4.1" class="ltx_text ltx_font_bold">57.83</span></td>
</tr>
<tr id="S4.T2.4.4" class="ltx_tr">
<td id="S4.T2.4.4.1" class="ltx_td ltx_align_left ltx_border_r">MCAN<math id="S4.T2.4.4.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,L)" display="inline"><semantics id="S4.T2.4.4.1.m1.1a"><mmultiscripts id="S4.T2.4.4.1.m1.1.1"><mrow id="S4.T2.4.4.1.m1.1.1.2"><mo stretchy="false" id="S4.T2.4.4.1.m1.1.1.2.1">(</mo><mn id="S4.T2.4.4.1.m1.1.1.2.2">1</mn><mo id="S4.T2.4.4.1.m1.1.1.2.3">/</mo><mn id="S4.T2.4.4.1.m1.1.1.2.4">2</mn><mi id="S4.T2.4.4.1.m1.1.1.2.5">D</mi><mo id="S4.T2.4.4.1.m1.1.1.2.6">,</mo><mi id="S4.T2.4.4.1.m1.1.1.2.7">L</mi><mo stretchy="false" id="S4.T2.4.4.1.m1.1.1.2.8">)</mo></mrow><mprescripts id="S4.T2.4.4.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T2.4.4.1.m1.1.1.3">BST</mtext><mrow id="S4.T2.4.4.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T2.4.4.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,L)</annotation></semantics></math>
</td>
<td id="S4.T2.4.4.2" class="ltx_td ltx_align_right">22M</td>
<td id="S4.T2.4.4.3" class="ltx_td ltx_align_right ltx_border_r">1.9G</td>
<td id="S4.T2.4.4.4" class="ltx_td ltx_align_center">57.67</td>
</tr>
<tr id="S4.T2.5.5" class="ltx_tr">
<td id="S4.T2.5.5.1" class="ltx_td ltx_align_left ltx_border_r">MCAN<math id="S4.T2.5.5.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)" display="inline"><semantics id="S4.T2.5.5.1.m1.1a"><mmultiscripts id="S4.T2.5.5.1.m1.1.1"><mrow id="S4.T2.5.5.1.m1.1.1.2"><mo stretchy="false" id="S4.T2.5.5.1.m1.1.1.2.1">(</mo><mn id="S4.T2.5.5.1.m1.1.1.2.2">1</mn><mo id="S4.T2.5.5.1.m1.1.1.2.3">/</mo><mn id="S4.T2.5.5.1.m1.1.1.2.4">2</mn><mi id="S4.T2.5.5.1.m1.1.1.2.5">D</mi><mo id="S4.T2.5.5.1.m1.1.1.2.6">,</mo><mn id="S4.T2.5.5.1.m1.1.1.2.7">1</mn><mo id="S4.T2.5.5.1.m1.1.1.2.8">/</mo><mn id="S4.T2.5.5.1.m1.1.1.2.9">3</mn><mi id="S4.T2.5.5.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T2.5.5.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T2.5.5.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T2.5.5.1.m1.1.1.3">BST</mtext><mrow id="S4.T2.5.5.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T2.5.5.1.m1.1b">{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)</annotation></semantics></math>
</td>
<td id="S4.T2.5.5.2" class="ltx_td ltx_align_right">15M</td>
<td id="S4.T2.5.5.3" class="ltx_td ltx_align_right ltx_border_r">0.8G</td>
<td id="S4.T2.5.5.4" class="ltx_td ltx_align_center">57.09</td>
</tr>
<tr id="S4.T2.6.6" class="ltx_tr">
<td id="S4.T2.6.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">MCAN<math id="S4.T2.6.6.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.T2.6.6.1.m1.1a"><mmultiscripts id="S4.T2.6.6.1.m1.1.1"><mrow id="S4.T2.6.6.1.m1.1.1.2"><mo stretchy="false" id="S4.T2.6.6.1.m1.1.1.2.1">(</mo><mn id="S4.T2.6.6.1.m1.1.1.2.2">1</mn><mo id="S4.T2.6.6.1.m1.1.1.2.3">/</mo><mn id="S4.T2.6.6.1.m1.1.1.2.4">4</mn><mi id="S4.T2.6.6.1.m1.1.1.2.5">D</mi><mo id="S4.T2.6.6.1.m1.1.1.2.6">,</mo><mn id="S4.T2.6.6.1.m1.1.1.2.7">1</mn><mo id="S4.T2.6.6.1.m1.1.1.2.8">/</mo><mn id="S4.T2.6.6.1.m1.1.1.2.9">3</mn><mi id="S4.T2.6.6.1.m1.1.1.2.10">L</mi><mo stretchy="false" id="S4.T2.6.6.1.m1.1.1.2.11">)</mo></mrow><mprescripts id="S4.T2.6.6.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.T2.6.6.1.m1.1.1.3">BST</mtext><mrow id="S4.T2.6.6.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.T2.6.6.1.m1.1b">{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)</annotation></semantics></math>
</td>
<td id="S4.T2.6.6.2" class="ltx_td ltx_align_right ltx_border_bb">10M</td>
<td id="S4.T2.6.6.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r">0.4G</td>
<td id="S4.T2.6.6.4" class="ltx_td ltx_align_center ltx_border_bb">56.38</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Main Results</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.7" class="ltx_p">In Tables <a href="#S4.T1" title="TABLE I ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> and <a href="#S4.T2" title="TABLE II ‣ IV-B Experimental Setup ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we compare MCAN<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><msub id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1a" xref="S4.SS3.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><ci id="S4.SS3.p1.1.m1.1.1.1a.cmml" xref="S4.SS3.p1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>, UNITER<math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><msub id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1a" xref="S4.SS3.p1.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><ci id="S4.SS3.p1.2.m2.1.1.1a.cmml" xref="S4.SS3.p1.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">{}_{\texttt{BST}}</annotation></semantics></math>, and CLIP-ViL<math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><msub id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1a" xref="S4.SS3.p1.3.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.3.m3.1.1.1" xref="S4.SS3.p1.3.m3.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><ci id="S4.SS3.p1.3.m3.1.1.1a.cmml" xref="S4.SS3.p1.3.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">{}_{\texttt{BST}}</annotation></semantics></math> to the state-of-the-art VQA methods on VQA-v2 and GQA, respectively. For MCAN<math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><msub id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mi id="S4.SS3.p1.4.m4.1.1a" xref="S4.SS3.p1.4.m4.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><ci id="S4.SS3.p1.4.m4.1.1.1a.cmml" xref="S4.SS3.p1.4.m4.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">{}_{\texttt{BST}}</annotation></semantics></math>, the compared methods include UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, MFB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, MFH <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, MUAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, which were the best-performing solutions in the VQA Challenge in recent years. In addition, we introduce the lightweight VQA model RWSAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> into the comparison. For UNITER<math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><msub id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mi id="S4.SS3.p1.5.m5.1.1a" xref="S4.SS3.p1.5.m5.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><ci id="S4.SS3.p1.5.m5.1.1.1a.cmml" xref="S4.SS3.p1.5.m5.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">{}_{\texttt{BST}}</annotation></semantics></math> and CLIP-ViL<math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><msub id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml"><mi id="S4.SS3.p1.6.m6.1.1a" xref="S4.SS3.p1.6.m6.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.6.m6.1.1.1" xref="S4.SS3.p1.6.m6.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><apply id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1"><ci id="S4.SS3.p1.6.m6.1.1.1a.cmml" xref="S4.SS3.p1.6.m6.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.6.m6.1.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">{}_{\texttt{BST}}</annotation></semantics></math>, the compared methods include ViLBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, VLBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, LXMERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, OSCAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, ALBEF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, which are representative vision-language pretraining methods. Moreover, although DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> is not specifically designed for VQA, we reimplement it ourselves to integrate it with UNITER, resulting in a slimmable VQA model UNITER<math id="S4.SS3.p1.7.m7.1" class="ltx_Math" alttext="{}_{\texttt{DYN}}" display="inline"><semantics id="S4.SS3.p1.7.m7.1a"><msub id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml"><mi id="S4.SS3.p1.7.m7.1.1a" xref="S4.SS3.p1.7.m7.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p1.7.m7.1.1.1" xref="S4.SS3.p1.7.m7.1.1.1a.cmml">DYN</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><apply id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1"><ci id="S4.SS3.p1.7.m7.1.1.1a.cmml" xref="S4.SS3.p1.7.m7.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p1.7.m7.1.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1">DYN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">{}_{\texttt{DYN}}</annotation></semantics></math> for comparison.
Due to space limitations, we do not show the results of all the submodels (<em id="S4.SS3.p1.7.1" class="ltx_emph ltx_font_italic">i.e.</em>, the ten submodels selected by the triangle selection strategy in Fig. <a href="#S3.F4" title="Figure 4 ‣ III-D Training Strategy for BST Models ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) in these tables. Instead, four typical submodels are selected for comparison with the state-of-the-art approaches.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2203.12814/assets/fig5.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.6.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.7.2" class="ltx_text" style="font-size:90%;">Accuracy <em id="S4.F5.7.2.1" class="ltx_emph ltx_font_italic">vs.</em> #FLOPs on the VQA-v2 <span id="S4.F5.7.2.2" class="ltx_text ltx_font_typewriter">test-dev</span> split. For each VQA model (<em id="S4.F5.7.2.3" class="ltx_emph ltx_font_italic">i.e.</em>, MCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, UNITER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and CLIP-ViL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>), we report the results of ten submodels obtained from BST training and independent training, respectively.</span></figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2203.12814/assets/fig6.png" id="S4.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="281" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.4.2" class="ltx_text" style="font-size:90%;">Total number of parameters (left) and total training time (right) of the 10 submodels obtained by BST training and independent training, respectively. The training time is measured on a single Nvidia TitanV GPU.</span></figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.8.2.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S4.T3.2.1" class="ltx_text" style="font-size:90%;">Runtime latency (ms) of three typical MCAN<sub id="S4.T3.2.1.1" class="ltx_sub"><span id="S4.T3.2.1.1.1" class="ltx_text ltx_font_typewriter">BST</span></sub> submodels on three platforms, namely GPU, CPU, and mobile. For each platform, we report the results on three device.</span></figcaption>
<table id="S4.T3.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.5.4" class="ltx_tr">
<td id="S4.T3.5.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">platforms</td>
<td id="S4.T3.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">GPU</td>
<td id="S4.T3.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">CPU</td>
<td id="S4.T3.5.4.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">mobile</td>
</tr>
<tr id="S4.T3.5.5" class="ltx_tr">
<td id="S4.T3.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">device type</td>
<td id="S4.T3.5.5.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.2.1" class="ltx_text"></span> <span id="S4.T3.5.5.2.2" class="ltx_text">
<span id="S4.T3.5.5.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.2.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">RTX</span></span>
<span id="S4.T3.5.5.2.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">3090</span></span>
</span></span><span id="S4.T3.5.5.2.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.3.1" class="ltx_text"></span> <span id="S4.T3.5.5.3.2" class="ltx_text">
<span id="S4.T3.5.5.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.3.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">RTX</span></span>
<span id="S4.T3.5.5.3.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">2080Ti</span></span>
</span></span><span id="S4.T3.5.5.3.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.5.5.4.1" class="ltx_text"></span> <span id="S4.T3.5.5.4.2" class="ltx_text">
<span id="S4.T3.5.5.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.4.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">GTX</span></span>
<span id="S4.T3.5.5.4.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">1650</span></span>
</span></span><span id="S4.T3.5.5.4.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.5.1" class="ltx_text"></span> <span id="S4.T3.5.5.5.2" class="ltx_text">
<span id="S4.T3.5.5.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.5.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Intel</span></span>
<span id="S4.T3.5.5.5.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">E5-2620v4</span></span>
</span></span><span id="S4.T3.5.5.5.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.6.1" class="ltx_text"></span> <span id="S4.T3.5.5.6.2" class="ltx_text">
<span id="S4.T3.5.5.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.6.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Intel</span></span>
<span id="S4.T3.5.5.6.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">I3-10100</span></span>
</span></span><span id="S4.T3.5.5.6.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.5.5.7.1" class="ltx_text"></span> <span id="S4.T3.5.5.7.2" class="ltx_text">
<span id="S4.T3.5.5.7.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.7.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">AMD</span></span>
<span id="S4.T3.5.5.7.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">R7 4800H</span></span>
</span></span><span id="S4.T3.5.5.7.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.8" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.8.1" class="ltx_text"></span> <span id="S4.T3.5.5.8.2" class="ltx_text">
<span id="S4.T3.5.5.8.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.8.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Qualcomm</span></span>
<span id="S4.T3.5.5.8.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Snapdragon 888</span></span>
</span></span><span id="S4.T3.5.5.8.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.9" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.9.1" class="ltx_text"></span> <span id="S4.T3.5.5.9.2" class="ltx_text">
<span id="S4.T3.5.5.9.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.9.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">MediaTek</span></span>
<span id="S4.T3.5.5.9.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.9.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Dimensity 1100</span></span>
</span></span><span id="S4.T3.5.5.9.3" class="ltx_text"></span></td>
<td id="S4.T3.5.5.10" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.10.1" class="ltx_text"></span> <span id="S4.T3.5.5.10.2" class="ltx_text">
<span id="S4.T3.5.5.10.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.10.2.1.1" class="ltx_tr">
<span id="S4.T3.5.5.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Qualcomm</span></span>
<span id="S4.T3.5.5.10.2.1.2" class="ltx_tr">
<span id="S4.T3.5.5.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Snapdragon 660</span></span>
</span></span><span id="S4.T3.5.5.10.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T3.3.1" class="ltx_tr">
<td id="S4.T3.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S4.T3.3.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S4.T3.3.1.1.m1.2" class="ltx_Math" alttext="(D,L)" display="inline"><semantics id="S4.T3.3.1.1.m1.2a"><mrow id="S4.T3.3.1.1.m1.2.3.2" xref="S4.T3.3.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T3.3.1.1.m1.2.3.2.1" xref="S4.T3.3.1.1.m1.2.3.1.cmml">(</mo><mi id="S4.T3.3.1.1.m1.1.1" xref="S4.T3.3.1.1.m1.1.1.cmml">D</mi><mo id="S4.T3.3.1.1.m1.2.3.2.2" xref="S4.T3.3.1.1.m1.2.3.1.cmml">,</mo><mi id="S4.T3.3.1.1.m1.2.2" xref="S4.T3.3.1.1.m1.2.2.cmml">L</mi><mo stretchy="false" id="S4.T3.3.1.1.m1.2.3.2.3" xref="S4.T3.3.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.1.1.m1.2b"><interval closure="open" id="S4.T3.3.1.1.m1.2.3.1.cmml" xref="S4.T3.3.1.1.m1.2.3.2"><ci id="S4.T3.3.1.1.m1.1.1.cmml" xref="S4.T3.3.1.1.m1.1.1">𝐷</ci><ci id="S4.T3.3.1.1.m1.2.2.cmml" xref="S4.T3.3.1.1.m1.2.2">𝐿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.1.1.m1.2c">(D,L)</annotation></semantics></math></td>
<td id="S4.T3.3.1.3" class="ltx_td ltx_align_center ltx_border_t">22</td>
<td id="S4.T3.3.1.4" class="ltx_td ltx_align_center ltx_border_t">29</td>
<td id="S4.T3.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40</td>
<td id="S4.T3.3.1.6" class="ltx_td ltx_align_center ltx_border_t">51</td>
<td id="S4.T3.3.1.7" class="ltx_td ltx_align_center ltx_border_t">101</td>
<td id="S4.T3.3.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">127</td>
<td id="S4.T3.3.1.9" class="ltx_td ltx_align_center ltx_border_t">167</td>
<td id="S4.T3.3.1.10" class="ltx_td ltx_align_center ltx_border_t">361</td>
<td id="S4.T3.3.1.11" class="ltx_td ltx_align_center ltx_border_t">439</td>
</tr>
<tr id="S4.T3.4.2" class="ltx_tr">
<td id="S4.T3.4.2.2" class="ltx_td ltx_align_center ltx_border_r">2</td>
<td id="S4.T3.4.2.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T3.4.2.1.m1.2" class="ltx_Math" alttext="(1/4D,L)" display="inline"><semantics id="S4.T3.4.2.1.m1.2a"><mrow id="S4.T3.4.2.1.m1.2.2.1" xref="S4.T3.4.2.1.m1.2.2.2.cmml"><mo stretchy="false" id="S4.T3.4.2.1.m1.2.2.1.2" xref="S4.T3.4.2.1.m1.2.2.2.cmml">(</mo><mrow id="S4.T3.4.2.1.m1.2.2.1.1" xref="S4.T3.4.2.1.m1.2.2.1.1.cmml"><mrow id="S4.T3.4.2.1.m1.2.2.1.1.2" xref="S4.T3.4.2.1.m1.2.2.1.1.2.cmml"><mn id="S4.T3.4.2.1.m1.2.2.1.1.2.2" xref="S4.T3.4.2.1.m1.2.2.1.1.2.2.cmml">1</mn><mo id="S4.T3.4.2.1.m1.2.2.1.1.2.1" xref="S4.T3.4.2.1.m1.2.2.1.1.2.1.cmml">/</mo><mn id="S4.T3.4.2.1.m1.2.2.1.1.2.3" xref="S4.T3.4.2.1.m1.2.2.1.1.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T3.4.2.1.m1.2.2.1.1.1" xref="S4.T3.4.2.1.m1.2.2.1.1.1.cmml">​</mo><mi id="S4.T3.4.2.1.m1.2.2.1.1.3" xref="S4.T3.4.2.1.m1.2.2.1.1.3.cmml">D</mi></mrow><mo id="S4.T3.4.2.1.m1.2.2.1.3" xref="S4.T3.4.2.1.m1.2.2.2.cmml">,</mo><mi id="S4.T3.4.2.1.m1.1.1" xref="S4.T3.4.2.1.m1.1.1.cmml">L</mi><mo stretchy="false" id="S4.T3.4.2.1.m1.2.2.1.4" xref="S4.T3.4.2.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.2.1.m1.2b"><interval closure="open" id="S4.T3.4.2.1.m1.2.2.2.cmml" xref="S4.T3.4.2.1.m1.2.2.1"><apply id="S4.T3.4.2.1.m1.2.2.1.1.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1"><times id="S4.T3.4.2.1.m1.2.2.1.1.1.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1.1"></times><apply id="S4.T3.4.2.1.m1.2.2.1.1.2.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1.2"><divide id="S4.T3.4.2.1.m1.2.2.1.1.2.1.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1.2.1"></divide><cn type="integer" id="S4.T3.4.2.1.m1.2.2.1.1.2.2.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1.2.2">1</cn><cn type="integer" id="S4.T3.4.2.1.m1.2.2.1.1.2.3.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1.2.3">4</cn></apply><ci id="S4.T3.4.2.1.m1.2.2.1.1.3.cmml" xref="S4.T3.4.2.1.m1.2.2.1.1.3">𝐷</ci></apply><ci id="S4.T3.4.2.1.m1.1.1.cmml" xref="S4.T3.4.2.1.m1.1.1">𝐿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.2.1.m1.2c">(1/4D,L)</annotation></semantics></math></td>
<td id="S4.T3.4.2.3" class="ltx_td ltx_align_center">21</td>
<td id="S4.T3.4.2.4" class="ltx_td ltx_align_center">29</td>
<td id="S4.T3.4.2.5" class="ltx_td ltx_align_center ltx_border_r">35</td>
<td id="S4.T3.4.2.6" class="ltx_td ltx_align_center">30</td>
<td id="S4.T3.4.2.7" class="ltx_td ltx_align_center">44</td>
<td id="S4.T3.4.2.8" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T3.4.2.9" class="ltx_td ltx_align_center">87</td>
<td id="S4.T3.4.2.10" class="ltx_td ltx_align_center">127</td>
<td id="S4.T3.4.2.11" class="ltx_td ltx_align_center">197</td>
</tr>
<tr id="S4.T3.5.3" class="ltx_tr">
<td id="S4.T3.5.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">3</td>
<td id="S4.T3.5.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><math id="S4.T3.5.3.1.m1.2" class="ltx_Math" alttext="(1/4D,1/6L)" display="inline"><semantics id="S4.T3.5.3.1.m1.2a"><mrow id="S4.T3.5.3.1.m1.2.2.2" xref="S4.T3.5.3.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.T3.5.3.1.m1.2.2.2.3" xref="S4.T3.5.3.1.m1.2.2.3.cmml">(</mo><mrow id="S4.T3.5.3.1.m1.1.1.1.1" xref="S4.T3.5.3.1.m1.1.1.1.1.cmml"><mrow id="S4.T3.5.3.1.m1.1.1.1.1.2" xref="S4.T3.5.3.1.m1.1.1.1.1.2.cmml"><mn id="S4.T3.5.3.1.m1.1.1.1.1.2.2" xref="S4.T3.5.3.1.m1.1.1.1.1.2.2.cmml">1</mn><mo id="S4.T3.5.3.1.m1.1.1.1.1.2.1" xref="S4.T3.5.3.1.m1.1.1.1.1.2.1.cmml">/</mo><mn id="S4.T3.5.3.1.m1.1.1.1.1.2.3" xref="S4.T3.5.3.1.m1.1.1.1.1.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T3.5.3.1.m1.1.1.1.1.1" xref="S4.T3.5.3.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.T3.5.3.1.m1.1.1.1.1.3" xref="S4.T3.5.3.1.m1.1.1.1.1.3.cmml">D</mi></mrow><mo id="S4.T3.5.3.1.m1.2.2.2.4" xref="S4.T3.5.3.1.m1.2.2.3.cmml">,</mo><mrow id="S4.T3.5.3.1.m1.2.2.2.2" xref="S4.T3.5.3.1.m1.2.2.2.2.cmml"><mrow id="S4.T3.5.3.1.m1.2.2.2.2.2" xref="S4.T3.5.3.1.m1.2.2.2.2.2.cmml"><mn id="S4.T3.5.3.1.m1.2.2.2.2.2.2" xref="S4.T3.5.3.1.m1.2.2.2.2.2.2.cmml">1</mn><mo id="S4.T3.5.3.1.m1.2.2.2.2.2.1" xref="S4.T3.5.3.1.m1.2.2.2.2.2.1.cmml">/</mo><mn id="S4.T3.5.3.1.m1.2.2.2.2.2.3" xref="S4.T3.5.3.1.m1.2.2.2.2.2.3.cmml">6</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T3.5.3.1.m1.2.2.2.2.1" xref="S4.T3.5.3.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.T3.5.3.1.m1.2.2.2.2.3" xref="S4.T3.5.3.1.m1.2.2.2.2.3.cmml">L</mi></mrow><mo stretchy="false" id="S4.T3.5.3.1.m1.2.2.2.5" xref="S4.T3.5.3.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.3.1.m1.2b"><interval closure="open" id="S4.T3.5.3.1.m1.2.2.3.cmml" xref="S4.T3.5.3.1.m1.2.2.2"><apply id="S4.T3.5.3.1.m1.1.1.1.1.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1"><times id="S4.T3.5.3.1.m1.1.1.1.1.1.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1.1"></times><apply id="S4.T3.5.3.1.m1.1.1.1.1.2.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1.2"><divide id="S4.T3.5.3.1.m1.1.1.1.1.2.1.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1.2.1"></divide><cn type="integer" id="S4.T3.5.3.1.m1.1.1.1.1.2.2.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1.2.2">1</cn><cn type="integer" id="S4.T3.5.3.1.m1.1.1.1.1.2.3.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1.2.3">4</cn></apply><ci id="S4.T3.5.3.1.m1.1.1.1.1.3.cmml" xref="S4.T3.5.3.1.m1.1.1.1.1.3">𝐷</ci></apply><apply id="S4.T3.5.3.1.m1.2.2.2.2.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2"><times id="S4.T3.5.3.1.m1.2.2.2.2.1.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2.1"></times><apply id="S4.T3.5.3.1.m1.2.2.2.2.2.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2.2"><divide id="S4.T3.5.3.1.m1.2.2.2.2.2.1.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2.2.1"></divide><cn type="integer" id="S4.T3.5.3.1.m1.2.2.2.2.2.2.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2.2.2">1</cn><cn type="integer" id="S4.T3.5.3.1.m1.2.2.2.2.2.3.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2.2.3">6</cn></apply><ci id="S4.T3.5.3.1.m1.2.2.2.2.3.cmml" xref="S4.T3.5.3.1.m1.2.2.2.2.3">𝐿</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.3.1.m1.2c">(1/4D,1/6L)</annotation></semantics></math></td>
<td id="S4.T3.5.3.3" class="ltx_td ltx_align_center ltx_border_bb">5</td>
<td id="S4.T3.5.3.4" class="ltx_td ltx_align_center ltx_border_bb">7</td>
<td id="S4.T3.5.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">12</td>
<td id="S4.T3.5.3.6" class="ltx_td ltx_align_center ltx_border_bb">11</td>
<td id="S4.T3.5.3.7" class="ltx_td ltx_align_center ltx_border_bb">14</td>
<td id="S4.T3.5.3.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">22</td>
<td id="S4.T3.5.3.9" class="ltx_td ltx_align_center ltx_border_bb">58</td>
<td id="S4.T3.5.3.10" class="ltx_td ltx_align_center ltx_border_bb">93</td>
<td id="S4.T3.5.3.11" class="ltx_td ltx_align_center ltx_border_bb">160</td>
</tr>
</table>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.14" class="ltx_p">From the results in the upper part of Table <a href="#S4.T1" title="TABLE I ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, we have the following observations: 1) With the same model architecture, the largest submodel MCAN<math id="S4.SS3.p2.1.m1.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}(D,L)" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mmultiscripts id="S4.SS3.p2.1.m1.1.1"><mrow id="S4.SS3.p2.1.m1.1.1.2"><mo stretchy="false" id="S4.SS3.p2.1.m1.1.1.2.1">(</mo><mi id="S4.SS3.p2.1.m1.1.1.2.2">D</mi><mo id="S4.SS3.p2.1.m1.1.1.2.3">,</mo><mi id="S4.SS3.p2.1.m1.1.1.2.4">L</mi><mo stretchy="false" id="S4.SS3.p2.1.m1.1.1.2.5">)</mo></mrow><mprescripts id="S4.SS3.p2.1.m1.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p2.1.m1.1.1.3">BST</mtext><mrow id="S4.SS3.p2.1.m1.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1b">{}_{\texttt{BST}}(D,L)</annotation></semantics></math> and the smallest submodel MCAN<math id="S4.SS3.p2.2.m2.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mmultiscripts id="S4.SS3.p2.2.m2.1.1"><mrow id="S4.SS3.p2.2.m2.1.1.2"><mo stretchy="false" id="S4.SS3.p2.2.m2.1.1.2.1">(</mo><mn id="S4.SS3.p2.2.m2.1.1.2.2">1</mn><mo id="S4.SS3.p2.2.m2.1.1.2.3">/</mo><mn id="S4.SS3.p2.2.m2.1.1.2.4">4</mn><mi id="S4.SS3.p2.2.m2.1.1.2.5">D</mi><mo id="S4.SS3.p2.2.m2.1.1.2.6">,</mo><mn id="S4.SS3.p2.2.m2.1.1.2.7">1</mn><mo id="S4.SS3.p2.2.m2.1.1.2.8">/</mo><mn id="S4.SS3.p2.2.m2.1.1.2.9">3</mn><mi id="S4.SS3.p2.2.m2.1.1.2.10">L</mi><mo stretchy="false" id="S4.SS3.p2.2.m2.1.1.2.11">)</mo></mrow><mprescripts id="S4.SS3.p2.2.m2.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p2.2.m2.1.1.3">BST</mtext><mrow id="S4.SS3.p2.2.m2.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1b">{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)</annotation></semantics></math> outperform their independently-trained counterparts, respectively (#9 <em id="S4.SS3.p2.14.1" class="ltx_emph ltx_font_italic">vs</em>. #6, #12 <em id="S4.SS3.p2.14.2" class="ltx_emph ltx_font_italic">vs</em>. #7). This improvement is a benefit of the synergistic effect of the weight-sharing submodel architectures and KD training strategy. 2) With only 0.38<math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mo id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><times id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\times</annotation></semantics></math> the model size and 0.27<math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mo id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><times id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\times</annotation></semantics></math> the FLOPs, MCAN<math id="S4.SS3.p2.5.m5.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,L)" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mmultiscripts id="S4.SS3.p2.5.m5.1.1"><mrow id="S4.SS3.p2.5.m5.1.1.2"><mo stretchy="false" id="S4.SS3.p2.5.m5.1.1.2.1">(</mo><mn id="S4.SS3.p2.5.m5.1.1.2.2">1</mn><mo id="S4.SS3.p2.5.m5.1.1.2.3">/</mo><mn id="S4.SS3.p2.5.m5.1.1.2.4">2</mn><mi id="S4.SS3.p2.5.m5.1.1.2.5">D</mi><mo id="S4.SS3.p2.5.m5.1.1.2.6">,</mo><mi id="S4.SS3.p2.5.m5.1.1.2.7">L</mi><mo stretchy="false" id="S4.SS3.p2.5.m5.1.1.2.8">)</mo></mrow><mprescripts id="S4.SS3.p2.5.m5.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p2.5.m5.1.1.3">BST</mtext><mrow id="S4.SS3.p2.5.m5.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1b">{}_{\texttt{BST}}({1}/{2}D,L)</annotation></semantics></math> is still competitive with the reference MCAN model (#10 <em id="S4.SS3.p2.14.3" class="ltx_emph ltx_font_italic">vs</em>. #6), showing the potential of width slimming. In contrast to RWSAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, which has a similar model size, MCAN<math id="S4.SS3.p2.6.m6.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,L)" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mmultiscripts id="S4.SS3.p2.6.m6.1.1"><mrow id="S4.SS3.p2.6.m6.1.1.2"><mo stretchy="false" id="S4.SS3.p2.6.m6.1.1.2.1">(</mo><mn id="S4.SS3.p2.6.m6.1.1.2.2">1</mn><mo id="S4.SS3.p2.6.m6.1.1.2.3">/</mo><mn id="S4.SS3.p2.6.m6.1.1.2.4">2</mn><mi id="S4.SS3.p2.6.m6.1.1.2.5">D</mi><mo id="S4.SS3.p2.6.m6.1.1.2.6">,</mo><mi id="S4.SS3.p2.6.m6.1.1.2.7">L</mi><mo stretchy="false" id="S4.SS3.p2.6.m6.1.1.2.8">)</mo></mrow><mprescripts id="S4.SS3.p2.6.m6.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p2.6.m6.1.1.3">BST</mtext><mrow id="S4.SS3.p2.6.m6.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1b">{}_{\texttt{BST}}({1}/{2}D,L)</annotation></semantics></math> achieves higher accuracy and 0.25<math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><mo id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><times id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">\times</annotation></semantics></math> the FLOPs. 3) By slimming the depth to <math id="S4.SS3.p2.8.m8.1" class="ltx_Math" alttext="{1}/{3}L" display="inline"><semantics id="S4.SS3.p2.8.m8.1a"><mrow id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml"><mrow id="S4.SS3.p2.8.m8.1.1.2" xref="S4.SS3.p2.8.m8.1.1.2.cmml"><mn id="S4.SS3.p2.8.m8.1.1.2.2" xref="S4.SS3.p2.8.m8.1.1.2.2.cmml">1</mn><mo id="S4.SS3.p2.8.m8.1.1.2.1" xref="S4.SS3.p2.8.m8.1.1.2.1.cmml">/</mo><mn id="S4.SS3.p2.8.m8.1.1.2.3" xref="S4.SS3.p2.8.m8.1.1.2.3.cmml">3</mn></mrow><mo lspace="0em" rspace="0em" id="S4.SS3.p2.8.m8.1.1.1" xref="S4.SS3.p2.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS3.p2.8.m8.1.1.3" xref="S4.SS3.p2.8.m8.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><apply id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1"><times id="S4.SS3.p2.8.m8.1.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1.1"></times><apply id="S4.SS3.p2.8.m8.1.1.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2"><divide id="S4.SS3.p2.8.m8.1.1.2.1.cmml" xref="S4.SS3.p2.8.m8.1.1.2.1"></divide><cn type="integer" id="S4.SS3.p2.8.m8.1.1.2.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2.2">1</cn><cn type="integer" id="S4.SS3.p2.8.m8.1.1.2.3.cmml" xref="S4.SS3.p2.8.m8.1.1.2.3">3</cn></apply><ci id="S4.SS3.p2.8.m8.1.1.3.cmml" xref="S4.SS3.p2.8.m8.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">{1}/{3}L</annotation></semantics></math> (#11), its corresponding model size and FLOPs are respectively reduced to 0.6<math id="S4.SS3.p2.9.m9.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.9.m9.1a"><mo id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><times id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">\times</annotation></semantics></math> and 0.4<math id="S4.SS3.p2.10.m10.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.10.m10.1a"><mo id="S4.SS3.p2.10.m10.1.1" xref="S4.SS3.p2.10.m10.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.10.m10.1b"><times id="S4.SS3.p2.10.m10.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.10.m10.1c">\times</annotation></semantics></math> those of its counterpart in #10, respectively, at the expense of a 1-point accuracy drop. Compared with MFB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, MFH <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, and BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, MCAN<math id="S4.SS3.p2.11.m11.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)" display="inline"><semantics id="S4.SS3.p2.11.m11.1a"><mmultiscripts id="S4.SS3.p2.11.m11.1.1"><mrow id="S4.SS3.p2.11.m11.1.1.2"><mo stretchy="false" id="S4.SS3.p2.11.m11.1.1.2.1">(</mo><mn id="S4.SS3.p2.11.m11.1.1.2.2">1</mn><mo id="S4.SS3.p2.11.m11.1.1.2.3">/</mo><mn id="S4.SS3.p2.11.m11.1.1.2.4">2</mn><mi id="S4.SS3.p2.11.m11.1.1.2.5">D</mi><mo id="S4.SS3.p2.11.m11.1.1.2.6">,</mo><mn id="S4.SS3.p2.11.m11.1.1.2.7">1</mn><mo id="S4.SS3.p2.11.m11.1.1.2.8">/</mo><mn id="S4.SS3.p2.11.m11.1.1.2.9">3</mn><mi id="S4.SS3.p2.11.m11.1.1.2.10">L</mi><mo stretchy="false" id="S4.SS3.p2.11.m11.1.1.2.11">)</mo></mrow><mprescripts id="S4.SS3.p2.11.m11.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p2.11.m11.1.1.3">BST</mtext><mrow id="S4.SS3.p2.11.m11.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p2.11.m11.1b">{}_{\texttt{BST}}({1}/{2}D,{1}/{3}L)</annotation></semantics></math> achieves superior or comparable performance with up to 0.125<math id="S4.SS3.p2.12.m12.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.12.m12.1a"><mo id="S4.SS3.p2.12.m12.1.1" xref="S4.SS3.p2.12.m12.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.12.m12.1b"><times id="S4.SS3.p2.12.m12.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.12.m12.1c">\times</annotation></semantics></math> the model size and 0.05<math id="S4.SS3.p2.13.m13.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.13.m13.1a"><mo id="S4.SS3.p2.13.m13.1.1" xref="S4.SS3.p2.13.m13.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.13.m13.1b"><times id="S4.SS3.p2.13.m13.1.1.cmml" xref="S4.SS3.p2.13.m13.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.13.m13.1c">\times</annotation></semantics></math> the FLOPs. 4) MCAN<math id="S4.SS3.p2.14.m14.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.SS3.p2.14.m14.1a"><mmultiscripts id="S4.SS3.p2.14.m14.1.1"><mrow id="S4.SS3.p2.14.m14.1.1.2"><mo stretchy="false" id="S4.SS3.p2.14.m14.1.1.2.1">(</mo><mn id="S4.SS3.p2.14.m14.1.1.2.2">1</mn><mo id="S4.SS3.p2.14.m14.1.1.2.3">/</mo><mn id="S4.SS3.p2.14.m14.1.1.2.4">4</mn><mi id="S4.SS3.p2.14.m14.1.1.2.5">D</mi><mo id="S4.SS3.p2.14.m14.1.1.2.6">,</mo><mn id="S4.SS3.p2.14.m14.1.1.2.7">1</mn><mo id="S4.SS3.p2.14.m14.1.1.2.8">/</mo><mn id="S4.SS3.p2.14.m14.1.1.2.9">3</mn><mi id="S4.SS3.p2.14.m14.1.1.2.10">L</mi><mo stretchy="false" id="S4.SS3.p2.14.m14.1.1.2.11">)</mo></mrow><mprescripts id="S4.SS3.p2.14.m14.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p2.14.m14.1.1.3">BST</mtext><mrow id="S4.SS3.p2.14.m14.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p2.14.m14.1b">{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)</annotation></semantics></math> still outperforms UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> by 2.8 points with an extremely small model size of 10M. This model size is close to the lower bound of MCAN, which includes 7.8M uncompressible model parameters in the input and output embedding layers.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.6" class="ltx_p">From the results in the lower part of Table <a href="#S4.T1" title="TABLE I ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, we obtain similar observations to those on MCAN<math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><msub id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mi id="S4.SS3.p3.1.m1.1.1a" xref="S4.SS3.p3.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p3.1.m1.1.1.1" xref="S4.SS3.p3.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><ci id="S4.SS3.p3.1.m1.1.1.1a.cmml" xref="S4.SS3.p3.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math>. The slimmable UNITER<math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><msub id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mi id="S4.SS3.p3.2.m2.1.1a" xref="S4.SS3.p3.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p3.2.m2.1.1.1" xref="S4.SS3.p3.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><ci id="S4.SS3.p3.2.m2.1.1.1a.cmml" xref="S4.SS3.p3.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">{}_{\texttt{BST}}</annotation></semantics></math> and CLIP-ViL<math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><msub id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml"><mi id="S4.SS3.p3.3.m3.1.1a" xref="S4.SS3.p3.3.m3.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p3.3.m3.1.1.1" xref="S4.SS3.p3.3.m3.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><apply id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1"><ci id="S4.SS3.p3.3.m3.1.1.1a.cmml" xref="S4.SS3.p3.3.m3.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p3.3.m3.1.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">{}_{\texttt{BST}}</annotation></semantics></math> models attain superior or comparable performance to their reference independently-trained counterparts (#25 <em id="S4.SS3.p3.6.1" class="ltx_emph ltx_font_italic">vs.</em> #18, #28 <em id="S4.SS3.p3.6.2" class="ltx_emph ltx_font_italic">vs.</em> #19, #29 <em id="S4.SS3.p3.6.3" class="ltx_emph ltx_font_italic">vs.</em> #20, #32 <em id="S4.SS3.p3.6.4" class="ltx_emph ltx_font_italic">vs.</em> #21). The slimmed submodels in #26-28 and #30-32 attain significant reduction in computational costs at the expense of a drop in accuracy. Compared with the slimmable model UNITER<math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="{}_{\texttt{DYB}}" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><msub id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mi id="S4.SS3.p3.4.m4.1.1a" xref="S4.SS3.p3.4.m4.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p3.4.m4.1.1.1" xref="S4.SS3.p3.4.m4.1.1.1a.cmml">DYB</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><ci id="S4.SS3.p3.4.m4.1.1.1a.cmml" xref="S4.SS3.p3.4.m4.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1.1">DYB</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">{}_{\texttt{DYB}}</annotation></semantics></math> of DynaBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> (#22-24), our UNITER<math id="S4.SS3.p3.5.m5.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p3.5.m5.1a"><msub id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml"><mi id="S4.SS3.p3.5.m5.1.1a" xref="S4.SS3.p3.5.m5.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p3.5.m5.1.1.1" xref="S4.SS3.p3.5.m5.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><apply id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1"><ci id="S4.SS3.p3.5.m5.1.1.1a.cmml" xref="S4.SS3.p3.5.m5.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p3.5.m5.1.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">{}_{\texttt{BST}}</annotation></semantics></math> achieves higher performance with similar model sizes (#22 <em id="S4.SS3.p3.6.5" class="ltx_emph ltx_font_italic">vs.</em> #25, #23 <em id="S4.SS3.p3.6.6" class="ltx_emph ltx_font_italic">vs.</em> #26, #24 <em id="S4.SS3.p3.6.7" class="ltx_emph ltx_font_italic">vs.</em> #27). Additionally, the total training time for DynaBERT is 3.6<math id="S4.SS3.p3.6.m6.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p3.6.m6.1a"><mo id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><times id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">\times</annotation></semantics></math> longer than ours. These results verify that our slimming and training strategies are more effective than those of DynaBERT.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.5" class="ltx_p">To further examine the generalization of BST, we compare MCAN<math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><msub id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mi id="S4.SS3.p4.1.m1.1.1a" xref="S4.SS3.p4.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><ci id="S4.SS3.p4.1.m1.1.1.1a.cmml" xref="S4.SS3.p4.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> to the state-of-the-art methods on GQA. Table <a href="#S4.T2" title="TABLE II ‣ IV-B Experimental Setup ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> shows that MCAN<math id="S4.SS3.p4.2.m2.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}(D,L)" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mmultiscripts id="S4.SS3.p4.2.m2.1.1"><mrow id="S4.SS3.p4.2.m2.1.1.2"><mo stretchy="false" id="S4.SS3.p4.2.m2.1.1.2.1">(</mo><mi id="S4.SS3.p4.2.m2.1.1.2.2">D</mi><mo id="S4.SS3.p4.2.m2.1.1.2.3">,</mo><mi id="S4.SS3.p4.2.m2.1.1.2.4">L</mi><mo stretchy="false" id="S4.SS3.p4.2.m2.1.1.2.5">)</mo></mrow><mprescripts id="S4.SS3.p4.2.m2.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p4.2.m2.1.1.3">BST</mtext><mrow id="S4.SS3.p4.2.m2.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1b">{}_{\texttt{BST}}(D,L)</annotation></semantics></math> is 1.2 points higher than the reference MCAN model without BST. Furthermore, with 0.17<math id="S4.SS3.p4.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p4.3.m3.1a"><mo id="S4.SS3.p4.3.m3.1.1" xref="S4.SS3.p4.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m3.1b"><times id="S4.SS3.p4.3.m3.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m3.1c">\times</annotation></semantics></math> the model size and 0.06<math id="S4.SS3.p4.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p4.4.m4.1a"><mo id="S4.SS3.p4.4.m4.1.1" xref="S4.SS3.p4.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m4.1b"><times id="S4.SS3.p4.4.m4.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m4.1c">\times</annotation></semantics></math> the FLOPs, MCAN<math id="S4.SS3.p4.5.m5.1" class="ltx_math_unparsed" alttext="{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)" display="inline"><semantics id="S4.SS3.p4.5.m5.1a"><mmultiscripts id="S4.SS3.p4.5.m5.1.1"><mrow id="S4.SS3.p4.5.m5.1.1.2"><mo stretchy="false" id="S4.SS3.p4.5.m5.1.1.2.1">(</mo><mn id="S4.SS3.p4.5.m5.1.1.2.2">1</mn><mo id="S4.SS3.p4.5.m5.1.1.2.3">/</mo><mn id="S4.SS3.p4.5.m5.1.1.2.4">4</mn><mi id="S4.SS3.p4.5.m5.1.1.2.5">D</mi><mo id="S4.SS3.p4.5.m5.1.1.2.6">,</mo><mn id="S4.SS3.p4.5.m5.1.1.2.7">1</mn><mo id="S4.SS3.p4.5.m5.1.1.2.8">/</mo><mn id="S4.SS3.p4.5.m5.1.1.2.9">3</mn><mi id="S4.SS3.p4.5.m5.1.1.2.10">L</mi><mo stretchy="false" id="S4.SS3.p4.5.m5.1.1.2.11">)</mo></mrow><mprescripts id="S4.SS3.p4.5.m5.1.1a"></mprescripts><mtext class="ltx_mathvariant_monospace" id="S4.SS3.p4.5.m5.1.1.3">BST</mtext><mrow id="S4.SS3.p4.5.m5.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S4.SS3.p4.5.m5.1b">{}_{\texttt{BST}}({1}/{4}D,{1}/{3}L)</annotation></semantics></math> achieves comparable results to the reference MCAN model, surpassing the rest of its counterparts by a distinct margin.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">Next, we show the results of all the ten submodels in terms of BST training and standard independent training. By independent training, we mean that each submodel is trained independently <em id="S4.SS3.p5.1.1" class="ltx_emph ltx_font_italic">without</em> sharing its model parameters<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>For the independent training for UNITER and CLIP-ViL, each submodel is first initialized with a specific portion of the model parameters from the pretrained model and then finetuned independently.</span></span></span>. From the results in Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-C Main Results ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we can see that all the ten submodels obtained by BST training deliver better performance than their counterparts obtained by independent training. This corroborates the results in Table <a href="#S4.T1" title="TABLE I ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.2" class="ltx_p">Finally, the submodels obtained by BST are slimmed from <em id="S4.SS3.p6.2.1" class="ltx_emph ltx_font_italic">one single model without retraining</em>, outperforming the same submodels obtained by independent training in terms of both the total model size and total training time. From the results in Fig. <a href="#S4.F6" title="Figure 6 ‣ IV-C Main Results ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we can see that the total model size of the ten submodels obtained by BST training is <math id="S4.SS3.p6.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS3.p6.1.m1.1a"><mo id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><csymbol cd="latexml" id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">\sim</annotation></semantics></math>25% of that obtained by independent training. Furthermore, the total training time for BST training is <math id="S4.SS3.p6.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS3.p6.2.m2.1a"><mo id="S4.SS3.p6.2.m2.1.1" xref="S4.SS3.p6.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.2.m2.1b"><csymbol cd="latexml" id="S4.SS3.p6.2.m2.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.2.m2.1c">\sim</annotation></semantics></math>50% of that for independent training, revealing the synergistic effect of different weight-sharing submodels in BST training.</p>
</div>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p">To summarize, these observations above verify the effectiveness and generality of the proposed BST in terms of different Transformer architectures, training paradigms, and visual encoders.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Runtime Latency on Different Hardware Platforms</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">To precisely measure the efficiency of different submodels, we report the runtime latency on different hardware platforms in Table <a href="#S4.T3" title="TABLE III ‣ IV-C Main Results ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. Specifically, we deploy three typical submodels of a MCAN<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><msub id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.1.1a" xref="S4.SS4.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><ci id="S4.SS4.p1.1.m1.1.1.1a.cmml" xref="S4.SS4.p1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> model (<em id="S4.SS4.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, the largest submodel, the smallest submodel, and a deep and narrow submodel) on three commonly-used platforms (GPU, CPU, and mobile devices). For each platform, we choose three devices with different computational capabilities.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">From the results in Table <a href="#S4.T3" title="TABLE III ‣ IV-C Main Results ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we can see that: 1) For each submodel, different platforms and device types lead to significant discrepancies in terms of runtime latency, which stems from their diverse computational capabilities. 2) When width slimming is performed (#1 <em id="S4.SS4.p2.1.1" class="ltx_emph ltx_font_italic">vs.</em> #2), the latency on the GPU platform is not reduced significantly, while the latency on the CPU platform decreases prominently. This suggests that the GPU has no significant advantage over the CPU for these <em id="S4.SS4.p2.1.2" class="ltx_emph ltx_font_italic">narrow</em> models. 3) When depth slimming is also further performed (#1 <em id="S4.SS4.p2.1.3" class="ltx_emph ltx_font_italic">vs.</em> #3), the latencies on the GPU and CPU platforms are not distinct. This suggests that computational capabilities of the GPU and CPU platforms are excessive for such small submodels. 4) The smallest submodel in #3 can be deployed on a non-latest cellphone with a Snapdragon 888 chip. The 58 ms latency can support applications with real-time requirements.</p>
</div>
<figure id="S4.T4" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.5.2.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S4.T4.2.1" class="ltx_text" style="font-size:90%;">Ablations of the MCAN<math id="S4.T4.2.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.T4.2.1.m1.1b"><msub id="S4.T4.2.1.m1.1.1" xref="S4.T4.2.1.m1.1.1.cmml"><mi id="S4.T4.2.1.m1.1.1b" xref="S4.T4.2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.T4.2.1.m1.1.1.1" xref="S4.T4.2.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.2.1.m1.1c"><apply id="S4.T4.2.1.m1.1.1.cmml" xref="S4.T4.2.1.m1.1.1"><ci id="S4.T4.2.1.m1.1.1.1a.cmml" xref="S4.T4.2.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.T4.2.1.m1.1.1.1.cmml" xref="S4.T4.2.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.1.m1.1d">{}_{\texttt{BST}}</annotation></semantics></math> variants models evaluated on the <span id="S4.T4.2.1.1" class="ltx_text ltx_font_typewriter">minival</span> split of VQA-v2. The default setting and the best result are bolded.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T4.st1" class="ltx_table ltx_figure_panel">
<table id="S4.T4.st1.8" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.st1.8.9" class="ltx_tr">
<td id="S4.T4.st1.8.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">slimming strategy</td>
<td id="S4.T4.st1.8.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">submodel</td>
<td id="S4.T4.st1.8.9.3" class="ltx_td ltx_align_center ltx_border_tt">#FLOPs</td>
<td id="S4.T4.st1.8.9.4" class="ltx_td ltx_align_center ltx_border_tt">accuracy (%)</td>
</tr>
<tr id="S4.T4.st1.2.2" class="ltx_tr">
<td id="S4.T4.st1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.st1.2.2.3.1" class="ltx_text ltx_font_bold">slim-all</span></td>
<td id="S4.T4.st1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(<math id="S4.T4.st1.1.1.1.m1.1" class="ltx_Math" alttext="1/2D" display="inline"><semantics id="S4.T4.st1.1.1.1.m1.1a"><mrow id="S4.T4.st1.1.1.1.m1.1.1" xref="S4.T4.st1.1.1.1.m1.1.1.cmml"><mrow id="S4.T4.st1.1.1.1.m1.1.1.2" xref="S4.T4.st1.1.1.1.m1.1.1.2.cmml"><mn id="S4.T4.st1.1.1.1.m1.1.1.2.2" xref="S4.T4.st1.1.1.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.T4.st1.1.1.1.m1.1.1.2.1" xref="S4.T4.st1.1.1.1.m1.1.1.2.1.cmml">/</mo><mn id="S4.T4.st1.1.1.1.m1.1.1.2.3" xref="S4.T4.st1.1.1.1.m1.1.1.2.3.cmml">2</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T4.st1.1.1.1.m1.1.1.1" xref="S4.T4.st1.1.1.1.m1.1.1.1.cmml">​</mo><mi id="S4.T4.st1.1.1.1.m1.1.1.3" xref="S4.T4.st1.1.1.1.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.st1.1.1.1.m1.1b"><apply id="S4.T4.st1.1.1.1.m1.1.1.cmml" xref="S4.T4.st1.1.1.1.m1.1.1"><times id="S4.T4.st1.1.1.1.m1.1.1.1.cmml" xref="S4.T4.st1.1.1.1.m1.1.1.1"></times><apply id="S4.T4.st1.1.1.1.m1.1.1.2.cmml" xref="S4.T4.st1.1.1.1.m1.1.1.2"><divide id="S4.T4.st1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T4.st1.1.1.1.m1.1.1.2.1"></divide><cn type="integer" id="S4.T4.st1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T4.st1.1.1.1.m1.1.1.2.2">1</cn><cn type="integer" id="S4.T4.st1.1.1.1.m1.1.1.2.3.cmml" xref="S4.T4.st1.1.1.1.m1.1.1.2.3">2</cn></apply><ci id="S4.T4.st1.1.1.1.m1.1.1.3.cmml" xref="S4.T4.st1.1.1.1.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.1.1.1.m1.1c">1/2D</annotation></semantics></math>,<math id="S4.T4.st1.2.2.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.T4.st1.2.2.2.m2.1a"><mi id="S4.T4.st1.2.2.2.m2.1.1" xref="S4.T4.st1.2.2.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T4.st1.2.2.2.m2.1b"><ci id="S4.T4.st1.2.2.2.m2.1.1.cmml" xref="S4.T4.st1.2.2.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.2.2.2.m2.1c">L</annotation></semantics></math>)</td>
<td id="S4.T4.st1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">1.5G</td>
<td id="S4.T4.st1.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.st1.2.2.5.1" class="ltx_text ltx_font_bold">67.98</span></td>
</tr>
<tr id="S4.T4.st1.4.4" class="ltx_tr">
<td id="S4.T4.st1.4.4.3" class="ltx_td ltx_align_left ltx_border_r">slim-interm. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="S4.T4.st1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">(<math id="S4.T4.st1.3.3.1.m1.1" class="ltx_Math" alttext="1/4D" display="inline"><semantics id="S4.T4.st1.3.3.1.m1.1a"><mrow id="S4.T4.st1.3.3.1.m1.1.1" xref="S4.T4.st1.3.3.1.m1.1.1.cmml"><mrow id="S4.T4.st1.3.3.1.m1.1.1.2" xref="S4.T4.st1.3.3.1.m1.1.1.2.cmml"><mn id="S4.T4.st1.3.3.1.m1.1.1.2.2" xref="S4.T4.st1.3.3.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.T4.st1.3.3.1.m1.1.1.2.1" xref="S4.T4.st1.3.3.1.m1.1.1.2.1.cmml">/</mo><mn id="S4.T4.st1.3.3.1.m1.1.1.2.3" xref="S4.T4.st1.3.3.1.m1.1.1.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T4.st1.3.3.1.m1.1.1.1" xref="S4.T4.st1.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S4.T4.st1.3.3.1.m1.1.1.3" xref="S4.T4.st1.3.3.1.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.st1.3.3.1.m1.1b"><apply id="S4.T4.st1.3.3.1.m1.1.1.cmml" xref="S4.T4.st1.3.3.1.m1.1.1"><times id="S4.T4.st1.3.3.1.m1.1.1.1.cmml" xref="S4.T4.st1.3.3.1.m1.1.1.1"></times><apply id="S4.T4.st1.3.3.1.m1.1.1.2.cmml" xref="S4.T4.st1.3.3.1.m1.1.1.2"><divide id="S4.T4.st1.3.3.1.m1.1.1.2.1.cmml" xref="S4.T4.st1.3.3.1.m1.1.1.2.1"></divide><cn type="integer" id="S4.T4.st1.3.3.1.m1.1.1.2.2.cmml" xref="S4.T4.st1.3.3.1.m1.1.1.2.2">1</cn><cn type="integer" id="S4.T4.st1.3.3.1.m1.1.1.2.3.cmml" xref="S4.T4.st1.3.3.1.m1.1.1.2.3">4</cn></apply><ci id="S4.T4.st1.3.3.1.m1.1.1.3.cmml" xref="S4.T4.st1.3.3.1.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.3.3.1.m1.1c">1/4D</annotation></semantics></math>,<math id="S4.T4.st1.4.4.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.T4.st1.4.4.2.m2.1a"><mi id="S4.T4.st1.4.4.2.m2.1.1" xref="S4.T4.st1.4.4.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T4.st1.4.4.2.m2.1b"><ci id="S4.T4.st1.4.4.2.m2.1.1.cmml" xref="S4.T4.st1.4.4.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.4.4.2.m2.1c">L</annotation></semantics></math>)</td>
<td id="S4.T4.st1.4.4.4" class="ltx_td ltx_align_center">1.6G</td>
<td id="S4.T4.st1.4.4.5" class="ltx_td ltx_align_center">67.86</td>
</tr>
<tr id="S4.T4.st1.6.6" class="ltx_tr">
<td id="S4.T4.st1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.st1.6.6.3.1" class="ltx_text ltx_font_bold">slim-all</span></td>
<td id="S4.T4.st1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(<math id="S4.T4.st1.5.5.1.m1.1" class="ltx_Math" alttext="1/2D" display="inline"><semantics id="S4.T4.st1.5.5.1.m1.1a"><mrow id="S4.T4.st1.5.5.1.m1.1.1" xref="S4.T4.st1.5.5.1.m1.1.1.cmml"><mrow id="S4.T4.st1.5.5.1.m1.1.1.2" xref="S4.T4.st1.5.5.1.m1.1.1.2.cmml"><mn id="S4.T4.st1.5.5.1.m1.1.1.2.2" xref="S4.T4.st1.5.5.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.T4.st1.5.5.1.m1.1.1.2.1" xref="S4.T4.st1.5.5.1.m1.1.1.2.1.cmml">/</mo><mn id="S4.T4.st1.5.5.1.m1.1.1.2.3" xref="S4.T4.st1.5.5.1.m1.1.1.2.3.cmml">2</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T4.st1.5.5.1.m1.1.1.1" xref="S4.T4.st1.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S4.T4.st1.5.5.1.m1.1.1.3" xref="S4.T4.st1.5.5.1.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.st1.5.5.1.m1.1b"><apply id="S4.T4.st1.5.5.1.m1.1.1.cmml" xref="S4.T4.st1.5.5.1.m1.1.1"><times id="S4.T4.st1.5.5.1.m1.1.1.1.cmml" xref="S4.T4.st1.5.5.1.m1.1.1.1"></times><apply id="S4.T4.st1.5.5.1.m1.1.1.2.cmml" xref="S4.T4.st1.5.5.1.m1.1.1.2"><divide id="S4.T4.st1.5.5.1.m1.1.1.2.1.cmml" xref="S4.T4.st1.5.5.1.m1.1.1.2.1"></divide><cn type="integer" id="S4.T4.st1.5.5.1.m1.1.1.2.2.cmml" xref="S4.T4.st1.5.5.1.m1.1.1.2.2">1</cn><cn type="integer" id="S4.T4.st1.5.5.1.m1.1.1.2.3.cmml" xref="S4.T4.st1.5.5.1.m1.1.1.2.3">2</cn></apply><ci id="S4.T4.st1.5.5.1.m1.1.1.3.cmml" xref="S4.T4.st1.5.5.1.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.5.5.1.m1.1c">1/2D</annotation></semantics></math>,<math id="S4.T4.st1.6.6.2.m2.1" class="ltx_Math" alttext="1/3L" display="inline"><semantics id="S4.T4.st1.6.6.2.m2.1a"><mrow id="S4.T4.st1.6.6.2.m2.1.1" xref="S4.T4.st1.6.6.2.m2.1.1.cmml"><mrow id="S4.T4.st1.6.6.2.m2.1.1.2" xref="S4.T4.st1.6.6.2.m2.1.1.2.cmml"><mn id="S4.T4.st1.6.6.2.m2.1.1.2.2" xref="S4.T4.st1.6.6.2.m2.1.1.2.2.cmml">1</mn><mo id="S4.T4.st1.6.6.2.m2.1.1.2.1" xref="S4.T4.st1.6.6.2.m2.1.1.2.1.cmml">/</mo><mn id="S4.T4.st1.6.6.2.m2.1.1.2.3" xref="S4.T4.st1.6.6.2.m2.1.1.2.3.cmml">3</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T4.st1.6.6.2.m2.1.1.1" xref="S4.T4.st1.6.6.2.m2.1.1.1.cmml">​</mo><mi id="S4.T4.st1.6.6.2.m2.1.1.3" xref="S4.T4.st1.6.6.2.m2.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.st1.6.6.2.m2.1b"><apply id="S4.T4.st1.6.6.2.m2.1.1.cmml" xref="S4.T4.st1.6.6.2.m2.1.1"><times id="S4.T4.st1.6.6.2.m2.1.1.1.cmml" xref="S4.T4.st1.6.6.2.m2.1.1.1"></times><apply id="S4.T4.st1.6.6.2.m2.1.1.2.cmml" xref="S4.T4.st1.6.6.2.m2.1.1.2"><divide id="S4.T4.st1.6.6.2.m2.1.1.2.1.cmml" xref="S4.T4.st1.6.6.2.m2.1.1.2.1"></divide><cn type="integer" id="S4.T4.st1.6.6.2.m2.1.1.2.2.cmml" xref="S4.T4.st1.6.6.2.m2.1.1.2.2">1</cn><cn type="integer" id="S4.T4.st1.6.6.2.m2.1.1.2.3.cmml" xref="S4.T4.st1.6.6.2.m2.1.1.2.3">3</cn></apply><ci id="S4.T4.st1.6.6.2.m2.1.1.3.cmml" xref="S4.T4.st1.6.6.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.6.6.2.m2.1c">1/3L</annotation></semantics></math>)</td>
<td id="S4.T4.st1.6.6.4" class="ltx_td ltx_align_center ltx_border_t">0.6G</td>
<td id="S4.T4.st1.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.st1.6.6.5.1" class="ltx_text ltx_font_bold">66.95</span></td>
</tr>
<tr id="S4.T4.st1.8.8" class="ltx_tr">
<td id="S4.T4.st1.8.8.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">slim-interm. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="S4.T4.st1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">(<math id="S4.T4.st1.7.7.1.m1.1" class="ltx_Math" alttext="1/4D" display="inline"><semantics id="S4.T4.st1.7.7.1.m1.1a"><mrow id="S4.T4.st1.7.7.1.m1.1.1" xref="S4.T4.st1.7.7.1.m1.1.1.cmml"><mrow id="S4.T4.st1.7.7.1.m1.1.1.2" xref="S4.T4.st1.7.7.1.m1.1.1.2.cmml"><mn id="S4.T4.st1.7.7.1.m1.1.1.2.2" xref="S4.T4.st1.7.7.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.T4.st1.7.7.1.m1.1.1.2.1" xref="S4.T4.st1.7.7.1.m1.1.1.2.1.cmml">/</mo><mn id="S4.T4.st1.7.7.1.m1.1.1.2.3" xref="S4.T4.st1.7.7.1.m1.1.1.2.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T4.st1.7.7.1.m1.1.1.1" xref="S4.T4.st1.7.7.1.m1.1.1.1.cmml">​</mo><mi id="S4.T4.st1.7.7.1.m1.1.1.3" xref="S4.T4.st1.7.7.1.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.st1.7.7.1.m1.1b"><apply id="S4.T4.st1.7.7.1.m1.1.1.cmml" xref="S4.T4.st1.7.7.1.m1.1.1"><times id="S4.T4.st1.7.7.1.m1.1.1.1.cmml" xref="S4.T4.st1.7.7.1.m1.1.1.1"></times><apply id="S4.T4.st1.7.7.1.m1.1.1.2.cmml" xref="S4.T4.st1.7.7.1.m1.1.1.2"><divide id="S4.T4.st1.7.7.1.m1.1.1.2.1.cmml" xref="S4.T4.st1.7.7.1.m1.1.1.2.1"></divide><cn type="integer" id="S4.T4.st1.7.7.1.m1.1.1.2.2.cmml" xref="S4.T4.st1.7.7.1.m1.1.1.2.2">1</cn><cn type="integer" id="S4.T4.st1.7.7.1.m1.1.1.2.3.cmml" xref="S4.T4.st1.7.7.1.m1.1.1.2.3">4</cn></apply><ci id="S4.T4.st1.7.7.1.m1.1.1.3.cmml" xref="S4.T4.st1.7.7.1.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.7.7.1.m1.1c">1/4D</annotation></semantics></math>,<math id="S4.T4.st1.8.8.2.m2.1" class="ltx_Math" alttext="1/3L" display="inline"><semantics id="S4.T4.st1.8.8.2.m2.1a"><mrow id="S4.T4.st1.8.8.2.m2.1.1" xref="S4.T4.st1.8.8.2.m2.1.1.cmml"><mrow id="S4.T4.st1.8.8.2.m2.1.1.2" xref="S4.T4.st1.8.8.2.m2.1.1.2.cmml"><mn id="S4.T4.st1.8.8.2.m2.1.1.2.2" xref="S4.T4.st1.8.8.2.m2.1.1.2.2.cmml">1</mn><mo id="S4.T4.st1.8.8.2.m2.1.1.2.1" xref="S4.T4.st1.8.8.2.m2.1.1.2.1.cmml">/</mo><mn id="S4.T4.st1.8.8.2.m2.1.1.2.3" xref="S4.T4.st1.8.8.2.m2.1.1.2.3.cmml">3</mn></mrow><mo lspace="0em" rspace="0em" id="S4.T4.st1.8.8.2.m2.1.1.1" xref="S4.T4.st1.8.8.2.m2.1.1.1.cmml">​</mo><mi id="S4.T4.st1.8.8.2.m2.1.1.3" xref="S4.T4.st1.8.8.2.m2.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.st1.8.8.2.m2.1b"><apply id="S4.T4.st1.8.8.2.m2.1.1.cmml" xref="S4.T4.st1.8.8.2.m2.1.1"><times id="S4.T4.st1.8.8.2.m2.1.1.1.cmml" xref="S4.T4.st1.8.8.2.m2.1.1.1"></times><apply id="S4.T4.st1.8.8.2.m2.1.1.2.cmml" xref="S4.T4.st1.8.8.2.m2.1.1.2"><divide id="S4.T4.st1.8.8.2.m2.1.1.2.1.cmml" xref="S4.T4.st1.8.8.2.m2.1.1.2.1"></divide><cn type="integer" id="S4.T4.st1.8.8.2.m2.1.1.2.2.cmml" xref="S4.T4.st1.8.8.2.m2.1.1.2.2">1</cn><cn type="integer" id="S4.T4.st1.8.8.2.m2.1.1.2.3.cmml" xref="S4.T4.st1.8.8.2.m2.1.1.2.3">3</cn></apply><ci id="S4.T4.st1.8.8.2.m2.1.1.3.cmml" xref="S4.T4.st1.8.8.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st1.8.8.2.m2.1c">1/3L</annotation></semantics></math>)</td>
<td id="S4.T4.st1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb">0.8G</td>
<td id="S4.T4.st1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb">66.83</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.st1.13.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.T4.st1.14.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Width Slimming.<span id="S4.T4.st1.14.2.1" class="ltx_text ltx_font_medium"> Under the same model depth and similar number of FLOPs, the obtained submodels trained with the <em id="S4.T4.st1.14.2.1.1" class="ltx_emph ltx_font_italic">slim-all</em> strategy outperform the <em id="S4.T4.st1.14.2.1.2" class="ltx_emph ltx_font_italic">slim-intermediate</em> strategy, showing the significance of keeping the ratio of input-output dimensionality in width slimming.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T4.st2" class="ltx_table ltx_figure_panel">
<table id="S4.T4.st2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.st2.2.1" class="ltx_tr">
<td id="S4.T4.st2.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">slimming strategy</td>
<td id="S4.T4.st2.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">  average accuracy (%)</td>
</tr>
<tr id="S4.T4.st2.2.2" class="ltx_tr">
<td id="S4.T4.st2.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-bottom:1.42262pt;">slim-random</td>
<td id="S4.T4.st2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:1.42262pt;">66.98</td>
</tr>
<tr id="S4.T4.st2.2.3" class="ltx_tr">
<td id="S4.T4.st2.2.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-bottom:1.42262pt;">slim-first</td>
<td id="S4.T4.st2.2.3.2" class="ltx_td ltx_align_center" style="padding-bottom:1.42262pt;">66.99</td>
</tr>
<tr id="S4.T4.st2.2.4" class="ltx_tr">
<td id="S4.T4.st2.2.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-bottom:1.42262pt;">slim-last</td>
<td id="S4.T4.st2.2.4.2" class="ltx_td ltx_align_center" style="padding-bottom:1.42262pt;">67.07</td>
</tr>
<tr id="S4.T4.st2.2.5" class="ltx_tr">
<td id="S4.T4.st2.2.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-bottom:0.85358pt;"><span id="S4.T4.st2.2.5.1.1" class="ltx_text ltx_font_bold">slim-middle</span></td>
<td id="S4.T4.st2.2.5.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-bottom:0.85358pt;"><span id="S4.T4.st2.2.5.2.1" class="ltx_text ltx_font_bold">67.14</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.st2.5.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.T4.st2.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Depth Slimming.<span id="S4.T4.st2.6.2.1" class="ltx_text ltx_font_medium"> The <em id="S4.T4.st2.6.2.1.1" class="ltx_emph ltx_font_italic">slim-middle</em> strategy outperforms all the counterparts in terms of average accuracy, verifying that the middle layers in Transformer are less important than the first and last ones. More evidence is shown in Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-E Ablation Studies ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T4.st3" class="ltx_table ltx_figure_panel">
<table id="S4.T4.st3.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.st3.6.1" class="ltx_tr">
<td id="S4.T4.st3.6.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">#sampled submodels</td>
<td id="S4.T4.st3.6.1.2" class="ltx_td ltx_align_center ltx_border_tt">average accuracy (%)</td>
<td id="S4.T4.st3.6.1.3" class="ltx_td ltx_align_center ltx_border_tt">training time (h)</td>
</tr>
<tr id="S4.T4.st3.6.2" class="ltx_tr">
<td id="S4.T4.st3.6.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.st3.6.2.1.1" class="ltx_text ltx_font_italic">K</span>=3</td>
<td id="S4.T4.st3.6.2.2" class="ltx_td ltx_align_center ltx_border_t">66.88</td>
<td id="S4.T4.st3.6.2.3" class="ltx_td ltx_align_center ltx_border_t">64</td>
</tr>
<tr id="S4.T4.st3.6.3" class="ltx_tr">
<td id="S4.T4.st3.6.3.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T4.st3.6.3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">K<span id="S4.T4.st3.6.3.1.1.1" class="ltx_text ltx_font_upright">=4</span></span></td>
<td id="S4.T4.st3.6.3.2" class="ltx_td ltx_align_center">67.14</td>
<td id="S4.T4.st3.6.3.3" class="ltx_td ltx_align_center">68</td>
</tr>
<tr id="S4.T4.st3.6.4" class="ltx_tr">
<td id="S4.T4.st3.6.4.1" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T4.st3.6.4.1.1" class="ltx_text ltx_font_italic">K</span>=5</td>
<td id="S4.T4.st3.6.4.2" class="ltx_td ltx_align_center">67.15</td>
<td id="S4.T4.st3.6.4.3" class="ltx_td ltx_align_center">73</td>
</tr>
<tr id="S4.T4.st3.6.5" class="ltx_tr">
<td id="S4.T4.st3.6.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">
<span id="S4.T4.st3.6.5.1.1" class="ltx_text ltx_font_italic">K</span>=6</td>
<td id="S4.T4.st3.6.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.st3.6.5.2.1" class="ltx_text ltx_font_bold">67.16</span></td>
<td id="S4.T4.st3.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">79</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.st3.8.3.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.T4.st3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Number of Sampled Submodels.<span id="S4.T4.st3.4.2.2" class="ltx_text ltx_font_medium"> <math id="S4.T4.st3.3.1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.T4.st3.3.1.1.m1.1b"><mi id="S4.T4.st3.3.1.1.m1.1.1" xref="S4.T4.st3.3.1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.T4.st3.3.1.1.m1.1c"><ci id="S4.T4.st3.3.1.1.m1.1.1.cmml" xref="S4.T4.st3.3.1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st3.3.1.1.m1.1d">K</annotation></semantics></math>=4 is a good trade-off between the average accuracy and training time. Further increasing <math id="S4.T4.st3.4.2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.T4.st3.4.2.2.m2.1b"><mi id="S4.T4.st3.4.2.2.m2.1.1" xref="S4.T4.st3.4.2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.T4.st3.4.2.2.m2.1c"><ci id="S4.T4.st3.4.2.2.m2.1.1.cmml" xref="S4.T4.st3.4.2.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.st3.4.2.2.m2.1d">K</annotation></semantics></math> does not bring prominent performance improvement but takes more training time.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T4.st4" class="ltx_table ltx_figure_panel">
<table id="S4.T4.st4.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.st4.2.1" class="ltx_tr">
<td id="S4.T4.st4.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">training strategy</td>
<td id="S4.T4.st4.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">average accuracy (%)</td>
</tr>
<tr id="S4.T4.st4.2.2" class="ltx_tr">
<td id="S4.T4.st4.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w/ random init, w/o KD</td>
<td id="S4.T4.st4.2.2.2" class="ltx_td ltx_align_center ltx_border_t">65.89</td>
</tr>
<tr id="S4.T4.st4.2.3" class="ltx_tr">
<td id="S4.T4.st4.2.3.1" class="ltx_td ltx_align_left ltx_border_r">w/ random init, w/ ID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>
</td>
<td id="S4.T4.st4.2.3.2" class="ltx_td ltx_align_center">65.55</td>
</tr>
<tr id="S4.T4.st4.2.4" class="ltx_tr">
<td id="S4.T4.st4.2.4.1" class="ltx_td ltx_align_left ltx_border_r">w/ random init, w/ KD</td>
<td id="S4.T4.st4.2.4.2" class="ltx_td ltx_align_center">66.95</td>
</tr>
<tr id="S4.T4.st4.2.5" class="ltx_tr">
<td id="S4.T4.st4.2.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T4.st4.2.5.1.1" class="ltx_text ltx_font_bold">w/ teacher init, w/ KD</span></td>
<td id="S4.T4.st4.2.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.st4.2.5.2.1" class="ltx_text ltx_font_bold">67.14</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.st4.4.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.T4.st4.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Training Strategy.<span id="S4.T4.st4.5.2.1" class="ltx_text ltx_font_medium"> The teacher initialization and KD strategies show advantages over the random initialization and ID strategies in terms of average accuracy, respectively.</span></span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Ablation Studies</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">We run a number of ablations on MCAN<math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><msub id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml"><mi id="S4.SS5.p1.1.m1.1.1a" xref="S4.SS5.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS5.p1.1.m1.1.1.1" xref="S4.SS5.p1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1"><ci id="S4.SS5.p1.1.m1.1.1.1a.cmml" xref="S4.SS5.p1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> to analyze the effectiveness of the key component in BST. The results are shown in Table <a href="#S4.T4.st4" title="In TABLE IV ‣ IV-D Runtime Latency on Different Hardware Platforms ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV(d)</span></a> and Fig. <a href="#S4.F7" title="Figure 7 ‣ IV-E Ablation Studies ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and discussed in detail below.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para ltx_noindent">
<p id="S4.SS5.p2.1" class="ltx_p"><span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_bold">Width Slimming.</span>
In Table <a href="#S4.T4.st1" title="In TABLE IV ‣ IV-D Runtime Latency on Different Hardware Platforms ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV(a)</span></a>, we show the results of the MCAN<math id="S4.SS5.p2.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS5.p2.1.m1.1a"><msub id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml"><mi id="S4.SS5.p2.1.m1.1.1a" xref="S4.SS5.p2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS5.p2.1.m1.1.1.1" xref="S4.SS5.p2.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><apply id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1"><ci id="S4.SS5.p2.1.m1.1.1.1a.cmml" xref="S4.SS5.p2.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS5.p2.1.m1.1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> variants trained with different width slimming strategies, <em id="S4.SS5.p2.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, the <em id="S4.SS5.p2.1.3" class="ltx_emph ltx_font_italic">slim-all</em> strategy introduced in this paper and the <em id="S4.SS5.p2.1.4" class="ltx_emph ltx_font_italic">slim-intermediate</em> strategy introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. By comparing two submodels of similar FLOPs, we see that our <em id="S4.SS5.p2.1.5" class="ltx_emph ltx_font_italic">slim-all</em> strategy delivers better model performance than the <em id="S4.SS5.p2.1.6" class="ltx_emph ltx_font_italic">slim-intermediate</em> strategy under different model depths.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><span id="S4.F7.1.pic1" class="ltx_picture ltx_centering" style="width:211.8pt;height:138.0pt;">\begin{overpic}[width=212.47617pt]{fig7a.png}
\put(45.0,23.0){\includegraphics[width=117.07924pt]{fig7b.pdf}}
\end{overpic}</span>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.9.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Submodel Selection.<span id="S4.F7.3.2.1.1" class="ltx_text ltx_font_medium"> The accuracies <span id="S4.F7.3.2.1.1.1" class="ltx_text ltx_font_italic">vs</span>. FLOPs on VQA-v2 <span id="S4.F7.3.2.1.1.2" class="ltx_text ltx_font_typewriter">minival</span> split are reported to compare two MCAN<math id="S4.F7.3.2.1.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.F7.3.2.1.1.m1.1b"><msub id="S4.F7.3.2.1.1.m1.1.1" xref="S4.F7.3.2.1.1.m1.1.1.cmml"><mi id="S4.F7.3.2.1.1.m1.1.1b" xref="S4.F7.3.2.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.F7.3.2.1.1.m1.1.1.1" xref="S4.F7.3.2.1.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F7.3.2.1.1.m1.1c"><apply id="S4.F7.3.2.1.1.m1.1.1.cmml" xref="S4.F7.3.2.1.1.m1.1.1"><ci id="S4.F7.3.2.1.1.m1.1.1.1a.cmml" xref="S4.F7.3.2.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.F7.3.2.1.1.m1.1.1.1.cmml" xref="S4.F7.3.2.1.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.3.2.1.1.m1.1d">{}_{\texttt{BST}}</annotation></semantics></math> variants with 10 and 16 submodels, respectively. The network architectures of the 10 submodels (red squares) correspond to a subset of the 16 submodels (blue squares) after discarding 6 <em id="S4.F7.3.2.1.1.3" class="ltx_emph ltx_font_italic">ineffective</em> submodels (red crosses) by using our triangle selection strategy.</span></span></figcaption>
</figure>
<div id="S4.SS5.p3" class="ltx_para ltx_noindent">
<p id="S4.SS5.p3.1" class="ltx_p"><span id="S4.SS5.p3.1.1" class="ltx_text ltx_font_bold">Depth Slimming.</span> In Table <a href="#S4.T4.st2" title="In TABLE IV ‣ IV-D Runtime Latency on Different Hardware Platforms ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV(b)</span></a>, we compare the MCAN<math id="S4.SS5.p3.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS5.p3.1.m1.1a"><msub id="S4.SS5.p3.1.m1.1.1" xref="S4.SS5.p3.1.m1.1.1.cmml"><mi id="S4.SS5.p3.1.m1.1.1a" xref="S4.SS5.p3.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS5.p3.1.m1.1.1.1" xref="S4.SS5.p3.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.1.m1.1b"><apply id="S4.SS5.p3.1.m1.1.1.cmml" xref="S4.SS5.p3.1.m1.1.1"><ci id="S4.SS5.p3.1.m1.1.1.1a.cmml" xref="S4.SS5.p3.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS5.p3.1.m1.1.1.1.cmml" xref="S4.SS5.p3.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> variants with different depth slimming strategies (mentioned in Section <a href="#S3.SS2" title="III-B The BST Framework ‣ III Bilaterally Slimmable Transformer (BST) ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>) in terms of average accuracy over the ten submodels. From the results, we can see that the <em id="S4.SS5.p3.1.2" class="ltx_emph ltx_font_italic">slim-middle</em> strategy achieves the best performance among the counterparts, suggesting that the bottom and top layers of the Transformer are more important than the middle layers. This observation is consistent with the results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. We also provide visualization results in section <a href="#S4.SS6" title="IV-F Visualization Analysis ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-F</span></span></a> by introducing a simple score function based on the magnitudes of the output features of each layer. The calculated layer scores are consistent with those obtained by the slim-middle strategy, verifying its effectiveness from a side view.</p>
</div>
<div id="S4.SS5.p4" class="ltx_para ltx_noindent">
<p id="S4.SS5.p4.3" class="ltx_p"><span id="S4.SS5.p4.3.1" class="ltx_text ltx_font_bold">Number of Sampled Submodels.</span> In Table <a href="#S4.T4.st3" title="In TABLE IV ‣ IV-D Runtime Latency on Different Hardware Platforms ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV(c)</span></a>, we ablate the effects of different numbers of sampled submodels during the BST training. The results suggest that <math id="S4.SS5.p4.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS5.p4.1.m1.1a"><mi id="S4.SS5.p4.1.m1.1.1" xref="S4.SS5.p4.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.1.m1.1b"><ci id="S4.SS5.p4.1.m1.1.1.cmml" xref="S4.SS5.p4.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.1.m1.1c">K</annotation></semantics></math>=4 is a good trade-off between the average accuracy and training time. Further increasing <math id="S4.SS5.p4.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS5.p4.2.m2.1a"><mi id="S4.SS5.p4.2.m2.1.1" xref="S4.SS5.p4.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.2.m2.1b"><ci id="S4.SS5.p4.2.m2.1.1.cmml" xref="S4.SS5.p4.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.2.m2.1c">K</annotation></semantics></math> does not bring a great performance improvement but takes much more training time. The fast saturation with such a small <math id="S4.SS5.p4.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS5.p4.3.m3.1a"><mi id="S4.SS5.p4.3.m3.1.1" xref="S4.SS5.p4.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.3.m3.1b"><ci id="S4.SS5.p4.3.m3.1.1.cmml" xref="S4.SS5.p4.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.3.m3.1c">K</annotation></semantics></math> is facilitated by the weight-sharing strategy of different submodels.</p>
</div>
<div id="S4.SS5.p5" class="ltx_para ltx_noindent">
<p id="S4.SS5.p5.1" class="ltx_p"><span id="S4.SS5.p5.1.1" class="ltx_text ltx_font_bold">Training Strategy.</span> Our default training strategy uses the model parameters from a teacher model for initialization and then trains the submodels using a KD training strategy to exploit the implicit knowledge from the teacher model. The results in Table <a href="#S4.T4.st4" title="In TABLE IV ‣ IV-D Runtime Latency on Different Hardware Platforms ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV(d)</span></a> show that both the teacher model initialization and the KD training improve the obtained MCAN<math id="S4.SS5.p5.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS5.p5.1.m1.1a"><msub id="S4.SS5.p5.1.m1.1.1" xref="S4.SS5.p5.1.m1.1.1.cmml"><mi id="S4.SS5.p5.1.m1.1.1a" xref="S4.SS5.p5.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS5.p5.1.m1.1.1.1" xref="S4.SS5.p5.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p5.1.m1.1b"><apply id="S4.SS5.p5.1.m1.1.1.cmml" xref="S4.SS5.p5.1.m1.1.1"><ci id="S4.SS5.p5.1.m1.1.1.1a.cmml" xref="S4.SS5.p5.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS5.p5.1.m1.1.1.1.cmml" xref="S4.SS5.p5.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p5.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> model, compared to the model variants trained with random initialization or supervised by the ground-truth answer. In contrast to our KD training strategy that uses a fixed teacher model, an alternative strategy introduces a special <em id="S4.SS5.p5.1.2" class="ltx_emph ltx_font_italic">inplace distillation</em> (ID) training strategy that takes the largest submodel as the <em id="S4.SS5.p5.1.3" class="ltx_emph ltx_font_italic">dynamic</em> teacher to perform knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. We note that the ID-based strategy results in worse performance than the KD training strategy (65.55% <em id="S4.SS5.p5.1.4" class="ltx_emph ltx_font_italic">vs.</em> 66.95% in terms of average accuracy), and even underperforms standard training without knowledge distillation (65.55% <em id="S4.SS5.p5.1.5" class="ltx_emph ltx_font_italic">vs.</em> 65.89%). This suggests that a stable teacher model plays a key role in BST.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2203.12814/assets/x5.png" id="S4.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="214" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.4.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.5.2" class="ltx_text" style="font-size:90%;">Visualizations of the calculated layer importance scores given trained MCAN, UNITER, and CLIP-ViL models, respectively. A darker color indicates a larger score of the layer. The layer scores for all the three models exhibit a “heavy ends and light middle” phenomenon, which are consistent with the layer scores achieved by the <em id="S4.F8.5.2.1" class="ltx_emph ltx_font_italic">slim-middle</em> strategy.</span></figcaption>
</figure>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2203.12814/assets/x6.png" id="S4.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="151" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.7.3.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.5.4.2" class="ltx_text" style="font-size:90%;">Visualizations of the learned attention maps (<math id="S4.F9.4.3.1.m1.1" class="ltx_Math" alttext="\mathrm{softmax}(QK^{T}/\sqrt{D_{H}})" display="inline"><semantics id="S4.F9.4.3.1.m1.1b"><mrow id="S4.F9.4.3.1.m1.1.1" xref="S4.F9.4.3.1.m1.1.1.cmml"><mi id="S4.F9.4.3.1.m1.1.1.3" xref="S4.F9.4.3.1.m1.1.1.3.cmml">softmax</mi><mo lspace="0em" rspace="0em" id="S4.F9.4.3.1.m1.1.1.2" xref="S4.F9.4.3.1.m1.1.1.2.cmml">​</mo><mrow id="S4.F9.4.3.1.m1.1.1.1.1" xref="S4.F9.4.3.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.F9.4.3.1.m1.1.1.1.1.2" xref="S4.F9.4.3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.F9.4.3.1.m1.1.1.1.1.1" xref="S4.F9.4.3.1.m1.1.1.1.1.1.cmml"><mrow id="S4.F9.4.3.1.m1.1.1.1.1.1.2" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.cmml"><mi id="S4.F9.4.3.1.m1.1.1.1.1.1.2.2" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.F9.4.3.1.m1.1.1.1.1.1.2.1" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.1.cmml">​</mo><msup id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.cmml"><mi id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.2" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.2.cmml">K</mi><mi id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.3" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.3.cmml">T</mi></msup></mrow><mo id="S4.F9.4.3.1.m1.1.1.1.1.1.1" xref="S4.F9.4.3.1.m1.1.1.1.1.1.1.cmml">/</mo><msqrt id="S4.F9.4.3.1.m1.1.1.1.1.1.3" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.cmml"><msub id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.cmml"><mi id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.2" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.2.cmml">D</mi><mi id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.3" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.3.cmml">H</mi></msub></msqrt></mrow><mo stretchy="false" id="S4.F9.4.3.1.m1.1.1.1.1.3" xref="S4.F9.4.3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F9.4.3.1.m1.1c"><apply id="S4.F9.4.3.1.m1.1.1.cmml" xref="S4.F9.4.3.1.m1.1.1"><times id="S4.F9.4.3.1.m1.1.1.2.cmml" xref="S4.F9.4.3.1.m1.1.1.2"></times><ci id="S4.F9.4.3.1.m1.1.1.3.cmml" xref="S4.F9.4.3.1.m1.1.1.3">softmax</ci><apply id="S4.F9.4.3.1.m1.1.1.1.1.1.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1"><divide id="S4.F9.4.3.1.m1.1.1.1.1.1.1.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.1"></divide><apply id="S4.F9.4.3.1.m1.1.1.1.1.1.2.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2"><times id="S4.F9.4.3.1.m1.1.1.1.1.1.2.1.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.1"></times><ci id="S4.F9.4.3.1.m1.1.1.1.1.1.2.2.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.2">𝑄</ci><apply id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.1.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3">superscript</csymbol><ci id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.2.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.2">𝐾</ci><ci id="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.3.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S4.F9.4.3.1.m1.1.1.1.1.1.3.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3"><root id="S4.F9.4.3.1.m1.1.1.1.1.1.3a.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3"></root><apply id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.1.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.2.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.2">𝐷</ci><ci id="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.3.cmml" xref="S4.F9.4.3.1.m1.1.1.1.1.1.3.2.3">𝐻</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F9.4.3.1.m1.1d">\mathrm{softmax}(QK^{T}/\sqrt{D_{H}})</annotation></semantics></math>) from three MCAN<math id="S4.F9.5.4.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.F9.5.4.2.m2.1b"><msub id="S4.F9.5.4.2.m2.1.1" xref="S4.F9.5.4.2.m2.1.1.cmml"><mi id="S4.F9.5.4.2.m2.1.1b" xref="S4.F9.5.4.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.F9.5.4.2.m2.1.1.1" xref="S4.F9.5.4.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F9.5.4.2.m2.1c"><apply id="S4.F9.5.4.2.m2.1.1.cmml" xref="S4.F9.5.4.2.m2.1.1"><ci id="S4.F9.5.4.2.m2.1.1.1a.cmml" xref="S4.F9.5.4.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.F9.5.4.2.m2.1.1.1.cmml" xref="S4.F9.5.4.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F9.5.4.2.m2.1d">{}_{\texttt{BST}}</annotation></semantics></math> submodels trained on VQA-v2. For each submodel, we show the attention maps from different heads in the first and last layers of the question encoder and image decoder, respectively. We highlight some representative attention maps with blue bounding boxes to better understand the attention mechnisims behind.</span></figcaption>
</figure>
<div id="S4.SS5.p6" class="ltx_para ltx_noindent">
<p id="S4.SS5.p6.7" class="ltx_p"><span id="S4.SS5.p6.7.1" class="ltx_text ltx_font_bold">Submodel Selection.</span> In Fig. <a href="#S4.F7" title="Figure 7 ‣ IV-E Ablation Studies ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we compare two MCAN<math id="S4.SS5.p6.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS5.p6.1.m1.1a"><msub id="S4.SS5.p6.1.m1.1.1" xref="S4.SS5.p6.1.m1.1.1.cmml"><mi id="S4.SS5.p6.1.m1.1.1a" xref="S4.SS5.p6.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS5.p6.1.m1.1.1.1" xref="S4.SS5.p6.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.1.m1.1b"><apply id="S4.SS5.p6.1.m1.1.1.cmml" xref="S4.SS5.p6.1.m1.1.1"><ci id="S4.SS5.p6.1.m1.1.1.1a.cmml" xref="S4.SS5.p6.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS5.p6.1.m1.1.1.1.cmml" xref="S4.SS5.p6.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> variants with 10 and 16 submodels. From the results, we have the following observations: 1) all the <em id="S4.SS5.p6.7.2" class="ltx_emph ltx_font_italic">ineffective</em> submodels, which require more FLOPs but obtain lower accuracies than some other submodels, are precisely detected by our simple triangle selection strategy, 2) removing such ineffective submodel architectures before the BST training brings improvements to all the remaining submodels, and 3) taking the submodel (3/4<math id="S4.SS5.p6.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS5.p6.2.m2.1a"><mi id="S4.SS5.p6.2.m2.1.1" xref="S4.SS5.p6.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.2.m2.1b"><ci id="S4.SS5.p6.2.m2.1.1.cmml" xref="S4.SS5.p6.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.2.m2.1c">D</annotation></semantics></math>, 2/3<math id="S4.SS5.p6.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS5.p6.3.m3.1a"><mi id="S4.SS5.p6.3.m3.1.1" xref="S4.SS5.p6.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.3.m3.1b"><ci id="S4.SS5.p6.3.m3.1.1.cmml" xref="S4.SS5.p6.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.3.m3.1c">L</annotation></semantics></math>) as the reference model, the submodel (3/4<math id="S4.SS5.p6.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS5.p6.4.m4.1a"><mi id="S4.SS5.p6.4.m4.1.1" xref="S4.SS5.p6.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.4.m4.1b"><ci id="S4.SS5.p6.4.m4.1.1.cmml" xref="S4.SS5.p6.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.4.m4.1c">D</annotation></semantics></math>, <math id="S4.SS5.p6.5.m5.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS5.p6.5.m5.1a"><mi id="S4.SS5.p6.5.m5.1.1" xref="S4.SS5.p6.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.5.m5.1b"><ci id="S4.SS5.p6.5.m5.1.1.cmml" xref="S4.SS5.p6.5.m5.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.5.m5.1c">L</annotation></semantics></math>) outperforms (<math id="S4.SS5.p6.6.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS5.p6.6.m6.1a"><mi id="S4.SS5.p6.6.m6.1.1" xref="S4.SS5.p6.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.6.m6.1b"><ci id="S4.SS5.p6.6.m6.1.1.cmml" xref="S4.SS5.p6.6.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.6.m6.1c">D</annotation></semantics></math>, 2/3<math id="S4.SS5.p6.7.m7.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS5.p6.7.m7.1a"><mi id="S4.SS5.p6.7.m7.1.1" xref="S4.SS5.p6.7.m7.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p6.7.m7.1b"><ci id="S4.SS5.p6.7.m7.1.1.cmml" xref="S4.SS5.p6.7.m7.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p6.7.m7.1c">L</annotation></semantics></math>) with fewer FLOPs, verifying our hypothesis that increasing depth is more economical than increasing width for the Transformer.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.4.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.5.2" class="ltx_text ltx_font_italic">Visualization Analysis</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">As discussed in section <a href="#S4.SS5" title="IV-E Ablation Studies ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-E</span></span></a>, the method of measuring the layer importance plays key role in depth slimming.
Here, we introduce a data-driven strategy to measure the importance of each layer. Specifically, given a trained MCAN (UNITER or CLIP-ViL) model without model slimming, we first feed all the training samples through the network and memorize the output features for each layer. For the output features obtained from each layer, mean pooling is performed on each flattened feature vector to obtain its unnormalized score. Using this strategy, we show the importance scores for each layer of the MCAN, UNITER, and CLIP-ViL models in Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-E Ablation Studies ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. From the visualized results, we see that the layer scores of all models exhibit “heavy tails and a light middle”, which is consistent with the layer scores achieved by the slim-middle strategy.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.10" class="ltx_p">To better understand the behaviors of the weight-sharing submodels learned by BST, we show the attention maps from three MCAN<math id="S4.SS6.p2.1.m1.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS6.p2.1.m1.1a"><msub id="S4.SS6.p2.1.m1.1.1" xref="S4.SS6.p2.1.m1.1.1.cmml"><mi id="S4.SS6.p2.1.m1.1.1a" xref="S4.SS6.p2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS6.p2.1.m1.1.1.1" xref="S4.SS6.p2.1.m1.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.1.m1.1b"><apply id="S4.SS6.p2.1.m1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1"><ci id="S4.SS6.p2.1.m1.1.1.1a.cmml" xref="S4.SS6.p2.1.m1.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS6.p2.1.m1.1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.1.m1.1c">{}_{\texttt{BST}}</annotation></semantics></math> submodels in Fig. <a href="#S4.F9" title="Figure 9 ‣ IV-E Ablation Studies ‣ IV Experimental Results ‣ Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. Due to space limitations, we only show one example and visualize the attention maps from the first and last layers of the question encoder and image decoder, respectively. To better understand the effect of the attention mechanism, we highlight some representative attention maps with blue bounding boxes. From the results, we have the following observations. In general, the slimmed submodels MCAN<math id="S4.SS6.p2.2.m2.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS6.p2.2.m2.1a"><msub id="S4.SS6.p2.2.m2.1.1" xref="S4.SS6.p2.2.m2.1.1.cmml"><mi id="S4.SS6.p2.2.m2.1.1a" xref="S4.SS6.p2.2.m2.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS6.p2.2.m2.1.1.1" xref="S4.SS6.p2.2.m2.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.2.m2.1b"><apply id="S4.SS6.p2.2.m2.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1"><ci id="S4.SS6.p2.2.m2.1.1.1a.cmml" xref="S4.SS6.p2.2.m2.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS6.p2.2.m2.1.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.2.m2.1c">{}_{\texttt{BST}}</annotation></semantics></math>(1/4<math id="S4.SS6.p2.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS6.p2.3.m3.1a"><mi id="S4.SS6.p2.3.m3.1.1" xref="S4.SS6.p2.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.3.m3.1b"><ci id="S4.SS6.p2.3.m3.1.1.cmml" xref="S4.SS6.p2.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.3.m3.1c">D</annotation></semantics></math>,<math id="S4.SS6.p2.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS6.p2.4.m4.1a"><mi id="S4.SS6.p2.4.m4.1.1" xref="S4.SS6.p2.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.4.m4.1b"><ci id="S4.SS6.p2.4.m4.1.1.cmml" xref="S4.SS6.p2.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.4.m4.1c">L</annotation></semantics></math>) and MCAN<math id="S4.SS6.p2.5.m5.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS6.p2.5.m5.1a"><msub id="S4.SS6.p2.5.m5.1.1" xref="S4.SS6.p2.5.m5.1.1.cmml"><mi id="S4.SS6.p2.5.m5.1.1a" xref="S4.SS6.p2.5.m5.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS6.p2.5.m5.1.1.1" xref="S4.SS6.p2.5.m5.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.5.m5.1b"><apply id="S4.SS6.p2.5.m5.1.1.cmml" xref="S4.SS6.p2.5.m5.1.1"><ci id="S4.SS6.p2.5.m5.1.1.1a.cmml" xref="S4.SS6.p2.5.m5.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS6.p2.5.m5.1.1.1.cmml" xref="S4.SS6.p2.5.m5.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.5.m5.1c">{}_{\texttt{BST}}</annotation></semantics></math>(1/4<math id="S4.SS6.p2.6.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS6.p2.6.m6.1a"><mi id="S4.SS6.p2.6.m6.1.1" xref="S4.SS6.p2.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.6.m6.1b"><ci id="S4.SS6.p2.6.m6.1.1.cmml" xref="S4.SS6.p2.6.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.6.m6.1c">D</annotation></semantics></math>,1/3<math id="S4.SS6.p2.7.m7.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS6.p2.7.m7.1a"><mi id="S4.SS6.p2.7.m7.1.1" xref="S4.SS6.p2.7.m7.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.7.m7.1b"><ci id="S4.SS6.p2.7.m7.1.1.cmml" xref="S4.SS6.p2.7.m7.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.7.m7.1c">L</annotation></semantics></math>) have fewer <em id="S4.SS6.p2.10.1" class="ltx_emph ltx_font_italic">redundant</em> heads (<em id="S4.SS6.p2.10.2" class="ltx_emph ltx_font_italic">i.e.</em>, similar attention maps within one layer) than the full-sized model MCAN<math id="S4.SS6.p2.8.m8.1" class="ltx_Math" alttext="{}_{\texttt{BST}}" display="inline"><semantics id="S4.SS6.p2.8.m8.1a"><msub id="S4.SS6.p2.8.m8.1.1" xref="S4.SS6.p2.8.m8.1.1.cmml"><mi id="S4.SS6.p2.8.m8.1.1a" xref="S4.SS6.p2.8.m8.1.1.cmml"></mi><mtext class="ltx_mathvariant_monospace" id="S4.SS6.p2.8.m8.1.1.1" xref="S4.SS6.p2.8.m8.1.1.1a.cmml">BST</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.8.m8.1b"><apply id="S4.SS6.p2.8.m8.1.1.cmml" xref="S4.SS6.p2.8.m8.1.1"><ci id="S4.SS6.p2.8.m8.1.1.1a.cmml" xref="S4.SS6.p2.8.m8.1.1.1"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S4.SS6.p2.8.m8.1.1.1.cmml" xref="S4.SS6.p2.8.m8.1.1.1">BST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.8.m8.1c">{}_{\texttt{BST}}</annotation></semantics></math>(<math id="S4.SS6.p2.9.m9.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS6.p2.9.m9.1a"><mi id="S4.SS6.p2.9.m9.1.1" xref="S4.SS6.p2.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.9.m9.1b"><ci id="S4.SS6.p2.9.m9.1.1.cmml" xref="S4.SS6.p2.9.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.9.m9.1c">D</annotation></semantics></math>,<math id="S4.SS6.p2.10.m10.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS6.p2.10.m10.1a"><mi id="S4.SS6.p2.10.m10.1.1" xref="S4.SS6.p2.10.m10.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.10.m10.1b"><ci id="S4.SS6.p2.10.m10.1.1.cmml" xref="S4.SS6.p2.10.m10.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.10.m10.1c">L</annotation></semantics></math>). This verifies the feasibility and necessity of our BST framework. Moreover, the three submodels, which have different widths and depths, all predict the correct answer. This verifies the effectiveness of both the width and depth slimming strategies, as well as the training paradigm. Furthermore, the attention maps from the different submodels have similar properties to the attention maps in the original MCAN paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Almost all the attention maps from the first layer of the question encoder (<em id="S4.SS6.p2.10.3" class="ltx_emph ltx_font_italic">i.e.</em>, enc-1) attend to the column of words such as ‘<em id="S4.SS6.p2.10.4" class="ltx_emph ltx_font_italic">what</em>’, which act as the question type classifiers. In contrast, some attention maps from the last layer of the question encoder (<em id="S4.SS6.p2.10.5" class="ltx_emph ltx_font_italic">i.e.</em>, enc-6) and image decoder (<em id="S4.SS6.p2.10.6" class="ltx_emph ltx_font_italic">i.e.</em>, dec-1 and dec-6) focus on the columns of keywords such as ‘<em id="S4.SS6.p2.10.7" class="ltx_emph ltx_font_italic">head</em>’.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we present a new direction for the VQA task: learning efficient and elastic models that can adaptively fit different platforms. To this end, we present a general bilaterally slimmable Transformer (BST) framework that can be seamlessly integrated with any Transformer-based VQA model in theory. By integrating the BST framework with three typical Transformer-based VQA approaches, the resulting slimmable models outperform state-of-the-art methods with similar model sizes, or achieve comparable performance to that of much smaller models on both VQA-v2 and GQA datasets. Moreover, the quantitative experiments on diverse hardware platforms and devices show the practicability and necessity of BST.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">To the best of our knowledge, the proposed BST framework is the first attempt to explore efficient and elastic models for VQA. We hope our general framework can serve as a baseline to inspire future research on efficient multimodal learning.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems (NIPS)</em>, 2017, pp. 6000–6010.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Z. Yu, J. Yu, Y. Cui, D. Tao, and Q. Tian, “Deep modular co-attention networks
for visual question answering,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision
and Pattern Recognition (CVPR)</em>, 2019, pp. 6281–6290.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y.-C. Chen, L. Li, L. Yu, A. E. Kholy, F. Ahmed, Z. Gan, Y. Cheng, and J. Liu,
“Uniter: Universal image-text representation learning,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">European
Conference on Computer Vision (ECCV)</em>, 2020, pp. 104–120.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. Shen, L. H. Li, H. Tan, M. Bansal, A. Rohrbach, K.-W. Chang, Z. Yao, and
K. Keutzer, “How much can clip benefit vision-and-language tasks?” in
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Z. Yu, Y. Cui, J. Yu, M. Wang, D. Tao, and Q. Tian, “Deep multimodal neural
architecture search,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM International
Conference on Multimedia</em>, 2020, pp. 3743–3752.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Dong, X. Li, and D. Xu, “Cross-media similarity evaluation for web image
retrieval in the wild,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, vol. 20,
no. 9, pp. 2371–2384, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang,
“Bottom-up and top-down attention for image captioning and visual question
answering,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2018, pp. 6077–6086.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
L. Yu, Z. Lin, X. Shen, J. Yang, X. Lu, M. Bansal, and T. L. Berg, “Mattnet:
Modular attention network for referring expression comprehension,” in
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2018, pp. 1307–1315.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M. Sun, W. Suo, P. Wang, Y. Zhang, and Q. Wu, “A proposal-free one-stage
framework for referring expression comprehension and generation via dense
cross-attention,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, pp. 1–1, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
N. Ouyang, Q. Huang, P. Li, Y. Cai, B. Liu, H.-f. Leung, and Q. Li,
“Suppressing biased samples for robust vqa,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Multimedia</em>, vol. 24, pp. 3405–3415, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Z. Yu, Y. Cui, J. Yu, D. Tao, and Q. Tian, “Multimodal unified attention
networks for vision-and-language interactions,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1908.04107</em>, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
H. Tan and M. Bansal, “Lxmert: Learning cross-modality encoder representations
from transformers,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural
Language Processing (EMNLP)</em>, 2019, pp. 5100–5111.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Li, R. Selvaraju, A. Gotmare, S. Joty, C. Xiong, and S. C. H. Hoi, “Align
before fuse: Vision and language representation learning with momentum
distillation,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems (NIPS)</em>, 2021,
pp. 9694–9705.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Z. Yu, J. Yu, C. Xiang, J. Fan, and D. Tao, “Beyond bilinear: Generalized
multimodal factorized high-order pooling for visual question answering,”
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>, vol. 29,
no. 12, pp. 5947–5959, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J.-H. Kim, J. Jun, and B.-T. Zhang, “Bilinear attention networks,” in
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems (NIPS)</em>, 2018, pp. 1571–1581.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
W. Su, X. Zhu, Y. Cao, B. Li, L. Lu, F. Wei, and J. Dai, “Vl-bert:
Pre-training of generic visual-linguistic representations,” in
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Lu, D. Batra, D. Parikh, and S. Lee, “Vilbert: Pretraining task-agnostic
visiolinguistic representations for vision-and-language tasks,” in
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems (NIPS)</em>, 2019, pp. 13–23.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
X. Ma, P. Zhang, S. Zhang, N. Duan, Y. Hou, M. Zhou, and D. Song, “A
tensorized transformer for language modeling,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Neural Information
Processing Systems (NIPS)</em>, 2019, pp. 2229–2239.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, “Albert: A
lite bert for self-supervised learning of language representations,” in
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Dehghani, S. Gouws, O. Vinyals, J. Uszkoreit, and L. Kaiser, “Universal
transformers,” in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>, 2018.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
B. Cui, Y. Li, M. Chen, and Z. Zhang, “Fine-tune bert with sparse
self-attention mechanism,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in
Natural Language Processing and the International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP)</em>, 2019, pp. 3548–3553.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Fan, E. Grave, and A. Joulin, “Reducing transformer depth on demand with
structured dropout,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations (ICLR)</em>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
R. Tang, Y. Lu, L. Liu, L. Mou, O. Vechtomova, and J. Lin, “Distilling
task-specific knowledge from bert into simple neural networks,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1903.12136</em>, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
V. Sanh, L. Debut, J. Chaumond, and T. Wolf, “Distilbert, a distilled version
of bert: smaller, faster, cheaper and lighter,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1910.01108</em>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Z. Sun, H. Yu, X. Song, R. Liu, Y. Yang, and D. Zhou, “Mobilebert: a compact
task-agnostic bert for resource-limited devices,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of
the Association for Computational Linguistics (ACL)</em>, 2020, pp. 2158–2170.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
W. Liu, P. Zhou, Z. Wang, Z. Zhao, H. Deng, and Q. Ju, “Fastbert: a
self-distilling bert with adaptive inference time,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Annual Meeting
of the Association for Computational Linguistics (ACL)</em>, 2020, pp.
6035–6044.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
W. Wang, F. Wei, L. Dong, H. Bao, N. Yang, and M. Zhou, “Minilm: Deep
self-attention distillation for task-agnostic compression of pre-trained
transformers,” in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems (NIPS)</em>, 2020,
pp. 5776–5788.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Yu, L. Yang, N. Xu, J. Yang, and T. Huang, “Slimmable neural networks,” in
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
L. Hou, Z. Huang, L. Shang, X. Jiang, X. Chen, and Q. Liu, “Dynabert: Dynamic
bert with adaptive width and depth,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing
Systems (NIPS)</em>, 2020, pp. 9782–9793.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
B. Qin, H. Hu, and Y. Zhuang, “Deep residual weight-sharing attention network
with low-rank attention for visual question answering,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Multimedia</em>, vol. 24, pp. 1–1, 2022.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
B. Zhou, Y. Tian, S. Sukhbaatar, A. Szlam, and R. Fergus, “Simple baseline for
visual question answering,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations (ICLR)</em>, 2015.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. Lawrence Zitnick, and
D. Parikh, “Vqa: Visual question answering,” in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE International
Conference on Computer Vision (ICCV)</em>, 2015, pp. 2425–2433.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
A. Fukui, D. H. Park, D. Yang, A. Rohrbach, T. Darrell, and M. Rohrbach,
“Multimodal compact bilinear pooling for visual question answering and
visual grounding,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>, pp. 457–468, 2016.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
J.-H. Kim, K. W. On, W. Lim, J. Kim, J.-W. Ha, and B.-T. Zhang, “Hadamard
product for low-rank bilinear pooling,” in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">International Conference on
Learning Representation (ICLR)</em>, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Z. Yu, J. Yu, J. Fan, and D. Tao, “Multi-modal factorized bilinear pooling
with co-attention learning for visual question answering,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">IEEE
International Conference on Computer Vision (ICCV)</em>, pp. 1839–1848, 2017.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Z. Yang, X. He, J. Gao, L. Deng, and A. Smola, “Stacked attention networks for
image question answering,” in <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, 2016, pp. 21–29.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
J. Yu, W. Zhang, Y. Lu, Z. Qin, Y. Hu, J. Tan, and Q. Wu, “Reasoning on the
relation: Enhancing visual representation for visual question answering and
cross-modal retrieval,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, vol. 22,
no. 12, pp. 3196–3209, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
J. Lu, J. Yang, D. Batra, and D. Parikh, “Hierarchical question-image
co-attention for visual question answering,” in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Neural Information
Processing Systems (NIPS)</em>, 2016, pp. 289–297.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
D.-K. Nguyen and T. Okatani, “Improved fusion of visual and language
representations by dense symmetric co-attention for visual question
answering,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</em>, pp. 6087–6096, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
F. Liu, J. Liu, Z. Fang, R. Hong, and H. Lu, “Visual question answering with
dense inter-and intra-modality interactions,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Multimedia</em>, vol. 23, pp. 3518–3529, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep
bidirectional transformers for language understanding,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2019 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long and
Short Papers)</em>, 2019, pp. 4171–4186.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and S. Zagoruyko,
“End-to-end object detection with transformers,” in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">European
conference on computer vision (ECCV)</em>.   Springer, 2020, pp. 213–229.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit,
and N. Houlsby, “An image is worth 16x16 words: Transformers for image
recognition at scale,” 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
J. Yu, J. Li, Z. Yu, and Q. Huang, “Multimodal transformer with multi-view
visual representation for image captioning,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on
circuits and systems for video technology</em>, vol. 30, no. 12, pp. 4467–4480,
2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
J. Lei, L. Li, L. Zhou, Z. Gan, T. L. Berg, M. Bansal, and J. Liu, “Less is
more: Clipbert for video-and-language learning via sparse sampling,” in
<em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2021, pp. 7331–7341.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
L. Li, Y.-C. Chen, Y. Cheng, Z. Gan, L. Yu, and J. Liu, “Hero: Hierarchical
encoder for video+ language omni-representation pre-training,” in
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language Processing
(EMNLP)</em>, 2020, pp. 2046–2065.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
L. Zhu and Y. Yang, “Actbert: Learning global-local video-text
representations,” in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2020, pp. 8746–8755.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
P. Gao, Z. Jiang, H. You, P. Lu, S. C. Hoi, X. Wang, and H. Li, “Dynamic
fusion with intra-and inter-modality attention flow for visual question
answering,” in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2019, pp. 6639–6648.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Z. Yu, J. Wei, Yu, J. Zhu, and Z. Kuang, “Knowledge-representation-enhanced
multimodal transformer for scene text visual questionanswering,”
<em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Journal of Image and Graphics</em>, vol. 27, no. 9, pp. 2761–2774, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
R. Hu, A. Singh, T. Darrell, and M. Rohrbach, “Iterative answer prediction
with pointer-augmented multimodal transformers for textvqa,” in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">IEEE
Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020, pp.
9992–10 002.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Y. Liu, Y.-S. Wei, H. Yan, G.-B. Li, and L. Lin, “Causal reasoning meets
visual representation learning: A prospective study,” <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Machine
Intelligence Research</em>, no. 19, pp. 1–27, 2022.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
L. Chen, X. Yan, J. Xiao, H. Zhang, S. Pu, and Y. Zhuang, “Counterfactual
samples synthesizing for robust visual question answering,” in <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">IEEE
Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020, pp.
10 800–10 809.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Z. Yang, Z. Gan, J. Wang, X. Hu, Y. Lu, Z. Liu, and L. Wang, “An empirical
study of gpt-3 for few-shot knowledge-based vqa,” in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the AAAI Conference on Artificial Intelligence</em>, vol. 36, no. 3, 2022, pp.
3081–3089.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Z. Shao, Z. Yu, M. Wang, and J. Yu, “Prompting large language models with
answer heuristis for knowledge-based visual question answering,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1607.06450</em>, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
X. Li, X. Yin, C. Li, P. Zhang, X. Hu, L. Zhang, L. Wang, H. Hu, L. Dong,
F. Wei <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Oscar: Object-semantics aligned pre-training for
vision-language tasks,” in <em id="bib.bib55.2.2" class="ltx_emph ltx_font_italic">European Conference on Computer Vision
(ECCV)</em>, 2020, pp. 121–137.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
F. Yu, J. Tang, W. Yin, Y. Sun, H. Tian, H. Wu, and H. Wang, “Ernie-vil:
Knowledge enhanced vision-language representations through scene graphs,” in
<em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
vol. 35, no. 4, 2021, pp. 3208–3216.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Y. Cui, Z. Yu, C. Wang, Z. Zhao, J. Zhang, M. Wang, and J. Yu, “Rosita:
Enhancing vision-and-language semantic alignments via cross-and intra-modal
knowledge integration,” in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th ACM International
Conference on Multimedia</em>, 2021, pp. 797–806.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry,
A. Askell, P. Mishkin, J. Clark <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Learning transferable visual
models from natural language supervision,” in <em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic">International Conference
on Machine Learning (ICML)</em>.   PMLR,
2021, pp. 8748–8763.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
P. Wang, A. Yang, R. Men, J. Lin, S. Bai, Z. Li, J. Ma, C. Zhou, J. Zhou, and
H. Yang, “OFA: unifying architectures, tasks, and modalities through a
simple sequence-to-sequence learning framework,” in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning (ICML)</em>, 2022, pp. 23 318–23 340.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
J. Li, D. Li, C. Xiong, and S. Hoi, “Blip: Bootstrapping language-image
pre-training for unified vision-language understanding and generation,” in
<em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em>, 2022, pp.
12 888–12 900.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Z.-Y. Dou, Y. Xu, Z. Gan, J. Wang, S. Wang, L. Wang, C. Zhu, P. Zhang, L. Yuan,
N. Peng <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “An empirical study of training end-to-end
vision-and-language transformers,” in <em id="bib.bib61.2.2" class="ltx_emph ltx_font_italic">IEEE Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, 2022, pp. 18 166–18 176.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
S. Han, H. Mao, and W. J. Dally, “Deep compression: Compressing deep neural
networks with pruning, trained quantization and huffman coding,” in
<em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2016.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
S. Han, J. Pool, J. Tran, and W. Dally, “Learning both weights and connections
for efficient neural network,” in <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing
Systems (NIPS)</em>, 2015, pp. 1135–1143.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang, “Learning efficient
convolutional networks through network slimming,” in <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">IEEE
International Conference on Computer Vision (ICCV)</em>, 2017, pp. 2736–2744.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer,
“Squeezenet: Alexnet-level accuracy with 50x fewer parameters and¡ 0.5 mb
model size,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1602.07360</em>, 2016.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand,
M. Andreetto, and H. Adam, “Mobilenets: Efficient convolutional neural
networks for mobile vision applications,” <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1704.04861</em>, 2017.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
X. Zhang, X. Zhou, M. Lin, and J. Sun, “Shufflenet: An extremely efficient
convolutional neural network for mobile devices,” in <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">IEEE conference
on computer vision and pattern recognition (CVPR)</em>, 2018, pp. 6848–6856.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Z. Wu, T. Nagarajan, A. Kumar, S. Rennie, L. S. Davis, K. Grauman, and
R. Feris, “Blockdrop: Dynamic inference paths in residual networks,” in
<em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2018, pp. 8817–8826.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
G. Huang, Y. Sun, Z. Liu, D. Sedra, and K. Q. Weinberger, “Deep networks with
stochastic depth,” in <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV)</em>,
2016, pp. 646–661.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, pp. 770–778, 2016.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
J. Yu and T. S. Huang, “Universally slimmable networks and improved training
techniques,” in <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Computer Vision
(ICCV)</em>, 2019, pp. 1803–1811.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
H. Cai, C. Gan, T. Wang, Z. Zhang, and S. Han, “Once-for-all: Train one
network and specialize it for efficient deployment,” in <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">International
Conference on Learning Representations (ICLR)</em>, 2019.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,” <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1607.06450</em>, 2016.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
L. Zettlemoyer, and V. Stoyanov, “Roberta: A robustly optimized bert
pretraining approach,” <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving language
understanding by generative pre-training,” <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">URL https://s3-us-west-2.
amazonaws. com/openai-assets/research-covers/languageunsupervised/language
understanding paper. pdf</em>, 2018.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Language models are unsupervised multitask learners,” <em id="bib.bib76.2.2" class="ltx_emph ltx_font_italic">OpenAI blog</em>,
vol. 1, no. 8, p. 9, 2019.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
W. Li, and P. J. Liu, “Exploring the limits of transfer learning with a
unified text-to-text transformer,” <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning
Research (JMLR)</em>, vol. 21, no. 140, pp. 1–67, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
W. Wang and Z. Tu, “Rethinking the value of transformer components,” in
<em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">International Conference on Computational Linguistics (COLING)</em>, 2020,
pp. 6019–6029.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Y. Goyal, T. Khot, D. Summers-Stay, D. Batra, and D. Parikh, “Making the v in
vqa matter: Elevating the role of image understanding in visual question
answering,” in <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2017, pp. 6904–6913.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
H. Wang, Z. Wu, Z. Liu, H. Cai, L. Zhu, C. Gan, and S. Han, “Hat:
Hardware-aware transformers for efficient natural language processing,” in
<em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics (ACL)</em>,
2020, pp. 7675–7688.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
A. Khetan and Z. Karnin, “schubert: Optimizing elements of bert,” in
<em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics (ACL)</em>,
2020, pp. 2807–2818.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
network,” <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>, 2015.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
D. A. Hudson and C. D. Manning, “Gqa: A new dataset for real-world visual
reasoning and compositional question answering,” <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, pp. 6700–6709, 2019.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Dollár, and C. L. Zitnick, “Microsoft coco: Common objects in
context,” in <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV)</em>, 2014, pp.
740–755.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen,
Y. Kalantidis, L.-J. Li, D. A. Shamma <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Visual genome:
Connecting language and vision using crowdsourced dense image annotations,”
<em id="bib.bib85.2.2" class="ltx_emph ltx_font_italic">International Journal of Computer Vision (IJCV)</em>, vol. 123, no. 1, pp.
32–73, 2017.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2203.12813" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2203.12814" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2203.12814">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2203.12814" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2203.12815" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 06:44:24 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
