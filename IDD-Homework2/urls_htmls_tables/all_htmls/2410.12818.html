<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Super-Resolution GPS: Restoring High-Precision Mobility Data</title>
<!--Generated on Tue Oct  1 11:55:51 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Privacy-preserving,  Trajectory Reconstruction,  Deep Learning" lang="en" name="keywords"/>
<base href="/html/2410.12818v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S1" title="In Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S2" title="In Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">2</span> </span><span class="ltx_text" style="color:#000000;">Related Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S2.SS1" title="In 2. Related Work ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">2.1</span> </span><span class="ltx_text" style="color:#000000;">Privacy-preserving method on human mobility data</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S2.SS2" title="In 2. Related Work ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">2.2</span> </span><span class="ltx_text" style="color:#000000;">GPS trajectory reconstruction</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S3" title="In Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">3</span> </span><span class="ltx_text" style="color:#000000;">System details</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S3.SS1" title="In 3. System details ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">3.1</span> </span><span class="ltx_text" style="color:#000000;">Virtual Data Collection</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S3.SS2" title="In 3. System details ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">3.2</span> </span><span class="ltx_text" style="color:#000000;">Data Processing</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S3.SS3" title="In 3. System details ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">3.3</span> </span><span class="ltx_text" style="color:#000000;">Model Training</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4" title="In Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">4</span> </span><span class="ltx_text" style="color:#000000;">Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.SS1" title="In 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">4.1</span> </span><span class="ltx_text" style="color:#000000;">Experimental Settings</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.SS2" title="In 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">4.2</span> </span><span class="ltx_text" style="color:#000000;">Result</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S5" title="In Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="color:#000000;">5</span> </span><span class="ltx_text" style="color:#000000;">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Super-Resolution GPS: Restoring High-Precision Mobility Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haruki Yonekura
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id1.1.id1">Japan</span><span class="ltx_text ltx_affiliation_institution" id="id2.2.id2">Osaka University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:h-yonekura@ist.osaka-u.ac.jp">h-yonekura@ist.osaka-u.ac.jp</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ren Ozeki
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id3.1.id1">Japan</span><span class="ltx_text ltx_affiliation_institution" id="id4.2.id2">Osaka University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:r-ozeki@ist.osaka-u.ac.jp">r-ozeki@ist.osaka-u.ac.jp</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamada Rizk
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id5.1.id1">Osaka University, Japan</span><span class="ltx_text ltx_affiliation_institution" id="id6.2.id2">Tanta University, Egypt</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:hamada_rizk@ist.osaka-u.ac.jp">hamada_rizk@ist.osaka-u.ac.jp</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hirozumi Yamaguchi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id7.1.id1">Japan</span><span class="ltx_text ltx_affiliation_institution" id="id8.2.id2">Osaka University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:h-yamagu@ist.osaka-u.ac.jp">h-yamagu@ist.osaka-u.ac.jp</a>
</span></span></span>
</div>
<h1 class="ltx_title ltx_title_document">Restoring Super-High Resolution GPS Mobility Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haruki Yonekura
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id1.1.id1">Japan</span><span class="ltx_text ltx_affiliation_institution" id="id2.2.id2">Osaka University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:h-yonekura@ist.osaka-u.ac.jp">h-yonekura@ist.osaka-u.ac.jp</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ren Ozeki
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id3.1.id1">Japan</span><span class="ltx_text ltx_affiliation_institution" id="id4.2.id2">Osaka University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:r-ozeki@ist.osaka-u.ac.jp">r-ozeki@ist.osaka-u.ac.jp</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamada Rizk
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id5.1.id1">Osaka University, Japan</span><span class="ltx_text ltx_affiliation_institution" id="id6.2.id2">Tanta University, Egypt</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:hamada_rizk@ist.osaka-u.ac.jp">hamada_rizk@ist.osaka-u.ac.jp</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hirozumi Yamaguchi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_country" id="id7.1.id1">Japan</span><span class="ltx_text ltx_affiliation_institution" id="id8.2.id2">Osaka University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:h-yamagu@ist.osaka-u.ac.jp">h-yamagu@ist.osaka-u.ac.jp</a>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id9.id1">This paper presents a novel system for reconstructing high-resolution GPS trajectory data from truncated or synthetic low-resolution inputs, addressing the critical challenge of balancing data utility with privacy preservation in mobility applications. The system integrates transformer-based encoder-decoder models with graph convolutional networks (GCNs) to effectively capture both the temporal dependencies of trajectory data and the spatial relationships in road networks. By combining these techniques, the system is able to recover fine-grained trajectory details that are lost through data truncation or rounding, a common practice to protect user privacy.
We evaluate the system on the Beijing trajectory dataset, demonstrating its superior performance over traditional map-matching algorithms and LSTM-based synthetic data generation methods. The proposed model achieves an average Fréchet distance of 0.198 km, significantly outperforming map-matching algorithms (0.632 km) and synthetic trajectory models (0.498 km).
The results show that the system is not only capable of accurately reconstructing real-world trajectories but also generalizes effectively to synthetic data.
These findings suggest that the system can be deployed in urban mobility applications, providing both high accuracy and robust privacy protection.
</p>
</div>
<div class="ltx_keywords">Privacy-preserving, Trajectory Reconstruction, Deep Learning
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Networks Location based services</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Security and privacy Privacy Protection</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Human mobility trajectory data is rapidly becoming a cornerstone in various sectors, powering applications that are integral to the efficient operation of smart cities. From optimizing transportation systems and traffic management to supporting urban planning and ensuring effective crisis management during emergencies, mobility data underpins the design and deployment of data-driven services. As cities grow increasingly complex, the accurate tracking and analysis of movement patterns of large populations can significantly improve urban decision-making, resource allocation, and safety. However, the widespread availability and utilization of such data also present substantial challenges related to data quality, privacy, storage, and network efficiency.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">At the core of these challenges is the vast amount of trajectory data generated by GPS-enabled devices, such as smartphones, vehicles, and IoT sensors. This data is frequently used to model and predict human movement patterns for applications such as ride-sharing services, public transit optimization, and crowd control in emergencies. Yet, despite its usefulness, raw GPS data often requires rounding or compression to meet practical constraints. These include preserving user privacy, reducing storage and transmission costs, and mitigating issues related to GPS signal noise and sensitivity, especially in urban areas with dense infrastructure. Such transformations, while necessary, result in a reduction in the spatial and temporal resolution of the data, limiting its effectiveness for fine-grained analysis.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The trade-off between compression and the retention of critical trajectory information is a long-standing problem. Traditional lossy compression methods have been developed to reduce the size of GPS data, but they tend to obscure key features such as rapid changes in direction, sharp turns, or short-distance deviations. These dynamics are essential for understanding specific mobility behaviors, such as vehicle movements in congested areas or pedestrian paths in crowded environments. Furthermore, the compression process often removes intricate details that could be vital for applications like precise traffic flow analysis, emergency evacuation planning, or identifying anomalous behavior patterns in real-time <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="color:#000000;">Makris et al</span><span class="ltx_text" style="color:#000000;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib10" title=""><span class="ltx_text" style="color:#000000;">2021</span></a>; <span class="ltx_text" style="color:#000000;">Muckell et al</span><span class="ltx_text" style="color:#000000;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib11" title=""><span class="ltx_text" style="color:#000000;">2014</span></a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Despite these advancements in data compression, research on methods to recover or enhance low-resolution GPS data that have been compressed or rounded for storage or privacy reasons remains limited.
In our preliminary work <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="color:#000000;">Goto et al</span><span class="ltx_text" style="color:#000000;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib4" title=""><span class="ltx_text" style="color:#000000;">2023</span></a>; <span class="ltx_text" style="color:#000000;">Ozeki et al</span><span class="ltx_text" style="color:#000000;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib14" title=""><span class="ltx_text" style="color:#000000;">2023a</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib18" title=""><span class="ltx_text" style="color:#000000;">2024</span></a>)</cite>, we explored methods to accurately predict taxi demand using distributed GPS data, representing an approach toward privacy-preserving data analysis by reducing the need for centralized data collection.
The ability to reconstruct high-resolution GPS data from low-resolution counterparts holds immense potential for enhancing the usability of mobility services in smart cities. For instance, reconstructing fine-grained movement patterns from aggregated data could significantly improve applications that rely on high precision, such as dynamic navigation systems, autonomous vehicle guidance, or smart grid energy optimization. More importantly, this capability could serve as a privacy-preserving mechanism, allowing detailed analyses to be performed without exposing individuals’ exact locations.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This reconstruction problem shares similarities with challenges in computer vision, where high-resolution images are often reconstructed from low-resolution inputs through sophisticated models such as super-resolution techniques <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="color:#000000;">Yu et al</span><span class="ltx_text" style="color:#000000;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib27" title=""><span class="ltx_text" style="color:#000000;">2024</span></a>)</cite>. In the context of mobility trajectory data, the goal is not just to recover spatial resolution but also to preserve the complex temporal dependencies and contextual information, such as the underlying road network or movement patterns of the surrounding environment. Current solutions fall short in this regard, as they primarily focus on minimizing data size rather than intelligently restoring it for specific downstream tasks.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Motivated by these limitations, in this paper, we propose a novel system that reconstructs truncated or low-resolution GPS trajectory data to recover its utility and precision. Our approach integrates two powerful components: a transformer-based encoder-decoder model to handle the spatio-temporal characteristics of the GPS trajectory data and a graph neural network (GNN) to incorporate flexible road network information.
Transformers, known for their ability to capture long-range dependencies in time-series data, are particularly well-suited for handling the spatio-temporal nature of GPS trajectories. In our system, the transformer-based model serves as the foundation for learning and encoding the temporal dynamics and spatial correlations inherent in the trajectory data. By modeling the relationship between successive GPS points over time, this approach captures both short-term fluctuations and long-term trends in mobility patterns, enabling accurate trajectory reconstruction.
In addition to the transformer, we employ a graph neural network (GNN) that processes the underlying road network information. Urban road networks are inherently structured as graphs, where nodes represent intersections and edges represent roads. By leveraging GNNs, we can embed this graph structure into the trajectory reconstruction process, ensuring that the reconstructed GPS points align with realistic road constraints and follow plausible mobility routes. This fusion of road network information with GPS data allows our system to generate high-resolution trajectories that are not only spatially accurate but also contextually aware of the road environment.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">By integrating these components, our system effectively reconstructs high-resolution trajectories from compressed or rounded GPS data, mitigating the loss of crucial information during the compression process. This approach addresses the key limitations of existing methods, enabling more robust and reliable trajectory-based services in the context of smart city applications. Ultimately, this research contributes to the growing demand for data-efficient and privacy-preserving solutions, while ensuring the recovery of high-precision mobility data that is essential for next-generation urban systems.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Privacy-preserving method on human mobility data</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text" id="S2.SS1.p1.1.1" style="color:#000000;">Spatio-temporal data plays a crucial role in training data-driven models for various applications, including taxi demand prediction. However, gathering such data is expensive and can expose sensitive information, thereby posing risks to user privacy. Consequently, numerous studies have been devoted to developing techniques that safeguard the privacy of data and machine learning models.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text" id="S2.SS1.p2.1.1" style="color:#000000;">Several studies </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p2.1.2.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">You et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p2.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib26" title=""><span class="ltx_text" style="color:#000000;">2007</span></a>; <span class="ltx_text" style="color:#000000;">Suzuki et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p2.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib22" title=""><span class="ltx_text" style="color:#000000;">2010</span></a><span class="ltx_text" id="S2.SS1.p2.1.4.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p2.1.5" style="color:#000000;"> have concentrated on protecting user privacy by introducing dummy data into mobility datasets.
The approach proposed in </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p2.1.6.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">You et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p2.1.7.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib26" title=""><span class="ltx_text" style="color:#000000;">2007</span></a><span class="ltx_text" id="S2.SS1.p2.1.8.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p2.1.9" style="color:#000000;"> introduces false location points into the trajectory in either a random or rotational fashion.
To create more realistic trajectories, the authors of </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p2.1.10.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Suzuki et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p2.1.11.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib22" title=""><span class="ltx_text" style="color:#000000;">2010</span></a><span class="ltx_text" id="S2.SS1.p2.1.12.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p2.1.13" style="color:#000000;"> proposed generating dummy locations by constraining the user’s movement.
This technique enhances anonymity within a specified spatial area while maintaining the plausibility of the trajectory.
However, it has limitations, such as when an attacker possesses prior knowledge of the user’s lifestyle, they could potentially infer the user’s interests or actual location </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p2.1.14.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Hemkumar et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p2.1.15.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib5" title=""><span class="ltx_text" style="color:#000000;">2020</span></a><span class="ltx_text" id="S2.SS1.p2.1.16.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p2.1.17" style="color:#000000;">.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.2"><span class="ltx_text" id="S2.SS1.p3.2.1" style="color:#000000;">In addition to these approaches, synthesis-based methods for privacy protection have been introduced, which involve replacing the original mobility data with synthetic data </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p3.2.2.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Rao et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib20" title=""><span class="ltx_text" style="color:#000000;">2020</span></a>; <span class="ltx_text" style="color:#000000;">Abul et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib2" title=""><span class="ltx_text" style="color:#000000;">2008</span></a>; <span class="ltx_text" style="color:#000000;">Zhu et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib30" title=""><span class="ltx_text" style="color:#000000;">2023</span></a><span class="ltx_text" id="S2.SS1.p3.2.4.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p3.2.5" style="color:#000000;">.
One of the key concepts in this context is k-anonymity, which guarantees privacy by ensuring that there are at least </span><math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" mathcolor="#000000" xref="S2.SS1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="S2.SS1.p3.2.6" style="color:#000000;"> users with similar characteristics, thus preventing an attacker from narrowing down the potential users to fewer than </span><math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p3.2.m2.1"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" mathcolor="#000000" xref="S2.SS1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.2.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="S2.SS1.p3.2.7" style="color:#000000;">, even when attempting to identify a user based on specific traits.
To achieve k-anonymity in mobility data, the method proposed in </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p3.2.8.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Abul et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.9.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib2" title=""><span class="ltx_text" style="color:#000000;">2008</span></a><span class="ltx_text" id="S2.SS1.p3.2.10.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p3.2.11" style="color:#000000;"> incorporates uncertainty into the location data.
To address privacy concerns more effectively, differential privacy has emerged as a leading technique for anonymization and privacy preservation </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p3.2.12.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Jiang et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.13.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib7" title=""><span class="ltx_text" style="color:#000000;">2013</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib6" title=""><span class="ltx_text" style="color:#000000;">2021</span></a><span class="ltx_text" id="S2.SS1.p3.2.14.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p3.2.15" style="color:#000000;">. This is a mathematical framework that adds noise to the data, ensuring a certain degree of privacy protection. Several techniques, such as CNoise and SDD </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p3.2.16.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Jiang et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.17.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib7" title=""><span class="ltx_text" style="color:#000000;">2013</span></a><span class="ltx_text" id="S2.SS1.p3.2.18.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p3.2.19" style="color:#000000;">, have been introduced to apply differential privacy to mobility trajectory data by adding noise to guarantee privacy. The added noise and the corresponding level of privacy have been mathematically validated, making this approach more robust than others.
For creating realistic synthetic mobility data, DiffTraj </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p3.2.20.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Zhu et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.21.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib30" title=""><span class="ltx_text" style="color:#000000;">2023</span></a><span class="ltx_text" id="S2.SS1.p3.2.22.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p3.2.23" style="color:#000000;"> generates a synthetic location dataset using a diffusion model.
LSTM-trajGAN and recent pioneering work</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p3.2.24.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Ozeki et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.25.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib15" title=""><span class="ltx_text" style="color:#000000;">2022</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib16" title=""><span class="ltx_text" style="color:#000000;">2023b</span></a>; <span class="ltx_text" style="color:#000000;">Yonekura et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS1.p3.2.25.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib25" title=""><span class="ltx_text" style="color:#000000;">2023</span></a><span class="ltx_text" id="S2.SS1.p3.2.26.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS1.p3.2.27" style="color:#000000;">, on the other hand, generates synthetic mobility data using LSTM and replaces the original dataset with this synthetic version.
Since LSTM-trajGAN employs a GAN-based approach to train the LSTM generator, the resulting synthetic trajectories are expected to be highly realistic.
Nevertheless, these methods do not fully guarantee the privacy and utility of the generated data.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>GPS trajectory reconstruction</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text" id="S2.SS2.p1.1.1" style="color:#000000;">Research in addressing low-sampled or incomplete trajectories has been ongoing for over a decade.
The significant demand for high-resolution trajectories has driven efforts to insert additional points between consecutive trajectory points.
Various terms, including trajectory interpolation, completion, recovery, and reconstruction commonly refer to this process.</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text" id="S2.SS2.p2.1.1" style="color:#000000;">One common approach to trajectory reconstruction is map matching, as demonstrated in studies like </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.2.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Newson and Krumm</span><span class="ltx_text" id="S2.SS2.p2.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib13" title=""><span class="ltx_text" style="color:#000000;">2009</span></a>; <span class="ltx_text" style="color:#000000;">Yuan et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib28" title=""><span class="ltx_text" style="color:#000000;">2010</span></a>; <span class="ltx_text" style="color:#000000;">Lou et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib9" title=""><span class="ltx_text" style="color:#000000;">2009</span></a><span class="ltx_text" id="S2.SS2.p2.1.4.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.5" style="color:#000000;">.
These methods often employ models like the hidden Markov model or rely on a voting process among sampled points.
Other approaches </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.6.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Wang et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.7.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib23" title=""><span class="ltx_text" style="color:#000000;">2021</span></a>; <span class="ltx_text" style="color:#000000;">Li et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.7.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib8" title=""><span class="ltx_text" style="color:#000000;">2016</span></a><span class="ltx_text" id="S2.SS2.p2.1.8.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.9" style="color:#000000;"> leverage historical trajectory data and road network information to recover missing trajectories.
The authors of </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.10.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Li et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.11.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib8" title=""><span class="ltx_text" style="color:#000000;">2016</span></a><span class="ltx_text" id="S2.SS2.p2.1.12.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.13" style="color:#000000;"> focus on junctions in urban regions, extracting a basic trajectory skeleton from sparse data and using a clustering framework to reconstruct incomplete GPS trajectories.
The authors of </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.14.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Wang et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.15.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib23" title=""><span class="ltx_text" style="color:#000000;">2021</span></a><span class="ltx_text" id="S2.SS2.p2.1.16.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.17" style="color:#000000;"> use LSTM-based autoencoder architecture for recovery from sub-trajectory to the whole trajectory and use Kalman Filter to decrease the noise and calibrate trajectory estimation.
KAMEL</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.18.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Musleh and Mokbel</span><span class="ltx_text" id="S2.SS2.p2.1.19.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib12" title=""><span class="ltx_text" style="color:#000000;">2023</span></a><span class="ltx_text" id="S2.SS2.p2.1.20.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.21" style="color:#000000;"> adapts the BERT concept to realize trajectory imputation without using map geometry.
They partition the area and regard a cell as a word so that the data can be processed through a BERT-like architecture.
By introducing the spatial constraints, they make it possible to impute trajectories.
Additionally, there are studies that do not rely on map information for trajectory reconstruction or imputation, such as </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.22.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Chen et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.23.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib3" title=""><span class="ltx_text" style="color:#000000;">2016</span></a>; <span class="ltx_text" style="color:#000000;">Ruan et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.23.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib21" title=""><span class="ltx_text" style="color:#000000;">2020</span></a>; <span class="ltx_text" style="color:#000000;">Qin et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.23.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib19" title=""><span class="ltx_text" style="color:#000000;">2023</span></a><span class="ltx_text" id="S2.SS2.p2.1.24.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.25" style="color:#000000;">.
Among them, INGRAIN</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p2.1.26.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Qin et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S2.SS2.p2.1.27.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib19" title=""><span class="ltx_text" style="color:#000000;">2023</span></a><span class="ltx_text" id="S2.SS2.p2.1.28.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S2.SS2.p2.1.29" style="color:#000000;"> employs the attention mechanism of transformer architectures to impute missing data.</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text" id="S2.SS2.p3.1.1" style="color:#000000;">In comparison to these existing approaches, our proposed system integrates transformers for understanding GPS time-series data and graph neural networks for spatial data interpretation, offering a more comprehensive solution to trajectory reconstruction.</span></p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="124" id="S2.F1.g1" src="extracted/5892577/imgs/attack_model_without_attacker.png" width="538"/>
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.4.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S2.F1.5.2" style="font-size:90%;">System overview.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">3. </span>System details</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1"><span class="ltx_text" id="S3.p1.1.1" style="color:#000000;">The system is designed to reconstruct high-resolution GPS trajectory data from low-resolution, privacy-preserved inputs. As shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S2.F1" style="color:#000000;" title="Figure 1 ‣ 2.2. GPS trajectory reconstruction ‣ 2. Related Work ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.p1.1.2" style="color:#000000;">, it consists of three main modules: virtual data collection, data processing, and model training. These components work in tandem, utilizing advanced deep learning methods such as Graph Convolutional Networks (GCNs) and Transformer models to accurately reconstruct trajectory data while taking into account both the spatial and temporal dimensions.</span></p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Virtual Data Collection</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text" id="S3.SS1.p1.1.1" style="color:#000000;">The first step in our system involves the generation of virtual data that captures general mobility patterns within a specified geographical region. This is done by randomly selecting points within the target region and using publicly available tools, such as routing algorithms, to calculate the shortest paths between these points. The output of this process is a set of trajectories, and each is represented as a sequence of latitude and longitude pairs. These trajectories are critical for simulating real-world mobility patterns that can be used to train the super-resolution model.</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text" id="S3.SS1.p2.1.1" style="color:#000000;">In parallel, we extract the graph structure of the road network associated with the generated trajectories. The road network is modeled as a graph, where nodes represent intersections and edges represent the haversine distance between adjacent intersections. Each node in the graph is annotated with the latitude and longitude of the corresponding intersection, and the edges are weighted based on the geospatial distance between intersections. This graph structure provides crucial contextual information about the layout of the area, enabling the model to incorporate local road network constraints during trajectory reconstruction. By allowing users to generate data for any region with adjustable parameters, the system remains flexible and adaptable to different geographical contexts, enabling scalability across various application domains.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Data Processing</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1"><span class="ltx_text" id="S3.SS2.p1.1.1" style="color:#000000;">Once the virtual data is generated, it undergoes several preprocessing steps to ensure compatibility with the model and simulate real-world scenarios where GPS data is often altered to preserve privacy or reduce storage overhead. This step involves artificially modifying the virtual trajectories by applying techniques such as rounding the latitude and longitude values, adding noise, or implementing spatial cloaking methods. These modifications mimic common practices used in privacy-preserving GPS data applications, where high-resolution data is intentionally degraded to protect user identity or to optimize storage and transmission efficiency.
</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text" id="S3.SS2.p2.1.1" style="color:#000000;">The modified (or low-resolution) trajectories are then used as inputs to the model, while the corresponding original (or high-resolution) trajectories serve as the ground truth for training. The goal of the model is to learn how to accurately reconstruct the original high-resolution trajectory from the degraded version. To facilitate learning, we normalize all latitude and longitude values using z-score normalization. This ensures that the data fed into the model is standardized across regions, preventing the model from being biased toward specific geographic scales. Additionally, the distances between intersections (represented as edges in the road network graph) are transformed by taking their inverse, which enhances the propagation of information in the GCN by prioritizing shorter, more relevant distances between nodes. This step helps the model focus on nearby intersections, where small variations in trajectory data can have significant implications for the reconstruction process.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Model Training</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text" id="S3.SS3.p1.1.1" style="color:#000000;">The core of the system lies in its two deep learning components: the Graph Convolutional Network and the Transformer-based encoder-decoder architecture. These components work together to process both the road network information and the spatio-temporal trajectory data, ultimately generating a high-resolution output.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1" style="color:#000000;">GCN for road network embedding:</span><span class="ltx_text" id="S3.SS3.p2.1.2" style="color:#000000;"> 
Road networks are highly variable in their structure, with differences in the number of intersections, the density of roads, and the layout of cities or regions. Traditional machine learning models struggle to handle this complexity due to their reliance on fixed-length inputs. To address this, we treat the road network as a graph, where nodes correspond to road intersections, and edges represent the connections between them. The GCN allows us to learn a rich embedding of this graph, capturing the structural relationships between nodes while considering the geospatial proximity of the roads.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text" id="S3.SS3.p3.1.1" style="color:#000000;">For each node (intersection), the latitude and longitude serve as features, while the inverse haversine distance between connected nodes serves as edge weights. By using platforms such as OpenStreetMap, we can obtain detailed road network data for any region, allowing the model to adapt to different geographic areas. During the training process, the GCN computes a node embedding for each intersection, which encodes the local road network information relevant to the trajectory reconstruction task. To optimize memory efficiency and computation time, we limit the graph to the area surrounding the trajectory, instead of using the entire region covered by the dataset. This localized approach improves the message-passing mechanism within the GCN, ensuring that the model focuses on the most relevant parts of the road network.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1" style="color:#000000;">Transformer Encoder for Trajectory Embedding:</span><span class="ltx_text" id="S3.SS3.p4.1.2" style="color:#000000;"></span></p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1"><span class="ltx_text" id="S3.SS3.p5.1.1" style="color:#000000;">The transformer encoder is responsible for modeling the sequential and temporal aspects of the GPS trajectory data. GPS trajectories are inherently time-series data, where each point is defined not only by its spatial coordinates but also by its temporal order. To capture these dependencies, we use a multivariate transformer model that processes the standardized latitude, longitude, and timestamp values for each point in the trajectory.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.1"><span class="ltx_text" id="S3.SS3.p6.1.1" style="color:#000000;">Since trajectories vary in length, the model dynamically adjusts by padding shorter sequences and masking irrelevant inputs to ensure consistency during training. This allows the transformer to focus on meaningful sections of the trajectory, avoiding bias from extraneous padding. The transformer encoder learns a representation of the trajectory that captures both local variations (such as short-term changes in direction) and global patterns (such as long-term trends in movement), enabling the model to reconstruct fine-grained details in the GPS data.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.1" style="color:#000000;">Transformer Decoder for Super-Resolution:</span><span class="ltx_text" id="S3.SS3.p7.1.2" style="color:#000000;"></span></p>
</div>
<div class="ltx_para" id="S3.SS3.p8">
<p class="ltx_p" id="S3.SS3.p8.1"><span class="ltx_text" id="S3.SS3.p8.1.1" style="color:#000000;">The transformer decoder serves as the final component of the system, where the goal is to enhance the resolution of the input trajectory. The decoder combines the embeddings generated by the GCN (which captures road network information) and the transformer encoder (which captures spatio-temporal dynamics) to produce a high-resolution trajectory. This is achieved by mapping the low-resolution input to a finer-grained output that closely resembles the original trajectory.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p9">
<p class="ltx_p" id="S3.SS3.p9.1"><span class="ltx_text" id="S3.SS3.p9.1.1" style="color:#000000;">To transform the standardized outputs back into actual latitude and longitude values, we apply reverse normalization using the mean and variance of the original data. This ensures that the reconstructed trajectory corresponds to real-world GPS coordinates, preserving its spatial fidelity. We use Soft Dynamic Time Warping (SoftDTW) as the loss function, which is particularly effective for measuring the similarity between time-series data. SoftDTW accounts for potential temporal misalignments between the reconstructed trajectory and the ground truth, ensuring that the model accurately captures the underlying movement patterns even when there are small deviations in timing. The loss function is minimized through backpropagation, enabling the model to iteratively refine its predictions and improve the accuracy of the reconstructed trajectory.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p10">
<p class="ltx_p" id="S3.SS3.p10.1"><span class="ltx_text" id="S3.SS3.p10.1.1" style="color:#000000;">Through the combined use of GCNs and Transformers, our system is able to effectively reconstruct high-resolution GPS trajectory data from degraded inputs, addressing the challenges posed by privacy-preserving modifications and data compression. The integration of road network information ensures that the reconstructed trajectories align with real-world geography, while the transformer model captures the nuanced spatio-temporal dependencies that are essential for accurate mobility modeling.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">4. </span>Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text" id="S4.p1.1.1" style="color:#000000;">The evaluation of the proposed system was conducted to assess its ability to reconstruct high-resolution GPS trajectories from low-resolution. This section provides a detailed explanation of the experimental settings, evaluation metrics, and the results obtained. The experiments focus on the performance comparison between the proposed model and traditional methods for trajectory reconstruction, specifically map-matching algorithms.</span></p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experimental Settings</h3>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="482" id="S4.F2.g1" src="x1.png" width="789"/>
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.4.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S4.F2.5.2" style="font-size:90%;">Data publication scenarios.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="503" id="S4.F3.sf1.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.sf1.4.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F3.sf1.5.2" style="font-size:90%;">Distance from actual trajectory[km].</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="218" id="S4.F3.sf2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.sf2.4.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F3.sf2.5.2" style="font-size:90%;">Histogram of the error distance (H3 resolution is set as 7).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="218" id="S4.F3.sf3.g1" src="x4.png" width="831"/>
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.sf3.4.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S4.F3.sf3.5.2" style="font-size:90%;">One of the samples of super-resolution trajectory.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.4.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S4.F3.5.2" style="font-size:90%;">Comparison of reconstructed trajectories, error histograms, and visualizations.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text" id="S4.SS1.p1.1.1" style="color:#000000;">To evaluate the proposed system, we utilized the Beijing trajectory dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p1.1.2.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Zheng et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S4.SS1.p1.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib29" title=""><span class="ltx_text" style="color:#000000;">2011</span></a><span class="ltx_text" id="S4.SS1.p1.1.4.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S4.SS1.p1.1.5" style="color:#000000;">, a large-scale public dataset containing real-world human mobility data. From this dataset, we selected trajectories with sequence lengths not exceeding 128 points. We generated a total of 25,769 virtual GPS trajectories within the Beijing region to train our model. The synthetic data generation ensures that the model can learn region-specific mobility patterns while being tested on real-world trajectory data. This approach allows us to control the characteristics of the data used for training, such as sequence length and density, making it adaptable to different urban scenarios.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text" id="S4.SS1.p2.1.1" style="color:#000000;">For privacy preservation, we applied rounding to the GPS values in the dataset using the H3 indexing system </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p2.1.2.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Woźniak and Szymański</span><span class="ltx_text" id="S4.SS1.p2.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib24" title=""><span class="ltx_text" style="color:#000000;">2021</span></a><span class="ltx_text" id="S4.SS1.p2.1.4.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S4.SS1.p2.1.5" style="color:#000000;">. Each GPS point was snapped to the center of its corresponding H3 hexagonal cell, ensuring that the spatial resolution of the data was reduced. This truncation simulates real-world practices where GPS data is often obfuscated for privacy protection. </span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>H3 is a geospatial indexing system that divides the globe into hexagonal cells. Each cell is assigned a unique identifier, and by snapping GPS points to the nearest cell center, we reduce the granularity of the data, preserving privacy while introducing spatial errors.</span></span></span><span class="ltx_text" id="S4.SS1.p2.1.6" style="color:#000000;"></span></p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text" id="S4.SS1.p3.1.1" style="color:#000000;">The evaluation was conducted in two scenarios:</span></p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1" style="color:#000000;">Scenario 1:</span><span class="ltx_text" id="S4.I1.i1.p1.1.2" style="color:#000000;"> The GPS trajectory data is directly rounded and published without any additional processing.</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1" style="color:#000000;">Scenario 2:</span><span class="ltx_text" id="S4.I1.i2.p1.1.2" style="color:#000000;"> A synthetic trajectory dataset is generated using a model trained on real data, such as the LSTM-based TrajGAN model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.I1.i2.p1.1.3.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Ozeki et al</span><span class="ltx_text" style="color:#000000;">.</span><span class="ltx_text" id="S4.I1.i2.p1.1.4.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib17" title=""><span class="ltx_text" style="color:#000000;">2023c</span></a><span class="ltx_text" id="S4.I1.i2.p1.1.5.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S4.I1.i2.p1.1.6" style="color:#000000;">. The synthetic data is made publicly available, and the data users can employ the trained model to generate more synthetic trajectories for further analysis.</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text" id="S4.SS1.p4.1.1" style="color:#000000;">These two scenarios allow us to assess how the proposed system performs in both simple truncation cases and more complex generative cases. Scenario 2 introduces a more challenging task where synthetic data needs to be transformed into high-resolution outputs.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1"><span class="ltx_text" id="S4.SS1.p5.1.1" style="color:#000000;">For comparison, we employed a traditional map-matching algorithm </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p5.1.2.1" style="color:#000000;">(</span><span class="ltx_text" style="color:#000000;">Newson and Krumm</span><span class="ltx_text" id="S4.SS1.p5.1.3.2.1.1" style="color:#000000;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#bib.bib13" title=""><span class="ltx_text" style="color:#000000;">2009</span></a><span class="ltx_text" id="S4.SS1.p5.1.4.3" style="color:#000000;">)</span></cite><span class="ltx_text" id="S4.SS1.p5.1.5" style="color:#000000;">, which aligns low-resolution GPS points to the nearest roads in a map database, aiming to reconstruct the most likely trajectory.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Result</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1"><span class="ltx_text" id="S4.SS2.p1.1.1" style="color:#000000;">The evaluation of the proposed system’s performance was based on the Fréchet distance, a widely recognized metric for measuring the similarity between two curves by accounting for both spatial and temporal alignment. This metric is particularly well-suited for trajectory data because it captures not only the spatial deviations between paths but also their timing, making it an ideal tool for assessing the fidelity of reconstructed trajectories relative to the original ones. Lower Fréchet distances indicate a closer match between the reconstructed and original high-resolution trajectories.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text" id="S4.SS2.p2.1.1" style="color:#000000;">The visual results in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.F3.sf1" style="color:#000000;" title="In Figure 3 ‣ 4.1. Experimental Settings ‣ 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_tag">3(a)</span></a><span class="ltx_text" id="S4.SS2.p2.1.2" style="color:#000000;"> provide a clear comparison of the original, truncated, and reconstructed trajectories. The proposed system demonstrates exceptional performance in restoring detailed movement paths.
In Scenario 1, where GPS points were rounded to reduce spatial resolution, our model was able to reconstruct trajectories that follow the original path with high accuracy, effectively recovering fine-grained details lost during truncation.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text" id="S4.SS2.p3.1.1" style="color:#000000;">A more detailed comparison is shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.F3.sf2" style="color:#000000;" title="In Figure 3 ‣ 4.1. Experimental Settings ‣ 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_tag">3(b)</span></a><span class="ltx_text" id="S4.SS2.p3.1.2" style="color:#000000;">, where the truncated trajectory, map-matched trajectory, and reconstructed trajectory are visually examined. The proposed system clearly recovers finer details, even from heavily truncated or synthetic data, which map-matching fails to restore accurately. This demonstrates the system’s ability to infer complex movement patterns that traditional methods overlook, particularly in scenarios where GPS points have been heavily degraded or artificially generated.
Further analysis of the Fréchet distance is provided in the histogram in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.F3.sf2" style="color:#000000;" title="In Figure 3 ‣ 4.1. Experimental Settings ‣ 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_tag">3(b)</span></a><span class="ltx_text" id="S4.SS2.p3.1.3" style="color:#000000;">, which shows that 85.7% of the reconstructed trajectories fall within a very narrow error margin. This high success rate underscores the system’s ability to handle a wide range of truncation levels effectively, further validated across various H3 resolution levels. The model’s flexibility in maintaining performance at different spatial granularities highlights its adaptability, making it suitable for diverse real-world applications, from low-resolution data sources to heavily obfuscated trajectories.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text" id="S4.SS2.p4.1.1" style="color:#000000;">In Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.F3.sf3" style="color:#000000;" title="In Figure 3 ‣ 4.1. Experimental Settings ‣ 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_tag">3(c)</span></a><span class="ltx_text" id="S4.SS2.p4.1.2" style="color:#000000;">, the visual comparison between the truncated trajectory, map-matched trajectory, and the reconstructed trajectory clearly shows that the proposed model more accurately recovers the fine-grained details of the movement, even from heavily truncated or synthetic data.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1"><span class="ltx_text" id="S4.SS2.p5.1.1" style="color:#000000;">The performance metrics, summarized in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2410.12818v1#S4.T1" style="color:#000000;" title="Table 1 ‣ 4.2. Result ‣ 4. Evaluation ‣ Super-Resolution GPS: Restoring High-Precision Mobility Data"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S4.SS2.p5.1.2" style="color:#000000;">, provide further evidence of the model’s strength. Our proposed system achieves an average reconstruction error of 0.198 km, which is a significant improvement over the map-matching algorithm’s average error of 0.632 km.
This result demonstrates superior generalization capabilities. The substantial reduction in reconstruction error suggests that the model can handle both real and synthetic data effectively, improving upon the initial inaccuracies introduced during the generative process.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.1"><span class="ltx_text" id="S4.SS2.p6.1.1" style="color:#000000;">The proposed system’s significant improvement in Fréchet distance across both scenarios confirms the advantages of integrating Transformer and GCN models for GPS trajectory reconstruction. The Transformer captures long-range dependencies and temporal patterns, while the GCN effectively models spatial relationships in the road network. This combination allows the system to restore fine-grained mobility patterns with precision, making it particularly valuable for applications in urban environments, such as transportation planning, traffic flow optimization, and emergency response.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.1"><span class="ltx_text" id="S4.SS2.p7.1.1" style="color:#000000;">The results clearly demonstrate that, by leveraging the spatial and temporal dimensions of trajectory data, the proposed system offers a robust solution to the challenges of GPS trajectory reconstruction, particularly in cases where data truncation or obfuscation is necessary for privacy preservation. The ability to recover accurate, high-resolution trajectories from heavily truncated data positions the system as a powerful tool for a wide range of urban and mobility applications, ensuring both privacy protection and data utility.</span></p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.4.1.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S4.T1.5.2" style="font-size:90%;">LSTM autoencoder trajectories summary.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.6.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.6.1.1.1"><span class="ltx_text" id="S4.T1.6.1.1.1.1" style="color:#000000;">Trajectory</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.6.1.1.2"><span class="ltx_text" id="S4.T1.6.1.1.2.1" style="color:#000000;">Distance</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.6.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.6.2.1.1"><span class="ltx_text" id="S4.T1.6.2.1.1.1" style="color:#000000;">LSTM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.6.2.1.2"><span class="ltx_text" id="S4.T1.6.2.1.2.1" style="color:#000000;">0.498 km</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.6.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.6.3.2.1"><span class="ltx_text" id="S4.T1.6.3.2.1.1" style="color:#000000;">Map matching trajectory</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.6.3.2.2"><span class="ltx_text" id="S4.T1.6.3.2.2.1" style="color:#000000;">0.632 km</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.6.4.3">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.6.4.3.1"><span class="ltx_text" id="S4.T1.6.4.3.1.1" style="color:#000000;">Proposed system</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.6.4.3.2"><span class="ltx_text" id="S4.T1.6.4.3.2.1" style="color:#000000;">0.198 km</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text" id="S5.p1.1.1" style="color:#000000;">In this work, we proposed and developed a robust system for reconstructing high-resolution GPS trajectory data from low-resolution, privacy-preserved inputs. By integrating transformer-based models and GCNs, the system effectively captures the temporal dynamics of human movement while incorporating the spatial structure of road networks. This hybrid approach enables the model to restore fine-grained trajectory data that would otherwise be lost due to truncation, rounding, or the use of synthetic data generation techniques.
The evaluation of the system using the Beijing trajectory dataset confirmed its significant performance advantages over traditional map-matching algorithms and LSTM-based synthetic trajectory models. The proposed model consistently produced lower Fréchet distances, demonstrating its ability to handle both real and synthetic data with high accuracy. The results indicate that the system is particularly well-suited for urban applications that require precise mobility data, such as transportation planning, emergency response, and smart city services, while maintaining strong privacy protections.
Future work may explore the system’s adaptability to other geographical regions and the integration of additional privacy-preserving techniques to further enhance the balance between data utility and user privacy.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="color:#000000;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="color:#000000;">(1)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.3.1" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.6.6.1" style="color:#000000;">Abul et al</span><span class="ltx_text" id="bib.bib2.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib2.8.8.3" style="color:#000000;"> (2008)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.10.1" style="color:#000000;">
Osman Abul, Francesco Bonchi, and Mirco Nanni. 2008.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.11.1" style="color:#000000;">Never Walk Alone: Uncertainty for Anonymity in Moving Objects Databases. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib2.12.2" style="color:#000000;">2008 IEEE 24th International Conference on Data Engineering</em><span class="ltx_text" id="bib.bib2.13.3" style="color:#000000;">. 376–385.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.6.6.1" style="color:#000000;">Chen et al</span><span class="ltx_text" id="bib.bib3.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib3.8.8.3" style="color:#000000;"> (2016)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.10.1" style="color:#000000;">
Chen Chen, Cewu Lu, Qixing Huang, Qiang Yang, Dimitrios Gunopulos, and Leonidas Guibas. 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.11.1" style="color:#000000;">City-Scale Map Creation and Updating using GPS Collections. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.12.2" style="color:#000000;">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em><span class="ltx_text" id="bib.bib3.13.3" style="color:#000000;"> </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.14.4" style="color:#000000;">(KDD ’16)</em><span class="ltx_text" id="bib.bib3.15.5" style="color:#000000;">. Association for Computing Machinery, New York, NY, USA, 1465–1474.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.16.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2939672.2939833" style="color:#000000;" title="">https://doi.org/10.1145/2939672.2939833</a><span class="ltx_text" id="bib.bib3.17.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.6.6.1" style="color:#000000;">Goto et al</span><span class="ltx_text" id="bib.bib4.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib4.8.8.3" style="color:#000000;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.10.1" style="color:#000000;">
Yumeki Goto, Tomoya Matsumoto, Hamada Rizk, Naoto Yanai, and Hirozumi Yamaguchi. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.11.1" style="color:#000000;">Privacy-Preserving Taxi-Demand Prediction Using Federated Learning. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib4.12.2" style="color:#000000;">International Conference on Smart Computing</em><span class="ltx_text" id="bib.bib4.13.3" style="color:#000000;">. IEEE.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.6.6.1" style="color:#000000;">Hemkumar et al</span><span class="ltx_text" id="bib.bib5.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib5.8.8.3" style="color:#000000;"> (2020)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.10.1" style="color:#000000;">
D. Hemkumar, S. Ravichandra, and D.V.L.N. Somayajulu. 2020.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.11.1" style="color:#000000;">Impact of prior knowledge on privacy leakage in trajectory data publishing.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.12.1" style="color:#000000;">Engineering Science and Technology, an International Journal</em><span class="ltx_text" id="bib.bib5.13.2" style="color:#000000;"> 23, 6 (2020), 1291–1300.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.14.1" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.6.6.1" style="color:#000000;">Jiang et al</span><span class="ltx_text" id="bib.bib6.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib6.8.8.3" style="color:#000000;"> (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.10.1" style="color:#000000;">
Hongbo Jiang, Jie Li, Ping Zhao, Fanzi Zeng, Zhu Xiao, and Arun Iyengar. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.11.1" style="color:#000000;">Location Privacy-Preserving Mechanisms in Location-Based Services: A Comprehensive Survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.12.1" style="color:#000000;">ACM Comput. Surv.</em><span class="ltx_text" id="bib.bib6.13.2" style="color:#000000;"> 54, 1, Article 4 (jan 2021), 36 pages.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.14.1" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.6.6.1" style="color:#000000;">Jiang et al</span><span class="ltx_text" id="bib.bib7.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib7.8.8.3" style="color:#000000;"> (2013)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.10.1" style="color:#000000;">
Kaifeng Jiang, Dongxu Shao, Stéphane Bressan, Thomas Kister, and Kian-Lee Tan. 2013.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.11.1" style="color:#000000;">Publishing Trajectories with Differential Privacy Guarantees. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.12.2" style="color:#000000;">Proceedings of the 25th International Conference on Scientific and Statistical Database Management</em><span class="ltx_text" id="bib.bib7.13.3" style="color:#000000;"> </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.14.4" style="color:#000000;">(SSDBM)</em><span class="ltx_text" id="bib.bib7.15.5" style="color:#000000;">. Association for Computing Machinery, New York, NY, USA, Article 12, 12 pages.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.16.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2484838.2484846" style="color:#000000;" title="">https://doi.org/10.1145/2484838.2484846</a><span class="ltx_text" id="bib.bib7.17.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.6.6.1" style="color:#000000;">Li et al</span><span class="ltx_text" id="bib.bib8.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib8.8.8.3" style="color:#000000;"> (2016)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.10.1" style="color:#000000;">
Yang Li, Yangyan Li, Dimitrios Gunopulos, and Leonidas Guibas. 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.11.1" style="color:#000000;">Knowledge-based trajectory completion from sparse GPS samples. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib8.12.2" style="color:#000000;">Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems</em><span class="ltx_text" id="bib.bib8.13.3" style="color:#000000;">. 1–10.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.6.6.1" style="color:#000000;">Lou et al</span><span class="ltx_text" id="bib.bib9.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib9.8.8.3" style="color:#000000;"> (2009)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.10.1" style="color:#000000;">
Yin Lou, Chengyang Zhang, Yu Zheng, Xing Xie, Wei Wang, and Yan Huang. 2009.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.11.1" style="color:#000000;">Map-matching for low-sampling-rate GPS trajectories. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.12.2" style="color:#000000;">Proceedings of the 17th ACM SIGSPATIAL international conference on advances in geographic information systems</em><span class="ltx_text" id="bib.bib9.13.3" style="color:#000000;">. 352–361.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.6.6.1" style="color:#000000;">Makris et al</span><span class="ltx_text" id="bib.bib10.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib10.8.8.3" style="color:#000000;"> (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.10.1" style="color:#000000;">
Antonios Makris, Camila Leite da Silva, Vania Bogorny, Luis Otavio Alvares, Jose Antonio Macedo, and Konstantinos Tserpes. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.11.1" style="color:#000000;">Evaluating the effect of compressing algorithms for trajectory similarity and classification problems.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.12.1" style="color:#000000;">Geoinformatica</em><span class="ltx_text" id="bib.bib10.13.2" style="color:#000000;"> 25, 4 (oct 2021), 679–711.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.14.1" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.6.6.1" style="color:#000000;">Muckell et al</span><span class="ltx_text" id="bib.bib11.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib11.8.8.3" style="color:#000000;"> (2014)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.10.1" style="color:#000000;">
Jonathan Muckell, Paul W. Olsen, Jeong-Hyon Hwang, Catherine T. Lawson, and S. S. Ravi. 2014.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.11.1" style="color:#000000;">Compression of trajectory data: a comprehensive evaluation and new approach.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.12.1" style="color:#000000;">Geoinformatica</em><span class="ltx_text" id="bib.bib11.13.2" style="color:#000000;"> 18, 3 (jul 2014), 435–460.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.14.1" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.5.5.1" style="color:#000000;">Musleh and Mokbel (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="color:#000000;">
Mashaal Musleh and Mohamed F Mokbel. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.8.1" style="color:#000000;">Kamel: A Scalable BERT-based System for Trajectory Imputation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.9.1" style="color:#000000;">Proceedings of the VLDB Endowment</em><span class="ltx_text" id="bib.bib12.10.2" style="color:#000000;"> 17, 3 (2023), 525–538.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.5.5.1" style="color:#000000;">Newson and Krumm (2009)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.7.1" style="color:#000000;">
Paul Newson and John Krumm. 2009.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.8.1" style="color:#000000;">Hidden Markov map matching through noise and sparseness. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.9.2" style="color:#000000;">Proceedings of the 17th ACM SIGSPATIAL international conference on advances in geographic information systems</em><span class="ltx_text" id="bib.bib13.10.3" style="color:#000000;">. 336–343.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.6.6.1" style="color:#000000;">Ozeki et al</span><span class="ltx_text" id="bib.bib14.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib14.8.8.3" style="color:#000000;"> (2023a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.10.1" style="color:#000000;">
Ren Ozeki, Haruki Yonekura, Aidana Baimbetova, Hamada Rizk, and Hirozumi Yamaguchi. 2023a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.11.1" style="color:#000000;">One Model Fits All: Cross-Region Taxi-Demand Forecasting. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib14.12.2" style="color:#000000;">Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems</em><span class="ltx_text" id="bib.bib14.13.3" style="color:#000000;"> </span><em class="ltx_emph ltx_font_italic" id="bib.bib14.14.4" style="color:#000000;">(SIGSPATIAL ’23)</em><span class="ltx_text" id="bib.bib14.15.5" style="color:#000000;">. Association for Computing Machinery, New York, NY, USA, Article 101, 4 pages.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.16.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3589132.3625651" style="color:#000000;" title="">https://doi.org/10.1145/3589132.3625651</a><span class="ltx_text" id="bib.bib14.17.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.6.6.1" style="color:#000000;">Ozeki et al</span><span class="ltx_text" id="bib.bib15.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib15.8.8.3" style="color:#000000;"> (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.10.1" style="color:#000000;">
Ren Ozeki, Haruki Yonekura, Hamada Rizk, and Hirozumi Yamaguchi. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.11.1" style="color:#000000;">Sharing without caring: privacy protection of users’ spatio-temporal data without compromise on utility. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib15.12.2" style="color:#000000;">Proceedings of the 30th International Conference on Advances in Geographic Information Systems</em><span class="ltx_text" id="bib.bib15.13.3" style="color:#000000;">. 1–2.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.6.6.1" style="color:#000000;">Ozeki et al</span><span class="ltx_text" id="bib.bib16.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib16.8.8.3" style="color:#000000;"> (2023b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.10.1" style="color:#000000;">
Ren Ozeki, Haruki Yonekura, Hamada Rizk, and Hirozumi Yamaguchi. 2023b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.11.1" style="color:#000000;">Balancing Privacy and Utility of Spatio-Temporal Data for Taxi-Demand Prediction. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.12.2" style="color:#000000;">The 24th IEEE International Conference on Mobile Data Management</em><span class="ltx_text" id="bib.bib16.13.3" style="color:#000000;">. IEEE.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.6.6.1" style="color:#000000;">Ozeki et al</span><span class="ltx_text" id="bib.bib17.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib17.8.8.3" style="color:#000000;"> (2023c)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.10.1" style="color:#000000;">
Ren Ozeki, Haruki Yonekura, Hamada Rizk, and Hirozumi Yamaguchi. 2023c.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.11.1" style="color:#000000;">Balancing privacy and utility of spatio-temporal data for taxi-demand prediction. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib17.12.2" style="color:#000000;">2023 24th IEEE International Conference on Mobile Data Management (MDM)</em><span class="ltx_text" id="bib.bib17.13.3" style="color:#000000;">. IEEE, 215–220.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.6.6.1" style="color:#000000;">Ozeki et al</span><span class="ltx_text" id="bib.bib18.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib18.8.8.3" style="color:#000000;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.10.1" style="color:#000000;">
Ren Ozeki, Haruki Yonekura, Hamada Rizk, and Hirozumi Yamaguchi. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.11.1" style="color:#000000;">Privacy-Preserved Taxi Demand Prediction System Utilizing Distributed Data. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib18.12.2" style="color:#000000;">Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems</em><span class="ltx_text" id="bib.bib18.13.3" style="color:#000000;"> </span><em class="ltx_emph ltx_font_italic" id="bib.bib18.14.4" style="color:#000000;">(SIGSPATIAL ’24)</em><span class="ltx_text" id="bib.bib18.15.5" style="color:#000000;">. Association for Computing Machinery, to appear.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.6.6.1" style="color:#000000;">Qin et al</span><span class="ltx_text" id="bib.bib19.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib19.8.8.3" style="color:#000000;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.10.1" style="color:#000000;">
Kyle K. Qin, Yongli Ren, Wei Shao, Brennan Lake, Filippo Privitera, and Flora D. Salim. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.11.1" style="color:#000000;">Multiple-level Point Embedding for Solving Human Trajectory Imputation with Prediction.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.12.1" style="color:#000000;">ACM Trans. Spatial Algorithms Syst.</em><span class="ltx_text" id="bib.bib19.13.2" style="color:#000000;"> 9, 2, Article 15 (may 2023), 22 pages.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.14.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3582427" style="color:#000000;" title="">https://doi.org/10.1145/3582427</a><span class="ltx_text" id="bib.bib19.15.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.6.6.1" style="color:#000000;">Rao et al</span><span class="ltx_text" id="bib.bib20.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib20.8.8.3" style="color:#000000;"> (2020)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.10.1" style="color:#000000;">
Jinmeng Rao, Song Gao, Yuhao Kang, and Qunying Huang. 2020.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.11.1" style="color:#000000;">LSTM-TrajGAN: A Deep Learning Approach to Trajectory Privacy Protection.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.12.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2006.10521" style="color:#000000;" title="">https://doi.org/10.48550/ARXIV.2006.10521</a><span class="ltx_text" id="bib.bib20.13.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.6.6.1" style="color:#000000;">Ruan et al</span><span class="ltx_text" id="bib.bib21.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib21.8.8.3" style="color:#000000;"> (2020)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.10.1" style="color:#000000;">
Sijie Ruan, Cheng Long, Jie Bao, Chunyang Li, Zisheng Yu, Ruiyuan Li, Yuxuan Liang, Tianfu He, and Yu Zheng. 2020.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.11.1" style="color:#000000;">Learning to Generate Maps from Trajectories.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.12.1" style="color:#000000;">Proceedings of the AAAI Conference on Artificial Intelligence</em><span class="ltx_text" id="bib.bib21.13.2" style="color:#000000;"> 34, 01 (Apr. 2020), 890–897.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.14.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ojs.aaai.org/index.php/AAAI/article/view/5435" style="color:#000000;" title="">https://ojs.aaai.org/index.php/AAAI/article/view/5435</a><span class="ltx_text" id="bib.bib21.15.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.6.6.1" style="color:#000000;">Suzuki et al</span><span class="ltx_text" id="bib.bib22.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib22.8.8.3" style="color:#000000;"> (2010)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.10.1" style="color:#000000;">
Akiyoshi Suzuki, Mayu Iwata, Yuki Arase, Takahiro Hara, Xing Xie, and Shojiro Nishio. 2010.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.11.1" style="color:#000000;">A User Location Anonymization Method for Location Based Services in a Real Environment. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.12.2" style="color:#000000;">Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems</em><span class="ltx_text" id="bib.bib22.13.3" style="color:#000000;"> </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.14.4" style="color:#000000;">(GIS ’10)</em><span class="ltx_text" id="bib.bib22.15.5" style="color:#000000;">. Association for Computing Machinery, New York, NY, USA, 398–401.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.16.1" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.6.6.1" style="color:#000000;">Wang et al</span><span class="ltx_text" id="bib.bib23.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib23.8.8.3" style="color:#000000;"> (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.10.1" style="color:#000000;">
Jingyuan Wang, Ning Wu, Xinxi Lu, Wayne Xin Zhao, and Kai Feng. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.11.1" style="color:#000000;">Deep Trajectory Recovery with Fine-Grained Calibration using Kalman Filter.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.12.1" style="color:#000000;">IEEE Transactions on Knowledge and Data Engineering</em><span class="ltx_text" id="bib.bib23.13.2" style="color:#000000;"> 33, 3 (2021), 921–934.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="color:#000000;">Woźniak and Szymański (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.7.1" style="color:#000000;">
Szymon Woźniak and Piotr Szymański. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.8.1" style="color:#000000;">Hex2vec: Context-aware embedding h3 hexagons with openstreetmap tags. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib24.9.2" style="color:#000000;">Proceedings of the 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery</em><span class="ltx_text" id="bib.bib24.10.3" style="color:#000000;">. 61–71.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.6.6.1" style="color:#000000;">Yonekura et al</span><span class="ltx_text" id="bib.bib25.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib25.8.8.3" style="color:#000000;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.10.1" style="color:#000000;">
Haruki Yonekura, Ren Ozeki, Hamada Rizk, and Hirozumi Yamaguchi. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.11.1" style="color:#000000;">STM-A Privacy-Enhanced Solution for Spatio-Temporal Trajectory Management. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib25.12.2" style="color:#000000;">2023 24th IEEE International Conference on Mobile Data Management (MDM)</em><span class="ltx_text" id="bib.bib25.13.3" style="color:#000000;">. IEEE, 168–171.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.6.6.1" style="color:#000000;">You et al</span><span class="ltx_text" id="bib.bib26.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib26.8.8.3" style="color:#000000;"> (2007)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.10.1" style="color:#000000;">
Tun-Hao You, Wen-Chih Peng, and Wang-Chien Lee. 2007.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.11.1" style="color:#000000;">Protecting Moving Trajectories with Dummies. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib26.12.2" style="color:#000000;">2007 International Conference on Mobile Data Management</em><span class="ltx_text" id="bib.bib26.13.3" style="color:#000000;">. 278–282.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.14.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MDM.2007.58" style="color:#000000;" title="">https://doi.org/10.1109/MDM.2007.58</a><span class="ltx_text" id="bib.bib26.15.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.6.6.1" style="color:#000000;">Yu et al</span><span class="ltx_text" id="bib.bib27.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib27.8.8.3" style="color:#000000;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.10.1" style="color:#000000;">
Ming Yu, Jiecong Shi, Cuihong Xue, Xiaoke Hao, and Gang Yan. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.11.1" style="color:#000000;">A review of single image super-resolution reconstruction based on deep learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.12.1" style="color:#000000;">Multimedia Tools and Applications</em><span class="ltx_text" id="bib.bib27.13.2" style="color:#000000;"> 83, 18 (2024), 55921–55962.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.6.6.1" style="color:#000000;">Yuan et al</span><span class="ltx_text" id="bib.bib28.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib28.8.8.3" style="color:#000000;"> (2010)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.10.1" style="color:#000000;">
Jing Yuan, Yu Zheng, Chengyang Zhang, Xing Xie, and Guang-Zhong Sun. 2010.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.11.1" style="color:#000000;">An interactive-voting based map matching algorithm. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib28.12.2" style="color:#000000;">2010 Eleventh international conference on mobile data management</em><span class="ltx_text" id="bib.bib28.13.3" style="color:#000000;">. IEEE, 43–52.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.6.6.1" style="color:#000000;">Zheng et al</span><span class="ltx_text" id="bib.bib29.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib29.8.8.3" style="color:#000000;"> (2011)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.10.1" style="color:#000000;">
Yu Zheng, Hao Fu, Xing Xie, Wei-Ying Ma, and Quannan Li. 2011.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.11.1" style="color:#000000;">Geolife GPS trajectory dataset - User Guide</em><span class="ltx_text" id="bib.bib29.12.2" style="color:#000000;"> (geolife gps trajectories 1.1 ed.).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.13.1" style="color:#000000;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/" style="color:#000000;" title="">https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/</a><span class="ltx_text" id="bib.bib29.14.2" style="color:#000000;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.6.6.1" style="color:#000000;">Zhu et al</span><span class="ltx_text" id="bib.bib30.7.7.2" style="color:#000000;">.</span><span class="ltx_text" id="bib.bib30.8.8.3" style="color:#000000;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.10.1" style="color:#000000;">
Yuanshao Zhu, Yongchao Ye, Xiangyu Zhao, and James JQ Yu. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.11.1" style="color:#000000;">Diffusion Model for GPS Trajectory Generation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.12.1" style="color:#000000;">arXiv preprint arXiv:2304.11582</em><span class="ltx_text" id="bib.bib30.13.2" style="color:#000000;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  1 11:55:51 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
