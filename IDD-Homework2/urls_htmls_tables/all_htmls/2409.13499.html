<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.13499] Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper</title><meta property="og:description" content="The training of automatic speech recognition (ASR) with little to no supervised data remains an open question.
In this work, we demonstrate that streaming Transformer-Transducer (TT) models can be trained from scratch …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.13499">

<!--Generated on Sat Oct  5 21:53:23 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Fast Streaming Transducer ASR Prototyping via
<br class="ltx_break">Knowledge Distillation with Whisper</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.1" class="ltx_text ltx_font_bold">Iuliia Thorbecke<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex1.1.1.1" class="ltx_text ltx_font_medium">1</span></span>Equal contribution. Order is determined by a coin flip.</span></span></span><sup id="id1.1.1.1" class="ltx_sup"><span id="id1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,2</span></sup></span>
<span id="id2.2.2" class="ltx_text ltx_font_bold">Juan Zuluaga-Gomez<span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex2.1.1.1" class="ltx_text ltx_font_medium">1</span></span>Equal contribution. Order is determined by a coin flip.</span></span></span><sup id="id2.2.2.1" class="ltx_sup"><span id="id2.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,3</span></sup></span>
<span id="id3.3.3" class="ltx_text ltx_font_bold">Esaú Villatoro-Tello<sup id="id3.3.3.1" class="ltx_sup"><span id="id3.3.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>
<span id="id4.4.4" class="ltx_text ltx_font_bold">Shashi Kumar<sup id="id4.4.4.1" class="ltx_sup"><span id="id4.4.4.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,3</span></sup></span> 
<br class="ltx_break"><span id="id5.5.5" class="ltx_text ltx_font_bold">Pradeep Rangappa<sup id="id5.5.5.1" class="ltx_sup"><span id="id5.5.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>
<span id="id6.6.6" class="ltx_text ltx_font_bold">Sergio Burdisso<sup id="id6.6.6.1" class="ltx_sup"><span id="id6.6.6.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>
<span id="id7.7.7" class="ltx_text ltx_font_bold">Petr Motlicek<sup id="id7.7.7.1" class="ltx_sup"><span id="id7.7.7.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,4</span></sup></span>
<span id="id8.8.8" class="ltx_text ltx_font_bold">Karthik Pandia<sup id="id8.8.8.1" class="ltx_sup"><span id="id8.8.8.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5</span></sup></span>
<span id="id9.9.9" class="ltx_text ltx_font_bold">Aravind Ganapathiraju<sup id="id9.9.9.1" class="ltx_sup"><span id="id9.9.9.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5</span></sup></span>

<br class="ltx_break"><sup id="id15.15.id1" class="ltx_sup"><span id="id15.15.id1.1" class="ltx_text ltx_font_italic">1</span></sup> Idiap Research Institute
<sup id="id16.16.id2" class="ltx_sup"><span id="id16.16.id2.1" class="ltx_text ltx_font_italic">2</span></sup> University of Zurich
<sup id="id17.17.id3" class="ltx_sup"><span id="id17.17.id3.1" class="ltx_text ltx_font_italic">3</span></sup> EPFL
<sup id="id18.18.id4" class="ltx_sup"><span id="id18.18.id4.1" class="ltx_text ltx_font_italic">4</span></sup> Brno University of Technology
<sup id="id19.19.id5" class="ltx_sup"><span id="id19.19.id5.1" class="ltx_text ltx_font_italic">5</span></sup> Uniphore 
<br class="ltx_break"><span id="id20.20.id6" class="ltx_text ltx_font_typewriter">iuliia.thorbecke@uzh.ch</span>
<span id="id21.21.id7" class="ltx_text ltx_font_typewriter">juan.zuluaga@eu4m.eu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id22.id1" class="ltx_p">The training of automatic speech recognition (ASR) with little to no supervised data remains an open question.
In this work, we demonstrate that streaming Transformer-Transducer (TT) models can be trained from scratch in consumer and accessible GPUs in their entirety with pseudo-labeled (PL) speech from foundational speech models (FSM).
This allows training a robust ASR model just in one stage and does not require large data and computational budget compared to the two-step scenario with pre-training and fine-tuning. We perform a comprehensive ablation on different aspects of PL-based streaming TT models such as the impact of (1) shallow fusion of n-gram LMs, (2) contextual biasing with named entities, (3) chunk-wise decoding for low-latency streaming applications, and (4) TT overall performance as the function of the FSM size. Our results demonstrate that TT can be trained from scratch without supervised data, even with very noisy PLs. We validate the proposed framework on 6 languages from CommonVoice and propose multiple heuristics to filter out hallucinated PLs.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.14" class="ltx_block ltx_align_bottom">
<p id="p1.14.15" class="ltx_p"><span id="p1.14.15.1" class="ltx_text ltx_font_bold">Fast Streaming Transducer ASR Prototyping via
<br class="ltx_break">Knowledge Distillation with Whisper</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.14.14" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.14.14.14" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.14.14.14.14" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.4.4.4.4.4" class="ltx_tr">
<span id="p1.4.4.4.4.4.4" class="ltx_td ltx_align_center"><span id="p1.4.4.4.4.4.4.4" class="ltx_text ltx_font_bold">Iuliia Thorbecke<span id="footnotex3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex3.1.1.1" class="ltx_text ltx_font_medium">1</span></span>Equal contribution. Order is determined by a coin flip.</span></span></span><sup id="p1.4.4.4.4.4.4.4.1" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,2</span></sup>
Juan Zuluaga-Gomez<span id="footnotex4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex4.1.1.1" class="ltx_text ltx_font_medium">1</span></span>Equal contribution. Order is determined by a coin flip.</span></span></span><sup id="p1.4.4.4.4.4.4.4.2" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1,3</span></sup>
Esaú Villatoro-Tello<sup id="p1.4.4.4.4.4.4.4.3" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>
Shashi Kumar<sup id="p1.4.4.4.4.4.4.4.4" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.4.1" class="ltx_text ltx_font_medium ltx_font_italic">1,3</span></sup></span></span></span>
<span id="p1.9.9.9.9.9" class="ltx_tr">
<span id="p1.9.9.9.9.9.5" class="ltx_td ltx_align_center"><span id="p1.5.5.5.5.5.1.1" class="ltx_text ltx_font_bold">Pradeep Rangappa<sup id="p1.5.5.5.5.5.1.1.1" class="ltx_sup"><span id="p1.5.5.5.5.5.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>
<span id="p1.6.6.6.6.6.2.2" class="ltx_text ltx_font_bold">Sergio Burdisso<sup id="p1.6.6.6.6.6.2.2.1" class="ltx_sup"><span id="p1.6.6.6.6.6.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>
<span id="p1.7.7.7.7.7.3.3" class="ltx_text ltx_font_bold">Petr Motlicek<sup id="p1.7.7.7.7.7.3.3.1" class="ltx_sup"><span id="p1.7.7.7.7.7.3.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,4</span></sup></span>
<span id="p1.8.8.8.8.8.4.4" class="ltx_text ltx_font_bold">Karthik Pandia<sup id="p1.8.8.8.8.8.4.4.1" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5</span></sup></span>
<span id="p1.9.9.9.9.9.5.5" class="ltx_text ltx_font_bold">Aravind Ganapathiraju<sup id="p1.9.9.9.9.9.5.5.1" class="ltx_sup"><span id="p1.9.9.9.9.9.5.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5</span></sup></span></span></span>
<span id="p1.14.14.14.14.14" class="ltx_tr">
<span id="p1.14.14.14.14.14.5" class="ltx_td ltx_align_center"><sup id="p1.14.14.14.14.14.5.1" class="ltx_sup"><span id="p1.14.14.14.14.14.5.1.1" class="ltx_text ltx_font_italic">1</span></sup> Idiap Research Institute
<sup id="p1.14.14.14.14.14.5.2" class="ltx_sup"><span id="p1.14.14.14.14.14.5.2.1" class="ltx_text ltx_font_italic">2</span></sup> University of Zurich
<sup id="p1.14.14.14.14.14.5.3" class="ltx_sup"><span id="p1.14.14.14.14.14.5.3.1" class="ltx_text ltx_font_italic">3</span></sup> EPFL
<sup id="p1.14.14.14.14.14.5.4" class="ltx_sup"><span id="p1.14.14.14.14.14.5.4.1" class="ltx_text ltx_font_italic">4</span></sup> Brno University of Technology
<sup id="p1.14.14.14.14.14.5.5" class="ltx_sup"><span id="p1.14.14.14.14.14.5.5.1" class="ltx_text ltx_font_italic">5</span></sup> Uniphore</span></span>
<span id="p1.14.14.14.14.15.1" class="ltx_tr">
<span id="p1.14.14.14.14.15.1.1" class="ltx_td ltx_align_center"><span id="p1.14.14.14.14.15.1.1.1" class="ltx_text ltx_font_typewriter">iuliia.thorbecke@uzh.ch</span>
<span id="p1.14.14.14.14.15.1.1.2" class="ltx_text ltx_font_typewriter">juan.zuluaga@eu4m.eu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">There are many challenges when developing automatic speech recognition (ASR) engines for industrial applications, including (1) large-scale databases that generalize across multiple domains; (2) inference under challenging low-latency settings; and (3) lightweight ASR model size to minimize deployment costs.
While the first has been solved by training large acoustic foundational speech models (FSM) with massive databases <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al., <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Pratap et al., <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite>, the latter two strongly relate to architectural choices, e.g., using Connectionist Temporal Classification (CTC) <cite class="ltx_cite ltx_citemacro_citep">(Graves et al., <a href="#bib.bib21" title="" class="ltx_ref">2006</a>)</cite> or transducer-based <cite class="ltx_cite ltx_citemacro_citep">(Graves, <a href="#bib.bib20" title="" class="ltx_ref">2012</a>)</cite> modeling.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.13499/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="456" height="386" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Proposed framework for efficient and fast streaming ASR prototyping with pseudo-labeled data. Transducer model are further improved via shallow fusion of n-gram LMs and contextual biasing of target named entities.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In industrial applications, large supervised databases in target domains are not always available, thus several techniques have been proposed to develop robust ASR models with small supervised corpora:
(1) data augmentation <cite class="ltx_cite ltx_citemacro_citep">(Park et al., <a href="#bib.bib41" title="" class="ltx_ref">2019</a>; Bartelds et al., <a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>;
(2) only-audio self-supervised pre-training with large databases and fine-tuning with small corpora <cite class="ltx_cite ltx_citemacro_citep">(Baevski et al., <a href="#bib.bib5" title="" class="ltx_ref">2020</a>; Conneau et al., <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Zuluaga-Gomez et al., <a href="#bib.bib66" title="" class="ltx_ref">2023</a>)</cite>;
(3) pseudo-label then fine-tune, e.g., semi-supervised learning <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a href="#bib.bib64" title="" class="ltx_ref">2023</a>; Lugosch et al., <a href="#bib.bib37" title="" class="ltx_ref">2022</a>; Zuluaga-Gomez et al., <a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite> and weakly supervised learning  <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>. Most of the approaches target the attention-based encoder-decoder (AED) <cite class="ltx_cite ltx_citemacro_citep">(Watanabe et al., <a href="#bib.bib53" title="" class="ltx_ref">2017a</a>)</cite> or CTC models.
Even though these two architectures have shown impressive results on multiple benchmarks (e.g., Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>), they still lag in streaming settings <cite class="ltx_cite ltx_citemacro_citep">(Prabhavalkar et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The Transformer-Transducer architecture <cite class="ltx_cite ltx_citemacro_citep">(Yeh et al., <a href="#bib.bib59" title="" class="ltx_ref">2019</a>)</cite> is widely exploited for industrial uses that require streaming decoding because the transducer decoder naturally supports
streaming <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib35" title="" class="ltx_ref">2021</a>, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>. However, the transducer used to be harder to train compared to AED and CTC, thus, it was less explored in the community, until it was shown to achieve a performance as close as AED models <cite class="ltx_cite ltx_citemacro_citep">(Sainath et al., <a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>. The transducer models consist of an encoder, predictor and joint networks. Using a Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a href="#bib.bib52" title="" class="ltx_ref">2017</a>)</cite> encoder leads to a Transformer-Transducer (TT) architecture <cite class="ltx_cite ltx_citemacro_citep">(Battenberg et al., <a href="#bib.bib9" title="" class="ltx_ref">2017</a>; Yeh et al., <a href="#bib.bib59" title="" class="ltx_ref">2019</a>; Zhang et al., <a href="#bib.bib62" title="" class="ltx_ref">2020</a>)</cite>. When trained from scratch, the TT models require sufficient amounts of supervised datasets in the target language and domain <cite class="ltx_cite ltx_citemacro_citep">(Noroozi et al., <a href="#bib.bib38" title="" class="ltx_ref">2023</a>; Li et al., <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>. At the same time, fine-tuning a large pre-trained model, even when using a transducer decoder, would not allow streaming decoding.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, we focus on two questions partly unanswered by the research community: (1) Could we quickly prototype a streaming TT model on a single accessible GPU? (2) Can we train TT models with only pseudo-labeled (PL) data? We target the streaming scenario, which is by nature more challenging than standard offline (full attention) decoding <cite class="ltx_cite ltx_citemacro_citep">(Sainath et al., <a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>. Despite the robustness of AED models in the offline scenario, they still require a large amount of supervised data.
Here, we use TT models <cite class="ltx_cite ltx_citemacro_citep">(Yeh et al., <a href="#bib.bib59" title="" class="ltx_ref">2019</a>)</cite>, where the challenge arises on the fact that these do not include a self-supervised stage,<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><cite class="ltx_cite ltx_citemacro_citet">Chiu et al. (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite> explore to warm start the encoder with a pre-trained SSL-based model, albeit closed source model.</span></span></span> i.e., needing audio-text pairs always. We demonstrate that TT models can be trained entirely from scratch with PLs generated from Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> while attaining competitive performance in streaming scenarios. The overall proposed approach is illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contributions:</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a framework for full-stack rapid development of ASR streaming solutions from scratch with low-to-zero supervised resources;</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">comprehensive study of TT performance as a function of the pseudo-labels quality, for both, online and offline settings;</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">robust heuristics to filter out noisy and hallucinated PLs from FSM;</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">evaluation of the impact of shallow fusion with external n-gram LM and contextual biasing for named entities;</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">experimentation and validation on 6 languages from CommonVoice.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Developing robust ASR systems for low-latency online settings with little to no supervised data is still an open challenge in the community. In this section, we introduce the most prominent approaches to overcome these issues.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">From Encoder-Decoder to Transducer models</h5>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">One of the key advantages of transducer models over encoder-decoder relies on the fact that it supports streaming decoding. Not until recently, it has been demonstrated that these models can surpass standard AED systems  <cite class="ltx_cite ltx_citemacro_citep">(Sainath et al., <a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>. There have been multiple breakthroughs that have made transducer training easier, such as (1) pruned transducer loss  <cite class="ltx_cite ltx_citemacro_citep">(Kuang et al., <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite>, (2) better architectures, e.g., FastConformer <cite class="ltx_cite ltx_citemacro_citep">(Rekesh et al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>;
and (3) from the modeling side, e.g., model pruning, sparsification <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib56" title="" class="ltx_ref">2022a</a>)</cite>, and quantization <cite class="ltx_cite ltx_citemacro_citep">(Sainath et al., <a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>. However, little to no work has been done on fast TT model prototyping (few GPU-days) with pure pseudo-labeled data.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pseudo-labeling in ASR</h5>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.7" class="ltx_p">Semi-supervised learning <cite class="ltx_cite ltx_citemacro_citep">(Higuchi et al., <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, pseudo labeling <cite class="ltx_cite ltx_citemacro_citep">(Zavaliagkos and Colthurst, <a href="#bib.bib60" title="" class="ltx_ref">1998</a>)</cite>, and weakly supervised learning <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> are a family of methods aiming to partly alleviate the burden of lack of labeled data for supervised ASR training. These approaches have shown promising word error rate (WER) improvement in multiple settings and languages. In practice, a teacher model <math id="S2.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">g</annotation></semantics></math> is trained on an audio-text paired corpus <math id="S2.SS0.SSS0.Px2.p1.2.m2.2" class="ltx_Math" alttext="D_{l}=\{X_{i},Y_{i}\}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.2.m2.2a"><mrow id="S2.SS0.SSS0.Px2.p1.2.m2.2.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.cmml"><msub id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.cmml"><mi id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.2.cmml">D</mi><mi id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.3.cmml">l</mi></msub><mo id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.3.cmml">=</mo><mrow id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.3.cmml">{</mo><msub id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.2.cmml">X</mi><mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.4" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.3.cmml">,</mo><msub id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.cmml"><mi id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.2.cmml">Y</mi><mi id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.5" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.2b"><apply id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2"><eq id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.3"></eq><apply id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.2">𝐷</ci><ci id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.3.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.4.3">𝑙</ci></apply><set id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2"><apply id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.2">𝑋</ci><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.2">𝑌</ci><ci id="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.2.2.2.2.2.3">𝑖</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.2c">D_{l}=\{X_{i},Y_{i}\}</annotation></semantics></math>. Then, it is used to pseudo label a much larger unlabeled only audio corpus, <math id="S2.SS0.SSS0.Px2.p1.3.m3.2" class="ltx_Math" alttext="D_{pl}=\{X_{i},Y^{*}_{i}\}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.3.m3.2a"><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.cmml"><msub id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.2.cmml">D</mi><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.3.cmml">l</mi></mrow></msub><mo id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.3.cmml">=</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.3.cmml">{</mo><msub id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml">X</mi><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.4" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.3.cmml">,</mo><msubsup id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.2.cmml">Y</mi><mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.3.cmml">i</mi><mo id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.5" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.2b"><apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2"><eq id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.3"></eq><apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.2">𝐷</ci><apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3"><times id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.1"></times><ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.2">𝑝</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.4.3.3">𝑙</ci></apply></apply><set id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2"><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2">𝑋</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.2">𝑌</ci><times id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.2.3"></times></apply><ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.2.2.2.3">𝑖</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.2c">D_{pl}=\{X_{i},Y^{*}_{i}\}</annotation></semantics></math>. Afterward, usually a smaller model <cite class="ltx_cite ltx_citemacro_citep">(Barrault et al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite> can use <math id="S2.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="D_{l}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.4.m4.1a"><msub id="S2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml">D</mi><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2">𝐷</ci><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.4.m4.1c">D_{l}</annotation></semantics></math> and <math id="S2.SS0.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="D_{pl}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.5.m5.1a"><msub id="S2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml">D</mi><mrow id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.3.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2">𝐷</ci><apply id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3"><times id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.1"></times><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.2">𝑝</ci><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.5.m5.1c">D_{pl}</annotation></semantics></math> for supervised training or fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Hsu et al., <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>.
However, PLs are often noisy and bounded by <math id="S2.SS0.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.6.m6.1a"><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.6.m6.1b"><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.6.m6.1c">g</annotation></semantics></math> model quality, whereas their use might result in suboptimal final performance in the models. This can be solved by either filtering out the nosiest samples or increasing <math id="S2.SS0.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.7.m7.1a"><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.7.m7.1b"><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.7.m7.1c">g</annotation></semantics></math> model size to improve their quality.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We assume that a larger model, trained under the same conditions and with increased data, will attain lower WERs.</span></span></span> Several approaches to improve the PL quality include improving loss functions <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a href="#bib.bib64" title="" class="ltx_ref">2023</a>; Gao et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>,
pairing online and offline models at training time <cite class="ltx_cite ltx_citemacro_citep">(Higuchi et al., <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, and continuous single-language  <cite class="ltx_cite ltx_citemacro_citep">(Likhomanenko et al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a>; Berrebbi et al., <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite> and multilingual pseudo-labeling setting <cite class="ltx_cite ltx_citemacro_citep">(Lugosch et al., <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Knowledge Distillation with Large Models</h5>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Knowledge distillation (KD), or teacher-student training <cite class="ltx_cite ltx_citemacro_citep">(Watanabe et al., <a href="#bib.bib54" title="" class="ltx_ref">2017b</a>)</cite>, is a very well-known technique to distill knowledge from a large model into a smaller model <cite class="ltx_cite ltx_citemacro_citep">(Hinton et al., <a href="#bib.bib24" title="" class="ltx_ref">2015</a>)</cite>. The former is considered the <span id="S2.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">Teacher</span> and the latter is the <span id="S2.SS0.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">Student</span>. In this framework, we first train the teacher model with the correct label (e.g., supervised training) <cite class="ltx_cite ltx_citemacro_citep">(Takashima et al., <a href="#bib.bib50" title="" class="ltx_ref">2018</a>)</cite> or in a self-supervised manner. The student model is then trained with the posterior distributions of the pre-trained teacher model <cite class="ltx_cite ltx_citemacro_citep">(Chebotar and Waters, <a href="#bib.bib11" title="" class="ltx_ref">2016</a>)</cite>. There has been prior work on KD for CTC <cite class="ltx_cite ltx_citemacro_citep">(Takashima et al., <a href="#bib.bib50" title="" class="ltx_ref">2018</a>)</cite> and AED models with Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Gandhi et al., <a href="#bib.bib17" title="" class="ltx_ref">2023</a>; Ferraz et al., <a href="#bib.bib16" title="" class="ltx_ref">2024</a>)</cite> and Transducer models <cite class="ltx_cite ltx_citemacro_citep">(Panchapagesan et al., <a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite>. Similarly, work to distil offline transducer models into online has been explored by <cite class="ltx_cite ltx_citemacro_citet">Kurata and Saon (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> or from self-supervised models <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib57" title="" class="ltx_ref">2022b</a>)</cite>.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">In our work, we focus on sequence-level KD, which means we use the one-best hypothesis from the teacher model instead of using the posterior distribution. This approach has some benefits: (1) no need to cache the teacher model or its outputs into memory; (2) no need to modify the current ASR training pipelines; (3) overall faster ASR training w.r.t teacher-student based KD, where we can leverage highly optimized inference pipelines–including model quantization–for PL generation, e.g., WhisperX <cite class="ltx_cite ltx_citemacro_citep">(Bain et al., <a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>. All this results in pseudo-labeling that meets the needs for fast prototyping for standard industrial applications.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section describes the datasets, TT architecture, details for training with pseudo-labeled data, effective integration of language model and contextual biasing with shallow fusion, and metrics we use for evaluation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Pseudo Labeling with Whisper</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Our core contribution is the fast prototyping of TT streaming ASR trained exclusively on pseudo-labeled data. We select the Whisper model as our teacher model <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> due to its strong performance across multiple benchmarks. In addition, Whisper provides models at different parameter scales.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Decoding with WhisperX pipeline</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">We use the WhisperX pipeline <cite class="ltx_cite ltx_citemacro_citep">(Bain et al., <a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite> across all the experiments to generate PLs. It is composed of (1) a voice activity detection step to segment long-form audio; (2) batching multiple segments for efficient inference; (3) model quantization of Whisper and C++ implementation on FasterWhisper<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/SYSTRAN/faster-whisper" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SYSTRAN/faster-whisper</a></span></span></span> which uses CTranslate2 for fast decoding;<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://github.com/OpenNMT/CTranslate2/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/OpenNMT/CTranslate2/</a></span></span></span> (4) model inference and word level alignment. Note that we pseudo-label each training corpus with 5 Whisper model sizes, i.e., whisper-tiny, base, small, medium, and large-v3.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data filtering heuristics</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.7" class="ltx_p">We developed multiple data selection heuristics (<math id="S3.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">H</annotation></semantics></math>) to filter out noisy and hallucinated PLs. <math id="S3.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="H1" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.2.m2.1a"><mrow id="S3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml">​</mo><mn id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1"><times id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1"></times><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2">𝐻</ci><cn type="integer" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.2.m2.1c">H1</annotation></semantics></math><span id="S3.SS1.SSS0.Px2.p1.7.1" class="ltx_text ltx_font_bold">:</span> remove PL if composed of the same unigram three or more times. <math id="S3.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="H2" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.3.m3.1a"><mrow id="S3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml">​</mo><mn id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1"><times id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1"></times><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2">𝐻</ci><cn type="integer" id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.3.m3.1c">H2</annotation></semantics></math><span id="S3.SS1.SSS0.Px2.p1.7.2" class="ltx_text ltx_font_bold">:</span> compute maximum word length from supervised training corpus and remove utterances with one or more PLs larger than the max threshold.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>See the per language proposed thresholds in appendix <a href="#A3" title="Appendix C Filtering stage ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</span></span></span> <math id="S3.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="H3" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.4.m4.1a"><mrow id="S3.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.1" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.1.cmml">​</mo><mn id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1"><times id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.1"></times><ci id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2">𝐻</ci><cn type="integer" id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.4.m4.1c">H3</annotation></semantics></math><span id="S3.SS1.SSS0.Px2.p1.7.3" class="ltx_text ltx_font_bold">:</span> compute <math id="S3.SS1.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="word_{ratio}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.5.m5.1a"><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1a" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.4" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1b" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml">​</mo><msub id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.2.cmml">d</mi><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1a" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.4" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1b" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.5" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1c" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.6" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.6.cmml">o</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1"><times id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1"></times><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2">𝑤</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3">𝑜</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.4.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.4">𝑟</ci><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.2">𝑑</ci><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3"><times id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.1"></times><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.2">𝑟</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.3">𝑎</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.4.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.4">𝑡</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.5.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.5">𝑖</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.6.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.5.3.6">𝑜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.5.m5.1c">word_{ratio}</annotation></semantics></math><span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Number of words divided by utterance duration [seconds].</span></span></span> and filter out samples with <math id="S3.SS1.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="word_{ratio}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.6.m6.1a"><mrow id="S3.SS1.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1a" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.4" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1b" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml">​</mo><msub id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.cmml"><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.2" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.2.cmml">d</mi><mrow id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.2" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.3" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1a" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.4" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1b" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.5" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1c" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.6" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.6.cmml">o</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1"><times id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1"></times><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2">𝑤</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3">𝑜</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.4.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.4">𝑟</ci><apply id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.2.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.2">𝑑</ci><apply id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3"><times id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.1"></times><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.2">𝑟</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.3">𝑎</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.4.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.4">𝑡</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.5.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.5">𝑖</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.6.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.5.3.6">𝑜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.6.m6.1c">word_{ratio}</annotation></semantics></math> less than 1 or more than 4. <math id="S3.SS1.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="H4" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.7.m7.1a"><mrow id="S3.SS1.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.1" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.1.cmml">​</mo><mn id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1"><times id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.1"></times><ci id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2">𝐻</ci><cn type="integer" id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.7.m7.1c">H4</annotation></semantics></math><span id="S3.SS1.SSS0.Px2.p1.7.4" class="ltx_text ltx_font_bold">:</span> verbalize all the numbers from the pseudo-labels, remove punctuation and normalize following the CommonVoice recipe in Lhotse <cite class="ltx_cite ltx_citemacro_citep">(Żelasko et al., <a href="#bib.bib61" title="" class="ltx_ref">2021</a>)</cite>. These heuristics are applied for every training corpora. Similar heuristics are proposed in <cite class="ltx_cite ltx_citemacro_citep">(Barrault et al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Transformer-Transducer Training</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We train Transformer-Transducer models from scratch for each language and dataset. We use stateless predictor <cite class="ltx_cite ltx_citemacro_citep">(Ghodsi et al., <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> and Zipformer encoder model <cite class="ltx_cite ltx_citemacro_citep">(Yao et al., <a href="#bib.bib58" title="" class="ltx_ref">2023</a>)</cite> with the latest Icefall Transducer recipe and its default training hyper-parameters.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer</a>.</span></span></span> This includes <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">ScaledAdam</span> optimizer <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a href="#bib.bib28" title="" class="ltx_ref">2014</a>)</cite>, learning rate scheduler with a 500-step warmup phase <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a href="#bib.bib52" title="" class="ltx_ref">2017</a>)</cite> followed by a decay phase (each 7.5k steps and 3.5 epochs), as in <cite class="ltx_cite ltx_citemacro_citet">Yao et al. (<a href="#bib.bib58" title="" class="ltx_ref">2023</a>)</cite>. The neural TT model is jointly optimized with an interpolation of simple and pruned RNN-T loss <cite class="ltx_cite ltx_citemacro_citep">(Kuang et al., <a href="#bib.bib29" title="" class="ltx_ref">2022</a>; Graves, <a href="#bib.bib20" title="" class="ltx_ref">2012</a>)</cite> and CTC loss <cite class="ltx_cite ltx_citemacro_citep">(Graves et al., <a href="#bib.bib21" title="" class="ltx_ref">2006</a>)</cite> (<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\lambda=0.1" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">λ</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝜆</ci><cn type="float" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\lambda=0.1</annotation></semantics></math>), according to:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}=(1-\lambda)\cdot\mathcal{L}_{RNN\-T}+\lambda\cdot\mathcal{L}_{CTC}." display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">ℒ</mi><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">⋅</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.3.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.4" xref="S3.E1.m1.1.1.1.1.1.1.3.3.4.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.3.3.1b" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.5" xref="S3.E1.m1.1.1.1.1.1.1.3.3.5.cmml">T</mi></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.3.2.cmml">λ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.3.1.cmml">⋅</mo><msub id="S3.E1.m1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.3.3.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.1.1.1.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.3.3.3.1" xref="S3.E1.m1.1.1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.1.3.3.3.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.3.3.3.1a" xref="S3.E1.m1.1.1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.3.3.3.4" xref="S3.E1.m1.1.1.1.1.1.3.3.3.4.cmml">C</mi></mrow></msub></mrow></mrow></mrow><mo lspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><ci id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></plus><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">⋅</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3">𝜆</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2">𝑅</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3">𝑁</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.4">𝑁</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.5.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.5">𝑇</ci></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3"><ci id="S3.E1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.1">⋅</ci><ci id="S3.E1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2">𝜆</ci><apply id="S3.E1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3.3"><times id="S3.E1.m1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3.3.2">𝐶</ci><ci id="S3.E1.m1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3.3.3">𝑇</ci><ci id="S3.E1.m1.1.1.1.1.1.3.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3.3.4">𝐶</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{L}=(1-\lambda)\cdot\mathcal{L}_{RNN\-T}+\lambda\cdot\mathcal{L}_{CTC}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.2" class="ltx_p">The peak learning rate is <math id="S3.SS2.p1.2.m1.1" class="ltx_Math" alttext="lr=5.0e^{-2}" display="inline"><semantics id="S3.SS2.p1.2.m1.1a"><mrow id="S3.SS2.p1.2.m1.1.1" xref="S3.SS2.p1.2.m1.1.1.cmml"><mrow id="S3.SS2.p1.2.m1.1.1.2" xref="S3.SS2.p1.2.m1.1.1.2.cmml"><mi id="S3.SS2.p1.2.m1.1.1.2.2" xref="S3.SS2.p1.2.m1.1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.2.m1.1.1.2.1" xref="S3.SS2.p1.2.m1.1.1.2.1.cmml">​</mo><mi id="S3.SS2.p1.2.m1.1.1.2.3" xref="S3.SS2.p1.2.m1.1.1.2.3.cmml">r</mi></mrow><mo id="S3.SS2.p1.2.m1.1.1.1" xref="S3.SS2.p1.2.m1.1.1.1.cmml">=</mo><mrow id="S3.SS2.p1.2.m1.1.1.3" xref="S3.SS2.p1.2.m1.1.1.3.cmml"><mn id="S3.SS2.p1.2.m1.1.1.3.2" xref="S3.SS2.p1.2.m1.1.1.3.2.cmml">5.0</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p1.2.m1.1.1.3.1" xref="S3.SS2.p1.2.m1.1.1.3.1.cmml">​</mo><msup id="S3.SS2.p1.2.m1.1.1.3.3" xref="S3.SS2.p1.2.m1.1.1.3.3.cmml"><mi id="S3.SS2.p1.2.m1.1.1.3.3.2" xref="S3.SS2.p1.2.m1.1.1.3.3.2.cmml">e</mi><mrow id="S3.SS2.p1.2.m1.1.1.3.3.3" xref="S3.SS2.p1.2.m1.1.1.3.3.3.cmml"><mo id="S3.SS2.p1.2.m1.1.1.3.3.3a" xref="S3.SS2.p1.2.m1.1.1.3.3.3.cmml">−</mo><mn id="S3.SS2.p1.2.m1.1.1.3.3.3.2" xref="S3.SS2.p1.2.m1.1.1.3.3.3.2.cmml">2</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m1.1b"><apply id="S3.SS2.p1.2.m1.1.1.cmml" xref="S3.SS2.p1.2.m1.1.1"><eq id="S3.SS2.p1.2.m1.1.1.1.cmml" xref="S3.SS2.p1.2.m1.1.1.1"></eq><apply id="S3.SS2.p1.2.m1.1.1.2.cmml" xref="S3.SS2.p1.2.m1.1.1.2"><times id="S3.SS2.p1.2.m1.1.1.2.1.cmml" xref="S3.SS2.p1.2.m1.1.1.2.1"></times><ci id="S3.SS2.p1.2.m1.1.1.2.2.cmml" xref="S3.SS2.p1.2.m1.1.1.2.2">𝑙</ci><ci id="S3.SS2.p1.2.m1.1.1.2.3.cmml" xref="S3.SS2.p1.2.m1.1.1.2.3">𝑟</ci></apply><apply id="S3.SS2.p1.2.m1.1.1.3.cmml" xref="S3.SS2.p1.2.m1.1.1.3"><times id="S3.SS2.p1.2.m1.1.1.3.1.cmml" xref="S3.SS2.p1.2.m1.1.1.3.1"></times><cn type="float" id="S3.SS2.p1.2.m1.1.1.3.2.cmml" xref="S3.SS2.p1.2.m1.1.1.3.2">5.0</cn><apply id="S3.SS2.p1.2.m1.1.1.3.3.cmml" xref="S3.SS2.p1.2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m1.1.1.3.3.1.cmml" xref="S3.SS2.p1.2.m1.1.1.3.3">superscript</csymbol><ci id="S3.SS2.p1.2.m1.1.1.3.3.2.cmml" xref="S3.SS2.p1.2.m1.1.1.3.3.2">𝑒</ci><apply id="S3.SS2.p1.2.m1.1.1.3.3.3.cmml" xref="S3.SS2.p1.2.m1.1.1.3.3.3"><minus id="S3.SS2.p1.2.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.p1.2.m1.1.1.3.3.3"></minus><cn type="integer" id="S3.SS2.p1.2.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.p1.2.m1.1.1.3.3.3.2">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m1.1c">lr=5.0e^{-2}</annotation></semantics></math> and we train each TT for 30 epochs on a single RTX 3090 GPU with only PLs.<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We also run an experiment valuable for the industrial domain. It includes a thorough analysis of PLs quality for the call-center domain, see Appendix <a href="#A4" title="Appendix D Call-center speech use case ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</span></span></span> Training takes between 1 and 2 days.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Regularization with supervised data</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.4" class="ltx_p">We perform experiments where along with PLs we mix in 100h of randomly selected supervised data from the train set <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="D_{l}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2">𝐷</ci><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">D_{l}</annotation></semantics></math> during training. We compute mixing weights between <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="D_{l}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">D</mi><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2">𝐷</ci><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">D_{l}</annotation></semantics></math> and <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="D_{pl}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">D</mi><mrow id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.3.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2">𝐷</ci><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3"><times id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.2">𝑝</ci><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">D_{pl}</annotation></semantics></math> so each training batch contains at least one sample from <math id="S3.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="D_{l}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml">D</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2">𝐷</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.1c">D_{l}</annotation></semantics></math>. This is achieved with <span id="S3.SS2.SSS0.Px1.p1.4.1" class="ltx_text ltx_font_italic">CutSet.Mux</span> function from Lhotse <cite class="ltx_cite ltx_citemacro_citep">(Żelasko et al., <a href="#bib.bib61" title="" class="ltx_ref">2021</a>)</cite>.<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>It lazily loads two or more datasets and mixes them on the fly according to pre-defined mixing weights.</span></span></span>
All the experiments that uses PL and supervised data are denoted with <span id="S3.SS2.SSS0.Px1.p1.4.2" class="ltx_text ltx_font_bold ltx_font_italic">+sup. [100h]</span>, otherwise, the model is trained with PL only. As an ablation experiment, we also test the performance by scaling up supervised data to 200h and 400h when using the weakest FSM, i.e., whisper-tiny. This experiment aims to (1) compensate for very low-quality PLs, and (2) demonstrate that Whisper PLs (from the largest models) are of sufficient quality for transducer training without any supervised data.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Enabling streaming decoding with multi-chunk training</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">All the models proposed in this work can perform streaming decoding. This is achieved by performing chunk-wise multi-chunk training. During training, we use causal masking of different sizes to enable streaming decoding under different low-latency configurations <cite class="ltx_cite ltx_citemacro_citep">(Swietojanski et al., <a href="#bib.bib49" title="" class="ltx_ref">2023</a>; Kumar et al., <a href="#bib.bib31" title="" class="ltx_ref">2024</a>)</cite>. Specifically, we
rely on two lists: chunk-size={640ms,1280ms,2560ms,full} and <span id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_text">left-context-frames={64,128,256,full}</span>.<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>The effective number of left context chunks is computed as <math id="footnote10.m1.1" class="ltx_math_unparsed" alttext="left\_context\_frames//chunk\_size" display="inline"><semantics id="footnote10.m1.1b"><mrow id="footnote10.m1.1c"><mi id="footnote10.m1.1.1">l</mi><mi id="footnote10.m1.1.2">e</mi><mi id="footnote10.m1.1.3">f</mi><mi id="footnote10.m1.1.4">t</mi><mi mathvariant="normal" id="footnote10.m1.1.5">_</mi><mi id="footnote10.m1.1.6">c</mi><mi id="footnote10.m1.1.7">o</mi><mi id="footnote10.m1.1.8">n</mi><mi id="footnote10.m1.1.9">t</mi><mi id="footnote10.m1.1.10">e</mi><mi id="footnote10.m1.1.11">x</mi><mi id="footnote10.m1.1.12">t</mi><mi mathvariant="normal" id="footnote10.m1.1.13">_</mi><mi id="footnote10.m1.1.14">f</mi><mi id="footnote10.m1.1.15">r</mi><mi id="footnote10.m1.1.16">a</mi><mi id="footnote10.m1.1.17">m</mi><mi id="footnote10.m1.1.18">e</mi><mi id="footnote10.m1.1.19">s</mi><mo rspace="0em" id="footnote10.m1.1.20">/</mo><mo lspace="0em" id="footnote10.m1.1.21">/</mo><mi id="footnote10.m1.1.22">c</mi><mi id="footnote10.m1.1.23">h</mi><mi id="footnote10.m1.1.24">u</mi><mi id="footnote10.m1.1.25">n</mi><mi id="footnote10.m1.1.26">k</mi><mi mathvariant="normal" id="footnote10.m1.1.27">_</mi><mi id="footnote10.m1.1.28">s</mi><mi id="footnote10.m1.1.29">i</mi><mi id="footnote10.m1.1.30">z</mi><mi id="footnote10.m1.1.31">e</mi></mrow><annotation encoding="application/x-tex" id="footnote10.m1.1d">left\_context\_frames//chunk\_size</annotation></semantics></math>.</span></span></span> At training time, we randomly select the chunk size and the left context chunks for each batch. This enables the final model to work on a wide variety of streaming settings. At test time, we select 13 different decoding configurations ranging from 320 ms<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>Decode chunk size of 320ms is more challenging as it has not been used during training.</span></span></span> to 2560 ms chunks (see App. <a href="#A1" title="Appendix A Streaming decoding configurations ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>).</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Language Modeling and Contextual Biasing</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.3" class="ltx_p">Leveraging more text data and context information with language model and keywords integration can considerably improve ASR performance. Since in our set-up, we assume that we have zero (or very little) supervised data, using extra unpaired text data would not contradict the original constraints. At the same time, relying mainly on pseudo-labels, we see text knowledge integration as an opportunity to make our models more reliable and robust. The widely used method of LM integration during the decoding is <span id="S3.SS3.p1.3.1" class="ltx_text ltx_font_italic">shallow fusion</span> (SF) <cite class="ltx_cite ltx_citemacro_citep">(Aleksic et al., <a href="#bib.bib2" title="" class="ltx_ref">2015</a>; Kannan et al., <a href="#bib.bib27" title="" class="ltx_ref">2018</a>; Zhao et al., <a href="#bib.bib63" title="" class="ltx_ref">2019</a>; Jung et al., <a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite>. SF means log-linear interpolation of the score from the ASR model with an external separately optimized LM at each step of the beam search:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="y^{\ast}=\operatorname*{argmax}\log P(y|x)+\lambda\log P_{LM}(y)," display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msup id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">y</mi><mo id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml">∗</mo></msup><mo rspace="0.1389em" id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.3.1.cmml"><mo lspace="0.1389em" rspace="0.167em" id="S3.E2.m1.2.2.1.1.1.1.3.1.1" xref="S3.E2.m1.2.2.1.1.1.1.3.1.1.cmml">argmax</mo><mi id="S3.E2.m1.2.2.1.1.1.1.3.1.2" xref="S3.E2.m1.2.2.1.1.1.1.3.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S3.E2.m1.2.2.1.1.1.1.3a" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml">⁡</mo><mi id="S3.E2.m1.2.2.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">+</mo><mrow id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.3.2.cmml">λ</mi><mo lspace="0.167em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.3.1.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.3.1" xref="S3.E2.m1.2.2.1.1.1.3.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.E2.m1.2.2.1.1.1.3.3a" xref="S3.E2.m1.2.2.1.1.1.3.3.cmml">⁡</mo><msub id="S3.E2.m1.2.2.1.1.1.3.3.2" xref="S3.E2.m1.2.2.1.1.1.3.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.3.2.2" xref="S3.E2.m1.2.2.1.1.1.3.3.2.2.cmml">P</mi><mrow id="S3.E2.m1.2.2.1.1.1.3.3.2.3" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.3.2.3.2" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.3.3.2.3.1" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.1.3.3.2.3.3" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.3.cmml">M</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.3.1a" xref="S3.E2.m1.2.2.1.1.1.3.1.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.3.4.2" xref="S3.E2.m1.2.2.1.1.1.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.3.4.2.1" xref="S3.E2.m1.2.2.1.1.1.3.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">y</mi><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.3.4.2.2" xref="S3.E2.m1.2.2.1.1.1.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">𝑦</ci><ci id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3">∗</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><plus id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"></plus><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2"></times><apply id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3"><apply id="S3.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1"><ci id="S3.E2.m1.2.2.1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1.1">argmax</ci><log id="S3.E2.m1.2.2.1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1.2"></log></apply><ci id="S3.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2">𝑃</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3"><times id="S3.E2.m1.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1"></times><ci id="S3.E2.m1.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.2">𝜆</ci><apply id="S3.E2.m1.2.2.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3"><log id="S3.E2.m1.2.2.1.1.1.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.1"></log><apply id="S3.E2.m1.2.2.1.1.1.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.3.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2.2">𝑃</ci><apply id="S3.E2.m1.2.2.1.1.1.3.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3"><times id="S3.E2.m1.2.2.1.1.1.3.3.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.1"></times><ci id="S3.E2.m1.2.2.1.1.1.3.3.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.2">𝐿</ci><ci id="S3.E2.m1.2.2.1.1.1.3.3.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2.3.3">𝑀</ci></apply></apply></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">y^{\ast}=\operatorname*{argmax}\log P(y|x)+\lambda\log P_{LM}(y),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.2" class="ltx_p">where <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="P_{LM}(y)" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.2" xref="S3.SS3.p1.1.m1.1.2.cmml"><msub id="S3.SS3.p1.1.m1.1.2.2" xref="S3.SS3.p1.1.m1.1.2.2.cmml"><mi id="S3.SS3.p1.1.m1.1.2.2.2" xref="S3.SS3.p1.1.m1.1.2.2.2.cmml">P</mi><mrow id="S3.SS3.p1.1.m1.1.2.2.3" xref="S3.SS3.p1.1.m1.1.2.2.3.cmml"><mi id="S3.SS3.p1.1.m1.1.2.2.3.2" xref="S3.SS3.p1.1.m1.1.2.2.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.2.2.3.1" xref="S3.SS3.p1.1.m1.1.2.2.3.1.cmml">​</mo><mi id="S3.SS3.p1.1.m1.1.2.2.3.3" xref="S3.SS3.p1.1.m1.1.2.2.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.2.1" xref="S3.SS3.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S3.SS3.p1.1.m1.1.2.3.2" xref="S3.SS3.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.1.m1.1.2.3.2.1" xref="S3.SS3.p1.1.m1.1.2.cmml">(</mo><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">y</mi><mo stretchy="false" id="S3.SS3.p1.1.m1.1.2.3.2.2" xref="S3.SS3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.2"><times id="S3.SS3.p1.1.m1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.1"></times><apply id="S3.SS3.p1.1.m1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.2.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.2.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.2.2">𝑃</ci><apply id="S3.SS3.p1.1.m1.1.2.2.3.cmml" xref="S3.SS3.p1.1.m1.1.2.2.3"><times id="S3.SS3.p1.1.m1.1.2.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.2.2.3.1"></times><ci id="S3.SS3.p1.1.m1.1.2.2.3.2.cmml" xref="S3.SS3.p1.1.m1.1.2.2.3.2">𝐿</ci><ci id="S3.SS3.p1.1.m1.1.2.2.3.3.cmml" xref="S3.SS3.p1.1.m1.1.2.2.3.3">𝑀</ci></apply></apply><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">P_{LM}(y)</annotation></semantics></math> is an external LM and <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\lambda</annotation></semantics></math> is a hyperparameter to control the impact of the LM on the overall model score.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">To gain more possible improvement from the text information, we explore three options with the SF: (1) word-level n-gram LM, (2) named-entities, (3) combination of word-level n-gram LM and named-entities. We choose n-gram over neural network (NN) LMs, as the use of NN-LMs would be impractical in low-latency streaming scenarios due to the size of the models. Named entities are extracted automatically and considered as keywords forming biasing lists: for more details see Section <a href="#S3.SS4.SSS1" title="3.4.1 CommonVoice Database ‣ 3.4 Databases ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.1</span></a>.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Shallow fusion with Aho-Corasick</h5>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">One of the drawbacks of LM fusion is that it typically slows down the decoding time during inference, especially when using bigger NN-LMs. Since we focus on streaming ASR models in this paper, any potential increase in inference time is critical for us.
Recent studies demonstrated that SF implemented with the Aho-Corasick (AC) algorithm <cite class="ltx_cite ltx_citemacro_citep">(Aho and Corasick, <a href="#bib.bib1" title="" class="ltx_ref">1975</a>)</cite> is fast and optimized when used for the keyword biasing <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a href="#bib.bib22" title="" class="ltx_ref">2023</a>)</cite>. Thus, we use the AC implementation from Icefall<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a target="_blank" href="https://github.com/k2-fsa/icefall/blob/master/icefall/context_graph.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/k2-fsa/icefall/blob/master/icefall/context_graph.py</a></span></span></span> to integrate key named entities (NE) and word-level n-gram LMs during the decoding.</p>
</div>
<div id="S3.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p2.1" class="ltx_p">The Transducer model we use outputs its hypotheses at the subword level and, in this case, an external LM is also typically trained on subwords. In our experiments, to benefit from the word-level statistics, we integrate word-based n-gram external LMs. Such integration from word to subword level is possible with the AC implementation. First, the LM n-grams are converted into strings of subword units with SentecePieces;<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a target="_blank" href="https://github.com/google/sentencepiece" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/google/sentencepiece</a></span></span></span> second, the subword units are used to build an AC prefix trie including LM weights in the probability domain.</p>
</div>
<div id="S3.SS3.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p3.1" class="ltx_p">When a string match occurs between a model prediction and a string in the prefix trie, the log probability of the matching hypothesis is augmented by the LM weight. To obtain positive cost, we convert the logarithmic LM weights (e.g., from ARPA) back to probabilities by taking an exponent.
In the case of context biasing, SF works in the same way but instead of LM weights a fixed bias cost is added to each matched arc. Typically when applying context biasing alone, we set such cost to 0.7.<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>For contextual biasing with NEs, we tested the biasing costs = {0.1, 0.3,0.5,0.7,1.0,1.5,2.0}. 0.7 performed systematically better in all scenarios.</span></span></span>
For SF with combined n-gram LM and biasing list, we still use LM weights, bias cost, and a single prefix tree. Using a single prefix tree has the advantage of faster running time, which is relevant for streaming models. We tune the biasing cost on the dev sets and set it differently when a biased entity is present in the LM vs when it is not<span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>For SF of n-gram LM combined with NEs, we tested the biasing following costs: inLM = {0.5,1.0,1.5,2.0};
notInLM= {0.5,1.0,1.5,2.0}. inLM=0.5 and notInLM=1.5 performed systematically better in all settings.</span></span></span>:</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.6" class="ltx_Math" alttext="C=\begin{cases}\alpha_{outLM}&amp;\text{if NE is not in LM,}\\
exp(LMw)+\alpha_{inLM}&amp;\text{if NE is in LM,}\\
exp(LMw)&amp;\text{otherwise.}\end{cases}" display="block"><semantics id="S3.Ex1.m1.6a"><mrow id="S3.Ex1.m1.6.7" xref="S3.Ex1.m1.6.7.cmml"><mi id="S3.Ex1.m1.6.7.2" xref="S3.Ex1.m1.6.7.2.cmml">C</mi><mo id="S3.Ex1.m1.6.7.1" xref="S3.Ex1.m1.6.7.1.cmml">=</mo><mrow id="S3.Ex1.m1.6.6" xref="S3.Ex1.m1.6.7.3.1.cmml"><mo id="S3.Ex1.m1.6.6.7" xref="S3.Ex1.m1.6.7.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.Ex1.m1.6.6.6" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtr id="S3.Ex1.m1.6.6.6a" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.6.6.6b" xref="S3.Ex1.m1.6.7.3.1.cmml"><msub id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.cmml">α</mi><mrow id="S3.Ex1.m1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.3.1" xref="S3.Ex1.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.3.1a" xref="S3.Ex1.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.4" xref="S3.Ex1.m1.1.1.1.1.1.1.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.3.1b" xref="S3.Ex1.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.5" xref="S3.Ex1.m1.1.1.1.1.1.1.3.5.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.3.1c" xref="S3.Ex1.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.6" xref="S3.Ex1.m1.1.1.1.1.1.1.3.6.cmml">M</mi></mrow></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.6.6.6c" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtext id="S3.Ex1.m1.2.2.2.2.2.1" xref="S3.Ex1.m1.2.2.2.2.2.1a.cmml">if NE is not in LM,</mtext></mtd></mtr><mtr id="S3.Ex1.m1.6.6.6d" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.6.6.6e" xref="S3.Ex1.m1.6.7.3.1.cmml"><mrow id="S3.Ex1.m1.3.3.3.3.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.cmml"><mrow id="S3.Ex1.m1.3.3.3.3.1.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.1.cmml"><mi id="S3.Ex1.m1.3.3.3.3.1.1.1.3" xref="S3.Ex1.m1.3.3.3.3.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.1.2" xref="S3.Ex1.m1.3.3.3.3.1.1.1.2.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.1.4" xref="S3.Ex1.m1.3.3.3.3.1.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.1.2a" xref="S3.Ex1.m1.3.3.3.3.1.1.1.2.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.1.5" xref="S3.Ex1.m1.3.3.3.3.1.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.1.2b" xref="S3.Ex1.m1.3.3.3.3.1.1.1.2.cmml">​</mo><mrow id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.2" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.2" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.3" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.1a" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.4" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.4.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.3" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.3.3.3.3.1.1.2" xref="S3.Ex1.m1.3.3.3.3.1.1.2.cmml">+</mo><msub id="S3.Ex1.m1.3.3.3.3.1.1.3" xref="S3.Ex1.m1.3.3.3.3.1.1.3.cmml"><mi id="S3.Ex1.m1.3.3.3.3.1.1.3.2" xref="S3.Ex1.m1.3.3.3.3.1.1.3.2.cmml">α</mi><mrow id="S3.Ex1.m1.3.3.3.3.1.1.3.3" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.cmml"><mi id="S3.Ex1.m1.3.3.3.3.1.1.3.3.2" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.3.3.1" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.1.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.3.3.3" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.3.3.1a" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.1.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.3.3.4" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.3.3.3.3.1.1.3.3.1b" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.1.cmml">​</mo><mi id="S3.Ex1.m1.3.3.3.3.1.1.3.3.5" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.5.cmml">M</mi></mrow></msub></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.6.6.6f" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtext id="S3.Ex1.m1.4.4.4.4.2.1" xref="S3.Ex1.m1.4.4.4.4.2.1a.cmml">if NE is in LM,</mtext></mtd></mtr><mtr id="S3.Ex1.m1.6.6.6g" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.6.6.6h" xref="S3.Ex1.m1.6.7.3.1.cmml"><mrow id="S3.Ex1.m1.5.5.5.5.1.1" xref="S3.Ex1.m1.5.5.5.5.1.1.cmml"><mi id="S3.Ex1.m1.5.5.5.5.1.1.3" xref="S3.Ex1.m1.5.5.5.5.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.5.5.5.5.1.1.2" xref="S3.Ex1.m1.5.5.5.5.1.1.2.cmml">​</mo><mi id="S3.Ex1.m1.5.5.5.5.1.1.4" xref="S3.Ex1.m1.5.5.5.5.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.5.5.5.5.1.1.2a" xref="S3.Ex1.m1.5.5.5.5.1.1.2.cmml">​</mo><mi id="S3.Ex1.m1.5.5.5.5.1.1.5" xref="S3.Ex1.m1.5.5.5.5.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.5.5.5.5.1.1.2b" xref="S3.Ex1.m1.5.5.5.5.1.1.2.cmml">​</mo><mrow id="S3.Ex1.m1.5.5.5.5.1.1.1.1" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.5.5.5.5.1.1.1.1.2" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.2" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.1" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.1.cmml">​</mo><mi id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.3" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.1a" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.1.cmml">​</mo><mi id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.4" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.4.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.5.5.5.5.1.1.1.1.3" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.6.6.6i" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtext id="S3.Ex1.m1.6.6.6.6.2.1" xref="S3.Ex1.m1.6.6.6.6.2.1a.cmml">otherwise.</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.6b"><apply id="S3.Ex1.m1.6.7.cmml" xref="S3.Ex1.m1.6.7"><eq id="S3.Ex1.m1.6.7.1.cmml" xref="S3.Ex1.m1.6.7.1"></eq><ci id="S3.Ex1.m1.6.7.2.cmml" xref="S3.Ex1.m1.6.7.2">𝐶</ci><apply id="S3.Ex1.m1.6.7.3.1.cmml" xref="S3.Ex1.m1.6.6"><csymbol cd="latexml" id="S3.Ex1.m1.6.7.3.1.1.cmml" xref="S3.Ex1.m1.6.6.7">cases</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2">𝛼</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3"><times id="S3.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.1"></times><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.2">𝑜</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3">𝑢</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.4.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.4">𝑡</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.5.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.5">𝐿</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.6.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.6">𝑀</ci></apply></apply><ci id="S3.Ex1.m1.2.2.2.2.2.1a.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1">if NE is not in LM,</mtext></ci><apply id="S3.Ex1.m1.3.3.3.3.1.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1"><plus id="S3.Ex1.m1.3.3.3.3.1.1.2.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.2"></plus><apply id="S3.Ex1.m1.3.3.3.3.1.1.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1"><times id="S3.Ex1.m1.3.3.3.3.1.1.1.2.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.2"></times><ci id="S3.Ex1.m1.3.3.3.3.1.1.1.3.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.3">𝑒</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.1.4.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.4">𝑥</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.1.5.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.5">𝑝</ci><apply id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1"><times id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.1"></times><ci id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.2">𝐿</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.3">𝑀</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.4.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.1.1.1.1.4">𝑤</ci></apply></apply><apply id="S3.Ex1.m1.3.3.3.3.1.1.3.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.3.3.3.3.1.1.3.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.3.3.3.3.1.1.3.2.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.2">𝛼</ci><apply id="S3.Ex1.m1.3.3.3.3.1.1.3.3.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3"><times id="S3.Ex1.m1.3.3.3.3.1.1.3.3.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.1"></times><ci id="S3.Ex1.m1.3.3.3.3.1.1.3.3.2.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.2">𝑖</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.3.3.3.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.3">𝑛</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.3.3.4.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.4">𝐿</ci><ci id="S3.Ex1.m1.3.3.3.3.1.1.3.3.5.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1.3.3.5">𝑀</ci></apply></apply></apply><ci id="S3.Ex1.m1.4.4.4.4.2.1a.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1">if NE is in LM,</mtext></ci><apply id="S3.Ex1.m1.5.5.5.5.1.1.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1"><times id="S3.Ex1.m1.5.5.5.5.1.1.2.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.2"></times><ci id="S3.Ex1.m1.5.5.5.5.1.1.3.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.3">𝑒</ci><ci id="S3.Ex1.m1.5.5.5.5.1.1.4.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.4">𝑥</ci><ci id="S3.Ex1.m1.5.5.5.5.1.1.5.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.5">𝑝</ci><apply id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1"><times id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.1"></times><ci id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.2">𝐿</ci><ci id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.3">𝑀</ci><ci id="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.4.cmml" xref="S3.Ex1.m1.5.5.5.5.1.1.1.1.1.4">𝑤</ci></apply></apply><ci id="S3.Ex1.m1.6.6.6.6.2.1a.cmml" xref="S3.Ex1.m1.6.6.6.6.2.1"><mtext id="S3.Ex1.m1.6.6.6.6.2.1.cmml" xref="S3.Ex1.m1.6.6.6.6.2.1">otherwise.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.6c">C=\begin{cases}\alpha_{outLM}&amp;\text{if NE is not in LM,}\\
exp(LMw)+\alpha_{inLM}&amp;\text{if NE is in LM,}\\
exp(LMw)&amp;\text{otherwise.}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Language modeling</h5>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.1" class="ltx_p">For LM SF, we train tri-gram word-level LMs with SRILM <cite class="ltx_cite ltx_citemacro_citep">(Stolcke, <a href="#bib.bib48" title="" class="ltx_ref">2002</a>)</cite>. To train n-gram LMs, we use text data from the corresponding train sets.
All the train texts are uppercased and normalized to contain only unicode characters.</p>
</div>
<div id="S3.SS3.SSS0.Px2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS0.Px2.p2.1" class="ltx_p"><span id="S3.SS3.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_bold">Evaluation protocol</span>  For evaluation, we use the standard word error rate (WER) metric for ASR which is the lower the better.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Databases</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Here, we introduce the datasets used for fast ASR prototyping and describe the process of generating biasing lists for each language.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>CommonVoice Database</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">The CommonVoice dataset comprises several thousand hours of audio in more than 100 languages <cite class="ltx_cite ltx_citemacro_citep">(Ardila et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>. For experimentation, we select six languages from CommonVoice-v11 <cite class="ltx_cite ltx_citemacro_citep">(Ardila et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> <span id="footnote16" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span>CommonVoice-v11: cv-corpus-11.0-2022-09-21</span></span></span> which have sufficient data for training ASR and language models:
Catalan (CA),
English (EN),
German (DE),
French (FR),
Spanish (ES), and Italian (IT). We use the official train sets and report WERs on the official test sets. See Table <a href="#S3.T1" title="Table 1 ‣ 3.4.1 CommonVoice Database ‣ 3.4 Databases ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for further statistics.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Train and test sets statistics with context information per CommonVoice language. <sup id="S3.T1.9.1" class="ltx_sup"><span id="S3.T1.9.1.1" class="ltx_text ltx_font_italic">†</span></sup>total of unique entities per test set after removing unigrams shorter than 5 characters. <sup id="S3.T1.10.2" class="ltx_sup"><span id="S3.T1.10.2.1" class="ltx_text ltx_font_italic">‡</span></sup>number of utterances in the test set with at least one named entity.
</figcaption>
<div id="S3.T1.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:261.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(97.5pt,-58.8pt) scale(1.81679844839869,1.81679844839869) ;">
<table id="S3.T1.6.2" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.6.2.3.1" class="ltx_tr">
<td id="S3.T1.6.2.3.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Lang</td>
<td id="S3.T1.6.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Train set</td>
<td id="S3.T1.6.2.3.1.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_tt" colspan="3">Test set stats &amp; Named entities</td>
</tr>
<tr id="S3.T1.6.2.2" class="ltx_tr">
<td id="S3.T1.6.2.2.3" class="ltx_td ltx_align_left ltx_border_r">(code)</td>
<td id="S3.T1.6.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.6.2.2.4.1" class="ltx_text ltx_font_bold">[hr]</span></td>
<td id="S3.T1.6.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.6.2.2.5.1" class="ltx_text ltx_font_bold">utt/hr</span></td>
<td id="S3.T1.5.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.1.1.1.1" class="ltx_text ltx_font_bold">unique<sup id="S3.T1.5.1.1.1.1.1" class="ltx_sup"><span id="S3.T1.5.1.1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">†</span></sup></span></td>
<td id="S3.T1.6.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.6.2.2.2.1" class="ltx_text ltx_font_bold">nb. utt<sup id="S3.T1.6.2.2.2.1.1" class="ltx_sup"><span id="S3.T1.6.2.2.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">‡</span></sup></span></td>
</tr>
<tr id="S3.T1.6.2.4.2" class="ltx_tr">
<td id="S3.T1.6.2.4.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">EN</td>
<td id="S3.T1.6.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1000</td>
<td id="S3.T1.6.2.4.2.3" class="ltx_td ltx_align_center ltx_border_t">16K/27</td>
<td id="S3.T1.6.2.4.2.4" class="ltx_td ltx_align_center ltx_border_t">6921</td>
<td id="S3.T1.6.2.4.2.5" class="ltx_td ltx_align_center ltx_border_t">6442</td>
</tr>
<tr id="S3.T1.6.2.5.3" class="ltx_tr">
<td id="S3.T1.6.2.5.3.1" class="ltx_td ltx_align_left ltx_border_r">CA</td>
<td id="S3.T1.6.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r">1200</td>
<td id="S3.T1.6.2.5.3.3" class="ltx_td ltx_align_center">16.3K/28</td>
<td id="S3.T1.6.2.5.3.4" class="ltx_td ltx_align_center">2108</td>
<td id="S3.T1.6.2.5.3.5" class="ltx_td ltx_align_center">2607</td>
</tr>
<tr id="S3.T1.6.2.6.4" class="ltx_tr">
<td id="S3.T1.6.2.6.4.1" class="ltx_td ltx_align_left ltx_border_r">FR</td>
<td id="S3.T1.6.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r">600</td>
<td id="S3.T1.6.2.6.4.3" class="ltx_td ltx_align_center">16K/26</td>
<td id="S3.T1.6.2.6.4.4" class="ltx_td ltx_align_center">6035</td>
<td id="S3.T1.6.2.6.4.5" class="ltx_td ltx_align_center">7486</td>
</tr>
<tr id="S3.T1.6.2.7.5" class="ltx_tr">
<td id="S3.T1.6.2.7.5.1" class="ltx_td ltx_align_left ltx_border_r">DE</td>
<td id="S3.T1.6.2.7.5.2" class="ltx_td ltx_align_center ltx_border_r">600</td>
<td id="S3.T1.6.2.7.5.3" class="ltx_td ltx_align_center">16K/27</td>
<td id="S3.T1.6.2.7.5.4" class="ltx_td ltx_align_center">6949</td>
<td id="S3.T1.6.2.7.5.5" class="ltx_td ltx_align_center">8491</td>
</tr>
<tr id="S3.T1.6.2.8.6" class="ltx_tr">
<td id="S3.T1.6.2.8.6.1" class="ltx_td ltx_align_left ltx_border_r">ES</td>
<td id="S3.T1.6.2.8.6.2" class="ltx_td ltx_align_center ltx_border_r">317</td>
<td id="S3.T1.6.2.8.6.3" class="ltx_td ltx_align_center">15.5K/26</td>
<td id="S3.T1.6.2.8.6.4" class="ltx_td ltx_align_center">4776</td>
<td id="S3.T1.6.2.8.6.5" class="ltx_td ltx_align_center">6528</td>
</tr>
<tr id="S3.T1.6.2.9.7" class="ltx_tr">
<td id="S3.T1.6.2.9.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">IT</td>
<td id="S3.T1.6.2.9.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">200</td>
<td id="S3.T1.6.2.9.7.3" class="ltx_td ltx_align_center ltx_border_bb">15k/26</td>
<td id="S3.T1.6.2.9.7.4" class="ltx_td ltx_align_center ltx_border_bb">5838</td>
<td id="S3.T1.6.2.9.7.5" class="ltx_td ltx_align_center ltx_border_bb">5938</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section id="S3.SS4.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Biasing List Creation</h5>

<div id="S3.SS4.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px1.p1.1" class="ltx_p">We automatically create biasing lists for target CommonVoice subsets to perform the contextual biasing experiments. For this purpose, we use BERT models from HuggingFace <cite class="ltx_cite ltx_citemacro_citep">(Wolf et al., <a href="#bib.bib55" title="" class="ltx_ref">2020</a>)</cite> fine-tuned on the named-entity recognition (NER) task for each language individually.<span id="footnote17" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span>EN: <a href="dslim/bert-base-NER-uncased" title="" class="ltx_ref ltx_url ltx_font_typewriter">dslim/bert-base-NER-uncased</a>; DE, ES, FR: <a href="Babelscape/wikineural-multilingual-ner" title="" class="ltx_ref ltx_url ltx_font_typewriter">Babelscape/wikineural-multilingual-ner</a> <cite class="ltx_cite ltx_citemacro_citep">(Armengol-Estapé et al., <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>; CA: <a href="projecte-aina/roberta-base-ca-cased-ner" title="" class="ltx_ref ltx_url ltx_font_typewriter">projecte-aina/roberta-base-ca-cased-ner</a> <cite class="ltx_cite ltx_citemacro_citep">(Tedeschi et al., <a href="#bib.bib51" title="" class="ltx_ref">2021</a>)</cite>.</span></span></span> The following steps are included: (1) automatic text labeling with BERT, (2) NEs extraction from the BERT labels, (3) NEs lists filtering.
In Table <a href="#S3.T1" title="Table 1 ‣ 3.4.1 CommonVoice Database ‣ 3.4 Databases ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, one can see the statistics of NE lists per language where the size of lists with unique NEs varies from 2108 to 6949 which is rather long for contextual biasing.<span id="footnote18" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span>The ideal size of the biasing FST is significantly influenced by the data; according to <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, performance started to decline when the number of contextual entities surpassed 1000.</span></span></span>
The last column of Table <a href="#S3.T1" title="Table 1 ‣ 3.4.1 CommonVoice Database ‣ 3.4 Databases ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the number of utterances per test set that contain at least one NE. This information gives an estimation of the proportion of NEs in the test sets: DE and FR sets have almost half of the utterances with NEs, at the same time, the CA set has only 17% of those.</p>
</div>
</section>
<section id="S3.SS4.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Heuristics for biasing list selection</h5>

<div id="S3.SS4.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px2.p1.4" class="ltx_p">Since NEs are automatically extracted with the BERT-based NER, extraction errors are inevitable. To minimize noise from potentially erroneously extracted NEs, we follow simple filtering heuristics when preparing the final biasing lists. <math id="S3.SS4.SSS1.Px2.p1.1.m1.1" class="ltx_Math" alttext="H1" display="inline"><semantics id="S3.SS4.SSS1.Px2.p1.1.m1.1a"><mrow id="S3.SS4.SSS1.Px2.p1.1.m1.1.1" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.2" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.1" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.1.cmml">​</mo><mn id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.3" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.Px2.p1.1.m1.1b"><apply id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1"><times id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.1"></times><ci id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.2">𝐻</ci><cn type="integer" id="S3.SS4.SSS1.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS4.SSS1.Px2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.Px2.p1.1.m1.1c">H1</annotation></semantics></math><span id="S3.SS4.SSS1.Px2.p1.4.1" class="ltx_text ltx_font_bold">:</span> select only NEs that are composed of 1 to 4 words, and <math id="S3.SS4.SSS1.Px2.p1.2.m2.1" class="ltx_Math" alttext="H2" display="inline"><semantics id="S3.SS4.SSS1.Px2.p1.2.m2.1a"><mrow id="S3.SS4.SSS1.Px2.p1.2.m2.1.1" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.2" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.1" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.1.cmml">​</mo><mn id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.3" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.Px2.p1.2.m2.1b"><apply id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1"><times id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.1"></times><ci id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.2">𝐻</ci><cn type="integer" id="S3.SS4.SSS1.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS1.Px2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.Px2.p1.2.m2.1c">H2</annotation></semantics></math><span id="S3.SS4.SSS1.Px2.p1.4.2" class="ltx_text ltx_font_bold">:</span> remove single-word NEs shorter than 5 characters. For example, the filtering step is important to reduce such noisy outputs as short single words that often are not NEs: <span id="S3.SS4.SSS1.Px2.p1.4.3" class="ltx_text ltx_font_italic">ich, wir, die</span> – for DE, <span id="S3.SS4.SSS1.Px2.p1.4.4" class="ltx_text ltx_font_italic">san, mar, new</span> – for ES. We also tried to further filter the lists by only allowing NEs that are repeated at least twice, or NEs composed of bigram or more. However, in our experiments, only applying <math id="S3.SS4.SSS1.Px2.p1.3.m3.1" class="ltx_Math" alttext="H1" display="inline"><semantics id="S3.SS4.SSS1.Px2.p1.3.m3.1a"><mrow id="S3.SS4.SSS1.Px2.p1.3.m3.1.1" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.cmml"><mi id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.2" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.1" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.1.cmml">​</mo><mn id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.3" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.Px2.p1.3.m3.1b"><apply id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1"><times id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.1"></times><ci id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.2">𝐻</ci><cn type="integer" id="S3.SS4.SSS1.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS4.SSS1.Px2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.Px2.p1.3.m3.1c">H1</annotation></semantics></math> and <math id="S3.SS4.SSS1.Px2.p1.4.m4.1" class="ltx_Math" alttext="H2" display="inline"><semantics id="S3.SS4.SSS1.Px2.p1.4.m4.1a"><mrow id="S3.SS4.SSS1.Px2.p1.4.m4.1.1" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.cmml"><mi id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.2" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.1" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.1.cmml">​</mo><mn id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.3" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.Px2.p1.4.m4.1b"><apply id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1"><times id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.1.cmml" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.1"></times><ci id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.2.cmml" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.2">𝐻</ci><cn type="integer" id="S3.SS4.SSS1.Px2.p1.4.m4.1.1.3.cmml" xref="S3.SS4.SSS1.Px2.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.Px2.p1.4.m4.1c">H2</annotation></semantics></math> was sufficient and yielded better WERs overall.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We report our results in two parts. First, we present the overall performance of models trained with PL and with different settings. The following configurations are compared: (1) offline VS streaming TT models, (2)  models trained on PL-only VS models with supervised data regularization, and (3) models with different chunk sizes. Second, we report the performance of models with SF. For the <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">baseline</span>, we use a Zipformer streaming model trained per each language on PL only. In addition, we also compare our results to the offline Zipformer trained on the same data and include the reference to the previous results reported on CommonVoice in <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> (Table <a href="#A2.T3" title="Table 3 ‣ Offline models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).<span id="footnote19" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span>Note that the results from <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> are not directly comparable to ours, as we use the CV-11 version of CommonVoice and <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> uses the version CV-7. We anyway include their results to have the previous reference point but locate them in Appendix.</span></span></span></p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2409.13499/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="365" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>WERs for offline Zipformer models on six languages of CommonVoice. Models are trained with pseudo-labels from different Whisper model sizes (blue graphs). Adding 100h of supervised data during training (red graph) regularizes the training up to models with 700M params, especially for languages with less data.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Performance on models with PL of different quality</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Offline models</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">In Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we present the offline results for TT models trained from scratch on PL data only in six languages (depicted by blue graphs). These models are evaluated only in a non-streaming context to determine the upper bound WERs achievable by training with PLs of varying qualities. As the size of the Whisper Model increases (shown on a log-scaled x-axis), there is a corresponding improvement in WERs, also on a log-scale. The best performance is observed for ES, with the least favourable results for EN. These results show that our approach adapts across a spectrum of PL data quantities and qualities, ranging from 200h for IT to over 1000h for CA and EN. We additionally analyzed the performance of models trained on PLs depending on how well each language is represented in the data used for training Whisper models <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>. Yet, no consistent effect is noticed.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Regularization with supervised data</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">Red graphs in Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> also show WERs for offline models that along with PLs include a small amount of supervised data, up to 100h, for regularization. This strategy proves to be beneficial in cases with noisier PLs, particularly for smaller Whisper models like Whisper-tiny, Whisper-base, and Whisper-small when WER goes down for all the languages. The benefits, however, decrease or are absent with more accurate PLs generated by larger models, such as Whisper-medium and Whisper-large-v3. Thus, with our results on six languages, we can conclude that when supervised data is available, regularization is recommended for models with weak PLs and can be omitted with strong PLs. The results with 100h regularization are also available in Table <a href="#A2.T3" title="Table 3 ‣ Offline models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for offline models and are consistent with the performance on streaming models reported in Table <a href="#S4.T2" title="Table 2 ‣ Scaling-up supervised data helps on cases with very noisy PLs ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2409.13499/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="123" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Box plots of WERs for six languages of CommonVoice.
Streaming Zipformer models are trained from scratch, with only PLs generated with different Whisper model sizes. Each box denotes 13 decoding configurations, ranging from challenging (320ms chunk with limited left context) to more relaxed (2560ms chunk with full left context) streaming settings. (Note different WER scaling on the y-axis.)</figcaption>
</figure>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Scaling-up supervised data helps on cases with very noisy PLs</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">For the ablation experiment on mixing in more supervised data, we maintain a fixed computational budget for generating PLs and explore the extent to which supervised data can offset noisy PLs. The results are pictured in Figure <a href="#S4.F4" title="Figure 4 ‣ Scaling-up supervised data helps on cases with very noisy PLs ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Using only Whisper-tiny, we train TT models from scratch for the six CommonVoice languages with over 200h of available supervised data.
Our results show significant improvements in WER as supervised data increases from 100h to 200h and even more so up to 400h, especially in languages like Catalan, French, and Italian, which likely suffer from lower-quality PLs. For this experiment, our oracle results are from the models fully trained on the supervised data, which can be found in Table <a href="#A2.T3" title="Table 3 ‣ Offline models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for offline models and in Table <a href="#S4.T2" title="Table 2 ‣ Scaling-up supervised data helps on cases with very noisy PLs ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for streaming models.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2409.13499/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="457" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Ablations on WERs of Zipformer models for 6 languages of CommonVoice. We study the impact of mixing supervised data during training with pseudo-labeled of very low quality, i.e., Whisper-tiny.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>WERs for streaming evaluation with n-gram LM and bias-lists (BL). Listed on four CommonVoice languages and two decoding configurations. The Zipformer models are trained with pseudo-labeled data from different Whisper models and 100h of supervised data (“sup. [100h]”) from the original train set. All experiments show additive WERs improvement when adding either (or both) n-gram LM or biasing lists.
</figcaption>
<div id="S4.T2.12" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:876.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(65.4pt,-132.2pt) scale(1.43213636201224,1.43213636201224) ;">
<table id="S4.T2.12.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<td id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4"><span id="S4.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">cs=320ms;lf=2.5s</span></td>
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">cs=320ms;lf=<math id="S4.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><infinity id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">\infty</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T2.12.12.13.1" class="ltx_tr">
<th id="S4.T2.12.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T2.12.12.13.1.1.1" class="ltx_text ltx_font_bold">Experiment</span></th>
<td id="S4.T2.12.12.13.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">CA</td>
<td id="S4.T2.12.12.13.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">DE</td>
<td id="S4.T2.12.12.13.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ES</td>
<td id="S4.T2.12.12.13.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">IT</td>
<td id="S4.T2.12.12.13.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">CA</td>
<td id="S4.T2.12.12.13.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">DE</td>
<td id="S4.T2.12.12.13.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ES</td>
<td id="S4.T2.12.12.13.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">IT</td>
</tr>
<tr id="S4.T2.2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="S4.T2.2.2.2.1.1" class="ltx_text ltx_font_bold">Whisper-tiny (<math id="S4.T2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="39M" display="inline"><semantics id="S4.T2.2.2.2.1.1.m1.1a"><mrow id="S4.T2.2.2.2.1.1.m1.1.1" xref="S4.T2.2.2.2.1.1.m1.1.1.cmml"><mn id="S4.T2.2.2.2.1.1.m1.1.1.2" xref="S4.T2.2.2.2.1.1.m1.1.1.2.cmml">39</mn><mo lspace="0em" rspace="0em" id="S4.T2.2.2.2.1.1.m1.1.1.1" xref="S4.T2.2.2.2.1.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.2.2.2.1.1.m1.1.1.3" xref="S4.T2.2.2.2.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.1.1.m1.1b"><apply id="S4.T2.2.2.2.1.1.m1.1.1.cmml" xref="S4.T2.2.2.2.1.1.m1.1.1"><times id="S4.T2.2.2.2.1.1.m1.1.1.1.cmml" xref="S4.T2.2.2.2.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.2.2.2.1.1.m1.1.1.2.cmml" xref="S4.T2.2.2.2.1.1.m1.1.1.2">39</cn><ci id="S4.T2.2.2.2.1.1.m1.1.1.3.cmml" xref="S4.T2.2.2.2.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.1.1.m1.1c">39M</annotation></semantics></math>)</span></th>
</tr>
<tr id="S4.T2.3.3.3" class="ltx_tr">
<th id="S4.T2.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="S4.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="S4.T2.3.3.3.1.m1.1a"><mrow id="S4.T2.3.3.3.1.m1.1.1" xref="S4.T2.3.3.3.1.m1.1.1.cmml"><mn id="S4.T2.3.3.3.1.m1.1.1.2" xref="S4.T2.3.3.3.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="S4.T2.3.3.3.1.m1.1.1.1" xref="S4.T2.3.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.3.3.3.1.m1.1.1.3" xref="S4.T2.3.3.3.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.1.m1.1b"><apply id="S4.T2.3.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.3.1.m1.1.1"><times id="S4.T2.3.3.3.1.m1.1.1.1.cmml" xref="S4.T2.3.3.3.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.3.3.3.1.m1.1.1.2.cmml" xref="S4.T2.3.3.3.1.m1.1.1.2">70</cn><ci id="S4.T2.3.3.3.1.m1.1.1.3.cmml" xref="S4.T2.3.3.3.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="S4.T2.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">46.2</td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">29.5</td>
<td id="S4.T2.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">24.5</td>
<td id="S4.T2.3.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">37.3</td>
<td id="S4.T2.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">46.0</td>
<td id="S4.T2.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">28.9</td>
<td id="S4.T2.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.8</td>
<td id="S4.T2.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">36.7</td>
</tr>
<tr id="S4.T2.12.12.14.2" class="ltx_tr">
<th id="S4.T2.12.12.14.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="S4.T2.12.12.14.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.7</td>
<td id="S4.T2.12.12.14.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">27.0</td>
<td id="S4.T2.12.12.14.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.6</td>
<td id="S4.T2.12.12.14.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">26.7</td>
<td id="S4.T2.12.12.14.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.3</td>
<td id="S4.T2.12.12.14.2.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.4</td>
<td id="S4.T2.12.12.14.2.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.0</td>
<td id="S4.T2.12.12.14.2.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.9</td>
</tr>
<tr id="S4.T2.12.12.15.3" class="ltx_tr">
<th id="S4.T2.12.12.15.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="S4.T2.12.12.15.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.6</td>
<td id="S4.T2.12.12.15.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.2</td>
<td id="S4.T2.12.12.15.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.2</td>
<td id="S4.T2.12.12.15.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">25.7</td>
<td id="S4.T2.12.12.15.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.2</td>
<td id="S4.T2.12.12.15.3.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.5</td>
<td id="S4.T2.12.12.15.3.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.5</td>
<td id="S4.T2.12.12.15.3.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.0</td>
</tr>
<tr id="S4.T2.12.12.16.4" class="ltx_tr">
<th id="S4.T2.12.12.16.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="S4.T2.12.12.16.4.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">34.4</td>
<td id="S4.T2.12.12.16.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.3</td>
<td id="S4.T2.12.12.16.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="S4.T2.12.12.16.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">25.5</td>
<td id="S4.T2.12.12.16.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">33.9</td>
<td id="S4.T2.12.12.16.4.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.7</td>
<td id="S4.T2.12.12.16.4.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.5</td>
<td id="S4.T2.12.12.16.4.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.7</td>
</tr>
<tr id="S4.T2.12.12.17.5" class="ltx_tr">
<th id="S4.T2.12.12.17.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="S4.T2.12.12.17.5.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">34.0</td>
<td id="S4.T2.12.12.17.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.7</td>
<td id="S4.T2.12.12.17.5.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.0</td>
<td id="S4.T2.12.12.17.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">24.7</td>
<td id="S4.T2.12.12.17.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">33.6</td>
<td id="S4.T2.12.12.17.5.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.1</td>
<td id="S4.T2.12.12.17.5.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.2</td>
<td id="S4.T2.12.12.17.5.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.9</td>
</tr>
<tr id="S4.T2.4.4.4" class="ltx_tr">
<th id="S4.T2.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="S4.T2.4.4.4.1.1" class="ltx_text ltx_font_bold">Whisper-base (<math id="S4.T2.4.4.4.1.1.m1.1" class="ltx_Math" alttext="74M" display="inline"><semantics id="S4.T2.4.4.4.1.1.m1.1a"><mrow id="S4.T2.4.4.4.1.1.m1.1.1" xref="S4.T2.4.4.4.1.1.m1.1.1.cmml"><mn id="S4.T2.4.4.4.1.1.m1.1.1.2" xref="S4.T2.4.4.4.1.1.m1.1.1.2.cmml">74</mn><mo lspace="0em" rspace="0em" id="S4.T2.4.4.4.1.1.m1.1.1.1" xref="S4.T2.4.4.4.1.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.4.4.4.1.1.m1.1.1.3" xref="S4.T2.4.4.4.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.1.1.m1.1b"><apply id="S4.T2.4.4.4.1.1.m1.1.1.cmml" xref="S4.T2.4.4.4.1.1.m1.1.1"><times id="S4.T2.4.4.4.1.1.m1.1.1.1.cmml" xref="S4.T2.4.4.4.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.4.4.4.1.1.m1.1.1.2.cmml" xref="S4.T2.4.4.4.1.1.m1.1.1.2">74</cn><ci id="S4.T2.4.4.4.1.1.m1.1.1.3.cmml" xref="S4.T2.4.4.4.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.1.1.m1.1c">74M</annotation></semantics></math>)</span></th>
</tr>
<tr id="S4.T2.5.5.5" class="ltx_tr">
<th id="S4.T2.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="S4.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="S4.T2.5.5.5.1.m1.1a"><mrow id="S4.T2.5.5.5.1.m1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.cmml"><mn id="S4.T2.5.5.5.1.m1.1.1.2" xref="S4.T2.5.5.5.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="S4.T2.5.5.5.1.m1.1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.5.5.5.1.m1.1.1.3" xref="S4.T2.5.5.5.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.1.m1.1b"><apply id="S4.T2.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1"><times id="S4.T2.5.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.5.5.5.1.m1.1.1.2.cmml" xref="S4.T2.5.5.5.1.m1.1.1.2">70</cn><ci id="S4.T2.5.5.5.1.m1.1.1.3.cmml" xref="S4.T2.5.5.5.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="S4.T2.5.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">39.7</td>
<td id="S4.T2.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.9</td>
<td id="S4.T2.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20.2</td>
<td id="S4.T2.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">28.4</td>
<td id="S4.T2.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">39.4</td>
<td id="S4.T2.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.3</td>
<td id="S4.T2.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">19.5</td>
<td id="S4.T2.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">27.6</td>
</tr>
<tr id="S4.T2.12.12.18.6" class="ltx_tr">
<th id="S4.T2.12.12.18.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="S4.T2.12.12.18.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.9</td>
<td id="S4.T2.12.12.18.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.2</td>
<td id="S4.T2.12.12.18.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.3</td>
<td id="S4.T2.12.12.18.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">23.0</td>
<td id="S4.T2.12.12.18.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.6</td>
<td id="S4.T2.12.12.18.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.5</td>
<td id="S4.T2.12.12.18.6.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
<td id="S4.T2.12.12.18.6.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.3</td>
</tr>
<tr id="S4.T2.12.12.19.7" class="ltx_tr">
<th id="S4.T2.12.12.19.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="S4.T2.12.12.19.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.4</td>
<td id="S4.T2.12.12.19.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.4</td>
<td id="S4.T2.12.12.19.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
<td id="S4.T2.12.12.19.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">22.2</td>
<td id="S4.T2.12.12.19.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.1</td>
<td id="S4.T2.12.12.19.7.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.8</td>
<td id="S4.T2.12.12.19.7.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.1</td>
<td id="S4.T2.12.12.19.7.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.5</td>
</tr>
<tr id="S4.T2.12.12.20.8" class="ltx_tr">
<th id="S4.T2.12.12.20.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="S4.T2.12.12.20.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.0</td>
<td id="S4.T2.12.12.20.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.6</td>
<td id="S4.T2.12.12.20.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
<td id="S4.T2.12.12.20.8.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">22.0</td>
<td id="S4.T2.12.12.20.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.6</td>
<td id="S4.T2.12.12.20.8.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.0</td>
<td id="S4.T2.12.12.20.8.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.9</td>
<td id="S4.T2.12.12.20.8.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.2</td>
</tr>
<tr id="S4.T2.12.12.21.9" class="ltx_tr">
<th id="S4.T2.12.12.21.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="S4.T2.12.12.21.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.7</td>
<td id="S4.T2.12.12.21.9.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.0</td>
<td id="S4.T2.12.12.21.9.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
<td id="S4.T2.12.12.21.9.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="S4.T2.12.12.21.9.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.2</td>
<td id="S4.T2.12.12.21.9.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.4</td>
<td id="S4.T2.12.12.21.9.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="S4.T2.12.12.21.9.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.7</td>
</tr>
<tr id="S4.T2.6.6.6" class="ltx_tr">
<th id="S4.T2.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="S4.T2.6.6.6.1.1" class="ltx_text ltx_font_bold">Whisper-small (<math id="S4.T2.6.6.6.1.1.m1.1" class="ltx_Math" alttext="244M" display="inline"><semantics id="S4.T2.6.6.6.1.1.m1.1a"><mrow id="S4.T2.6.6.6.1.1.m1.1.1" xref="S4.T2.6.6.6.1.1.m1.1.1.cmml"><mn id="S4.T2.6.6.6.1.1.m1.1.1.2" xref="S4.T2.6.6.6.1.1.m1.1.1.2.cmml">244</mn><mo lspace="0em" rspace="0em" id="S4.T2.6.6.6.1.1.m1.1.1.1" xref="S4.T2.6.6.6.1.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.6.6.6.1.1.m1.1.1.3" xref="S4.T2.6.6.6.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.1.1.m1.1b"><apply id="S4.T2.6.6.6.1.1.m1.1.1.cmml" xref="S4.T2.6.6.6.1.1.m1.1.1"><times id="S4.T2.6.6.6.1.1.m1.1.1.1.cmml" xref="S4.T2.6.6.6.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.6.6.6.1.1.m1.1.1.2.cmml" xref="S4.T2.6.6.6.1.1.m1.1.1.2">244</cn><ci id="S4.T2.6.6.6.1.1.m1.1.1.3.cmml" xref="S4.T2.6.6.6.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.1.1.m1.1c">244M</annotation></semantics></math>)</span></th>
</tr>
<tr id="S4.T2.7.7.7" class="ltx_tr">
<th id="S4.T2.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="S4.T2.7.7.7.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="S4.T2.7.7.7.1.m1.1a"><mrow id="S4.T2.7.7.7.1.m1.1.1" xref="S4.T2.7.7.7.1.m1.1.1.cmml"><mn id="S4.T2.7.7.7.1.m1.1.1.2" xref="S4.T2.7.7.7.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="S4.T2.7.7.7.1.m1.1.1.1" xref="S4.T2.7.7.7.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.7.7.7.1.m1.1.1.3" xref="S4.T2.7.7.7.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.1.m1.1b"><apply id="S4.T2.7.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.7.1.m1.1.1"><times id="S4.T2.7.7.7.1.m1.1.1.1.cmml" xref="S4.T2.7.7.7.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.7.7.7.1.m1.1.1.2.cmml" xref="S4.T2.7.7.7.1.m1.1.1.2">70</cn><ci id="S4.T2.7.7.7.1.m1.1.1.3.cmml" xref="S4.T2.7.7.7.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="S4.T2.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.1</td>
<td id="S4.T2.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">22.4</td>
<td id="S4.T2.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.2</td>
<td id="S4.T2.7.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.5</td>
<td id="S4.T2.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20.8</td>
<td id="S4.T2.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="S4.T2.7.7.7.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.4</td>
<td id="S4.T2.7.7.7.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20.6</td>
</tr>
<tr id="S4.T2.12.12.22.10" class="ltx_tr">
<th id="S4.T2.12.12.22.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="S4.T2.12.12.22.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.1</td>
<td id="S4.T2.12.12.22.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
<td id="S4.T2.12.12.22.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="S4.T2.12.12.22.10.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">20.1</td>
<td id="S4.T2.12.12.22.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.8</td>
<td id="S4.T2.12.12.22.10.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
<td id="S4.T2.12.12.22.10.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="S4.T2.12.12.22.10.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.3</td>
</tr>
<tr id="S4.T2.12.12.23.11" class="ltx_tr">
<th id="S4.T2.12.12.23.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="S4.T2.12.12.23.11.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.6</td>
<td id="S4.T2.12.12.23.11.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.1</td>
<td id="S4.T2.12.12.23.11.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.5</td>
<td id="S4.T2.12.12.23.11.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">19.3</td>
<td id="S4.T2.12.12.23.11.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.3</td>
<td id="S4.T2.12.12.23.11.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="S4.T2.12.12.23.11.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="S4.T2.12.12.23.11.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.5</td>
</tr>
<tr id="S4.T2.12.12.24.12" class="ltx_tr">
<th id="S4.T2.12.12.24.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="S4.T2.12.12.24.12.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.7</td>
<td id="S4.T2.12.12.24.12.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
<td id="S4.T2.12.12.24.12.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.4</td>
<td id="S4.T2.12.12.24.12.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">19.3</td>
<td id="S4.T2.12.12.24.12.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.3</td>
<td id="S4.T2.12.12.24.12.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.6</td>
<td id="S4.T2.12.12.24.12.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.7</td>
<td id="S4.T2.12.12.24.12.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.5</td>
</tr>
<tr id="S4.T2.12.12.25.13" class="ltx_tr">
<th id="S4.T2.12.12.25.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="S4.T2.12.12.25.13.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.4</td>
<td id="S4.T2.12.12.25.13.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="S4.T2.12.12.25.13.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.0</td>
<td id="S4.T2.12.12.25.13.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">18.8</td>
<td id="S4.T2.12.12.25.13.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.1</td>
<td id="S4.T2.12.12.25.13.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="S4.T2.12.12.25.13.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.3</td>
<td id="S4.T2.12.12.25.13.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.9</td>
</tr>
<tr id="S4.T2.8.8.8" class="ltx_tr">
<th id="S4.T2.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="S4.T2.8.8.8.1.1" class="ltx_text ltx_font_bold">Whisper-medium (<math id="S4.T2.8.8.8.1.1.m1.1" class="ltx_Math" alttext="769M" display="inline"><semantics id="S4.T2.8.8.8.1.1.m1.1a"><mrow id="S4.T2.8.8.8.1.1.m1.1.1" xref="S4.T2.8.8.8.1.1.m1.1.1.cmml"><mn id="S4.T2.8.8.8.1.1.m1.1.1.2" xref="S4.T2.8.8.8.1.1.m1.1.1.2.cmml">769</mn><mo lspace="0em" rspace="0em" id="S4.T2.8.8.8.1.1.m1.1.1.1" xref="S4.T2.8.8.8.1.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.8.8.8.1.1.m1.1.1.3" xref="S4.T2.8.8.8.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.1.1.m1.1b"><apply id="S4.T2.8.8.8.1.1.m1.1.1.cmml" xref="S4.T2.8.8.8.1.1.m1.1.1"><times id="S4.T2.8.8.8.1.1.m1.1.1.1.cmml" xref="S4.T2.8.8.8.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.8.8.8.1.1.m1.1.1.2.cmml" xref="S4.T2.8.8.8.1.1.m1.1.1.2">769</cn><ci id="S4.T2.8.8.8.1.1.m1.1.1.3.cmml" xref="S4.T2.8.8.8.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.1.1.m1.1c">769M</annotation></semantics></math>)</span></th>
</tr>
<tr id="S4.T2.9.9.9" class="ltx_tr">
<th id="S4.T2.9.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="S4.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="S4.T2.9.9.9.1.m1.1a"><mrow id="S4.T2.9.9.9.1.m1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.cmml"><mn id="S4.T2.9.9.9.1.m1.1.1.2" xref="S4.T2.9.9.9.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="S4.T2.9.9.9.1.m1.1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.9.9.9.1.m1.1.1.3" xref="S4.T2.9.9.9.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.1.m1.1b"><apply id="S4.T2.9.9.9.1.m1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1"><times id="S4.T2.9.9.9.1.m1.1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.9.9.9.1.m1.1.1.2.cmml" xref="S4.T2.9.9.9.1.m1.1.1.2">70</cn><ci id="S4.T2.9.9.9.1.m1.1.1.3.cmml" xref="S4.T2.9.9.9.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="S4.T2.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="S4.T2.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="S4.T2.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
<td id="S4.T2.9.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">18.6</td>
<td id="S4.T2.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="S4.T2.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="S4.T2.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="S4.T2.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
</tr>
<tr id="S4.T2.12.12.26.14" class="ltx_tr">
<th id="S4.T2.12.12.26.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="S4.T2.12.12.26.14.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="S4.T2.12.12.26.14.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.6</td>
<td id="S4.T2.12.12.26.14.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.9</td>
<td id="S4.T2.12.12.26.14.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">19.4</td>
<td id="S4.T2.12.12.26.14.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.2</td>
<td id="S4.T2.12.12.26.14.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="S4.T2.12.12.26.14.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.3</td>
<td id="S4.T2.12.12.26.14.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.4</td>
</tr>
<tr id="S4.T2.12.12.27.15" class="ltx_tr">
<th id="S4.T2.12.12.27.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="S4.T2.12.12.27.15.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="S4.T2.12.12.27.15.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="S4.T2.12.12.27.15.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="S4.T2.12.12.27.15.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">18.6</td>
<td id="S4.T2.12.12.27.15.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="S4.T2.12.12.27.15.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.1</td>
<td id="S4.T2.12.12.27.15.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.9</td>
<td id="S4.T2.12.12.27.15.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.7</td>
</tr>
<tr id="S4.T2.12.12.28.16" class="ltx_tr">
<th id="S4.T2.12.12.28.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="S4.T2.12.12.28.16.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="S4.T2.12.12.28.16.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="S4.T2.12.12.28.16.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="S4.T2.12.12.28.16.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">18.6</td>
<td id="S4.T2.12.12.28.16.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.5</td>
<td id="S4.T2.12.12.28.16.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="S4.T2.12.12.28.16.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.9</td>
<td id="S4.T2.12.12.28.16.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.7</td>
</tr>
<tr id="S4.T2.12.12.29.17" class="ltx_tr">
<th id="S4.T2.12.12.29.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="S4.T2.12.12.29.17.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="S4.T2.12.12.29.17.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.5</td>
<td id="S4.T2.12.12.29.17.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.3</td>
<td id="S4.T2.12.12.29.17.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">18.1</td>
<td id="S4.T2.12.12.29.17.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.3</td>
<td id="S4.T2.12.12.29.17.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="S4.T2.12.12.29.17.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.6</td>
<td id="S4.T2.12.12.29.17.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
</tr>
<tr id="S4.T2.10.10.10" class="ltx_tr">
<th id="S4.T2.10.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="S4.T2.10.10.10.1.1" class="ltx_text ltx_font_bold">Whisper-large-v3 (<math id="S4.T2.10.10.10.1.1.m1.1" class="ltx_math_unparsed" alttext="1.5B)" display="inline"><semantics id="S4.T2.10.10.10.1.1.m1.1a"><mrow id="S4.T2.10.10.10.1.1.m1.1b"><mn id="S4.T2.10.10.10.1.1.m1.1.1">1.5</mn><mi id="S4.T2.10.10.10.1.1.m1.1.2">B</mi><mo stretchy="false" id="S4.T2.10.10.10.1.1.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T2.10.10.10.1.1.m1.1c">1.5B)</annotation></semantics></math></span></th>
</tr>
<tr id="S4.T2.11.11.11" class="ltx_tr">
<th id="S4.T2.11.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="S4.T2.11.11.11.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="S4.T2.11.11.11.1.m1.1a"><mrow id="S4.T2.11.11.11.1.m1.1.1" xref="S4.T2.11.11.11.1.m1.1.1.cmml"><mn id="S4.T2.11.11.11.1.m1.1.1.2" xref="S4.T2.11.11.11.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="S4.T2.11.11.11.1.m1.1.1.1" xref="S4.T2.11.11.11.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.11.11.11.1.m1.1.1.3" xref="S4.T2.11.11.11.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.1.m1.1b"><apply id="S4.T2.11.11.11.1.m1.1.1.cmml" xref="S4.T2.11.11.11.1.m1.1.1"><times id="S4.T2.11.11.11.1.m1.1.1.1.cmml" xref="S4.T2.11.11.11.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.11.11.11.1.m1.1.1.2.cmml" xref="S4.T2.11.11.11.1.m1.1.1.2">70</cn><ci id="S4.T2.11.11.11.1.m1.1.1.3.cmml" xref="S4.T2.11.11.11.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="S4.T2.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">22.5</td>
<td id="S4.T2.11.11.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="S4.T2.11.11.11.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="S4.T2.11.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.5</td>
<td id="S4.T2.11.11.11.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.8</td>
<td id="S4.T2.11.11.11.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="S4.T2.11.11.11.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.1</td>
<td id="S4.T2.11.11.11.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
</tr>
<tr id="S4.T2.12.12.30.18" class="ltx_tr">
<th id="S4.T2.12.12.30.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="S4.T2.12.12.30.18.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.6</td>
<td id="S4.T2.12.12.30.18.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.3</td>
<td id="S4.T2.12.12.30.18.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="S4.T2.12.12.30.18.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">18.4</td>
<td id="S4.T2.12.12.30.18.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="S4.T2.12.12.30.18.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="S4.T2.12.12.30.18.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.0</td>
<td id="S4.T2.12.12.30.18.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
</tr>
<tr id="S4.T2.12.12.31.19" class="ltx_tr">
<th id="S4.T2.12.12.31.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="S4.T2.12.12.31.19.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.2</td>
<td id="S4.T2.12.12.31.19.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="S4.T2.12.12.31.19.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.2</td>
<td id="S4.T2.12.12.31.19.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
<td id="S4.T2.12.12.31.19.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="S4.T2.12.12.31.19.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.9</td>
<td id="S4.T2.12.12.31.19.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.6</td>
<td id="S4.T2.12.12.31.19.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.8</td>
</tr>
<tr id="S4.T2.12.12.32.20" class="ltx_tr">
<th id="S4.T2.12.12.32.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="S4.T2.12.12.32.20.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.0</td>
<td id="S4.T2.12.12.32.20.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="S4.T2.12.12.32.20.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.1</td>
<td id="S4.T2.12.12.32.20.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
<td id="S4.T2.12.12.32.20.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="S4.T2.12.12.32.20.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.1</td>
<td id="S4.T2.12.12.32.20.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.5</td>
<td id="S4.T2.12.12.32.20.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.0</td>
</tr>
<tr id="S4.T2.12.12.33.21" class="ltx_tr">
<th id="S4.T2.12.12.33.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="S4.T2.12.12.33.21.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="S4.T2.12.12.33.21.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="S4.T2.12.12.33.21.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.8</td>
<td id="S4.T2.12.12.33.21.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
<td id="S4.T2.12.12.33.21.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.5</td>
<td id="S4.T2.12.12.33.21.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="S4.T2.12.12.33.21.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.2</td>
<td id="S4.T2.12.12.33.21.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
</tr>
<tr id="S4.T2.12.12.34.22" class="ltx_tr">
<th id="S4.T2.12.12.34.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="S4.T2.12.12.34.22.1.1" class="ltx_text ltx_font_bold">Baseline streaming Zipformer (only supervised data)</span></th>
</tr>
<tr id="S4.T2.12.12.12" class="ltx_tr">
<th id="S4.T2.12.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="S4.T2.12.12.12.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="S4.T2.12.12.12.1.m1.1a"><mrow id="S4.T2.12.12.12.1.m1.1.1" xref="S4.T2.12.12.12.1.m1.1.1.cmml"><mn id="S4.T2.12.12.12.1.m1.1.1.2" xref="S4.T2.12.12.12.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="S4.T2.12.12.12.1.m1.1.1.1" xref="S4.T2.12.12.12.1.m1.1.1.1.cmml">​</mo><mi id="S4.T2.12.12.12.1.m1.1.1.3" xref="S4.T2.12.12.12.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.1.m1.1b"><apply id="S4.T2.12.12.12.1.m1.1.1.cmml" xref="S4.T2.12.12.12.1.m1.1.1"><times id="S4.T2.12.12.12.1.m1.1.1.1.cmml" xref="S4.T2.12.12.12.1.m1.1.1.1"></times><cn type="integer" id="S4.T2.12.12.12.1.m1.1.1.2.cmml" xref="S4.T2.12.12.12.1.m1.1.1.2">70</cn><ci id="S4.T2.12.12.12.1.m1.1.1.3.cmml" xref="S4.T2.12.12.12.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="S4.T2.12.12.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">7.8</td>
<td id="S4.T2.12.12.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.8</td>
<td id="S4.T2.12.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.5</td>
<td id="S4.T2.12.12.12.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.5</td>
<td id="S4.T2.12.12.12.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">7.6</td>
<td id="S4.T2.12.12.12.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.1</td>
<td id="S4.T2.12.12.12.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">12.8</td>
<td id="S4.T2.12.12.12.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Low-latency streaming decoding</h5>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.1" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 ‣ Regularization with supervised data ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> lists the streaming decoding results across six CommonVoice languages, testing 13 different decoding configurations (see <a href="#S3.SS2" title="3.2 Transformer-Transducer Training ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). We establish an upper performance bound with models tested in non-streaming mode and also include a box plot for each TT model trained with PLs derived from various Whisper model sizes.
The results show how model performance can fluctuate under different streaming conditions, with smaller chunk sizes or limited left context posing greater challenges.</p>
</div>
<div id="S4.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p2.1" class="ltx_p">The results with the configuration with cs=320ms and lf=2.5s are also reported in Tables <a href="#S4.T2" title="Table 2 ‣ Scaling-up supervised data helps on cases with very noisy PLs ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#A2.T4" title="Table 4 ‣ Streaming models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and demonstrate consistently better performance when the full left context is used. This tendency stays independent of language and SF.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>SF with n-gram LM brings substantial WER reductions on challenging scenarios - and decoding analysis</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Performance on different models and languages with SF is presented in Table <a href="#S4.T2" title="Table 2 ‣ Scaling-up supervised data helps on cases with very noisy PLs ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Zipformer models in the table are our baselines, i.e., streaming models trained on PL data. We use the further improved models with an additional 100h of supervised data for decoding with SF. For all the languages, we can see a WER decrease when decoded with an external LM. The WER also always improves when context biasing with NEs is introduced. It is an important observation since all NEs are extracted automatically with no human supervision involved. Moreover, all biasing lists are rather long, which often is an obstacle to improvement when biasing methods are used <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>. Nevertheless, our approach proves to work on biasing lists of large sizes as well. According to our results, external LM and context NEs fusions are complementary methods, gaining the best WER when they are combined during decoding.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The improvement with SF is consistent through the languages and has the biggest impact when models are trained on weaker PLs generated from the smaller Whisper models. This behavior is expected, as the models that saw less training data have more potential to still benefit from any additional data given during regularization and/or decoding. On the other hand, the improvement decreases with the PLs generated by Whisper-medium and Whisper-large-v3.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Another remarkable observation is that the models trained on PLs are more competitive with the models trained on the supervised data only when less training data is given. For example, CA language has 1200h of training data and supervised models are considerably winning over the PL models even after all the improvements we introduce: 7.8% VS 14.8% for supervised and PL models correspondingly.<span id="footnote20" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span>Here and below in this paragraph, we report WERs for the configuration with cs=320ms and lf=2.5s. We observe the same tendency in the results with the other configuration as well.</span></span></span> When double less training data is used for DE language, i.e., 600h, the difference is less prominent but still considerable: 13.8% VS 15.3% for supervised and PL models correspondingly. When the amount of training data is further reduced to 317h for ES and 200h for IT, we observe either little or no degradation from supervised models to PL models: 13.5% VS 13.8% for ES and 17.5% VS 17.2% for IT for supervised and PL models correspondingly. These results illustrate well the advantages and strengths of the proposed framework and methods for the low-resource scenarios. Due to space constraints, in Table <a href="#S4.T2" title="Table 2 ‣ Scaling-up supervised data helps on cases with very noisy PLs ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show the performance only on four languages; SF impact on offline models for all six languages can be found in Table <a href="#A2.T3" title="Table 3 ‣ Offline models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we propose a framework to meet the challenge of training streaming ASR systems with few-to-none supervised data by leveraging PLs from foundational speech models.
We conduct a thorough examination of the efficacy of PL-based TT models across various dimensions, including offline and chunk-wise decoding for streaming applications, and the influence of FSM size on the TT model’s WERs. We introduce robust heuristics to filter out unreliable and hallucinated PLs. Our findings reveal that TT models can be effectively trained from scratch on noisy PLs. We managed to further improve the performance of models trained with weak pseudo-labels (generated by Whisper-tiny, -base, and -small) by adding regularization with different amounts of supervised data. Additionally, we prove that decoding with the shallow fusion of external n-gram LM and automatically generated named entities always improves the performance of models independent of the quality of pseudo-labels.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">One of the limitations of the paper is that the data from the CommonVoice dataset is read speech that can considerably differ from spontaneous speech and unprepared conversations. Our choice was mostly due to the possibility of testing our framework on six different languages and in this regard, CommonVoice suited us well. Besides this, models for each language were trained on a different amount of data (from 200h to 1200h) that demonstrated different impacts of the proposed methods. However, no experiments were done to see the performance with different amounts of train data within each language.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Another limitation of the paper is that despite focusing mostly on the streaming ASR models, we provide no results on the execution time. This information would be especially important for the shallow fusion experiments. Although we noted good time performance of the proposed shallow fusion implementation for offline models, the evaluation for streaming models is missing.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">All speech data sets we use have anonymous speakers. We do not have any access to nor try to create any PII of speakers.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aho and Corasick (1975)</span>
<span class="ltx_bibblock">
Alfred V Aho and Margaret J Corasick. 1975.

</span>
<span class="ltx_bibblock">Efficient string matching: an aid to bibliographic search.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 18(6):333–340.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aleksic et al. (2015)</span>
<span class="ltx_bibblock">
Petar Aleksic, Mohammadreza Ghodsi, et al. 2015.

</span>
<span class="ltx_bibblock">Bringing contextual information to google speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, pages 468–472.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardila et al. (2020)</span>
<span class="ltx_bibblock">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber. 2020.

</span>
<span class="ltx_bibblock">Common voice: A massively-multilingual speech corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 4218–4222.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Armengol-Estapé et al. (2021)</span>
<span class="ltx_bibblock">
Jordi Armengol-Estapé, Casimiro Pio Carrino, Carlos Rodriguez-Penagos, Ona de Gibert Bonet, Carme Armentano-Oller, Aitor Gonzalez-Agirre, Maite Melero, and Marta Villegas. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.findings-acl.437" title="" class="ltx_ref ltx_href">Are multilingual models the best choice for moderately under-resourced languages? A comprehensive assessment for Catalan</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>, pages 4933–4946, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski et al. (2020)</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:12449–12460.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bain et al. (2023)</span>
<span class="ltx_bibblock">
Max Bain, Jaesung Huh, Tengda Han, and Andrew Zisserman. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2023-78" title="" class="ltx_ref ltx_href">WhisperX: Time-Accurate Speech Transcription of Long-Form Audio</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proc. INTERSPEECH 2023</em>, pages 4489–4493.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barrault et al. (2023)</span>
<span class="ltx_bibblock">
Loïc Barrault, Yu-An Chung, Mariano Cora Meglioli, David Dale, Ning Dong, Paul-Ambroise Duquenne, Hady Elsahar, Hongyu Gong, Kevin Heffernan, John Hoffman, et al. 2023.

</span>
<span class="ltx_bibblock">Seamlessm4t-massively multilingual &amp; multimodal machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.11596</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bartelds et al. (2023)</span>
<span class="ltx_bibblock">
Martijn Bartelds, Nay San, Bradley McDonnell, Dan Jurafsky, and Martijn Wieling. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.42" title="" class="ltx_ref ltx_href">Making more of little data: Improving low-resource automatic speech recognition using data augmentation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 715–729, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Battenberg et al. (2017)</span>
<span class="ltx_bibblock">
Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur Yi Li, Hairong Liu, Sanjeev Satheesh, Anuroop Sriram, and Zhenyao Zhu. 2017.

</span>
<span class="ltx_bibblock">Exploring neural transducers for end-to-end speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2017 IEEE automatic speech recognition and understanding workshop (ASRU)</em>, pages 206–213. IEEE.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berrebbi et al. (2022)</span>
<span class="ltx_bibblock">
Dan Berrebbi, Ronan Collobert, Samy Bengio, Navdeep Jaitly, and Tatiana Likhomanenko. 2022.

</span>
<span class="ltx_bibblock">Continuous pseudo-labeling from the start.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chebotar and Waters (2016)</span>
<span class="ltx_bibblock">
Yevgen Chebotar and Austin Waters. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2016-1190" title="" class="ltx_ref ltx_href">Distilling Knowledge from Ensembles of Neural Networks for Speech Recognition</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2016</em>, pages 3439–3443.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Guoguo Chen, Shuzhou Chai, Guan-Bo Wang, Jiayu Du, Wei-Qiang Zhang, Chao Weng, Dan Su, Daniel Povey, Jan Trmal, Junbo Zhang, Mingjie Jin, Sanjeev Khudanpur, Shinji Watanabe, Shuaijiang Zhao, Wei Zou, Xiangang Li, Xuchen Yao, Yongqing Wang, Zhao You, and Zhiyong Yan. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2021-1965" title="" class="ltx_ref ltx_href">GigaSpeech: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, pages 3670–3674.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2019)</span>
<span class="ltx_bibblock">
Zhehuai Chen, Mahaveer Jain, Yongqiang Wang, Michael L Seltzer, and Christian Fuegen. 2019.

</span>
<span class="ltx_bibblock">End-to-end contextual speech recognition using class language models and a token passing decoder.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proc. of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 6186–6190. IEEE.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiu et al. (2022)</span>
<span class="ltx_bibblock">
Chung-Cheng Chiu, James Qin, Yu Zhang, Jiahui Yu, and Yonghui Wu. 2022.

</span>
<span class="ltx_bibblock">Self-supervised learning with random-projection quantizer for speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 3915–3924. PMLR.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2020)</span>
<span class="ltx_bibblock">
Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning for speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.13979</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferraz et al. (2024)</span>
<span class="ltx_bibblock">
Thomas Palmeira Ferraz, Marcely Zanon Boito, Caroline Brun, and Vassilina Nikoulina. 2024.

</span>
<span class="ltx_bibblock">Multilingual distilwhisper: Efficient distillation of multi-task speech models via language-specific experts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gandhi et al. (2023)</span>
<span class="ltx_bibblock">
Sanchit Gandhi, Patrick von Platen, and Alexander M Rush. 2023.

</span>
<span class="ltx_bibblock">Distil-whisper: Robust knowledge distillation via large-scale pseudo labelling.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.00430</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Dongji Gao, Matthew Wiesner, Hainan Xu, Leibny Paola Garcia, Daniel Povey, and Sanjeev Khudanpur. 2023.

</span>
<span class="ltx_bibblock">Bypass temporal classification: Weakly supervised automatic speech recognition with imperfect transcripts.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.01031</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghodsi et al. (2020)</span>
<span class="ltx_bibblock">
Mohammadreza Ghodsi, Xiaofeng Liu, James Apfel, Rodrigo Cabrera, and Eugene Weinstein. 2020.

</span>
<span class="ltx_bibblock">Rnn-transducer with stateless prediction network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 7049–7053. IEEE.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves (2012)</span>
<span class="ltx_bibblock">
Alex Graves. 2012.

</span>
<span class="ltx_bibblock">Sequence transduction with recurrent neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1211.3711</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. (2006)</span>
<span class="ltx_bibblock">
Alex Graves, Santiago Fernández, Faustino J. Gomez, and Jürgen Schmidhuber. 2006.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/1143844.1143891" title="" class="ltx_ref ltx_href">Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Machine Learning, Proceedings of the Twenty-Third International Conference (ICML 2006), Pittsburgh, Pennsylvania, USA, June 25-29, 2006</em>, volume 148 of <em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic">ACM International Conference Proceeding Series</em>, pages 369–376. ACM.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2023)</span>
<span class="ltx_bibblock">
Yachao Guo, Zhibin Qiu, Hao Huang, and Chng Eng Siong. 2023.

</span>
<span class="ltx_bibblock">Improved keyword recognition based on aho-corasick automaton.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2023 International Joint Conference on Neural Networks (IJCNN)</em>, pages 1–7. IEEE.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Higuchi et al. (2021)</span>
<span class="ltx_bibblock">
Yosuke Higuchi, Niko Moritz, Jonathan Le Roux, and Takaaki Hori. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2021-571" title="" class="ltx_ref ltx_href">Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, pages 726–730.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. (2021)</span>
<span class="ltx_bibblock">
Wei-Ning Hsu, Yao-Hung Hubert Tsai, Benjamin Bolte, Ruslan Salakhutdinov, and Abdelrahman Mohamed. 2021.

</span>
<span class="ltx_bibblock">Hubert: How much can a bad teacher benefit asr pre-training?

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 6533–6537. IEEE.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jung et al. (2022)</span>
<span class="ltx_bibblock">
Namkyu Jung, Geonmin Kim, and Joon Son Chung. 2022.

</span>
<span class="ltx_bibblock">Spell my name: keyword boosted speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 6642–6646. IEEE.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kannan et al. (2018)</span>
<span class="ltx_bibblock">
Anjuli Kannan, Yonghui Wu, Patrick Nguyen, Tara N Sainath, Zhijeng Chen, and Rohit Prabhavalkar. 2018.

</span>
<span class="ltx_bibblock">An analysis of incorporating an external language model into a sequence-to-sequence model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 1–5828. IEEE.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2014)</span>
<span class="ltx_bibblock">
Diederik P Kingma and Jimmy Ba. 2014.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuang et al. (2022)</span>
<span class="ltx_bibblock">
Fangjun Kuang, Liyong Guo, Wei Kang, Long Lin, Mingshuang Luo, Zengwei Yao, and Daniel Povey. 2022.

</span>
<span class="ltx_bibblock">Pruned rnn-t for fast, memory-efficient asr training.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.13236</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al. (2023)</span>
<span class="ltx_bibblock">
Anurag Kumar, Ke Tan, Zhaoheng Ni, Pranay Manocha, Xiaohui Zhang, Ethan Henderson, and Buye Xu. 2023.

</span>
<span class="ltx_bibblock">Torchaudio-squim: Reference-less speech quality and intelligibility measures in torchaudio.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 1–5. IEEE.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al. (2024)</span>
<span class="ltx_bibblock">
Shashi Kumar, Srikanth Madikeri, Juan Zuluaga-Gomez, Easu Villatoro-Tello, , Iuliia Nigmatulina, Petr Motlicek, K E Manjunath, and Aravind Ganapathiraju. 2024.

</span>
<span class="ltx_bibblock">XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Submitted to INTERSPEECH 2024</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurata and Saon (2020)</span>
<span class="ltx_bibblock">
Gakuto Kurata and George Saon. 2020.

</span>
<span class="ltx_bibblock">Knowledge distillation from offline to streaming rnn transducer for end-to-end speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, pages 2117–2121.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lhoest et al. (2021)</span>
<span class="ltx_bibblock">
Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, et al. 2021.

</span>
<span class="ltx_bibblock">Datasets: A community library for natural language processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.02846</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Bo Li, Shuo-yiin Chang, Tara N Sainath, Ruoming Pang, Yanzhang He, Trevor Strohman, and Yonghui Wu. 2020.

</span>
<span class="ltx_bibblock">Towards fast and accurate streaming end-to-end asr.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 6069–6073. IEEE.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Bo Li, Anmol Gulati, Jiahui Yu, Tara N Sainath, Chung-Cheng Chiu, Arun Narayanan, Shuo-Yiin Chang, Ruoming Pang, Yanzhang He, James Qin, et al. 2021.

</span>
<span class="ltx_bibblock">A better and faster end-to-end model for streaming asr.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 5634–5638. IEEE.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Likhomanenko et al. (2022)</span>
<span class="ltx_bibblock">
Tatiana Likhomanenko, Ronan Collobert, Navdeep Jaitly, and Samy Bengio. 2022.

</span>
<span class="ltx_bibblock">Continuous soft pseudo-labeling in asr.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">I Can’t Believe It’s Not Better Workshop: Understanding Deep Learning Through Empirical Falsification</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lugosch et al. (2022)</span>
<span class="ltx_bibblock">
Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert. 2022.

</span>
<span class="ltx_bibblock">Pseudo-labeling for massively multilingual speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 7687–7691. IEEE.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noroozi et al. (2023)</span>
<span class="ltx_bibblock">
Vahid Noroozi, Somshubra Majumdar, Ankur Kumar, Jagadeesh Balam, and Boris Ginsburg. 2023.

</span>
<span class="ltx_bibblock">Stateful fastconformer with cache-based inference for streaming automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.17279</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov et al. (2015)</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015.

</span>
<span class="ltx_bibblock">Librispeech: an ASR corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 5206–5210. IEEE.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panchapagesan et al. (2021)</span>
<span class="ltx_bibblock">
Sankaran Panchapagesan, Daniel S Park, Chung-Cheng Chiu, Yuan Shangguan, Qiao Liang, and Alexander Gruenstein. 2021.

</span>
<span class="ltx_bibblock">Efficient knowledge distillation for rnn-transducer models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 5639–5643. IEEE.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. (2019)</span>
<span class="ltx_bibblock">
Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D. Cubuk, and Quoc V. Le. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2019-2680" title="" class="ltx_ref ltx_href">SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, pages 2613–2617.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prabhavalkar et al. (2023)</span>
<span class="ltx_bibblock">
Rohit Prabhavalkar, Takaaki Hori, Tara N Sainath, Ralf Schlüter, and Shinji Watanabe. 2023.

</span>
<span class="ltx_bibblock">End-to-end speech recognition: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pratap et al. (2023)</span>
<span class="ltx_bibblock">
Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, et al. 2023.

</span>
<span class="ltx_bibblock">Scaling speech technology to 1,000+ languages.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13516</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2022)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.04356" title="" class="ltx_ref ltx_href">Robust speech recognition via large-scale weak supervision</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ArXiv preprint</em>, abs/2212.04356.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">OpenAI blog</em>, 1(8):9.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rekesh et al. (2023)</span>
<span class="ltx_bibblock">
Dima Rekesh, Nithin Rao Koluguri, Samuel Kriman, Somshubra Majumdar, Vahid Noroozi, He Huang, Oleksii Hrinchuk, Krishna Puvvada, Ankur Kumar, Jagadeesh Balam, et al. 2023.

</span>
<span class="ltx_bibblock">Fast conformer with linearly scalable attention for efficient speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>, pages 1–8. IEEE.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sainath et al. (2020)</span>
<span class="ltx_bibblock">
Tara N Sainath, Yanzhang He, Bo Li, Arun Narayanan, Ruoming Pang, Antoine Bruguier, Shuo-yiin Chang, Wei Li, Raziel Alvarez, Zhifeng Chen, et al. 2020.

</span>
<span class="ltx_bibblock">A streaming on-device end-to-end model surpassing server-side conventional model quality and latency.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 6059–6063. IEEE.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stolcke (2002)</span>
<span class="ltx_bibblock">
Andreas Stolcke. 2002.

</span>
<span class="ltx_bibblock">Srilm-an extensible language modeling toolkit.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Seventh international conference on spoken language processing</em>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Swietojanski et al. (2023)</span>
<span class="ltx_bibblock">
Pawel Swietojanski, Stefan Braun, et al. 2023.

</span>
<span class="ltx_bibblock">Variable attention masking for configurable transformer transducer speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 1–5. IEEE.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Takashima et al. (2018)</span>
<span class="ltx_bibblock">
Ryoichi Takashima, Sheng Li, and Hisashi Kawai. 2018.

</span>
<span class="ltx_bibblock">An investigation of a knowledge distillation method for ctc acoustic models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 5809–5813. IEEE.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tedeschi et al. (2021)</span>
<span class="ltx_bibblock">
Simone Tedeschi, Valentino Maiorca, Niccolò Campolungo, Francesco Cecconi, and Roberto Navigli. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.findings-emnlp.215" title="" class="ltx_ref ltx_href">WikiNEuRal: Combined neural and knowledge-based silver data creation for multilingual NER</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 2521–2533, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Watanabe et al. (2017a)</span>
<span class="ltx_bibblock">
Shinji Watanabe, Takaaki Hori, Suyoun Kim, John R Hershey, and Tomoki Hayashi. 2017a.

</span>
<span class="ltx_bibblock">Hybrid ctc/attention architecture for end-to-end speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</em>, 11(8):1240–1253.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Watanabe et al. (2017b)</span>
<span class="ltx_bibblock">
Shinji Watanabe, Takaaki Hori, Jonathan Le Roux, and John R Hershey. 2017b.

</span>
<span class="ltx_bibblock">Student-teacher network learning with enhanced features.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 5275–5279. IEEE.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al. (2020)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. 2020.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations</em>, pages 38–45.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2022a)</span>
<span class="ltx_bibblock">
Haichuan Yang, Yuan Shangguan, Dilin Wang, Meng Li, Pierce Chuang, Xiaohui Zhang, Ganesh Venkatesh, Ozlem Kalinli, and Vikas Chandra. 2022a.

</span>
<span class="ltx_bibblock">Omni-sparsity dnn: Fast sparsity optimization for on-device streaming e2e asr via supernet.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 8197–8201. IEEE.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2022b)</span>
<span class="ltx_bibblock">
Xiaoyu Yang, Qiujia Li, and Philip C Woodland. 2022b.

</span>
<span class="ltx_bibblock">Knowledge distillation for neural transducers from large self-supervised pre-trained models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 8527–8531. IEEE.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2023)</span>
<span class="ltx_bibblock">
Zengwei Yao, Liyong Guo, Xiaoyu Yang, Wei Kang, Fangjun Kuang, Yifan Yang, Zengrui Jin, Long Lin, and Daniel Povey. 2023.

</span>
<span class="ltx_bibblock">Zipformer: A faster and better encoder for automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.11230</em>.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeh et al. (2019)</span>
<span class="ltx_bibblock">
Ching-Feng Yeh, Jay Mahadeokar, Kaustubh Kalgaonkar, Yongqiang Wang, Duc Le, Mahaveer Jain, Kjell Schubert, Christian Fuegen, and Michael L Seltzer. 2019.

</span>
<span class="ltx_bibblock">Transformer-transducer: End-to-end speech recognition with self-attention.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.12977</em>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zavaliagkos and Colthurst (1998)</span>
<span class="ltx_bibblock">
George Zavaliagkos and Thomas Colthurst. 1998.

</span>
<span class="ltx_bibblock">Utilizing untranscribed training data to improve perfomance.

</span>
<span class="ltx_bibblock">In <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">LREC</em>, pages 317–322. Citeseer.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Żelasko et al. (2021)</span>
<span class="ltx_bibblock">
Piotr Żelasko, Daniel Povey, Jan Trmal, Sanjeev Khudanpur, et al. 2021.

</span>
<span class="ltx_bibblock">Lhotse: a speech data representation library for the modern deep learning ecosystem.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.12561</em>.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Qian Zhang, Han Lu, Hasim Sak, Anshuman Tripathi, Erik McDermott, Stephen Koo, and Shankar Kumar. 2020.

</span>
<span class="ltx_bibblock">Transformer transducer: A streamable speech recognition model with transformer encoders and rnn-t loss.

</span>
<span class="ltx_bibblock">In <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 7829–7833. IEEE.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2019)</span>
<span class="ltx_bibblock">
Ding Zhao, Tara N Sainath, David Rybach, Pat Rondon, Deepti Bhatia, Bo Li, and Ruoming Pang. 2019.

</span>
<span class="ltx_bibblock">Shallow-fusion end-to-end contextual biasing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, pages 1418–1422.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2023)</span>
<span class="ltx_bibblock">
Han Zhu, Dongji Gao, Gaofeng Cheng, Daniel Povey, Pengyuan Zhang, and Yonghong Yan. 2023.

</span>
<span class="ltx_bibblock">Alternative pseudo-labeling for semi-supervised automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zuluaga-Gomez et al. (2021)</span>
<span class="ltx_bibblock">
Juan Zuluaga-Gomez, Iuliia Nigmatulina, Amrutha Prasad, Petr Motlicek, Karel Veselý, Martin Kocour, and Igor Szöke. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2021-1373" title="" class="ltx_ref ltx_href">Contextual Semi-Supervised Learning: An Approach to Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, pages 3296–3300.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zuluaga-Gomez et al. (2023)</span>
<span class="ltx_bibblock">
Juan Zuluaga-Gomez, Amrutha Prasad, Iuliia Nigmatulina, Seyyed Saeed Sarfjoo, Petr Motlicek, Matthias Kleinert, Hartmut Helmke, Oliver Ohneiser, and Qingran Zhan. 2023.

</span>
<span class="ltx_bibblock">How does pre-trained wav2vec 2.0 perform on domain-shifted asr? an extensive benchmark on air traffic control communications.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">2022 IEEE Spoken Language Technology Workshop (SLT)</em>, pages 205–212. IEEE.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Streaming decoding configurations</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">We perform a swipe of streaming decoding evaluations under multiple low-latency settings. We evaluate the following configurations:</p>
</div>
<div id="A1.p2" class="ltx_para">
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p">Decode chunk size = 320ms with left context of 2560ms, 5120ms and full;</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p">decode chunk size = 640ms with left context of 2560ms, 5120ms and full;</p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p">decode chunk size = 1280ms with left context of 2560ms, 5120ms and full;</p>
</div>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p id="A1.I1.i4.p1.1" class="ltx_p">decode chunk size = 2560ms with left context of 2560ms, 5120ms and full.</p>
</div>
</li>
</ul>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.1" class="ltx_p">The overall results are reported in Figure <a href="#S4.F3" title="Figure 3 ‣ Regularization with supervised data ‣ 4.1 Performance on models with PL of different quality ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for each of the proposed languages.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Extended results for models trained on PL data</h2>

<section id="A2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Offline models evaluation</h5>

<div id="A2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px1.p1.1" class="ltx_p">Table <a href="#A2.T3" title="Table 3 ‣ Offline models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the WERs for Zipformer offline models trained on six CommonVoice languages with either solely PLs or a mix of PLs and a small amount of supervised data (100h). These extended results correspond to those depicted in Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Results ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> in the main paper.</p>
</div>
<figure id="A2.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>WERs for six CommonVoice languages. The Zipformer offline models are trained with pseudo-labeled data from different Whisper models. We also report WERs when a small amount of supervised data is added during training, denoted as <span id="A2.T3.15.1" class="ltx_text ltx_font_typewriter">"sup. [100h]"</span>. Note that the transducer models are trained from scratch in <math id="A2.T3.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A2.T3.2.m1.1b"><mo id="A2.T3.2.m1.1.1" xref="A2.T3.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A2.T3.2.m1.1c"><csymbol cd="latexml" id="A2.T3.2.m1.1.1.cmml" xref="A2.T3.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.2.m1.1d">\sim</annotation></semantics></math>1 day GPU time.
</figcaption>
<div id="A2.T3.13" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:761.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(37.4pt,-65.7pt) scale(1.20869453706624,1.20869453706624) ;">
<table id="A2.T3.13.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T3.13.11.12.1" class="ltx_tr">
<th id="A2.T3.13.11.12.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<td id="A2.T3.13.11.12.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="6"><span id="A2.T3.13.11.12.1.2.1" class="ltx_text ltx_font_bold">Language [hours]</span></td>
</tr>
<tr id="A2.T3.13.11.13.2" class="ltx_tr">
<th id="A2.T3.13.11.13.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A2.T3.13.11.13.2.1.1" class="ltx_text ltx_font_bold">Experiment</span></th>
<td id="A2.T3.13.11.13.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">CA</td>
<td id="A2.T3.13.11.13.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EN</td>
<td id="A2.T3.13.11.13.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">DE</td>
<td id="A2.T3.13.11.13.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">FR</td>
<td id="A2.T3.13.11.13.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ES</td>
<td id="A2.T3.13.11.13.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">IT</td>
</tr>
<tr id="A2.T3.13.11.14.3" class="ltx_tr">
<th id="A2.T3.13.11.14.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<td id="A2.T3.13.11.14.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1200</td>
<td id="A2.T3.13.11.14.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1000</td>
<td id="A2.T3.13.11.14.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">600</td>
<td id="A2.T3.13.11.14.3.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">600</td>
<td id="A2.T3.13.11.14.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">317</td>
<td id="A2.T3.13.11.14.3.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">200</td>
</tr>
<tr id="A2.T3.3.1.1" class="ltx_tr">
<th id="A2.T3.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T3.3.1.1.1.1" class="ltx_text ltx_font_bold">Whisper-tiny (<math id="A2.T3.3.1.1.1.1.m1.1" class="ltx_Math" alttext="39M" display="inline"><semantics id="A2.T3.3.1.1.1.1.m1.1a"><mrow id="A2.T3.3.1.1.1.1.m1.1.1" xref="A2.T3.3.1.1.1.1.m1.1.1.cmml"><mn id="A2.T3.3.1.1.1.1.m1.1.1.2" xref="A2.T3.3.1.1.1.1.m1.1.1.2.cmml">39</mn><mo lspace="0em" rspace="0em" id="A2.T3.3.1.1.1.1.m1.1.1.1" xref="A2.T3.3.1.1.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.3.1.1.1.1.m1.1.1.3" xref="A2.T3.3.1.1.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.3.1.1.1.1.m1.1b"><apply id="A2.T3.3.1.1.1.1.m1.1.1.cmml" xref="A2.T3.3.1.1.1.1.m1.1.1"><times id="A2.T3.3.1.1.1.1.m1.1.1.1.cmml" xref="A2.T3.3.1.1.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.3.1.1.1.1.m1.1.1.2.cmml" xref="A2.T3.3.1.1.1.1.m1.1.1.2">39</cn><ci id="A2.T3.3.1.1.1.1.m1.1.1.3.cmml" xref="A2.T3.3.1.1.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.3.1.1.1.1.m1.1c">39M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T3.13.11.15.4" class="ltx_tr">
<th id="A2.T3.13.11.15.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_citet">Radford et al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite></th>
<td id="A2.T3.13.11.15.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">51.0</td>
<td id="A2.T3.13.11.15.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">28.8</td>
<td id="A2.T3.13.11.15.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">34.5</td>
<td id="A2.T3.13.11.15.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">49.7</td>
<td id="A2.T3.13.11.15.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.3</td>
<td id="A2.T3.13.11.15.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">44.5</td>
</tr>
<tr id="A2.T3.4.2.2" class="ltx_tr">
<th id="A2.T3.4.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T3.4.2.2.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T3.4.2.2.1.m1.1a"><mrow id="A2.T3.4.2.2.1.m1.1.1" xref="A2.T3.4.2.2.1.m1.1.1.cmml"><mn id="A2.T3.4.2.2.1.m1.1.1.2" xref="A2.T3.4.2.2.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T3.4.2.2.1.m1.1.1.1" xref="A2.T3.4.2.2.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.4.2.2.1.m1.1.1.3" xref="A2.T3.4.2.2.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.4.2.2.1.m1.1b"><apply id="A2.T3.4.2.2.1.m1.1.1.cmml" xref="A2.T3.4.2.2.1.m1.1.1"><times id="A2.T3.4.2.2.1.m1.1.1.1.cmml" xref="A2.T3.4.2.2.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.4.2.2.1.m1.1.1.2.cmml" xref="A2.T3.4.2.2.1.m1.1.1.2">70</cn><ci id="A2.T3.4.2.2.1.m1.1.1.3.cmml" xref="A2.T3.4.2.2.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.4.2.2.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T3.4.2.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">41.1</td>
<td id="A2.T3.4.2.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.5</td>
<td id="A2.T3.4.2.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.7</td>
<td id="A2.T3.4.2.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">33.8</td>
<td id="A2.T3.4.2.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.1</td>
<td id="A2.T3.4.2.2.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">32.2</td>
</tr>
<tr id="A2.T3.13.11.16.5" class="ltx_tr">
<th id="A2.T3.13.11.16.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="A2.T3.13.11.16.5.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">36.8</td>
<td id="A2.T3.13.11.16.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.9</td>
<td id="A2.T3.13.11.16.5.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.6</td>
<td id="A2.T3.13.11.16.5.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.7</td>
<td id="A2.T3.13.11.16.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="A2.T3.13.11.16.5.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.8</td>
</tr>
<tr id="A2.T3.13.11.17.6" class="ltx_tr">
<th id="A2.T3.13.11.17.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T3.13.11.17.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">32.4</td>
<td id="A2.T3.13.11.17.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.0</td>
<td id="A2.T3.13.11.17.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.1</td>
<td id="A2.T3.13.11.17.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">31.3</td>
<td id="A2.T3.13.11.17.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="A2.T3.13.11.17.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.7</td>
</tr>
<tr id="A2.T3.13.11.18.7" class="ltx_tr">
<th id="A2.T3.13.11.18.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T3.13.11.18.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">32.0</td>
<td id="A2.T3.13.11.18.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.7</td>
<td id="A2.T3.13.11.18.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.5</td>
<td id="A2.T3.13.11.18.7.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30.8</td>
<td id="A2.T3.13.11.18.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="A2.T3.13.11.18.7.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.0</td>
</tr>
<tr id="A2.T3.5.3.3" class="ltx_tr">
<th id="A2.T3.5.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T3.5.3.3.1.1" class="ltx_text ltx_font_bold">Whisper-base (<math id="A2.T3.5.3.3.1.1.m1.1" class="ltx_Math" alttext="74M" display="inline"><semantics id="A2.T3.5.3.3.1.1.m1.1a"><mrow id="A2.T3.5.3.3.1.1.m1.1.1" xref="A2.T3.5.3.3.1.1.m1.1.1.cmml"><mn id="A2.T3.5.3.3.1.1.m1.1.1.2" xref="A2.T3.5.3.3.1.1.m1.1.1.2.cmml">74</mn><mo lspace="0em" rspace="0em" id="A2.T3.5.3.3.1.1.m1.1.1.1" xref="A2.T3.5.3.3.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.5.3.3.1.1.m1.1.1.3" xref="A2.T3.5.3.3.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.5.3.3.1.1.m1.1b"><apply id="A2.T3.5.3.3.1.1.m1.1.1.cmml" xref="A2.T3.5.3.3.1.1.m1.1.1"><times id="A2.T3.5.3.3.1.1.m1.1.1.1.cmml" xref="A2.T3.5.3.3.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.5.3.3.1.1.m1.1.1.2.cmml" xref="A2.T3.5.3.3.1.1.m1.1.1.2">74</cn><ci id="A2.T3.5.3.3.1.1.m1.1.1.3.cmml" xref="A2.T3.5.3.3.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.5.3.3.1.1.m1.1c">74M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T3.13.11.19.8" class="ltx_tr">
<th id="A2.T3.13.11.19.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_citet">Radford et al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite></th>
<td id="A2.T3.13.11.19.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">39.9</td>
<td id="A2.T3.13.11.19.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.9</td>
<td id="A2.T3.13.11.19.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">24.5</td>
<td id="A2.T3.13.11.19.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">37.3</td>
<td id="A2.T3.13.11.19.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">19.6</td>
<td id="A2.T3.13.11.19.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.5</td>
</tr>
<tr id="A2.T3.6.4.4" class="ltx_tr">
<th id="A2.T3.6.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T3.6.4.4.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T3.6.4.4.1.m1.1a"><mrow id="A2.T3.6.4.4.1.m1.1.1" xref="A2.T3.6.4.4.1.m1.1.1.cmml"><mn id="A2.T3.6.4.4.1.m1.1.1.2" xref="A2.T3.6.4.4.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T3.6.4.4.1.m1.1.1.1" xref="A2.T3.6.4.4.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.6.4.4.1.m1.1.1.3" xref="A2.T3.6.4.4.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.6.4.4.1.m1.1b"><apply id="A2.T3.6.4.4.1.m1.1.1.cmml" xref="A2.T3.6.4.4.1.m1.1.1"><times id="A2.T3.6.4.4.1.m1.1.1.1.cmml" xref="A2.T3.6.4.4.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.6.4.4.1.m1.1.1.2.cmml" xref="A2.T3.6.4.4.1.m1.1.1.2">70</cn><ci id="A2.T3.6.4.4.1.m1.1.1.3.cmml" xref="A2.T3.6.4.4.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.6.4.4.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T3.6.4.4.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">30.5</td>
<td id="A2.T3.6.4.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.2</td>
<td id="A2.T3.6.4.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.4</td>
<td id="A2.T3.6.4.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.7</td>
<td id="A2.T3.6.4.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="A2.T3.6.4.4.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.7</td>
</tr>
<tr id="A2.T3.13.11.20.9" class="ltx_tr">
<th id="A2.T3.13.11.20.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="A2.T3.13.11.20.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">27.9</td>
<td id="A2.T3.13.11.20.9.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.1</td>
<td id="A2.T3.13.11.20.9.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.5</td>
<td id="A2.T3.13.11.20.9.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.8</td>
<td id="A2.T3.13.11.20.9.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.6</td>
<td id="A2.T3.13.11.20.9.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.3</td>
</tr>
<tr id="A2.T3.13.11.21.10" class="ltx_tr">
<th id="A2.T3.13.11.21.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T3.13.11.21.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.0</td>
<td id="A2.T3.13.11.21.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.1</td>
<td id="A2.T3.13.11.21.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.0</td>
<td id="A2.T3.13.11.21.10.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.2</td>
<td id="A2.T3.13.11.21.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.2</td>
<td id="A2.T3.13.11.21.10.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.5</td>
</tr>
<tr id="A2.T3.13.11.22.11" class="ltx_tr">
<th id="A2.T3.13.11.22.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T3.13.11.22.11.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.7</td>
<td id="A2.T3.13.11.22.11.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.8</td>
<td id="A2.T3.13.11.22.11.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T3.13.11.22.11.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.7</td>
<td id="A2.T3.13.11.22.11.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.8</td>
<td id="A2.T3.13.11.22.11.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
</tr>
<tr id="A2.T3.7.5.5" class="ltx_tr">
<th id="A2.T3.7.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T3.7.5.5.1.1" class="ltx_text ltx_font_bold">Whisper-small (<math id="A2.T3.7.5.5.1.1.m1.1" class="ltx_Math" alttext="244M" display="inline"><semantics id="A2.T3.7.5.5.1.1.m1.1a"><mrow id="A2.T3.7.5.5.1.1.m1.1.1" xref="A2.T3.7.5.5.1.1.m1.1.1.cmml"><mn id="A2.T3.7.5.5.1.1.m1.1.1.2" xref="A2.T3.7.5.5.1.1.m1.1.1.2.cmml">244</mn><mo lspace="0em" rspace="0em" id="A2.T3.7.5.5.1.1.m1.1.1.1" xref="A2.T3.7.5.5.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.7.5.5.1.1.m1.1.1.3" xref="A2.T3.7.5.5.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.7.5.5.1.1.m1.1b"><apply id="A2.T3.7.5.5.1.1.m1.1.1.cmml" xref="A2.T3.7.5.5.1.1.m1.1.1"><times id="A2.T3.7.5.5.1.1.m1.1.1.1.cmml" xref="A2.T3.7.5.5.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.7.5.5.1.1.m1.1.1.2.cmml" xref="A2.T3.7.5.5.1.1.m1.1.1.2">244</cn><ci id="A2.T3.7.5.5.1.1.m1.1.1.3.cmml" xref="A2.T3.7.5.5.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.7.5.5.1.1.m1.1c">244M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T3.13.11.23.12" class="ltx_tr">
<th id="A2.T3.13.11.23.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_citet">Radford et al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite></th>
<td id="A2.T3.13.11.23.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.8</td>
<td id="A2.T3.13.11.23.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.5</td>
<td id="A2.T3.13.11.23.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.0</td>
<td id="A2.T3.13.11.23.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">22.7</td>
<td id="A2.T3.13.11.23.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">10.3</td>
<td id="A2.T3.13.11.23.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
</tr>
<tr id="A2.T3.8.6.6" class="ltx_tr">
<th id="A2.T3.8.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T3.8.6.6.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T3.8.6.6.1.m1.1a"><mrow id="A2.T3.8.6.6.1.m1.1.1" xref="A2.T3.8.6.6.1.m1.1.1.cmml"><mn id="A2.T3.8.6.6.1.m1.1.1.2" xref="A2.T3.8.6.6.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T3.8.6.6.1.m1.1.1.1" xref="A2.T3.8.6.6.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.8.6.6.1.m1.1.1.3" xref="A2.T3.8.6.6.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.8.6.6.1.m1.1b"><apply id="A2.T3.8.6.6.1.m1.1.1.cmml" xref="A2.T3.8.6.6.1.m1.1.1"><times id="A2.T3.8.6.6.1.m1.1.1.1.cmml" xref="A2.T3.8.6.6.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.8.6.6.1.m1.1.1.2.cmml" xref="A2.T3.8.6.6.1.m1.1.1.2">70</cn><ci id="A2.T3.8.6.6.1.m1.1.1.3.cmml" xref="A2.T3.8.6.6.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.8.6.6.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T3.8.6.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.6</td>
<td id="A2.T3.8.6.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.1</td>
<td id="A2.T3.8.6.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.4</td>
<td id="A2.T3.8.6.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="A2.T3.8.6.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.7</td>
<td id="A2.T3.8.6.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
</tr>
<tr id="A2.T3.13.11.24.13" class="ltx_tr">
<th id="A2.T3.13.11.24.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="A2.T3.13.11.24.13.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.4</td>
<td id="A2.T3.13.11.24.13.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.9</td>
<td id="A2.T3.13.11.24.13.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.8</td>
<td id="A2.T3.13.11.24.13.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="A2.T3.13.11.24.13.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.2</td>
<td id="A2.T3.13.11.24.13.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.9</td>
</tr>
<tr id="A2.T3.13.11.25.14" class="ltx_tr">
<th id="A2.T3.13.11.25.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T3.13.11.25.14.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.1</td>
<td id="A2.T3.13.11.25.14.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="A2.T3.13.11.25.14.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.4</td>
<td id="A2.T3.13.11.25.14.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="A2.T3.13.11.25.14.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.0</td>
<td id="A2.T3.13.11.25.14.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.4</td>
</tr>
<tr id="A2.T3.13.11.26.15" class="ltx_tr">
<th id="A2.T3.13.11.26.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T3.13.11.26.15.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.9</td>
<td id="A2.T3.13.11.26.15.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T3.13.11.26.15.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.9</td>
<td id="A2.T3.13.11.26.15.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.4</td>
<td id="A2.T3.13.11.26.15.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">9.7</td>
<td id="A2.T3.13.11.26.15.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.8</td>
</tr>
<tr id="A2.T3.9.7.7" class="ltx_tr">
<th id="A2.T3.9.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T3.9.7.7.1.1" class="ltx_text ltx_font_bold">Whisper-medium (<math id="A2.T3.9.7.7.1.1.m1.1" class="ltx_Math" alttext="769M" display="inline"><semantics id="A2.T3.9.7.7.1.1.m1.1a"><mrow id="A2.T3.9.7.7.1.1.m1.1.1" xref="A2.T3.9.7.7.1.1.m1.1.1.cmml"><mn id="A2.T3.9.7.7.1.1.m1.1.1.2" xref="A2.T3.9.7.7.1.1.m1.1.1.2.cmml">769</mn><mo lspace="0em" rspace="0em" id="A2.T3.9.7.7.1.1.m1.1.1.1" xref="A2.T3.9.7.7.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.9.7.7.1.1.m1.1.1.3" xref="A2.T3.9.7.7.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.9.7.7.1.1.m1.1b"><apply id="A2.T3.9.7.7.1.1.m1.1.1.cmml" xref="A2.T3.9.7.7.1.1.m1.1.1"><times id="A2.T3.9.7.7.1.1.m1.1.1.1.cmml" xref="A2.T3.9.7.7.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.9.7.7.1.1.m1.1.1.2.cmml" xref="A2.T3.9.7.7.1.1.m1.1.1.2">769</cn><ci id="A2.T3.9.7.7.1.1.m1.1.1.3.cmml" xref="A2.T3.9.7.7.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.9.7.7.1.1.m1.1c">769M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T3.13.11.27.16" class="ltx_tr">
<th id="A2.T3.13.11.27.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_citet">Radford et al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite></th>
<td id="A2.T3.13.11.27.16.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T3.13.11.27.16.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">11.2</td>
<td id="A2.T3.13.11.27.16.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">8.5</td>
<td id="A2.T3.13.11.27.16.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="A2.T3.13.11.27.16.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">6.9</td>
<td id="A2.T3.13.11.27.16.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">9.4</td>
</tr>
<tr id="A2.T3.10.8.8" class="ltx_tr">
<th id="A2.T3.10.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T3.10.8.8.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T3.10.8.8.1.m1.1a"><mrow id="A2.T3.10.8.8.1.m1.1.1" xref="A2.T3.10.8.8.1.m1.1.1.cmml"><mn id="A2.T3.10.8.8.1.m1.1.1.2" xref="A2.T3.10.8.8.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T3.10.8.8.1.m1.1.1.1" xref="A2.T3.10.8.8.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.10.8.8.1.m1.1.1.3" xref="A2.T3.10.8.8.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.10.8.8.1.m1.1b"><apply id="A2.T3.10.8.8.1.m1.1.1.cmml" xref="A2.T3.10.8.8.1.m1.1.1"><times id="A2.T3.10.8.8.1.m1.1.1.1.cmml" xref="A2.T3.10.8.8.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.10.8.8.1.m1.1.1.2.cmml" xref="A2.T3.10.8.8.1.m1.1.1.2">70</cn><ci id="A2.T3.10.8.8.1.m1.1.1.3.cmml" xref="A2.T3.10.8.8.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.10.8.8.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T3.10.8.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.0</td>
<td id="A2.T3.10.8.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="A2.T3.10.8.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.3</td>
<td id="A2.T3.10.8.8.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.7</td>
<td id="A2.T3.10.8.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">9.5</td>
<td id="A2.T3.10.8.8.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.1</td>
</tr>
<tr id="A2.T3.13.11.28.17" class="ltx_tr">
<th id="A2.T3.13.11.28.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="A2.T3.13.11.28.17.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.7</td>
<td id="A2.T3.13.11.28.17.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T3.13.11.28.17.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.3</td>
<td id="A2.T3.13.11.28.17.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.5</td>
<td id="A2.T3.13.11.28.17.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">9.5</td>
<td id="A2.T3.13.11.28.17.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.0</td>
</tr>
<tr id="A2.T3.13.11.29.18" class="ltx_tr">
<th id="A2.T3.13.11.29.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T3.13.11.29.18.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.1</td>
<td id="A2.T3.13.11.29.18.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.2</td>
<td id="A2.T3.13.11.29.18.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.9</td>
<td id="A2.T3.13.11.29.18.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.2</td>
<td id="A2.T3.13.11.29.18.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">9.3</td>
<td id="A2.T3.13.11.29.18.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.5</td>
</tr>
<tr id="A2.T3.13.11.30.19" class="ltx_tr">
<th id="A2.T3.13.11.30.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T3.13.11.30.19.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.9</td>
<td id="A2.T3.13.11.30.19.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="A2.T3.13.11.30.19.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.4</td>
<td id="A2.T3.13.11.30.19.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.9</td>
<td id="A2.T3.13.11.30.19.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">9.0</td>
<td id="A2.T3.13.11.30.19.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.1</td>
</tr>
<tr id="A2.T3.11.9.9" class="ltx_tr">
<th id="A2.T3.11.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T3.11.9.9.1.1" class="ltx_text ltx_font_bold">Whisper-large-v3 (<math id="A2.T3.11.9.9.1.1.m1.1" class="ltx_math_unparsed" alttext="1.5B)" display="inline"><semantics id="A2.T3.11.9.9.1.1.m1.1a"><mrow id="A2.T3.11.9.9.1.1.m1.1b"><mn id="A2.T3.11.9.9.1.1.m1.1.1">1.5</mn><mi id="A2.T3.11.9.9.1.1.m1.1.2">B</mi><mo stretchy="false" id="A2.T3.11.9.9.1.1.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="A2.T3.11.9.9.1.1.m1.1c">1.5B)</annotation></semantics></math></span></th>
</tr>
<tr id="A2.T3.13.11.31.20" class="ltx_tr">
<th id="A2.T3.13.11.31.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_citet">Radford et al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite></th>
<td id="A2.T3.13.11.31.20.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.1</td>
<td id="A2.T3.13.11.31.20.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">9.4</td>
<td id="A2.T3.13.11.31.20.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">6.4</td>
<td id="A2.T3.13.11.31.20.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.9</td>
<td id="A2.T3.13.11.31.20.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">5.6</td>
<td id="A2.T3.13.11.31.20.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">7.1</td>
</tr>
<tr id="A2.T3.12.10.10" class="ltx_tr">
<th id="A2.T3.12.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T3.12.10.10.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T3.12.10.10.1.m1.1a"><mrow id="A2.T3.12.10.10.1.m1.1.1" xref="A2.T3.12.10.10.1.m1.1.1.cmml"><mn id="A2.T3.12.10.10.1.m1.1.1.2" xref="A2.T3.12.10.10.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T3.12.10.10.1.m1.1.1.1" xref="A2.T3.12.10.10.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.12.10.10.1.m1.1.1.3" xref="A2.T3.12.10.10.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.12.10.10.1.m1.1b"><apply id="A2.T3.12.10.10.1.m1.1.1.cmml" xref="A2.T3.12.10.10.1.m1.1.1"><times id="A2.T3.12.10.10.1.m1.1.1.1.cmml" xref="A2.T3.12.10.10.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.12.10.10.1.m1.1.1.2.cmml" xref="A2.T3.12.10.10.1.m1.1.1.2">70</cn><ci id="A2.T3.12.10.10.1.m1.1.1.3.cmml" xref="A2.T3.12.10.10.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.12.10.10.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T3.12.10.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.8</td>
<td id="A2.T3.12.10.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.2</td>
<td id="A2.T3.12.10.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.5</td>
<td id="A2.T3.12.10.10.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.4</td>
<td id="A2.T3.12.10.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">8.9</td>
<td id="A2.T3.12.10.10.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.1</td>
</tr>
<tr id="A2.T3.13.11.32.21" class="ltx_tr">
<th id="A2.T3.13.11.32.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+sup. [100h]</th>
<td id="A2.T3.13.11.32.21.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.6</td>
<td id="A2.T3.13.11.32.21.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.3</td>
<td id="A2.T3.13.11.32.21.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.7</td>
<td id="A2.T3.13.11.32.21.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.4</td>
<td id="A2.T3.13.11.32.21.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">9.0</td>
<td id="A2.T3.13.11.32.21.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.6</td>
</tr>
<tr id="A2.T3.13.11.33.22" class="ltx_tr">
<th id="A2.T3.13.11.33.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T3.13.11.33.22.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.1</td>
<td id="A2.T3.13.11.33.22.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="A2.T3.13.11.33.22.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.4</td>
<td id="A2.T3.13.11.33.22.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.0</td>
<td id="A2.T3.13.11.33.22.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">8.9</td>
<td id="A2.T3.13.11.33.22.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.3</td>
</tr>
<tr id="A2.T3.13.11.34.23" class="ltx_tr">
<th id="A2.T3.13.11.34.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T3.13.11.34.23.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.8</td>
<td id="A2.T3.13.11.34.23.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="A2.T3.13.11.34.23.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.0</td>
<td id="A2.T3.13.11.34.23.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">11.6</td>
<td id="A2.T3.13.11.34.23.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">8.6</td>
<td id="A2.T3.13.11.34.23.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10.8</td>
</tr>
<tr id="A2.T3.13.11.35.24" class="ltx_tr">
<th id="A2.T3.13.11.35.24.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T3.13.11.35.24.1.1" class="ltx_text ltx_font_bold">Baseline offline Zipformer (only supervised data)</span></th>
</tr>
<tr id="A2.T3.13.11.11" class="ltx_tr">
<th id="A2.T3.13.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T3.13.11.11.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T3.13.11.11.1.m1.1a"><mrow id="A2.T3.13.11.11.1.m1.1.1" xref="A2.T3.13.11.11.1.m1.1.1.cmml"><mn id="A2.T3.13.11.11.1.m1.1.1.2" xref="A2.T3.13.11.11.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T3.13.11.11.1.m1.1.1.1" xref="A2.T3.13.11.11.1.m1.1.1.1.cmml">​</mo><mi id="A2.T3.13.11.11.1.m1.1.1.3" xref="A2.T3.13.11.11.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.13.11.11.1.m1.1b"><apply id="A2.T3.13.11.11.1.m1.1.1.cmml" xref="A2.T3.13.11.11.1.m1.1.1"><times id="A2.T3.13.11.11.1.m1.1.1.1.cmml" xref="A2.T3.13.11.11.1.m1.1.1.1"></times><cn type="integer" id="A2.T3.13.11.11.1.m1.1.1.2.cmml" xref="A2.T3.13.11.11.1.m1.1.1.2">70</cn><ci id="A2.T3.13.11.11.1.m1.1.1.3.cmml" xref="A2.T3.13.11.11.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.13.11.11.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T3.13.11.11.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">4.9</td>
<td id="A2.T3.13.11.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.5</td>
<td id="A2.T3.13.11.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">8.5</td>
<td id="A2.T3.13.11.11.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">10.7</td>
<td id="A2.T3.13.11.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">8.1</td>
<td id="A2.T3.13.11.11.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">10.2</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Streaming models evaluation</h5>

<div id="A2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px2.p1.1" class="ltx_p">Table <a href="#A2.T4" title="Table 4 ‣ Streaming models evaluation ‣ Appendix B Extended results for models trained on PL data ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the WERs for Zipformer streaming models trained on four CommonVoice languages with solely PLs and evaluated on two different streaming configurations.</p>
</div>
<figure id="A2.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>WERs for streaming evaluation with n-gram LM and bias-lists (BL). Listed on four CommonVoice languages and two decoding configurations. The Zipformer models are trained with only pseudo-labeled data from different Whisper models. All experiments show additive WERs improvement when adding either (or both) n-gram LM or biasing lists.
</figcaption>
<div id="A2.T4.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:747.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(65.4pt,-112.8pt) scale(1.43213636201224,1.43213636201224) ;">
<table id="A2.T4.12.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T4.1.1.1" class="ltx_tr">
<th id="A2.T4.1.1.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<td id="A2.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4"><span id="A2.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">cs=320ms;lf=2.5s</span></td>
<td id="A2.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4"><span id="A2.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">cs=320ms;lf=<math id="A2.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="A2.T4.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A2.T4.1.1.1.1.1.m1.1.1" xref="A2.T4.1.1.1.1.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A2.T4.1.1.1.1.1.m1.1b"><infinity id="A2.T4.1.1.1.1.1.m1.1.1.cmml" xref="A2.T4.1.1.1.1.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.1.1.1.1.1.m1.1c">\infty</annotation></semantics></math></span></td>
</tr>
<tr id="A2.T4.12.12.13.1" class="ltx_tr">
<th id="A2.T4.12.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A2.T4.12.12.13.1.1.1" class="ltx_text ltx_font_bold">Experiment</span></th>
<td id="A2.T4.12.12.13.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">CA</td>
<td id="A2.T4.12.12.13.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">DE</td>
<td id="A2.T4.12.12.13.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ES</td>
<td id="A2.T4.12.12.13.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">IT</td>
<td id="A2.T4.12.12.13.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">CA</td>
<td id="A2.T4.12.12.13.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">DE</td>
<td id="A2.T4.12.12.13.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ES</td>
<td id="A2.T4.12.12.13.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">IT</td>
</tr>
<tr id="A2.T4.2.2.2" class="ltx_tr">
<th id="A2.T4.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="A2.T4.2.2.2.1.1" class="ltx_text ltx_font_bold">Whisper-tiny (<math id="A2.T4.2.2.2.1.1.m1.1" class="ltx_Math" alttext="39M" display="inline"><semantics id="A2.T4.2.2.2.1.1.m1.1a"><mrow id="A2.T4.2.2.2.1.1.m1.1.1" xref="A2.T4.2.2.2.1.1.m1.1.1.cmml"><mn id="A2.T4.2.2.2.1.1.m1.1.1.2" xref="A2.T4.2.2.2.1.1.m1.1.1.2.cmml">39</mn><mo lspace="0em" rspace="0em" id="A2.T4.2.2.2.1.1.m1.1.1.1" xref="A2.T4.2.2.2.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.2.2.2.1.1.m1.1.1.3" xref="A2.T4.2.2.2.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.2.2.2.1.1.m1.1b"><apply id="A2.T4.2.2.2.1.1.m1.1.1.cmml" xref="A2.T4.2.2.2.1.1.m1.1.1"><times id="A2.T4.2.2.2.1.1.m1.1.1.1.cmml" xref="A2.T4.2.2.2.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.2.2.2.1.1.m1.1.1.2.cmml" xref="A2.T4.2.2.2.1.1.m1.1.1.2">39</cn><ci id="A2.T4.2.2.2.1.1.m1.1.1.3.cmml" xref="A2.T4.2.2.2.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.2.2.2.1.1.m1.1c">39M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T4.3.3.3" class="ltx_tr">
<th id="A2.T4.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T4.3.3.3.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T4.3.3.3.1.m1.1a"><mrow id="A2.T4.3.3.3.1.m1.1.1" xref="A2.T4.3.3.3.1.m1.1.1.cmml"><mn id="A2.T4.3.3.3.1.m1.1.1.2" xref="A2.T4.3.3.3.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T4.3.3.3.1.m1.1.1.1" xref="A2.T4.3.3.3.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.3.3.3.1.m1.1.1.3" xref="A2.T4.3.3.3.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.3.3.3.1.m1.1b"><apply id="A2.T4.3.3.3.1.m1.1.1.cmml" xref="A2.T4.3.3.3.1.m1.1.1"><times id="A2.T4.3.3.3.1.m1.1.1.1.cmml" xref="A2.T4.3.3.3.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.3.3.3.1.m1.1.1.2.cmml" xref="A2.T4.3.3.3.1.m1.1.1.2">70</cn><ci id="A2.T4.3.3.3.1.m1.1.1.3.cmml" xref="A2.T4.3.3.3.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.3.3.3.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T4.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">46.2</td>
<td id="A2.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">29.5</td>
<td id="A2.T4.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">24.5</td>
<td id="A2.T4.3.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">37.3</td>
<td id="A2.T4.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">46.0</td>
<td id="A2.T4.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">28.9</td>
<td id="A2.T4.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.8</td>
<td id="A2.T4.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">36.7</td>
</tr>
<tr id="A2.T4.12.12.14.2" class="ltx_tr">
<th id="A2.T4.12.12.14.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T4.12.12.14.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">46.0</td>
<td id="A2.T4.12.12.14.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">29.0</td>
<td id="A2.T4.12.12.14.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.0</td>
<td id="A2.T4.12.12.14.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">36.5</td>
<td id="A2.T4.12.12.14.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">45.8</td>
<td id="A2.T4.12.12.14.2.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">28.4</td>
<td id="A2.T4.12.12.14.2.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.2</td>
<td id="A2.T4.12.12.14.2.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35.9</td>
</tr>
<tr id="A2.T4.12.12.15.3" class="ltx_tr">
<th id="A2.T4.12.12.15.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="A2.T4.12.12.15.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.7</td>
<td id="A2.T4.12.12.15.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">28.9</td>
<td id="A2.T4.12.12.15.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.7</td>
<td id="A2.T4.12.12.15.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">36.0</td>
<td id="A2.T4.12.12.15.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.6</td>
<td id="A2.T4.12.12.15.3.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">28.4</td>
<td id="A2.T4.12.12.15.3.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.0</td>
<td id="A2.T4.12.12.15.3.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35.3</td>
</tr>
<tr id="A2.T4.12.12.16.4" class="ltx_tr">
<th id="A2.T4.12.12.16.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T4.12.12.16.4.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.6</td>
<td id="A2.T4.12.12.16.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">28.4</td>
<td id="A2.T4.12.12.16.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.3</td>
<td id="A2.T4.12.12.16.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">35.3</td>
<td id="A2.T4.12.12.16.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.5</td>
<td id="A2.T4.12.12.16.4.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">28.0</td>
<td id="A2.T4.12.12.16.4.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.6</td>
<td id="A2.T4.12.12.16.4.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">34.6</td>
</tr>
<tr id="A2.T4.4.4.4" class="ltx_tr">
<th id="A2.T4.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="A2.T4.4.4.4.1.1" class="ltx_text ltx_font_bold">Whisper-base (<math id="A2.T4.4.4.4.1.1.m1.1" class="ltx_Math" alttext="74M" display="inline"><semantics id="A2.T4.4.4.4.1.1.m1.1a"><mrow id="A2.T4.4.4.4.1.1.m1.1.1" xref="A2.T4.4.4.4.1.1.m1.1.1.cmml"><mn id="A2.T4.4.4.4.1.1.m1.1.1.2" xref="A2.T4.4.4.4.1.1.m1.1.1.2.cmml">74</mn><mo lspace="0em" rspace="0em" id="A2.T4.4.4.4.1.1.m1.1.1.1" xref="A2.T4.4.4.4.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.4.4.4.1.1.m1.1.1.3" xref="A2.T4.4.4.4.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.4.4.4.1.1.m1.1b"><apply id="A2.T4.4.4.4.1.1.m1.1.1.cmml" xref="A2.T4.4.4.4.1.1.m1.1.1"><times id="A2.T4.4.4.4.1.1.m1.1.1.1.cmml" xref="A2.T4.4.4.4.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.4.4.4.1.1.m1.1.1.2.cmml" xref="A2.T4.4.4.4.1.1.m1.1.1.2">74</cn><ci id="A2.T4.4.4.4.1.1.m1.1.1.3.cmml" xref="A2.T4.4.4.4.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.4.4.4.1.1.m1.1c">74M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T4.5.5.5" class="ltx_tr">
<th id="A2.T4.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T4.5.5.5.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T4.5.5.5.1.m1.1a"><mrow id="A2.T4.5.5.5.1.m1.1.1" xref="A2.T4.5.5.5.1.m1.1.1.cmml"><mn id="A2.T4.5.5.5.1.m1.1.1.2" xref="A2.T4.5.5.5.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T4.5.5.5.1.m1.1.1.1" xref="A2.T4.5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.5.5.5.1.m1.1.1.3" xref="A2.T4.5.5.5.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.5.5.5.1.m1.1b"><apply id="A2.T4.5.5.5.1.m1.1.1.cmml" xref="A2.T4.5.5.5.1.m1.1.1"><times id="A2.T4.5.5.5.1.m1.1.1.1.cmml" xref="A2.T4.5.5.5.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.5.5.5.1.m1.1.1.2.cmml" xref="A2.T4.5.5.5.1.m1.1.1.2">70</cn><ci id="A2.T4.5.5.5.1.m1.1.1.3.cmml" xref="A2.T4.5.5.5.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.5.5.5.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T4.5.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">39.7</td>
<td id="A2.T4.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.9</td>
<td id="A2.T4.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20.2</td>
<td id="A2.T4.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">28.4</td>
<td id="A2.T4.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">39.4</td>
<td id="A2.T4.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.3</td>
<td id="A2.T4.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">19.5</td>
<td id="A2.T4.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">27.6</td>
</tr>
<tr id="A2.T4.12.12.17.5" class="ltx_tr">
<th id="A2.T4.12.12.17.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T4.12.12.17.5.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">39.1</td>
<td id="A2.T4.12.12.17.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.2</td>
<td id="A2.T4.12.12.17.5.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.8</td>
<td id="A2.T4.12.12.17.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">27.5</td>
<td id="A2.T4.12.12.17.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">38.7</td>
<td id="A2.T4.12.12.17.5.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.5</td>
<td id="A2.T4.12.12.17.5.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.0</td>
<td id="A2.T4.12.12.17.5.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.7</td>
</tr>
<tr id="A2.T4.12.12.18.6" class="ltx_tr">
<th id="A2.T4.12.12.18.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="A2.T4.12.12.18.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">36.2</td>
<td id="A2.T4.12.12.18.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.3</td>
<td id="A2.T4.12.12.18.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.6</td>
<td id="A2.T4.12.12.18.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">27.2</td>
<td id="A2.T4.12.12.18.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">36.0</td>
<td id="A2.T4.12.12.18.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.7</td>
<td id="A2.T4.12.12.18.6.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.9</td>
<td id="A2.T4.12.12.18.6.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.4</td>
</tr>
<tr id="A2.T4.12.12.19.7" class="ltx_tr">
<th id="A2.T4.12.12.19.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T4.12.12.19.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">36.0</td>
<td id="A2.T4.12.12.19.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.7</td>
<td id="A2.T4.12.12.19.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.3</td>
<td id="A2.T4.12.12.19.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">26.5</td>
<td id="A2.T4.12.12.19.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35.7</td>
<td id="A2.T4.12.12.19.7.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.2</td>
<td id="A2.T4.12.12.19.7.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.5</td>
<td id="A2.T4.12.12.19.7.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.7</td>
</tr>
<tr id="A2.T4.6.6.6" class="ltx_tr">
<th id="A2.T4.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="A2.T4.6.6.6.1.1" class="ltx_text ltx_font_bold">Whisper-small (<math id="A2.T4.6.6.6.1.1.m1.1" class="ltx_Math" alttext="244M" display="inline"><semantics id="A2.T4.6.6.6.1.1.m1.1a"><mrow id="A2.T4.6.6.6.1.1.m1.1.1" xref="A2.T4.6.6.6.1.1.m1.1.1.cmml"><mn id="A2.T4.6.6.6.1.1.m1.1.1.2" xref="A2.T4.6.6.6.1.1.m1.1.1.2.cmml">244</mn><mo lspace="0em" rspace="0em" id="A2.T4.6.6.6.1.1.m1.1.1.1" xref="A2.T4.6.6.6.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.6.6.6.1.1.m1.1.1.3" xref="A2.T4.6.6.6.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.6.6.6.1.1.m1.1b"><apply id="A2.T4.6.6.6.1.1.m1.1.1.cmml" xref="A2.T4.6.6.6.1.1.m1.1.1"><times id="A2.T4.6.6.6.1.1.m1.1.1.1.cmml" xref="A2.T4.6.6.6.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.6.6.6.1.1.m1.1.1.2.cmml" xref="A2.T4.6.6.6.1.1.m1.1.1.2">244</cn><ci id="A2.T4.6.6.6.1.1.m1.1.1.3.cmml" xref="A2.T4.6.6.6.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.6.6.6.1.1.m1.1c">244M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T4.7.7.7" class="ltx_tr">
<th id="A2.T4.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T4.7.7.7.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T4.7.7.7.1.m1.1a"><mrow id="A2.T4.7.7.7.1.m1.1.1" xref="A2.T4.7.7.7.1.m1.1.1.cmml"><mn id="A2.T4.7.7.7.1.m1.1.1.2" xref="A2.T4.7.7.7.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T4.7.7.7.1.m1.1.1.1" xref="A2.T4.7.7.7.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.7.7.7.1.m1.1.1.3" xref="A2.T4.7.7.7.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.7.7.7.1.m1.1b"><apply id="A2.T4.7.7.7.1.m1.1.1.cmml" xref="A2.T4.7.7.7.1.m1.1.1"><times id="A2.T4.7.7.7.1.m1.1.1.1.cmml" xref="A2.T4.7.7.7.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.7.7.7.1.m1.1.1.2.cmml" xref="A2.T4.7.7.7.1.m1.1.1.2">70</cn><ci id="A2.T4.7.7.7.1.m1.1.1.3.cmml" xref="A2.T4.7.7.7.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.7.7.7.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T4.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.1</td>
<td id="A2.T4.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">22.4</td>
<td id="A2.T4.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.2</td>
<td id="A2.T4.7.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.5</td>
<td id="A2.T4.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20.8</td>
<td id="A2.T4.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="A2.T4.7.7.7.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.4</td>
<td id="A2.T4.7.7.7.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20.6</td>
</tr>
<tr id="A2.T4.12.12.20.8" class="ltx_tr">
<th id="A2.T4.12.12.20.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T4.12.12.20.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.8</td>
<td id="A2.T4.12.12.20.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.8</td>
<td id="A2.T4.12.12.20.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="A2.T4.12.12.20.8.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">20.7</td>
<td id="A2.T4.12.12.20.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.5</td>
<td id="A2.T4.12.12.20.8.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.8</td>
<td id="A2.T4.12.12.20.8.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.0</td>
<td id="A2.T4.12.12.20.8.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.8</td>
</tr>
<tr id="A2.T4.12.12.21.9" class="ltx_tr">
<th id="A2.T4.12.12.21.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="A2.T4.12.12.21.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.0</td>
<td id="A2.T4.12.12.21.9.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.7</td>
<td id="A2.T4.12.12.21.9.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="A2.T4.12.12.21.9.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">20.5</td>
<td id="A2.T4.12.12.21.9.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.7</td>
<td id="A2.T4.12.12.21.9.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.6</td>
<td id="A2.T4.12.12.21.9.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="A2.T4.12.12.21.9.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.7</td>
</tr>
<tr id="A2.T4.12.12.22.10" class="ltx_tr">
<th id="A2.T4.12.12.22.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T4.12.12.22.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.8</td>
<td id="A2.T4.12.12.22.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="A2.T4.12.12.22.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.2</td>
<td id="A2.T4.12.12.22.10.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">20.0</td>
<td id="A2.T4.12.12.22.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.6</td>
<td id="A2.T4.12.12.22.10.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">20.2</td>
<td id="A2.T4.12.12.22.10.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.5</td>
<td id="A2.T4.12.12.22.10.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.1</td>
</tr>
<tr id="A2.T4.8.8.8" class="ltx_tr">
<th id="A2.T4.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="A2.T4.8.8.8.1.1" class="ltx_text ltx_font_bold">Whisper-medium (<math id="A2.T4.8.8.8.1.1.m1.1" class="ltx_Math" alttext="769M" display="inline"><semantics id="A2.T4.8.8.8.1.1.m1.1a"><mrow id="A2.T4.8.8.8.1.1.m1.1.1" xref="A2.T4.8.8.8.1.1.m1.1.1.cmml"><mn id="A2.T4.8.8.8.1.1.m1.1.1.2" xref="A2.T4.8.8.8.1.1.m1.1.1.2.cmml">769</mn><mo lspace="0em" rspace="0em" id="A2.T4.8.8.8.1.1.m1.1.1.1" xref="A2.T4.8.8.8.1.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.8.8.8.1.1.m1.1.1.3" xref="A2.T4.8.8.8.1.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.8.8.8.1.1.m1.1b"><apply id="A2.T4.8.8.8.1.1.m1.1.1.cmml" xref="A2.T4.8.8.8.1.1.m1.1.1"><times id="A2.T4.8.8.8.1.1.m1.1.1.1.cmml" xref="A2.T4.8.8.8.1.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.8.8.8.1.1.m1.1.1.2.cmml" xref="A2.T4.8.8.8.1.1.m1.1.1.2">769</cn><ci id="A2.T4.8.8.8.1.1.m1.1.1.3.cmml" xref="A2.T4.8.8.8.1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.8.8.8.1.1.m1.1c">769M</annotation></semantics></math>)</span></th>
</tr>
<tr id="A2.T4.9.9.9" class="ltx_tr">
<th id="A2.T4.9.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T4.9.9.9.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T4.9.9.9.1.m1.1a"><mrow id="A2.T4.9.9.9.1.m1.1.1" xref="A2.T4.9.9.9.1.m1.1.1.cmml"><mn id="A2.T4.9.9.9.1.m1.1.1.2" xref="A2.T4.9.9.9.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T4.9.9.9.1.m1.1.1.1" xref="A2.T4.9.9.9.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.9.9.9.1.m1.1.1.3" xref="A2.T4.9.9.9.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.9.9.9.1.m1.1b"><apply id="A2.T4.9.9.9.1.m1.1.1.cmml" xref="A2.T4.9.9.9.1.m1.1.1"><times id="A2.T4.9.9.9.1.m1.1.1.1.cmml" xref="A2.T4.9.9.9.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.9.9.9.1.m1.1.1.2.cmml" xref="A2.T4.9.9.9.1.m1.1.1.2">70</cn><ci id="A2.T4.9.9.9.1.m1.1.1.3.cmml" xref="A2.T4.9.9.9.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.9.9.9.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T4.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="A2.T4.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
<td id="A2.T4.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
<td id="A2.T4.9.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">18.6</td>
<td id="A2.T4.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T4.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="A2.T4.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
<td id="A2.T4.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
</tr>
<tr id="A2.T4.12.12.23.11" class="ltx_tr">
<th id="A2.T4.12.12.23.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T4.12.12.23.11.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T4.12.12.23.11.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="A2.T4.12.12.23.11.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.4</td>
<td id="A2.T4.12.12.23.11.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
<td id="A2.T4.12.12.23.11.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="A2.T4.12.12.23.11.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.1</td>
<td id="A2.T4.12.12.23.11.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T4.12.12.23.11.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.0</td>
</tr>
<tr id="A2.T4.12.12.24.12" class="ltx_tr">
<th id="A2.T4.12.12.24.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="A2.T4.12.12.24.12.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="A2.T4.12.12.24.12.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="A2.T4.12.12.24.12.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.0</td>
<td id="A2.T4.12.12.24.12.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.8</td>
<td id="A2.T4.12.12.24.12.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="A2.T4.12.12.24.12.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="A2.T4.12.12.24.12.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
<td id="A2.T4.12.12.24.12.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.1</td>
</tr>
<tr id="A2.T4.12.12.25.13" class="ltx_tr">
<th id="A2.T4.12.12.25.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T4.12.12.25.13.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="A2.T4.12.12.25.13.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="A2.T4.12.12.25.13.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.8</td>
<td id="A2.T4.12.12.25.13.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.3</td>
<td id="A2.T4.12.12.25.13.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.7</td>
<td id="A2.T4.12.12.25.13.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.9</td>
<td id="A2.T4.12.12.25.13.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.8</td>
<td id="A2.T4.12.12.25.13.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.5</td>
</tr>
<tr id="A2.T4.10.10.10" class="ltx_tr">
<th id="A2.T4.10.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="7"><span id="A2.T4.10.10.10.1.1" class="ltx_text ltx_font_bold">Whisper-large-v3 (<math id="A2.T4.10.10.10.1.1.m1.1" class="ltx_math_unparsed" alttext="1.5B)" display="inline"><semantics id="A2.T4.10.10.10.1.1.m1.1a"><mrow id="A2.T4.10.10.10.1.1.m1.1b"><mn id="A2.T4.10.10.10.1.1.m1.1.1">1.5</mn><mi id="A2.T4.10.10.10.1.1.m1.1.2">B</mi><mo stretchy="false" id="A2.T4.10.10.10.1.1.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="A2.T4.10.10.10.1.1.m1.1c">1.5B)</annotation></semantics></math></span></th>
<td id="A2.T4.10.10.10.2" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="A2.T4.10.10.10.3" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="A2.T4.11.11.11" class="ltx_tr">
<th id="A2.T4.11.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T4.11.11.11.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T4.11.11.11.1.m1.1a"><mrow id="A2.T4.11.11.11.1.m1.1.1" xref="A2.T4.11.11.11.1.m1.1.1.cmml"><mn id="A2.T4.11.11.11.1.m1.1.1.2" xref="A2.T4.11.11.11.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T4.11.11.11.1.m1.1.1.1" xref="A2.T4.11.11.11.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.11.11.11.1.m1.1.1.3" xref="A2.T4.11.11.11.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.11.11.11.1.m1.1b"><apply id="A2.T4.11.11.11.1.m1.1.1.cmml" xref="A2.T4.11.11.11.1.m1.1.1"><times id="A2.T4.11.11.11.1.m1.1.1.1.cmml" xref="A2.T4.11.11.11.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.11.11.11.1.m1.1.1.2.cmml" xref="A2.T4.11.11.11.1.m1.1.1.2">70</cn><ci id="A2.T4.11.11.11.1.m1.1.1.3.cmml" xref="A2.T4.11.11.11.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.11.11.11.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T4.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">22.5</td>
<td id="A2.T4.11.11.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
<td id="A2.T4.11.11.11.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="A2.T4.11.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.5</td>
<td id="A2.T4.11.11.11.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">21.8</td>
<td id="A2.T4.11.11.11.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="A2.T4.11.11.11.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.1</td>
<td id="A2.T4.11.11.11.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.7</td>
</tr>
<tr id="A2.T4.12.12.26.14" class="ltx_tr">
<th id="A2.T4.12.12.26.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM</th>
<td id="A2.T4.12.12.26.14.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.4</td>
<td id="A2.T4.12.12.26.14.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.4</td>
<td id="A2.T4.12.12.26.14.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="A2.T4.12.12.26.14.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">16.8</td>
<td id="A2.T4.12.12.26.14.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.7</td>
<td id="A2.T4.12.12.26.14.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.7</td>
<td id="A2.T4.12.12.26.14.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.9</td>
<td id="A2.T4.12.12.26.14.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.0</td>
</tr>
<tr id="A2.T4.12.12.27.15" class="ltx_tr">
<th id="A2.T4.12.12.27.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+bias-list</th>
<td id="A2.T4.12.12.27.15.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.9</td>
<td id="A2.T4.12.12.27.15.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
<td id="A2.T4.12.12.27.15.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.5</td>
<td id="A2.T4.12.12.27.15.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">16.9</td>
<td id="A2.T4.12.12.27.15.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.1</td>
<td id="A2.T4.12.12.27.15.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.9</td>
<td id="A2.T4.12.12.27.15.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.8</td>
<td id="A2.T4.12.12.27.15.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.1</td>
</tr>
<tr id="A2.T4.12.12.28.16" class="ltx_tr">
<th id="A2.T4.12.12.28.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">+n-gram LM+(BL)</th>
<td id="A2.T4.12.12.28.16.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.1</td>
<td id="A2.T4.12.12.28.16.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.2</td>
<td id="A2.T4.12.12.28.16.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="A2.T4.12.12.28.16.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">16.4</td>
<td id="A2.T4.12.12.28.16.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="A2.T4.12.12.28.16.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.5</td>
<td id="A2.T4.12.12.28.16.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="A2.T4.12.12.28.16.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.6</td>
</tr>
<tr id="A2.T4.12.12.29.17" class="ltx_tr">
<th id="A2.T4.12.12.29.17.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="9"><span id="A2.T4.12.12.29.17.1.1" class="ltx_text ltx_font_bold">Baseline streaming Zipformer (only supervised data)</span></th>
</tr>
<tr id="A2.T4.12.12.12" class="ltx_tr">
<th id="A2.T4.12.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Zipformer (<math id="A2.T4.12.12.12.1.m1.1" class="ltx_Math" alttext="70M" display="inline"><semantics id="A2.T4.12.12.12.1.m1.1a"><mrow id="A2.T4.12.12.12.1.m1.1.1" xref="A2.T4.12.12.12.1.m1.1.1.cmml"><mn id="A2.T4.12.12.12.1.m1.1.1.2" xref="A2.T4.12.12.12.1.m1.1.1.2.cmml">70</mn><mo lspace="0em" rspace="0em" id="A2.T4.12.12.12.1.m1.1.1.1" xref="A2.T4.12.12.12.1.m1.1.1.1.cmml">​</mo><mi id="A2.T4.12.12.12.1.m1.1.1.3" xref="A2.T4.12.12.12.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.12.12.12.1.m1.1b"><apply id="A2.T4.12.12.12.1.m1.1.1.cmml" xref="A2.T4.12.12.12.1.m1.1.1"><times id="A2.T4.12.12.12.1.m1.1.1.1.cmml" xref="A2.T4.12.12.12.1.m1.1.1.1"></times><cn type="integer" id="A2.T4.12.12.12.1.m1.1.1.2.cmml" xref="A2.T4.12.12.12.1.m1.1.1.2">70</cn><ci id="A2.T4.12.12.12.1.m1.1.1.3.cmml" xref="A2.T4.12.12.12.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.12.12.12.1.m1.1c">70M</annotation></semantics></math>)</th>
<td id="A2.T4.12.12.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">7.8</td>
<td id="A2.T4.12.12.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.8</td>
<td id="A2.T4.12.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.5</td>
<td id="A2.T4.12.12.12.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.5</td>
<td id="A2.T4.12.12.12.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">7.6</td>
<td id="A2.T4.12.12.12.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.1</td>
<td id="A2.T4.12.12.12.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">12.8</td>
<td id="A2.T4.12.12.12.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">16.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Filtering stage</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">As part of our efforts to reduce the amount of the hallucinated or low-quality pseudo-labels, we propose to filter out data based on some heuristics, as described in Section <a href="#S3" title="3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">In Table <a href="#A3.T5" title="Table 5 ‣ Appendix C Filtering stage ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we list the exact statistics of the maximum number of characters allowed per pseudo-labeled word for each dataset from CommonVoice. Note that languages that join words, such as German (DE) have a substantially larger threshold. Note that if a single word of the full pseudo-labeled utterance meets the threshold, we discard the entire sample.</p>
</div>
<figure id="A3.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Maximum number of characters allowed in each pseudo-labeled word with Whisper.
</figcaption>
<table id="A3.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T5.1.1.1" class="ltx_tr">
<th id="A3.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A3.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">CA</span></th>
<th id="A3.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A3.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">EN</span></th>
<th id="A3.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A3.T5.1.1.1.3.1" class="ltx_text ltx_font_bold">DE</span></th>
<th id="A3.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A3.T5.1.1.1.4.1" class="ltx_text ltx_font_bold">FR</span></th>
<th id="A3.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A3.T5.1.1.1.5.1" class="ltx_text ltx_font_bold">ES</span></th>
<th id="A3.T5.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A3.T5.1.1.1.6.1" class="ltx_text ltx_font_bold">IT</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T5.1.2.1" class="ltx_tr">
<td id="A3.T5.1.2.1.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">16</td>
<td id="A3.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">16</td>
<td id="A3.T5.1.2.1.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">30</td>
<td id="A3.T5.1.2.1.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">20</td>
<td id="A3.T5.1.2.1.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25</td>
<td id="A3.T5.1.2.1.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">22</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Call-center speech use case</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">We also evaluate our approach on a particularly important use case for industrial applications. Here, we are given 1.7k hr of unlabeled audio and our task is to train a TT system from scratch without incurring costly labeling for supervised training. This is a challenging scenario because Whisper models might not perform as well as in benchmarks due to, unseen noise or artifacts, accent or simply due to domain shift. Below, we define the database and the steps followed.</p>
</div>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Call-center database</h3>

<div id="A4.SS1.p1" class="ltx_para">
<p id="A4.SS1.p1.1" class="ltx_p">We employ a collection of unlabeled two-channel agent-user conversations of more than 10 minutes long from the call center domain. In total, there are 12.8k WAV audio files, i.e., <math id="A4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A4.SS1.p1.1.m1.1a"><mo id="A4.SS1.p1.1.m1.1.1" xref="A4.SS1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A4.SS1.p1.1.m1.1b"><csymbol cd="latexml" id="A4.SS1.p1.1.m1.1.1.cmml" xref="A4.SS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p1.1.m1.1c">\sim</annotation></semantics></math>1728 hr. We use a 54-min test set with gold annotations to evaluate our system. We generate pseudo-labels with WhisperX pipeline (§<a href="#S3.SS1" title="3.1 Pseudo Labeling with Whisper ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), though we slightly modify the VAD step to only allow up to 5 seconds of contiguous silence between contiguous segments. This process leads to 735 hrs of pure pseudo-labeled audio.</p>
</div>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Baseline performance</h3>

<div id="A4.SS2.p1" class="ltx_para">
<p id="A4.SS2.p1.1" class="ltx_p">In Figure <a href="#A4.F5" title="Figure 5 ‣ D.2 Baseline performance ‣ Appendix D Call-center speech use case ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we list a matrix with the WERs obtained by varying the Whisper model size and the maximum chunk size for the cut and merge step from WhisperX <cite class="ltx_cite ltx_citemacro_cite">Bain et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>. See more information in §<a href="#S3.SS1" title="3.1 Pseudo Labeling with Whisper ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>. Increasing model size yields better WERs while having 25-second long segments produces lower WERs overall. This is expected as the Whisper model is trained with audios of <math id="A4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A4.SS2.p1.1.m1.1a"><mo id="A4.SS2.p1.1.m1.1.1" xref="A4.SS2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="A4.SS2.p1.1.m1.1.1.cmml" xref="A4.SS2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.1.m1.1c">\sim</annotation></semantics></math>30 seconds long <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<figure id="A4.F5" class="ltx_figure"><img src="/html/2409.13499/assets/figures/whisper-model_vs_chunk_size.png" id="A4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="443" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>WERs on the test set with different Whisper model configurations and chunk sizes of the VAD model.</figcaption>
</figure>
</section>
<section id="A4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Filtering Stage</h3>

<div id="A4.SS3.p1" class="ltx_para">
<p id="A4.SS3.p1.1" class="ltx_p">We perform an exhaustive filtering stage to remove potential low-quality data. This step further reduces the dataset to 510 hours, i.e., a 30% relative reduction. We use similar heuristics as in §<a href="#S3.SS1" title="3.1 Pseudo Labeling with Whisper ‣ 3 Experimental Setup ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> to reduce the hallucinated hypotheses.<span id="footnote21" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span>An example of a hallucinated hypothesis: <span id="footnote21.1" class="ltx_text ltx_font_typewriter">utt-id-01 <span id="footnote21.1.1" class="ltx_text ltx_font_italic">let me try to turn my flashlight on okay w b a d w b a d w w w w</span></span>.</span></span></span></p>
</div>
</section>
<section id="A4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.4 </span>Additional supervised data</h3>

<div id="A4.SS4.p1" class="ltx_para">
<p id="A4.SS4.p1.1" class="ltx_p">We use GigaSpeech <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite> (GS) L subset (2.5k hours), full LibriSpeech <cite class="ltx_cite ltx_citemacro_cite">Panayotov et al. (<a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite> (LS) train set and CommonVoice English <cite class="ltx_cite ltx_citemacro_cite">Ardila et al. (<a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> (CV) train subset (1.5k hours) as extra datasets during training. This aims to regularize the training phase. In total, we use 5k hours of speech as extra datasets, while 510 hours are set as the target domain set.</p>
</div>
</section>
<section id="A4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.5 </span>Pseudo-labeled data filtering</h3>

<div id="A4.SS5.p1" class="ltx_para">
<p id="A4.SS5.p1.1" class="ltx_p">As we aim to develop an ASR system as fast as possible, we developed a process to select a subset of the PL database smartly.
We extract acoustic and text-based metadata from each <math id="A4.SS5.p1.1.m1.2" class="ltx_Math" alttext="\{X,Y^{*}\}" display="inline"><semantics id="A4.SS5.p1.1.m1.2a"><mrow id="A4.SS5.p1.1.m1.2.2.1" xref="A4.SS5.p1.1.m1.2.2.2.cmml"><mo stretchy="false" id="A4.SS5.p1.1.m1.2.2.1.2" xref="A4.SS5.p1.1.m1.2.2.2.cmml">{</mo><mi id="A4.SS5.p1.1.m1.1.1" xref="A4.SS5.p1.1.m1.1.1.cmml">X</mi><mo id="A4.SS5.p1.1.m1.2.2.1.3" xref="A4.SS5.p1.1.m1.2.2.2.cmml">,</mo><msup id="A4.SS5.p1.1.m1.2.2.1.1" xref="A4.SS5.p1.1.m1.2.2.1.1.cmml"><mi id="A4.SS5.p1.1.m1.2.2.1.1.2" xref="A4.SS5.p1.1.m1.2.2.1.1.2.cmml">Y</mi><mo id="A4.SS5.p1.1.m1.2.2.1.1.3" xref="A4.SS5.p1.1.m1.2.2.1.1.3.cmml">∗</mo></msup><mo stretchy="false" id="A4.SS5.p1.1.m1.2.2.1.4" xref="A4.SS5.p1.1.m1.2.2.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS5.p1.1.m1.2b"><set id="A4.SS5.p1.1.m1.2.2.2.cmml" xref="A4.SS5.p1.1.m1.2.2.1"><ci id="A4.SS5.p1.1.m1.1.1.cmml" xref="A4.SS5.p1.1.m1.1.1">𝑋</ci><apply id="A4.SS5.p1.1.m1.2.2.1.1.cmml" xref="A4.SS5.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="A4.SS5.p1.1.m1.2.2.1.1.1.cmml" xref="A4.SS5.p1.1.m1.2.2.1.1">superscript</csymbol><ci id="A4.SS5.p1.1.m1.2.2.1.1.2.cmml" xref="A4.SS5.p1.1.m1.2.2.1.1.2">𝑌</ci><times id="A4.SS5.p1.1.m1.2.2.1.1.3.cmml" xref="A4.SS5.p1.1.m1.2.2.1.1.3"></times></apply></set></annotation-xml><annotation encoding="application/x-tex" id="A4.SS5.p1.1.m1.2c">\{X,Y^{*}\}</annotation></semantics></math> pair. The acoustic metrics (1) STOI, PESQ and SI-SDR are computed with TorchAaudio-SQUIM <cite class="ltx_cite ltx_citemacro_cite">Kumar et al. (<a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>; (2) perplexity is computed with GPT2 <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite> using HuggingFace <cite class="ltx_cite ltx_citemacro_cite">Wolf et al. (<a href="#bib.bib55" title="" class="ltx_ref">2020</a>); Lhoest et al. (<a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> and (3) a pseudo-edit-distance metric computed by comparing different Whisper model outputs, i.e., WER metric: <span id="A4.SS5.p1.1.1" class="ltx_text ltx_font_typewriter">whisper-tiny</span>:<span id="A4.SS5.p1.1.2" class="ltx_text ltx_font_bold">hypothesis</span> &amp; <span id="A4.SS5.p1.1.3" class="ltx_text ltx_font_typewriter">whisper-large-v2</span>:<span id="A4.SS5.p1.1.4" class="ltx_text ltx_font_bold">reference</span>.</p>
</div>
</section>
<section id="A4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.6 </span>Experiments</h3>

<div id="A4.SS6.p1" class="ltx_para">
<p id="A4.SS6.p1.1" class="ltx_p">We perform two experiments for the call center use case. First, in the baseline scenario, we filter out (or select) a subset from the original PL dataset by using one or multiple metrics, e.g., perplexity and SI-SDR threshold. We use the remaining dataset for ASR training. Second, we are presented with a fixed computational budget that limits the final dataset size for model training. This leads us to select a smaller portion of the PL dataset based on i) random selection or ii) sorting the PL dataset by one metric (e.g., SI-DR) and then selecting the top samples that meet the allowed computational budget.</p>
</div>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Data Selection Based on Metrics</h2>

<div id="A5.p1" class="ltx_para">
<p id="A5.p1.1" class="ltx_p">This is the baseline scenario, where we filter the PL dataset by one or multiple metrics, and then we use the remaining dataset for ASR training. The results of this approach are listed in Table <a href="#A5.T6" title="Table 6 ‣ Appendix E Data Selection Based on Metrics ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Experiment 0) shows the WERs when using all the PL dataset, which serves as the baseline. From Exp 1) to 5) we run several filtering strategies, with some proposed metrics. Furthermore, we note that Exp 3) shows the best WERs while using 25% less data than Exp 0). This translates to faster training and convergence of the Zipformer model. In conclusion, these early experiments indicate that better WERs can be attained with fewer data points when a smart policy is in place. For instance, 0.5% absolute WER reduction, i.e., 13.9% WER (Exp 0) <math id="A5.p1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A5.p1.1.m1.1a"><mo stretchy="false" id="A5.p1.1.m1.1.1" xref="A5.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A5.p1.1.m1.1b"><ci id="A5.p1.1.m1.1.1.cmml" xref="A5.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.1.m1.1c">\rightarrow</annotation></semantics></math> 13.4% WER (Exp 3) from Table <a href="#A5.T6" title="Table 6 ‣ Appendix E Data Selection Based on Metrics ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="A5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>WERs for Zipformer models trained for 20 epochs with different data selection policies. Note that all experiments use the multi-dataset training recipe unless otherwise specified. <sup id="A5.T6.15.1" class="ltx_sup"><span id="A5.T6.15.1.1" class="ltx_text ltx_font_italic">†</span></sup>Metric computed from comparing hypothesis between Whisper <span id="A5.T6.16.2" class="ltx_text ltx_font_italic">tiny</span> and <span id="A5.T6.17.3" class="ltx_text ltx_font_italic">large-v2</span>.
</figcaption>
<div id="A5.T6.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:244.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(89.3pt,-50.4pt) scale(1.70065272721723,1.70065272721723) ;">
<table id="A5.T6.11.9" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A5.T6.11.9.10.1" class="ltx_tr">
<td id="A5.T6.11.9.10.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A5.T6.11.9.10.1.1.1" class="ltx_text ltx_font_bold">Exp</span></td>
<td id="A5.T6.11.9.10.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="5"><span id="A5.T6.11.9.10.1.2.1" class="ltx_text ltx_font_bold">Data selection policy</span></td>
<td id="A5.T6.11.9.10.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A5.T6.11.9.10.1.3.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="A5.T6.11.9.10.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A5.T6.11.9.10.1.4.1" class="ltx_text ltx_font_bold">WER</span></td>
</tr>
<tr id="A5.T6.3.1.1" class="ltx_tr">
<td id="A5.T6.3.1.1.2" class="ltx_td ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A5.T6.3.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">PPL</td>
<td id="A5.T6.3.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">STOI</td>
<td id="A5.T6.3.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">SI-SDR</td>
<td id="A5.T6.3.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">WER<sup id="A5.T6.3.1.1.1.1" class="ltx_sup"><span id="A5.T6.3.1.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
<td id="A5.T6.3.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">BLEU</td>
<td id="A5.T6.3.1.1.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A5.T6.3.1.1.7.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="A5.T6.3.1.1.8" class="ltx_td" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
</tr>
<tr id="A5.T6.11.9.11.2" class="ltx_tr">
<td id="A5.T6.11.9.11.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-)</td>
<td id="A5.T6.11.9.11.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="5">ALL data (no additional data)</td>
<td id="A5.T6.11.9.11.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">510</td>
<td id="A5.T6.11.9.11.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">15.1</td>
</tr>
<tr id="A5.T6.11.9.12.3" class="ltx_tr">
<td id="A5.T6.11.9.12.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0)</td>
<td id="A5.T6.11.9.12.3.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="5">ALL data (baseline model)</td>
<td id="A5.T6.11.9.12.3.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">510</td>
<td id="A5.T6.11.9.12.3.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">13.9</td>
</tr>
<tr id="A5.T6.6.4.4" class="ltx_tr">
<td id="A5.T6.6.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1)</td>
<td id="A5.T6.4.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.4.2.2.1.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="A5.T6.4.2.2.1.m1.1a"><mo id="A5.T6.4.2.2.1.m1.1.1" xref="A5.T6.4.2.2.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="A5.T6.4.2.2.1.m1.1b"><leq id="A5.T6.4.2.2.1.m1.1.1.cmml" xref="A5.T6.4.2.2.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.4.2.2.1.m1.1c">\leq</annotation></semantics></math> 500</td>
<td id="A5.T6.5.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.5.3.3.2.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="A5.T6.5.3.3.2.m1.1a"><mo id="A5.T6.5.3.3.2.m1.1.1" xref="A5.T6.5.3.3.2.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="A5.T6.5.3.3.2.m1.1b"><leq id="A5.T6.5.3.3.2.m1.1.1.cmml" xref="A5.T6.5.3.3.2.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.5.3.3.2.m1.1c">\leq</annotation></semantics></math> 0.7</td>
<td id="A5.T6.6.4.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.6.4.4.3.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="A5.T6.6.4.4.3.m1.1a"><mo id="A5.T6.6.4.4.3.m1.1.1" xref="A5.T6.6.4.4.3.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="A5.T6.6.4.4.3.m1.1b"><geq id="A5.T6.6.4.4.3.m1.1.1.cmml" xref="A5.T6.6.4.4.3.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.6.4.4.3.m1.1c">\geq</annotation></semantics></math> 15</td>
<td id="A5.T6.6.4.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.6.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.6.4.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">210</td>
<td id="A5.T6.6.4.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">15.1</td>
</tr>
<tr id="A5.T6.9.7.7" class="ltx_tr">
<td id="A5.T6.9.7.7.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">2)</td>
<td id="A5.T6.7.5.5.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.7.5.5.1.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="A5.T6.7.5.5.1.m1.1a"><mo id="A5.T6.7.5.5.1.m1.1.1" xref="A5.T6.7.5.5.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="A5.T6.7.5.5.1.m1.1b"><leq id="A5.T6.7.5.5.1.m1.1.1.cmml" xref="A5.T6.7.5.5.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.7.5.5.1.m1.1c">\leq</annotation></semantics></math> 800</td>
<td id="A5.T6.8.6.6.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.8.6.6.2.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="A5.T6.8.6.6.2.m1.1a"><mo id="A5.T6.8.6.6.2.m1.1.1" xref="A5.T6.8.6.6.2.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="A5.T6.8.6.6.2.m1.1b"><leq id="A5.T6.8.6.6.2.m1.1.1.cmml" xref="A5.T6.8.6.6.2.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.8.6.6.2.m1.1c">\leq</annotation></semantics></math> 0.3</td>
<td id="A5.T6.9.7.7.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.9.7.7.3.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="A5.T6.9.7.7.3.m1.1a"><mo id="A5.T6.9.7.7.3.m1.1.1" xref="A5.T6.9.7.7.3.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="A5.T6.9.7.7.3.m1.1b"><geq id="A5.T6.9.7.7.3.m1.1.1.cmml" xref="A5.T6.9.7.7.3.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.9.7.7.3.m1.1c">\geq</annotation></semantics></math> 5</td>
<td id="A5.T6.9.7.7.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.9.7.7.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.9.7.7.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">437</td>
<td id="A5.T6.9.7.7.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">13.5</td>
</tr>
<tr id="A5.T6.10.8.8" class="ltx_tr">
<td id="A5.T6.10.8.8.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3)</td>
<td id="A5.T6.10.8.8.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.10.8.8.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.10.8.8.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.10.8.8.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.10.8.8.1.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="A5.T6.10.8.8.1.m1.1a"><mo id="A5.T6.10.8.8.1.m1.1.1" xref="A5.T6.10.8.8.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="A5.T6.10.8.8.1.m1.1b"><leq id="A5.T6.10.8.8.1.m1.1.1.cmml" xref="A5.T6.10.8.8.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.10.8.8.1.m1.1c">\leq</annotation></semantics></math> 25%</td>
<td id="A5.T6.10.8.8.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.10.8.8.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">387</td>
<td id="A5.T6.10.8.8.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A5.T6.10.8.8.8.1" class="ltx_text ltx_font_bold">13.4</span></td>
</tr>
<tr id="A5.T6.11.9.9" class="ltx_tr">
<td id="A5.T6.11.9.9.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">4)</td>
<td id="A5.T6.11.9.9.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.11.9.9.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.11.9.9.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.11.9.9.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="A5.T6.11.9.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="A5.T6.11.9.9.1.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="A5.T6.11.9.9.1.m1.1a"><mo id="A5.T6.11.9.9.1.m1.1.1" xref="A5.T6.11.9.9.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="A5.T6.11.9.9.1.m1.1b"><geq id="A5.T6.11.9.9.1.m1.1.1.cmml" xref="A5.T6.11.9.9.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="A5.T6.11.9.9.1.m1.1c">\geq</annotation></semantics></math> 50</td>
<td id="A5.T6.11.9.9.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">428</td>
<td id="A5.T6.11.9.9.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">13.9</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section id="A5.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fixed Computational Budget</h5>

<div id="A5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px1.p1.1" class="ltx_p">In this setting, we are presented with a fixed computational budget, i.e., limited by the dataset sized for model training. This leads to selecting a smaller portion of the PL dataset based on i) random selection or ii) sorting the PL dataset by one metric (e.g., SI-DR) and then selecting the top samples meeting the allowed budget.
These results are listed in Table <a href="#A5.T7" title="Table 7 ‣ Fixed Computational Budget ‣ Appendix E Data Selection Based on Metrics ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We can see significant WERs improvements up to the 200h of training. After this point, bringing more PL data at training time does not improve significantly WERs. In addition, we can conclude that none of the proposed sorting metrics is significantly better than random selection for ASR training when a fixed computational budget is imposed. <span id="A5.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_bold">There are several hypotheses that can justify these results, as follows:</span></p>
<ol id="A5.I1" class="ltx_enumerate">
<li id="A5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A5.I1.i1.p1" class="ltx_para">
<p id="A5.I1.i1.p1.1" class="ltx_p">The amount of PL data brings more WERs reductions than the proposed sorting metrics;</p>
</div>
</li>
<li id="A5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A5.I1.i2.p1" class="ltx_para">
<p id="A5.I1.i2.p1.1" class="ltx_p">pseudo-labels from Whisper large-v2 are of sufficiently good quality, close to gold annotation levels;</p>
</div>
</li>
<li id="A5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A5.I1.i3.p1" class="ltx_para">
<p id="A5.I1.i3.p1.1" class="ltx_p">the filtering stage is already removing most of the noisy and/or hallucinated PLs, i.e., the remaining 510-hour subset is already of good quality overall;</p>
</div>
</li>
<li id="A5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A5.I1.i4.p1" class="ltx_para">
<p id="A5.I1.i4.p1.1" class="ltx_p">the proposed sorting metrics are not sufficiently discriminative for selecting the data required for the downstream application, i.e., random selection leads to lower WERs in some cases;</p>
</div>
</li>
<li id="A5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="A5.I1.i5.p1" class="ltx_para">
<p id="A5.I1.i5.p1.1" class="ltx_p">using supervised data at training time brings important regularization, thus minimizing the issue of using noisy PLs.</p>
</div>
</li>
</ol>
</div>
<figure id="A5.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>WERs for Zipformer models trained for 10 epochs with different computational budgets w.r.t amount of data. <sup id="A5.T7.10.1" class="ltx_sup"><span id="A5.T7.10.1.1" class="ltx_text ltx_font_italic">†</span></sup>delta of relative WER reduction 50h <math id="A5.T7.4.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A5.T7.4.m2.1b"><mo stretchy="false" id="A5.T7.4.m2.1.1" xref="A5.T7.4.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A5.T7.4.m2.1c"><ci id="A5.T7.4.m2.1.1.cmml" xref="A5.T7.4.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.4.m2.1d">\rightarrow</annotation></semantics></math> 400h.</figcaption>
<div id="A5.T7.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:202.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(81.7pt,-38.1pt) scale(1.60434610565676,1.60434610565676) ;">
<table id="A5.T7.8.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A5.T7.5.1.1" class="ltx_tr">
<th id="A5.T7.5.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th id="A5.T7.5.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.5.1.1.3.1" class="ltx_text ltx_font_bold">Sorting</span></th>
<th id="A5.T7.5.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="5"><span id="A5.T7.5.1.1.4.1" class="ltx_text ltx_font_bold">Dataset size</span></th>
<th id="A5.T7.5.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="A5.T7.5.1.1.1.m1.1" class="ltx_Math" alttext="\Delta^{\dagger}" display="inline"><semantics id="A5.T7.5.1.1.1.m1.1a"><msup id="A5.T7.5.1.1.1.m1.1.1" xref="A5.T7.5.1.1.1.m1.1.1.cmml"><mi mathvariant="normal" id="A5.T7.5.1.1.1.m1.1.1.2" xref="A5.T7.5.1.1.1.m1.1.1.2.cmml">Δ</mi><mo id="A5.T7.5.1.1.1.m1.1.1.3" xref="A5.T7.5.1.1.1.m1.1.1.3.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="A5.T7.5.1.1.1.m1.1b"><apply id="A5.T7.5.1.1.1.m1.1.1.cmml" xref="A5.T7.5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T7.5.1.1.1.m1.1.1.1.cmml" xref="A5.T7.5.1.1.1.m1.1.1">superscript</csymbol><ci id="A5.T7.5.1.1.1.m1.1.1.2.cmml" xref="A5.T7.5.1.1.1.m1.1.1.2">Δ</ci><ci id="A5.T7.5.1.1.1.m1.1.1.3.cmml" xref="A5.T7.5.1.1.1.m1.1.1.3">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.5.1.1.1.m1.1c">\Delta^{\dagger}</annotation></semantics></math></th>
</tr>
<tr id="A5.T7.8.4.5.1" class="ltx_tr">
<th id="A5.T7.8.4.5.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th id="A5.T7.8.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.8.4.5.1.2.1" class="ltx_text ltx_font_bold">Metric</span></th>
<th id="A5.T7.8.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">50h</th>
<th id="A5.T7.8.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">100h</th>
<th id="A5.T7.8.4.5.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">200h</th>
<th id="A5.T7.8.4.5.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">300h</th>
<th id="A5.T7.8.4.5.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">400h</th>
<th id="A5.T7.8.4.5.1.8" class="ltx_td ltx_th ltx_th_column" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
</tr>
<tr id="A5.T7.8.4.6.2" class="ltx_tr">
<th id="A5.T7.8.4.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0)</th>
<th id="A5.T7.8.4.6.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ALL data (baseline)</th>
<th id="A5.T7.8.4.6.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="5">[510h] 13.9% WER</th>
<th id="A5.T7.8.4.6.2.4" class="ltx_td ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A5.T7.6.2.2" class="ltx_tr">
<th id="A5.T7.6.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1)</th>
<th id="A5.T7.6.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">WER (<math id="A5.T7.6.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T7.6.2.2.1.m1.1a"><mo stretchy="false" id="A5.T7.6.2.2.1.m1.1.1" xref="A5.T7.6.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T7.6.2.2.1.m1.1b"><ci id="A5.T7.6.2.2.1.m1.1.1.cmml" xref="A5.T7.6.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.6.2.2.1.m1.1c">\downarrow</annotation></semantics></math>)</th>
<td id="A5.T7.6.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30.7</td>
<td id="A5.T7.6.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.6.2.2.4.1" class="ltx_text ltx_font_bold">19.3</span></td>
<td id="A5.T7.6.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.3</td>
<td id="A5.T7.6.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">15.0</td>
<td id="A5.T7.6.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.6.2.2.7.1" class="ltx_text ltx_font_bold">13.8</span></td>
<td id="A5.T7.6.2.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">55%</td>
</tr>
<tr id="A5.T7.7.3.3" class="ltx_tr">
<th id="A5.T7.7.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">2)</th>
<th id="A5.T7.7.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Perplexity (<math id="A5.T7.7.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T7.7.3.3.1.m1.1a"><mo stretchy="false" id="A5.T7.7.3.3.1.m1.1.1" xref="A5.T7.7.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T7.7.3.3.1.m1.1b"><ci id="A5.T7.7.3.3.1.m1.1.1.cmml" xref="A5.T7.7.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.7.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</th>
<td id="A5.T7.7.3.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">31.3</td>
<td id="A5.T7.7.3.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.3</td>
<td id="A5.T7.7.3.3.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
<td id="A5.T7.7.3.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.6</td>
<td id="A5.T7.7.3.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">14.0</td>
<td id="A5.T7.7.3.3.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">55%</td>
</tr>
<tr id="A5.T7.8.4.4" class="ltx_tr">
<th id="A5.T7.8.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">3)</th>
<th id="A5.T7.8.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">STOI (<math id="A5.T7.8.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T7.8.4.4.1.m1.1a"><mo stretchy="false" id="A5.T7.8.4.4.1.m1.1.1" xref="A5.T7.8.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T7.8.4.4.1.m1.1b"><ci id="A5.T7.8.4.4.1.m1.1.1.cmml" xref="A5.T7.8.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.8.4.4.1.m1.1c">\uparrow</annotation></semantics></math>)</th>
<td id="A5.T7.8.4.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">33.0</td>
<td id="A5.T7.8.4.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">21.7</td>
<td id="A5.T7.8.4.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.6</td>
<td id="A5.T7.8.4.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">15.9</td>
<td id="A5.T7.8.4.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">13.9</td>
<td id="A5.T7.8.4.4.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">57%</td>
</tr>
<tr id="A5.T7.8.4.7.1" class="ltx_tr">
<th id="A5.T7.8.4.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">4)</th>
<th id="A5.T7.8.4.7.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Random selection</th>
<td id="A5.T7.8.4.7.1.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.8.4.7.1.3.1" class="ltx_text ltx_font_bold">30.0</span></td>
<td id="A5.T7.8.4.7.1.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">19.7</td>
<td id="A5.T7.8.4.7.1.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.8.4.7.1.5.1" class="ltx_text ltx_font_bold">14.9</span></td>
<td id="A5.T7.8.4.7.1.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A5.T7.8.4.7.1.6.1" class="ltx_text ltx_font_bold">14.2</span></td>
<td id="A5.T7.8.4.7.1.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">13.9</td>
<td id="A5.T7.8.4.7.1.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">53%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="A5.SS0.SSS0.Px1.p2" class="ltx_para ltx_noindent">
<p id="A5.SS0.SSS0.Px1.p2.1" class="ltx_p"><span id="A5.SS0.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_bold">The filtering stage is key for model training.</span>  We confirmed this hypothesis by training a Zipformer model with multi-dataset training on the unfiltered PL dataset, i.e., a 735-hour subset. To our surprise, the model performance, even though seeing more data than Exp 0 (Table <a href="#A5.T7" title="Table 7 ‣ Fixed Computational Budget ‣ Appendix E Data Selection Based on Metrics ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Table <a href="#A5.T6" title="Table 6 ‣ Appendix E Data Selection Based on Metrics ‣ Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>), did not reach acceptable WERs, e.g., 30%+ WER. Further research down this line will shed light on what are the best practices for selecting representative data for training, including filtering of hallucinated PLs. Note that selecting or sorting PLs might be of less importance as the dataset size increases.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.13498" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.13499" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.13499">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.13499" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.13500" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 21:53:23 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
