<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2110.02221] Securing Federated Learning: A Covert Communication-based Approach</title><meta property="og:description" content="Federated Learning Networks (FLNs) have been envisaged as a promising paradigm to collaboratively train models among mobile devices without exposing their local privacy data. Due to the need for frequent model updates …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Securing Federated Learning: A Covert Communication-based Approach">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Securing Federated Learning: A Covert Communication-based Approach">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2110.02221">

<!--Generated on Tue Mar 19 14:42:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  secure aggregation,  covert communication,  privacy attacks.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Securing Federated Learning: 
<br class="ltx_break">A Covert Communication-based Approach</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuan-Ai Xie, Jiawen Kang, Dusit Niyato, , Nguyen Thi Thanh Van, Nguyen Cong Luong*, Zhixin Liu, and Han Yu
<br class="ltx_break">
</span><span class="ltx_author_notes">Yuan-Ai Xie and Zhixin Liu are with the Institute of Electrical Engineering, Yanshan University, Qinhuangdao 066004, China. Email: xieyuan_ai@163.com, lzxauto@ysu.edu.cn.Jiawen Kang is with School of Automation, Guangdong University of Technology. Email:kjwx886@163.com.Dusit Niyato, and Han Yu are with School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798. Emails: dniyato@ntu.edu.sg, han.yu@ntu.edu.sg.Nguyen Thi Thanh Van is with the Faculty of Electrical and Electronic
Engineering, PHENIKAA University, Hanoi, Vietnam. Email: van.nguyenthithanh@phenikaa-uni.edu.vn.Nguyen Cong Luong* (Corresponding author) is with the Faculty of Computer Science, PHENIKAA
University, Hanoi, Vietnam. Email: luong.nguyencong@phenikaa-uni.edu.vn.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated Learning Networks (FLNs) have been envisaged as a promising paradigm to collaboratively train models among mobile devices without exposing their local privacy data. Due to the need for frequent model updates and communications, FLNs are vulnerable to various attacks (e.g., eavesdropping attacks, inference attacks, poisoning attacks, and backdoor attacks). Balancing privacy protection with efficient distributed model training is a key challenge for FLNs. Existing countermeasures incur high computation costs and are only designed for specific attacks on FLNs. In this paper, we bridge this gap by proposing the Covert Communication-based Federated Learning (CCFL) approach. Based on the emerging communication security technique of covert communication which hides the existence of wireless communication activities, CCFL can degrade attackers’ capability of extracting useful information from the FLN training protocol, which is a fundamental step for most existing attacks, and thereby holistically enhances the privacy of FLNs. We experimentally evaluate CCFL extensively under real-world settings in which the FL latency is optimized under given security requirements. Numerical results demonstrate the significant effectiveness of the proposed approach in terms of both training efficiency and communication security.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, secure aggregation, covert communication, privacy attacks.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated Learning Networks (FLNs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> have been proposed as a distributed privacy-preserving collaborative model training approach to alleviating societies’ concerns on the exposure of sensitive data when building artificial intelligence applications. In FLNs, a server and a large number of mobile devices (MDs) perform multiple rounds of training iterations through wireless model updates to build machine learning models for specific tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. However, FLNs with frequent model updates and communications are vulnerable to various types of privacy attacks, such as eavesdropping attacks, inference attacks, poisoning attacks and backdoor attacks, which in turn, have inspired a myriad of defense mechanisms (a.k.a. countermeasures) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, there are still major limitations for existing countermeasures. On the one hand, each countermeasure is designed to address a specific attack. Hence, to tackle multiple different attacks, separate countermeasures are required. Such a defense strategy can be costly. On the other hand, existing countermeasures address attacks individually without unified security protection for FLNs. There are potential conflicts between some countermeasures when deployed together, which can further complicate FLN security issues. There is an urgent need for a unified, efficient, and highly secure solution to provide low-cost and effective defense for FLNs, and bring this field closer to real-world applications.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Recently, Covert Communication (CC) has been introduced as a promising security technique to prevent adversaries from detecting the existence of wireless transmission links <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Historically, the spread spectrum technique was adopted to achieve CC through spreading the transmitted signal power over a large time-frequency space. However, its covertness cannot be well analyzed. Hence, channel artifacts, such as additive white Gaussian noise channels, are used to hide communications. The fundamental information-theoretic limits of CC over random channels (i.e., the square root law) were explored in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Specific CC techniques, such as Artificial Noises (AN) or jamming signals, were widely used to prevent attackers from detecting the legitimate transmissions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Compared with the traditional cryptography and Physical Layer Security (PLS) technologies, CC can provide higher-level security by hiding transmissions that attract attackers’ attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">As eavesdropping on the FL communication channels is often the first step for malicious third parties to launch attacks, we envision a <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">Covert Communication-based Federated Learning (CCFL)</span> approach to secure the model transmissions from the MDs to the FL server. The following key technical challenge when re-contexting CC into FLNs needs to be resolved. When the jamming signals are introduced to help hide the model transmissions from the MDs to the server in FLNs, they inevitably degrade the transmission rates and thus increase the latency of FL. Hence, CCFL must jointly optimize the transmit power of each MD, the jamming power of the friendly jammer, and the local model accuracy at the MDs. This envisioned approach can contribute to the federated learning literature in the following ways:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Holistic Security:</span> CCFL provides a unified and holistic security framework to mitigate a broad range of attacks on FL which involves eavesdropping on the communication channels between the MDs and the FL server.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Cost Effectiveness:</span> As CCFL is aimed at the key enabling step for malicious third parties to launch attacks on FLNs, it can preclude such attacks. In this way, MDs are no longer required to host computationally expensive countermeasures. This enables more resource-constrained devices to participate in FL.
</p>
</div>
</li>
</ol>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We carry out a case study grounded in real-world scenarios to showcase the potential benefits of CCFL, in which the AN-based CC technique is leveraged to hide the model transmissions from the MDs to the FL server from a warden (i.e., an attacker). Numerical results demonstrate significant advantages of the envisioned CCFL approach.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Preliminaries</span>
</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2110.02221/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="452" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Covert communication-based model updates for secure FLNs.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In a typical centralized learning network, the MDs are required to upload their local data to the central server through wireless links. Then, machine learning models are trained in the server (e.g., through Stochastic Gradient Descent (SGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>). Nevertheless, the broadcast nature and limited spectrum of wireless networks as well as centralized data storage have led to critical issues including risks of privacy leakage, high communication overhead, and limited scalability.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">To address the issues, FLNs have been proposed.
As shown in Figure <a href="#S2.F1" title="Figure 1 ‣ II Preliminaries ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the MDs obtain a shared global model broadcast by the FL server. They then train the local models with their data, and upload the local model parameters (e.g., gradients) to the server. After that, the server updates its global model by aggregating the received model updates (e.g., through federated averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>). These steps are repeated until the global model converges. During this process, the MDs transmit the model parameters instead of their local data. As a result, FLNs significantly reduces communication overheads and avoids privacy leakage by design.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Attacks on FLNs and Countermeasures</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Due to the exposure of the communications between the MDs and the server to any interested and capable parties, FLNs generally have a large attack surface. Various attacks such as eavesdropping attacks, inference attacks, poisoning attacks, and backdoor attacks have been successfully mounted against FLNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. In the following part of this section, we present common attacks in FLNs and discuss the corresponding countermeasures.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS1.5.1.1" class="ltx_text">II-A</span>1 </span>Eavesdropping Attacks</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">In FLNs, the trained models can leak some sensitive information about the owners of the MDs (e.g., gender, occupation, and location) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. In this context, eavesdropping attacks can occur when an adversary intercepts, deletes, or modifies these models that are transmitted between the FL server and the MDs. Since eavesdropping attacks are relatively easy to perform and can escalate to more severe cyber-attacks (e.g., Denial of Service (DoS)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>DoS can overwhelm the server by making it go offline and deny further connection requests.</span></span></span> and jamming<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Jamming can cause a poor model accuracy or even interrupt model transmissions.</span></span></span>), they are considered as one of the most common and fundamental attacks.
Based on whether the attacker listens to private conversations passively or actively, eavesdropping attacks can be categorized into passive and active eavesdropping attacks (a.k.a. man-in-the-middle attacks). Note that man-in-the-middle attackers pretend to be the intended FL server or MDs between these two entities in FLNs, and get access to control the traffic and fake the model transmissions. Unlike the passive eavesdropping attacks which are often regarded as less harmful, the man-in-the-middle attacks are severely harmful to FLNs.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.1" class="ltx_p"><span id="S2.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Countermeasures:</span> To mitigate eavesdropping attacks, cryptographic methods and PLS have been proposed. The cryptographic methods encrypt the transmitted models through a secret key that is only known by its intended receivers (e.g., the FL server). However, these methods also incur high computation costs and system complexity. This is especially challenging for FLNs involving a large number of MDs. Unlike the cryptographic methods, the main idea of PLS is to exploit the randomness of wireless channels and the AN (i.e., the jamming signal) to limit the quantity of models extracted or intercepted by an eavesdropper. Nevertheless, PLS cannot provide adequate security since the attackers are still able to capture part of the confidential FL model by side-channel analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS2.5.1.1" class="ltx_text">II-A</span>2 </span>Poisoning Attacks</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">The two major types of poisoning attacks are data poisoning and model poisoning. Through modification of the training data (e.g., by flipping the labels randomly or specifically), the malicious MDs can launch data poisoning attacks and update incorrect model updates. Furthermore, the malicious MDs can flip the sign of benign model updates or adopt a predefined compromised model to craft poisoned model updates, which tamper with the FL model and reduces its performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Model poisoning can be regarded to include data poisoning, since data poisoning attacks ultimately act on the updated model, too.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p"><span id="S2.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Countermeasures:</span> Two types of countermeasures are commonly employed to mitigate poisoning attacks on FLNs: 1) anomaly detection-based, and 2) robust aggregation. Anomaly detection-based methods are used to differentiate benign and poisoned model updates. For example, poisoned model updates can be identified and removed through analyzing their cosine similarities or mapped low-dimensional representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. On the other hand, robust aggregation methods aim resist poisoned model updates. COMED, GEOMED, COTMED and KRUM are the commonly-used robust aggregation methods which replace the model averaging FL aggregation approach with component-wise median, geometric median, component-wise trimmed median and the shortest Euclidean distances from others, respectively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. In addition, these two types of countermeasures can be combined to into a workflow.
The main drawback is that they incur high computation costs, and are not suitable for deployment on MDs.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS3.5.1.1" class="ltx_text">II-A</span>3 </span>Inference Attacks</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.1" class="ltx_p">Inference attacks fall largely into two categories: 1) membership inference attacks and 2) property inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. The membership inference attacks aim to determine whether an exact data point was used to train a given model. By observing SGD-based gradient updates, attackers can infer a significant amount of private information and then may launch a powerful attack (e.g., gradient ascent attack) against other MDs.
On the other hand, property inference attacks aim to infer properties of training data that are independent of the characterized features of a class. Meanwhile, the attacker is assumed to have auxiliary training data correctly labeled with the property they intend to infer. </p>
</div>
<div id="S2.SS1.SSS3.p2" class="ltx_para">
<p id="S2.SS1.SSS3.p2.1" class="ltx_p"><span id="S2.SS1.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Countermeasures:</span> Differential Privacy (DP)-based solutions and encryption-based solutions are commonly used to mitigate inference attacks on FLNs. For DP-based solutions, a rigorous randomization mechanism (e.g., a Gaussian noise mechanism), is designed to inject additive noises into the trained parameters before they are uploaded to the FL server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. This guarantees that the addition or removal of a single data sample or model parameter does not affect the outcome of any inference. For example, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> introduced a differentially private SGD algorithm that can effectively protect the privacy of parameters trained by deep neural networks. However, due to the added noise in the local models from the MDs, the overall model accuracy suffers. Encryption-based solutions leverage encryption techniques to secure the data privacy of the MDs when the local model parameters are shared. On this basis, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> proposed a homomorphic encryption-based technique, which can protect sensitive information while preserving model performance. Nevertheless, they incur high computation costs and require complex system designs.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Summary of various high-risk attacks on federated learning networks (FLNs) and the corresponding countermeasures</figcaption>
<div id="S2.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104.6pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-117.0pt,28.1pt) scale(0.649454661136641,0.649454661136641) ;">
<table id="S2.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1.1" class="ltx_tr" style="background-color:#CBCEFB;">
<td id="S2.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.1.1.1" class="ltx_text" style="background-color:#CBCEFB;">Attack types</span></td>
<td id="S2.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.1.2.1" class="ltx_text" style="background-color:#CBCEFB;">Attack effect</span></td>
<td id="S2.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.1.3.1" class="ltx_text" style="background-color:#CBCEFB;">Source of Vulnerability</span></td>
<td id="S2.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.1.4.1" class="ltx_text" style="background-color:#CBCEFB;">Countermeasures</span></td>
<td id="S2.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.1.5.1" class="ltx_text" style="background-color:#CBCEFB;">Limitations</span></td>
</tr>
<tr id="S2.T1.1.1.2.2" class="ltx_tr">
<td id="S2.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Eavesdropping attacks</td>
<td id="S2.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S2.T1.1.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.2.2.2.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Medium</td>
</tr>
<tr id="S2.T1.1.1.2.2.2.1.2" class="ltx_tr">
<td id="S2.T1.1.1.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">but prevailing</td>
</tr>
</table>
</td>
<td id="S2.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S2.T1.1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.2.2.3.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">MDs, compromised server</td>
</tr>
<tr id="S2.T1.1.1.2.2.3.1.2" class="ltx_tr">
<td id="S2.T1.1.1.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">wireless transmission</td>
</tr>
</table>
</td>
<td id="S2.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cryptographic methods/PLS</td>
<td id="S2.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S2.T1.1.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.2.2.5.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">High computation costs/</td>
</tr>
<tr id="S2.T1.1.1.2.2.5.1.2" class="ltx_tr">
<td id="S2.T1.1.1.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">inadequate security</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.3.3" class="ltx_tr">
<td id="S2.T1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Poisoning attacks</td>
<td id="S2.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">High</td>
<td id="S2.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MDs, compromised server</td>
<td id="S2.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S2.T1.1.1.3.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.3.3.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.3.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Anomaly detection-based methods/</td>
</tr>
<tr id="S2.T1.1.1.3.3.4.1.2" class="ltx_tr">
<td id="S2.T1.1.1.3.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">robust aggregation methods</td>
</tr>
</table>
</td>
<td id="S2.T1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">High computation costs</td>
</tr>
<tr id="S2.T1.1.1.4.4" class="ltx_tr">
<td id="S2.T1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Inference attacks</td>
<td id="S2.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">High</td>
<td id="S2.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MDs, compromised server</td>
<td id="S2.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S2.T1.1.1.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.4.4.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.4.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Differential privacy-based protection/</td>
</tr>
<tr id="S2.T1.1.1.4.4.4.1.2" class="ltx_tr">
<td id="S2.T1.1.1.4.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">encryption-based solutions</td>
</tr>
</table>
</td>
<td id="S2.T1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S2.T1.1.1.4.4.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.4.4.5.1.1" class="ltx_tr">
<td id="S2.T1.1.1.4.4.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Relatively poor model accuracy/</td>
</tr>
<tr id="S2.T1.1.1.4.4.5.1.2" class="ltx_tr">
<td id="S2.T1.1.1.4.4.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">high computation costs</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.5.5" class="ltx_tr">
<td id="S2.T1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Backdoor attacks</td>
<td id="S2.T1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">High</td>
<td id="S2.T1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">MDs</td>
<td id="S2.T1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Pruning and fine-tuning</td>
<td id="S2.T1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Low-rank security</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS4.5.1.1" class="ltx_text">II-A</span>4 </span>Backdoor Attacks</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">Backdoor attacks aim to inject
a malicious task into the FL model without affecting the
performance of the model on the actual learning task. Compared with poisoning and inference attacks, backdoor attacks are more subtle. Hence, the backdoor attacks are significantly more challenging to detect, especially when the accuracy of the model on the intended learning task does not show any variation which can alert the users to investigate the causes.</p>
</div>
<div id="S2.SS1.SSS4.p2" class="ltx_para">
<p id="S2.SS1.SSS4.p2.1" class="ltx_p"><span id="S2.SS1.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Countermeasures:</span> There are two commonly used defenses against backdoor attacks: 1) pruning and 2) fine-tuning. By eliminating neurons that are dormant on clean inputs, pruning reduces the size of a compromised network, thereby disabling backdoor behaviors. However, a stronger pruning-aware attack can be mounted to evade pruning-based defense by concentrating the clean and backdoor behavior on the same set of neurons. Hence, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> proposed the fine-tuning defense which retrains a small number of local models on a clean training dataset. Nevertheless, neither of these countermeasures offer adequate protection against backdoor attackers at the moment.</p>
</div>
<div id="S2.SS1.SSS4.p3" class="ltx_para">
<p id="S2.SS1.SSS4.p3.1" class="ltx_p">Existing countermeasures can protect FLNs against the corresponding attacks to different extents. However, as summarized in Table <a href="#S2.T1" title="TABLE I ‣ II-A3 Inference Attacks ‣ II-A Attacks on FLNs and Countermeasures ‣ II Preliminaries ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, all countermeasures have some limitations when addressing these diverse attacks. They often incur high computation costs or decrease the efficiency of FLN training, which makes deployment on MDs challenging. Moreover, in the worst-case scenario in which multiple types of attacks are launched simultaneously, the detection of such attacks and deployment of countermeasures might result in unintended complications in addition to the prohibitively high resource requirements and system complexity. Thus, a unified, efficient, and highly secure FLN protection framework is needed for this technology to become widely adopted.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Covert Communication-based Federated Learning</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Covert Communication</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Covert Communication (CC), a.k.a. low probability of detection (LPD) communication, aims to mask the existence of a legitimate wireless transmission from a watchful adversary under the requirement of a certain covert rate for the intended user <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Generally, CC provides three major advantages. Firstly, different from PLS which prevents an adversary from knowing the messages sent by the transmitter, CC prevents an adversary from knowing whether the transmission has occurred. If the adversary cannot detect the transmission, it will be unable to launch further attacks. Secondly, unlike encryption technologies, CC is low-cost, and its performance does not depend on the adversary’s computation capability. Thirdly, CC has wide compatibility and can be easily adopted to complement advanced distributed artificial intelligence techniques, such as FL.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">To improve the covertness of wireless links, various approaches have been developed based on the CC technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Noise Uncertainty:</span> Two major sources of uncertain noises are leveraged: background noise and random AN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The background noise is easily affected by environmental factors such as temperature and humidity. Hence, an appropriate communication scenario or time should be chosen to enhance the covertness of the communication link. Conversely, the random AN can flexibly and efficiently amplify interference dynamics and confuse the adversary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In contrast to background noise, the random AN is highly controllable and can be designed to exhibit different distributions, which greatly improves communication link covertness.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Multi-Antenna Technologies:</span> By adequately exploiting spatial degree of freedom, multi-antenna technologies can help enhance the covertness of wireless links from all directions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Its realization requires beamforming to generate spatial selectivity. Specifically, a beamformer adjusts the corresponding amplitude and phase of the signals on each element of an antenna array in such a way that the superimposed radiation pattern is constructive in the desired direction and destructive in other directions. As a result, the transmitted signals can reach the desired receiver to enhance the data rate and simultaneously null the transmission at the adversary site. As the number of antennas increases, the antenna array will have a higher beamforming resolution which can be utilized to achieve a more reliable covert rate.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Jammer-Aided Technologies:</span> There can be two types of friendly jammers for enhancing the stealthiness: 1) scheduled jammers, and 2) random jammers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. A scheduled jammer is informed about the transmission of the legitimate transmitter and releases its AN with optimized parameters (e.g., jamming power). In contrast, a random jammer is unaware of the transmission by the legitimate transmitter and rather randomly or continuously transmits its AN. Compared with the random jammer, the scheduled jammer is more efficient and has more reliable covertness performance. For example, at the time the legitimate transmitter starts to transmit a codeword, the scheduled jammer turns down the power of the transmitted Gaussian noise, which is turned back up at the moment the transmitter finishes transmitting.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">Cooperative Relaying:</span> By leveraging the cooperation from intermediate node(s), cooperative relaying can achieve CC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Note that the access distance shows a significant effect on covertness. For long-distance communication, high transmit power is required to achieve a target rate, which unavoidably impairs the covertness. To remedy this issue, multi-hop forwarding-based cooperative relaying is used. The fundamental is to shorten the communication distance of each hop to maintain the required transmit power low, leading to a low detection probability of the adversary. Through this technique, the covertness performance can be considerably enhanced.
</p>
</div>
</li>
</ol>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">CC has demonstrated its superiority. It is a promising foundation for building a holistic security framework for FLNs. To achieve this goal, there are still several technical challenges that need to be resolved. On the one hand, the unified security of CC may not be enough to counter some attacks, especially when the adversary possesses strong detection capability. Hence, it is necessary to introduce additional covertness techniques. On the other hand, the enhancement of system covertness may be at the expense of other system performance metrics, such as latency or transmission rate. This motivates us to focus on the overall resource optimization of FLNs and forge a well-functioning system. In the next section, we discuss a vision towards a covert communication-based federated learning (CCFL) framework.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">The Envisioned CCFL Approach</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In FLNs, the learning process involves multiple rounds of communications between MDs and the FL server. Adversaries can launch eavesdropping attacks and extract model parameter information via a weak channel condition. By detecting the existence of model updates, it is possible for eavesdropping attacks to escalate into more severe forms of attacks (e.g., DoS, jamming, and black holes) to manipulate FL model updates and aggregations.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To curb these cyber attacks effectively and preclude them from escalating, we envision incorporating CC into the FLN training process to hide the occurrence of model update transmissions. Without awareness of these transmissions, it is hard for the adversary to lunch attacks effectively. Since the large-scale FL devices are always configured with orthogonal channels, CC can deliver holistic security for the FL MDs through distributedly deploying it to each orthogonal channel. In addition, the distributed power control for CC incurs lower computation costs than existing countermeasures such as cryptographic methods and PLS. Multi-antenna technologies and cooperative relaying are more suitable for the downlink global FL model broadcast. The noise uncertainty and jammer-aided techniques are useful for securing the more vulnerable uplink FL model updates.
</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">A Case Study of CCFL</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We show a case study in which the jammer-aided technology is used to secure the local models transmitted from the MDs to the FL server for defending against eavesdropping attacks.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.5.1.1" class="ltx_text">III-C</span>1 </span>System Model</h4>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2110.02221/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="272" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Jammer-based covert communication for FLNs.</figcaption>
</figure>
<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.4" class="ltx_p">We consider an FL network as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III-C1 System Model ‣ III-C A Case Study of CCFL ‣ III Covert Communication-based Federated Learning ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> which consists of <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">N</annotation></semantics></math> devices, one FL server located at a Base Station (BS), and an attacker Willie. To achieve high efficiency, the orthogonal frequency-division multiple access technique is used for local model uploading by the MDs. A friendly jammer with <math id="S3.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mi id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><ci id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">N</annotation></semantics></math> antennas is deployed to transmit AN signals continuously with total power <math id="S3.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="p^{j}" display="inline"><semantics id="S3.SS3.SSS1.p1.3.m3.1a"><msup id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p1.3.m3.1.1.2" xref="S3.SS3.SSS1.p1.3.m3.1.1.2.cmml">p</mi><mi id="S3.SS3.SSS1.p1.3.m3.1.1.3" xref="S3.SS3.SSS1.p1.3.m3.1.1.3.cmml">j</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b"><apply id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.2">𝑝</ci><ci id="S3.SS3.SSS1.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">p^{j}</annotation></semantics></math> to Willie. To secure the model transmissions of all the devices, the jammer leverages the barrage jamming technique that transmits the AN signals over the full bandwidth occupied by the devices. Note that the AN signals also cause interference to the BS and may reduce the Signal-to-Interference-plus-Noise-Ratio (SINR) at the BS. The jammer is self-interested and rational. Thus, the server needs to pay the jammer a fee for the jamming service. For simplicity of discussion, a linear cost model is adopted in which the cost paid to the jammer is linearly proportional to <math id="S3.SS3.SSS1.p1.4.m4.1" class="ltx_Math" alttext="p^{j}" display="inline"><semantics id="S3.SS3.SSS1.p1.4.m4.1a"><msup id="S3.SS3.SSS1.p1.4.m4.1.1" xref="S3.SS3.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS3.SSS1.p1.4.m4.1.1.2" xref="S3.SS3.SSS1.p1.4.m4.1.1.2.cmml">p</mi><mi id="S3.SS3.SSS1.p1.4.m4.1.1.3" xref="S3.SS3.SSS1.p1.4.m4.1.1.3.cmml">j</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.m4.1b"><apply id="S3.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1.2">𝑝</ci><ci id="S3.SS3.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.m4.1c">p^{j}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.3" class="ltx_p">The FL model training process involves multiple iterations. In each iteration, the MDs train their local models to achieve a local accuracy <math id="S3.SS3.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S3.SS3.SSS1.p2.1.m1.1a"><mi id="S3.SS3.SSS1.p2.1.m1.1.1" xref="S3.SS3.SSS1.p2.1.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.1.m1.1b"><ci id="S3.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.1.m1.1c">\eta</annotation></semantics></math> (in terms of training error). At the end of each iteration, each MD can decide to transmit or not to transmit its local model to the FL server with a pre-defined transmission probability. When a device decides to transmit its model update to the server, and Willie judges that the device does not execute the transmission, then a <span id="S3.SS3.SSS1.p2.3.1" class="ltx_text ltx_font_italic">miss-detection</span> occurs. When Willie judges that the device is transmitting the update while the device does not, then a <span id="S3.SS3.SSS1.p2.3.2" class="ltx_text ltx_font_italic">false alarm</span> occurs. We define the covert probability for a device as the sum of the false alarm probability and the miss detection probability. We expect a high covert probability for situations in which Willie cannot correctly detect the model transmission of any device in the network. For this, the cover probability for the device in the FL network needs to be greater than a security requirement <math id="S3.SS3.SSS1.p2.2.m2.1" class="ltx_Math" alttext="(1-\epsilon)" display="inline"><semantics id="S3.SS3.SSS1.p2.2.m2.1a"><mrow id="S3.SS3.SSS1.p2.2.m2.1.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS1.p2.2.m2.1.1.1.2" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS1.p2.2.m2.1.1.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.cmml"><mn id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.2" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.1.cmml">−</mo><mi id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.3" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S3.SS3.SSS1.p2.2.m2.1.1.1.3" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.2.m2.1b"><apply id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.1"><minus id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.2">1</cn><ci id="S3.SS3.SSS1.p2.2.m2.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.2.m2.1c">(1-\epsilon)</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, where <math id="S3.SS3.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS1.p2.3.m3.1a"><mi id="S3.SS3.SSS1.p2.3.m3.1.1" xref="S3.SS3.SSS1.p2.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.3.m3.1b"><ci id="S3.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p2.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.3.m3.1c">\epsilon</annotation></semantics></math> is the security threshold. This is the CC constraint.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2110.02221/assets/x3.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="216" height="171" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.4.2.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S3.F3.sf1.2.1" class="ltx_text" style="font-size:80%;">FL latency versus the number of devices <math id="S3.F3.sf1.2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.F3.sf1.2.1.m1.1b"><mi id="S3.F3.sf1.2.1.m1.1.1" xref="S3.F3.sf1.2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.F3.sf1.2.1.m1.1c"><ci id="S3.F3.sf1.2.1.m1.1.1.cmml" xref="S3.F3.sf1.2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf1.2.1.m1.1d">N</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2110.02221/assets/x4.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="235" height="171" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.4.2.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S3.F3.sf2.2.1" class="ltx_text" style="font-size:80%;">FL latency and security performance versus security threshold <math id="S3.F3.sf2.2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.F3.sf2.2.1.m1.1b"><mi id="S3.F3.sf2.2.1.m1.1.1" xref="S3.F3.sf2.2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.F3.sf2.2.1.m1.1c"><ci id="S3.F3.sf2.2.1.m1.1.1.cmml" xref="S3.F3.sf2.2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf2.2.1.m1.1d">\epsilon</annotation></semantics></math></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The number of devices is set as <math id="S3.F3.13.m1.1" class="ltx_Math" alttext="N=50" display="inline"><semantics id="S3.F3.13.m1.1b"><mrow id="S3.F3.13.m1.1.1" xref="S3.F3.13.m1.1.1.cmml"><mi id="S3.F3.13.m1.1.1.2" xref="S3.F3.13.m1.1.1.2.cmml">N</mi><mo id="S3.F3.13.m1.1.1.1" xref="S3.F3.13.m1.1.1.1.cmml">=</mo><mn id="S3.F3.13.m1.1.1.3" xref="S3.F3.13.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.13.m1.1c"><apply id="S3.F3.13.m1.1.1.cmml" xref="S3.F3.13.m1.1.1"><eq id="S3.F3.13.m1.1.1.1.cmml" xref="S3.F3.13.m1.1.1.1"></eq><ci id="S3.F3.13.m1.1.1.2.cmml" xref="S3.F3.13.m1.1.1.2">𝑁</ci><cn type="integer" id="S3.F3.13.m1.1.1.3.cmml" xref="S3.F3.13.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.13.m1.1d">N=50</annotation></semantics></math>. The devices, jammer, and Willie are distributed randomly in a square area of size of <math id="S3.F3.14.m2.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.F3.14.m2.1b"><mn id="S3.F3.14.m2.1.1" xref="S3.F3.14.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.F3.14.m2.1c"><cn type="integer" id="S3.F3.14.m2.1.1.cmml" xref="S3.F3.14.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.14.m2.1d">500</annotation></semantics></math> m <math id="S3.F3.15.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.F3.15.m3.1b"><mo id="S3.F3.15.m3.1.1" xref="S3.F3.15.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.F3.15.m3.1c"><times id="S3.F3.15.m3.1.1.cmml" xref="S3.F3.15.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.15.m3.1d">\times</annotation></semantics></math> <math id="S3.F3.16.m4.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.F3.16.m4.1b"><mn id="S3.F3.16.m4.1.1" xref="S3.F3.16.m4.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.F3.16.m4.1c"><cn type="integer" id="S3.F3.16.m4.1.1.cmml" xref="S3.F3.16.m4.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.16.m4.1d">500</annotation></semantics></math> m. The transmission probability of the devices is <math id="S3.F3.17.m5.1" class="ltx_Math" alttext="0.7" display="inline"><semantics id="S3.F3.17.m5.1b"><mn id="S3.F3.17.m5.1.1" xref="S3.F3.17.m5.1.1.cmml">0.7</mn><annotation-xml encoding="MathML-Content" id="S3.F3.17.m5.1c"><cn type="float" id="S3.F3.17.m5.1.1.cmml" xref="S3.F3.17.m5.1.1">0.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.17.m5.1d">0.7</annotation></semantics></math>, and their maximum power is <math id="S3.F3.18.m6.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.F3.18.m6.1b"><mn id="S3.F3.18.m6.1.1" xref="S3.F3.18.m6.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.F3.18.m6.1c"><cn type="integer" id="S3.F3.18.m6.1.1.cmml" xref="S3.F3.18.m6.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.18.m6.1d">10</annotation></semantics></math> dBm. Each device has <math id="S3.F3.19.m7.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.F3.19.m7.1b"><mn id="S3.F3.19.m7.1.1" xref="S3.F3.19.m7.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.F3.19.m7.1c"><cn type="integer" id="S3.F3.19.m7.1.1.cmml" xref="S3.F3.19.m7.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.19.m7.1d">500</annotation></semantics></math> data samples for its local training, and the device has a maximum computation capacity of <math id="S3.F3.20.m8.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.F3.20.m8.1b"><mn id="S3.F3.20.m8.1.1" xref="S3.F3.20.m8.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.F3.20.m8.1c"><cn type="integer" id="S3.F3.20.m8.1.1.cmml" xref="S3.F3.20.m8.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.20.m8.1d">2</annotation></semantics></math> GHz. The total bandwidth for the model transmissions of the devices is <math id="S3.F3.21.m9.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S3.F3.21.m9.1b"><mn id="S3.F3.21.m9.1.1" xref="S3.F3.21.m9.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.F3.21.m9.1c"><cn type="integer" id="S3.F3.21.m9.1.1.cmml" xref="S3.F3.21.m9.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.21.m9.1d">20</annotation></semantics></math> MHz. The price per jamming power unit is <math id="S3.F3.22.m10.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.F3.22.m10.1b"><mn id="S3.F3.22.m10.1.1" xref="S3.F3.22.m10.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.F3.22.m10.1c"><cn type="float" id="S3.F3.22.m10.1.1.cmml" xref="S3.F3.22.m10.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.22.m10.1d">0.5</annotation></semantics></math>$ that is set by the jammer, and the budget of the server is <math id="S3.F3.23.m11.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S3.F3.23.m11.1b"><mn id="S3.F3.23.m11.1.1" xref="S3.F3.23.m11.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.F3.23.m11.1c"><cn type="integer" id="S3.F3.23.m11.1.1.cmml" xref="S3.F3.23.m11.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.23.m11.1d">30</annotation></semantics></math>$. The security requirement is <math id="S3.F3.24.m12.1" class="ltx_Math" alttext="\epsilon=0.1" display="inline"><semantics id="S3.F3.24.m12.1b"><mrow id="S3.F3.24.m12.1.1" xref="S3.F3.24.m12.1.1.cmml"><mi id="S3.F3.24.m12.1.1.2" xref="S3.F3.24.m12.1.1.2.cmml">ϵ</mi><mo id="S3.F3.24.m12.1.1.1" xref="S3.F3.24.m12.1.1.1.cmml">=</mo><mn id="S3.F3.24.m12.1.1.3" xref="S3.F3.24.m12.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.24.m12.1c"><apply id="S3.F3.24.m12.1.1.cmml" xref="S3.F3.24.m12.1.1"><eq id="S3.F3.24.m12.1.1.1.cmml" xref="S3.F3.24.m12.1.1.1"></eq><ci id="S3.F3.24.m12.1.1.2.cmml" xref="S3.F3.24.m12.1.1.2">italic-ϵ</ci><cn type="float" id="S3.F3.24.m12.1.1.3.cmml" xref="S3.F3.24.m12.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.24.m12.1d">\epsilon=0.1</annotation></semantics></math>.</figcaption>
</figure>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">To prevent Willie from detecting the local model transmissions by the devices, the server can request the jammer to transmit the AN signal with a higher power. However, this increases the cost that the server needs to pay the jammer and also reduces the SINR at the BS, leading to an increase in FL latency. Otherwise, the server can increase the local accuracy <math id="S3.SS3.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S3.SS3.SSS1.p3.1.m1.1a"><mi id="S3.SS3.SSS1.p3.1.m1.1.1" xref="S3.SS3.SSS1.p3.1.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.1.m1.1b"><ci id="S3.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p3.1.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.1.m1.1c">\eta</annotation></semantics></math> at the devices to reduce the number of local iterations, thereby reducing the computation time at the devices. However, this approach requires more global iterations to achieve high accuracy, thereby increasing the FL latency. Therefore, the joint optimization problem must simultaneously consider: 1) jamming power, 2) transmit power of the devices, and 3) local accuracy at the devices, in order to minimize the FL latency, subject to: 1) the CC constraint, 2) the maximum power of the devices, 3) the maximum power of the jammer, and 4) the FL server’s budget. Here, the FL latency is defined as the maximum latency among the devices. The objective function and the CC constraint are non-convex. Thus, the optimization problem is non-convex. To solve the problem, we can adopt an alternating descent algorithm. The algorithm divides the original problem into two sub-problems that are alternately optimized at each iteration using successive convex approximation.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.5.1.1" class="ltx_text">III-C</span>2 </span>Numerical Results</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.8" class="ltx_p">This part discusses the impact of important parameters on the latency and the security performance of the FL network.
Figure <a href="#S3.F3.sf1" title="In Figure 3 ‣ III-C1 System Model ‣ III-C A Case Study of CCFL ‣ III Covert Communication-based Federated Learning ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> shows the impact of the number of MDs <math id="S3.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><mi id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><ci id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">N</annotation></semantics></math> and the security threshold <math id="S3.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><mi id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><ci id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">\epsilon</annotation></semantics></math> on FL latency. As can be observed, given the security threshold <math id="S3.SS3.SSS2.p1.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p1.3.m3.1a"><mi id="S3.SS3.SSS2.p1.3.m3.1.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.3.m3.1b"><ci id="S3.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.3.m3.1c">\epsilon</annotation></semantics></math>, the FL latency increases as the number of devices <math id="S3.SS3.SSS2.p1.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.SSS2.p1.4.m4.1a"><mi id="S3.SS3.SSS2.p1.4.m4.1.1" xref="S3.SS3.SSS2.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.4.m4.1b"><ci id="S3.SS3.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.4.m4.1c">N</annotation></semantics></math> increases. The reason is that the same fixed bandwidth is allocated to more devices. This decreases the transmission rate of each device, thereby increasing FL latency. It can also be observed from Figure <a href="#S3.F3.sf1" title="In Figure 3 ‣ III-C1 System Model ‣ III-C A Case Study of CCFL ‣ III Covert Communication-based Federated Learning ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> that, as the security threshold <math id="S3.SS3.SSS2.p1.5.m5.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p1.5.m5.1a"><mi id="S3.SS3.SSS2.p1.5.m5.1.1" xref="S3.SS3.SSS2.p1.5.m5.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.5.m5.1b"><ci id="S3.SS3.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS2.p1.5.m5.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.5.m5.1c">\epsilon</annotation></semantics></math> increases, FL latency decreases. The reason is that as <math id="S3.SS3.SSS2.p1.6.m6.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p1.6.m6.1a"><mi id="S3.SS3.SSS2.p1.6.m6.1.1" xref="S3.SS3.SSS2.p1.6.m6.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.6.m6.1b"><ci id="S3.SS3.SSS2.p1.6.m6.1.1.cmml" xref="S3.SS3.SSS2.p1.6.m6.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.6.m6.1c">\epsilon</annotation></semantics></math> increases, the security requirement <math id="S3.SS3.SSS2.p1.7.m7.1" class="ltx_Math" alttext="(1-\epsilon)" display="inline"><semantics id="S3.SS3.SSS2.p1.7.m7.1a"><mrow id="S3.SS3.SSS2.p1.7.m7.1.1.1" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS2.p1.7.m7.1.1.1.2" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS2.p1.7.m7.1.1.1.1" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.cmml"><mn id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.2" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.1" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.1.cmml">−</mo><mi id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.3" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S3.SS3.SSS2.p1.7.m7.1.1.1.3" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.7.m7.1b"><apply id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.7.m7.1.1.1"><minus id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.2">1</cn><ci id="S3.SS3.SSS2.p1.7.m7.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p1.7.m7.1.1.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.7.m7.1c">(1-\epsilon)</annotation></semantics></math> decreases. The low-security requirement allows the devices to transmit the models with higher transmit power. This leads to increases in SINR at the BS, thereby decreasing FL latency. Recall that when <math id="S3.SS3.SSS2.p1.8.m8.1" class="ltx_Math" alttext="(1-\epsilon)" display="inline"><semantics id="S3.SS3.SSS2.p1.8.m8.1a"><mrow id="S3.SS3.SSS2.p1.8.m8.1.1.1" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS2.p1.8.m8.1.1.1.2" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS2.p1.8.m8.1.1.1.1" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.cmml"><mn id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.2" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.1" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.1.cmml">−</mo><mi id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.3" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S3.SS3.SSS2.p1.8.m8.1.1.1.3" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.8.m8.1b"><apply id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.8.m8.1.1.1"><minus id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.2">1</cn><ci id="S3.SS3.SSS2.p1.8.m8.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p1.8.m8.1.1.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.8.m8.1c">(1-\epsilon)</annotation></semantics></math> decreases, Willie can detect the transmissions of the devices more easily. As such, there is a trade-off between security performance and FL training efficiency.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.5" class="ltx_p">Now, we discuss the impacts of the security threshold <math id="S3.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p2.1.m1.1a"><mi id="S3.SS3.SSS2.p2.1.m1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.1.m1.1b"><ci id="S3.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.1.m1.1c">\epsilon</annotation></semantics></math> and the server’s budget <math id="S3.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="\chi" display="inline"><semantics id="S3.SS3.SSS2.p2.2.m2.1a"><mi id="S3.SS3.SSS2.p2.2.m2.1.1" xref="S3.SS3.SSS2.p2.2.m2.1.1.cmml">χ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.2.m2.1b"><ci id="S3.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1">𝜒</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.2.m2.1c">\chi</annotation></semantics></math>, FL latency and security performance. As shown in Figure <a href="#S3.F3.sf2" title="In Figure 3 ‣ III-C1 System Model ‣ III-C A Case Study of CCFL ‣ III Covert Communication-based Federated Learning ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>, as <math id="S3.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p2.3.m3.1a"><mi id="S3.SS3.SSS2.p2.3.m3.1.1" xref="S3.SS3.SSS2.p2.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.3.m3.1b"><ci id="S3.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.3.m3.1c">\epsilon</annotation></semantics></math> increases, the covert probability of the FL network decreases. This is obvious since as <math id="S3.SS3.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.SSS2.p2.4.m4.1a"><mi id="S3.SS3.SSS2.p2.4.m4.1.1" xref="S3.SS3.SSS2.p2.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.4.m4.1b"><ci id="S3.SS3.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS2.p2.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.4.m4.1c">\epsilon</annotation></semantics></math> increases (i.e., <math id="S3.SS3.SSS2.p2.5.m5.1" class="ltx_Math" alttext="(1-\epsilon)" display="inline"><semantics id="S3.SS3.SSS2.p2.5.m5.1a"><mrow id="S3.SS3.SSS2.p2.5.m5.1.1.1" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS2.p2.5.m5.1.1.1.2" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS2.p2.5.m5.1.1.1.1" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.cmml"><mn id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.2" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.1" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.1.cmml">−</mo><mi id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.3" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S3.SS3.SSS2.p2.5.m5.1.1.1.3" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.5.m5.1b"><apply id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.5.m5.1.1.1"><minus id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.2">1</cn><ci id="S3.SS3.SSS2.p2.5.m5.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p2.5.m5.1.1.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.5.m5.1c">(1-\epsilon)</annotation></semantics></math> decreases), a lower covert probability is enough to satisfy the CC constraint. Figure <a href="#S3.F3.sf2" title="In Figure 3 ‣ III-C1 System Model ‣ III-C A Case Study of CCFL ‣ III Covert Communication-based Federated Learning ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> further shows that the covert probability remains almost constant over different budget settings by the FL server. The reason is that the covert probability depends on the ratio of the jamming power to the transmit power of the devices. As the budget varies, the jamming power bought from the jammer and the transmit power committed by the devices change together to satisfy the security requirement. Therefore, the covert probability remains unchanged over diverse budget values.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.4" class="ltx_p">Nevertheless, varying the budget of the server leads to changes in FL latency. As shown in Figure <a href="#S3.F3.sf2" title="In Figure 3 ‣ III-C1 System Model ‣ III-C A Case Study of CCFL ‣ III Covert Communication-based Federated Learning ‣ Securing Federated Learning: A Covert Communication-based Approach" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>, as we decrease the server’s budget from <math id="S3.SS3.SSS2.p3.1.m1.1" class="ltx_Math" alttext="\chi=\$30" display="inline"><semantics id="S3.SS3.SSS2.p3.1.m1.1a"><mrow id="S3.SS3.SSS2.p3.1.m1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.cmml"><mi id="S3.SS3.SSS2.p3.1.m1.1.1.2" xref="S3.SS3.SSS2.p3.1.m1.1.1.2.cmml">χ</mi><mo rspace="0.1389em" id="S3.SS3.SSS2.p3.1.m1.1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS3.SSS2.p3.1.m1.1.1.3" xref="S3.SS3.SSS2.p3.1.m1.1.1.3.cmml"><mo lspace="0.1389em" rspace="0.167em" id="S3.SS3.SSS2.p3.1.m1.1.1.3.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.3.1.cmml">$</mo><mn id="S3.SS3.SSS2.p3.1.m1.1.1.3.2" xref="S3.SS3.SSS2.p3.1.m1.1.1.3.2.cmml">30</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.1.m1.1b"><apply id="S3.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1"><eq id="S3.SS3.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.1"></eq><ci id="S3.SS3.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.2">𝜒</ci><apply id="S3.SS3.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.3"><csymbol cd="latexml" id="S3.SS3.SSS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.3.1">currency-dollar</csymbol><cn type="integer" id="S3.SS3.SSS2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.3.2">30</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.1.m1.1c">\chi=\$30</annotation></semantics></math> to <math id="S3.SS3.SSS2.p3.2.m2.1" class="ltx_Math" alttext="\chi=\$10" display="inline"><semantics id="S3.SS3.SSS2.p3.2.m2.1a"><mrow id="S3.SS3.SSS2.p3.2.m2.1.1" xref="S3.SS3.SSS2.p3.2.m2.1.1.cmml"><mi id="S3.SS3.SSS2.p3.2.m2.1.1.2" xref="S3.SS3.SSS2.p3.2.m2.1.1.2.cmml">χ</mi><mo rspace="0.1389em" id="S3.SS3.SSS2.p3.2.m2.1.1.1" xref="S3.SS3.SSS2.p3.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS3.SSS2.p3.2.m2.1.1.3" xref="S3.SS3.SSS2.p3.2.m2.1.1.3.cmml"><mo lspace="0.1389em" rspace="0.167em" id="S3.SS3.SSS2.p3.2.m2.1.1.3.1" xref="S3.SS3.SSS2.p3.2.m2.1.1.3.1.cmml">$</mo><mn id="S3.SS3.SSS2.p3.2.m2.1.1.3.2" xref="S3.SS3.SSS2.p3.2.m2.1.1.3.2.cmml">10</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.2.m2.1b"><apply id="S3.SS3.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p3.2.m2.1.1"><eq id="S3.SS3.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p3.2.m2.1.1.1"></eq><ci id="S3.SS3.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p3.2.m2.1.1.2">𝜒</ci><apply id="S3.SS3.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S3.SS3.SSS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS2.p3.2.m2.1.1.3.1">currency-dollar</csymbol><cn type="integer" id="S3.SS3.SSS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS2.p3.2.m2.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.2.m2.1c">\chi=\$10</annotation></semantics></math>, FL latency increases. The reason is that the server with a low budget can only buy a low amount of power from the jammer. The lower jamming power requires the devices to reduce their transmit power in order to satisfy the security requirement <math id="S3.SS3.SSS2.p3.3.m3.1" class="ltx_Math" alttext="(1-\epsilon)" display="inline"><semantics id="S3.SS3.SSS2.p3.3.m3.1a"><mrow id="S3.SS3.SSS2.p3.3.m3.1.1.1" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS2.p3.3.m3.1.1.1.2" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS2.p3.3.m3.1.1.1.1" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.cmml"><mn id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.2" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.1" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.1.cmml">−</mo><mi id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.3" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S3.SS3.SSS2.p3.3.m3.1.1.1.3" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.3.m3.1b"><apply id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.cmml" xref="S3.SS3.SSS2.p3.3.m3.1.1.1"><minus id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.2">1</cn><ci id="S3.SS3.SSS2.p3.3.m3.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p3.3.m3.1.1.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.3.m3.1c">(1-\epsilon)</annotation></semantics></math> (i.e., to prevent Willie from detecting the transmissions from the MDs). This leads to decreases in SINR at the BS, thereby increasing FL latency. Under a higher budget setting (i.e., <math id="S3.SS3.SSS2.p3.4.m4.1" class="ltx_Math" alttext="\$30" display="inline"><semantics id="S3.SS3.SSS2.p3.4.m4.1a"><mrow id="S3.SS3.SSS2.p3.4.m4.1.1" xref="S3.SS3.SSS2.p3.4.m4.1.1.cmml"><mo rspace="0.167em" id="S3.SS3.SSS2.p3.4.m4.1.1.1" xref="S3.SS3.SSS2.p3.4.m4.1.1.1.cmml">$</mo><mn id="S3.SS3.SSS2.p3.4.m4.1.1.2" xref="S3.SS3.SSS2.p3.4.m4.1.1.2.cmml">30</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.4.m4.1b"><apply id="S3.SS3.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS3.SSS2.p3.4.m4.1.1"><csymbol cd="latexml" id="S3.SS3.SSS2.p3.4.m4.1.1.1.cmml" xref="S3.SS3.SSS2.p3.4.m4.1.1.1">currency-dollar</csymbol><cn type="integer" id="S3.SS3.SSS2.p3.4.m4.1.1.2.cmml" xref="S3.SS3.SSS2.p3.4.m4.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.4.m4.1c">\$30</annotation></semantics></math>), FL latency does not change significantly. The reason is that the server already finds an optimal jamming power that minimizes the FL latency while guaranteeing the security requirement, and it does not need to buy more power from the jammer. For this, the devices are not allowed to increase the transmit power due to the fixed security requirement. Thus, FL latency remains stable even when the budget is high.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Conclusions and Future Directions</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this article, we present a vision towards the holistic and cost-effective protection of FLNs from attacks through a covert communication-based approach. We start by discussing existing security issues for distributed collaborative training of FL networks. We then review key existing covert communication techniques, and present a case study in which jammer-based CC is used to prevent an attacker from detecting the local model transmissions by the devices involved in an FL setting. The use of the AN signals leads to the increase of the FL latency. Thus, we have investigated the FL latency minimization problem subject to the CC constraint. The numerical results provide an overview of the impact of important parameters such as the number of devices, security requirement, and budget of the server on FL latency and security performance. To the best of our knowledge, this is the first exploration on the potential of leveraging CC to enhance the security of FLNs.
</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">For this emerging field of research, many interesting and challenging problems remain open:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Impact of multiple attackers:</span> In this work, we assume that there is a single attacker in the FL network. In fact, there may be multiple attackers, and the server needs to prevent all of them from detecting the transmissions of the devices. This is challenging since the attackers may have different detection capabilities. One solution is to design the server to focus on defending against the attacker with the best detection capability.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Dynamic pricing of jamming power:</span> In this work, the jamming power price is fixed. In fact, the jammer can be self-interested and can dynamically set the price in different FL iterations to maximize its benefit. The server needs to account for time-varying prices to adapt the jamming power to avoid exceeding its budget.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Use of intelligent reflection surface (IRS):</span> To reduce the high cost for the jamming power, IRS can be deployed to enhance CC in the FL network. An IRS consists of reconfigurable reflecting elements that can reshape the phases, amplitudes, and
reflecting the angles of the environmental signals. For this, the phase shifts of the IRS can be configured to maximize the SINR at the BS, subject to the CC requirement.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research is supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-RP-2020-019); the Nanyang Assistant Professorship (NAP); and the RIE 2020 Advanced Manufacturing and Engineering (AME) Programmatic Fund (No. A20G8b0102), Singapore. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, R. G. L. D’Oliveira,
H. Eichner, S. E. Rouayheb, D. Evans, J. Gardner, Z. Garrett, A. Gascón,
B. Ghazi, P. B. Gibbons, M. Gruteser, Z. Harchaoui, C. He, L. He, Z. Huo,
B. Hutchinson, J. Hsu, M. Jaggi, T. Javidi, G. Joshi, M. Khodak,
J. Konečný, A. Korolova, F. Koushanfar, S. Koyejo, T. Lepoint, Y. Liu,
P. Mittal, M. Mohri, R. Nock, A. Özgür, R. Pagh, M. Raykova, H. Qi,
D. Ramage, R. Raskar, D. Song, W. Song, S. U. Stich, Z. Sun, A. T. Suresh,
F. Tramèr, P. Vepakomma, J. Wang, L. Xiong, Z. Xu, Q. Yang, F. X. Yu, H. Yu,
and S. Zhao, “Advances and open problems in federated learning,”
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends in Machine Learning</em>, vol. 14, no. 1-2, pp.
1–210, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, X. Ma, L. Sun, J. Zhao, Q. Yang, and P. S. Yu, “Privacy and
robustness in federated learning: Attacks and defenses,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">preprint
arXiv:2012.06337</em>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
X. Lu, E. Hossain, T. Shafique, S. Feng, H. Jiang, and D. Niyato, “Intelligent
reflecting surface enabled covert communications in wireless networks,”
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 34, no. 5, pp. 148–155, Sep./Oct. 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X. Jiang, X. Chen, J. Tang, N. Zhao, X. Y. Zhang, D. Niyato, and K.-K. Wong,
“Covert communication in UAV-assisted air-ground networks,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE
Wireless Communications</em>, vol. 28, no. 4, pp. 190–197, Aug. 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T. V. Sobers, B. A. Bash, S. Guha, D. Towsley, and D. Goeckel, “Covert
communication in the presence of an uninformed jammer,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, vol. 16, no. 9, pp. 6193–6206,
Sep. 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
B. A. Bash, D. Goeckel, and D. Towsley, “Limits of reliable communication with
low probability of detection on awgn channels,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE journal on
selected areas in communications</em>, vol. 31, no. 9, pp. 1921–1930, Sep. 2013.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Tan, Y.-C. Liang, N. C. Luong, and D. Niyato, “Toward smart security
enhancement of federated learning networks,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 35,
no. 1, pp. 340–347, Jan./Feb. 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, “Exploiting unintended
feature leakage in collaborative learning,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on
Security and Privacy (SP)</em>.   IEEE,
2019, pp. 691–706.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>,
vol. 22, no. 3, pp. 2031–2063, 3rd Quart. 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang, “Deep learning with differential privacy,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2016 ACM SIGSAC conference on computer and communications security</em>,
2016, pp. 308–318.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y. Aono <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Privacy-preserving deep learning via additively
homomorphic encryption,” <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em>, vol. 13, no. 5, pp. 1333–1345, May 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
K. Liu, B. Dolan-Gavitt, and S. Garg, “Fine-pruning: Defending against
backdooring attacks on deep neural networks,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International
Symposium on Research in Attacks, Intrusions, and Defenses</em>.   Springer, 2018, pp. 273–294.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T.-X. Zheng, H.-M. Wang, D. W. K. Ng, and J. Yuan, “Multi-antenna covert
communications in random wireless networks,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Wireless Communications</em>, vol. 18, no. 3, pp. 1974–1987, Mar. 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. Shahzad, X. Zhou, and S. Yan, “Covert wireless communication in presence of
a multi-antenna adversary and delay constraints,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Vehicular Technology</em>, vol. 68, no. 12, pp. 12 432–12 436, Dec. 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2110.02220" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2110.02221" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2110.02221">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2110.02221" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2110.02222" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 14:42:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
