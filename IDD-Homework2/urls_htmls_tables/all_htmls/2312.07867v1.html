<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.07867] BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab.</title><meta property="og:description" content="Medical Visual Question Answering (Med-VQA) is a very important task in healthcare industry, which answers a natural language question with a medical image. Existing VQA techniques in information systems can be directl…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab.">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab.">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.07867">

<!--Generated on Tue Feb 27 13:57:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Medical Visual Question Answering Benchmark Evaluation System Comprehensive Empirical Study">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>School of Informatics, Xiamen University, Xiamen, China
<span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{xjhong,zxsong,feiyanliu}@stu.xmu.edu.cn, xlwang@xmu.edu.cn</span></span></span>
<br class="ltx_break"></span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Meetyou AI Lab, Xiamen, China
<br class="ltx_break"><span id="id2.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>liliangzhi@xiaoyouzi.com</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">BESTMVQA: A Benchmark Evaluation System for Medical Visual Question Answering<span id="id1.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>This work was done when Xiaojie Hong worked for the project of Meetyou AI Lab.</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Xiaojie Hong
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zixin Song
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liangzhi Li
</span><span class="ltx_author_notes">2 (2 ())</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaoli Wang
</span><span class="ltx_author_notes">1 (1 ())
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-8677-9080" title="ORCID identifier" class="ltx_ref">0000-0002-8677-9080</a></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Feiyan Liu
</span><span class="ltx_author_notes">11</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Medical Visual Question Answering (Med-VQA) is a very important task in healthcare industry, which answers a natural language question with a medical image. Existing VQA techniques in information systems can be directly applied to solving the task. However, they often suffer from (<span id="id2.id1.1" class="ltx_text ltx_font_italic">i</span>) the data insufficient problem, which makes it difficult to train the state of the arts (SOTAs) for the domain-specific task, and (<span id="id2.id1.2" class="ltx_text ltx_font_italic">ii</span>) the reproducibility problem, that many existing models have not been thoroughly evaluated in a unified experimental setup. To address these issues, this paper develops a Benchmark Evaluation SysTem for Medical Visual Question Answering, denoted by BESTMVQA. Given self-collected clinical data, our system provides a useful tool for users to automatically build Med-VQA datasets, which helps overcoming the data insufficient problem. Users also can conveniently select a wide spectrum of SOTA models from our model library to perform a comprehensive empirical study. With simple configurations, our system automatically trains and evaluates the selected models over a benchmark dataset, and reports the comprehensive results for users to develop new techniques or perform medical practice. Limitations of existing work are overcome (<span id="id2.id1.3" class="ltx_text ltx_font_italic">i</span>) by the data generation tool, which automatically constructs new datasets from unstructured clinical data, and (<span id="id2.id1.4" class="ltx_text ltx_font_italic">ii</span>) by evaluating SOTAs on benchmark datasets in a unified experimental setup. The demonstration video of our system can be found at <a target="_blank" href="https://youtu.be/QkEeFlu1x4A" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://youtu.be/QkEeFlu1x4A</a>. Our code and data will be available soon.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Medical Visual Question Answering Benchmark Evaluation System Comprehensive Empirical Study
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Medical visual question answering is a challenging task in healthcare industry, which answers a natural language question with a medical image. Fig.<a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows an example of the Med-VQA data. It may aid doctors in interpreting medical images for diagnoses with responses to close questions, or help patients with urgent needs get timely feedback on open questions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. It is a challenging problem in computer vision and natural language processing, which processes multi-modal information of visual images and textual language. Different from general VQA, Med-VQA requires substantial prior domain-specific knowledge to thoroughly understand the contents and semantics of medical visual questions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Many exiting techniques in information systems contribute to solving this task (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>). However, they generally suffer from the data insufficient problem. They need to be trained on well-annotated large-scale datasets, to learn enough domain-specific knowledge for understanding medical visual questions. Several works have focused on constructing Med-VQA datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. However, these datasets seem to be a drop in the bucket. Several works employ data augmentation method to tackle the problem. VQAMix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> has focused on generating Med-VQA training samples. However, it may incur noisy samples that affect the performance of models. Current work have adopted transfer learning to pre-train a visual encoder on external medical image-text pairs to capture suitable visual representations for subsequent cross-modal reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. They have achieved significant success by performing pre-training using large-scale pairs of medical images and text, without additional manual annotations. However, they have not been thoroughly evaluated in benchmark settings.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F2.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:206.0pt;"><img src="/html/2312.07867/assets/pics/pic.png" id="S1.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="425" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An example of Med-VQA</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F2.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:223.3pt;"><img src="/html/2312.07867/assets/pics/paper.png" id="S1.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="538" height="391" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Publications on Med-VQA since 2016</figcaption>
</figure>
</div>
</div>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To address the problems, we develop BESTMVQA, which is a benchmark evaluation system for Med-VQA. We first provide a data generation tool for users to automatically construct new datasets from self-collected clinical data. We implement a wide spectrum of SOTA models for Med-VQA in a model library. Accordingly, users can conveniently select a benchmark dataset and any model in model library for medical practice. Our system can automatically train the models and evaluate them over the selected dataset, and present a final comprehensive report to users. With our system, researchers can comprehensively study SOTA models and their applicability in Med-VQA. The impact of our contributions also can be inferred from Fig.<a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, which shows the significant increase in Med-VQA publications since 2016. We provide a unified evaluation system for users to (<span id="S1.p3.1.1" class="ltx_text ltx_font_italic">i</span>) reveal the applicability of SOTA models to benchmark datasets, (<span id="S1.p3.1.2" class="ltx_text ltx_font_italic">ii</span>) conduct a comprehensive study of the available alternatives to develop new Med-VQA techniques, and (<span id="S1.p3.1.3" class="ltx_text ltx_font_italic">iii</span>) perform various medical practice.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Research Scope and Task Description</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The research scope is tailored to two types of readers: (<span id="S2.p1.1.1" class="ltx_text ltx_font_italic">i</span>) Researchers who require Med-VQA techniques to perform downstream tasks; (<span id="S2.p1.1.2" class="ltx_text ltx_font_italic">ii</span>) Contributors in the research community of Med-VQA who need to thoroughly evaluate the SOTAs.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Medical visual question answering is defined as a domain-specific task that takes a medical image and a clinical question about the image as the input and output an answer in natural language. It generally requires prior domain-specific knowledge to thoroughly understand the contents and semantics of medical visual questions, resulting in additional challenges compared against the general VQA task. The lack of well-annotated large-scale datasets makes it hard to learn enough medical knowledge. To address the challenge, current work typically pre-train a visual encoder on large unlabeled medical image-text pairs.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In Fig. <a href="#S2.F3" title="Figure 3 ‣ 2 Research Scope and Task Description ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, Med-VQA models mainly contain four components: vision encoder, text encoder, feature fusion and answer prediction. The vision encoder takes a medical image as the input, then outputs the image features. The text encoder captures the textual features by taking the medical question as the input. The visual and textual features are then fused to generate a joint representation that is finally used as the input of a classifier or generator for predicting the answer.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2312.07867/assets/x1.png" id="S2.F3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The architecture of mainstream Med-VQA models</figcaption>
</figure>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The statistics of considered models, including the parameter size (Params), the training time (Training Time), supporting pre-training or not (Support PT), supporting fine-tuning or not (Support FT) and model category (Model Category). The left value of Training Time represents the smallest training time over all datasets, while the right value is the largest one.</figcaption>
<table id="S2.T1.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.7.8.1" class="ltx_tr">
<td id="S2.T1.7.8.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Baseline</td>
<td id="S2.T1.7.8.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Params</td>
<td id="S2.T1.7.8.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Training Time</td>
<td id="S2.T1.7.8.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Support PT</td>
<td id="S2.T1.7.8.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Support FT</td>
<td id="S2.T1.7.8.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Model Category</td>
</tr>
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MEVF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15M</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.03h 0.3h</td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><times id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Joint Embedding</td>
</tr>
<tr id="S2.T1.2.2" class="ltx_tr">
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S2.T1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38M</td>
<td id="S2.T1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.04h-0.4h</td>
<td id="S2.T1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.2.2.1.m1.1a"><mo id="S2.T1.2.2.1.m1.1.1" xref="S2.T1.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.1.m1.1b"><times id="S2.T1.2.2.1.m1.1.1.cmml" xref="S2.T1.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.2.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Joint Embedding</td>
</tr>
<tr id="S2.T1.7.9.2" class="ltx_tr">
<td id="S2.T1.7.9.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MMQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S2.T1.7.9.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20M</td>
<td id="S2.T1.7.9.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.5h-3.0h</td>
<td id="S2.T1.7.9.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.9.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.9.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Joint Embedding</td>
</tr>
<tr id="S2.T1.3.3" class="ltx_tr">
<td id="S2.T1.3.3.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VQAMix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S2.T1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19M</td>
<td id="S2.T1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.6h-6.0h</td>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.3.3.1.m1.1a"><mo id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><times id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.3.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Joint Embedding</td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CMSA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S2.T1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">88M</td>
<td id="S2.T1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.0h-4.2h</td>
<td id="S2.T1.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.4.4.1.m1.1a"><mo id="S2.T1.4.4.1.m1.1.1" xref="S2.T1.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.1.m1.1b"><times id="S2.T1.4.4.1.m1.1.1.cmml" xref="S2.T1.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Attention-Based</td>
</tr>
<tr id="S2.T1.7.10.3" class="ltx_tr">
<td id="S2.T1.7.10.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MMBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</td>
<td id="S2.T1.7.10.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">117M</td>
<td id="S2.T1.7.10.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.7h-13.3h</td>
<td id="S2.T1.7.10.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.10.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.10.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Attention-Based</td>
</tr>
<tr id="S2.T1.7.11.4" class="ltx_tr">
<td id="S2.T1.7.11.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PTUnifier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S2.T1.7.11.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">350M</td>
<td id="S2.T1.7.11.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.0h-13.0h</td>
<td id="S2.T1.7.11.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.11.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.11.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Attention-Based</td>
</tr>
<tr id="S2.T1.7.12.5" class="ltx_tr">
<td id="S2.T1.7.12.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">METER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S2.T1.7.12.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">320M</td>
<td id="S2.T1.7.12.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.5h-18.0h</td>
<td id="S2.T1.7.12.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.12.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.7.12.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Attention-Based</td>
</tr>
<tr id="S2.T1.5.5" class="ltx_tr">
<td id="S2.T1.5.5.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">TCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S2.T1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">580M</td>
<td id="S2.T1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.3h-8.3h</td>
<td id="S2.T1.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.5.5.1.m1.1a"><mo id="S2.T1.5.5.1.m1.1.1" xref="S2.T1.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.1.m1.1b"><times id="S2.T1.5.5.1.m1.1.1.cmml" xref="S2.T1.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S2.T1.5.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Encoder-Decoder</td>
</tr>
<tr id="S2.T1.7.7" class="ltx_tr">
<td id="S2.T1.7.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">MiniGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S2.T1.7.7.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">14110M</td>
<td id="S2.T1.7.7.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S2.T1.6.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S2.T1.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.6.6.1.m1.1a"><mo id="S2.T1.6.6.1.m1.1.1" xref="S2.T1.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.1.m1.1b"><times id="S2.T1.6.6.1.m1.1.1.cmml" xref="S2.T1.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.7.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S2.T1.7.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.7.7.2.m1.1a"><mo id="S2.T1.7.7.2.m1.1.1" xref="S2.T1.7.7.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.2.m1.1b"><times id="S2.T1.7.7.2.m1.1.1.cmml" xref="S2.T1.7.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.7.7.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">LLMs</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related Work</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Med-VQA is a challenging task that combines natural language processing and computer vision. Early work employing traditional machine learning algorithms suffers from poor performance due to significant differences between visual and textual features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Inspired by the success of deep learning in information systems, deep learning models for Med-VQA are reported to have performance gains over traditional models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. They can be classified into four categories: joint embedding, encoder-decoder, attention-based, and large language models (LLMs). Table <a href="#S2.T1" title="Table 1 ‣ 2 Research Scope and Task Description ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the statistics of SOTAs we reproduced.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The joint embedding models combine visual and textual embeddings into a final representation. We implement some representative models such as MEVF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and CR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> . MEVF uses MAML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and CDAE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to initialize the model weights for visual feature extraction, while CR proposes question-conditioned reasoning and task-conditioned reasoning modules for textual feature extraction.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">For encoder-decoder models, visual and textual features are extracted separately by encoders, and fused in a feature fusion layer. The decoder generates the answer based on the fused features. TCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> is such a representative model.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">The third category employs attention mechanisms to capture representative visual and textual features. We have implemented four representative models, including MMBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, CMSA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, PTUnifier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and METER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. MMBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> employ Transformer-style architecture to extract visual and textual features. CMSA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> introduce a cross-modal self-attention module to selectively capture the long-range contextual relevance for more effective fusion of visual and textual features.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Recently, LLMs are trained on large amounts of textual data that can help interpret complex and detailed information in medical images. Our model library also provides the MiniGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> for generating the linguistic representation of the question in Med-VQA, and supporting further medical practice.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2312.07867/assets/pics/demo.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="292" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>System architecture of our BESTMVQA</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>System Overview</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In Fig.<a href="#S3.F4" title="Figure 4 ‣ 3 Related Work ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, our BESTMVQA system has three components: data preparation, model library, and model practice. The data preparation component is developed based on a semi-automatic data generation tool. Users first upload self-collected clinical data. Then, medical images and relevant texts are extracted for medical concept discovery. We provide a human-in-the-loop framework to analyze and annotate medical concepts. To facilitate the effort, we first auto-label the medical concepts by employing the BioLinkBERT-BiLSTM-CRF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Then, professionals can conveniently verify the medical concepts. After that, medical images, medical concepts and diagnosis texts are fed into a pre-trained language model for generating high-quality QA pairs. We employ a large-scale medical multi-modal corpus to pre-train and fine-tune an effective model, which can be easily incorporated into existing neural models for generating medical VQA pairs. our system provides a model library, to avoid duplication of efforts on implementing SOTAs for experimental evaluation. A wide spectrum of SOTAs have been implemented. The detailed statistics of the models can be seen in Section <a href="#S3" title="3 Related Work ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Based our library, users can conveniently select a benchmark dataset and any number of SOTAs from our model library. Then, our system automatically performs extensive experiments to evaluate SOTAs over the benchmark dataset, and presents the final report to the user. From our report, the user can comprehensively study SOTAs and their applicability to Med-VQA. Users can also download the experimental reports and the source codes for further practice.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Empirical Study</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Users can conveniently use our BESTMVQA system to systematically evaluate SOTAs on benchmark datasets for Med-VQA. To comprehensively evaluate the effectiveness of the models, we employ the metric of <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="accuracy" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1a" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.4" xref="S5.p1.1.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1b" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.5" xref="S5.p1.1.m1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1c" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.6" xref="S5.p1.1.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1d" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.7" xref="S5.p1.1.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1e" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.8" xref="S5.p1.1.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1f" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.9" xref="S5.p1.1.m1.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝑎</ci><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">𝑐</ci><ci id="S5.p1.1.m1.1.1.4.cmml" xref="S5.p1.1.m1.1.1.4">𝑐</ci><ci id="S5.p1.1.m1.1.1.5.cmml" xref="S5.p1.1.m1.1.1.5">𝑢</ci><ci id="S5.p1.1.m1.1.1.6.cmml" xref="S5.p1.1.m1.1.1.6">𝑟</ci><ci id="S5.p1.1.m1.1.1.7.cmml" xref="S5.p1.1.m1.1.1.7">𝑎</ci><ci id="S5.p1.1.m1.1.1.8.cmml" xref="S5.p1.1.m1.1.1.8">𝑐</ci><ci id="S5.p1.1.m1.1.1.9.cmml" xref="S5.p1.1.m1.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">accuracy</annotation></semantics></math> for open-ended questions, closed-ended questions, and the overall questions. Five datasets are provided for users for model practice to investigate the applicability of models to diverse application scenarios.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>The statistics of datasets. Here, NI, NQ, and NA represent the number of images, questions and answers, respectively. MeanQL and MeanAL represent the length of questions and answers, respectively.</figcaption>
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Dataset</th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NI</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NQ</th>
<th id="S5.T2.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MeanQL</th>
<th id="S5.T2.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MeanAL</th>
<th id="S5.T2.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NA</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.2.1" class="ltx_tr">
<td id="S5.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VQA-RAD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</td>
<td id="S5.T2.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">314</td>
<td id="S5.T2.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3515</td>
<td id="S5.T2.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6.49</td>
<td id="S5.T2.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.61</td>
<td id="S5.T2.1.2.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">557</td>
</tr>
<tr id="S5.T2.1.3.2" class="ltx_tr">
<td id="S5.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MedVQA-2019 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</td>
<td id="S5.T2.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4200</td>
<td id="S5.T2.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15292</td>
<td id="S5.T2.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6.88</td>
<td id="S5.T2.1.3.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.12</td>
<td id="S5.T2.1.3.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1749</td>
</tr>
<tr id="S5.T2.1.4.3" class="ltx_tr">
<td id="S5.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">SLAKE-EN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</td>
<td id="S5.T2.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">642</td>
<td id="S5.T2.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7033</td>
<td id="S5.T2.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8.03</td>
<td id="S5.T2.1.4.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.4</td>
<td id="S5.T2.1.4.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">234</td>
</tr>
<tr id="S5.T2.1.5.4" class="ltx_tr">
<td id="S5.T2.1.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PathVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</td>
<td id="S5.T2.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4289</td>
<td id="S5.T2.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32795</td>
<td id="S5.T2.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6.33</td>
<td id="S5.T2.1.5.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.79</td>
<td id="S5.T2.1.5.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4946</td>
</tr>
<tr id="S5.T2.1.6.5" class="ltx_tr">
<td id="S5.T2.1.6.5.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">OVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S5.T2.1.6.5.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">2000</td>
<td id="S5.T2.1.6.5.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">19020</td>
<td id="S5.T2.1.6.5.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">8.73</td>
<td id="S5.T2.1.6.5.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">3.32</td>
<td id="S5.T2.1.6.5.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">1065</td>
</tr>
</tbody>
</table>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Considered Models</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We emphasize the utilization of “out-of-the-box” models, defining a model as “usable out of the box” if it meets the following criteria: (<span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">i</span>) publicly available executable source code, (<span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_italic">ii</span>) well-defined default hyperparameters, (<span id="S5.SS1.p1.1.3" class="ltx_text ltx_font_italic">iii</span>) no mandatory hyperparameter optimization, and (<span id="S5.SS1.p1.1.4" class="ltx_text ltx_font_italic">iv</span>) absence of requirements for language model retraining and vocabulary adaptation. To ensure consistent evaluation and practical applicability, all models are expected to generate predictions in a standard format. Adhering to the criteria is essential for models that can help guarantee aligning with the concept of “out of the box”.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">According to this definition, ten models are identified and classified, as shown in Table <a href="#S2.T1" title="Table 1 ‣ 2 Research Scope and Task Description ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. These models contain: (<span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">i</span>) those specifically tailored for Med-VQA, and (<span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">ii</span>) the application of general VQA models to the medical domain.</p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/ovqa.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="186" height="190" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S5.F5.sf1.3.2" class="ltx_text" style="font-size:80%;">OVQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/medvqa.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_img_square" width="186" height="191" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S5.F5.sf2.3.2" class="ltx_text" style="font-size:80%;">MedVQA-2019</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/slake.png" id="S5.F5.sf3.g1" class="ltx_graphics ltx_img_square" width="186" height="191" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S5.F5.sf3.3.2" class="ltx_text" style="font-size:80%;">SLAKE-EN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/pathvqa.png" id="S5.F5.sf4.g1" class="ltx_graphics ltx_img_square" width="180" height="175" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf4.2.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S5.F5.sf4.3.2" class="ltx_text" style="font-size:80%;">PathVQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/vqarad.png" id="S5.F5.sf5.g1" class="ltx_graphics ltx_img_square" width="180" height="184" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf5.2.1.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><span id="S5.F5.sf5.3.2" class="ltx_text" style="font-size:80%;">VQA-RAD</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Distribution of question types per dataset</figcaption>
</figure>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Default values for Batch Size, Learning Rate, and Epoch for each model</figcaption>
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Baseline</th>
<th id="S5.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Batch Size</th>
<th id="S5.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Learning Rate</th>
<th id="S5.T3.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Epoch</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.1.2.1" class="ltx_tr">
<td id="S5.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MEVF+SAN</td>
<td id="S5.T3.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">16</td>
<td id="S5.T3.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20</td>
</tr>
<tr id="S5.T3.1.3.2" class="ltx_tr">
<td id="S5.T3.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MEVF+BAN</td>
<td id="S5.T3.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8</td>
<td id="S5.T3.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20</td>
</tr>
<tr id="S5.T3.1.4.3" class="ltx_tr">
<td id="S5.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CR</td>
<td id="S5.T3.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64</td>
<td id="S5.T3.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">40</td>
</tr>
<tr id="S5.T3.1.5.4" class="ltx_tr">
<td id="S5.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MMQ</td>
<td id="S5.T3.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64</td>
<td id="S5.T3.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">60</td>
</tr>
<tr id="S5.T3.1.6.5" class="ltx_tr">
<td id="S5.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VQAMix+SAN</td>
<td id="S5.T3.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8</td>
<td id="S5.T3.1.6.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.6.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80</td>
</tr>
<tr id="S5.T3.1.7.6" class="ltx_tr">
<td id="S5.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VQAMix+BAN</td>
<td id="S5.T3.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8</td>
<td id="S5.T3.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.7.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80</td>
</tr>
<tr id="S5.T3.1.8.7" class="ltx_tr">
<td id="S5.T3.1.8.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CMSA</td>
<td id="S5.T3.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32</td>
<td id="S5.T3.1.8.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.8.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">60</td>
</tr>
<tr id="S5.T3.1.9.8" class="ltx_tr">
<td id="S5.T3.1.9.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MMBERT</td>
<td id="S5.T3.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">16</td>
<td id="S5.T3.1.9.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-03</td>
<td id="S5.T3.1.9.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80</td>
</tr>
<tr id="S5.T3.1.10.9" class="ltx_tr">
<td id="S5.T3.1.10.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PTUnifier</td>
<td id="S5.T3.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8</td>
<td id="S5.T3.1.10.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-05</td>
<td id="S5.T3.1.10.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50</td>
</tr>
<tr id="S5.T3.1.11.10" class="ltx_tr">
<td id="S5.T3.1.11.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">METER</td>
<td id="S5.T3.1.11.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32</td>
<td id="S5.T3.1.11.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.00E-05</td>
<td id="S5.T3.1.11.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25</td>
</tr>
<tr id="S5.T3.1.12.11" class="ltx_tr">
<td id="S5.T3.1.12.11.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">TCL</td>
<td id="S5.T3.1.12.11.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">4</td>
<td id="S5.T3.1.12.11.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">2.00E-05</td>
<td id="S5.T3.1.12.11.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">20</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental Setup</h3>

<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Datasets.</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.1" class="ltx_p">All models are evaluated using the following five datasets:</p>
</div>
<div id="S5.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p2.1" class="ltx_p"><span id="S5.SS2.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_bold">OVQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> has 2,001 images and 19,020 QA pairs, with each image linked to multiple QA pairs.</p>
</div>
<div id="S5.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p3.1" class="ltx_p"><span id="S5.SS2.SSS0.Px1.p3.1.1" class="ltx_text ltx_font_bold">VQA-RAD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> includes 314 images and 3,515 questions answered by clinical doctors, with 10 question types across the head, chest and abdomen.</p>
</div>
<div id="S5.SS2.SSS0.Px1.p4" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p4.1" class="ltx_p"><span id="S5.SS2.SSS0.Px1.p4.1.1" class="ltx_text ltx_font_bold">SLAKE</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> is a bilingual dataset annotated by experienced doctors, which is represented as SLAKE-EN in English.</p>
</div>
<div id="S5.SS2.SSS0.Px1.p5" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p5.1" class="ltx_p"><span id="S5.SS2.SSS0.Px1.p5.1.1" class="ltx_text ltx_font_bold">MedVQA-2019</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is a radiology dataset from the ImageClef challenge, which includes 642 images with over 7,000 QA pairs.</p>
</div>
<div id="S5.SS2.SSS0.Px1.p6" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p6.1" class="ltx_p"><span id="S5.SS2.SSS0.Px1.p6.1.1" class="ltx_text ltx_font_bold">PathVQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> consists of 32,795 pairs generated from pathological images.</p>
</div>
<div id="S5.SS2.SSS0.Px1.p7" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p7.1" class="ltx_p">Datasets were chosen for their diversity in sample sizes (refer to Table <a href="#S5.T2" title="Table 2 ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). For VQA-RAD and SLAKE, we have reorganized the datasets in a 70%-15%-15% ratio due to the lack of validation sets. As for the other datasets, We use the proportion of the corresponding dataset for split. The detailed statistics for data splits are shown in Table <a href="#S5.T4" title="Table 4 ‣ Datasets. ‣ 5.2 Experimental Setup ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The distribution of question types is illustrated in Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.1 Considered Models ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>The statistics of data splits. NI represents the number of images. MaxQL, MinQL and MeanQL represent the max, min and mean length of question, respectively; NCF and NOF represent the number of close-ended and open-ended questions in the corresponding samples. Note that MedVQA-2019 is not strictly divided into open-ended and closed-ended questions.</figcaption>
<table id="S5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Dataset</th>
<th id="S5.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Sample</th>
<th id="S5.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NI</th>
<th id="S5.T4.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MaxQL</th>
<th id="S5.T4.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MinQL</th>
<th id="S5.T4.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">MeanQL</th>
<th id="S5.T4.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Vocabulary</th>
<th id="S5.T4.1.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NCF</th>
<th id="S5.T4.1.1.1.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NOF</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.1.2.1" class="ltx_tr">
<th id="S5.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">VQA-RAD (train)</th>
<td id="S5.T4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2451</td>
<td id="S5.T4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">314</td>
<td id="S5.T4.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21</td>
<td id="S5.T4.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3</td>
<th id="S5.T4.1.2.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">6.43</th>
<td id="S5.T4.1.2.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1114</td>
<td id="S5.T4.1.2.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1443</td>
<td id="S5.T4.1.2.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1008</td>
</tr>
<tr id="S5.T4.1.3.2" class="ltx_tr">
<th id="S5.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">VQA-RAD (valid)</th>
<td id="S5.T4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">613</td>
<td id="S5.T4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r">258</td>
<td id="S5.T4.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r">19</td>
<td id="S5.T4.1.3.2.5" class="ltx_td ltx_align_left ltx_border_r">3</td>
<th id="S5.T4.1.3.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.42</th>
<td id="S5.T4.1.3.2.7" class="ltx_td ltx_align_left ltx_border_r">625</td>
<td id="S5.T4.1.3.2.8" class="ltx_td ltx_align_left ltx_border_r">380</td>
<td id="S5.T4.1.3.2.9" class="ltx_td ltx_align_left ltx_border_r">233</td>
</tr>
<tr id="S5.T4.1.4.3" class="ltx_tr">
<th id="S5.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">VQA-RAD (test)</th>
<td id="S5.T4.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r">451</td>
<td id="S5.T4.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r">203</td>
<td id="S5.T4.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r">22</td>
<td id="S5.T4.1.4.3.5" class="ltx_td ltx_align_left ltx_border_r">3</td>
<th id="S5.T4.1.4.3.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.89</th>
<td id="S5.T4.1.4.3.7" class="ltx_td ltx_align_left ltx_border_r">538</td>
<td id="S5.T4.1.4.3.8" class="ltx_td ltx_align_left ltx_border_r">272</td>
<td id="S5.T4.1.4.3.9" class="ltx_td ltx_align_left ltx_border_r">179</td>
</tr>
<tr id="S5.T4.1.5.4" class="ltx_tr">
<th id="S5.T4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Total</th>
<td id="S5.T4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">3515</td>
<td id="S5.T4.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r">314</td>
<td id="S5.T4.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r">22</td>
<td id="S5.T4.1.5.4.5" class="ltx_td ltx_align_left ltx_border_r">3</td>
<th id="S5.T4.1.5.4.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.49</th>
<td id="S5.T4.1.5.4.7" class="ltx_td ltx_align_left ltx_border_r">1288</td>
<td id="S5.T4.1.5.4.8" class="ltx_td ltx_align_left ltx_border_r">2095</td>
<td id="S5.T4.1.5.4.9" class="ltx_td ltx_align_left ltx_border_r">1420</td>
</tr>
<tr id="S5.T4.1.6.5" class="ltx_tr">
<th id="S5.T4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">MedVQA-2019 (train)</th>
<td id="S5.T4.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12792</td>
<td id="S5.T4.1.6.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3200</td>
<td id="S5.T4.1.6.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">11</td>
<td id="S5.T4.1.6.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4</td>
<th id="S5.T4.1.6.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">6.88</th>
<td id="S5.T4.1.6.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98</td>
<td id="S5.T4.1.6.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S5.T4.1.6.5.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S5.T4.1.7.6" class="ltx_tr">
<th id="S5.T4.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MedVQA-2019 (valid)</th>
<td id="S5.T4.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r">2000</td>
<td id="S5.T4.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r">500</td>
<td id="S5.T4.1.7.6.4" class="ltx_td ltx_align_left ltx_border_r">11</td>
<td id="S5.T4.1.7.6.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.7.6.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.86</th>
<td id="S5.T4.1.7.6.7" class="ltx_td ltx_align_left ltx_border_r">94</td>
<td id="S5.T4.1.7.6.8" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.1.7.6.9" class="ltx_td ltx_align_left ltx_border_r">-</td>
</tr>
<tr id="S5.T4.1.8.7" class="ltx_tr">
<th id="S5.T4.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MedVQA-2019 (test)</th>
<td id="S5.T4.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r">500</td>
<td id="S5.T4.1.8.7.3" class="ltx_td ltx_align_left ltx_border_r">500</td>
<td id="S5.T4.1.8.7.4" class="ltx_td ltx_align_left ltx_border_r">11</td>
<td id="S5.T4.1.8.7.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.8.7.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.86</th>
<td id="S5.T4.1.8.7.7" class="ltx_td ltx_align_left ltx_border_r">93</td>
<td id="S5.T4.1.8.7.8" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.1.8.7.9" class="ltx_td ltx_align_left ltx_border_r">-</td>
</tr>
<tr id="S5.T4.1.9.8" class="ltx_tr">
<th id="S5.T4.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Total</th>
<td id="S5.T4.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">15292</td>
<td id="S5.T4.1.9.8.3" class="ltx_td ltx_align_left ltx_border_r">4200</td>
<td id="S5.T4.1.9.8.4" class="ltx_td ltx_align_left ltx_border_r">11</td>
<td id="S5.T4.1.9.8.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.9.8.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.88</th>
<td id="S5.T4.1.9.8.7" class="ltx_td ltx_align_left ltx_border_r">98</td>
<td id="S5.T4.1.9.8.8" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.1.9.8.9" class="ltx_td ltx_align_left ltx_border_r">-</td>
</tr>
<tr id="S5.T4.1.10.9" class="ltx_tr">
<th id="S5.T4.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SLAKE-EN (train)</th>
<td id="S5.T4.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4777</td>
<td id="S5.T4.1.10.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">546</td>
<td id="S5.T4.1.10.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21</td>
<td id="S5.T4.1.10.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4</td>
<th id="S5.T4.1.10.9.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">7.98</th>
<td id="S5.T4.1.10.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">301</td>
<td id="S5.T4.1.10.9.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1905</td>
<td id="S5.T4.1.10.9.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2872</td>
</tr>
<tr id="S5.T4.1.11.10" class="ltx_tr">
<th id="S5.T4.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">SLAKE-EN (valid)</th>
<td id="S5.T4.1.11.10.2" class="ltx_td ltx_align_left ltx_border_r">1195</td>
<td id="S5.T4.1.11.10.3" class="ltx_td ltx_align_left ltx_border_r">484</td>
<td id="S5.T4.1.11.10.4" class="ltx_td ltx_align_left ltx_border_r">18</td>
<td id="S5.T4.1.11.10.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.11.10.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">8.12</th>
<td id="S5.T4.1.11.10.7" class="ltx_td ltx_align_left ltx_border_r">265</td>
<td id="S5.T4.1.11.10.8" class="ltx_td ltx_align_left ltx_border_r">460</td>
<td id="S5.T4.1.11.10.9" class="ltx_td ltx_align_left ltx_border_r">735</td>
</tr>
<tr id="S5.T4.1.12.11" class="ltx_tr">
<th id="S5.T4.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">SLAKE-EN (test)</th>
<td id="S5.T4.1.12.11.2" class="ltx_td ltx_align_left ltx_border_r">1061</td>
<td id="S5.T4.1.12.11.3" class="ltx_td ltx_align_left ltx_border_r">96</td>
<td id="S5.T4.1.12.11.4" class="ltx_td ltx_align_left ltx_border_r">21</td>
<td id="S5.T4.1.12.11.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.12.11.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">8.11</th>
<td id="S5.T4.1.12.11.7" class="ltx_td ltx_align_left ltx_border_r">265</td>
<td id="S5.T4.1.12.11.8" class="ltx_td ltx_align_left ltx_border_r">416</td>
<td id="S5.T4.1.12.11.9" class="ltx_td ltx_align_left ltx_border_r">645</td>
</tr>
<tr id="S5.T4.1.13.12" class="ltx_tr">
<th id="S5.T4.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Total</th>
<td id="S5.T4.1.13.12.2" class="ltx_td ltx_align_left ltx_border_r">7033</td>
<td id="S5.T4.1.13.12.3" class="ltx_td ltx_align_left ltx_border_r">642</td>
<td id="S5.T4.1.13.12.4" class="ltx_td ltx_align_left ltx_border_r">21</td>
<td id="S5.T4.1.13.12.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.13.12.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">8.03</th>
<td id="S5.T4.1.13.12.7" class="ltx_td ltx_align_left ltx_border_r">306</td>
<td id="S5.T4.1.13.12.8" class="ltx_td ltx_align_left ltx_border_r">2781</td>
<td id="S5.T4.1.13.12.9" class="ltx_td ltx_align_left ltx_border_r">4252</td>
</tr>
<tr id="S5.T4.1.14.13" class="ltx_tr">
<th id="S5.T4.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">PathVQA (train)</th>
<td id="S5.T4.1.14.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19755</td>
<td id="S5.T4.1.14.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2599</td>
<td id="S5.T4.1.14.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37</td>
<td id="S5.T4.1.14.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2</td>
<th id="S5.T4.1.14.13.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">6.35</th>
<td id="S5.T4.1.14.13.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4161</td>
<td id="S5.T4.1.14.13.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">9868</td>
<td id="S5.T4.1.14.13.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">9887</td>
</tr>
<tr id="S5.T4.1.15.14" class="ltx_tr">
<th id="S5.T4.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">PathVQA (valid)</th>
<td id="S5.T4.1.15.14.2" class="ltx_td ltx_align_left ltx_border_r">6279</td>
<td id="S5.T4.1.15.14.3" class="ltx_td ltx_align_left ltx_border_r">832</td>
<td id="S5.T4.1.15.14.4" class="ltx_td ltx_align_left ltx_border_r">37</td>
<td id="S5.T4.1.15.14.5" class="ltx_td ltx_align_left ltx_border_r">2</td>
<th id="S5.T4.1.15.14.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.24</th>
<td id="S5.T4.1.15.14.7" class="ltx_td ltx_align_left ltx_border_r">2537</td>
<td id="S5.T4.1.15.14.8" class="ltx_td ltx_align_left ltx_border_r">3156</td>
<td id="S5.T4.1.15.14.9" class="ltx_td ltx_align_left ltx_border_r">3123</td>
</tr>
<tr id="S5.T4.1.16.15" class="ltx_tr">
<th id="S5.T4.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">PathVQA (test)</th>
<td id="S5.T4.1.16.15.2" class="ltx_td ltx_align_left ltx_border_r">6761</td>
<td id="S5.T4.1.16.15.3" class="ltx_td ltx_align_left ltx_border_r">858</td>
<td id="S5.T4.1.16.15.4" class="ltx_td ltx_align_left ltx_border_r">42</td>
<td id="S5.T4.1.16.15.5" class="ltx_td ltx_align_left ltx_border_r">2</td>
<th id="S5.T4.1.16.15.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.33</th>
<td id="S5.T4.1.16.15.7" class="ltx_td ltx_align_left ltx_border_r">2608</td>
<td id="S5.T4.1.16.15.8" class="ltx_td ltx_align_left ltx_border_r">3409</td>
<td id="S5.T4.1.16.15.9" class="ltx_td ltx_align_left ltx_border_r">3352</td>
</tr>
<tr id="S5.T4.1.17.16" class="ltx_tr">
<th id="S5.T4.1.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Total</th>
<td id="S5.T4.1.17.16.2" class="ltx_td ltx_align_left ltx_border_r">32795</td>
<td id="S5.T4.1.17.16.3" class="ltx_td ltx_align_left ltx_border_r">4289</td>
<td id="S5.T4.1.17.16.4" class="ltx_td ltx_align_left ltx_border_r">42</td>
<td id="S5.T4.1.17.16.5" class="ltx_td ltx_align_left ltx_border_r">2</td>
<th id="S5.T4.1.17.16.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6.33</th>
<td id="S5.T4.1.17.16.7" class="ltx_td ltx_align_left ltx_border_r">5095</td>
<td id="S5.T4.1.17.16.8" class="ltx_td ltx_align_left ltx_border_r">16433</td>
<td id="S5.T4.1.17.16.9" class="ltx_td ltx_align_left ltx_border_r">16362</td>
</tr>
<tr id="S5.T4.1.18.17" class="ltx_tr">
<th id="S5.T4.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">OVQA (train)</th>
<td id="S5.T4.1.18.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15216</td>
<td id="S5.T4.1.18.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2000</td>
<td id="S5.T4.1.18.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95</td>
<td id="S5.T4.1.18.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4</td>
<th id="S5.T4.1.18.17.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">8.63</th>
<td id="S5.T4.1.18.17.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">958</td>
<td id="S5.T4.1.18.17.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8037</td>
<td id="S5.T4.1.18.17.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7179</td>
</tr>
<tr id="S5.T4.1.19.18" class="ltx_tr">
<th id="S5.T4.1.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">OVQA (valid)</th>
<td id="S5.T4.1.19.18.2" class="ltx_td ltx_align_left ltx_border_r">1902</td>
<td id="S5.T4.1.19.18.3" class="ltx_td ltx_align_left ltx_border_r">1235</td>
<td id="S5.T4.1.19.18.4" class="ltx_td ltx_align_left ltx_border_r">62</td>
<td id="S5.T4.1.19.18.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.19.18.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">9.04</th>
<td id="S5.T4.1.19.18.7" class="ltx_td ltx_align_left ltx_border_r">613</td>
<td id="S5.T4.1.19.18.8" class="ltx_td ltx_align_left ltx_border_r">830</td>
<td id="S5.T4.1.19.18.9" class="ltx_td ltx_align_left ltx_border_r">1072</td>
</tr>
<tr id="S5.T4.1.20.19" class="ltx_tr">
<th id="S5.T4.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">OVQA (test)</th>
<td id="S5.T4.1.20.19.2" class="ltx_td ltx_align_left ltx_border_r">1902</td>
<td id="S5.T4.1.20.19.3" class="ltx_td ltx_align_left ltx_border_r">1234</td>
<td id="S5.T4.1.20.19.4" class="ltx_td ltx_align_left ltx_border_r">67</td>
<td id="S5.T4.1.20.19.5" class="ltx_td ltx_align_left ltx_border_r">4</td>
<th id="S5.T4.1.20.19.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">9.26</th>
<td id="S5.T4.1.20.19.7" class="ltx_td ltx_align_left ltx_border_r">533</td>
<td id="S5.T4.1.20.19.8" class="ltx_td ltx_align_left ltx_border_r">832</td>
<td id="S5.T4.1.20.19.9" class="ltx_td ltx_align_left ltx_border_r">1070</td>
</tr>
<tr id="S5.T4.1.21.20" class="ltx_tr">
<th id="S5.T4.1.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Total</th>
<td id="S5.T4.1.21.20.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">19020</td>
<td id="S5.T4.1.21.20.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">2000</td>
<td id="S5.T4.1.21.20.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">95</td>
<td id="S5.T4.1.21.20.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">4</td>
<th id="S5.T4.1.21.20.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">8.73</th>
<td id="S5.T4.1.21.20.7" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1005</td>
<td id="S5.T4.1.21.20.8" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">9699</td>
<td id="S5.T4.1.21.20.9" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">9321</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Experimental results for each baseline on the test set of VQA-RAD, SLAKE-EN, PathVQA, and OVQA datasets. This includes the values of three indicators: Closed-ended Questions <math id="S5.T5.4.m1.1" class="ltx_Math" alttext="Accuracy" display="inline"><semantics id="S5.T5.4.m1.1b"><mrow id="S5.T5.4.m1.1.1" xref="S5.T5.4.m1.1.1.cmml"><mi id="S5.T5.4.m1.1.1.2" xref="S5.T5.4.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.3" xref="S5.T5.4.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1b" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.4" xref="S5.T5.4.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1c" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.5" xref="S5.T5.4.m1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1d" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.6" xref="S5.T5.4.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1e" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.7" xref="S5.T5.4.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1f" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.8" xref="S5.T5.4.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.4.m1.1.1.1g" xref="S5.T5.4.m1.1.1.1.cmml">​</mo><mi id="S5.T5.4.m1.1.1.9" xref="S5.T5.4.m1.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.4.m1.1c"><apply id="S5.T5.4.m1.1.1.cmml" xref="S5.T5.4.m1.1.1"><times id="S5.T5.4.m1.1.1.1.cmml" xref="S5.T5.4.m1.1.1.1"></times><ci id="S5.T5.4.m1.1.1.2.cmml" xref="S5.T5.4.m1.1.1.2">𝐴</ci><ci id="S5.T5.4.m1.1.1.3.cmml" xref="S5.T5.4.m1.1.1.3">𝑐</ci><ci id="S5.T5.4.m1.1.1.4.cmml" xref="S5.T5.4.m1.1.1.4">𝑐</ci><ci id="S5.T5.4.m1.1.1.5.cmml" xref="S5.T5.4.m1.1.1.5">𝑢</ci><ci id="S5.T5.4.m1.1.1.6.cmml" xref="S5.T5.4.m1.1.1.6">𝑟</ci><ci id="S5.T5.4.m1.1.1.7.cmml" xref="S5.T5.4.m1.1.1.7">𝑎</ci><ci id="S5.T5.4.m1.1.1.8.cmml" xref="S5.T5.4.m1.1.1.8">𝑐</ci><ci id="S5.T5.4.m1.1.1.9.cmml" xref="S5.T5.4.m1.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.m1.1d">Accuracy</annotation></semantics></math>, Open-ended Questions <math id="S5.T5.5.m2.1" class="ltx_Math" alttext="Accuracy" display="inline"><semantics id="S5.T5.5.m2.1b"><mrow id="S5.T5.5.m2.1.1" xref="S5.T5.5.m2.1.1.cmml"><mi id="S5.T5.5.m2.1.1.2" xref="S5.T5.5.m2.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.3" xref="S5.T5.5.m2.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1b" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.4" xref="S5.T5.5.m2.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1c" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.5" xref="S5.T5.5.m2.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1d" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.6" xref="S5.T5.5.m2.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1e" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.7" xref="S5.T5.5.m2.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1f" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.8" xref="S5.T5.5.m2.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.5.m2.1.1.1g" xref="S5.T5.5.m2.1.1.1.cmml">​</mo><mi id="S5.T5.5.m2.1.1.9" xref="S5.T5.5.m2.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.5.m2.1c"><apply id="S5.T5.5.m2.1.1.cmml" xref="S5.T5.5.m2.1.1"><times id="S5.T5.5.m2.1.1.1.cmml" xref="S5.T5.5.m2.1.1.1"></times><ci id="S5.T5.5.m2.1.1.2.cmml" xref="S5.T5.5.m2.1.1.2">𝐴</ci><ci id="S5.T5.5.m2.1.1.3.cmml" xref="S5.T5.5.m2.1.1.3">𝑐</ci><ci id="S5.T5.5.m2.1.1.4.cmml" xref="S5.T5.5.m2.1.1.4">𝑐</ci><ci id="S5.T5.5.m2.1.1.5.cmml" xref="S5.T5.5.m2.1.1.5">𝑢</ci><ci id="S5.T5.5.m2.1.1.6.cmml" xref="S5.T5.5.m2.1.1.6">𝑟</ci><ci id="S5.T5.5.m2.1.1.7.cmml" xref="S5.T5.5.m2.1.1.7">𝑎</ci><ci id="S5.T5.5.m2.1.1.8.cmml" xref="S5.T5.5.m2.1.1.8">𝑐</ci><ci id="S5.T5.5.m2.1.1.9.cmml" xref="S5.T5.5.m2.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.m2.1d">Accuracy</annotation></semantics></math>, and Overall <math id="S5.T5.6.m3.1" class="ltx_Math" alttext="Accuracy" display="inline"><semantics id="S5.T5.6.m3.1b"><mrow id="S5.T5.6.m3.1.1" xref="S5.T5.6.m3.1.1.cmml"><mi id="S5.T5.6.m3.1.1.2" xref="S5.T5.6.m3.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.3" xref="S5.T5.6.m3.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1b" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.4" xref="S5.T5.6.m3.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1c" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.5" xref="S5.T5.6.m3.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1d" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.6" xref="S5.T5.6.m3.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1e" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.7" xref="S5.T5.6.m3.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1f" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.8" xref="S5.T5.6.m3.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T5.6.m3.1.1.1g" xref="S5.T5.6.m3.1.1.1.cmml">​</mo><mi id="S5.T5.6.m3.1.1.9" xref="S5.T5.6.m3.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.6.m3.1c"><apply id="S5.T5.6.m3.1.1.cmml" xref="S5.T5.6.m3.1.1"><times id="S5.T5.6.m3.1.1.1.cmml" xref="S5.T5.6.m3.1.1.1"></times><ci id="S5.T5.6.m3.1.1.2.cmml" xref="S5.T5.6.m3.1.1.2">𝐴</ci><ci id="S5.T5.6.m3.1.1.3.cmml" xref="S5.T5.6.m3.1.1.3">𝑐</ci><ci id="S5.T5.6.m3.1.1.4.cmml" xref="S5.T5.6.m3.1.1.4">𝑐</ci><ci id="S5.T5.6.m3.1.1.5.cmml" xref="S5.T5.6.m3.1.1.5">𝑢</ci><ci id="S5.T5.6.m3.1.1.6.cmml" xref="S5.T5.6.m3.1.1.6">𝑟</ci><ci id="S5.T5.6.m3.1.1.7.cmml" xref="S5.T5.6.m3.1.1.7">𝑎</ci><ci id="S5.T5.6.m3.1.1.8.cmml" xref="S5.T5.6.m3.1.1.8">𝑐</ci><ci id="S5.T5.6.m3.1.1.9.cmml" xref="S5.T5.6.m3.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.m3.1d">Accuracy</annotation></semantics></math>. The definition of evaluation indicators can be found in Section <a href="#S5.SS3" title="5.3 Evaluation Metrics ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a></figcaption>
<table id="S5.T5.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.7.1.1" class="ltx_tr">
<th id="S5.T5.7.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">  Dataset</th>
<th id="S5.T5.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">  Baseline</th>
<th id="S5.T5.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">  Closed-ended</th>
<th id="S5.T5.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">  Open-ended</th>
<th id="S5.T5.7.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">     Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.7.2.1" class="ltx_tr">
<td id="S5.T5.7.2.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S5.T5.7.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MEVF+SAN</td>
<td id="S5.T5.7.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.4</td>
<td id="S5.T5.7.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.2</td>
<td id="S5.T5.7.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.4</td>
</tr>
<tr id="S5.T5.7.3.2" class="ltx_tr">
<td id="S5.T5.7.3.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.3.2.2" class="ltx_td ltx_align_center ltx_border_r">MEVF+BAN</td>
<td id="S5.T5.7.3.2.3" class="ltx_td ltx_align_center ltx_border_r">78.3</td>
<td id="S5.T5.7.3.2.4" class="ltx_td ltx_align_center ltx_border_r">52.5</td>
<td id="S5.T5.7.3.2.5" class="ltx_td ltx_align_center ltx_border_r">68.1</td>
</tr>
<tr id="S5.T5.7.4.3" class="ltx_tr">
<td id="S5.T5.7.4.3.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.4.3.2" class="ltx_td ltx_align_center ltx_border_r">CR</td>
<td id="S5.T5.7.4.3.3" class="ltx_td ltx_align_center ltx_border_r">77.2</td>
<td id="S5.T5.7.4.3.4" class="ltx_td ltx_align_center ltx_border_r">57.6</td>
<td id="S5.T5.7.4.3.5" class="ltx_td ltx_align_center ltx_border_r">69.4</td>
</tr>
<tr id="S5.T5.7.5.4" class="ltx_tr">
<td id="S5.T5.7.5.4.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.5.4.2" class="ltx_td ltx_align_center ltx_border_r">MMQ</td>
<td id="S5.T5.7.5.4.3" class="ltx_td ltx_align_center ltx_border_r">75.7</td>
<td id="S5.T5.7.5.4.4" class="ltx_td ltx_align_center ltx_border_r">56.9</td>
<td id="S5.T5.7.5.4.5" class="ltx_td ltx_align_center ltx_border_r">68.2</td>
</tr>
<tr id="S5.T5.7.6.5" class="ltx_tr">
<td id="S5.T5.7.6.5.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.6.5.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+SAN</td>
<td id="S5.T5.7.6.5.3" class="ltx_td ltx_align_center ltx_border_r">79.4</td>
<td id="S5.T5.7.6.5.4" class="ltx_td ltx_align_center ltx_border_r">57</td>
<td id="S5.T5.7.6.5.5" class="ltx_td ltx_align_center ltx_border_r">70.5</td>
</tr>
<tr id="S5.T5.7.7.6" class="ltx_tr">
<td id="S5.T5.7.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">VQA-RAD</td>
<td id="S5.T5.7.7.6.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+BAN</td>
<td id="S5.T5.7.7.6.3" class="ltx_td ltx_align_center ltx_border_r">80.9</td>
<td id="S5.T5.7.7.6.4" class="ltx_td ltx_align_center ltx_border_r">57.5</td>
<td id="S5.T5.7.7.6.5" class="ltx_td ltx_align_center ltx_border_r">71.6</td>
</tr>
<tr id="S5.T5.7.8.7" class="ltx_tr">
<td id="S5.T5.7.8.7.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.8.7.2" class="ltx_td ltx_align_center ltx_border_r">CMSA</td>
<td id="S5.T5.7.8.7.3" class="ltx_td ltx_align_center ltx_border_r">78.5</td>
<td id="S5.T5.7.8.7.4" class="ltx_td ltx_align_center ltx_border_r">63.7</td>
<td id="S5.T5.7.8.7.5" class="ltx_td ltx_align_center ltx_border_r">72.5</td>
</tr>
<tr id="S5.T5.7.9.8" class="ltx_tr">
<td id="S5.T5.7.9.8.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.9.8.2" class="ltx_td ltx_align_center ltx_border_r">MMBERT</td>
<td id="S5.T5.7.9.8.3" class="ltx_td ltx_align_center ltx_border_r">74.3</td>
<td id="S5.T5.7.9.8.4" class="ltx_td ltx_align_center ltx_border_r">46.9</td>
<td id="S5.T5.7.9.8.5" class="ltx_td ltx_align_center ltx_border_r">63.4</td>
</tr>
<tr id="S5.T5.7.10.9" class="ltx_tr">
<td id="S5.T5.7.10.9.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.10.9.2" class="ltx_td ltx_align_center ltx_border_r">PTUnifier</td>
<td id="S5.T5.7.10.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.10.9.3.1" class="ltx_text ltx_font_bold">86.4</span></td>
<td id="S5.T5.7.10.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.10.9.4.1" class="ltx_text ltx_font_bold">68.2</span></td>
<td id="S5.T5.7.10.9.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.10.9.5.1" class="ltx_text ltx_font_bold">79.2</span></td>
</tr>
<tr id="S5.T5.7.11.10" class="ltx_tr">
<td id="S5.T5.7.11.10.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.11.10.2" class="ltx_td ltx_align_center ltx_border_r">METER</td>
<td id="S5.T5.7.11.10.3" class="ltx_td ltx_align_center ltx_border_r">78.3</td>
<td id="S5.T5.7.11.10.4" class="ltx_td ltx_align_center ltx_border_r">57</td>
<td id="S5.T5.7.11.10.5" class="ltx_td ltx_align_center ltx_border_r">69.8</td>
</tr>
<tr id="S5.T5.7.12.11" class="ltx_tr">
<td id="S5.T5.7.12.11.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.12.11.2" class="ltx_td ltx_align_center ltx_border_r">TCL</td>
<td id="S5.T5.7.12.11.3" class="ltx_td ltx_align_center ltx_border_r">73.5</td>
<td id="S5.T5.7.12.11.4" class="ltx_td ltx_align_center ltx_border_r">56.4</td>
<td id="S5.T5.7.12.11.5" class="ltx_td ltx_align_center ltx_border_r">66.7</td>
</tr>
<tr id="S5.T5.7.13.12" class="ltx_tr">
<td id="S5.T5.7.13.12.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.13.12.2" class="ltx_td ltx_align_center ltx_border_r">MiniGPT-4</td>
<td id="S5.T5.7.13.12.3" class="ltx_td ltx_align_center ltx_border_r">27.9</td>
<td id="S5.T5.7.13.12.4" class="ltx_td ltx_align_center ltx_border_r">28.5</td>
<td id="S5.T5.7.13.12.5" class="ltx_td ltx_align_center ltx_border_r">28.2</td>
</tr>
<tr id="S5.T5.7.14.13" class="ltx_tr">
<td id="S5.T5.7.14.13.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S5.T5.7.14.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MEVF+SAN</td>
<td id="S5.T5.7.14.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.4</td>
<td id="S5.T5.7.14.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.3</td>
<td id="S5.T5.7.14.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.5</td>
</tr>
<tr id="S5.T5.7.15.14" class="ltx_tr">
<td id="S5.T5.7.15.14.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.15.14.2" class="ltx_td ltx_align_center ltx_border_r">MEVF+BAN</td>
<td id="S5.T5.7.15.14.3" class="ltx_td ltx_align_center ltx_border_r">81</td>
<td id="S5.T5.7.15.14.4" class="ltx_td ltx_align_center ltx_border_r">75.7</td>
<td id="S5.T5.7.15.14.5" class="ltx_td ltx_align_center ltx_border_r">77.8</td>
</tr>
<tr id="S5.T5.7.16.15" class="ltx_tr">
<td id="S5.T5.7.16.15.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.16.15.2" class="ltx_td ltx_align_center ltx_border_r">CR</td>
<td id="S5.T5.7.16.15.3" class="ltx_td ltx_align_center ltx_border_r">76.9</td>
<td id="S5.T5.7.16.15.4" class="ltx_td ltx_align_center ltx_border_r">78.4</td>
<td id="S5.T5.7.16.15.5" class="ltx_td ltx_align_center ltx_border_r">77.5</td>
</tr>
<tr id="S5.T5.7.17.16" class="ltx_tr">
<td id="S5.T5.7.17.16.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.17.16.2" class="ltx_td ltx_align_center ltx_border_r">MMQ</td>
<td id="S5.T5.7.17.16.3" class="ltx_td ltx_align_center ltx_border_r">78.4</td>
<td id="S5.T5.7.17.16.4" class="ltx_td ltx_align_center ltx_border_r">76.7</td>
<td id="S5.T5.7.17.16.5" class="ltx_td ltx_align_center ltx_border_r">77.4</td>
</tr>
<tr id="S5.T5.7.18.17" class="ltx_tr">
<td id="S5.T5.7.18.17.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.18.17.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+SAN</td>
<td id="S5.T5.7.18.17.3" class="ltx_td ltx_align_center ltx_border_r">77.9</td>
<td id="S5.T5.7.18.17.4" class="ltx_td ltx_align_center ltx_border_r">77.7</td>
<td id="S5.T5.7.18.17.5" class="ltx_td ltx_align_center ltx_border_r">77.8</td>
</tr>
<tr id="S5.T5.7.19.18" class="ltx_tr">
<td id="S5.T5.7.19.18.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">SLAKE-EN</td>
<td id="S5.T5.7.19.18.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+BAN</td>
<td id="S5.T5.7.19.18.3" class="ltx_td ltx_align_center ltx_border_r">83.2</td>
<td id="S5.T5.7.19.18.4" class="ltx_td ltx_align_center ltx_border_r">78.1</td>
<td id="S5.T5.7.19.18.5" class="ltx_td ltx_align_center ltx_border_r">80.1</td>
</tr>
<tr id="S5.T5.7.20.19" class="ltx_tr">
<td id="S5.T5.7.20.19.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.20.19.2" class="ltx_td ltx_align_center ltx_border_r">CMSA</td>
<td id="S5.T5.7.20.19.3" class="ltx_td ltx_align_center ltx_border_r">68.3</td>
<td id="S5.T5.7.20.19.4" class="ltx_td ltx_align_center ltx_border_r">49.1</td>
<td id="S5.T5.7.20.19.5" class="ltx_td ltx_align_center ltx_border_r">56.6</td>
</tr>
<tr id="S5.T5.7.21.20" class="ltx_tr">
<td id="S5.T5.7.21.20.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.21.20.2" class="ltx_td ltx_align_center ltx_border_r">MMBERT</td>
<td id="S5.T5.7.21.20.3" class="ltx_td ltx_align_center ltx_border_r">43.3</td>
<td id="S5.T5.7.21.20.4" class="ltx_td ltx_align_center ltx_border_r">1.9</td>
<td id="S5.T5.7.21.20.5" class="ltx_td ltx_align_center ltx_border_r">18.1</td>
</tr>
<tr id="S5.T5.7.22.21" class="ltx_tr">
<td id="S5.T5.7.22.21.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.22.21.2" class="ltx_td ltx_align_center ltx_border_r">PTUnifier</td>
<td id="S5.T5.7.22.21.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.22.21.3.1" class="ltx_text ltx_font_bold">89.4</span></td>
<td id="S5.T5.7.22.21.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.22.21.4.1" class="ltx_text ltx_font_bold">81.6</span></td>
<td id="S5.T5.7.22.21.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.22.21.5.1" class="ltx_text ltx_font_bold">84.6</span></td>
</tr>
<tr id="S5.T5.7.23.22" class="ltx_tr">
<td id="S5.T5.7.23.22.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.23.22.2" class="ltx_td ltx_align_center ltx_border_r">METER</td>
<td id="S5.T5.7.23.22.3" class="ltx_td ltx_align_center ltx_border_r">87.3</td>
<td id="S5.T5.7.23.22.4" class="ltx_td ltx_align_center ltx_border_r">79.2</td>
<td id="S5.T5.7.23.22.5" class="ltx_td ltx_align_center ltx_border_r">82.4</td>
</tr>
<tr id="S5.T5.7.24.23" class="ltx_tr">
<td id="S5.T5.7.24.23.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.24.23.2" class="ltx_td ltx_align_center ltx_border_r">TCL</td>
<td id="S5.T5.7.24.23.3" class="ltx_td ltx_align_center ltx_border_r">87.5</td>
<td id="S5.T5.7.24.23.4" class="ltx_td ltx_align_center ltx_border_r">78.4</td>
<td id="S5.T5.7.24.23.5" class="ltx_td ltx_align_center ltx_border_r">82</td>
</tr>
<tr id="S5.T5.7.25.24" class="ltx_tr">
<td id="S5.T5.7.25.24.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.25.24.2" class="ltx_td ltx_align_center ltx_border_r">MiniGPT-4</td>
<td id="S5.T5.7.25.24.3" class="ltx_td ltx_align_center ltx_border_r">25.6</td>
<td id="S5.T5.7.25.24.4" class="ltx_td ltx_align_center ltx_border_r">27.3</td>
<td id="S5.T5.7.25.24.5" class="ltx_td ltx_align_center ltx_border_r">26.8</td>
</tr>
<tr id="S5.T5.7.26.25" class="ltx_tr">
<td id="S5.T5.7.26.25.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S5.T5.7.26.25.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MEVF+SAN</td>
<td id="S5.T5.7.26.25.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.4</td>
<td id="S5.T5.7.26.25.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.1</td>
<td id="S5.T5.7.26.25.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.5</td>
</tr>
<tr id="S5.T5.7.27.26" class="ltx_tr">
<td id="S5.T5.7.27.26.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.27.26.2" class="ltx_td ltx_align_center ltx_border_r">MEVF+BAN</td>
<td id="S5.T5.7.27.26.3" class="ltx_td ltx_align_center ltx_border_r">83.8</td>
<td id="S5.T5.7.27.26.4" class="ltx_td ltx_align_center ltx_border_r">16.4</td>
<td id="S5.T5.7.27.26.5" class="ltx_td ltx_align_center ltx_border_r">50.3</td>
</tr>
<tr id="S5.T5.7.28.27" class="ltx_tr">
<td id="S5.T5.7.28.27.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.28.27.2" class="ltx_td ltx_align_center ltx_border_r">CR</td>
<td id="S5.T5.7.28.27.3" class="ltx_td ltx_align_center ltx_border_r">84.9</td>
<td id="S5.T5.7.28.27.4" class="ltx_td ltx_align_center ltx_border_r">15.9</td>
<td id="S5.T5.7.28.27.5" class="ltx_td ltx_align_center ltx_border_r">50.5</td>
</tr>
<tr id="S5.T5.7.29.28" class="ltx_tr">
<td id="S5.T5.7.29.28.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.29.28.2" class="ltx_td ltx_align_center ltx_border_r">MMQ</td>
<td id="S5.T5.7.29.28.3" class="ltx_td ltx_align_center ltx_border_r">83.2</td>
<td id="S5.T5.7.29.28.4" class="ltx_td ltx_align_center ltx_border_r">14.3</td>
<td id="S5.T5.7.29.28.5" class="ltx_td ltx_align_center ltx_border_r">48.9</td>
</tr>
<tr id="S5.T5.7.30.29" class="ltx_tr">
<td id="S5.T5.7.30.29.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.30.29.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+SAN</td>
<td id="S5.T5.7.30.29.3" class="ltx_td ltx_align_center ltx_border_r">83.9</td>
<td id="S5.T5.7.30.29.4" class="ltx_td ltx_align_center ltx_border_r">9.6</td>
<td id="S5.T5.7.30.29.5" class="ltx_td ltx_align_center ltx_border_r">46.9</td>
</tr>
<tr id="S5.T5.7.31.30" class="ltx_tr">
<td id="S5.T5.7.31.30.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">PathVQA</td>
<td id="S5.T5.7.31.30.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+BAN</td>
<td id="S5.T5.7.31.30.3" class="ltx_td ltx_align_center ltx_border_r">84.3</td>
<td id="S5.T5.7.31.30.4" class="ltx_td ltx_align_center ltx_border_r">12.7</td>
<td id="S5.T5.7.31.30.5" class="ltx_td ltx_align_center ltx_border_r">48.6</td>
</tr>
<tr id="S5.T5.7.32.31" class="ltx_tr">
<td id="S5.T5.7.32.31.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.32.31.2" class="ltx_td ltx_align_center ltx_border_r">CMSA</td>
<td id="S5.T5.7.32.31.3" class="ltx_td ltx_align_center ltx_border_r">83.7</td>
<td id="S5.T5.7.32.31.4" class="ltx_td ltx_align_center ltx_border_r">16.1</td>
<td id="S5.T5.7.32.31.5" class="ltx_td ltx_align_center ltx_border_r">50.2</td>
</tr>
<tr id="S5.T5.7.33.32" class="ltx_tr">
<td id="S5.T5.7.33.32.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.33.32.2" class="ltx_td ltx_align_center ltx_border_r">MMBERT</td>
<td id="S5.T5.7.33.32.3" class="ltx_td ltx_align_center ltx_border_r">83.2</td>
<td id="S5.T5.7.33.32.4" class="ltx_td ltx_align_center ltx_border_r">13</td>
<td id="S5.T5.7.33.32.5" class="ltx_td ltx_align_center ltx_border_r">48.1</td>
</tr>
<tr id="S5.T5.7.34.33" class="ltx_tr">
<td id="S5.T5.7.34.33.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.34.33.2" class="ltx_td ltx_align_center ltx_border_r">PTUnifier</td>
<td id="S5.T5.7.34.33.3" class="ltx_td ltx_align_center ltx_border_r">85.5</td>
<td id="S5.T5.7.34.33.4" class="ltx_td ltx_align_center ltx_border_r">10.1</td>
<td id="S5.T5.7.34.33.5" class="ltx_td ltx_align_center ltx_border_r">48.1</td>
</tr>
<tr id="S5.T5.7.35.34" class="ltx_tr">
<td id="S5.T5.7.35.34.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.35.34.2" class="ltx_td ltx_align_center ltx_border_r">METER</td>
<td id="S5.T5.7.35.34.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.35.34.3.1" class="ltx_text ltx_font_bold">89.9</span></td>
<td id="S5.T5.7.35.34.4" class="ltx_td ltx_align_center ltx_border_r">29.8</td>
<td id="S5.T5.7.35.34.5" class="ltx_td ltx_align_center ltx_border_r">60</td>
</tr>
<tr id="S5.T5.7.36.35" class="ltx_tr">
<td id="S5.T5.7.36.35.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.36.35.2" class="ltx_td ltx_align_center ltx_border_r">TCL</td>
<td id="S5.T5.7.36.35.3" class="ltx_td ltx_align_center ltx_border_r">88.1</td>
<td id="S5.T5.7.36.35.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.36.35.4.1" class="ltx_text ltx_font_bold">36.9</span></td>
<td id="S5.T5.7.36.35.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.36.35.5.1" class="ltx_text ltx_font_bold">62.7</span></td>
</tr>
<tr id="S5.T5.7.37.36" class="ltx_tr">
<td id="S5.T5.7.37.36.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.37.36.2" class="ltx_td ltx_align_center ltx_border_r">MiniGPT-4</td>
<td id="S5.T5.7.37.36.3" class="ltx_td ltx_align_center ltx_border_r">11.5</td>
<td id="S5.T5.7.37.36.4" class="ltx_td ltx_align_center ltx_border_r">13.9</td>
<td id="S5.T5.7.37.36.5" class="ltx_td ltx_align_center ltx_border_r">12.7</td>
</tr>
<tr id="S5.T5.7.38.37" class="ltx_tr">
<td id="S5.T5.7.38.37.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S5.T5.7.38.37.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MEVF+SAN</td>
<td id="S5.T5.7.38.37.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.2</td>
<td id="S5.T5.7.38.37.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52.3</td>
<td id="S5.T5.7.38.37.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.9</td>
</tr>
<tr id="S5.T5.7.39.38" class="ltx_tr">
<td id="S5.T5.7.39.38.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.39.38.2" class="ltx_td ltx_align_center ltx_border_r">MEVF+BAN</td>
<td id="S5.T5.7.39.38.3" class="ltx_td ltx_align_center ltx_border_r">76.6</td>
<td id="S5.T5.7.39.38.4" class="ltx_td ltx_align_center ltx_border_r">50.5</td>
<td id="S5.T5.7.39.38.5" class="ltx_td ltx_align_center ltx_border_r">61.9</td>
</tr>
<tr id="S5.T5.7.40.39" class="ltx_tr">
<td id="S5.T5.7.40.39.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.40.39.2" class="ltx_td ltx_align_center ltx_border_r">CR</td>
<td id="S5.T5.7.40.39.3" class="ltx_td ltx_align_center ltx_border_r">76.6</td>
<td id="S5.T5.7.40.39.4" class="ltx_td ltx_align_center ltx_border_r">36.9</td>
<td id="S5.T5.7.40.39.5" class="ltx_td ltx_align_center ltx_border_r">54.3</td>
</tr>
<tr id="S5.T5.7.41.40" class="ltx_tr">
<td id="S5.T5.7.41.40.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.41.40.2" class="ltx_td ltx_align_center ltx_border_r">MMQ</td>
<td id="S5.T5.7.41.40.3" class="ltx_td ltx_align_center ltx_border_r">79</td>
<td id="S5.T5.7.41.40.4" class="ltx_td ltx_align_center ltx_border_r">53.2</td>
<td id="S5.T5.7.41.40.5" class="ltx_td ltx_align_center ltx_border_r">64.5</td>
</tr>
<tr id="S5.T5.7.42.41" class="ltx_tr">
<td id="S5.T5.7.42.41.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.42.41.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+SAN</td>
<td id="S5.T5.7.42.41.3" class="ltx_td ltx_align_center ltx_border_r">77.6</td>
<td id="S5.T5.7.42.41.4" class="ltx_td ltx_align_center ltx_border_r">59.1</td>
<td id="S5.T5.7.42.41.5" class="ltx_td ltx_align_center ltx_border_r">67.2</td>
</tr>
<tr id="S5.T5.7.43.42" class="ltx_tr">
<td id="S5.T5.7.43.42.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">OVQA</td>
<td id="S5.T5.7.43.42.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+BAN</td>
<td id="S5.T5.7.43.42.3" class="ltx_td ltx_align_center ltx_border_r">79.3</td>
<td id="S5.T5.7.43.42.4" class="ltx_td ltx_align_center ltx_border_r">57</td>
<td id="S5.T5.7.43.42.5" class="ltx_td ltx_align_center ltx_border_r">66.8</td>
</tr>
<tr id="S5.T5.7.44.43" class="ltx_tr">
<td id="S5.T5.7.44.43.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.44.43.2" class="ltx_td ltx_align_center ltx_border_r">CMSA</td>
<td id="S5.T5.7.44.43.3" class="ltx_td ltx_align_center ltx_border_r">79.7</td>
<td id="S5.T5.7.44.43.4" class="ltx_td ltx_align_center ltx_border_r">45.6</td>
<td id="S5.T5.7.44.43.5" class="ltx_td ltx_align_center ltx_border_r">60.5</td>
</tr>
<tr id="S5.T5.7.45.44" class="ltx_tr">
<td id="S5.T5.7.45.44.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.45.44.2" class="ltx_td ltx_align_center ltx_border_r">MMBERT</td>
<td id="S5.T5.7.45.44.3" class="ltx_td ltx_align_center ltx_border_r">80.5</td>
<td id="S5.T5.7.45.44.4" class="ltx_td ltx_align_center ltx_border_r">48.7</td>
<td id="S5.T5.7.45.44.5" class="ltx_td ltx_align_center ltx_border_r">62.6</td>
</tr>
<tr id="S5.T5.7.46.45" class="ltx_tr">
<td id="S5.T5.7.46.45.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.46.45.2" class="ltx_td ltx_align_center ltx_border_r">PTUnifier</td>
<td id="S5.T5.7.46.45.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.46.45.3.1" class="ltx_text ltx_font_bold">84.9</span></td>
<td id="S5.T5.7.46.45.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.46.45.4.1" class="ltx_text ltx_font_bold">60.5</span></td>
<td id="S5.T5.7.46.45.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.7.46.45.5.1" class="ltx_text ltx_font_bold">71.3</span></td>
</tr>
<tr id="S5.T5.7.47.46" class="ltx_tr">
<td id="S5.T5.7.47.46.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.47.46.2" class="ltx_td ltx_align_center ltx_border_r">METER</td>
<td id="S5.T5.7.47.46.3" class="ltx_td ltx_align_center ltx_border_r">82.1</td>
<td id="S5.T5.7.47.46.4" class="ltx_td ltx_align_center ltx_border_r">51.7</td>
<td id="S5.T5.7.47.46.5" class="ltx_td ltx_align_center ltx_border_r">65.1</td>
</tr>
<tr id="S5.T5.7.48.47" class="ltx_tr">
<td id="S5.T5.7.48.47.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.48.47.2" class="ltx_td ltx_align_center ltx_border_r">TCL</td>
<td id="S5.T5.7.48.47.3" class="ltx_td ltx_align_center ltx_border_r">82.6</td>
<td id="S5.T5.7.48.47.4" class="ltx_td ltx_align_center ltx_border_r">60.4</td>
<td id="S5.T5.7.48.47.5" class="ltx_td ltx_align_center ltx_border_r">70.1</td>
</tr>
<tr id="S5.T5.7.49.48" class="ltx_tr">
<td id="S5.T5.7.49.48.1" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S5.T5.7.49.48.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">MiniGPT-4</td>
<td id="S5.T5.7.49.48.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">37.3</td>
<td id="S5.T5.7.49.48.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">46.7</td>
<td id="S5.T5.7.49.48.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">42.6</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Experimental results for each baseline on the test set of MedVQA-2019. Due to the fact that the MedVQA-2019 is not strictly divided into open-ended and closed-ended question types, the table only contains the values of Overall <math id="S5.T6.2.m1.1" class="ltx_Math" alttext="Accuracy" display="inline"><semantics id="S5.T6.2.m1.1b"><mrow id="S5.T6.2.m1.1.1" xref="S5.T6.2.m1.1.1.cmml"><mi id="S5.T6.2.m1.1.1.2" xref="S5.T6.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.3" xref="S5.T6.2.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1b" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.4" xref="S5.T6.2.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1c" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.5" xref="S5.T6.2.m1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1d" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.6" xref="S5.T6.2.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1e" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.7" xref="S5.T6.2.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1f" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.8" xref="S5.T6.2.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T6.2.m1.1.1.1g" xref="S5.T6.2.m1.1.1.1.cmml">​</mo><mi id="S5.T6.2.m1.1.1.9" xref="S5.T6.2.m1.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.2.m1.1c"><apply id="S5.T6.2.m1.1.1.cmml" xref="S5.T6.2.m1.1.1"><times id="S5.T6.2.m1.1.1.1.cmml" xref="S5.T6.2.m1.1.1.1"></times><ci id="S5.T6.2.m1.1.1.2.cmml" xref="S5.T6.2.m1.1.1.2">𝐴</ci><ci id="S5.T6.2.m1.1.1.3.cmml" xref="S5.T6.2.m1.1.1.3">𝑐</ci><ci id="S5.T6.2.m1.1.1.4.cmml" xref="S5.T6.2.m1.1.1.4">𝑐</ci><ci id="S5.T6.2.m1.1.1.5.cmml" xref="S5.T6.2.m1.1.1.5">𝑢</ci><ci id="S5.T6.2.m1.1.1.6.cmml" xref="S5.T6.2.m1.1.1.6">𝑟</ci><ci id="S5.T6.2.m1.1.1.7.cmml" xref="S5.T6.2.m1.1.1.7">𝑎</ci><ci id="S5.T6.2.m1.1.1.8.cmml" xref="S5.T6.2.m1.1.1.8">𝑐</ci><ci id="S5.T6.2.m1.1.1.9.cmml" xref="S5.T6.2.m1.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.m1.1d">Accuracy</annotation></semantics></math>.</figcaption>
<table id="S5.T6.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.3.1.1" class="ltx_tr">
<th id="S5.T6.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">  Dataset</th>
<th id="S5.T6.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">  Baseline</th>
<th id="S5.T6.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">     Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.3.2.1" class="ltx_tr">
<td id="S5.T6.3.2.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S5.T6.3.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MEVF+SAN</td>
<td id="S5.T6.3.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50</td>
</tr>
<tr id="S5.T6.3.3.2" class="ltx_tr">
<td id="S5.T6.3.3.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.3.2.2" class="ltx_td ltx_align_center ltx_border_r">MEVF+BAN</td>
<td id="S5.T6.3.3.2.3" class="ltx_td ltx_align_center ltx_border_r">47.4</td>
</tr>
<tr id="S5.T6.3.4.3" class="ltx_tr">
<td id="S5.T6.3.4.3.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.4.3.2" class="ltx_td ltx_align_center ltx_border_r">CR</td>
<td id="S5.T6.3.4.3.3" class="ltx_td ltx_align_center ltx_border_r">46.8</td>
</tr>
<tr id="S5.T6.3.5.4" class="ltx_tr">
<td id="S5.T6.3.5.4.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.5.4.2" class="ltx_td ltx_align_center ltx_border_r">MMQ</td>
<td id="S5.T6.3.5.4.3" class="ltx_td ltx_align_center ltx_border_r">50</td>
</tr>
<tr id="S5.T6.3.6.5" class="ltx_tr">
<td id="S5.T6.3.6.5.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.6.5.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+SAN</td>
<td id="S5.T6.3.6.5.3" class="ltx_td ltx_align_center ltx_border_r">47.2</td>
</tr>
<tr id="S5.T6.3.7.6" class="ltx_tr">
<td id="S5.T6.3.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">MedVQA-2019</td>
<td id="S5.T6.3.7.6.2" class="ltx_td ltx_align_center ltx_border_r">VQAMix+BAN</td>
<td id="S5.T6.3.7.6.3" class="ltx_td ltx_align_center ltx_border_r">49</td>
</tr>
<tr id="S5.T6.3.8.7" class="ltx_tr">
<td id="S5.T6.3.8.7.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.8.7.2" class="ltx_td ltx_align_center ltx_border_r">CMSA</td>
<td id="S5.T6.3.8.7.3" class="ltx_td ltx_align_center ltx_border_r">47.4</td>
</tr>
<tr id="S5.T6.3.9.8" class="ltx_tr">
<td id="S5.T6.3.9.8.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.9.8.2" class="ltx_td ltx_align_center ltx_border_r">MMBERT</td>
<td id="S5.T6.3.9.8.3" class="ltx_td ltx_align_center ltx_border_r">51.2</td>
</tr>
<tr id="S5.T6.3.10.9" class="ltx_tr">
<td id="S5.T6.3.10.9.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.10.9.2" class="ltx_td ltx_align_center ltx_border_r">PTUnifier</td>
<td id="S5.T6.3.10.9.3" class="ltx_td ltx_align_center ltx_border_r">60.3</td>
</tr>
<tr id="S5.T6.3.11.10" class="ltx_tr">
<td id="S5.T6.3.11.10.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.11.10.2" class="ltx_td ltx_align_center ltx_border_r">METER</td>
<td id="S5.T6.3.11.10.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.3.11.10.3.1" class="ltx_text ltx_font_bold">73.9</span></td>
</tr>
<tr id="S5.T6.3.12.11" class="ltx_tr">
<td id="S5.T6.3.12.11.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.12.11.2" class="ltx_td ltx_align_center ltx_border_r">TCL</td>
<td id="S5.T6.3.12.11.3" class="ltx_td ltx_align_center ltx_border_r">63</td>
</tr>
<tr id="S5.T6.3.13.12" class="ltx_tr">
<td id="S5.T6.3.13.12.1" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S5.T6.3.13.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">MiniGPT-4</td>
<td id="S5.T6.3.13.12.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">14.6</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Implementation details.</h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.1" class="ltx_p">For dataset processing and pre-training, we use a large-scale publicly available medical dataset called by ROCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. It contains image-text pairs collected from PubMed<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://pubmed.ncbi.nlm.nih.gov/</span></span></span>, covering various images such as X-rays, MRI, angiography, etc. It also covers a wide range of body regions, such as the head, neck, teeth, etc. We selected 87,952 non composite radiographic images with relevant captions. For fine-tuning, we follow the training, validation, and testing data splitting according to Table <a href="#S5.T4" title="Table 4 ‣ Datasets. ‣ 5.2 Experimental Setup ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Five benchmark Med-VQA datasets were used to train and evaluate SOTAs. For fair comparison, we use the same data splits and follow the previous work to partition the datasets. Medical visual questions are usually divided into two categories: closed-ended and open-ended questions. Closed-ended questions are usually answered with “yes/no” or other limited options. Open-ended questions have no restrictive structure and can have multiple correct answers. All models are trained on dual graphics NVIDIA RTX V100 GPU. We use the AdamW optimizer with the same preheating steps. See Table <a href="#S5.T3" title="Table 3 ‣ 5.1 Considered Models ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for detailed parameter settings of the model.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Evaluation Metrics</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.6" class="ltx_p">In order to quantitatively measure the performance of models, we use the <math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="accuracy" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><mrow id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mi id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1a" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.4" xref="S5.SS3.p1.1.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1b" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.5" xref="S5.SS3.p1.1.m1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1c" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.6" xref="S5.SS3.p1.1.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1d" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.7" xref="S5.SS3.p1.1.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1e" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.8" xref="S5.SS3.p1.1.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.1.m1.1.1.1f" xref="S5.SS3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.1.m1.1.1.9" xref="S5.SS3.p1.1.m1.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><times id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1"></times><ci id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2">𝑎</ci><ci id="S5.SS3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.p1.1.m1.1.1.3">𝑐</ci><ci id="S5.SS3.p1.1.m1.1.1.4.cmml" xref="S5.SS3.p1.1.m1.1.1.4">𝑐</ci><ci id="S5.SS3.p1.1.m1.1.1.5.cmml" xref="S5.SS3.p1.1.m1.1.1.5">𝑢</ci><ci id="S5.SS3.p1.1.m1.1.1.6.cmml" xref="S5.SS3.p1.1.m1.1.1.6">𝑟</ci><ci id="S5.SS3.p1.1.m1.1.1.7.cmml" xref="S5.SS3.p1.1.m1.1.1.7">𝑎</ci><ci id="S5.SS3.p1.1.m1.1.1.8.cmml" xref="S5.SS3.p1.1.m1.1.1.8">𝑐</ci><ci id="S5.SS3.p1.1.m1.1.1.9.cmml" xref="S5.SS3.p1.1.m1.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">accuracy</annotation></semantics></math> as an evaluation metric, and compute it for two types of questions (open-ended and closed-ended). Let <math id="S5.SS3.p1.2.m2.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S5.SS3.p1.2.m2.1a"><msub id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml">P</mi><mi id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">𝑃</ci><ci id="S5.SS3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">P_{i}</annotation></semantics></math> and <math id="S5.SS3.p1.3.m3.1" class="ltx_Math" alttext="L_{i}" display="inline"><semantics id="S5.SS3.p1.3.m3.1a"><msub id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml"><mi id="S5.SS3.p1.3.m3.1.1.2" xref="S5.SS3.p1.3.m3.1.1.2.cmml">L</mi><mi id="S5.SS3.p1.3.m3.1.1.3" xref="S5.SS3.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><apply id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.1.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p1.3.m3.1.1.2.cmml" xref="S5.SS3.p1.3.m3.1.1.2">𝐿</ci><ci id="S5.SS3.p1.3.m3.1.1.3.cmml" xref="S5.SS3.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">L_{i}</annotation></semantics></math> respectively represent the prediction and ground-truth label of sample <math id="S5.SS3.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS3.p1.4.m4.1a"><mi id="S5.SS3.p1.4.m4.1.1" xref="S5.SS3.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><ci id="S5.SS3.p1.4.m4.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.1c">i</annotation></semantics></math> in the test set, and <math id="S5.SS3.p1.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.SS3.p1.5.m5.1a"><mi id="S5.SS3.p1.5.m5.1.1" xref="S5.SS3.p1.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.5.m5.1b"><ci id="S5.SS3.p1.5.m5.1.1.cmml" xref="S5.SS3.p1.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.5.m5.1c">T</annotation></semantics></math> represents the test set. The <math id="S5.SS3.p1.6.m6.1" class="ltx_Math" alttext="accuracy" display="inline"><semantics id="S5.SS3.p1.6.m6.1a"><mrow id="S5.SS3.p1.6.m6.1.1" xref="S5.SS3.p1.6.m6.1.1.cmml"><mi id="S5.SS3.p1.6.m6.1.1.2" xref="S5.SS3.p1.6.m6.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.3" xref="S5.SS3.p1.6.m6.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1a" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.4" xref="S5.SS3.p1.6.m6.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1b" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.5" xref="S5.SS3.p1.6.m6.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1c" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.6" xref="S5.SS3.p1.6.m6.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1d" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.7" xref="S5.SS3.p1.6.m6.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1e" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.8" xref="S5.SS3.p1.6.m6.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p1.6.m6.1.1.1f" xref="S5.SS3.p1.6.m6.1.1.1.cmml">​</mo><mi id="S5.SS3.p1.6.m6.1.1.9" xref="S5.SS3.p1.6.m6.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.6.m6.1b"><apply id="S5.SS3.p1.6.m6.1.1.cmml" xref="S5.SS3.p1.6.m6.1.1"><times id="S5.SS3.p1.6.m6.1.1.1.cmml" xref="S5.SS3.p1.6.m6.1.1.1"></times><ci id="S5.SS3.p1.6.m6.1.1.2.cmml" xref="S5.SS3.p1.6.m6.1.1.2">𝑎</ci><ci id="S5.SS3.p1.6.m6.1.1.3.cmml" xref="S5.SS3.p1.6.m6.1.1.3">𝑐</ci><ci id="S5.SS3.p1.6.m6.1.1.4.cmml" xref="S5.SS3.p1.6.m6.1.1.4">𝑐</ci><ci id="S5.SS3.p1.6.m6.1.1.5.cmml" xref="S5.SS3.p1.6.m6.1.1.5">𝑢</ci><ci id="S5.SS3.p1.6.m6.1.1.6.cmml" xref="S5.SS3.p1.6.m6.1.1.6">𝑟</ci><ci id="S5.SS3.p1.6.m6.1.1.7.cmml" xref="S5.SS3.p1.6.m6.1.1.7">𝑎</ci><ci id="S5.SS3.p1.6.m6.1.1.8.cmml" xref="S5.SS3.p1.6.m6.1.1.8">𝑐</ci><ci id="S5.SS3.p1.6.m6.1.1.9.cmml" xref="S5.SS3.p1.6.m6.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.6.m6.1c">accuracy</annotation></semantics></math> is calculated as follows:</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<table id="S5.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E1.m1.2" class="ltx_Math" alttext="accuracy=\frac{1}{|T|}\sum_{i\in T}l(P_{i}=L_{i})" display="block"><semantics id="S5.E1.m1.2a"><mrow id="S5.E1.m1.2.2" xref="S5.E1.m1.2.2.cmml"><mrow id="S5.E1.m1.2.2.3" xref="S5.E1.m1.2.2.3.cmml"><mi id="S5.E1.m1.2.2.3.2" xref="S5.E1.m1.2.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.3" xref="S5.E1.m1.2.2.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1a" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.4" xref="S5.E1.m1.2.2.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1b" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.5" xref="S5.E1.m1.2.2.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1c" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.6" xref="S5.E1.m1.2.2.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1d" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.7" xref="S5.E1.m1.2.2.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1e" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.8" xref="S5.E1.m1.2.2.3.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.3.1f" xref="S5.E1.m1.2.2.3.1.cmml">​</mo><mi id="S5.E1.m1.2.2.3.9" xref="S5.E1.m1.2.2.3.9.cmml">y</mi></mrow><mo id="S5.E1.m1.2.2.2" xref="S5.E1.m1.2.2.2.cmml">=</mo><mrow id="S5.E1.m1.2.2.1" xref="S5.E1.m1.2.2.1.cmml"><mfrac id="S5.E1.m1.1.1" xref="S5.E1.m1.1.1.cmml"><mn id="S5.E1.m1.1.1.3" xref="S5.E1.m1.1.1.3.cmml">1</mn><mrow id="S5.E1.m1.1.1.1.3" xref="S5.E1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E1.m1.1.1.1.3.1" xref="S5.E1.m1.1.1.1.2.1.cmml">|</mo><mi id="S5.E1.m1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.cmml">T</mi><mo stretchy="false" id="S5.E1.m1.1.1.1.3.2" xref="S5.E1.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.1.2" xref="S5.E1.m1.2.2.1.2.cmml">​</mo><mrow id="S5.E1.m1.2.2.1.1" xref="S5.E1.m1.2.2.1.1.cmml"><munder id="S5.E1.m1.2.2.1.1.2" xref="S5.E1.m1.2.2.1.1.2.cmml"><mo movablelimits="false" id="S5.E1.m1.2.2.1.1.2.2" xref="S5.E1.m1.2.2.1.1.2.2.cmml">∑</mo><mrow id="S5.E1.m1.2.2.1.1.2.3" xref="S5.E1.m1.2.2.1.1.2.3.cmml"><mi id="S5.E1.m1.2.2.1.1.2.3.2" xref="S5.E1.m1.2.2.1.1.2.3.2.cmml">i</mi><mo id="S5.E1.m1.2.2.1.1.2.3.1" xref="S5.E1.m1.2.2.1.1.2.3.1.cmml">∈</mo><mi id="S5.E1.m1.2.2.1.1.2.3.3" xref="S5.E1.m1.2.2.1.1.2.3.3.cmml">T</mi></mrow></munder><mrow id="S5.E1.m1.2.2.1.1.1" xref="S5.E1.m1.2.2.1.1.1.cmml"><mi id="S5.E1.m1.2.2.1.1.1.3" xref="S5.E1.m1.2.2.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.1.1.1.2" xref="S5.E1.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S5.E1.m1.2.2.1.1.1.1.1" xref="S5.E1.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E1.m1.2.2.1.1.1.1.1.2" xref="S5.E1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E1.m1.2.2.1.1.1.1.1.1" xref="S5.E1.m1.2.2.1.1.1.1.1.1.cmml"><msub id="S5.E1.m1.2.2.1.1.1.1.1.1.2" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S5.E1.m1.2.2.1.1.1.1.1.1.2.2" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml">P</mi><mi id="S5.E1.m1.2.2.1.1.1.1.1.1.2.3" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S5.E1.m1.2.2.1.1.1.1.1.1.1" xref="S5.E1.m1.2.2.1.1.1.1.1.1.1.cmml">=</mo><msub id="S5.E1.m1.2.2.1.1.1.1.1.1.3" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S5.E1.m1.2.2.1.1.1.1.1.1.3.2" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3.2.cmml">L</mi><mi id="S5.E1.m1.2.2.1.1.1.1.1.1.3.3" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S5.E1.m1.2.2.1.1.1.1.1.3" xref="S5.E1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.2b"><apply id="S5.E1.m1.2.2.cmml" xref="S5.E1.m1.2.2"><eq id="S5.E1.m1.2.2.2.cmml" xref="S5.E1.m1.2.2.2"></eq><apply id="S5.E1.m1.2.2.3.cmml" xref="S5.E1.m1.2.2.3"><times id="S5.E1.m1.2.2.3.1.cmml" xref="S5.E1.m1.2.2.3.1"></times><ci id="S5.E1.m1.2.2.3.2.cmml" xref="S5.E1.m1.2.2.3.2">𝑎</ci><ci id="S5.E1.m1.2.2.3.3.cmml" xref="S5.E1.m1.2.2.3.3">𝑐</ci><ci id="S5.E1.m1.2.2.3.4.cmml" xref="S5.E1.m1.2.2.3.4">𝑐</ci><ci id="S5.E1.m1.2.2.3.5.cmml" xref="S5.E1.m1.2.2.3.5">𝑢</ci><ci id="S5.E1.m1.2.2.3.6.cmml" xref="S5.E1.m1.2.2.3.6">𝑟</ci><ci id="S5.E1.m1.2.2.3.7.cmml" xref="S5.E1.m1.2.2.3.7">𝑎</ci><ci id="S5.E1.m1.2.2.3.8.cmml" xref="S5.E1.m1.2.2.3.8">𝑐</ci><ci id="S5.E1.m1.2.2.3.9.cmml" xref="S5.E1.m1.2.2.3.9">𝑦</ci></apply><apply id="S5.E1.m1.2.2.1.cmml" xref="S5.E1.m1.2.2.1"><times id="S5.E1.m1.2.2.1.2.cmml" xref="S5.E1.m1.2.2.1.2"></times><apply id="S5.E1.m1.1.1.cmml" xref="S5.E1.m1.1.1"><divide id="S5.E1.m1.1.1.2.cmml" xref="S5.E1.m1.1.1"></divide><cn type="integer" id="S5.E1.m1.1.1.3.cmml" xref="S5.E1.m1.1.1.3">1</cn><apply id="S5.E1.m1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.3"><abs id="S5.E1.m1.1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.1.3.1"></abs><ci id="S5.E1.m1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1">𝑇</ci></apply></apply><apply id="S5.E1.m1.2.2.1.1.cmml" xref="S5.E1.m1.2.2.1.1"><apply id="S5.E1.m1.2.2.1.1.2.cmml" xref="S5.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.1.1.2.1.cmml" xref="S5.E1.m1.2.2.1.1.2">subscript</csymbol><sum id="S5.E1.m1.2.2.1.1.2.2.cmml" xref="S5.E1.m1.2.2.1.1.2.2"></sum><apply id="S5.E1.m1.2.2.1.1.2.3.cmml" xref="S5.E1.m1.2.2.1.1.2.3"><in id="S5.E1.m1.2.2.1.1.2.3.1.cmml" xref="S5.E1.m1.2.2.1.1.2.3.1"></in><ci id="S5.E1.m1.2.2.1.1.2.3.2.cmml" xref="S5.E1.m1.2.2.1.1.2.3.2">𝑖</ci><ci id="S5.E1.m1.2.2.1.1.2.3.3.cmml" xref="S5.E1.m1.2.2.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S5.E1.m1.2.2.1.1.1.cmml" xref="S5.E1.m1.2.2.1.1.1"><times id="S5.E1.m1.2.2.1.1.1.2.cmml" xref="S5.E1.m1.2.2.1.1.1.2"></times><ci id="S5.E1.m1.2.2.1.1.1.3.cmml" xref="S5.E1.m1.2.2.1.1.1.3">𝑙</ci><apply id="S5.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1"><eq id="S5.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.1"></eq><apply id="S5.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2.2">𝑃</ci><ci id="S5.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S5.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E1.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3.2">𝐿</ci><ci id="S5.E1.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S5.E1.m1.2.2.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.2c">accuracy=\frac{1}{|T|}\sum_{i\in T}l(P_{i}=L_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.3" class="ltx_p">The generative model such as MiniGPT-4 uses the <math id="S5.SS3.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.SS3.p3.1.m1.1a"><mi id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><ci id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">n</annotation></semantics></math>-grams method to calculate the <math id="S5.SS3.p3.2.m2.1" class="ltx_Math" alttext="accuracy" display="inline"><semantics id="S5.SS3.p3.2.m2.1a"><mrow id="S5.SS3.p3.2.m2.1.1" xref="S5.SS3.p3.2.m2.1.1.cmml"><mi id="S5.SS3.p3.2.m2.1.1.2" xref="S5.SS3.p3.2.m2.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.3" xref="S5.SS3.p3.2.m2.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1a" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.4" xref="S5.SS3.p3.2.m2.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1b" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.5" xref="S5.SS3.p3.2.m2.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1c" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.6" xref="S5.SS3.p3.2.m2.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1d" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.7" xref="S5.SS3.p3.2.m2.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1e" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.8" xref="S5.SS3.p3.2.m2.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p3.2.m2.1.1.1f" xref="S5.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS3.p3.2.m2.1.1.9" xref="S5.SS3.p3.2.m2.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.2.m2.1b"><apply id="S5.SS3.p3.2.m2.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1"><times id="S5.SS3.p3.2.m2.1.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1.1"></times><ci id="S5.SS3.p3.2.m2.1.1.2.cmml" xref="S5.SS3.p3.2.m2.1.1.2">𝑎</ci><ci id="S5.SS3.p3.2.m2.1.1.3.cmml" xref="S5.SS3.p3.2.m2.1.1.3">𝑐</ci><ci id="S5.SS3.p3.2.m2.1.1.4.cmml" xref="S5.SS3.p3.2.m2.1.1.4">𝑐</ci><ci id="S5.SS3.p3.2.m2.1.1.5.cmml" xref="S5.SS3.p3.2.m2.1.1.5">𝑢</ci><ci id="S5.SS3.p3.2.m2.1.1.6.cmml" xref="S5.SS3.p3.2.m2.1.1.6">𝑟</ci><ci id="S5.SS3.p3.2.m2.1.1.7.cmml" xref="S5.SS3.p3.2.m2.1.1.7">𝑎</ci><ci id="S5.SS3.p3.2.m2.1.1.8.cmml" xref="S5.SS3.p3.2.m2.1.1.8">𝑐</ci><ci id="S5.SS3.p3.2.m2.1.1.9.cmml" xref="S5.SS3.p3.2.m2.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.2.m2.1c">accuracy</annotation></semantics></math> of predictions and ground-truths. If it is higher than the manually set threshold <math id="S5.SS3.p3.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS3.p3.3.m3.1a"><mi id="S5.SS3.p3.3.m3.1.1" xref="S5.SS3.p3.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.3.m3.1b"><ci id="S5.SS3.p3.3.m3.1.1.cmml" xref="S5.SS3.p3.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.3.m3.1c">\alpha</annotation></semantics></math>, the prediction is judged to be correct.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Results</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">Table <a href="#S5.T5" title="Table 5 ‣ Datasets. ‣ 5.2 Experimental Setup ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and  <a href="#S5.T6" title="Table 6 ‣ Datasets. ‣ 5.2 Experimental Setup ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> show the <math id="S5.SS4.p1.1.m1.1" class="ltx_Math" alttext="accuracy" display="inline"><semantics id="S5.SS4.p1.1.m1.1a"><mrow id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mi id="S5.SS4.p1.1.m1.1.1.2" xref="S5.SS4.p1.1.m1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.3" xref="S5.SS4.p1.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1a" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.4" xref="S5.SS4.p1.1.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1b" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.5" xref="S5.SS4.p1.1.m1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1c" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.6" xref="S5.SS4.p1.1.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1d" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.7" xref="S5.SS4.p1.1.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1e" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.8" xref="S5.SS4.p1.1.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p1.1.m1.1.1.1f" xref="S5.SS4.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS4.p1.1.m1.1.1.9" xref="S5.SS4.p1.1.m1.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><times id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1.1"></times><ci id="S5.SS4.p1.1.m1.1.1.2.cmml" xref="S5.SS4.p1.1.m1.1.1.2">𝑎</ci><ci id="S5.SS4.p1.1.m1.1.1.3.cmml" xref="S5.SS4.p1.1.m1.1.1.3">𝑐</ci><ci id="S5.SS4.p1.1.m1.1.1.4.cmml" xref="S5.SS4.p1.1.m1.1.1.4">𝑐</ci><ci id="S5.SS4.p1.1.m1.1.1.5.cmml" xref="S5.SS4.p1.1.m1.1.1.5">𝑢</ci><ci id="S5.SS4.p1.1.m1.1.1.6.cmml" xref="S5.SS4.p1.1.m1.1.1.6">𝑟</ci><ci id="S5.SS4.p1.1.m1.1.1.7.cmml" xref="S5.SS4.p1.1.m1.1.1.7">𝑎</ci><ci id="S5.SS4.p1.1.m1.1.1.8.cmml" xref="S5.SS4.p1.1.m1.1.1.8">𝑐</ci><ci id="S5.SS4.p1.1.m1.1.1.9.cmml" xref="S5.SS4.p1.1.m1.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">accuracy</annotation></semantics></math> achieved by all the considered models. We can obtain the following observations:</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">(<span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_italic">i</span>) Among all baselines, the PTUnifier which is pre-trained in the medical domain performs the best on VQA-RAD, SLAKE-EN and OVQA, but not so well on PathVQA and MedVQA-2019. As for the pre-trained models in general domain, TCL and METER achieve better performance on PathVQA and MedVQA-2019. The possible reason is that PathVQA is collected from a wide range of sources, including textbooks and literature, while MedVQA-2019 is artificially generated and cannot represent formal clinical data. PTUnifier adopts a visual language pre-training framework and unifies the fused encoder and dual encoder, thereby excelling on multi-modal tasks.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">(<span id="S5.SS4.p3.1.1" class="ltx_text ltx_font_italic">ii</span>) MiniGPT-4 shows the worst performance on every dataset. Although utilizing massive amounts of data for training, it is still unable to effectively mine the domain-specific knowledge to answer a medical question, resulting in poor performance. In addition, the usage of unappropriate prompts may further degrade the model performance.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p">(<span id="S5.SS4.p4.1.1" class="ltx_text ltx_font_italic">iii</span>) Discriminative models (all models except of MiniGPT-4), are more applicable to Med-VQA than generative models (MiniGPT-4). The discriminative models define the Med-VQA task as a classification problem, while generative models focus on simulating and generating data, requiring broader language understanding and visual information processing capabilities. Compared with generative models, discriminative models generally have fewer parameters.</p>
</div>
<div id="S5.SS4.p5" class="ltx_para">
<p id="S5.SS4.p5.1" class="ltx_p">(<span id="S5.SS4.p5.1.1" class="ltx_text ltx_font_italic">iv</span>) The performance of lightweight models such as MEVF, CR, MMQ, and CMSA is significantly inferior to complex models like PTUnifier, TCL, and METER. This is because models like PTUnifier have more parameters and adopt a deeper neural network structure, which is beneficial for learning the alignment between images and texts.</p>
</div>
<div id="S5.SS4.p6" class="ltx_para">
<p id="S5.SS4.p6.1" class="ltx_p">Fig. <a href="#S5.F6" title="Figure 6 ‣ 5.4 Results ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows that the values of hyperparameters are determined based on the values set with the best performance on the validation set. The results of each model are obtained by challenging the Batch Size (BZ) and Learning Rate (LR). Due to limited computing power, we only show parts of results: (<span id="S5.SS4.p6.1.1" class="ltx_text ltx_font_italic">i</span>) The results of MiniGPT-4 are eliminated as it cannot be re-trained and fine-tuned; (<span id="S5.SS4.p6.1.2" class="ltx_text ltx_font_italic">ii</span>) We show part of results for PTUnifier in Fig. <a href="#S5.F6.sf1" title="In Figure 6 ‣ 5.4 Results ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, as it requires more computing power for larger values of BZ; (<span id="S5.SS4.p6.1.3" class="ltx_text ltx_font_italic">iii</span>) Similarly, we show part of results for PTUnifier, TCL, and METER with larger number of parameters in Fig. <a href="#S5.F6.sf2" title="In Figure 6 ‣ 5.4 Results ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, as the value range of LR is not comparable to that of other models.</p>
</div>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/bs.png" id="S5.F6.sf1.g1" class="ltx_graphics ltx_img_portrait" width="284" height="362" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S5.F6.sf1.3.2" class="ltx_text" style="font-size:80%;">Batch Size</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2312.07867/assets/pics/lr.png" id="S5.F6.sf2.g1" class="ltx_graphics ltx_img_portrait" width="284" height="362" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S5.F6.sf2.3.2" class="ltx_text" style="font-size:80%;">Learning Rate</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Model performance varies with batch size and learning rate</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Detailed Analysis</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">In Fig. <a href="#S5.F6.sf1" title="In Figure 6 ‣ 5.4 Results ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, the performance of each model gradually increases with the increase of BZ values, and then decrease after reaching a saddle point, due to the gradient calculation. However, when BZ is set to a large value, some models converge to local stationary points, such as METER and VQAMix-SAN. In Fig. <a href="#S5.F6.sf2" title="In Figure 6 ‣ 5.4 Results ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, (<span id="S5.SS5.p1.1.1" class="ltx_text ltx_font_italic">i</span>) with the increase of LR values, the performance of MMBERT shows a significant decline, and (<span id="S5.SS5.p1.1.2" class="ltx_text ltx_font_italic">ii</span>) the performance of MEVF, CR, and CMSA first increase and then decrease with the increase of LR values.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">Fig. <a href="#S5.F7" title="Figure 7 ‣ 5.5 Detailed Analysis ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the results on various question types for each model over the OVQA dataset.</p>
</div>
<figure id="S5.F7" class="ltx_figure">
<p id="S5.F7.1" class="ltx_p ltx_align_center"><span id="S5.F7.1.1" class="ltx_text"><img src="/html/2312.07867/assets/pics/qt.png" id="S5.F7.1.1.g1" class="ltx_graphics ltx_img_landscape" width="568" height="326" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The <math id="S5.F7.3.m1.1" class="ltx_Math" alttext="Accuracy" display="inline"><semantics id="S5.F7.3.m1.1b"><mrow id="S5.F7.3.m1.1.1" xref="S5.F7.3.m1.1.1.cmml"><mi id="S5.F7.3.m1.1.1.2" xref="S5.F7.3.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.3" xref="S5.F7.3.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1b" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.4" xref="S5.F7.3.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1c" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.5" xref="S5.F7.3.m1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1d" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.6" xref="S5.F7.3.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1e" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.7" xref="S5.F7.3.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1f" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.8" xref="S5.F7.3.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.F7.3.m1.1.1.1g" xref="S5.F7.3.m1.1.1.1.cmml">​</mo><mi id="S5.F7.3.m1.1.1.9" xref="S5.F7.3.m1.1.1.9.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.3.m1.1c"><apply id="S5.F7.3.m1.1.1.cmml" xref="S5.F7.3.m1.1.1"><times id="S5.F7.3.m1.1.1.1.cmml" xref="S5.F7.3.m1.1.1.1"></times><ci id="S5.F7.3.m1.1.1.2.cmml" xref="S5.F7.3.m1.1.1.2">𝐴</ci><ci id="S5.F7.3.m1.1.1.3.cmml" xref="S5.F7.3.m1.1.1.3">𝑐</ci><ci id="S5.F7.3.m1.1.1.4.cmml" xref="S5.F7.3.m1.1.1.4">𝑐</ci><ci id="S5.F7.3.m1.1.1.5.cmml" xref="S5.F7.3.m1.1.1.5">𝑢</ci><ci id="S5.F7.3.m1.1.1.6.cmml" xref="S5.F7.3.m1.1.1.6">𝑟</ci><ci id="S5.F7.3.m1.1.1.7.cmml" xref="S5.F7.3.m1.1.1.7">𝑎</ci><ci id="S5.F7.3.m1.1.1.8.cmml" xref="S5.F7.3.m1.1.1.8">𝑐</ci><ci id="S5.F7.3.m1.1.1.9.cmml" xref="S5.F7.3.m1.1.1.9">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.3.m1.1d">Accuracy</annotation></semantics></math> values of different question types for each model in OVQA</figcaption>
</figure>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.1" class="ltx_p">(<span id="S5.SS5.p3.1.1" class="ltx_text ltx_font_italic">i</span>) All models perform well on the Modality type of questions because MRI or CT image features are obvious, enabling the image encoder to effectively extract image features.</p>
</div>
<div id="S5.SS5.p4" class="ltx_para">
<p id="S5.SS5.p4.1" class="ltx_p">(<span id="S5.SS5.p4.1.1" class="ltx_text ltx_font_italic">ii</span>) Compared to discriminative models, MiniGPT-4 performs worse on the Plane, Abnormality, and Condition type of questions, as these types of questions are more suitable to the label classification tasks.</p>
</div>
<div id="S5.SS5.p5" class="ltx_para">
<p id="S5.SS5.p5.1" class="ltx_p">(<span id="S5.SS5.p5.1.1" class="ltx_text ltx_font_italic">iii</span>) MiniGPT-4 achieves significantly better performance than other models on the Attribute Other type of questions. This is because LLMs possess extensive knowledge, providing more comprehensive and complete information when answering descriptive questions.</p>
</div>
<div id="S5.SS5.p6" class="ltx_para">
<p id="S5.SS5.p6.1" class="ltx_p">(<span id="S5.SS5.p6.1.1" class="ltx_text ltx_font_italic">iv</span>) Among discriminative models, TCL demonstrates better performance on the Attribute Other type of questions. TCL employs a contrastive learning approach in cross-modal and intra-modal self-supervision, which enhances the image-text alignment in the fusion encoder.</p>
</div>
<div id="S5.SS5.p7" class="ltx_para">
<p id="S5.SS5.p7.1" class="ltx_p">(<span id="S5.SS5.p7.1.1" class="ltx_text ltx_font_italic">v</span>) VQAMix performs well on most types of questions because it incorporates a conditional label combination strategy for data augmentation, allowing for extracting more comprehensive image features.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2312.07867/assets/x2.png" id="S5.F8.g1" class="ltx_graphics ltx_img_landscape" width="461" height="292" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Two testing examples selected from OVQA</figcaption>
</figure>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Qualitative Analysis</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">We provide a qualitative comparison of all models. Two examples from the OVQA dataset in Fig. <a href="#S5.F8" title="Figure 8 ‣ 5.5 Detailed Analysis ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> show that early discriminative models such as MEVF, CR, MMBERT, CMSA, and VQAMix, fail to answer Med-VQA questions, compared to the latest discriminative models such as TCL, METER, and PTUnifier. For example, in the second left figure in Fig. <a href="#S5.F8" title="Figure 8 ‣ 5.5 Detailed Analysis ‣ 5 Empirical Study ‣ BESTMVQA: A Benchmark Evaluation System for Medical Visual Question AnsweringThis work was done when Xiaojie Hong worked for the project of Meetyou AI Lab." class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, the Red Cross indicates that the prediction is wrong, and the green check indicates that the prediction is correct. We observed that although the given question is to consult the abnormal position of orthopedic images, the predicted result position of traditional models such as MEVF is wrong. In the same image, TCL, and other advanced general fields and VQA in the medical field will locate the abnormality to the correct position. This also shows that the advanced VQA deep learning model with large parameters can not only correctly capture the image content as a whole, but also understand the region of interest related to the question, so as to provide the correct answer.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Deep learning models face additional challenges for Med-VQA, compared with general VQA. It is a urgent need for researchers to perform a comprehensive empirical study on SOTAs over benchmark datasets, to develop new Med-VQA techniques or perform medical practice. Therefore, we implement a benchmark evaluation system for users to support this need. Our system thoroughly compares the user-selected models and reports the comprehensive results obtained from the experiments. Users also can download the datasets, evaluation reports and source code of SOTAs for further practice. In a word, we provide a unified benchmark evaluation system for users to conveniently perform diverse medical practice. The demonstration video of our system can be found at <a target="_blank" href="https://youtu.be/QkEeFlu1x4A" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://youtu.be/QkEeFlu1x4A</a>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ben Abacha, A., Hasan, S.A., Datla, V.V., Demner-Fushman, D., Müller, H.:
Vqa-med: Overview of the medical visual question answering task at imageclef
2019. In: CLEF. 9-12 September 2019 (2019)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Chen, Z., Diao, S., Wang, B., Li, G., Wan, X.: Towards unifying medical
vision-and-language pre-training via soft prompts. arXiv preprint
arXiv:2302.08958 (2023)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Do, T., Nguyen, B.X., Tjiputra, E., Tran, M., Tran, Q.D., Nguyen, A.: Multiple
meta-model quantifying for medical visual question answering. In: MICCAI. pp.
64–74. Springer (2021)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Dou, Z.Y., Xu, Y., Gan, Z., Wang, J., Wang, S., Wang, L., Zhu, C., Zhang, P.,
Yuan, L., Peng, N., et al.: An empirical study of training end-to-end
vision-and-language transformers. In: CVPR. pp. 18166–18176 (2022)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Eslami, S., de Melo, G., Meinel, C.: Does clip benefit visual question
answering in the medical domain as much as it does in the general domain?
arXiv preprint arXiv:2112.13906 (2021)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Finn, C., Abbeel, P., Levine, S.: Model-agnostic meta-learning for fast
adaptation of deep networks. In: ICML. pp. 1126–1135. PMLR (2017)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Gong, H., Chen, G., Liu, S., Yu, Y., Li, G.: Cross-modal self-attention with
multi-task pre-training for medical visual question answering. In: ACM ICMR.
pp. 456–460 (2021)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Gong, H., Chen, G., Mao, M., Li, Z., Li, G.: Vqamix: Conditional triplet mixup
for medical visual question answering. IEEE Trans Med Imaging
<span id="bib.bib8.1.1" class="ltx_text ltx_font_bold">41</span>(11), 3332–3343 (2022)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
He, X., Cai, Z., Wei, W., Zhang, Y., Mou, L., Xing, E., Xie, P.: Pathological
visual question answering. arXiv preprint arXiv:2010.12435 (2020)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Huang, Y., Wang, X., Liu, F., Huang, G.: Ovqa: a clinically generated visual
question answering dataset. In: ACM SIGIR. pp. 2924–2938 (2022)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Huang, Y., Wang, X., Su, J.: An effective pre-trained visual encoder for
medical visual question answering. In: ADMA. pp. 466–481. Springer (2023)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Khare, Y., Bagal, V., Mathew, M., Devi, A., Priyakumar, U.D., Jawahar, C.:
Mmbert: Multimodal bert pretraining for improved medical vqa. In: ISBI. pp.
1033–1036. IEEE (2021)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Lau, J.J., Gayen, S., Ben Abacha, A., Demner-Fushman, D.: A dataset of
clinically generated visual questions and answers about radiology images.
Scientific data <span id="bib.bib13.1.1" class="ltx_text ltx_font_bold">5</span>(1), 1–10 (2018)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Liu, B., Zhan, L.M., Xu, L., Ma, L., Yang, Y., Wu, X.M.: Slake: A
semantically-labeled knowledge-enhanced dataset for medical visual question
answering. In: ISBI. pp. 1650–1654. IEEE (2021)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Masci, J., Meier, U., Cireşan, D., Schmidhuber, J.: Stacked convolutional
auto-encoders for hierarchical feature extraction. In: ICANN. pp. 52–59.
Springer (2011)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Nguyen, B.D., Do, T.T., Nguyen, B.X., Do, T., Tjiputra, E., Tran, Q.D.:
Overcoming data limitation in medical visual question answering. In: MICCAI.
pp. 522–530. Springer (2019)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Pelka, O., Koitka, S., Rückert, J., Nensa, F., Friedrich, C.M.: Radiology
objects in context (roco): a multimodal image dataset. In: LABELS. pp.
180–189. Springer (2018)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Srivastava, Y., Murali, V., Dubey, S.R., Mukherjee, S.: Visual Question
Answering using Deep Learning: A Survey and Performance Analysis, p. 75–86
(Jan 2021). https://doi.org/10.1007/978-981-16-1092-9_7,
<a target="_blank" href="http://dx.doi.org/10.1007/978-981-16-1092-9_7" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1007/978-981-16-1092-9_7</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Wu, Q., Teney, D., Wang, P., Shen, C., Dick, A., Hengel, A.: Visual question
answering: A survey of methods and datasets. Cornell University -
arXiv,Cornell University - arXiv (Jul 2016)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Yang, J., Duan, J., Tran, S., Xu, Y., Chanda, S., Chen, L., Zeng, B., Chilimbi,
T., Huang, J.: Vision-language pre-training with triple contrastive learning.
In: CVPR. pp. 15671–15680 (2022)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Yasunaga, M., Leskovec, J., Liang, P.: LinkBERT: Pretraining language
models with document links. In: ACL. pp. 8003–8016 (2022)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Zhan, L.M., Liu, B., Fan, L., Chen, J., Wu, X.M.: Medical visual question
answering via conditional reasoning. In: ACM MM. pp. 2345–2354 (2020)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Zhu, D., Chen, J., Shen, X., Li, X., Elhoseiny, M.: Minigpt-4: Enhancing
vision-language understanding with advanced large language models. arXiv
preprint arXiv:2304.10592 (2023)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.07866" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.07867" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.07867">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.07867" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.07868" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 13:57:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
