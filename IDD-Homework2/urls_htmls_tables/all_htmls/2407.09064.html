<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.09064] Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports</title><meta property="og:description" content="Purpose:
Federated training is often hindered by heterogeneous datasets due to divergent data storage options, inconsistent naming schemes, varied annotation procedures, and disparities in label quality.
This is partic…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.09064">

<!--Generated on Mon Aug  5 19:14:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">1]<span id="p1.1.1" class="ltx_ERROR undefined">\orgname</span><span id="p1.1.2" class="ltx_text" style="font-size:90%;">DZHK (German Centre for Cardiovascular Research, all partner sites)</span></p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p">2]<span id="p2.1.1" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.2" class="ltx_text" style="font-size:90%;">Department of Cardiology, Angiology and Pneumology, <span id="p2.1.2.1" class="ltx_ERROR undefined">\orgname</span>Heidelberg University Hospital, <span id="p2.1.2.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.2.3" class="ltx_ERROR undefined">\city</span>Heidelberg, <span id="p2.1.2.4" class="ltx_ERROR undefined">\country</span>Germany</span>
3]<span id="p2.1.3" class="ltx_ERROR undefined">\orgname</span><span id="p2.1.4" class="ltx_text" style="font-size:90%;">Informatics for Life Institute, <span id="p2.1.4.1" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.4.2" class="ltx_ERROR undefined">\city</span>Heidelberg, <span id="p2.1.4.3" class="ltx_ERROR undefined">\country</span>Germany</span>
4]<span id="p2.1.5" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.6" class="ltx_text" style="font-size:90%;">Department of Diagnostic and Interventional Radiology and Nuclear Medicine, <span id="p2.1.6.1" class="ltx_ERROR undefined">\orgname</span>University Medical Center Hamburg-Eppendorf, <span id="p2.1.6.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.6.3" class="ltx_ERROR undefined">\city</span>Hamburg, <span id="p2.1.6.4" class="ltx_ERROR undefined">\country</span>Germany</span>
5]<span id="p2.1.7" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.8" class="ltx_text" style="font-size:90%;">Clinic for Cardiology III, <span id="p2.1.8.1" class="ltx_ERROR undefined">\orgname</span>University Hospital Münster, <span id="p2.1.8.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.8.3" class="ltx_ERROR undefined">\city</span>Münster, <span id="p2.1.8.4" class="ltx_ERROR undefined">\country</span>Germany</span>
6]<span id="p2.1.9" class="ltx_ERROR undefined">\orgname</span><span id="p2.1.10" class="ltx_text" style="font-size:90%;">Institute of Bioinformatics, <span id="p2.1.10.1" class="ltx_ERROR undefined">\orgname</span>University Medicine Greifswald, <span id="p2.1.10.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.10.3" class="ltx_ERROR undefined">\city</span>Greifswald, <span id="p2.1.10.4" class="ltx_ERROR undefined">\country</span>Germany</span>
7]<span id="p2.1.11" class="ltx_ERROR undefined">\orgname</span><span id="p2.1.12" class="ltx_text" style="font-size:90%;">Deutsches Herzzentrum der Charité (DHZC), <span id="p2.1.12.1" class="ltx_ERROR undefined">\orgdiv</span>Institute of Computer-assisted Cardiovascular Medicine, <span id="p2.1.12.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.12.3" class="ltx_ERROR undefined">\city</span>Berlin, <span id="p2.1.12.4" class="ltx_ERROR undefined">\country</span>Germany</span>
8]<span id="p2.1.13" class="ltx_ERROR undefined">\orgname</span><span id="p2.1.14" class="ltx_text" style="font-size:90%;">Charité – Universitätsmedizin Berlin, <span id="p2.1.14.1" class="ltx_ERROR undefined">\orgdiv</span>corporate member of Freie Universität Berlin and Humboldt-Universität zu Berlin, <span id="p2.1.14.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.14.3" class="ltx_ERROR undefined">\city</span>Berlin, <span id="p2.1.14.4" class="ltx_ERROR undefined">\country</span>Germany</span>
9]<span id="p2.1.15" class="ltx_ERROR undefined">\orgname</span><span id="p2.1.16" class="ltx_text" style="font-size:90%;">Fraunhofer Institute for Digital Medicine MEVIS, <span id="p2.1.16.1" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.16.2" class="ltx_ERROR undefined">\city</span>Bremen, <span id="p2.1.16.3" class="ltx_ERROR undefined">\country</span>Germany</span>
10]<span id="p2.1.17" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.18" class="ltx_text" style="font-size:90%;">Department of Medical Statistics, <span id="p2.1.18.1" class="ltx_ERROR undefined">\orgname</span>University Medical Center Göttingen, <span id="p2.1.18.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.18.3" class="ltx_ERROR undefined">\city</span>Göttingen, <span id="p2.1.18.4" class="ltx_ERROR undefined">\country</span>Germany</span>
11]<span id="p2.1.19" class="ltx_ERROR undefined">\orgname</span><span id="p2.1.20" class="ltx_text" style="font-size:90%;">Institute for Experimental and Translational Cardiovascular Imaging, <span id="p2.1.20.1" class="ltx_ERROR undefined">\orgname</span>Goethe University, <span id="p2.1.20.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.20.3" class="ltx_ERROR undefined">\city</span>Frankfurt am Main, <span id="p2.1.20.4" class="ltx_ERROR undefined">\country</span>Germany</span>
12]<span id="p2.1.21" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.22" class="ltx_text" style="font-size:90%;">Department of Medicine I, <span id="p2.1.22.1" class="ltx_ERROR undefined">\orgname</span>LMU University Hospital, LMU Munich, <span id="p2.1.22.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.22.3" class="ltx_ERROR undefined">\city</span>Munich, <span id="p2.1.22.4" class="ltx_ERROR undefined">\country</span>Germany</span>
13]<span id="p2.1.23" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.24" class="ltx_text" style="font-size:90%;">Department of Cardiology, University Heart and Vascular Center Hamburg, <span id="p2.1.24.1" class="ltx_ERROR undefined">\orgname</span>University Medical Center Hamburg-Eppendorf, <span id="p2.1.24.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.24.3" class="ltx_ERROR undefined">\city</span>Hamburg, <span id="p2.1.24.4" class="ltx_ERROR undefined">\country</span>Germany</span>
14]<span id="p2.1.25" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.26" class="ltx_text" style="font-size:90%;">Department of Cardiology, <span id="p2.1.26.1" class="ltx_ERROR undefined">\orgname</span>University Medicine Göttingen, <span id="p2.1.26.2" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.26.3" class="ltx_ERROR undefined">\city</span>Göttingen, <span id="p2.1.26.4" class="ltx_ERROR undefined">\country</span>Germany</span>
15]<span id="p2.1.27" class="ltx_ERROR undefined">\orgdiv</span><span id="p2.1.28" class="ltx_text" style="font-size:90%;">Department of Cardiology, <span id="p2.1.28.1" class="ltx_ERROR undefined">\orgname</span>Campus Kerckhoff of the Justus-Liebig-Universität Gießen, <span id="p2.1.28.2" class="ltx_ERROR undefined">\orgname</span>Kerckhoff-Clinic, <span id="p2.1.28.3" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.28.4" class="ltx_ERROR undefined">\city</span>Gießen, <span id="p2.1.28.5" class="ltx_ERROR undefined">\country</span>Germany</span></p>
</div>
<h1 class="ltx_title ltx_title_document">Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_ERROR undefined">\fnm</span>Malte <span id="id2.2.id2" class="ltx_ERROR undefined">\sur</span>Tölle <span id="id3.3.id3" class="ltx_ERROR undefined">\orcid</span>0000-0002-0804-5794
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:malte.toelle@med.uni-heidelberg.de">malte.toelle@med.uni-heidelberg.de</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id4.1.id1" class="ltx_ERROR undefined">\fnm</span>Lukas <span id="id5.2.id2" class="ltx_ERROR undefined">\sur</span>Burger
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id6.1.id1" class="ltx_ERROR undefined">\fnm</span>Halvar <span id="id7.2.id2" class="ltx_ERROR undefined">\sur</span>Kelm
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id8.1.id1" class="ltx_ERROR undefined">\fnm</span>Florian <span id="id9.2.id2" class="ltx_ERROR undefined">\sur</span>André
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id10.1.id1" class="ltx_ERROR undefined">\fnm</span>Peter <span id="id11.2.id2" class="ltx_ERROR undefined">\sur</span>Bannas
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id12.1.id1" class="ltx_ERROR undefined">\fnm</span>Gerhard <span id="id13.2.id2" class="ltx_ERROR undefined">\sur</span>Diller
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id14.1.id1" class="ltx_ERROR undefined">\fnm</span>Norbert <span id="id15.2.id2" class="ltx_ERROR undefined">\sur</span>Frey <span id="id16.3.id3" class="ltx_ERROR undefined">\orcid</span>0000-0001-7611-378X
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id17.1.id1" class="ltx_ERROR undefined">\fnm</span>Philipp <span id="id18.2.id2" class="ltx_ERROR undefined">\sur</span>Garthe
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id19.1.id1" class="ltx_ERROR undefined">\fnm</span>Stefan <span id="id20.2.id2" class="ltx_ERROR undefined">\sur</span>Groß
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id21.1.id1" class="ltx_ERROR undefined">\fnm</span>Anja <span id="id22.2.id2" class="ltx_ERROR undefined">\sur</span>Hennemuth
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id23.1.id1" class="ltx_ERROR undefined">\fnm</span>Lars <span id="id24.2.id2" class="ltx_ERROR undefined">\sur</span>Kaderali
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id25.1.id1" class="ltx_ERROR undefined">\fnm</span>Nina <span id="id26.2.id2" class="ltx_ERROR undefined">\sur</span>Krüger
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id27.1.id1" class="ltx_ERROR undefined">\fnm</span>Andreas <span id="id28.2.id2" class="ltx_ERROR undefined">\sur</span>Leha
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id29.1.id1" class="ltx_ERROR undefined">\fnm</span>Simon <span id="id30.2.id2" class="ltx_ERROR undefined">\sur</span>Martin
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id31.1.id1" class="ltx_ERROR undefined">\fnm</span>Alexander <span id="id32.2.id2" class="ltx_ERROR undefined">\sur</span>Meyer <span id="id33.3.id3" class="ltx_ERROR undefined">\orcid</span>0000-0002-6944-2478
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id34.1.id1" class="ltx_ERROR undefined">\fnm</span>Eike <span id="id35.2.id2" class="ltx_ERROR undefined">\sur</span>Nagel
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id36.1.id1" class="ltx_ERROR undefined">\fnm</span>Stefan <span id="id37.2.id2" class="ltx_ERROR undefined">\sur</span>Orwat
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id38.1.id1" class="ltx_ERROR undefined">\fnm</span>Clemens <span id="id39.2.id2" class="ltx_ERROR undefined">\sur</span>Scherer <span id="id40.3.id3" class="ltx_ERROR undefined">\orcid</span>0000-0003-2816-6793
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id41.1.id1" class="ltx_ERROR undefined">\fnm</span>Moritz <span id="id42.2.id2" class="ltx_ERROR undefined">\sur</span>Seiffert
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id43.1.id1" class="ltx_ERROR undefined">\fnm</span>Jan Moritz <span id="id44.2.id2" class="ltx_ERROR undefined">\sur</span>Seliger
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id45.1.id1" class="ltx_ERROR undefined">\fnm</span>Stefan <span id="id46.2.id2" class="ltx_ERROR undefined">\sur</span>Simm <span id="id47.3.id3" class="ltx_ERROR undefined">\orcid</span>0000-0001-9371-2709
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id48.1.id1" class="ltx_ERROR undefined">\fnm</span>Tim <span id="id49.2.id2" class="ltx_ERROR undefined">\sur</span>Friede
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id50.1.id1" class="ltx_ERROR undefined">\fnm</span>Tim <span id="id51.2.id2" class="ltx_ERROR undefined">\sur</span>Seidler
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id52.1.id1" class="ltx_ERROR undefined">\fnm</span>Sandy <span id="id53.2.id2" class="ltx_ERROR undefined">\sur</span>Engelhardt <span id="id54.3.id3" class="ltx_ERROR undefined">\orcid</span>0000-0001-8816-7654
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id55.id1" class="ltx_p"><span id="id55.id1.1" class="ltx_text ltx_font_bold">Purpose:</span>
Federated training is often hindered by heterogeneous datasets due to divergent data storage options, inconsistent naming schemes, varied annotation procedures, and disparities in label quality.
This is particularly evident in the emerging multi-modal learning paradigms, where dataset harmonization including a uniform data representation and filtering options are of paramount importance.</p>
<p id="id56.id2" class="ltx_p"><span id="id56.id2.1" class="ltx_text ltx_font_bold">Methods:</span>
DICOM structured reports enable the standardized linkage of arbitrary information beyond the imaging domain and can be used within Python deep learning pipelines with <span id="id56.id2.2" class="ltx_text ltx_font_typewriter">highdicom</span>.
Building on this, we developed an open platform for data integration and interactive filtering capabilities that simplifies the process of assembling multi-modal datasets.</p>
<p id="id57.id3" class="ltx_p"><span id="id57.id3.1" class="ltx_text ltx_font_bold">Results:</span>
In this study, we extend our prior work by showing its applicability to more and divergent data types, as well as streamlining datasets for federated training within an established consortium of eight university hospitals in Germany.
We prove its concurrent filtering ability by creating harmonized multi-modal datasets across all locations for predicting the outcome after minimally invasive heart valve replacement.
The data includes DICOM data (i.e. computed tomography images, electrocardiography scans) as well as annotations (i.e. calcification segmentations, pointsets and pacemaker dependency), and metadata (i.e. prosthesis and diagnoses).</p>
<p id="id58.id4" class="ltx_p"><span id="id58.id4.1" class="ltx_text ltx_font_bold">Conclusion:</span>
Structured reports bridge the traditional gap between imaging systems and information systems.
Utilizing the inherent DICOM reference system arbitrary data types can be queried concurrently to create meaningful cohorts for clinical studies.
The graphical interface as well as example structured report templates will be made publicly available.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>structured reports, multi-modal, federated learning, DICOM, transcatheter aortic valve replacement, data-filtering
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The predictive performance of modern deep learning models scales with the amount of training data.
The so called foundation models are trained on a incredibly large corpus of data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
A promising research direction is the incorporation of multi-modal data into the model training pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The literature on foundation models in the medical domain is scarce due to missing large scale datasets attributable to missing data unification and privacy laws.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">lectronic health records (EHR) promise a unified intra- and inter-hospital data representation that improves patient care by providing a timely access to centralized patient’s medical records.
Data based on EHRs is comprised of different formats including images, patient history, diagnostic reports, and other clinical domains.
Theoretically, there are many templates that can be followed to ensure interoperability between healthcare providers’ data.
However, in practice many different data formats and often self-defined templates are used that hinder the collection of large scale datasets even in an intra-hospital cohort selection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
The difficulty of data harmonization increases due to the breadth of templates used when operating across multiple locations, which is additionally impeded by privacy laws.
To realize the vision of the widespread application of deep learning models in clinical practice, standard interfaces need to be defined that enable interoperability.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">One renowned method, which can circumvent privacy concerns, but is dependent on data harmonization, is Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
FL inverts the common paradigm of central data storage by sending the model to each data owning institution, where local training is performed, before the model weights are sent back to the central instance for averaging.
However, due to the missing possibility of manually inspecting the data at each data holding institution data harmonization is of paramount importance to enable a meaningful model training.
</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">A possible internationally accepted standard for data harmonization is Digital Imaging and Communication in Medicine (DICOM), which is used for communication and storage of medical images and related information across a wide range of medical modalities and disciplines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
While originating in the field of imaging, it does also allow for storage and linking of other modalities such as waveforms, text, audio, or speech in structured reports (SR).
Although hospitals around the world have established an extensive enterprise imaging infrastructure, workflows and software applications based on DICOM often rely on non-standard formats and interfaces for the storage and exchange of data annotations and computational image analysis results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The aim of this work is to provide a platform for efficient data integration, matching, and cohort selection for multi-modal (federated) deep learning based on real world DICOM data.
Data integration refers to the aggregation of diverse data types into a single, coherent framework, while data matching ensures entries can be referenced and linked unambiguously on different levels of the document tree.
The contributions of this work are four-fold:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">By leveraging the DICOM standard we integrate data from different sources and modalities into a coherent framework that exceeds the imaging domain by using structured reports (SR).</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present a method to match and filter the data that is coming from different modalities and linked on different levels in the document tree.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">SRs represent a difficult domain due to their vast amount of templates.
We present a method for a unified extraction of the individual important information per template.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">By implementing an export functionality for the created cohorts, we are able to create harmonized datasets to enable federated training across multiple locations.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">A previous version of this article was published at the German Conference on Medical Image Computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
In that version we presented the general feasibility to filter data in a single location training scenario.
In this extension we install the federated infrastructure together with our designed filter tool at all locations within our FL consortium.
Each location exports its available data from their clinical PACS, pairs it with potentially present labels, converts the data to DICOM representation, and uploads everything into the presented tool.
After performing cohort selection at each individual location, the data is exported to subsequently enable a federated training.
To enable the conversion of all data types across the consortium we generate structured reports from additional templates for a more diverse and larger set of multi-modal medical data and subsequently investigate its filterability.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Material and methods</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Requirements</h3>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">An application that allows consistent data integration, matching, and cohort selection should fulfil four requirements.</p>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><em id="S2.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">R1 Integration</em>: Consistent representation of data from different formats in an unifying interface.
All required data shall be storable at one place in the same data format without the need to query multiple data bases.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><em id="S2.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">R2 Unambiguous Matching</em>: Different data types from the same patient must be matched and queryable together.
Concurrently, they must be filterable independent of other types and multiple conditions must be evaluable on the instance level.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><em id="S2.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">R3 Intuitive Cohort Selection</em>: Graphical visualization and filtering is desirable, while more complicated textual queries should also be possible.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><em id="S2.I1.i4.p1.1.1" class="ltx_emph ltx_font_italic">R4 Independent Platform or Extension to an Existing Platform</em>: Usage shall be enabled as a stand-alone application as well as an extension to existing frameworks such as e.g. Kaapana <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2407.09064/assets/Fig1.jpg" id="S2.F2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="509" height="202" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">
Different data types relevant for prediction of outcome after minimally invasive transcatheter aortic valve implantation (TAVI). The data is heterogeneous distributed across locations in the consortium in terms of type (indicated by the color scheme) and quantity.
Many different influence factors exist for TAVI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Derived information for an original data source is indicated by the hierarchy on the right hand side.
</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2407.09064/assets/Fig2.png" id="S2.F2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="509" height="206" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.5.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.6.2" class="ltx_text" style="font-size:90%;">Relevant data and their relationship to predict pacemaker dependecy after heart valve replacement. Structured Reports can reference e.g. images, waveforms, regions, and segments. Similar to <span id="S2.F2.6.2.1" class="ltx_text ltx_font_typewriter">highdicom</span> we also opt for the general Comprehensive (3D) SR due to its high generalizability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</span></figcaption>
</figure>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">DICOM Annotations</h3>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">Integrating machine learning models into clinical workflows requires interoperability between existing systems, achievable through adherence to established standards.
Although the DICOM standard is mainly used within the imaging departments of hospitals it allows storage of other data types with already defined templates as well.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p2.1" class="ltx_p">Structured reports represent a standardized method for the encoding, transmission, and storage of diagnostic findings.
In addition to images, they also allow the linking of other data types such as e.g. text, audio, time points, or other measurements.
Each SR must have a defined template that consists of a sequence of content items (see Fig. 6b in the appendix). Each content item defines a name-value pair that encodes a domain-specific property or concept.
Concept names must follow standard medical ontologies and terminologies such as the Systematized Nomenclature of Medical Clinical Terms (SNOMED CT), which ensures uniqueness and cross domain interpretability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
The value can take up to four different types: it can also be a coded concept, it might include a number, comprise one or more sets of points or other graphic data such as surfaces, or can be made up of plain text (see Fig. 5b in the appendix). Recently, the Python library <span id="S2.SS0.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_typewriter">highdicom</span> was introduced, which employs an object-oriented approach towards SRs simplifying their handling within deep learning pipelines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
However, they have so far only implemented template identity (TID) 1500 Measurement Report as their main focus was radiology and pathology.
The implementation of other templates allows for the extension to other fields.
Another common data type in radiology are segmentations in which one or multiple structures can be compartmentalized.
Each segment can be described by a specific label encoded by a coded concept similar to the name of a content item in SRs that ensures uniqueness.
Segments can also be referenced in a SR providing another level of entwinement.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Existing Platforms and Libraries</h3>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">One renowned platform that aims at facilitating the application of algorithms on real world clinical data is Kaapana<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.kaapana.ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaapana.ai</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
In addition to the possibility of deploying containerized algorithms directly in the platform they also provide a graphical filter tool for cohort selection based on the imaging data in the internal picture archiving and communication system (PACS).
However, multi-modal dataset creation is not supported as only image related attributes can be filtered and links to other forms of data (diagnoses, geometric relations, etc.) are not included.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">We showcase a possible integration of our developed platform by incorporation into Kaapana.
Similar to their inbuilt functionality we also opt for Opensearch as the tool of choice for enabling graphical cohort filtering<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://opensearch.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://opensearch.org/</a></span></span></span>.
But due to its deployability in a docker container our tool can also serve as a stand alone tool, which can be linked to any PACS.
Opensarch’s filtering plots are highly customizable due to the JSON based representation scheme, which also allows for very fast query times with a unified data representation.
While we believe our presented layout is a good compromise between complexity and usability, other researchers might want to include further elements or plots and subsequently use them for filtering, which Opensearch allows out of the box.
</p>
</div>
<div id="S2.SS0.SSS0.Px3.p3" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p3.1" class="ltx_p">A patient can have multiple reports or segmentations, which can contain e.g. different diagnoses or labels for different studies.
Filtering these interlinked data types on the same level requires the child element to be aware of its parent due to the possible reference of multiple instances within one object.
To ensure a parent document is evaluated at the level of its child, i.e. annotation, we use Opensearch’s nested objects.
With nested objects we can evaluate whether multiple conditions are true for one instance i.e. our children obtain boundaries.
As an example we might want all segmentations that have the left and right ventricle included.
Since segmentations reference a series on the whole without nested objects we would also receive all instances that have only one of both segmented.
To visualize such nested queries, one cannot use the default visualizations of Opensearch, one must rather use the declarative language Vega to create custom plots<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://vega.github.io/vega/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://vega.github.io/vega/</a></span></span></span>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Evaluation</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Federated Learning Consortium</h3>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotetext: </span><a target="_blank" href="https://dicom.nema.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dicom.nema.org</a></span></span></span>
<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">Within the German Centre for Cardiovascular Diseases (DZHK)<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://dzhk.de/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dzhk.de/</a></span></span></span> and further German Hospitals we have established an FL consortium spanning across eight university clinics (see Fig. <a href="#S2.F2" title="Figure 2 ‣ Requirements ‣ 2 Material and methods ‣ Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
The use case we want to address is the outcome prediction after minimally invasive transcatheter aortic valve implantation (TAVI) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
In the literature multiple possible impact factors on outcome derived from e.g. computed tomography (CT) and electrocardiography (ECG) scans are reported, such as the length of the membranous septum or the presence of a left bundle branch block (see Fig. <a href="#S2.F2" title="Figure 2 ‣ Requirements ‣ 2 Material and methods ‣ Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In general, the individual ECG scans can indicate existing disturbed heart stimulus conduction, while CTs provide further information about geometric relations and calcification. Additionally, patient characteristics such as a history of heart disease or diabetes mellitus can yield further insides.
However, a dedicated analysis of the interactions and an automated analysis on the raw input data with deep learning across multiple institutions is missing.
</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2407.09064/assets/x1.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="217" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">
Distribution of different label subsets across locations on log-scale.
The lower diagram displays the composition of the subset, where we restrict the subsets based on our estimation for their usefulness for independent model training.
In the upper diagram the amount of samples across all locations for the particular subset of data types are visualized.
Pacemaker refers to whether information (yes/no) of implantation is avilable.
</span></figcaption>
</figure>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Data Collection</h3>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">Every institution was required to export the relevant data they posses from their internal clinical information systems.
Even though every institution exported their CT scans from a PACS system the cross-location heterogeneity in the resulting data was large.
The textual descriptions as well as the field of view covered by the volume differed between and also within institutions.
Even worse are the data representations for ECG; it varied from extensive markup language (XML)<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://www.w3.org/TR/REC-xml/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.w3.org/TR/REC-xml/</a></span></span></span> over standard communications protocol for computer assisted electrocardiography (SCP-ECG)<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://dicom.nema.org/medical/dicom/current/output/chtml/part17/sect_C.7.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dicom.nema.org/medical/dicom/current/output/chtml/part17/sect_C.7.html</a></span></span></span> to DICOM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
The information of an implanted pacemaker was exported from the German procedure classification, the official classification for the encoding of operations, procedures and general medical measures<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://www.bfarm.de/EN/Code-systems/Classifications/OPS-ICHI/OPS/_node.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.bfarm.de/EN/Code-systems/Classifications/OPS-ICHI/OPS/_node.html</a></span></span></span>.
General patient metadata was extracted from the quality insurance data for the Institute for Quality Assurance and Transparency in Healthcare<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://iqtig.org/qs-verfahren/hch-komb/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://iqtig.org/qs-verfahren/hch-komb/</a></span></span></span>.
Prior to filtering we had to convert all data types to DICOM, to enable integration of all data types in a single data storage and matching between CTs, ECGs, and SRs on a patient level.
To verify the intended functionality of our platform we additionally uploaded five public datasets and aimed at filtering out the needed subset for our pacemaker prediction scenario at each location in our consortium <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our tool allows for the simultaneous filtering of DICOM imaging and waveform modalities and annotations in the form of structured reports and segmentations (<em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">R1</em>).
All data types present in the consortium could be converted to SRs and subsequently be uploaded into the local PACS. The DICOM representation ensures matching on a patient level across time points (<em id="S4.p1.1.2" class="ltx_emph ltx_font_italic">R2</em>).
In the case of segmentations we visualize all segment descriptions as well as the creator type (<em id="S4.p1.1.3" class="ltx_emph ltx_font_italic">R3</em>).
The dockerized implementation allows for a stand-alone usage as well as an integration into existing frameworks (R4).</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">SR templates exhibit a high degree of sophistication due to their intricately nested structure and the numerous attributes that can be defined <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
To make the data filterable when uploading the SR’s data into Opensearch the user must define, which measurements, geometrical data, qualitative and text attributes shall be queryable by providing the nested path (e.g. for TID 3700 ECG Report: Cardiovascular Patient History - Social History - Tobacco Smoker).
Although this might be complex at times we believe that it provides the flexibility needed for filtering such a sophisticated data structure as SRs.
The definition of the path to the wanted attributes must be defined once per template, but it can be expanded or contracted at any time (<em id="S4.p2.1.1" class="ltx_emph ltx_font_italic">R3</em>).
This also allows for the dynamic creation of custom templates if needed.
An example for the nested, object-oriented representation of the SR template 3700 ECG report and 3708 waveform information in <span id="S4.p2.1.2" class="ltx_text ltx_font_typewriter">highdicom</span> can be found in Fig. 6 in the appendix.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2407.09064/assets/Fig4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="538" height="739" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">The created dashboard with the filterable annotation attributes. The type of annotation can be chosen. Segmentations can be queried on individual segment level. Since for qualitative items both name and value are a concept name, we can filter both. For numeric (e.g. measurements) as well as geometric (e.g. points) items we filter on the name. When the value is text we incorporate free text search. Some filter options concerning imaging modalities (e.g. manufacturer or body part examined) are similar to existing functionality in Kaapana, but under the hood our tool utilizes nested objects to enhance filterability with the given elements.</span></figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Our chosen method was able to extract the required information from the uploaded SR templates and subsequently visualize and modify its distribution depending on the wanted cohort.
The final dashboard for Heidelberg is shown in Fig. <a href="#S4.F4" title="Figure 4 ‣ 4 Results ‣ Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, further resulting distribution from other locations can be found in the appendix.
The interactive graphical filtering procedure is showcased in the supplemental video.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">In Heidelberg we ended up with 1209 series from 840 patients from five modalities (MRI, CT, ECG, classical X-ray (CR), digital radiography (DX)), with a multitude of different annotations (1286) comprising of segmentations (21 different labels) in total.
In total we had over 20 different types of qualitative items, 5 quantitative, 2 geometric, and 1 free text.
With the help of our interface we identified 813 CT and 700 ECG scans that can generally be used for model training.
We had 78 scans with labelled hinge points and coronary arteries (HPs and CAs), 73 with membranous septum (MS), and 78 with annotated aortic root calcification.
When performing filtering at all federated locations, we obtained 6592 CT scans over all locations, 982 with CT and ECG scans across three locations, 7088 patients for which we had the implanted prosthesis information, and 5204 patients for which we had the label of whether a pacemaker was implanted or not post-TAVI.
The quantities within different subsets of data are shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ Federated Learning Consortium ‣ 3 Evaluation ‣ Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
After exporting all datasets in a unified manner to be readable by a federated learning pipeline, we can progress with training on each individual subset or the intersection of two or more.
The training results will be published elsewhere.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">In general the amount of pacemaker dependent patients after TAVI is low at each individual institution.
Thus, we have a very unbalanced label distribution if trained only at one location.
By employing the federated data collection we were able to obtain more cases and thus a more favorable balancing of the data the overall distribution of pacemaker labels.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Despite their complexity, SRs provide an useful tool for unifying diagnostic reports for physicians, model training, and results when utilized appropriately.
The DICOM standard unambiguously matches patient data samples, but large cohort creation that includes patients based on specific attributes is difficult from a PACS interface.
Our solution for determining on which attributes to filter the annotations opts for high flexibility as it is applicable to all SR templates by concurrent conformance with other DICOM data objects such as images or waveforms.
We believe our method is a step towards the concurrent filtering and cohort selection of DICOM data and their annotations.
The platform is openly available and can be used in other projects.
</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">SRs still have more inherent complexity than we have covered here, which is the main reason they are not adopted widely in clinical practice yet, despite their obvious usefulness.
The adoption of the object-oriented approach in <span id="S5.p2.1.1" class="ltx_text ltx_font_typewriter">highdicom</span> for defining and using SR templates in Python is a step towards their more widespread usage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Still, the definition of the required attributes for creating a SR is tedious and requires manual effort.
In future work, we also aim at storing the model output in a consistent manner similar to the homogenized training data.
</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Declarations</h2>

<div id="Sx1.p1" class="ltx_para">
<span id="Sx1.p1.1" class="ltx_ERROR undefined">\bmhead</span>
<p id="Sx1.p1.2" class="ltx_p">Conflict of interest
Norbert Frey reports speaker honoraria, presentations or advisory board consultations from AstraZeneca, Bayer AG, Boehringer Ingelheim, Novartis, Pfizer, Daiichi Sankyo Deutschland.
Tim Seidler reports research, educational, or travel grants and honoraria for lectures or advisory board consultations from Abbott Vascular, AstraZeneca, BoehringerIngelheim, Bristol Myers Squibb, Corvia, Cytokinetics, Edwards Life Sciences, Medtronic, Myocardia, Novartis, Pfizer, Teleflex.
Alexander Meyer reports consulting or lecturing fees from Medtronic, Bayer, Pfizer.
Clemens Scherer reports speaker honorarium from AstraZeneca.
None are related to the content of the manuscript
The other authors declare no conflicts of interest.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<span id="Sx1.p2.1" class="ltx_ERROR undefined">\bmhead</span>
<p id="Sx1.p2.2" class="ltx_p">Funding
The project was funded by the DZHK, the Klaus Tschira Foundation within the Informatics for Life framework, and the BMBF-SWAG Project 01KD2215D.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<span id="Sx1.p3.1" class="ltx_ERROR undefined">\bmhead</span>
<p id="Sx1.p3.2" class="ltx_p">Ethical approval
All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.
This article does not contain any studies with animals performed by any of the authors.
Ethical approval was waived by the local Ethics Committees of Heidelberg (S-475/2021), Göttingen (11/6/21), Hamburg (2021-200262-BO-bet), Munich (21-0497), Münster (2021-487-b-S), and Frankfurt (2021-366_1) in view of the retrospective nature of the study and all the procedures being performed were part of the routine care.
In Berlin, a multi-centric study must not explicitly be confirmed when another institutional ethics board waived approval.</p>
</div>
<div id="Sx1.p4" class="ltx_para">
<span id="Sx1.p4.1" class="ltx_ERROR undefined">\bmhead</span>
<p id="Sx1.p4.2" class="ltx_p">Informed consent
Informed consent was not obtained due to the retrospective nature of the study.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.1.1" class="ltx_bibitem">
<span class="ltx_bibblock"><span id="bib.1.1.1.1" class="ltx_ERROR undefined">\bibcommenthead</span>
</span>
</li>
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bridge et al [2022]</span>
<span class="ltx_bibblock">
Bridge C, Gorman C, Pieper S, Doyle S, Lennerz J, Kalpathy-Cramer J, Clunie D, Fedorov A, Herrmann M (2022) Highdicom: a python library for standardized encoding of image annotations and machine learning model outputs in pathology and radiology. J Digit Imaging 35(6):1719–1737. <a target="_blank" href="https:/doi.org/10.1007/s10278-022-00683-y" title="" class="ltx_ref">10.1007/s10278-022-00683-y</a>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chambon et al [2022]</span>
<span class="ltx_bibblock">
Chambon P, Bluethgen C, Delbrouck JB, Van der Sluijs R, Polacin M, Chaves JMZ, Abraham TM, Purohit S, Langlotz CP, Chaudhari A (2022) Roentgen: Vision-language foundation model for chest x-ray generation. <a target="_blank" href="https:/doi.org/10.48550/ARXIV.2211.12737" title="" class="ltx_ref">10.48550/ARXIV.2211.12737</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedorov et al [2023]</span>
<span class="ltx_bibblock">
Fedorov A, Longabaugh WJR, Pot D, Clunie DA, Pieper SD, Gibbs DL, Bridge C, Herrmann MD, Homeyer A, Lewis R, Aerts HJWL, Krishnaswamy D, Thiriveedhi VK, Ciausu C, Schacherer DP, Bontempi D, Pihl T, Wagner U, Farahani K, Kim E, et al (2023) National cancer institute imaging data commons: Toward transparency, reproducibility, and scalability in imaging artificial intelligence. Radiographics 43(12):e230180. <a target="_blank" href="https:/doi.org/10.1148/rg.230180" title="" class="ltx_ref">10.1148/rg.230180</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Généreux et al [2012]</span>
<span class="ltx_bibblock">
Généreux P, Head SJ, Wood DA, Kodali SK, Williams MR, Paradis JM, Spaziano M, Kappetein AP, Webb JG, Cribier A, Leon MB (2012) Transcatheter aortic valve implantation 10-year anniversary: review of current evidence and clinical implications. European Heart Journal 33(19):2388–2398. <a target="_blank" href="https:/doi.org/10.1093/eurheartj/ehs220" title="" class="ltx_ref">10.1093/eurheartj/ehs220</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kavur et al [2019]</span>
<span class="ltx_bibblock">
Kavur AE, Selver MA, Dicle O, Barış M, Gezer NS (2019) CHAOS - Combined (CT-MR) Healthy Abdominal Organ Segmentation Challenge Data. <a target="_blank" href="https:/doi.org/10.5281/zenodo.3362844" title="" class="ltx_ref">10.5281/zenodo.3362844</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnaswamy et al [2024]</span>
<span class="ltx_bibblock">
Krishnaswamy D, Bontempi D, Thiriveedhi VK, Punzo D, Clunie D, Bridge CP, Aerts HJWL, Kikinis R, Fedorov A (2024) Enrichment of lung cancer computed tomography collections with ai-derived annotations. Scientific Data 11(1):25. <a target="_blank" href="https:/doi.org/10.1038/s41597-023-02864-y" title="" class="ltx_ref">10.1038/s41597-023-02864-y</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Landman et al [2015]</span>
<span class="ltx_bibblock">
Landman B, Xu Z, Igelsias J, Styner M, Langerak T, Klein A (2015) MICCAI multi-atlas labeling beyond the cranial vault–workshop and challenge (2015). <a target="_blank" href="https:/doi.org/10.7303/SYN3193805" title="" class="ltx_ref">10.7303/SYN3193805</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martín-Isla et al [2023]</span>
<span class="ltx_bibblock">
Martín-Isla C, Campello VM, Izquierdo C, Kushibar K, Sendra-Balcells C, Gkontra P, Sojoudi A, Fulton MJ, Arega TW, Punithakumar K, Li L, Sun X, Al Khalil Y, Liu D, Jabbar S, Queirós S, Galati F, Mazher M, Gao Z, Beetz M, et al (2023) Deep Learning Segmentation of the Right Ventricle in Cardiac MRI: The M&amp;Ms Challenge. IEEE Journal of Biomedical and Health Informatics 27(7):3302–3313. <a target="_blank" href="https:/doi.org/10.1109/JBHI.2023.3267857" title="" class="ltx_ref">10.1109/JBHI.2023.3267857</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nobel et al [2022]</span>
<span class="ltx_bibblock">
Nobel M, van Geel K, Robben S (2022) Structured reporting in radiology. European Radiology 32:2837–2854. <a target="_blank" href="https:/doi.org/10.1007/s00330-021-08327-5" title="" class="ltx_ref">10.1007/s00330-021-08327-5</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noumeir [2006]</span>
<span class="ltx_bibblock">
Noumeir R (2006) Benefits of the dicom structured report. J Digit Imaging 16(4):295–306. <a target="_blank" href="https:/doi.org/10.1007/s10278-006-0631-7" title="" class="ltx_ref">10.1007/s10278-006-0631-7</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oquab et al [2024]</span>
<span class="ltx_bibblock">
Oquab M, Darcet T, Moutakanni T, Vo HV, Szafraniec M, Khalidov V, Fernandez P, HAZIZA D, Massa F, El-Nouby A, Assran M, Ballas N, Galuba W, Howes R, Huang PY, Li SW, Misra I, Rabbat M, Sharma V, Synnaeve G, et al (2024) DINOv2: Learning robust visual features without supervision. Transactions on Machine Learning Research <a target="_blank" href="https:/doi.org/10.48550/arXiv.2304.07193" title="" class="ltx_ref">10.48550/arXiv.2304.07193</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieke et al [2020]</span>
<span class="ltx_bibblock">
Rieke N, Hancox J, Li W, Milletarì F, Roth HR, Albarqouni S, Bakas S, Galtier MN, Landman BA, Maier-Hein K, Ourselin S, Sheller M, Summers RM, Trask A, Xu D, Baust M, Cardoso MJ (2020) The future of digital health with federated learning. npj Digital Medicine 3(119):2398–6352. <a target="_blank" href="https:/doi.org/10.1038/s41746-020-00323-1" title="" class="ltx_ref">10.1038/s41746-020-00323-1</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth et al [2016]</span>
<span class="ltx_bibblock">
Roth CJ, Lannum LM, Persons KR (2016) A foundation for enterprise imaging: Himss-siim collaborative white paper. Journal of Digital Imaging 29(5):530–538. <a target="_blank" href="https:/doi.org/10.1007/s10278-016-9882-0" title="" class="ltx_ref">10.1007/s10278-016-9882-0</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saltz et al [2021]</span>
<span class="ltx_bibblock">
Saltz J, Saltz M, Prasanna P, Moffitt R, Hajagos J, Bremer E, Balsamo J, Kurc T (2021) Stony brook university covid-19 positive cases. <a target="_blank" href="https:/doi.org/10.7937/TCIA.BBAG-2923" title="" class="ltx_ref">10.7937/TCIA.BBAG-2923</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scherer et al [2020]</span>
<span class="ltx_bibblock">
Scherer J, Nolden M, Kleesiek J, Metzger J, Kades K, Schneider V, Bach M, Sedlaczek O, Bucher AM, Vogl TJ, Grünwald F, Kühn JP, Hoffmann RT, Kotzerke J, Bethge O, Schimmöller L, Antoch G, Müller HW, Daul A, Nikolaou K, et al (2020) Joint imaging platform for federated clinical data analytics. JCO Clinical Cancer Informatics 4:1027–1038. <a target="_blank" href="https:/doi.org/10.1200/CCI.20.00045" title="" class="ltx_ref">10.1200/CCI.20.00045</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seidler et al [2022]</span>
<span class="ltx_bibblock">
Seidler T, Tölle M, André F, Bannas P, Frey N, Friedrich S, Groß S, Hennemuth A, Krüger N, Leha A, Martin S, Meyer A, Nagel E, Orwat S, Scherer C, Simm TStefan Friede, Engelhardt S (2022) Federated learning of tavi outcomes (floto) - a collaborative multi-center deep learning initiative. Clin Res Cardiol <a target="_blank" href="https:/doi.org/10.1007/s00392-022-02002-5" title="" class="ltx_ref">10.1007/s00392-022-02002-5</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tölle et al [2024]</span>
<span class="ltx_bibblock">
Tölle M, Burger L, Kelm H, Engelhardt S (2024) Towards unified multi-modal dataset creation for deep learning utilizing structured reports. In: Bildverarbeitung für die Medizin 2024, pp 130–135, <a target="_blank" href="https:/doi.org/10.1007/978-3-658-44037-4_39" title="" class="ltx_ref">10.1007/978-3-658-44037-4_39</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wasserthal et al [2023]</span>
<span class="ltx_bibblock">
Wasserthal J, Breit HC, Meyer MT, Pradella M, Hinck D, Sauter AW, Heye T, Boll D, Cyriac J, Yang S, Bach M, Segeroth M (2023) Totalsegmentator: robust segmentation of 104 anatomical structures in ct images. Radiology: Artificial Intelligence 5(5). <a target="_blank" href="https:/doi.org/10.1148/ryai.230024" title="" class="ltx_ref">10.1148/ryai.230024</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.09063" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.09064" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.09064">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.09064" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.09065" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 19:14:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
