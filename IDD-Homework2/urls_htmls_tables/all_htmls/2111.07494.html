<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2111.07494] Federated Learning for Internet of Things: Applications, Challenges, and Opportunities</title><meta property="og:description" content="Billions of IoT devices will be deployed in the near future, taking advantage of faster Internet speed and the possibility of orders of magnitude more endpoints brought by 5G/6G. With the growth of IoT devices, vast qu…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Internet of Things: Applications, Challenges, and Opportunities">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Internet of Things: Applications, Challenges, and Opportunities">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2111.07494">

<!--Generated on Tue Mar 19 16:24:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  IoT
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning for Internet of Things: Applications, Challenges, and Opportunities</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tuo Zhang, Lei Gao, Chaoyang He, Mi Zhang, Bhaskar Krishnamachari, and Salman Avestimehr
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Billions of IoT devices will be deployed in the near future, taking advantage of faster Internet speed and the possibility of orders of magnitude more endpoints brought by 5G/6G. With the growth of IoT devices, vast quantities of data that may contain users’ private information will be generated. The high communication and storage costs, mixed with privacy concerns, will increasingly challenge the traditional ecosystem of centralized over-the-cloud learning and processing for IoT platforms. Federated Learning (FL) has emerged as the most promising alternative approach to this problem. In FL, training data-driven machine learning models is an act of collaboration between multiple clients without requiring the data to be brought to a central point, hence alleviating communication and storage costs and providing a great degree of user-level privacy. However, there are still some challenges existing in the real FL system implementation on IoT networks. In this paper, we will discuss the opportunities and challenges of FL in IoT platforms, as well as how it can enable diverse IoT applications. In particular, we identify and discuss seven critical challenges of FL in IoT platforms and highlight some recent promising approaches towards addressing them.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, IoT

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The rapid advancement and expansion of the Internet of Things (IoT) result in exponential growth of data being generated at the network edge.
Such advancement and expansion pose new challenges to the conventional cloud-based centralized approaches for data analysis from primarily two aspects.
First, the centralized approaches no longer fit the 5G/6G era due to the extremely high communication and storage overhead (e.g., high-frequency data from high-volume time-series sensors such as video cameras or Lidar sensors) for pooling data from millions or billions of IoT devices.
Second, the data being collected is increasingly viewed as threatening user privacy. With the cloud-based centralized approaches, user data could be shared between or even sold to various companies, violating privacy rights and negatively affecting data security, further driving public distrust with data-driven applications.
Therefore, a distributed privacy-preserving approach for data-driven learning and inference-based applications is needed for efficiency and to alleviate privacy concerns.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In recent years, federated learning (FL) has emerged as a distributed privacy-preserving solution to addressing this pressing need.
The term federated learning was first introduced in 2016 by McMahan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. As shown in Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning for Internet of Things: Applications, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, in FL, training of machine learning models for data-driven applications is an act of collaboration between distributed clients without centralizing the client data.
The distributed and collaborative nature of FL is a natural fit to the network edge where each IoT device at the edge is an individual client. Moreover, since the raw data collected at each IoT device are not transmitted to others, FL provides an effective mechanism to protect user privacy particularly in the IoT domain where IoT sensors could directly capture data about users that contain privacy-sensitive personal information.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this article, we briefly explain the advantages that FL brings to the IoT domain and discuss some of the most important IoT applications enabled by these advantages. We then focus on discussing some of the outstanding challenges across systems, networking, security, practical issues in real-world deployments, and development tools that act as the key barriers of enabling FL for the IoT domain and the opportunities in tackling these challenges.
To distinguish our work from existing efforts such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, we focus on new challenges as well as articulating known challenges from new perspectives which have not been discussed before.
We hope that this article could inspire new research that turns the envisioned Internet of Federated Things into reality.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2111.07494/assets/image/fl_diagram.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="449" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Federated Learning for Internet of Things (IoT).</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Why Federated Learning for IoT?</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The distributed, collaborative, and privacy-preserving characteristics of FL bring a number of key advantages for IoT applications (Figure <a href="#S2.F2" title="Figure 2 ‣ II Why Federated Learning for IoT? ‣ Federated Learning for Internet of Things: Applications, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) as follows:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Preserving the Privacy of User Data</span>: In an ideal FL scenario, each IoT device in the system would learn nothing more than the information needed to play its role. The raw data never leaves the devices during the federated training process, and only the updates of the model are sent to the central server, which minimizes the risk of personal data leakage.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Improving Model Performance</span>: Due to device constraints, a single IoT device may not have sufficient data to learn a high-quality model by itself. Under the FL framework, all the IoT devices can collaboratively train a high-quality model such that each participant could benefit from learning data collected by others beyond its own data but without probing others’ private information. Moreover, as the FL could update the local model periodically, the edge device could always update its model in a time-varying manner. Thus, FL is an effective mechanism to enhance the model performance that each individual device cannot achieve by itself.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Flexible Scalability</span>: The distributed nature of FL is able to leverage the constrained computation resources located at multiple IoT devices across different geographical locations in a parallel manner. As edge device hardware capability is increasing, the data size of each individual becomes huge, and centralizing all data to the server either wastes the computing resource at the edge or brings pressure for wireless communication network, which become an obstacle for the network scalability. By attracting more devices to join the framework, FL enhances the scalability of IoT networks without adding an extra burden on a centralized server due to its distributed learning nature. In addition, within the FL framework, there is no need for the expansive transmission of raw IoT-collected data, which also increases the scalability with regard to communication costs, especially for the low bandwidth IoT networks.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2111.07494/assets/image/fl_advantages.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="341" height="336" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Advantages of Federated Learning for IoT.</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Applications</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Benefited from the advantages mentioned above, FL has enabled many important IoT applications. In this section, we briefly discuss some of the most important ones (Figure <a href="#S3.F3" title="Figure 3 ‣ III-A Industry 4.0 ‣ III Applications ‣ Federated Learning for Internet of Things: Applications, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Industry 4.0</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The rapid development in the Industrial Internet of Things (IIoT) brings several advances in information technology applications for the manufacturing field. The concept of Industry 4.0, also known as the fourth industrial revolution, has been proposed based on the emergence of significance for the inter-connectivity of IIoT and the access to real-time data.
With unprecedented connectivity, Industry 4.0 will bring greater insight, control, and data visibility for the supply chain in many industries. Currently, some mature implementations of Industry 4.0 include the Optical Character Recognition (OCR) for the labels, smart and automatic Incoming Quality Control (IQC), and smart Process Quality Control (PQC).
However, there are still some real-world problems challenging the deployment of Industry 4.0. First, the amount of data generated from a single factory may not be sufficient enough for training a reliable model comprehensively. Second, the data collected by the industrial IoT devices is highly related to the commercial value, which makes privacy-preserving important. For example, eavesdroppers may infer the capacity for manufacture from its electricity usage for industrial IoT users. The federated learning framework will become an inspired solution to address the above challenges.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2111.07494/assets/image/fl_applications.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Applications of Federated Learning for IoT.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Healthcare</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As IoT devices become more pervasive in individuals’ daily lives, the privacy of the collected data becomes a significant matter. An example to illustrate privacy concerns is IoT E-health. Nowadays, smart wearable devices are used to monitor the health status of patients, such as heartbeat, blood pressure, and glucose level. Compared to the other types of data, personal healthcare data is most sensitive to users’ privacy and highly restricted by government laws and regulations for any kind of data sharing. Therefore, techniques such as FL are a requirement for investigators and researchers to develop state-of-the-art ML models over a fractured and highly regulated data landscape. The ability to train machine learning models at scale across multiple medical institutions without pooling data is a critical technology to solve the problem of patient privacy and data protection. Successful implementation of federated learning in healthcare could hold significant potential for enabling precision medicine at a large scale, helping match the right treatment to the right patient at the right time.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Smart Home</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Smart home systems enabled by consumer IoT devices have achieved great popularity in the last few years as they improve the comfort and quality of life for the residents.
The wireless smart IoT home devices, such as smart bulbs, smart doorbells, and smart cameras, are capable of communicating with each other and controlled remotely by smartphones and microcontrollers. The implementations of Wake-Up-Word speech recognition and Automatic Speech Recognition (ASR) on IoT devices bring great convenience to everyday living, and people now tend to rely on smart IoT gateways with intelligent virtual assistants to control their home hands-free.
FL has thus become a critical technology that is able to improve the on-device speaker verification while reducing the risk of raw data leakage.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Smart City</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">IoT-enabled smart cities are bringing significant advancements by making city operations efficient while improving the quality of life for citizens.
Various IoT devices enable city managers to control the physical objects in real-time and provide intelligent information to citizens in terms of the traffic system, transportation, public safety, healthcare, smart parking, smart agriculture, and so on.
Due to the concerns of data privacy, smart infrastructures are moving to compute resources close to where data reside, which makes FL framework suitable for deployment.
For example, the FL-based smart grid system enables collaborative learning of power consumption patterns without leaking individual power traces and contributes to the establishment of an interconnected and intelligent energy exchange network in the city.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.4.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.5.2" class="ltx_text ltx_font_italic">Autonomous Driving</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Along with the advancement of the vehicular IoT, autonomous driving technology is making its way into everyday cars. For a reliable self-driving system, it needs frequent real-time communication with a multi-access communication environment. Also, the spatial and temporal changes of the vehicular environment require an intelligent approach that can evolve with the change of environment.
For the traditional centralized-over-cloud method, the driving system needs to transmit a large amount of raw data to the server, which would cause potential privacy leakage. The communication overhead triggered by the large-size data transmission and limited network bandwidth may also lead the driving system to not being able to respond to the real-time spatial changes precisely. Adopting federated learning in vehicular edge computing for autonomous driving has thus become a promising direction to mitigate the above challenges. With FL, each vehicle only needs to transmit a limited size of data to the cloud and can adapt to real-time local changes more sensitively.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS6.4.1.1" class="ltx_text">III-F</span> </span><span id="S3.SS6.5.2" class="ltx_text ltx_font_italic">Metaverse and Virtual Reality</span>
</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">The metaverse is a hypothesized next generation of the internet, providing fully connected, immersive, and engaging online 3D virtual experiences through conventional personal computing, as well as virtual and augmented reality devices. In metaverse, users own their avatars and can interact with virtual objects and other participants.
One of the fundamental building blocks of the metaverse is the digital twins duplicated in virtual environment that reflect the real-time physical world status. The connection between the virtual and physical world is tied by the data collected from IoT devices.
Federated learning is a promising solution to enable collaboration between edge and server for better global performance and also boost the security and privacy of the metaverse. For example, the eye tracking or motion tracking data collected by the wearables of millions of users can be trained in local devices and aggregated via an FL server. Hence, users can enjoy services in the metaverse without leaking their privacy.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2111.07494/assets/image/fl_challenge.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="419" height="417" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Challenges of Federated Learning for IoT.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Challenges and Opportunities</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To realize the full potential of FL in the applications mentioned above, we have identified seven challenges that act as the key barriers of enabling FL on potentially billions of IoT devices. These challenges come from 1) the limited resources of the IoT devices, 2) limited network bandwidth available at the edge, 3) intermittent connectivity and availability commonly occurred in real-world settings, 4) the diversity of IoT devices across their available resources, 5) the temporal dynamics after deployments, 6) how to protect from the adversarial attacks and aggregate client information securely, and 7) the lack of standardization and system development tools in the community.
In the following, we describe these challenges followed by the opportunities that have high promise to address those challenges.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Limited On-device Resources</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The deployment of FL on the network edge is severely impeded by the limited resources of the IoT devices. Existing machine learning models, especially deep neural networks, are known to be computation-intensive, which presents strict requirements on hardware and may result in low training efficiency on edge devices. Thus, developing customized and specialized hardware for machine learning applications on the edge is a promising direction to accelerate inference and training tasks while using much less energy compared with general-purpose processors.
Edge devices have limited resources not only in terms of computation but also in terms of memory for storage and data access. Recent neural network architectures require accessing a vast amount of memory locations for storing not only model weights and parameters but also the intermediate results produced by the computations. Therefore, a significant challenge for processing neural network models on a resource constraint device is reducing the memory accesses and keeping the data on-chip as to avoid costly reads and writes to the external memory modules.
Finally, in contrast to servers with CPUs and GPUs that can use a substantial amount of power, edge devices with embedded processors have a limited energy budget, which further imposes restrictions on the hardware performance. Despite the fact that current edge devices are increasingly powerful, training some deep learning models on-device is still time-consuming and inefficient.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">To make models more applicable for the edge environment, researchers mainly focus on two research directions: design lightweight and hardware-friendly models/algorithms, and compress existing models to obtain thinner and smaller models, which are more computation and energy-efficient.
As an example, FedMask <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> is proposed as a joint computation and communication-efficient FL framework. By applying FedMask, each device can learn a heterogeneous and structured sparse binary mask; based on the mask, it is able to generate a sparse model with reduced computation cost, memory footprint, and energy consumption. However, this approach is hardware-agnostic; to further reduce the resource demands of federated training, we envision that the approach of hardware and algorithm co-design, which sparsifies the model by taking the IoT hardware architecture into consideration during federated training, is a promising future direction.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Limited Network Bandwidth</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Communication bottleneck is considered one of the major challenges in an FL-based IoT environment.
Currently, most IoT devices communicate using wireless networks whose bandwidth is much smaller than wired network bandwidth in datacenters. For example, under a smart home scenario, the sum of the overall networking bandwidth is constant for the whole IoT system, no matter how many devices are connected. As more devices join the system, the communication problem is advent when clients possess different resources allocations. The limited network bandwidth not only makes the communication between clients and the server inefficient but also triggers the presence of straggler clients, which fail to share their local updates with the server during the communication round. They both serve as the bottlenecks for the performance of FL deployment in the large-scale IoT scenario.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">To reduce the bandwidth demand during federated training, methods such as gradient compression have been heavily explored. However, these methods compromise the training quality to gain training efficiency.
Mercury <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed a sampling-based framework that enables efficient on-device distributed training without compromising the training quality as a new inspiration for solving this challenge.
In addition, Chen et al.’s work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> formulates the bandwidth resource allocation and user selection problem during training federated learning models as an optimization problem whose goal is to minimize the training loss while meeting the delay and energy consumption requirements.
Liu et al. also proposed a client-edge-cloud hierarchical aggregation framework as a communication resource-efficient method to operate the federated learning in edge computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Each client is able to offload its data samples and learning tasks from its device to the edge in proximity (e.g., edge gateway at home) for fast computation in the client-edge-cloud paradigm, which allows multiple edge servers to perform partial model aggregation. These works proposed promising and orthogonal techniques to reduce the bandwidth demand in the context of IoT. We envision that those techniques can be combined together in the scenario where IoT devices are confronted with extremely limited network bandwidth.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Intermittent Connectivity and Availability</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Apart from the previous challenge of bandwidth limitations, the intermittent connectivity of the IoT devices signifies an unstable network connection that drops the device out of the system in the middle of the training round. Especially in large-scale IoT systems, the dropout problem followed by the intermittent connectivity and availability of various devices will become a serious obstacle for the FL framework to efficiently manage and schedule clients.
Currently, most of the FL studies are based on the synchronous update at the server, which implies that the server will not start the model aggregation until it receives the information sent from the slowest client. However, in real-world settings, due to the unbalanced communication abilities and training data distribution, the local training speed varies from device to device, and even some clients will be temporarily disconnected during the training phase, which makes the synchronous update nearly impossible. Also, not all of them will be simultaneously available for FL updating. In the asynchronous FL scenarios, a client could join the active learning group even in the middle of the training progress, which endangers the convergence of the federated training.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">To address this challenge, some researchers proposed an asynchronous aggregation scheme with the implementation of coding theory to resist the stragglers in the FL system. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, an asynchronous aggregation protocol known as FedBuff has been proposed to mitigate stragglers and enable secure aggregation jointly. Specifically, the individual updates are not incorporated by the server as soon they arrive. Instead, the server will keep receiving local updates in a secure buffer of size K, which is a tunable parameter, and then update the global model when the buffer is full. However, in real-world settings, IoT devices are by nature heterogeneous with diverse computing speeds. IoT devices with higher computing speed would be able to send in their local updates faster than IoT devices with slower computing speed, which inevitably leads to training bias. We envision that an asynchronous approach that can take the heterogeneity of IoT devices into account could be a better and promising solution.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">System Heterogeneity</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Within cross-device settings, clients under the FL framework have diverse system metrics in terms of both hardware and software.
Various devices with different hardware architectures or even different device vendors are used to perform the learning tasks in different operating systems and different software APIs. Clients may choose different deep learning frameworks such as TensorFlow, PyTorch, and Caffe to train the local models, resulting in different model formats for aggregation. All the diversities have not only posed a significant challenge to system design but also exacerbated the asynchronous communication problem as mentioned above.
Moreover, in IoT settings, the data collected by different devices can be very different in terms of the feature and dimensions, and various types of devices can also have different temporal and spatial preferences for their data collection, which may create a discrepancy in the local data structure among all the participants under FL framework. For example, a surveillance camera will record videos in real-time (24x7 hours), while the data generated by a doorbell is intermittent. However, the central server could not examine the impact of the data heterogeneity until the training is done.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">An FL framework for IoT should enable graceful adaptation of the data and compute load across different devices based on their resource availability. To address this challenge, we envision that the training quality and speed will be improved if we can determine the heterogeneity and make adjustments accordingly before the training starts. Diao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> proposed a heterogeneous FL framework that can produce a single global inference model from training heterogeneous local models on the clients. It is the first time to challenge the underlying assumption of existing work that local models have to share the same architecture as the global model, which inspires a solution to address the system heterogeneity among IoT devices.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Temporal Dynamics and Continual Learning</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">IoT sensing devices will, by their very nature, continuously collect new data, which will be used to update the model for lifelong or continual learning. With the objective of keeping providing services accommodating to newly collected data, the continued model update training poses a new challenge for resource-limited IoT devices. Specifically, as most of the IoT devices are memory-limited, their memory resources are not sufficient enough to handle both model inference and training.
Furthermore, the lack of sufficient memory to keep past collected data may exacerbate catastrophic forgetting, which is one of the most critical problems in continual learning.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">To address this challenge, we envision that the light-weighted machine learning engine is needed to reduce the memory consumption for on-device training. As an example, FedGKT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> is a potential method to reduce the training memory footprint for efficient on-device learning. With FedGKT, IoT devices could transfer knowledge from many compact CNN models to a large CNN at a cloud server, which reformulates FL as a group knowledge transfer training model for the large-size model training on resource-constrained edge devices. To avoid catastrophic forgetting, we envision the use of clustering approaches that identify and store a few core data samples from each time interval. Moreover, leveraging IoT “Hubs” that can store non-sensitive/public datasets to inject memory in the training system is another promising solution. Furthermore, approaches that can detect temporal distribution shifts at each IoT node to determine when to update the model would also be needed.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.4.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.5.2" class="ltx_text ltx_font_italic">Trustworthiness</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">In practical deployment, IoT devices are attractive targets for adversaries seeking to launch attacks such as phishing, identity theft, and distributed denial of service (DDoS). With the expansion of the IoT networks, the potential traffic volume of IoT-based DDoS attacks is reaching unprecedented levels, as witnessed during the Mirai botnet attack leveraging infected webcams and home routers.
Attacks through the Internet have raised awareness of the need for IoT risk assessment and security, e.g., in fields such as healthcare. Even though these attacks could be easily defended by installing security patches, many IoT devices lack the requisite computation resources to do so. Moreover, within a cross-device system setting, it is difficult to identify whether the coming participant is malicious or not before it joins the system. Therefore, it is crucial for the IoT system to detect malicious or broken IoT devices that will ruin the model training with limited resources.
To address this challenge, one of the promising directions is to implement a lightweight security protocol in the IoT system for the detection of broken and malicious devices. With the distributed nature, FL can offer an alternative approach for IoT cybersecurity by protecting the system from malicious attacks as close as possible to the IoT devices. DIoT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> is the first system to employ an FL approach to anomaly-detection-based intrusion detection in gateways to IoT devices without centralizing the on-device data, where it demonstrates the efficacy of federated learning in detecting a wider range of attack types occurring at multiple devices.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">Although FL shows its efficacy in cybersecurity for the IoT system, the privacy leakage from on-device sensitive data still matters as the participants share the model gradients or weight parameters with the server during the training process, which are derived from the participants’ private training data as a statistical representation of the data it was trained on. The attacker could initiate the model inversion attack on the FL server first to achieve the individual model of each participant, and then recover the personal training data by inverting these personal models. One of the representative works for the attacking above is the inverting gradients attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, which proves that personal data reconstruction from gradient information is possible in federated learning setups. Therefore, a critical consideration in FL design is to ensure that the server as a blackbox for aggregation that does not learn the locally trained model of each user during model aggregation. Currently, the state-of-the-art secure aggregation protocols in FL essentially rely on two main principles: the pairwise random-seed agreement between users in order to generate masks that hide users’ models while having an additive structure that allows their cancellation when added at the server; and the secret sharing of the random-seeds so as to enable the reconstruction and cancellation of masks belonging to dropped users. The main drawback of such approaches is that the number of mask reconstructions at the server substantially grows as more users are dropped, causing a major computational bottleneck. Especially for the low-end IoT devices, the additional operator for the secure aggregation becomes an excessive burden to the limited on-device computational resources. To address this challenge, one of the promising directions is to implement lightweight and secure aggregation protocols that could provide the same level of privacy and dropout resiliency guarantees while substantially reducing the aggregation complexity, which meets the constraint in the IoT setting.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS7.4.1.1" class="ltx_text">IV-G</span> </span><span id="S4.SS7.5.2" class="ltx_text ltx_font_italic">Standardization and System Development Tools</span>
</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">There are many concerns that the researchers need to take into account when designing a federated learning system on IoT networks. Issues such as different communication APIs, dataflow models, network configurations, and device properties have to be considered. As an emerging field, FL for IoT has not been standardized and appropriately implemented. Therefore, the research and development for standardization could help expedite the widespread deployment of FL systems on IoT networks and create an open environment for content sharing. Additionally, in light of the complexity involved in federated learning, researchers and industries need to further build upon existing FL developing and benchmarking tools such as TensorFlow Federated, PySyft, and FedML to accommodate the scenarios of IoT applications. From the application-level perspective, user-friendly integrated simulation environments are needed to help design and evaluate the entire FL system on a large scale of IoT networks and its feasibility without implementing the model in real-world settings. From the system design perspective, ideally, we are looking for tools that can help developers accomplish system-level tasks such as load balancing, resource management, task scheduling, or data migrations easily.</p>
</div>
<div id="S4.SS7.p2" class="ltx_para">
<p id="S4.SS7.p2.1" class="ltx_p">One work of note along this direction is FedIoT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> which provides a mature systems-level framework that the developer can use to deploy their federated learning applications on CPU or GPU-enabled IoT devices, such as Raspberry Pi and NVIDIA Jetson Nano. To make federated learning more ubiquitous on IoT devices, we believe that researchers should pay attention to extending the current training frameworks to edge FL setting with awareness of the challenges mentioned above. It is worth mentioning that current edge computing solutions such as TensorFlow Lite, MNN, and TVM are focusing on improving the performance and efficiency of edge inference instead of training, much less taking FL setting into consideration, which is an under-explored area that would bring significant values to the federated learning and IoT communities.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Concluding Remarks</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The distributed, collaborative, and privacy-preserving nature of federated learning makes it well suited for the IoT domain across a wide range of applications.
In this article, we highlighted the key advantages and elaborated on some important applications of federated learning for IoT. We have also identified seven challenges that act as the key barriers of enabling FL for IoT followed by discussing opportunities to address these challenges. We hope this article acts as a catalyst to inspire new research at the intersection of federated learning and IoT.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Acknowledgments</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This material is based upon work supported by Defense Advanced Research Projects Agency (DARPA) under Contract No. HR001120C0160, ARO award W911NF1810400, NSF grants CCF-1703575, CCF-1763673, CNS-2002874, ONR Award No. N00014-16-1-2189, a gift from Intel/Avast/Borsetta via the PrivateAI institute, a gift from Konica Minolta, and a gift from Cisco. The views, opinions, and/or findings expressed are those of the author(s) and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government. We would like to thank Eric van den Berg, Stuart Wagner, and Latha Kant from Peraton Labs for their insightful comments on an earlier draft of this work.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y. Arcas,
“Communication-Efficient Learning of Deep Networks from Decentralized
Data,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics</em>, ser. Proceedings of Machine Learning
Research, A. Singh and J. Zhu, Eds., vol. 54.   PMLR, 20–22 Apr 2017, pp. 1273–1282. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://proceedings.mlr.press/v54/mcmahan17a.html</span>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. B. Charles, G. Cormode, R. Cummings, R. G. L. D’Oliveira,
S. Y. E. Rouayheb, D. Evans, J. Gardner, Z. Garrett, A. Gascón, B. Ghazi,
P. B. Gibbons, M. Gruteser, Z. Harchaoui, C. He, L. He, Z. Huo,
B. Hutchinson, J. Hsu, M. Jaggi, T. Javidi, G. Joshi, M. Khodak,
J. Konecný, A. Korolova, F. Koushanfar, O. Koyejo, T. Lepoint, Y. Liu,
P. Mittal, M. Mohri, R. Nock, A. Özgür, R. Pagh, M. Raykova, H. Qi,
D. Ramage, R. Raskar, D. X. Song, W. Song, S. U. Stich, Z. Sun, A. T. Suresh,
F. Tramèr, P. Vepakomma, J. Wang, L. Xiong, Z. Xu, Q. Yang, F. X. Yu,
H. Yu, and S. Zhao, “Advances and open problems in federated learning,”
<em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Found. Trends Mach. Learn.</em>, vol. 14, pp. 1–210, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang, D. T.
Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>,
vol. 22, pp. 2031–2063, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. S. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing
Magazine</em>, vol. 37, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Imteaj, U. Thakker, S. Wang, J. Li, and M. H. Amini, “A survey on federated
learning for resource-constrained iot devices,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of
Things Journal</em>, vol. 9, pp. 1–24, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Li, J. Sun, X. Zeng, M. Zhang, H. Li, and Y. Chen, “FedMask: Joint
Computation and Communication-Efficient Personalized Federated Learning via
Heterogeneous Masking,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">ACM Conference on Embedded Networked
Sensor Systems (SenSys)</em>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
X. Zeng, M. Yan, and M. Zhang, “Mercury: Efficient on-device distributed dnn
training via stochastic importance sampling,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">The 19th ACM
Conference on Embedded Networked Sensor Systems (SenSys’21)</em>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning
and communications framework for federated learning over wireless networks,”
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless Communications</em>, vol. 20, no. 1, pp.
269–283, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Liu, J. Zhang, S. Song, and K. B. Letaief, “Client-edge-cloud hierarchical
federated learning,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ICC 2020 - 2020 IEEE International Conference
on Communications (ICC)</em>, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Nguyen, K. Malik, H. Zhan, A. Yousefpour, M. G. Rabbat, M. Malekesmaeili,
and D. Huba, “Federated learning with buffered asynchronous aggregation,”
<em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Federated Learning for User Privacy and Data Confidentiality Workshop
At ICML</em>, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
E. Diao, J. Ding, and V. Tarokh, “Heterofl: Computation and communication
efficient federated learning for heterogeneous clients,” in
<em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
C. He, M. Annavaram, and S. Avestimehr, “Group knowledge transfer: Federated
learning of large cnns at the edge,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, vol. 33, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni, N. Asokan, and A.-R.
Sadeghi, “DÏot: A federated self-learning anomaly detection system for
iot,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 39th International Conference on Distributed
Computing Systems (ICDCS)</em>, 2019, pp. 756–767.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller, “Inverting
gradients–how easy is it to break privacy in federated learning?”
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 33, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T. Zhang, C. He, T. Ma, L. Gao, M. Ma, and S. Avestimehr, “Federated learning
for internet of things,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM Conference on
Embedded Networked Sensor Systems</em>, ser. SenSys ’21.   New York, NY, USA: Association for Computing Machinery,
2021, p. 413–419. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1145/3485730.3493444</span>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.7.1" class="ltx_text ltx_font_smallcaps">Biography Section</span>
</h2>

<figure id="S7.1" class="ltx_float biography">
<table id="S7.1.1" class="ltx_tabular">
<tr id="S7.1.1.1" class="ltx_tr">
<td id="S7.1.1.1.1" class="ltx_td"><img src="/html/2111.07494/assets/x1.jpg" id="S7.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="107" height="138" alt="[Uncaptioned image]"></td>
<td id="S7.1.1.1.2" class="ltx_td">
<span id="S7.1.1.1.2.1" class="ltx_inline-block">
<span id="S7.1.1.1.2.1.1" class="ltx_p"><span id="S7.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Tuo Zhang</span> 
Tuo Zhang (tuozhang@usc.edu) received his B.S. degree in electrical engineering from University of California, Santa Barbara in 2020. He is currently working toward a Ph.D. in Viterbi School of Engineering, University of Southern California. His research interest is in developing trustworthy machine learning algorithms and systems.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S7.2" class="ltx_float biography">
<table id="S7.2.1" class="ltx_tabular">
<tr id="S7.2.1.1" class="ltx_tr">
<td id="S7.2.1.1.1" class="ltx_td"><img src="/html/2111.07494/assets/bio_image/Lei.jpeg" id="S7.2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="94" height="125" alt="[Uncaptioned image]"></td>
<td id="S7.2.1.1.2" class="ltx_td">
<span id="S7.2.1.1.2.1" class="ltx_inline-block">
<span id="S7.2.1.1.2.1.1" class="ltx_p"><span id="S7.2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Lei Gao</span> 
Lei Gao (leig@usc.edu) received his B.S. degree in electrical engineering from University of California, Santa Barbara in 2019, and his M.S. in electrical engineering from University of Southern California in 2021. He is currently working as a student researcher at vITAL Lab in University of Southern California. His research interests are machine learning, Internet of Things and edge computing.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S7.3" class="ltx_float biography">
<table id="S7.3.1" class="ltx_tabular">
<tr id="S7.3.1.1" class="ltx_tr">
<td id="S7.3.1.1.1" class="ltx_td"><img src="/html/2111.07494/assets/bio_image/chaoyanghe.png" id="S7.3.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="S7.3.1.1.2" class="ltx_td">
<span id="S7.3.1.1.2.1" class="ltx_inline-block">
<span id="S7.3.1.1.2.1.1" class="ltx_p"><span id="S7.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Chaoyang He</span>  Chaoyang He is a Ph.D. Candidate in the CS department at the University of Southern California. His research focuses on distributed/federated machine learning algorithms, systems, and applications. He is advised by Professor Salman Avestimehr (USC) and Mahdi Soltanolkotabi (USC). Previously, He was an R&amp;D Team Manager and Staff Software Engineer at Tencent (2014-2018), a Team Leader and Senior Software Engineer at Baidu (2012-2014), and a Software Engineer at Huawei (2011-2012).</span>
<span id="S7.3.1.1.2.1.2" class="ltx_p">Chaoyang He has received a number of awards in academia and industry, including Best Paper Award at NeurIPS 2020 Federated Learning workshop, Amazon Machine Learning Fellowship (2021-2022), Qualcomm Innovation Fellowship (2021-2022), Tencent Outstanding Staff Award (2015-2016), WeChat Special Award for Innovation (2016), Baidu LBS Group Star Awards (2013), and Huawei Golden Network Award (2012). During his Ph.D. study, he has published papers at ICML, NeurIPS, CVPR, ICLR, MLSys, among others. His homepage: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://chaoyanghe.com</span>.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S7.4" class="ltx_float biography">
<table id="S7.4.1" class="ltx_tabular">
<tr id="S7.4.1.1" class="ltx_tr">
<td id="S7.4.1.1.1" class="ltx_td"><img src="/html/2111.07494/assets/bio_image/Mi.jpg" id="S7.4.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="90" height="125" alt="[Uncaptioned image]"></td>
<td id="S7.4.1.1.2" class="ltx_td">
<span id="S7.4.1.1.2.1" class="ltx_inline-block">
<span id="S7.4.1.1.2.1.1" class="ltx_p"><span id="S7.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Mi Zhang</span> 
Mi Zhang is an Associate Professor and the Director of the Machine Learning Systems Lab at Michigan State University. He received his Ph.D. from University of Southern California and B.S. from Peking University. Before joining MSU, he was a postdoctoral scholar at Cornell University. His research lies at the intersection of mobile/edge/IoT systems and machine learning, spanning areas including On-Device AI, Automated Machine Learning (AutoML), Federated Learning, Systems for Machine Learning, Machine Learning for Systems, and AI for Health and Social Good.</span>
<span id="S7.4.1.1.2.1.2" class="ltx_p">Dr. Zhang has received a number of awards for his research. He is the 4th Place Winner of the 2019 Google MicroNet Challenge, the Third Place Winner of the 2017 NSF Hearables Challenge, and the champion of the 2016 NIH Pill Image Recognition Challenge. He is the recipient of seven best paper awards and nominations. He is also the recipient of the National Science Foundation CRII Award, Facebook Faculty Research Award, Amazon Machine Learning Research Award, and MSU Innovation of the Year Award.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S7.5" class="ltx_float biography">
<table id="S7.5.1" class="ltx_tabular">
<tr id="S7.5.1.1" class="ltx_tr">
<td id="S7.5.1.1.1" class="ltx_td"><img src="/html/2111.07494/assets/bio_image/bhaskark.png" id="S7.5.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="102" alt="[Uncaptioned image]"></td>
<td id="S7.5.1.1.2" class="ltx_td">
<span id="S7.5.1.1.2.1" class="ltx_inline-block">
<span id="S7.5.1.1.2.1.1" class="ltx_p"><span id="S7.5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Bhaskar Krishnamachari</span> 
Bhaskar Krishnamachari is Professor of Electrical and Computer Engineering at the USC Viterbi School of Engineering. He is the founding director of the USC Viterbi Center for Cyber-Physical Systems and the Internet of Things. He received his M.S. and Ph.D. in Electrical Engineering from Cornell University in 1999 and 2002 respectively, and his B.E. in Electrical Engineering from The Cooper Union for the Advancement of Science and Art in 1998. His research interests pertain to the design and analysis of algorithms, protocols and applications for the internet of things, distributed computing, blockchain technologies, and networked robotics. He is the recipient of an NSF CAREER Award, the ASEE Terman Award, IEEE-HKN Outstanding Young Electrical and Computer Engineer Award, and several conference best paper awards including at ACM Mobicom and IEEE/ACM IPSN.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S7.6" class="ltx_float biography">
<table id="S7.6.1" class="ltx_tabular">
<tr id="S7.6.1.1" class="ltx_tr">
<td id="S7.6.1.1.1" class="ltx_td"><img src="/html/2111.07494/assets/bio_image/SA.png" id="S7.6.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="119" alt="[Uncaptioned image]"></td>
<td id="S7.6.1.1.2" class="ltx_td">
<span id="S7.6.1.1.2.1" class="ltx_inline-block">
<span id="S7.6.1.1.2.1.1" class="ltx_p"><span id="S7.6.1.1.2.1.1.1" class="ltx_text ltx_font_bold">A. Salman Avestimehr</span>  A. Salman Avestimehr is a Dean’s Professor, the inaugural director of the USC-Amazon Center on Secure and Trusted Machine Learning (Trusted AI), and the director of the Information Theory and Machine Learning (vITAL) research lab at the Electrical and Computer Engineering Department of University of Southern California. He is also an Amazon Scholar at Alexa AI. He received his Ph.D. in 2008 and M.S. degree in 2005 in Electrical Engineering and Computer Science, both from the University of California, Berkeley. Prior to that, he obtained his B.S. in Electrical Engineering from Sharif University of Technology in 2003. His research interests include information theory, large-scale distributed computing and machine learning, secure and private computing/learning, and federated learning.</span>
<span id="S7.6.1.1.2.1.2" class="ltx_p">Dr. Avestimehr has received a number of awards for his research, including the James L. Massey Research &amp; Teaching Award from IEEE Information Theory Society, an Information Theory Society and Communication Society Joint Paper Award, a Presidential Early Career Award for Scientists and Engineers (PECASE) from the White House (President Obama), a Young Investigator Program (YIP) award from the U. S. Air Force Office of Scientific Research, a National Science Foundation CAREER award, the David J. Sakrison Memorial Prize, and several Best Paper Awards at Conferences. He has been an Associate Editor for IEEE Transactions on Information Theory and a general Co-Chair of the 2020 International Symposium on Information Theory (ISIT). He is a fellow of IEEE. <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.avestimehr.com</span>.</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2111.07493" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2111.07494" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2111.07494">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2111.07494" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2111.07495" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 16:24:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
