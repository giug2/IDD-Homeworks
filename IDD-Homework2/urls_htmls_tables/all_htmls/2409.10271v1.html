<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Causal Discovery in Recommender Systems: Example and Discussion</title>
<!--Generated on Mon Sep 16 13:22:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.10271v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S1" title="In Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S2" title="In Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Causal Discovery Process</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S2.SS0.SSS0.Px1" title="In 2. Causal Discovery Process â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title">Remove features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S2.SS0.SSS0.Px2" title="In 2. Causal Discovery Process â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title">Discretize features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S2.SS0.SSS0.Px3" title="In 2. Causal Discovery Process â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title">Build Prior-Knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S2.SS0.SSS0.Px4" title="In 2. Causal Discovery Process â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title">Structure Learning Phase</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S2.SS0.SSS0.Px5" title="In 2. Causal Discovery Process â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title">Average Causal Graph</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S3" title="In Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Learned Causal Graph</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S4" title="In Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#A1" title="In Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Full Learned Causal Graph</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Causal Discovery in Recommender Systems: Example and Discussion</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Emanuele Cavenaghi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:ecavenaghi@unibz.it">ecavenaghi@unibz.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-0235-0421" title="ORCID identifier">0000-0002-0235-0421</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Free University of Bozen-Bolzano</span><span class="ltx_text ltx_affiliation_streetaddress" id="id2.2.id2">Piazza UniversitÃ , 1</span><span class="ltx_text ltx_affiliation_city" id="id3.3.id3">Bolzano</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">Italy</span><span class="ltx_text ltx_affiliation_postcode" id="id5.5.id5">39100</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabio Stella
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:fabio.stella@unimib.it">fabio.stella@unimib.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-1394-0507" title="ORCID identifier">0000-0002-1394-0507</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">University of Milano-Bicocca</span><span class="ltx_text ltx_affiliation_streetaddress" id="id7.2.id2">Piazza dellâ€™Ateneo Nuovo, 1</span><span class="ltx_text ltx_affiliation_city" id="id8.3.id3">Milano</span><span class="ltx_text ltx_affiliation_country" id="id9.4.id4">Italy</span><span class="ltx_text ltx_affiliation_postcode" id="id10.5.id5">20126</span>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Markus Zanker
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mzanker@unibz.it">mzanker@unibz.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-4805-5516" title="ORCID identifier">0000-0002-4805-5516</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">Free University of Bozen-Bolzano</span><span class="ltx_text ltx_affiliation_streetaddress" id="id12.2.id2">Piazza UniversitÃ , 1</span><span class="ltx_text ltx_affiliation_city" id="id13.3.id3">Bolzano</span><span class="ltx_text ltx_affiliation_country" id="id14.4.id4">Italy</span><span class="ltx_text ltx_affiliation_postcode" id="id15.5.id5">39100</span>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id16.6.id1">University of Klagenfurt</span><span class="ltx_text ltx_affiliation_streetaddress" id="id17.7.id2">UniversitÃ¤tsstraÃŸe 65-67</span><span class="ltx_text ltx_affiliation_city" id="id18.8.id3">Klagenfurt</span><span class="ltx_text ltx_affiliation_country" id="id19.9.id4">Austria</span><span class="ltx_text ltx_affiliation_postcode" id="id20.10.id5">9020</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id21.id1">Causality is receiving increasing attention by the artificial intelligence and machine learning communities. This paper gives an example of modelling a recommender system problem using causal graphs. Specifically, we approached the causal discovery task to learn a causal graph by combining observational data from an open-source dataset with prior knowledge. The resulting causal graph shows that only a few variables effectively influence the analysed feedback signals. This contrasts with the recent trend in the machine learning community to include more and more variables in massive models, such as neural networks.</p>
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>Causality, Counterfactuals &amp; Sequential Decision-Making; Oct. 14th-18th 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>CONSEQUENCES â€™24: Causality, Counterfactuals &amp; Sequential Decision-Making, Oct. 14th-18th 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Mathematics of computingÂ Causal networks</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In recent years, several approaches from causality have been applied in <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">Recommender Systems</span> (RS) <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib4" title="">2023</a>; Gao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib7" title="">2022b</a>; Cavenaghi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib3" title="">2024</a>)</cite>, especially using Causal Graphs (CGs) <cite class="ltx_cite ltx_citemacro_citep">(Pearl, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib12" title="">2009</a>)</cite> which allow us to model, in a graphical and human-readable format, cause-and-effect relations among factors. Furthermore, to exploit the strength of causality, we should define the quantity that we aim to estimate as <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">causal estimands<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote1.1.1.1">1</span></span><span class="ltx_text ltx_font_upright" id="footnote1.5">A causal estimand is a quantity that encodes the notion of the causal effect of a variable (the cause) on another (the effect).</span></span></span></span></span> that can only be estimated in controlled experiments. However, through CGs, we can identify an equivalent <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">statistical estimand</span> that can be estimated using observational data, i.e., data collected outside the scope of controlled experiments. To this end, a common approach is to use the so-called <span class="ltx_text ltx_font_italic" id="S1.p1.1.4">adjustment formula</span> estimator <cite class="ltx_cite ltx_citemacro_citep">(Glymour etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib8" title="">2016</a>)</cite> on an <span class="ltx_text ltx_font_italic" id="S1.p1.1.5">adjustment set</span> identified on the CG. Moreover, even the commonly used causal approaches, such as <span class="ltx_text ltx_font_italic" id="S1.p1.1.6">Inverse Probability Weighting</span> <cite class="ltx_cite ltx_citemacro_citep">(Schnabel etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib15" title="">2016</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib18" title="">2016</a>; Joachims etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib9" title="">2017</a>)</cite>, doubly robust estimators <cite class="ltx_cite ltx_citemacro_citep">(Saito, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib14" title="">2020</a>)</cite> and counterfactuals <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib17" title="">2021</a>; Wei etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib19" title="">2021</a>; Yang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib21" title="">2021</a>)</cite>, can benefit from the use of CGs to identify the relevant variables that should be used and thus reduce the dimension of the problem.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, very few works tackle the problem of learning a CG in an RS domain <cite class="ltx_cite ltx_citemacro_citep">(Xu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib20" title="">2022</a>; Cavenaghi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib2" title="">2023</a>)</cite> from data. Nonetheless, a manually designed CG only encodes our knowledge of the problem without any information gathered from the data. Therefore, we tackled the problem of learning a CG by combining prior knowledge and observational data from the open-source dataset <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">KuaiRand</span> <cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib6" title="">2022a</a>)</cite>. As a result, we report all the steps followed to learn a CG, from data and prior knowledge to the final result, to inspire other researchers who want to use causal models to tackle RS problems.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Causal Discovery Process</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.6">In this section, we report the process followed to learn the CG reported below starting from the open-source dataset <span class="ltx_text ltx_font_italic" id="S2.p1.6.1">KuaiRand</span> <cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib6" title="">2022a</a>)</cite>. In particular, we used the <span class="ltx_text ltx_font_italic" id="S2.p1.6.2">KuaiRand-Pure</span> dataset collected through randomly recommended videos in the user interaction sequence. This version of the dataset consists of <math alttext="1\,186\,059" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">1â€‰186â€‰059</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn id="S2.p1.1.m1.1.1.cmml" type="integer" xref="S2.p1.1.m1.1.1">1186059</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">1\,186\,059</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">1 186 059</annotation></semantics></math> interactions between the system and the <math alttext="27\,285" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mn id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">27â€‰285</mn><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><cn id="S2.p1.2.m2.1.1.cmml" type="integer" xref="S2.p1.2.m2.1.1">27285</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">27\,285</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">27 285</annotation></semantics></math> users who were recommended from a pool of <math alttext="7\,583" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">7â€‰583</mn><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><cn id="S2.p1.3.m3.1.1.cmml" type="integer" xref="S2.p1.3.m3.1.1">7583</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">7\,583</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">7 583</annotation></semantics></math> items. Moreover, the dataset includes <math alttext="30" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><mn id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><cn id="S2.p1.4.m4.1.1.cmml" type="integer" xref="S2.p1.4.m4.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">30</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">30</annotation></semantics></math> usersâ€™ features, <math alttext="62" class="ltx_Math" display="inline" id="S2.p1.5.m5.1"><semantics id="S2.p1.5.m5.1a"><mn id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml">62</mn><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><cn id="S2.p1.5.m5.1.1.cmml" type="integer" xref="S2.p1.5.m5.1.1">62</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">62</annotation><annotation encoding="application/x-llamapun" id="S2.p1.5.m5.1d">62</annotation></semantics></math> itemsâ€™ features and <math alttext="12" class="ltx_Math" display="inline" id="S2.p1.6.m6.1"><semantics id="S2.p1.6.m6.1a"><mn id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><cn id="S2.p1.6.m6.1.1.cmml" type="integer" xref="S2.p1.6.m6.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">12</annotation><annotation encoding="application/x-llamapun" id="S2.p1.6.m6.1d">12</annotation></semantics></math> feedback signals. Below, we report the five macro-steps followed in the causal discovery process:</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Remove features</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">In the first step, we removed the interaction features irrelevant to our goal, such as the interaction date and time, and the feedback signals with too few positive observations. Furthermore, we excluded all the encrypted usersâ€™ features since we can not use prior knowledge on them as they lack any semantic information. Finally, we removed the itemsâ€™ music ID since almost all the videos are related to a different ID.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Discretize features</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">In the second step, we discretized all the features since the structure learning algorithm used to learn the CG can only handle discrete data. To this end, several features are available both with the original values and with a discretized version; thus, for these features, we decided to keep the discretization suggested by the authors of the dataset. For the remaining features, we chose the categories using the feature semantics to lose as little information as possible and to ensure that each category was observed a reasonable number of times.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Build Prior-Knowledge</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">In the third step, we defined how to include prior knowledge in the structure learning phase. To this extent, domain experts can list specific edges that the structure learning algorithm must exclude or include during the graph recovering procedure, i.e., forbidden and required edges. Alternatively, it is also possible to define ordered edge sets, or tiers, that induce a partial order among the observed variables where nodes in lower tiers can not be the cause of nodes in higher tiers. In this work, we used the tiers approach and defined the following tiers: (i) user features, (ii) context feature â€œ<span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px3.p1.1.1">tab</span>â€<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>As named in the dataset and described at https://kuairand.com/</span></span></span>, (iii) item features, (iv) item statistics and (v) feedback signals.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px4">
<h3 class="ltx_title ltx_title_paragraph">Structure Learning Phase</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px4.p1.4">In this work, we relied on the <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px4.p1.4.1">Hill-Climbing</em> (HC) <cite class="ltx_cite ltx_citemacro_citep">(Scutari etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib16" title="">2019</a>)</cite> algorithm implemented in <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px4.p1.4.2">bnlearn<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote3.1.1.1">3</span></span><span class="ltx_text ltx_font_upright" id="footnote3.5">https://www.bnlearn.com/</span></span></span></span></span>, which traverses the space of the possible CGs selecting the optimal graph <math alttext="\mathcal{G}^{*}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px4.p1.1.m1.1a"><msup id="S2.SS0.SSS0.Px4.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px4.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml">ğ’¢</mi><mo id="S2.SS0.SSS0.Px4.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px4.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1.2">ğ’¢</ci><times id="S2.SS0.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px4.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px4.p1.1.m1.1c">\mathcal{G}^{*}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px4.p1.1.m1.1d">caligraphic_G start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT</annotation></semantics></math> w.r.t. a goodness-of-fit function <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p1.2.m2.1"><semantics id="S2.SS0.SSS0.Px4.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px4.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px4.p1.2.m2.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px4.p1.2.m2.1b"><ci id="S2.SS0.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px4.p1.2.m2.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px4.p1.2.m2.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px4.p1.2.m2.1d">caligraphic_S</annotation></semantics></math>, known as the <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px4.p1.4.3">scoring criterion</span>. At its core, HC iteratively modifies the current recovered graph to maximize <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p1.3.m3.1"><semantics id="S2.SS0.SSS0.Px4.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px4.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px4.p1.3.m3.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px4.p1.3.m3.1b"><ci id="S2.SS0.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px4.p1.3.m3.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px4.p1.3.m3.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px4.p1.3.m3.1d">caligraphic_S</annotation></semantics></math> by adding, deleting or reversing individual edges. When no modification improves the score, the procedure halts and returns the current solution. HC is guaranteed to include edges coherent with the underlying independence statements, provided that <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p1.4.m4.1"><semantics id="S2.SS0.SSS0.Px4.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px4.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px4.p1.4.m4.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px4.p1.4.m4.1b"><ci id="S2.SS0.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px4.p1.4.m4.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px4.p1.4.m4.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px4.p1.4.m4.1d">caligraphic_S</annotation></semantics></math> is a <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px4.p1.4.4">consistent scoring criterion</em>. In this work, we used the <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px4.p1.4.5">Bayesian Information Criterion</span> (BIC) score <cite class="ltx_cite ltx_citemacro_citep">(Chickering, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib5" title="">1995</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px5">
<h3 class="ltx_title ltx_title_paragraph">Average Causal Graph</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px5.p1.2">In total, we learnt <math alttext="100" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px5.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px5.p1.1.m1.1a"><mn id="S2.SS0.SSS0.Px5.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px5.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px5.p1.1.m1.1b"><cn id="S2.SS0.SSS0.Px5.p1.1.m1.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px5.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px5.p1.1.m1.1c">100</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px5.p1.1.m1.1d">100</annotation></semantics></math> CGs using the HC algorithm with the prior knowledge and the discretized dataset described above. Then, to obtain a single CG containing only significant edges, we averaged the learnt CGs by selecting only the edges present in at least <math alttext="90\%" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px5.p1.2.m2.1"><semantics id="S2.SS0.SSS0.Px5.p1.2.m2.1a"><mrow id="S2.SS0.SSS0.Px5.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px5.p1.2.m2.1.1.cmml"><mn id="S2.SS0.SSS0.Px5.p1.2.m2.1.1.2" xref="S2.SS0.SSS0.Px5.p1.2.m2.1.1.2.cmml">90</mn><mo id="S2.SS0.SSS0.Px5.p1.2.m2.1.1.1" xref="S2.SS0.SSS0.Px5.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px5.p1.2.m2.1b"><apply id="S2.SS0.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px5.p1.2.m2.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px5.p1.2.m2.1.1.1">percent</csymbol><cn id="S2.SS0.SSS0.Px5.p1.2.m2.1.1.2.cmml" type="integer" xref="S2.SS0.SSS0.Px5.p1.2.m2.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px5.p1.2.m2.1c">90\%</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px5.p1.2.m2.1d">90 %</annotation></semantics></math> of the CGs. The learned CG is reported in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#A1" title="Appendix A Full Learned Causal Graph â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_tag">A</span></a> Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#A1.F2" title="Figure 2 â€£ Appendix A Full Learned Causal Graph â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Learned Causal Graph</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we report a part of the entire CG leveraging the independence statements to restrict the CG to a proper sub-graph by discarding irrelevant factors that are not in the <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">Markov Blanket</span> (MB) <cite class="ltx_cite ltx_citemacro_citep">(Pearl, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib11" title="">1988</a>)</cite> of the feedback signals nodes. An MB is defined as a subset of variables that contains all the useful information to infer the value of a random variable. Therefore, since the most important factors are the feedback signals, we restrict our focus on their MB, which is reported in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S3.F1" title="Figure 1 â€£ 3. Learned Causal Graph â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="298" id="S3.F1.g1" src="x1.png" width="332"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">Markov blanket of the feedback signals in the CG. Nodes are coloured by their semantics: users, items and context features are in blue, red and green, respectively.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The first natural questions that arise are: Is the learned CG correct? Why is it different from other models? The answer is closely linked to the primary purpose of causal models. Citing the words of <span class="ltx_text ltx_font_italic" id="S3.p2.1.1">Judea Pearl</span> <cite class="ltx_cite ltx_citemacro_citep">(Pearl, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib13" title="">2014</a>)</cite>: â€œThe purpose of the diagram is to provide an unambiguous description of the scientific context of a given applicationâ€. This <span class="ltx_text ltx_font_italic" id="S3.p2.1.2">unambiguous description</span> must not be taken as a dogma but should be used to build a â€œhypothetical consensus on what is plausible and important versus that which is deemed negligible or implausibleâ€ <cite class="ltx_cite ltx_citemacro_citep">(Pearl, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib13" title="">2014</a>)</cite>. This consensus, in the form of possible associations among measured and unmeasured variables, must be built through â€œ[â€¦] scientific considerations and debated by experts in the fieldâ€ <cite class="ltx_cite ltx_citemacro_citep">(Pearl, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib13" title="">2014</a>)</cite>. Indeed, the correctness of a CG can not be guaranteed by automatic tests/procedures but must be verified through the mix of domain knowledge and observations/experiments. However, this limitation should not be confused with a weakness w.r.t. other models, as no existing model can be guaranteed to be correct.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Nevertheless, unlike other models, experts can debate the cause-and-effect relations and dependencies/independencies embedded in a CG to build the <span class="ltx_text ltx_font_italic" id="S3.p3.1.1">hypothetical consensus</span> mentioned above. For example, according to the sub-CG in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#S3.F1" title="Figure 1 â€£ 3. Learned Causal Graph â€£ Causal Discovery in Recommender Systems: Example and Discussion"><span class="ltx_text ltx_ref_tag">1</span></a>, the only relevant itemsâ€™ features that influence the feedback the users give are the video duration and the upload type, while all the others are irrelevant. Therefore, following this model, our recommendations should consider only these two variables, disregarding all the others to avoid introducing noise in the decision and drastically reducing the amount of data required. Similarly, the analysed usersâ€™ features seem relevant only for the <span class="ltx_text ltx_font_italic" id="S3.p3.1.2">is_hate</span> feedback. However, in this case, we should note that the available features only describe the user on the platform, while the ones that identify a user are encrypted.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Conclusions</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This work focused on the causal discovery task of learning a CG by combining observational data from the KuaiRand open-source dataset with prior knowledge. The resulting CG contrasts the recent trend in Machine Learning and RSs to include more and more variables in larger and larger models. Indeed, the learned CG suggests that only a few variables effectively influence the analysed feedback signals. Therefore, all the others are irrelevant to our decisions and only contribute to noise. Moreover, more data is required as the number of variables (i.e., dimensions) increases. This finding can be supported by the fact that users (i.e., people) can not consider many factors when deciding, and their decisions are usually based on a few essential factors and subconscious emotional feelings <cite class="ltx_cite ltx_citemacro_citep">(Kahneman etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10271v1#bib.bib10" title="">2021</a>)</cite>. On the other hand, part of the effect of the recommended items is (usually) not captured by the available factors. Therefore, more emphasis should be placed on modelling the problem and collecting the necessary information to make informed decisions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cavenaghi etÂ al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Emanuele Cavenaghi, Alessio Zanga, A Rimoldi, P Minasi, F Stella, M Zanker, etÂ al<span class="ltx_text" id="bib.bib2.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Causal Discovery in Recommender Systems: a Case Study in Online Hotel Search.

</span>
<span class="ltx_bibblock">(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cavenaghi etÂ al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Emanuele Cavenaghi, Alessio Zanga, Fabio Stella, and Markus Zanker. 2024.

</span>
<span class="ltx_bibblock">Towards a Causal Decision-Making Framework for Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">ACM Trans. Recomm. Syst.</em> 2, 2, Article 17 (2024), 34Â pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2023.

</span>
<span class="ltx_bibblock">Bias and Debias in Recommender System: A Survey and Future Directions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">ACM Trans. Inf. Syst.</em> 41, 3, Article 67 (2023), 39Â pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chickering (1995)</span>
<span class="ltx_bibblock">
DavidÂ Maxwell Chickering. 1995.

</span>
<span class="ltx_bibblock">A transformational characterization of equivalent Bayesian network structures. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence</em> (MontrÃ©al, QuÃ©, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib5.2.2">(UAIâ€™95)</em>. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 87â€“98.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Chongming Gao, Shijun Li, Yuan Zhang, Jiawei Chen, Biao Li, Wenqiang Lei, Peng Jiang, and Xiangnan He. 2022a.

</span>
<span class="ltx_bibblock">KuaiRand: An Unbiased Sequential Recommendation Dataset with Randomly Exposed Videos. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proceedings of the 31st ACM International Conference on Information and Knowledge Management</em> (Atlanta, GA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib6.4.2">(CIKM â€™22)</em>. 3953â€“3957.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Chen Gao, Yu Zheng, Wenjie Wang, Fuli Feng, Xiangnan He, and Yong Li. 2022b.

</span>
<span class="ltx_bibblock">Causal Inference in Recommender Systems: A Survey and Future Directions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">arXiv preprint arXiv:2208.12397</em> 1 (2022), 29Â pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glymour etÂ al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Madelyn Glymour, Judea Pearl, and NicholasÂ P Jewell. 2016.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Causal inference in statistics: A primer</em>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, Hoboken, United States.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joachims etÂ al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017.

</span>
<span class="ltx_bibblock">Unbiased Learning-to-Rank with Biased Feedback. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</em> (Cambridge, United Kingdom) <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.2">(WSDM â€™17)</em>. Association for Computing Machinery, New York, NY, USA, 781â€“789.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kahneman etÂ al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Daniel Kahneman, Olivier Sibony, and CassÂ R Sunstein. 2021.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Noise: A flaw in human judgment</em>.

</span>
<span class="ltx_bibblock">Hachette UK.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pearl (1988)</span>
<span class="ltx_bibblock">
Judea Pearl. 1988.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Probabilistic reasoning in intelligent systems: networks of plausible inference</em>.

</span>
<span class="ltx_bibblock">Morgan kaufmann, Cambridge, Massachusetts, United States.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pearl (2009)</span>
<span class="ltx_bibblock">
Judea Pearl. 2009.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Causality</em>.

</span>
<span class="ltx_bibblock">Cambridge university press, Cambridge, United Kingdom.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pearl (2014)</span>
<span class="ltx_bibblock">
Judea Pearl. 2014.

</span>
<span class="ltx_bibblock">Interpretation and identification of causal mediation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Psychological methods</em> 19, 4 (2014), 459.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saito (2020)</span>
<span class="ltx_bibblock">
Yuta Saito. 2020.

</span>
<span class="ltx_bibblock">Doubly Robust Estimator for Ranking Metrics with Post-Click Conversions. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 14th ACM Conference on Recommender Systems</em> (Virtual Event, Brazil) <em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2">(RecSys â€™20)</em>. Association for Computing Machinery, New York, NY, USA, 92â€“100.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schnabel etÂ al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016.

</span>
<span class="ltx_bibblock">Recommendations as Treatments: Debiasing Learning and Evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of The 33rd International Conference on Machine Learning</em> <em class="ltx_emph ltx_font_italic" id="bib.bib15.4.2">(Proceedings of Machine Learning Research, Vol.Â 48)</em>, MariaÂ Florina Balcan and KilianÂ Q. Weinberger (Eds.). PMLR, New York, New York, USA, 1670â€“1679.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scutari etÂ al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Marco Scutari, Claudia Vitolo, and Allan Tucker. 2019.

</span>
<span class="ltx_bibblock">Learning Bayesian networks from big data with greedy search: computational complexity and efficient implementation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Statistics and Computing</em> 29 (2019), 1095â€“1108.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Wenjie Wang, Fuli Feng, Xiangnan He, Hanwang Zhang, and Tat-Seng Chua. 2021.

</span>
<span class="ltx_bibblock">Clicks Can Be Cheating: Counterfactual Recommendation for Mitigating Clickbait Issue. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Virtual Event, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib17.4.2">(SIGIR â€™21)</em>. Association for Computing Machinery, New York, NY, USA, 1288â€“1297.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016.

</span>
<span class="ltx_bibblock">Learning to Rank with Selection Bias in Personal Search. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Pisa, Italy) <em class="ltx_emph ltx_font_italic" id="bib.bib18.4.2">(SIGIR â€™16)</em>. Association for Computing Machinery, New York, NY, USA, 115â€“124.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Tianxin Wei, Fuli Feng, Jiawei Chen, Ziwei Wu, Jinfeng Yi, and Xiangnan He. 2021.

</span>
<span class="ltx_bibblock">Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and; Data Mining</em> (Virtual Event, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib19.4.2">(KDD â€™21)</em>. Association for Computing Machinery, New York, NY, USA, 1791â€“1800.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shuyuan Xu, Da Xu, Evren Korpeoglu, Sushant Kumar, Stephen Guo, Kannan Achan, and Yongfeng Zhang. 2022.

</span>
<span class="ltx_bibblock">Causal Structure Learning with Recommendation System.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">arXiv preprint arXiv:2210.10256</em> 1 (2022), 10Â pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Mengyue Yang, Quanyu Dai, Zhenhua Dong, Xu Chen, Xiuqiang He, and Jun Wang. 2021.

</span>
<span class="ltx_bibblock">Top-N Recommendation with Counterfactual User Preference Simulation. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em> (Virtual Event, Queensland, Australia) <em class="ltx_emph ltx_font_italic" id="bib.bib21.4.2">(CIKM â€™21)</em>. Association for Computing Machinery, New York, NY, USA, 2342â€“2351.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Full Learned Causal Graph</h2>
<figure class="ltx_figure" id="A1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="830" id="A1.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F2.2.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="A1.F2.3.2" style="font-size:90%;">Full SCM learned from data and expert knowledge.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep 16 13:22:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
