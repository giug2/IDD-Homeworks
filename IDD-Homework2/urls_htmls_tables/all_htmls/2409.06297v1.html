<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study</title>
<!--Generated on Tue Sep 10 07:44:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Large Language Models,  Recommender Systems,  Explainability,  GD6
" lang="en" name="keywords"/>
<base href="/html/2409.06297v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S1" title="In User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S2" title="In User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Technical Exploration and Implementation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S3" title="In User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">User-based evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S3.SS1" title="In III User-based evaluation ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Methodology</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S3.SS2" title="In III User-based evaluation ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Results</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S4" title="In User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Future Works</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1" title="In User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span> </span><span class="ltx_text ltx_font_italic">Authors’ Biographies</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS1" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>1 </span>Julien Albert</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS2" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>2 </span>Martin Balfroid</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS3" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>3 </span>Miriam Doh</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS4" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>4 </span>Jeremie Bogaert</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS5" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>5 </span>Luca La Fisca</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS6" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>6 </span>Liesbet De Vos</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS7" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>7 </span>Bryan Renard</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS8" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>8 </span>Vincent Stragier</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS1.SSS9" title="In -A Authors’ Biographies ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span>9 </span>Emmanuel Jean</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#A0.SS2" title="In User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-B</span> </span><span class="ltx_text ltx_font_italic">ARIAC and TRAIL</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Julien Albert
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">UNamur
<br class="ltx_break"/>julien.albert@unamur.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Martin Balfroid
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">UNamur
<br class="ltx_break"/>martin.balfroid@unamur.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Miriam Doh
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">ULB-UMONS
<br class="ltx_break"/>miriam.doh@ulb.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jeremie Bogaert


 <span class="ltx_text" id="id1.1.id1"></span><span class="ltx_text" id="id2.2.id2"></span> <span class="ltx_ERROR undefined" id="id3.3.id3">{@IEEEauthorhalign}</span>
Luca La Fisca
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">UCLouvain
<br class="ltx_break"/>jeremie.bogaert@uclouvain.be
</span>
<span class="ltx_contact ltx_role_affiliation">UMONS
<br class="ltx_break"/>luca.lafisca@umons.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liesbet De Vos
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">UNamur
<br class="ltx_break"/>liesbet.devos@unamur.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bryan Renard
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Multitel-UNamur
<br class="ltx_break"/>renard@multitel.be
<br class="ltx_break"/>bryan.renard@unamur.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vincent Stragier
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">UMONS
<br class="ltx_break"/>vincent.stragier@umons.ac.be
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Emmanuel Jean
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Multitel
<br class="ltx_break"/>jean@multitel.be
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">Recommender systems have become integral to our digital experiences, from online shopping to streaming platforms. Still, the rationale behind their suggestions often remains opaque to users. While some systems employ a graph-based approach, offering inherent explainability through paths associating recommended items and seed items, non-experts could not easily understand these explanations. A popular alternative is to convert graph-based explanations into textual ones using a template and an algorithm, which we denote here as “template-based” explanations. Yet, these can sometimes come across as impersonal or uninspiring. A novel method would be to employ large language models (LLMs) for this purpose, which we denote as “LLM-based”. To assess the effectiveness of LLMs in generating more resonant explanations, we conducted a pilot study with 25 participants. They were presented with three explanations: (1) traditional template-based, (2) LLM-based rephrasing of the template output, and (3) purely LLM-based explanations derived from the graph-based explanations. Although subject to high variance, preliminary findings suggest that LLM-based explanations may provide a richer and more engaging user experience, further aligning with user expectations. This study sheds light on the potential limitations of current explanation methods and offers promising directions for leveraging large language models to improve user satisfaction and trust in recommender systems.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Large Language Models, Recommender Systems, Explainability, GD6

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Most of us wonder daily why platforms like Facebook and YouTube recommend specific people or videos to us. The lack of transparency in these recommendations often leaves us without a clear explanation. This can degrade user confidence, recommendation acceptance and, more generally, the user experience <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib1" title="">1</a>]</cite>. To address those important concerns, a growing field of research focuses on making recommendation systems more transparent and explainable <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib3" title="">3</a>]</cite>. A promising approach is to use large language models (LLMs) to generate explanations<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In the context of this abstract, when we refer to the generation of LLMs-based recommendations explanations, we actually mean using an LLMs to rephrase an explanation or interpret a graph representation of an explainable recommendation.</span></span></span> for recommendations. LLMs are initially pre-trained on extensive corpora, allowing them to perform a versatile range of natural language processing (NLP) tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib4" title="">4</a>]</cite>. The generated text is typically well-written and clear, making it easy for humans to understand.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Motivated by these perspectives, we put them to the test in the generation of explanations for recommendations during the TRAIL’23 Workshop<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://trail.ac/en/trail-summer-workshops/the-trail-summer-workshop-2023/</span>, more details in the Appendix</span></span></span>. Concretely, we defined two goals to address during the workshop.
The first is implementing working examples of recommendation explanations generated with LLMs using various recommendation methods and LLM models. This way, we could assess the technical possibilities and limitations of LLMs.
The second goal is to evaluate explanations generated by different LLM models and recommendation methods to understand their qualities and their limitations in this context. To achieve this goal, we designed a user-based evaluation method to assess explanations w.r.t. different explanatory goals and subjective properties <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib1" title="">1</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Technical Exploration and Implementation</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S2.F1" title="Figure 1 ‣ II Technical Exploration and Implementation ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_tag">1</span></a>, we propose a pipeline that takes user preferences (i.e., past interactions with items) as input, and generates explained recommendations as output.
The most important design choice is to separate the recommendation and explanation processes, only using LLMs to explain items previously recommended by a standalone recommendation method.
We choose to use classic recommendation to ensure valid recommendation, as hallucination is an important issue with LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib5" title="">5</a>]</cite>. Moreover, this choice allows us to isolate the explanation task, empowering us to compare explanations created by a baseline explanation method, with explanations written by LLMs.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="314" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Pipeline used to guide our experiments. Methods and models used for the evaluation part are in fuchsia.</figcaption>
</figure>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Regarding the recommendation methods, we focused on graph-based methods. More specifically, we used <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">Personalized PageRank</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib6" title="">6</a>]</cite> and RippleNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib7" title="">7</a>]</cite>, both of which generate explanations based on a graph of the past interactions between users and items. This graph is augmented with knowledge about the movie domain, to further guide the recommendation system.
Those methods also provide explanations for recommendations in the form of paths from the seed items to the recommended ones. The datasets used for experimentation were Movielens-1M<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://grouplens.org/datasets/movielens/</span></span></span></span> and MindReader<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://mindreader.tech/dataset/</span></span></span></span>. For the user-based evaluation, we only used Movielens-1M in combination with the <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">Personalized PageRank</span>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">We are interested in textual explanations, since they convey rich information to the user <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib1" title="">1</a>]</cite>. The main existing approaches are template-based and generation-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib3" title="">3</a>]</cite>. As a baseline, we use a template-based approach, which transcripts path-based explanations into text. We compare this baseline method to LLM-based methods for generating explanations, inspired by the literature on the topic, e.g., PEPLER <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib8" title="">8</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Large Language Models (LLMs) are now some of the world’s most famous NLP models due to the publicity made by OpenAI with ChatGPT, which uses GPT-3.5-turbo and GPT-4 (SOTA). They can perform various NLP tasks. Current LLMs use a decoder-only architecture based on the transformer’s architecture<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib9" title="">9</a>]</cite>. They are trained to give a probability of distribution over the vocabulary of tokens, allowing to predict the next token.
The tokens are subparts of sentences, and the vocabulary of tokens, fixed and based on the training data, is often built using byte pair encoding (BPE)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib11" title="">11</a>]</cite>. To produce sequences of tokens, we used greedy decoding with Llama 2 70B Chat and the default technique (which we don’t know of) when using GPT-4. Greedy decoding only considers the most probable token at each generation step, which is time-efficient, unlike other techniques. We decided on using greedy decoding for our exploration study but plan to investigate other strategies in the future.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">We considered two methods for generating explanations for movie recommendations. We aimed to measure how effectively each approach could deliver concise yet informative explanations to users that align with their expectations.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="524" id="S2.F2.g1" src="x2.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of the three types of explanations compared in the user evaluation.</figcaption>
</figure>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Three types of explanations were finally chosen for the user-based evaluation (as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S2.F2" title="Figure 2 ‣ II Technical Exploration and Implementation ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_tag">2</span></a>):</p>
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Template-based</span>: our baseline method, which uses a template to generate explanations algorithmically based on the edges and nodes of the explanation paths;</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">LLM-based</span>: which uses LLMs to generate the explanation. We explored two variations:</p>
<ol class="ltx_enumerate" id="S2.I1.i2.I1">
<li class="ltx_item" id="S2.I1.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span>
<div class="ltx_para" id="S2.I1.i2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.I1.i1.p1.1.1">LLM-based rephrasing</span>: rephrase the template-based explanation;</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span>
<div class="ltx_para" id="S2.I1.i2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.I1.i2.p1.1.1">LLM-based graph-to-text</span>: the model deduces the reasoning behind the recommendation given a knowledge graph as context.</p>
</div>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Between the two LLM variants, only the context varies, either the template-based explanation or the graph. The definition of the task is, therefore, the same for both: to explain why a particular film has been recommended. To ensure a fairly consistent format across each generation, we constrained the LLM’s behaviour <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib12" title="">12</a>]</cite> by specifying that only one paragraph should be used and that it should be written in layman’s terms. Otherwise, the model tended to ramble and use technical terms that could confuse the user.</p>
</div>
<figure class="ltx_figure" id="S2.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="69" id="S2.F3.sf1.g1" src="x3.png" width="374"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>LLM-based rephrasing</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="159" id="S2.F3.sf2.g1" src="x4.png" width="374"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>LLM-based graph-to-text</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
Here is an example of the same recommendation presented in the same format as the prompt in Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib13" title="">13</a>]</cite>. <span class="ltx_text ltx_font_bold" id="S2.F3.4.1">Black</span>-colored text outlines the task, <span class="ltx_text ltx_font_bold" id="S2.F3.5.2" style="color:#C1272D;">red</span>-colored text highlights the formatting guidelines, and
<span class="ltx_text ltx_font_bold" id="S2.F3.6.3" style="color:#0000A7;">blue</span>-colored text is either the given template or the graph.
</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">User-based evaluation</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Methodology</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Part of our project’s goal was to perform a user-based evaluation of the three types of explanations generated by our pipeline. We drew inspiration from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib14" title="">14</a>]</cite> to craft the structure for our evaluation procedure (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S3.F4" title="Figure 4 ‣ III-A Methodology ‣ III User-based evaluation ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_tag">4</span></a>), albeit with slight modifications due to the inclusion of LLM-generated explanations. We decided to focus on the following key aspects:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Assessing user expectations of recommendation explanations using the seven goals from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib1" title="">1</a>]</cite>, also used by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib14" title="">14</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Presenting a recommended item to the user alongside multiple alternative explanations (based on a watching profile selected by the user beforehand).</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Requesting users to assess the explanations based on their general preference and measure the extent to which each explanation satisfies the seven goals.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1">Gathering qualitative insights via open question on user expectations and explanation assessments.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="455" id="S3.F4.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Structure of our user evaluation procedure</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Afterward, we conducted a dry run to validate the clarity of the questionnaire and assess its length to prevent evaluator fatigue. Subsequently, we rolled out the questionnaire to multiple evaluators to gather their responses.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Results</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We conducted 25 user tests with TRAIL’23 Workshop participants (researchers in AI). The small number of participants means that no statistically robust conclusions can be drawn, but certain trends can be observed.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Concerning the user’s expectations about explanations, we observe no difference in importance for the seven goals investigated. However, concerning user assessment of the generated explanations (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#S3.F5" title="Figure 5 ‣ III-B Results ‣ III User-based evaluation ‣ User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study"><span class="ltx_text ltx_ref_tag">5</span></a>), we observe that the explanation generated by the LLM from a knowledge graph performs best w.r.t. the 7 goals. And this result is confirmed by the participants’ general assessment of the explanations. According to the participants, this explanation type is mainly preferred because it’s often more detailed and more pleasant to read.
However, beyond the small sample size (<math alttext="n=25" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><eq id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></eq><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝑛</ci><cn id="S3.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">n=25</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_n = 25</annotation></semantics></math>), it is important to point out the significant variance in these last results. This indicates strong differences between participants in the way they perceive explanations, which is a result that should be investigated further.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="676" id="S3.F5.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>User assessment of explanations w.r.t. the 7 goals. about the recommendation explanations.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Moreover, we observed that LLMs often introduce additional details. Although most of them seem correct, they do not come from the knowledge graph and are therefore not verified. This may be due to the model’s ability to draw on cultural references <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib12" title="">12</a>]</cite>, in this case, movie titles. If this is undesirable, a workaround is to use numbered labels instead of movie titles. This will limit the model only to use in-context information.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Future Works</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In the future, we would like to explore various models. In particular, we would like to focus on smaller LLMs, to understand how model size affects efficiency. We expect that, due to their size, smaller models may struggle to generate explanations based on the knowledge graph, but may be sufficient for rephrasing the template-based explanations. This is particularly relevant considering the substantial computational requirements of larger LLMs. Furthermore, fine-tuning could be explored, as well as advanced prompting techniques like chain-of-thought <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib15" title="">15</a>]</cite> and self-consistency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib16" title="">16</a>]</cite> (which may appeal to users wanting more detailed reasoning). Another interesting approach might be to specify the explanation generation task by memetic proxy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib12" title="">12</a>]</cite>, i.e., to use the model’s ability to draw on cultural references, metaphors, analogies, role-playing, and so on.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Finally, instead of only relying on user-based evaluations, we aim to use mixed-methods evaluation to draw a complete picture of LLM’s explanation generation capabilities for recommendations. This evaluation would combine heuristics-based methods (based on classical metrics for text quality like BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib17" title="">17</a>]</cite> and ROUGE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib18" title="">18</a>]</cite> scores), explanation quality metrics (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib8" title="">8</a>]</cite>), and user-based methods. Such user-based methods could include qualitative (e.g., interviews) and quantitative (e.g., online survey) methods to assess explanations w.r.t. different explanatory goals and subjective properties <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.06297v1#bib.bib1" title="">1</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This research was partially supported by the ARIAC project (No. 2010235), funded by the Service Public de Wallonie (SPW Recherche).
This research used resources of the “Plateforme Technologique de Calcul Intensif (PTCI)” (http://www.ptci.unamur.be) located at the University of Namur, Belgium, which is supported by the FNRS-FRFC, the Walloon Region, and the University of Namur (Conventions No. 2.5020.11, GEQ U.G006.15, 1610468, RW/GEQ2016 et U.G011.22). The PTCI is member of the “Consortium des Équipements de Calcul Intensif (CÉCI)” (<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.ceci-hpc.be</span>).
Vincent Stragier is funded through a PhD grant from the Œuvre fédérale Les Amis des Aveugles et Malvoyants ASBL- The Friends of the Blind and Visually Impaired Federal Charity-, Ghlin, Belgium and the Loterie Nationale, Rue Belliard 25-33, 1040 Brussels, Belgium. Vincent Stragier is partially supported by the FNRS-FRS.
Bryan Renard is funded by the Public Service of Wallonia (Economy, Employment and Research), under the FoodWal agreement n°2210182 from the Win4Excellence project of the Wallonia Recovery Plan.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
N. Tintarev and J. Masthoff, “Explaining Recommendations: Design and Evaluation,” in <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Recommender Systems Handbook</span>, pp. 353–382, Boston, MA: Springer US, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Papadimitriou, P. Symeonidis, and Y. Manolopoulos, “A generalized taxonomy of explanations styles for traditional and social recommender systems,” <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Data Mining and Knowledge Discovery</span>, vol. 24, pp. 555–583, may 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y. Zhang and X. Chen, “Explainable Recommendation: A Survey and New Perspectives,” <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Foundations and Trends® in Information Retrieval</span>, vol. 14, no. 1, pp. 1–101, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">et al.</span>, “On the opportunities and risks of foundation models,” <span class="ltx_text ltx_font_italic" id="bib.bib4.2.2">arXiv e-prints</span>, pp. arXiv–2108, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang, A. Madotto, and P. Fung, “Survey of hallucination in natural language generation,” <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">ACM Comput. Surv.</span>, vol. 55, mar 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T. Haveliwala, “Topic-sensitive pagerank: a context-sensitive ranking algorithm for web search,” <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">IEEE Transactions on Knowledge and Data Engineering</span>, vol. 15, no. 4, pp. 784–796, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
H. Wang, F. Zhang, J. Wang, M. Zhao, W. Li, X. Xie, and M. Guo, “Ripplenet: Propagating user preferences on the knowledge graph for recommender systems,” in <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</span>, CIKM ’18, (New York, NY, USA), p. 417–426, Association for Computing Machinery, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
L. Li, Y. Zhang, and L. Chen, “Personalized Prompt Learning for Explainable Recommendation,” <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">ACM Transactions on Information Systems</span>, vol. 41, pp. 103:1–103:26, Mar. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Yang, H. Jin, R. Tang, X. Han, Q. Feng, H. Jiang, B. Yin, and X. Hu, “Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond,” Apr. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving Language Understanding by Generative Pre-Training,” 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou, H. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann, A. Korenev, P. S. Koura, M.-A. Lachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and T. Scialom, “Llama 2: Open Foundation and Fine-Tuned Chat Models,” July 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Reynolds and K. McDonell, “Prompt programming for large language models: Beyond the few-shot paradigm,” in <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–7, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Liu, C. Liu, R. Lv, K. Zhou, and Y. Zhang, “Is chatgpt a good recommender? a preliminary study,” <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2304.10149</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
K. Balog and F. Radlinski, “Measuring recommendation explanation quality: The conflicting goals of explanations,” in <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval</span>, pp. 329–338, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V. Le, D. Zhou, <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">et al.</span>, “Chain-of-thought prompting elicits reasoning in large language models,” in <span class="ltx_text ltx_font_italic" id="bib.bib15.2.2">Advances in Neural Information Processing Systems</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery, and D. Zhou, “Self-consistency improves chain of thought reasoning in language models,” <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2203.11171</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “Bleu: a method for automatic evaluation of machine translation,” in <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</span>, pp. 311–318, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C.-Y. Lin, “Rouge: A package for automatic evaluation of summaries,” in <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Text summarization branches out</span>, pp. 74–81, 2004.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_subsection" id="A0.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="A0.SS1.4.1.1">-A</span> </span><span class="ltx_text ltx_font_italic" id="A0.SS1.5.2">Authors’ Biographies</span>
</h3>
<section class="ltx_subsubsection" id="A0.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS1.4.1.1">-A</span>1 </span>Julien Albert</h4>
<div class="ltx_para" id="A0.SS1.SSS1.p1">
<p class="ltx_p" id="A0.SS1.SSS1.p1.1">After an initial career as a librarian, Julien Albert embarked on a career change and obtained a master’s degree in computer science from UNamur in 2020. He then worked for one year at UNamur on the EFFaTA-MeM research project, which aims to develop innovative tools for text analysis. In September 2021, he began a Ph.D. in computer science at UNamur under the supervision of Professors Benoît Frenay and Bruno Dumas. His research area is explainability in artificial intelligence. His approach involves placing the user at the centre of concerns by combining explainability techniques from machine learning with methods developed in human-computer interaction.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS2.4.1.1">-A</span>2 </span>Martin Balfroid</h4>
<div class="ltx_para" id="A0.SS1.SSS2.p1">
<p class="ltx_p" id="A0.SS1.SSS2.p1.1">Martin Balfroid is a PhD student at the University of Namur, his research investigates AI-in-the-loop approaches to improve software engineering. He earned his master’s in Computer Science, focusing on Data Science, in June 2022. The results of his master’s thesis were published at the 2nd Software Testing Education Workshop. Martin began his PhD in July 2022 with funding from the ARIAC project and is supervised by Assistant Professors Benoît Vanderose and Xavier Devroey.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS3.4.1.1">-A</span>3 </span>Miriam Doh</h4>
<div class="ltx_para" id="A0.SS1.SSS3.p1">
<p class="ltx_p" id="A0.SS1.SSS3.p1.1">Miriam Doh obtained a master’s degree in Information and Communication Engineering from the University of Trento (UniTn) in Italy in 2021. Her master’s thesis focused on the application of genetic algorithms to social networks, with a focus on studying the problem of community segregation in metropolitan areas. After completing her degree, she began a joint PhD program between ULB and UMONS on the intersection of Deep Learning and Computer Vision, with a particular emphasis on Explainable AI (XAI). Her research project is dedicated to exploring the integration of Cognitive Psychology principles to advance Explainable and Trustworthy Artificial Intelligence, particularly within the context of Face Analysis applications.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS4.4.1.1">-A</span>4 </span>Jeremie Bogaert</h4>
<div class="ltx_para" id="A0.SS1.SSS4.p1">
<p class="ltx_p" id="A0.SS1.SSS4.p1.1">Jérémie Bogaert obtained his master’s degree in computer science engineering with a focus on artificial intelligence from UCLouvain in 2021. His master’s thesis explored the limitations of deep fake news generation models and their detection using machine learning models and human readers. He started his doctoral thesis at UCLouvain in September 2021 and is currently working on the interaction between interpretable machine learning models and human readers for the detection of deep fake news. He has interest in studying the explainability of NLP models in general.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS5.4.1.1">-A</span>5 </span>Luca La Fisca</h4>
<div class="ltx_para" id="A0.SS1.SSS5.p1">
<p class="ltx_p" id="A0.SS1.SSS5.p1.1">Luca La Fisca is currently a PhD student with a keen interest in neural engineering. His primary research focus revolves around advancing tools for a deeper understanding of the intricacies of the human brain. Luca’s doctoral thesis specifically delves into the realm of ElectroEncephalogram (EEG) analysis. He is particularly fascinated by the interpretation of latent space to unveil critical interactions among brain regions during the execution of specific tasks, with a primary emphasis on visual tasks. Additionally, Luca harbours a strong interest in the field of neurofeedback.</p>
</div>
<div class="ltx_para" id="A0.SS1.SSS5.p2">
<p class="ltx_p" id="A0.SS1.SSS5.p2.1">Within the ARIAC project, Luca La Fisca is actively involved in Work Package 1, which centres on the interactions between humans and artificial intelligence. His contributions span various aspects, including interactive and human-in-the-loop algorithms, user assistance in AI-in-the-loop scenarios, consensus mechanisms, handling imperfect multi-expert labels, and the development of explainable AI solutions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS6">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS6.4.1.1">-A</span>6 </span>Liesbet De Vos</h4>
<div class="ltx_para" id="A0.SS1.SSS6.p1">
<p class="ltx_p" id="A0.SS1.SSS6.p1.1">Liesbet De Vos obtained a master’s in Linguistics at the Catholic University of Leuven in 2021. Fascinated by computational linguistics, she completed her studies with an advanced master’s in Artificial Intelligence at the Catholic University of Leuven, which she completed in 2022. Liesbet continues to nurture her passion for language during a PhD at the University of Namur, where she focuses on building hybrid AI systems that learn to use language through the same mechanisms as humans. In her thesis, she aims to extend the computational construction grammar framework to the visual modality so that it can adequately represent and learn the linguistic structure of sign languages. Within the ARIAC project, Liesbet actively contributes to Work Package 2, which revolves around trust mechanisms for artificial intelligence.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS7">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS7.4.1.1">-A</span>7 </span>Bryan Renard</h4>
<div class="ltx_para" id="A0.SS1.SSS7.p1">
<p class="ltx_p" id="A0.SS1.SSS7.p1.1">Bryan Renard obtained a master’s degree in theoretical physics from UNamur in 2022. He then changed his career path and is now a dedicated PhD student whose research interests span several exciting domains within the field of artificial intelligence. His primary focus is the application of artificial intelligence in the realm of proteins, exploring innovative ways to harness AI (especially LLMs) for protein-related research. Additionally, Bryan is passionate about self-supervised learning, particularly in the context of Automatic Speech Recognition (ASR).</p>
</div>
<div class="ltx_para" id="A0.SS1.SSS7.p2">
<p class="ltx_p" id="A0.SS1.SSS7.p2.1">His thesis is jointly conducted by UNamur and Multitel. It is funded by the FoodWal portfolio from the Public Service of Wallonia (Economy, Employment, and Research), more particularly within the PEPTIBoost project. As a part of the ARIAC project, Bryan Renard plays an integral role in Work Package 4, which revolves around optimizing AI implementations. His contributions encompass a wide range of topics, including transfer learning, High-Performance Computing (HPC) and self-supervised learning techniques.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS8">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS8.4.1.1">-A</span>8 </span>Vincent Stragier</h4>
<div class="ltx_para" id="A0.SS1.SSS8.p1">
<p class="ltx_p" id="A0.SS1.SSS8.p1.1">Vincent Stragier is a PhD student at the University of Mons (UMONS). He is working on an interactive assistant for visually impaired and blind people within the ISIA Lab, a department of the Faculty of Engineering. His research interests are mainly focused on NLP, large language models and computer vision related topics.</p>
</div>
<div class="ltx_para" id="A0.SS1.SSS8.p2">
<p class="ltx_p" id="A0.SS1.SSS8.p2.1">In 2021, he obtains his master’s degree in electrical Engineering, specialized in Signals, Systems and BioEngineering from the Faculty of Engineering in Mons. In 2020, he works on an epilepsy detection pipeline base on an XGBoost classifier built by the CETIC, where he is Engineer Intern at the time. During his studies, he participates in the electronic student association, electroLAB, and the Erasmus Student Network of Mons, ESNMons. In his free time, he likes taking photographs, fixing various things (hardware and software related), and learning new skills.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS1.SSS9">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS1.SSS9.4.1.1">-A</span>9 </span>Emmanuel Jean</h4>
<div class="ltx_para" id="A0.SS1.SSS9.p1">
<p class="ltx_p" id="A0.SS1.SSS9.p1.1">In 2009, Emmanuel Jean earned a dual degree in electrical engineering from the Faculty of Engineering at the University of Mons and Supelec-Paris. Subsequently, he joined the Signal Processing and Embedded Systems department at Multitel, where he actively participated in various regional and European projects involving vocal technologies and multimodal Human-Computer Interaction (HCI).</p>
</div>
<div class="ltx_para" id="A0.SS1.SSS9.p2">
<p class="ltx_p" id="A0.SS1.SSS9.p2.1">In 2012, he furthered his education by obtaining a Bachelor’s degree in Management Sciences from the Louvain School of Management at UCL-Mons. Since 2017, his professional focus has shifted towards diverse projects centred around Deep Learning applied to temporal signals, including audio, speech, and vibrations. His current research interests revolve around the development of weakly supervised machine learning techniques and the deployment of reliable artificial intelligence systems.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A0.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="A0.SS2.4.1.1">-B</span> </span><span class="ltx_text ltx_font_italic" id="A0.SS2.5.2">ARIAC and TRAIL</span>
</h3>
<div class="ltx_para" id="A0.SS2.p1">
<p class="ltx_p" id="A0.SS2.p1.1">TRAIL and the ARIAC research project are part of the regional DigitalWallonia4.ai program, which aims to accelerate the development of artificial intelligence technologies in Wallonia.</p>
</div>
<div class="ltx_para" id="A0.SS2.p2">
<p class="ltx_p" id="A0.SS2.p2.1">TRAIL (TRusted AI Labs) provides actors in the socio-economic landscape with R&amp;D expertise and AI technological bricks developed by the 5 French-speaking universities and 4 approved research centres active in AI. To achieve this, the SPW-EER has allocated a budget of €32 million for the ARIAC research project led by the TRAIL consortium. This initiative is part of the 4th axis of the regional DigitalWallonia4.ai programme: “Research, innovation and partnerships”.</p>
</div>
<div class="ltx_para" id="A0.SS2.p3">
<p class="ltx_p" id="A0.SS2.p3.1">The ambition is to pool research in artificial intelligence in the Wallonia-Brussels Federation and is concretely reflected through the research project “ARIAC by DigitalWallonia4.ai”, based on an agreement between the Walloon Region (SPW Research) and the actors forming the TRAIL consortium.</p>
</div>
<div class="ltx_para" id="A0.SS2.p4">
<p class="ltx_p" id="A0.SS2.p4.1">The ARIAC project (“Applications and Research for Trusted Artificial Intelligence” in English or “Applications et Recherche pour une Intelligence Artificielle de Confiance” in French) is spread over 6 years and is articulated around 5 WP (Work Package):</p>
</div>
<div class="ltx_para" id="A0.SS2.p5">
<ul class="ltx_itemize" id="A0.I1">
<li class="ltx_item" id="A0.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A0.I1.i1.p1">
<p class="ltx_p" id="A0.I1.i1.p1.1">human-AI interaction,</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A0.I1.i2.p1">
<p class="ltx_p" id="A0.I1.i2.p1.1">trust mechanisms for AI,</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A0.I1.i3.p1">
<p class="ltx_p" id="A0.I1.i3.p1.1">model-AI integration,</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A0.I1.i4.p1">
<p class="ltx_p" id="A0.I1.i4.p1.1">optimized implementations of AI,</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A0.I1.i5.p1">
<p class="ltx_p" id="A0.I1.i5.p1.1">TRAIL Factory.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 10 07:44:16 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
