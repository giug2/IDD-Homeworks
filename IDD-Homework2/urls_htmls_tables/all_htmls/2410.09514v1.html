<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Eco-Aware Graph Neural Networks for Sustainable Recommendations</title>
<!--Generated on Sat Oct 12 12:22:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Graph Neural Networks Recommendation Systems Environmental Impact." lang="en" name="keywords"/>
<base href="/html/2410.09514v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S1" title="In Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S2" title="In Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S3" title="In Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S3.SS1" title="In 3 Method ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Calculating CO<sub class="ltx_sub">2</sub> Emissions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S3.SS2" title="In 3 Method ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S3.SS3" title="In 3 Method ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Experimental Pipeline</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4" title="In Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4.SS1" title="In 4 Experiments ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4.SS2" title="In 4 Experiments ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4.SS3" title="In 4 Experiments ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Reproducibility</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4.SS4" title="In 4 Experiments ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Hardware</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S5" title="In Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S5.SS1" title="In 5 Results ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>RQ1: Which model excels, and at what cost?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S5.SS2" title="In 5 Results ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Embedding Size and Environmental Impact</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S6" title="In Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Sapienza University of Rome, Rome, Italy 
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{purificato, fsilvestri}@diag.uniroma1.it</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Eco-Aware Graph Neural Networks for Sustainable Recommendations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Antonio Purificato <span class="ltx_ERROR undefined" id="id1.1.id1">\orcidlink</span>0009-0009-3933-380X
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabrizio Silvestri <span class="ltx_ERROR undefined" id="id2.1.id1">\orcidlink</span>0000-0001-7669-9055
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Recommender systems play a crucial role in alleviating information overload by providing personalized recommendations tailored to users’ preferences and interests. Recently, Graph Neural Networks (GNNs) have emerged as a promising approach for recommender systems, leveraging their ability to effectively capture complex relationships and dependencies between users and items by representing them as nodes in a graph structure.</p>
<p class="ltx_p" id="id4.id2">In this study, we investigate the environmental impact of GNN-based recommender systems, an aspect that has been largely overlooked in the literature. Specifically, we conduct a comprehensive analysis of the carbon emissions associated with training and deploying GNN models for recommendation tasks. We evaluate the energy consumption and carbon footprint of different GNN architectures and configurations, considering factors such as model complexity, training duration, hardware specifications and embedding size.</p>
<p class="ltx_p" id="id5.id3">By addressing the environmental impact of resource-intensive algorithms in recommender systems, this study contributes to the ongoing efforts towards sustainable and responsible artificial intelligence, promoting the development of eco-friendly recommendation technologies that balance performance and environmental considerations. Code is available at:
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/antoniopurificato/gnn_recommendation_and_environment" title="">https://github.com/antoniopurificato/gnn_recommendation_and_environment</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Graph Neural Networks Recommendation Systems Environmental Impact.
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender systems (RSs) play a crucial role in mitigating information overload by providing personalized recommendations, benefiting users and service providers across various platforms, including e-commerce (e.g., Tmall, Amazon) <cite class="ltx_cite ltx_citemacro_citep">(Ge et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib9" title="">2020</a>)</cite> and social networks (e.g., Gowalla, Facebook) <cite class="ltx_cite ltx_citemacro_citep">(Peng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib19" title="">2020</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib29" title="">2016</a>)</cite>. Different approaches have been proposed, ranging from collaborative filtering techniques that leverage user-item interactions to content-based methods that analyze item features <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib7" title="">2018</a>)</cite> to sequential recommendation, aiming to capture the sequential patterns in user behavior and provide recommendations based on the current context or session <cite class="ltx_cite ltx_citemacro_citep">(Betello et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib5" title="">2024b</a>; Bacciu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib2" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In addition to sequential recommendation, Graph Neural Networks (GNNs) have emerged as a promising approach for recommender systems <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib15" title="">2024</a>; Mancino et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib16" title="">2023</a>)</cite>. GNNs can effectively capture the complex relationships and dependencies between users and items by representing them as nodes in a graph structure. By propagating and aggregating information along the edges of the graph, GNNs can learn rich representations that encode high-order connectivity patterns, leading to improved recommendation performance <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib26" title="">2022</a>)</cite>. Furthermore, GNNs can naturally incorporate various types of auxiliary information, such as user profiles, item attributes, and social connections, into the graph structure, enabling the exploitation of heterogeneous data sources for more accurate recommendations <cite class="ltx_cite ltx_citemacro_citep">(Purificato et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib20" title="">2024</a>)</cite>. Nowadays, resource-intensive algorithms have become prevalent in modern recommender systems, resulting in higher energy consumption for recommendation experiments <cite class="ltx_cite ltx_citemacro_citep">(Betello et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib4" title="">2024a</a>)</cite>. However, despite some studies having been carried out in regarding the environmental impact of SRSs <cite class="ltx_cite ltx_citemacro_citep">(Betello et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib4" title="">2024a</a>; Spillo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib22" title="">2023</a>)</cite>, only one work presented an analysis of the computational consumption of GNN-based RSs <cite class="ltx_cite ltx_citemacro_cite">Spillo et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib22" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we analyse the environmental impact of GNN-based RSs experiments by faithfully replicating representative experimental pipelines. Through a comprehensive comparative analysis, we shed light on the carbon emissions attributable to the training and deployment of GNN-based RSs. Our study serves as a clarion call for sustainability, underscoring the need to reconcile the pursuit of technological advancements with environmental consciousness within the realm of RSs. This study aims to answer to the following research questions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">RQ1</span>: Which model performs the best, and what are the trade-offs in terms of resource consumption?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">RQ2</span>: How does the embedding size of the GNN affect the environmental impact of the results?</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In the Glasgow Agreement <cite class="ltx_cite ltx_citemacro_citep">(Hunter et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib12" title="">2021</a>)</cite>, participating nations committed to reducing CO<sub class="ltx_sub" id="S2.p1.1.1">2</sub> emissions, underscoring the urgent need for environmental action. This commitment is particularly relevant to our field, as the environmental impact of GPU training in machine learning is significant. The energy consumption associated with these computational processes contributes significantly to CO<sub class="ltx_sub" id="S2.p1.1.2">2</sub> emissions, exacerbating climate change <cite class="ltx_cite ltx_citemacro_citep">(Patterson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib18" title="">2021</a>)</cite>. It is therefore our responsibility to raise awareness of this issue.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Although the environmental impact of deep learning algorithms has been investigated in certain domains, such as Natural Language Processing <cite class="ltx_cite ltx_citemacro_citep">(Bender et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib3" title="">2021</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib25" title="">2023</a>)</cite> and Information Retrieval <cite class="ltx_cite ltx_citemacro_citep">(Scells et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib21" title="">2022</a>)</cite>, there is a dearth of research examining the environmental footprint of Recommender Systems.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><cite class="ltx_cite ltx_citemacro_cite">Spillo et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib22" title="">2023</a>)</cite> benchmark several state-of-the-art recommendation algorithms
in terms of both recommendation performance and carbon emissions and analyze the trade-off between energy consumption, carbon emissions and the predictive accuracy of recommendation
algorithms. A difference with respect to our approach is that they do not study the impact of some important factors on the performance and on the emissions, such as the embedding size of each model.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><cite class="ltx_cite ltx_citemacro_cite">Betello et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib4" title="">2024a</a>)</cite> provide a code resource and a robust framework for developing RSs and establishing a foundation for consistent and reproducible experimentation. They also study how the number of parameters influences the CO<sub class="ltx_sub" id="S2.p4.1.1">2</sub> consumption of the proposed algorithms. Differently from our work, they do not consider GNN-based approaches, but only sequential recommendation algorithms. While their research aims to provide a reproducibility analysis with an associated framework, the objective of our work is to highlight the significance of implementing environmentally sustainable solutions for recommendation tasks.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">In the next Section we present our methodological approach to assess the environmental impact of recommender systems.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Calculating CO<sub class="ltx_sub" id="S3.SS1.1.1">2</sub> Emissions</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In this study, we use CodeCarbon<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://codecarbon.io" title="">https://codecarbon.io</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Courty et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib8" title="">2023</a>)</cite>, a tool designed to track the power consumption of both CPUs and GPUs. This allows us to measure carbon dioxide equivalent (CO<sub class="ltx_sub" id="S3.SS1.p1.1.1">2</sub>-eq), a widely accepted standard used by numerous organisations and governments to monitor emissions of various greenhouse gases <cite class="ltx_cite ltx_citemacro_citep">(Kim and Neff, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib14" title="">2009</a>)</cite>. CO<sub class="ltx_sub" id="S3.SS1.p1.1.2">2</sub>-eq facilitates the comparison of greenhouse gas emissions by converting quantities of different gases into an equivalent amount of CO<sub class="ltx_sub" id="S3.SS1.p1.1.3">2</sub>, based on their respective global warming potentials. By using CodeCarbon, we can accurately assess the environmental impact of our training processes, in line with our commitment to sustainability and responsible research practices in machine learning.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.4">Our decision to focus specifically on CO<sub class="ltx_sub" id="S3.SS1.p2.4.1">2</sub>-eq emissions is motivated by several factors. First, CO<sub class="ltx_sub" id="S3.SS1.p2.4.2">2</sub>-eq is a widely recognized and accepted metric for quantifying the combined impact of various greenhouse gases on global warming, allowing us to provide a standardized and comparable measure of the overall environmental impact <cite class="ltx_cite ltx_citemacro_cite">Betello et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib4" title="">2024a</a>); Spillo et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib22" title="">2023</a>)</cite>. Second, CO<sub class="ltx_sub" id="S3.SS1.p2.4.3">2</sub> emissions are particularly relevant in the context of energy-intensive machine learning training processes, which typically rely on electricity generated from fossil fuel sources. Tracking CO<sub class="ltx_sub" id="S3.SS1.p2.4.4">2</sub>-eq emissions allows us to directly assess the carbon footprint associated with the energy consumption of our experiments.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Models</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The Neural Graph Collaborative Filtering (NGCF) model <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib24" title="">2019</a>)</cite> represents user-item interactions as a bipartite graph and learns user and item embeddings by propagating them on the graph through message passing layers. The key idea is to capture high-order connectivity patterns by recursively propagating embeddings over the graph using graph convolutional layers. NGCF is trained end-to-end to minimize the difference between predicted and actual user-item interactions. It exploits high-order connectivity, learning non-linear relationships, and providing inductive capabilities for new users or items.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">LightGCN <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib11" title="">2020</a>)</cite> learns user and item embeddings by propagating them on the user-item interaction graph through a series of graph convolutional layers. Unlike NGCF, LightGCN removes the feature transformation and nonlinear activation layers, making it a linear model. The key idea is to simplify the GCN architecture while preserving the ability to capture high-order connectivity patterns between users and items. LightGCN is trained end-to-end to optimize the BCE between the predicted and actual user-item interactions. It has demonstrated competitive performance while being computationally efficient.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">SimGCL <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib28" title="">2022</a>)</cite> add random uniform noise
to hidden representations for augmentations, resulting in more
uniform node representations that mitigate the popularity bias. Adjusting the noise magnitude can improve regulation of representation uniformity, leading to advantages on recommendation accuracy and model training efficiency.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">In LightGCL <cite class="ltx_cite ltx_citemacro_citep">(Cai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib6" title="">2023</a>)</cite>, the graph augmentation is guided by singular value decomposition (SVD) to not only distill the useful information of user-item interactions but also inject the global collaborative context
into the representation alignment of contrastive learning. Instead of generating two handcrafted
augmented views, important semantic of user-item interactions can be preserved with their paradigm. This enables self-augmented representations to be reflective of both user-specific preferences and cross-user global dependencies.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Experimental Pipeline</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To evaluate the impact of different embedding sizes on the model’s performance and computational requirements, experiments with embedding sizes of 32, 64, 128, and 256 are conducted. The results of these experiments are presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S5" title="5 Results ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_tag">5</span></a>. Prior to commencing the training process, we initialize a CodeCarbon tracker to monitor the carbon emissions associated with the training process. Additionally, we utilize the DeepSpeed<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.deepspeed.ai" title="">https://www.deepspeed.ai</a></span></span></span> library to compute the number of floating-point operations (FLOPs) required for each model configuration.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">During the training process, the CodeCarbon library is used to log the power consumption every 30 seconds, allowing us to track the energy consumption in real-time. Upon completion of the training, we compute the total carbon emissions and various performance metrics, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4" title="4 Experiments ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">In the next Section we will presents the experimental setup and describe the different metrics and datasets used in the experiments.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our analyses encompass a collection of datasets, ensuring comprehensive and robust insights. By incorporating datasets with diverse characteristics, such as varying user and item counts, we aim to unravel the intricate interplay between these factors and our findings. This approach enables us to capture a view of real-world scenarios, thereby fortifying the applicability of our conclusions across a broad spectrum of contexts. All the statistics of these datasets are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S4.T1" title="Table 1 ‣ 4.1 Datasets ‣ 4 Experiments ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">MovieLens<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://grouplens.org/datasets/movielens" title="">https://grouplens.org/datasets/movielens</a></span></span></span>: The MovieLens dataset <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib10" title="">2015</a>)</cite> is widely recognized as a benchmark for evaluating recommendation algorithms. We utilize MovieLens 1M (ML-1M).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Amazon: These datasets consist of product reviews collected from Amazon.com <cite class="ltx_cite ltx_citemacro_citep">(McAuley et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib17" title="">2015</a>)</cite>. The data are organized into distinct datasets based on Amazon’s primary product categories. For our study, we focus on the “Beauty” category (Beauty).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">DianPing: This dataset contains the user reviews as well as the detailed business meta data information crawled from a famous Chinese online review website<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="DianPing.com" title="">DianPing.com</a></span></span></span>.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Our data preprocessing pipeline adheres to well-established practices in the field. We adopt an implicit approach, treating all interactions as binary events without considering rating values, as done in <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib13" title="">2018</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib23" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">For dataset partitioning, we employ a widely-used strategy in sequential recommendation tasks <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib23" title="">2019</a>; Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib13" title="">2018</a>)</cite>. The most recent interaction for each user is held out for testing, while the second-to-last interaction is reserved for validation. The remaining interactions constitute the training set, providing a chronological sequence of user behavior.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S4.T1.3.2" style="font-size:90%;">Dataset statistics after pre-processing. Density and sparsity are percentage values.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S4.T1.4.1.1.1">Dataset name</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.2">Users</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.3">Items</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T1.4.1.1.4">Interactions</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.5">Density</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.6">Sparsity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T1.4.2.1.1">Amazon Beauty</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.2">1,210,271</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.3">249,274</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.2.1.4">2,023,070</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.5">0.001</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.6">99.999</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T1.4.3.2.1">MovieLens 1M</th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.2">6,040</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.3">3,952</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.3.2.4">999,611</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.5">4.189</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.6">95.810</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S4.T1.4.4.3.1">DianPing</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.3.2">542,706</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.3.3">243,247</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.3.4">4,422,473</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.3.5">0.003</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.3.6">99.997</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Metrics</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To evaluate the performance of sequential recommendation algorithms, we employed four widely adopted metrics commonly used in Information Retrieval (IR) <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib13" title="">2018</a>; Purificato et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib20" title="">2024</a>)</cite>: Precision, Recall, Normalized Discounted Cumulative Gain (NDCG), and Hit Ratio (HIT). These metrics provide a comprehensive assessment of the recommendation system’s ability to identify relevant items and rank them effectively.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">Precision: This metric calculates the proportion of correctly identified relevant items among the recommended items. It measures the system’s ability to avoid irrelevant recommendations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">Recall: It quantifies the fraction of correctly identified relevant items among the recommendations relative to the total number of relevant items in the dataset. This metric evaluates the system’s capability to retrieve as many relevant items as possible.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">Normalized Discounted Cumulative Gain (NDCG): This metric evaluates the performance of a ranking system by considering the position of relevant items in the ranked list. It assigns higher scores to relevant items ranked higher, as they are typically where a user’s attention is focused. NDCG captures the importance of ranking relevant items at the top of the recommendation list.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1">Hit Ratio (HIT): Is a key metric in recommendation systems that measures whether relevant items appear within the top K positions of a model’s recommendation list. For each user, if at least one relevant item is included in the top K recommendations, it counts as a "hit." The HIT@K score is then calculated as the proportion of users for whom the model successfully includes at least one relevant item within the top K.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.2">Emissions: Represents the CO<sub class="ltx_sub" id="S4.I2.i5.p1.2.1">2</sub>-eq (measured in Kg) required for training a single model and is the sum of the single CO<sub class="ltx_sub" id="S4.I2.i5.p1.2.2">2</sub>-eq emissions over each epoch.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS2.p2.1">By employing these four metrics, we can comprehensively assess the recommendation system’s ability to identify relevant items, rank them effectively, and provide high-quality recommendations tailored to the user’s preferences and interests.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Reproducibility</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In order to facilitate a rigorous and unbiased comparison, a standardized experimental setup was adopted for all models. The training regime consisted of 400 epochs, with batch sizes of 2048 and 4096 for the training and validation stages, respectively. The optimization was carried out using the Adam algorithm, with a learning rate fixed at 0.001. Furthermore, to mitigate the effects of random initialization and promote reproducibility, an identical seed was employed across all experiments. In order to see how all the experiments evolve over time, no early stopping procedures were applied.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Hardware</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">All experiments were performed on a single NVIDIA RTX A6000 with 10752 CUDA cores and 48 GB of RAM. The code is written in Python 3 and to train all the models it was used the RecBole library<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://recbole.io/" title="">https://recbole.io/</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib27" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">In the next Section we will present the results of the proposed study, in terms of performance metrics and environmental impact.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>RQ1: Which model excels, and at what cost?</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S5.T2" title="Table 2 ‣ 5.1 RQ1: Which model excels, and at what cost? ‣ 5 Results ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a>, LightGCN outperforms all competitors across all datasets, with the most significant lead observed on the Beauty dataset, while the gap narrows on the ML-1M dataset. LightGCN’s superior performance can be attributed to two key factors: firstly, it is an advancement over NGCF, with its advantages clearly demonstrated in prior experiments <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#bib.bib11" title="">2020</a>)</cite>. Secondly, both LightGCL and SimGCL, although promising, involve higher computational complexity, and 400 epochs may not suffice for them to converge to optimal results. In terms of carbon emissions, NGCF remains the most efficient on two out of the three datasets—a somewhat unexpected outcome, given that LightGCN is touted by its authors as being more lightweight than NGCF. The best trade-off in terms of performance-emission will probably remain LightGCN, which is the second-best model in terms of environmental impact on two of the three datasets.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.8" style="width:433.6pt;height:183.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-59.7pt,25.2pt) scale(0.784220093325263,0.784220093325263) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.8.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.8.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.8.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.2.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.3.1">P@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.4.1">R@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.5.1">NDCG@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.8.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.6.1">HIT@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.7.1">P@100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.8.1">R@100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.9.1">NDCG@100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.8.1.1.1.10"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.10.1">HIT@100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.8.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.1.1.11.1">Emissions</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.8.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.1" rowspan="4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.2.1.1.1">Beauty</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.2.1.2.1">LightGCL</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.3.1">.0019</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.4.1">.0185</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.5.1">.0107</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.2.1.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.6.1">.0187</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.7.1">.0005</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.8.1">.0517</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.9.1">.0190</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.2.1.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.2.1.10.1">.0591</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.2.1.11">12.5521</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.1.1">LightGCN</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.2.1">.0022</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.3.1">.0212</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.4.1">.0121</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.3.2.5"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.5.1">.0217</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.6"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.6.1">.0006</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.7"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.7.1">.0583</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.8"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.8.1">.0195</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.3.2.9"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.3.2.9.1">.0594</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.3.2.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.3.2.10.1">4.1341</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.4.3.1.1">NGCF</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.2">.0017</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.3">.0160</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.4">.0087</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.4.3.5">.0164</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.6">.0005</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.7">.0508</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.8">.0156</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.4.3.9">.0519</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.4.3.10"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.4.3.10.1">1.1147</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.5.4.1.1">SimGCL</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.2">.0004</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.3">.0039</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.4">.0019</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.5.4.5">.0039</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.6">.0002</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.7">.0227</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.8">.0054</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.5.4.9">.0230</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.5.4.10">12.9475</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.6.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.1" rowspan="4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.6.5.1.1">DianPing</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.6.5.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.6.5.2.1">LightGCL</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.3.1">.0044</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.4.1">.0239</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.5.1">.0221</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.6.5.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.6.1">.0499</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.7.1">.0018</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.8.1">.1673</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.9.1">.0393</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.6.5.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.10.1">.1734</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.6.5.11">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.6.5.11.1">15.011</span>1</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.7.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.7.6.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.1.1">LightGCN</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.2.1">.0053</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.3"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.3.1">.0417</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.4.1">.0223</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.7.6.5"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.5.1">.0518</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.6"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.6.1">.0023</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.7"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.7.1">.1680</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.8"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.8.1">.0482</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.7.6.9"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.9.1">.2031</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.7.6.10"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.7.6.10.1">13.4835</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.8.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.8.7.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.8.7.1.1">NGCF</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.2">.0032</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.3">.0235</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.4">.0123</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.8.7.5">.0313</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.6">.0017</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.7">.1205</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.8">.0320</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.8.7.9">.1523</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.8.7.10">27.3234</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.9.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.9.8.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.9.8.1.1">SimGCL</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.2">.0040</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.3">.0238</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.4">.0101</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.9.8.5">.0474</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.6">.0016</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.7">.1435</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.8">.0347</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.9.8.9">.1600</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.9.8.10">21.2422</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.10.9">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.8.1.10.9.1" rowspan="4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.10.9.1.1">ML-1M</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.10.9.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.10.9.2.1">LightGCL</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.3">.1986</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.4">.1591</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.5">.2546</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.10.9.6">.7341</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.7">.0761</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.8">.5231</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.9">.3366</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.1.10.9.10">.9538</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.1.10.9.11"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.10.9.11.1">0.1185</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.11.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.11.10.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.1.1">LightGCN</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.2"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.2.1">.2094</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.3"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.3.1">.1731</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.4"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.4.1">.2681</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.11.10.5"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.5.1">.7626</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.6"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.6.1">.0808</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.7"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.7.1">.5692</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.8"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.8.1">.3619</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.11.10.9"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.11.10.9.1">.9664</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.11.10.10">0.2146</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.12.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.12.11.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.12.11.1.1">NGCF</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.2.1">.2001</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.3.1">.1623</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.4.1">.2549</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.12.11.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.5.1">.7373</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.6.1">.0786</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.7.1">.5492</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.8.1">.3470</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.8.1.12.11.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.1.12.11.9.1">.9621</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.1.12.11.10"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.12.11.10.1">0.1057</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.1.13.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.8.1.13.12.1"><span class="ltx_text ltx_font_bold" id="S5.T2.8.1.13.12.1.1">SimGCL</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.2">.1073</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.3">.1188</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.4">.1490</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.8.1.13.12.5">.6210</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.6">.0438</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.7">.4037</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.8">.2333</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.8.1.13.12.9">.9386</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.1.13.12.10">0.1281</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.12.4.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.6.3" style="font-size:90%;">Results of the models in terms of Precision@K (P@K), Recall@K (R@K), NDCG@K and HIT@K, with <span class="ltx_text" id="S5.T2.4.1.1">K <math alttext="\mathbf{\in\{10,100\}}" class="ltx_Math" display="inline" id="S5.T2.4.1.1.m1.2"><semantics id="S5.T2.4.1.1.m1.2b"><mrow id="S5.T2.4.1.1.m1.2.3" xref="S5.T2.4.1.1.m1.2.3.cmml"><mi id="S5.T2.4.1.1.m1.2.3.2" xref="S5.T2.4.1.1.m1.2.3.2.cmml"></mi><mo id="S5.T2.4.1.1.m1.2.3.1" xref="S5.T2.4.1.1.m1.2.3.1.cmml">∈</mo><mrow id="S5.T2.4.1.1.m1.2.3.3.2" xref="S5.T2.4.1.1.m1.2.3.3.1.cmml"><mo id="S5.T2.4.1.1.m1.2.3.3.2.1" stretchy="false" xref="S5.T2.4.1.1.m1.2.3.3.1.cmml">{</mo><mn id="S5.T2.4.1.1.m1.1.1" xref="S5.T2.4.1.1.m1.1.1.cmml">𝟏𝟎</mn><mo id="S5.T2.4.1.1.m1.2.3.3.2.2" xref="S5.T2.4.1.1.m1.2.3.3.1.cmml">,</mo><mn id="S5.T2.4.1.1.m1.2.2" xref="S5.T2.4.1.1.m1.2.2.cmml">𝟏𝟎𝟎</mn><mo id="S5.T2.4.1.1.m1.2.3.3.2.3" stretchy="false" xref="S5.T2.4.1.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.1.1.m1.2c"><apply id="S5.T2.4.1.1.m1.2.3.cmml" xref="S5.T2.4.1.1.m1.2.3"><in id="S5.T2.4.1.1.m1.2.3.1.cmml" xref="S5.T2.4.1.1.m1.2.3.1"></in><csymbol cd="latexml" id="S5.T2.4.1.1.m1.2.3.2.cmml" xref="S5.T2.4.1.1.m1.2.3.2">absent</csymbol><set id="S5.T2.4.1.1.m1.2.3.3.1.cmml" xref="S5.T2.4.1.1.m1.2.3.3.2"><cn id="S5.T2.4.1.1.m1.1.1.cmml" type="integer" xref="S5.T2.4.1.1.m1.1.1">10</cn><cn id="S5.T2.4.1.1.m1.2.2.cmml" type="integer" xref="S5.T2.4.1.1.m1.2.2">100</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.1.1.m1.2d">\mathbf{\in\{10,100\}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.1.1.m1.2e">∈ { bold_10 , bold_100 }</annotation></semantics></math></span> (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.5.2.m1.1"><semantics id="S5.T2.5.2.m1.1b"><mo id="S5.T2.5.2.m1.1.1" stretchy="false" xref="S5.T2.5.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.2.m1.1c"><ci id="S5.T2.5.2.m1.1.1.cmml" xref="S5.T2.5.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.2.m1.1d">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.2.m1.1e">↑</annotation></semantics></math> is better). Also the emissions in terms of CO<sub class="ltx_sub" id="S5.T2.6.3.2">2</sub>-eq [kg] are shown (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.6.3.m2.1"><semantics id="S5.T2.6.3.m2.1b"><mo id="S5.T2.6.3.m2.1.1" stretchy="false" xref="S5.T2.6.3.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.3.m2.1c"><ci id="S5.T2.6.3.m2.1.1.cmml" xref="S5.T2.6.3.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.3.m2.1d">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.3.m2.1e">↓</annotation></semantics></math> is better). <span class="ltx_text ltx_font_bold" id="S5.T2.6.3.3">Bold</span> denotes the best model for a dataset by the metric in the main group, <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.6.3.4">underlined</span> the second best.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Embedding Size and Environmental Impact</h3>
<figure class="ltx_figure" id="S5.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S5.F1.sf1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S5.F1.sf1.3.2" style="font-size:90%;">Beauty</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S5.F1.sf2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F1.sf2.3.2" style="font-size:90%;">DianPing</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F1.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S5.F1.sf3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S5.F1.sf3.3.2" style="font-size:90%;">ML-1M</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.5.2.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S5.F1.2.1" style="font-size:90%;">Difference in terms of environmental impact when changing the embedding size of the GNNs. On the y-axis it can be seen the CO<sub class="ltx_sub" id="S5.F1.2.1.1">2</sub>-eq while on the x-axis the embedding size.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09514v1#S5.F1" title="Figure 1 ‣ 5.2 Embedding Size and Environmental Impact ‣ 5 Results ‣ Eco-Aware Graph Neural Networks for Sustainable Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a> shows that increasing the size of the embeddings generally leads to a higher environmental impact across all models and datasets. This trend is particularly pronounced in the DianPing dataset, which contains a large number of interactions. Interestingly, on the DianPing dataset, NGCF has a higher cost than SimGCL, despite SimGCL being computationally more expensive. However, on the other datasets, SimGCL consistently remains the most computationally demanding model. The same Figure also illustrates how the dataset size affects CO<sub class="ltx_sub" id="S5.SS2.p1.1.1">2</sub>-eq costs. On the ML-1M dataset, the costs are significantly lower compared to those on the DianPing dataset. This not only depends from the number of users and the number of items, but also from the interactions between users and items. On the DianPing and Beauty datasets, as the embedding size increases, emissions also increase, as expected. It is interesting to note that on the ML-1M dataset, for the NGCF and LightGCL models, emissions related to an embedding size of 256 are higher compared to those with an embedding size of 128. This result requires more detailed investigation in future work, particularly on how each parameter of a model influences the environmental impact of the respective model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this study, we examined the environmental impact of GNN-based recommender systems, an aspect often overlooked in AI research. Our analysis of carbon emissions and energy consumption across different GNN architectures and configurations highlights how model complexity, training duration, hardware specifications, and embedding size affect their environmental footprint.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">While GNNs provide significant benefits in capturing complex relationships for recommendation tasks, our findings show that these gains can come with considerable environmental costs, especially when large datasets or extensive embeddings are used.
By emphasizing these trade-offs, our study contributes to the discourse on sustainable AI, encouraging the integration of environmental considerations into the development of recommender systems. Future research should focus on optimizing GNN architectures to balance performance with sustainability, exploring new algorithms and energy-efficient methods.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">We hope this work inspires further efforts to develop eco-friendly AI technologies that align with global sustainability goals.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work was partially supported by projects FAIR (PE0000013) and SERICS (PE00000014) under the MUR National Recovery and Resilience Plan funded by the European Union - NextGenerationEU and by PRIN 2020 project n.2020TA3K9N "LEGO.AI". Supported by the EC H2020RIA project “SoBigData++” (871042), PNRR MUR project IR0000013-SoBigData.it.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bacciu et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Andrea Bacciu, Federico Siciliano, Nicola Tonellotto, and Fabrizio Silvestri. 2023.

</span>
<span class="ltx_bibblock">Integrating item relevance in training loss for sequential recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 1114–1119.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021.

</span>
<span class="ltx_bibblock">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em> (Virtual Event, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib3.4.2">(FAccT ’21)</em>. Association for Computing Machinery, New York, NY, USA, 610–623.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3442188.3445922" title="">https://doi.org/10.1145/3442188.3445922</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Betello et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2024a)</span>
<span class="ltx_bibblock">
Filippo Betello, Antonio Purificato, Federico Siciliano, Giovanni Trappolini, Andrea Bacciu, Nicola Tonellotto, and Fabrizio Silvestri. 2024a.

</span>
<span class="ltx_bibblock">A Reproducible Analysis of Sequential Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">arXiv preprint arXiv:2408.03873</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Betello et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2024b)</span>
<span class="ltx_bibblock">
Filippo Betello, Federico Siciliano, Pushkar Mishra, and Fabrizio Silvestri. 2024b.

</span>
<span class="ltx_bibblock">Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Advances in Information Retrieval</em>. Springer Nature Switzerland, Cham, 205–220.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xuheng Cai, Chao Huang, Lianghao Xia, and Xubin Ren. 2023.

</span>
<span class="ltx_bibblock">LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">The Eleventh International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Rui Chen, Qingyi Hua, Yan-Shuo Chang, Bo Wang, Lei Zhang, and Xiangjie Kong. 2018.

</span>
<span class="ltx_bibblock">A Survey of Collaborative Filtering-Based Recommender Systems: From Traditional Methods to Hybrid Methods Based on Social Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">IEEE Access</em> 6 (2018), 64301–64320.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2018.2877208" title="">https://doi.org/10.1109/ACCESS.2018.2877208</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Courty et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Benoit Courty, Victor Schmidt, Goyal-Kamal, MarionCoutarel, Boris Feld, Jérémy Lecourt, SabAmine, kngoyal, Mathilde Léval, Alexis Cruveiller, inimaz, ouminasara, Franklin Zhao, Aditya Joshi, Alexis Bogroff, Amine Saboni, Hugues de Lavoreille, Niko Laskaris, Luis Blanche, Edoardo Abati, LiamConnell, Douglas Blank, Ziyao Wang, Armin Catovic, Michał Stęchły, alencon, JPW, MinervaBooks, Necmettin Çarkacı, and DomAlexRod. 2023.

</span>
<span class="ltx_bibblock">mlco2/codecarbon: v2.3.2.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.10213072" title="">https://doi.org/10.5281/zenodo.10213072</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yingqiang Ge, Shuya Zhao, Honglu Zhou, Changhua Pei, Fei Sun, Wenwu Ou, and Yongfeng Zhang. 2020.

</span>
<span class="ltx_bibblock">Understanding Echo Chambers in E-commerce Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Virtual Event, China) <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.2">(SIGIR ’20)</em>. Association for Computing Machinery, New York, NY, USA, 2261–2270.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401431" title="">https://doi.org/10.1145/3397271.3401431</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F. Maxwell Harper and Joseph A. Konstan. 2015.

</span>
<span class="ltx_bibblock">The MovieLens Datasets: History and Context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">ACM Trans. Interact. Intell. Syst.</em> 5, 4, Article 19 (dec 2015), 19 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2827872" title="">https://doi.org/10.1145/2827872</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, YongDong Zhang, and Meng Wang. 2020.

</span>
<span class="ltx_bibblock">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Virtual Event, China) <em class="ltx_emph ltx_font_italic" id="bib.bib11.4.2">(SIGIR ’20)</em>. Association for Computing Machinery, New York, NY, USA, 639–648.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401063" title="">https://doi.org/10.1145/3397271.3401063</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hunter et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
David B Hunter, James E Salzman, and Durwood Zaelke. 2021.

</span>
<span class="ltx_bibblock">Glasgow climate summit: Cop26.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2018 IEEE international conference on data mining (ICDM)</em>. IEEE, 197–206.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim and Neff (2009)</span>
<span class="ltx_bibblock">
Brent Kim and Roni Neff. 2009.

</span>
<span class="ltx_bibblock">Measurement and communication of greenhouse gas emissions from US food consumption via carbon calculators.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Ecological Economics</em> 69, 1 (2009), 186–196.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yuxi Liu, Lianghao Xia, and Chao Huang. 2024.

</span>
<span class="ltx_bibblock">SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Washington DC, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib15.4.2">(SIGIR ’24)</em>. Association for Computing Machinery, New York, NY, USA, 1609–1618.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3626772.3657716" title="">https://doi.org/10.1145/3626772.3657716</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mancino et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Alberto Carlo Maria Mancino, Antonio Ferrara, Salvatore Bufi, Daniele Malitesta, Tommaso Di Noia, and Eugenio Di Sciascio. 2023.

</span>
<span class="ltx_bibblock">KGTORe: Tailored Recommendations through Knowledge-aware GNN Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib16.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 576–587.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608804" title="">https://doi.org/10.1145/3604915.3608804</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McAuley et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. 2015.

</span>
<span class="ltx_bibblock">Image-Based Recommendations on Styles and Substitutes. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Santiago, Chile) <em class="ltx_emph ltx_font_italic" id="bib.bib17.4.2">(SIGIR ’15)</em>. Association for Computing Machinery, New York, NY, USA, 43–52.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2766462.2767755" title="">https://doi.org/10.1145/2766462.2767755</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patterson et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021.

</span>
<span class="ltx_bibblock">Carbon emissions and large neural network training.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang Xu, and Junzhou Huang. 2020.

</span>
<span class="ltx_bibblock">Graph Representation Learning via Graphical Mutual Information Maximization. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of The Web Conference 2020</em> (Taipei, Taiwan) <em class="ltx_emph ltx_font_italic" id="bib.bib19.4.2">(WWW ’20)</em>. Association for Computing Machinery, New York, NY, USA, 259–270.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3366423.3380112" title="">https://doi.org/10.1145/3366423.3380112</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Purificato et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Antonio Purificato, Giulia Cassarà, Federico Siciliano, Pietro Liò, and Fabrizio Silvestri. 2024.

</span>
<span class="ltx_bibblock">Sheaf4Rec: Sheaf Neural Networks for Graph-based Recommender Systems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2304.09097 [cs.IR]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2304.09097" title="">https://arxiv.org/abs/2304.09097</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scells et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Harrisen Scells, Shengyao Zhuang, and Guido Zuccon. 2022.

</span>
<span class="ltx_bibblock">Reduce, Reuse, Recycle: Green Information Retrieval Research. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Madrid, Spain) <em class="ltx_emph ltx_font_italic" id="bib.bib21.4.2">(SIGIR ’22)</em>. Association for Computing Machinery, New York, NY, USA, 2825–2837.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531766" title="">https://doi.org/10.1145/3477495.3531766</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spillo et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Giuseppe Spillo, Allegra De Filippo, Cataldo Musto, Michela Milano, and Giovanni Semeraro. 2023.

</span>
<span class="ltx_bibblock">Towards Sustainability-aware Recommender Systems: Analyzing the Trade-off Between Algorithms Performance and Carbon Footprint. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib22.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 856–862.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608840" title="">https://doi.org/10.1145/3604915.3608840</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1904.06690 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.

</span>
<span class="ltx_bibblock">Neural Graph Collaborative Filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Paris, France) <em class="ltx_emph ltx_font_italic" id="bib.bib24.4.2">(SIGIR’19)</em>. Association for Computing Machinery, New York, NY, USA, 165–174.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3331184.3331267" title="">https://doi.org/10.1145/3331184.3331267</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiaorong Wang, Clara Na, Emma Strubell, Sorelle Friedler, and Sasha Luccioni. 2023.

</span>
<span class="ltx_bibblock">Energy and Carbon Considerations of Fine-Tuning BERT. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">The 2023 Conference on Empirical Methods in Natural Language Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. 2022.

</span>
<span class="ltx_bibblock">Graph Neural Networks in Recommender Systems: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">ACM Comput. Surv.</em> 55, 5, Article 97 (dec 2022), 37 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3535101" title="">https://doi.org/10.1145/3535101</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Lanling Xu, Zhen Tian, Gaowei Zhang, Junjie Zhang, Lei Wang, Bowen Zheng, Yifan Li, Jiakai Tang, Zeyu Zhang, Yupeng Hou, Xingyu Pan, Wayne Xin Zhao, Xu Chen, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock">Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Taipei, Taiwan) <em class="ltx_emph ltx_font_italic" id="bib.bib27.4.2">(SIGIR ’23)</em>. Association for Computing Machinery, New York, NY, USA, 2837–2847.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3591889" title="">https://doi.org/10.1145/3539618.3591889</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022.

</span>
<span class="ltx_bibblock">Are graph augmentations necessary? simple graph contrastive learning for recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval</em>. 1294–1303.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Zhou Zhao, Hanqing Lu, Deng Cai, Xiaofei He, and Yueting Zhuang. 2016.

</span>
<span class="ltx_bibblock">User Preference Learning for Online Social Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">IEEE Trans. on Knowl. and Data Eng.</em> 28, 9 (sep 2016), 2522–2534.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TKDE.2016.2569096" title="">https://doi.org/10.1109/TKDE.2016.2569096</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Oct 12 12:22:31 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
