<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2109.05173] Making Table Understanding Work in Practice</title><meta property="og:description" content="Understanding the semantics of tables at scale is crucial for tasks like data integration, preparation, and search. Table understanding methods aim at detecting a tableâ€™s topic, semantic column types, column relations,â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Making Table Understanding Work in Practice">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Making Table Understanding Work in Practice">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2109.05173">

<!--Generated on Tue Mar 19 13:58:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Making Table Understanding Work in Practice</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Madelon Hulsebos
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Sigma Computing</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">San Francisco</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:madelon@sigmacomputing.com">madelon@sigmacomputing.com</a>
</span><span id="id4.4.id1" class="ltx_text ltx_affiliation_institution">University of Amsterdam</span><span id="id5.5.id2" class="ltx_text ltx_affiliation_city">Amsterdam</span><span id="id6.6.id3" class="ltx_text ltx_affiliation_country">Netherlands</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sneha Gathani
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Sigma Computing</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">San Francisco</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:sneha@sigmacomputing.com">sneha@sigmacomputing.com</a>
</span><span id="id10.4.id1" class="ltx_text ltx_affiliation_institution">University of Maryland</span><span id="id11.5.id2" class="ltx_text ltx_affiliation_city">College Park</span><span id="id12.6.id3" class="ltx_text ltx_affiliation_country">USA</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">James Gale
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id13.1.id1" class="ltx_text ltx_affiliation_institution">Sigma Computing</span><span id="id14.2.id2" class="ltx_text ltx_affiliation_city">San Francisco</span><span id="id15.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jlg@sigmacomputing.com">jlg@sigmacomputing.com</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Isil Dillig
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id16.1.id1" class="ltx_text ltx_affiliation_institution">University of Texas</span><span id="id17.2.id2" class="ltx_text ltx_affiliation_city">Austin</span><span id="id18.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:isil@cs.utexas.edu">isil@cs.utexas.edu</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Paul Groth
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id19.1.id1" class="ltx_text ltx_affiliation_institution">University of Amsterdam</span><span id="id20.2.id2" class="ltx_text ltx_affiliation_city">Amsterdam</span><span id="id21.3.id3" class="ltx_text ltx_affiliation_country">Netherlands</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:p.t.groth@uva.nl">p.t.groth@uva.nl</a>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ã‡aÄŸatay Demiralp
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id22.1.id1" class="ltx_text ltx_affiliation_institution">Sigma Computing</span><span id="id23.2.id2" class="ltx_text ltx_affiliation_city">San Francisco</span><span id="id24.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:cagatay@sigmacomputing.com">cagatay@sigmacomputing.com</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id25.id1" class="ltx_p">Understanding the semantics of tables at scale is crucial for tasks like data integration, preparation, and search. Table understanding methods aim at detecting a tableâ€™s topic, semantic column types, column relations, or entities. With the rise of deep learning, powerful models have been developed for these tasks with excellent accuracy on benchmarks. However, we observe that there exists a gap between the performance of these models on these benchmarks and their applicability in practice. In this paper, we address the question: what do we need for these models to work in practice?</p>
<p id="id26.id2" class="ltx_p">We discuss three challenges of deploying table understanding models and propose a framework to address them. These challenges include 1) difficulty in customizing models to specific domains, 2) lack of training data for typical database tables often found in enterprises, and 3) lack of confidence in the inferences made by models. We present <span id="id26.id2.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> which implements this framework for the semantic column type detection task. <span id="id26.id2.2" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> encapsulates a hybrid model trained on GitTables and integrates a lightweight human-in-the-loop approach to customize the model. Lastly, we highlight avenues for future research that further close the gap towards making table understanding effective in practice.</p>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>none</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>; Chaminade CA; USA</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The data used and generated by enterprise applications today are processed and stored overwhelmingly as relational tables in relational databases, including data warehouses. Table understanding aims at surfacing the semantics of tables in order to improve and help automate many tasks from data integration to data visualization. Recent developments in machine learning (ML), particularly deep representation and transfer learning, suggest that the time might be ripe for augmenting enterprise applications with computational table understanding. Table understandingÂ <cite class="ltx_cite ltx_citemacro_citep">(Pujara
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite> in this context refers to tasks such as topic inference, table annotation, semantic column type detection, entity resolution, relation extraction, and learning contextual semantic representations of table elements.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Surfacing table semantics as metadata and effective representations (e.g., contextual semantic embeddings) can improve data exploration tasks such as search and data discovery in applicationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Cafarella etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
For example, knowledge about semantic column types and inter-column relations is useful for automating data preparationÂ <cite class="ltx_cite ltx_citemacro_citep">(Chu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2015</a>)</cite> and data visualizationÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Dibia and
Demiralp, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Zhou
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>. Knowledge of table schemas and entities, in turn, facilitates the integration of two or more data sourcesÂ <cite class="ltx_cite ltx_citemacro_citep">(Stonebraker
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2018</a>)</cite> and can be used to construct data catalogs.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Recent work has introduced deep learning models such as SherlockÂ <cite class="ltx_cite ltx_citemacro_citep">(Hulsebos etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> and SATOÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite> to detect semantic column types. Using transformersÂ <cite class="ltx_cite ltx_citemacro_citep">(Vaswani etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2017</a>)</cite> and building on BERTÂ <cite class="ltx_cite ltx_citemacro_citep">(Devlin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>, researchers have also proposed pretrained table models such as TURLÂ <cite class="ltx_cite ltx_citemacro_citep">(Deng
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>, TaBERTÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite>, TaPaSÂ <cite class="ltx_cite ltx_citemacro_citep">(Herzig etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, TABBIEÂ <cite class="ltx_cite ltx_citemacro_citep">(Iida
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> and TUTAÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2021a</a>)</cite>
and successfully applied them in various downstream tasks for table understanding. While there is a heightened research interest in table understanding models, little is known about the feasibility of these
models in practice.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Commercial data systems such as TalendÂ <cite class="ltx_cite ltx_citemacro_citep">(Talend, <a href="#bib.bib37" title="" class="ltx_ref">2021a</a>)</cite>, TrifactaÂ <cite class="ltx_cite ltx_citemacro_citep">(Trifacta, <a href="#bib.bib41" title="" class="ltx_ref">2021a</a>)</cite>, and TableauÂ <cite class="ltx_cite ltx_citemacro_citep">(Tableau, <a href="#bib.bib36" title="" class="ltx_ref">2021</a>)</cite>, in general, do not seem to deploy such models in practice.
Instead, they primarily rely on simpler methods like regular expression matching for detecting a limited set of semantic typesÂ <cite class="ltx_cite ltx_citemacro_citep">(Trifacta, <a href="#bib.bib42" title="" class="ltx_ref">2021b</a>; Talend, <a href="#bib.bib38" title="" class="ltx_ref">2021b</a>; Google, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>. TamrÂ <cite class="ltx_cite ltx_citemacro_citep">(Stonebraker etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2013</a>)</cite> made the step towards machine learning but uses
less data-heavy machine learning models due to the unavailability of training data and lack of domain expert time, among other thingsÂ <cite class="ltx_cite ltx_citemacro_citep">(Stonebraker
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Motivated by the abundance of practical applications of table understanding, we shift our focus to making these models effective in practice. We identify three challenges in deploying table understanding models in practice.
First, early feedback from companies on semantic column type detection models such as Sherlock and SATO, highlighted the desire to customize models for different sets of tables and semantic types specific to domains. Doing so requires new large-scale datasets and semantic types that represent these domains well which often requires efficient labeling procedures and long retraining procedures. Although the pretraining/finetuning paradigm adopted for table understanding modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Deng
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Yin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> is meant to relieve these burdens, we observe that these models are not straightforward to finetune and still require a significant set of labeled data.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Second, these models are pretrained on tables that poorly resemble typical database tables, as the training data mostly reflects tables found on the WebÂ <cite class="ltx_cite ltx_citemacro_citep">(Langenecker etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Hulsebos
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>. Therefore, tuning a pretrained model or retraining a task-specific model towards a representative data distribution and labels still takes many resources.
Lastly, the quality and confidence of the inferences made with these models are typically unstable across labelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Hulsebos etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite>, which limits the reliability of the model output in practice. Besides reliability, no finetuning procedures are proposed to reflect whether samples are far from the training setÂ <cite class="ltx_cite ltx_citemacro_citep">(Dhamija
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>. In practice, it is important to accurately reflect out-of-distribution data points to ensure high precision.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Based on these challenges, we propose a framework that provides a foundation for table understanding systems in practice. This framework is principled in enabling lightweight and interactive customization towards the target data domain, generalizing to typical database tables, and ensuring high precision and coverage. We present <span id="S1.p7.1.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span>, a system that implements the proposed framework for the semantic column type detection task but generalizes to other table understanding tasks.
<span id="S1.p7.1.2" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> incorporates a pretrained global model identically deployed across all customers, which combines heuristics with a learned model to establish high precision and semantic type coverage. This base model adapts iteratively to the userâ€™s context based on user feedback. Building on the data programming by demonstration (DPBD) paradigmÂ <cite class="ltx_cite ltx_citemacro_citep">(Evensen
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>, <span id="S1.p7.1.3" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> generates custom training data for the model leveraging the userâ€™s feedback. <span id="S1.p7.1.4" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> is pretrained on GitTables providing representative tables as well as relevant semantic types.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">In summary, our contributions are as follows: 1) the identification of three key challenges of table understanding systems in practice; 2) a framework for building table understanding systems; and 3) <span id="S1.p8.1.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span>, an implementation of this framework for semantic column type detection.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Challenges</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Deploying table understanding models introduces many challenges in practical applications. Here, we discuss three challenges deduced from our experience and the literature.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Unknown data domains</h3>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2109.05173/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_img_landscape" width="191" height="67" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Models often fail when data-shift occurs. Data-shift comes in three flavors in practice: (a) covariate-shift, (b) label-shift, and (c) out-of-distribution data. Circles represent sample data points and their colors indicate the labels of the samples. The border of a circle indicates whether the corresponding sample stems from the training set (black) or target set (none).</span></figcaption>
</figure>
<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">One system does not fit every context. In order to provide responsive and intelligent functionalities, the accuracy of a table understanding system is expected to converge to a userâ€™s context and improve over time. If systems fail to do so, they might lose relevance to a user, leading to potential decreased satisfaction or engagement.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">There are three cases of shift that can occur between the training data and the data in the user context, the inference-time data. The first case is when the distribution of table values present in the training data differs from that of the inference-time
tables. This is also called covariate-shiftÂ <cite class="ltx_cite ltx_citemacro_citep">(Kouw and Loog, <a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite> (Fig.Â  <a href="#S2.F1" title="Figure 1 â€£ 2.1. Unknown data domains â€£ 2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>a). For example, in the case of semantic column
type detection, a column with the name â€œIDâ€ might contain values not previously seen for the semantic type <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">ID</span>.
The second case is when table values associated with a certain label in the training dataset correspond to a different label within the userâ€™s context. This is also known as label-shift (Fig.Â <a href="#S2.F1" title="Figure 1 â€£ 2.1. Unknown data domains â€£ 2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>b)Â <cite class="ltx_cite ltx_citemacro_citep">(Rabanser
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2018</a>)</cite>.
For example, a column with predicted semantic type <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">ID</span> might actually correspond to the <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">phone number</span> type within the userâ€™s context. The third is the case when we encounter out-of-distribution data (Fig.Â <a href="#S2.F1" title="Figure 1 â€£ 2.1. Unknown data domains â€£ 2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>c). A user might have tables and labels far from the training distributionÂ <cite class="ltx_cite ltx_citemacro_citep">(Rabanser
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Unrepresentative training data</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">With the availability of large-scale table resources like WebTablesÂ <cite class="ltx_cite ltx_citemacro_citep">(WebDataCommons, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite> the fruits of deep learning were leveraged to build deep learning models for semantic column type detection modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Hulsebos etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite>. Succeeding methods extend the pretraining paradigm to develop task-agnostic pretrained table understanding modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020</a>; Deng
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2021b</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Despite the abundance of pretrained table understanding models that have been published, they seem not widely adopted in practice. Business Intelligence systems like Tableau and Google Data Studio, for example, only detect a limited set of semantic types, seemingly with lookup functions or pattern matchingÂ <cite class="ltx_cite ltx_citemacro_citep">(Trifacta, <a href="#bib.bib42" title="" class="ltx_ref">2021b</a>; Google, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">We believe that this gap can be attributed to the datasets used to pretrain these models, which mainly represent tables from the Web. Such tables can only partially represent tables found in enterprise databasesÂ <cite class="ltx_cite ltx_citemacro_citep">(Hulsebos
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>; Langenecker etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Vogelsgesang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2018</a>)</cite>. This affects the applicability of concurrent pretrained table models to downstream tasks on typical â€œofflineâ€ databases. To remove this barrier, we need models pretrained on relevant tables, resembling what one encounters in offline databases.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Unreliable inferences</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">A table understanding system is useless to users, and might even do more harm than good if it cannot accurately infer table semantics. For example, a column type detector should be able to accurately predict basic types such as <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">date</span> and <span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">city</span> with high precision as a bare minimum, while more and specific semantics may be a nice-to-have. Balancing this precision with coverage, e.g. the number of labels a model is able to distinguish, is a hard challengeÂ <cite class="ltx_cite ltx_citemacro_citep">(Deng
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2010</a>)</cite> but finding the optimal operating point is critical to make a table understanding system effective.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Finally, in practice, and especially in applications with varying semantic contexts, we might encounter tables and target labels that are not covered in the training set (Fig. <a href="#S2.F1" title="Figure 1 â€£ 2.1. Unknown data domains â€£ 2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>c). While high-capacity models exist, they do not extrapolate well and can hardly capture the entire universe. Upon encountering tables and labels that are far from the training data, the system should avoid inferring labels for it. This is mainly critical in exact or user-facing applications such as data integration, visualization recommendation, or data cataloging.
If a system fails in this regard, we risk losing a userâ€™s trust in the system or produce critical errors. The question is, (how) do table understanding models recognize out-of-distribution tables? And how to handle situations where a model fails?</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2109.05173/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="390" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S2.F2.4.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">SigmaTyper<span id="S2.F2.4.2.1" class="ltx_text ltx_font_upright">: tables and semantic types are used to pretrain a global model. The local model adapts towards the userâ€™s context through data programming by demonstration: based on the userâ€™s feedback, labeling functions are inferred and used to generate new training data and function as weak predictors in the local model. The weight of the local model increases over time.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Framework</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We propose a general framework to addresses these challenges, providing a foundation for implementing table understanding
systems in practice.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Interactive customization</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Table understanding systems should effectively adapt to the userâ€™s context. Earlier information retrieval systems have shown that iteratively learning from interactive feedback is an efficient way to accomplish thisÂ <cite class="ltx_cite ltx_citemacro_citep">(Tamine-Lechani etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2010</a>; Joachims and
Radlinski, <a href="#bib.bib22" title="" class="ltx_ref">2007</a>)</cite>. Interactions for this end should be easy to use, taking minimal time and input, to maximize the effectiveness of the feedback cycle. Existing systems often, however, require complicated configurationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Talend, <a href="#bib.bib38" title="" class="ltx_ref">2021b</a>; Google, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In our vision, the userâ€™s feedback, implicit or explicit, should be used to derive rules automatically (e.g. regular expressions or heuristics) following the programming by demonstration (or example) frameworkÂ <cite class="ltx_cite ltx_citemacro_citep">(Lieberman, <a href="#bib.bib27" title="" class="ltx_ref">2001</a>)</cite>. For example, if we want to match tables describing similar products from different e-commerce platforms, we can extract rules that describe the distribution of prices across products. Such rules can be exploited in many ways to adapt the system to the userâ€™s task and data context. We believe they can, at least, be used to 1) generate customized training data using data programmingÂ <cite class="ltx_cite ltx_citemacro_citep">(Ratner
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2016</a>)</cite>, and 2) as weak learners to make new inferencesÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhou, <a href="#bib.bib51" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Relevant training data</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Models are only as good as the data they are trained on. Unlike large corpora of text extracted from the Web which are shown to be instrumental for pretraining widely used language modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Devlin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Brown
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>, pretrained table models have shown less impact in this regard. In fact, the generalizability of models trained towards typical database tables is found to be limitedÂ <cite class="ltx_cite ltx_citemacro_citep">(Langenecker etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Hulsebos
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To deploy table understanding models in enterprises, we need training data relevant to a variety of domains. Typical corpora used for pretraining table models include WebTablesÂ <cite class="ltx_cite ltx_citemacro_citep">(WebDataCommons, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite> and WikiTablesÂ <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2013</a>)</cite>. Tables from the Web are relatively small and homogeneous. Typical database tables, instead, are relatively large and heterogeneousÂ <cite class="ltx_cite ltx_citemacro_citep">(Vogelsgesang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2018</a>)</cite>. Table understanding models should reflect such data distributions and be pretrained on matching corpora and relevant labels.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Hybrid adaptive systems</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Systems should ensure high precision and high coverage, be assessed accordingly, and ensure reliability. We believe that systems should be hybrid, combining heuristics that are often pragmatic, fast, and transparent (e.g., easier to explain), with learned models that offer high capacity, flexibility, and semantic coverage.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Beyond accuracy and coverage, systems should learn to reflect their confidence about out-of-distribution samples by being trained specifically on these scenarios. Finally, the underlying pretrained models should adapt to new domains, and do so with minimal iterations.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>SigmaTyper</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We present <span id="S4.p1.1.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span>, a system that implements the proposed framework for semantic column type detection
(annotation), which is a popular table understanding task. Fig.Â <a href="#S2.F2" title="Figure 2 â€£ 2.3. Unreliable inferences â€£ 2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the high-level system architecture of our system.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Input data and labels</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">As traditional large-scale table corpora do not extend well to database tablesÂ <cite class="ltx_cite ltx_citemacro_citep">(Langenecker etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Hulsebos
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>, newer data sourcesÂ <cite class="ltx_cite ltx_citemacro_citep">(Herzig etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2021</a>; Hulsebos
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>; Vogelsgesang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2018</a>)</cite> aim at capturing more database-like tables. Since <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> is intended to operate on enterprise tables, we use the GitTablesÂ <cite class="ltx_cite ltx_citemacro_citep">(Hulsebos
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite> corpus to train it. GitTables has been recently introduced to address the need for database tables to train models for enterprise
applications.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Predictions of a learned model should be relevant for the majority of its intended users and their application domains. For semantic column type detection, this implies that we need semantic types common in the enterprise, science, and medical domains, and beyond. Tables in GitTables come along with over 500 semantic types from DBpediaÂ <cite class="ltx_cite ltx_citemacro_citep">(Auer etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2007</a>)</cite> and Schema.orgÂ <cite class="ltx_cite ltx_citemacro_citep">(Guha
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite>. We select the semantic types from the DBpedia ontology, given its broad semantic coverage and easy integration with the DBpedia Knowledge Base.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2109.05173/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="297" height="84" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.6.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S4.F3.7.2" class="ltx_text" style="font-size:90%;">Data pogramming by demonstration implementation of <span id="S4.F3.7.2.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span>. â‘  Based on the userâ€™s correction of â€œIncomeâ€ to type <span id="S4.F3.7.2.2" class="ltx_text ltx_font_typewriter">salary</span>, â‘¡ <span id="S4.F3.7.2.3" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> infers labeling functions (LFs) from the column using e.g. data profilers, and â‘¢ uses the LFs to extract customized training data from the source corpus, â‘£ into customized weakly labeled training data for semantic type <span id="S4.F3.7.2.4" class="ltx_text ltx_font_typewriter">salary</span>.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>System adaptation by DPBD</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To stay useful, systems incorporating learned models should adapt to the userâ€™s specific semantic context, without imposing time-consuming work on the user. Hand-labeling vast amounts of data to retrain machine learning models, especially deep learning models, is infeasible given budget constraintsÂ <cite class="ltx_cite ltx_citemacro_citep">(Stonebraker
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2018</a>)</cite>. We build on the data programming by demonstration framework (DPBD)Â <cite class="ltx_cite ltx_citemacro_citep">(Evensen
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> to handle these challenges. That is, we infer labeling functions automatically from a table based on the userâ€™s feedback, which may be implicit or explicit, and use these functions to generate new training data.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Considering the example in Figure <a href="#S4.F3" title="Figure 3 â€£ 4.1. Input data and labels â€£ 4. SigmaTyper â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the system yields initial column type predictions for each column in this table. The second column, labeled with type <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">revenue</span> is found to be incorrect by the user. The user explicitly relabels this column, originally named â€œIncomeâ€, with new type <span id="S4.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">salary</span>. Labeling functions are then inferred for the new type <span id="S4.SS2.p2.1.3" class="ltx_text ltx_font_typewriter">salary</span> and used to generate training data so that the model can be tuned to recognize the type in the futureÂ <cite class="ltx_cite ltx_citemacro_citep">(Ratner
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2016</a>)</cite>. While the interface allows explicit approval of the type predictions, the user does not give this explicit feedback for the remaining columns but leaves those type predictions as-is and conducts an analysis on the table. The system automatically interprets the other types to be implicitly approved. The entire table with its labels is then added to the training data along with the newly generated training data.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> infers labeling functions from columns with textual and numeric data types. For numeric columns, it captures statistics of the data distribution using a data profiler, currently Great ExpectationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Superconductive, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>, and extracts textual features from textual columns, e.g. the most frequent values and the number of unique values. For both type of columns, <span id="S4.SS2.p3.1.2" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> infers functions to indicate co-occurring columns based on the other detected types, e.g. the types of neighboring columns as in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.1. Input data and labels â€£ 4. SigmaTyper â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.2" class="ltx_p">To accommodate customization without occluding the model for other customers, <span id="S4.SS2.p4.2.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> consists of a â€œglobalâ€ and multiple â€œlocalâ€ models, one for each customer. The newly generated training data is only used to adapt the local model. The influence of the global and local models on the final prediction is captured in weight vectors representing the influence of each model per type, i.e. <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="\textbf{W}_{g}" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><msub id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2a.cmml">W</mtext><mi id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2a.cmml" xref="S4.SS2.p4.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">W</mtext></ci><ci id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">\textbf{W}_{g}</annotation></semantics></math> for the global model and <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="\textbf{W}_{l}" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><msub id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2a.cmml">W</mtext><mi id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2a.cmml" xref="S4.SS2.p4.2.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">W</mtext></ci><ci id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">\textbf{W}_{l}</annotation></semantics></math> for the local model. Over time, the influence of the local model on the final prediction increases.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2109.05173/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="187" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S4.F4.4.2" class="ltx_text" style="font-size:90%;">Semantic column type detection model of <span id="S4.F4.4.2.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span>. It implements a 3-step pipeline to predict the semantic type of a column based on the columnâ€™s header and values along with an embedding of the entire table.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Semantic type detection pipeline</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.3" class="ltx_p"><span id="S4.SS3.p1.3.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> implements a 3-step pipeline to predict the semantic types of columns based on the table header, column values, and an embedding of the entire table (Fig. <a href="#S4.F4" title="Figure 4 â€£ 4.2. System adaptation by DPBD â€£ 4. SigmaTyper â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).
To minimize overhead, each step in the pipeline is executed (potentially for a subset of columns) only if a preset confidence threshold <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">c</annotation></semantics></math> is not met by the prior step. The steps are executed in order of inference time, so that the slowest step is executed at last. Given a table <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">T</annotation></semantics></math> the system yields the top-<math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">k</annotation></semantics></math> semantic types for each column along with their confidence score.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.2" class="ltx_p">As the header of <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">T</annotation></semantics></math> might already correspond to a semantic type, <span id="S4.SS3.p2.2.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> matches each column name to the labels in the type ontology using syntactic and semantic matching. For syntactic matching, the column header is compared to the semantic types in the ontology using fuzzy matching. If there is a syntactic match, the confidence score is set to the maximum being <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mn id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">100</mn><mo id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">100\%</annotation></semantics></math>.For semantic matching, embedding vectors for the column names as well as the target semantic types are computed using FastTextÂ <cite class="ltx_cite ltx_citemacro_citep">(Joulin etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2016</a>)</cite> first. Then the cosine similarity between the column names and semantic types are calculated using their respective embedding vectors. <span id="S4.SS3.p2.2.2" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> considers these similarity scores as prediction confidences and returns the target types with the highest confidences are returned as final predictions for each column.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">If the confidence of the header matching step does not surpass a preset threshold for a subset of columns, a lookup step is triggered to label them. This step leverages lookup rules, to match a sample of column values to semantic types from the ontology. These rules consist of 1) the labeling functions from the global model and the local model which are obtained through DBPD (Sec. <a href="#S4.SS2" title="4.2. System adaptation by DPBD â€£ 4. SigmaTyper â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>), 2) the DBpedia Knowledge BaseÂ <cite class="ltx_cite ltx_citemacro_citep">(Auer etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2007</a>)</cite>, and 3) a set of regular expressions which might be expanded on user input as wellÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>. The fraction of values that matched a type, is returned as the confidence for that type. The types with the highest confidences are returned as final predictions for each column.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">If the confidence of prior steps for any column is low, the pipeline embeds <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mi id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">T</annotation></semantics></math> using a pretrained TaBERT modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite>. We trained TaBERTâ€™s parameters towards GitTables and finetuned it to enable semantic column type detection. To detect out-of-distribution samples (Fig. <a href="#S2.F1" title="Figure 1 â€£ 2.1. Unknown data domains â€£ 2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>c) we train the model on a background datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Reddy
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> and add the semantic type <span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_typewriter">unknown</span> to match columns of unknown types. The table embedding model in the local model is iteratively finetuned based on the weakly labeled data generated using DPDB.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.3" class="ltx_p">The final prediction for each column in <math id="S4.SS3.p5.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p5.1.m1.1a"><mi id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><ci id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">T</annotation></semantics></math> is the soft majority vote based on the concatenated confidence scores from each step. An optimal aggregation function can be learned as well. We infer a parameter <math id="S4.SS3.p5.2.m2.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS3.p5.2.m2.1a"><mi id="S4.SS3.p5.2.m2.1.1" xref="S4.SS3.p5.2.m2.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.2.m2.1b"><ci id="S4.SS3.p5.2.m2.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.2.m2.1c">\tau</annotation></semantics></math> and threshold predictions that are below <math id="S4.SS3.p5.3.m3.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS3.p5.3.m3.1a"><mi id="S4.SS3.p5.3.m3.1.1" xref="S4.SS3.p5.3.m3.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.3.m3.1b"><ci id="S4.SS3.p5.3.m3.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.3.m3.1c">\tau</annotation></semantics></math> such that the precision of the system is high, hence errors are minimized.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Future work</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Evaluation.</span>
While a first prototype of the system is built, we aim at integrating it into a product over the next weeks. We plan to investigate if and how accurately the system addresses the challenges discussed in sectionÂ <a href="#S2" title="2. Challenges â€£ Making Table Understanding Work in Practice" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In particular, we are interested in understanding how well and rapidly the system adapts to new data domains, how it generalizes to database tables and semantics in general, and in what scenarios it fails to make correct predictions.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Adaptation from scratch.</span>
It may be necessary to tailor a model to a different table distribution or ontology from scratch. One possible route for adapting to new data distributions is to take inspiration from multilingual models and pretrain a model on samples from both â€œlanguagesâ€Â <cite class="ltx_cite ltx_citemacro_citep">(Lample and
Conneau, <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>, tables with different data distributions in our case. This model can be fine-tuned towards the downstream task on a set of labeled tables from the source training data, which in turn can be used to infer the labels for the target table distribution. For a different ontology, we could leverage alternative inexpensive data sources, from a different modality, labeled with the desired ontologyÂ <cite class="ltx_cite ltx_citemacro_citep">(Suri etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Engaging users to provide feedback.</span>
An ongoing research topic is how users can be engaged with systems to improve the system for collective reasons. Users need to have individual incentives in order to give explicit feedback, or it should be made very easy to give feedback. Preferably, a system does not even need any explicit feedback and learns from implicit feedback directly. We foresee many possibilities in this space and plan to experiment with users to learn what works best.</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Deeper analysis of table models.</span>
We also propose a further analysis of the boundaries of what these models can and cannot do to elicit further developments. Prior work reports model performances often measured by predictive accuracy and occasionally analyze on which labels they fail. But we want to structurally answer the question <span id="S5.p4.1.2" class="ltx_text ltx_font_italic">when</span> these models do not work, and <span id="S5.p4.1.3" class="ltx_text ltx_font_italic">why</span>. Analyzing these aspects, in-depth, will help understanding where the weaknesses of these models reside.</p>
</div>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold">Table-specific representations.</span>
To achieve further performance in practice, it seems necessary to move beyond adapting natural language models towards tables. TCNÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2021b</a>)</cite> and RPTÂ <cite class="ltx_cite ltx_citemacro_citep">(Tang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite> propose the first steps towards leveraging the structure of tables. TCN deploys a convolutional neural network, while RPT decouples a table into tuples of attribute rows. TCN confirms the value of developing methods to represent tables, as it demonstrates the largest performance lift compared to other methods that build on top of language models like BERTÂ <cite class="ltx_cite ltx_citemacro_citep">(Devlin
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>. The latest model contribution, RPT, proposes a representation of row-wise tuples, solely leveraging row-wise relations. We believe these methods are a step in the right direction but in-depth analyses can help guide the next steps.</p>
</div>
<div id="S5.p6" class="ltx_para ltx_noindent">
<p id="S5.p6.1" class="ltx_p"><span id="S5.p6.1.1" class="ltx_text ltx_font_bold">Semantics from queries.</span>
Getting table understanding models to work in practice does not only impose challenges but also presents opportunities. An important aspect of semantics that prior deep representation learning research for both languages and tables ignored is the action or interactive semantics. A tableâ€™s semantics is not only embodied by its values and surrounding context (schema, title, etc.) but also by what people (users) do with the table. An important class of actions on tables is SQL queries run by users on tables. We believe that deploying table understanding models within enterprise applications such as Sigma opens up opportunities to incorporate semantics implied by queries into table understanding models.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">At Sigma Computing, we are building the technical foundation to integrate table understanding models with our product that will improve almost every aspect of user experience. Here we introduce a facet of this vision.
Table understanding models have been demonstrated to yield promising performance for detecting column types, entities, relations, and table topics. We believe the time has come to make these advances accessible to the masses, and explore avenues to make table understanding models work in practice.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">To this end, we discuss the main challenges of deploying these models, being: unknown data domains, unrepresentative training data, and unreliable inferences. We propose a general framework to address these challenges in any table understanding system. We present <span id="S6.p2.1.1" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> which implements this framework. To accomplish model customization, we leverage feedback and use the data programming by demonstration framework to infer labeling functions from data used to generate new training data and prediction functions. <span id="S6.p2.1.2" class="ltx_text ltx_font_smallcaps">SigmaTyper</span> is trained on data common in enterprise data warehouses and implements a hybrid and adaptive model and detects out-of-distribution data.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">The framework introduces many avenues for future research. We are particularly interested in methods to adapt and enrich models based on the userâ€™s explicit feedback and implicit signals. Besides the adaptive capabilities for table understanding models, we need to better understand how to best represent tables and develop models accordingly.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Auer etÂ al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2007)</span>
<span class="ltx_bibblock">
SÃ¶ren Auer, Christian
Bizer, Georgi Kobilarov, Jens Lehmann,
Richard Cyganiak, and Zachary Ives.
2007.

</span>
<span class="ltx_bibblock">DBpedia: A nucleus for a web of open data.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">ISWC</em> (2007),
722â€“735.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagavatula
etÂ al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
ChandraÂ Sekhar Bhagavatula,
Thanapon Noraset, and Doug Downey.
2013.

</span>
<span class="ltx_bibblock">Methods for exploring and mining tables on
wikipedia. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM SIGKDD
workshop on interactive data exploration and analytics</em>.
18â€“26.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown
etÂ al<span id="bib.bib4.3.3.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
TomÂ B Brown, Benjamin
Mann, Nick Ryder, Melanie Subbiah,
Jared Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
etÂ al<span id="bib.bib4.4.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.14165</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cafarella etÂ al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Michael Cafarella, Alon
Halevy, Hongrae Lee, Jayant Madhavan,
Cong Yu, DaisyÂ Zhe Wang, and
Eugene Wu. 2018.

</span>
<span class="ltx_bibblock">Ten years of webtables.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em>
11, 12 (2018),
2140â€“2149.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
etÂ al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Qiaochu Chen, Xinyu Wang,
Xi Ye, Greg Durrett, and
Isil Dillig. 2020.

</span>
<span class="ltx_bibblock">Multi-modal synthesis of regular expressions. In
<em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 41st ACM SIGPLAN Conference on
Programming Language Design and Implementation</em>. 487â€“502.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chu etÂ al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Xu Chu, John Morcos,
IhabÂ F Ilyas, Mourad Ouzzani,
Paolo Papotti, Nan Tang, and
Yin Ye. 2015.

</span>
<span class="ltx_bibblock">Katara: A data cleaning system powered by knowledge
bases and crowdsourcing. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
2015 ACM SIGMOD international conference on management of data</em>.
1247â€“1261.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng
etÂ al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Jia Deng, AlexanderÂ C
Berg, Kai Li, and Li Fei-Fei.
2010.

</span>
<span class="ltx_bibblock">What does classifying more than 10,000 image
categories tell us?. In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">European conference on
computer vision</em>. Springer, 71â€“84.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng
etÂ al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun,
Alyssa Lees, You Wu, and
Cong Yu. 2020.

</span>
<span class="ltx_bibblock">TURL: Table Understanding through
Representation Learning.

</span>
<span class="ltx_bibblock">14, 3 (Nov.
2020), 307â€“319.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin
etÂ al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding. In
<em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, Volume 1</em>. 4171â€“4186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhamija
etÂ al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
AkshayÂ Raj Dhamija, Manuel
GÃ¼nther, and TerranceÂ E Boult.
2018.

</span>
<span class="ltx_bibblock">Reducing network agnostophobia. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd International Conference on
Neural Information Processing Systems</em>. 9175â€“9186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dibia and
Demiralp (2019)</span>
<span class="ltx_bibblock">
Victor Dibia and
Ã‡aÄŸatay Demiralp.
2019.

</span>
<span class="ltx_bibblock">Data2vis: Automatic generation of data
visualizations using sequence-to-sequence recurrent neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE computer graphics and applications</em>
39, 5 (2019),
33â€“46.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Evensen
etÂ al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sara Evensen, Chang Ge,
Dongjin Choi, and Ã‡aÄŸatay
Demiralp. 2020.

</span>
<span class="ltx_bibblock">Data Programming by Demonstration: A Framework for
Interactively Learning Labeling Functions.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.01444</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google (2021)</span>
<span class="ltx_bibblock">
Google. 2021.

</span>
<span class="ltx_bibblock">Google â€” Dverview Studio.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://developers.google.com/datastudio/connector/reference#semantictype" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://developers.google.com/datastudio/connector/reference#semantictype</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha
etÂ al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
RamanathanÂ V Guha, Dan
Brickley, and Steve Macbeth.
2016.

</span>
<span class="ltx_bibblock">Schema. org: evolution of structured data on the
web.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 59,
2 (2016), 44â€“51.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig etÂ al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Thomas
MÃ¼ller, Syrine Krichene, and
JulianÂ Martin Eisenschlos.
2021.

</span>
<span class="ltx_bibblock">Open Domain Question Answering over Tables via
Dense Retrieval.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.12011</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig etÂ al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig,
PawelÂ Krzysztof Nowak, Thomas Mueller,
Francesco Piccinno, and Julian
Eisenschlos. 2020.

</span>
<span class="ltx_bibblock">TaPas: Weakly Supervised Table Parsing via
Pre-training. In <em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">ACL</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu
etÂ al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kevin Hu, MichielÂ A
Bakker, Stephen Li, Tim Kraska, and
CÃ©sar Hidalgo. 2019.

</span>
<span class="ltx_bibblock">Vizml: A machine learning approach to visualization
recommendation. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI
Conference on Human Factors in Computing Systems</em>. 1â€“12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hulsebos
etÂ al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Madelon Hulsebos,
Ã‡aÄŸatay Demiralp, and Paul
Groth. 2021.

</span>
<span class="ltx_bibblock">GitTables: A Large-Scale Corpus of Relational
Tables.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.07258</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hulsebos etÂ al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Madelon Hulsebos, Kevin
Hu, Michiel Bakker, Emanuel Zgraggen,
Arvind Satyanarayan, Tim Kraska,
Ã‡agatay Demiralp, and CÃ©sar
Hidalgo. 2019.

</span>
<span class="ltx_bibblock">Sherlock: A deep learning approach to semantic data
type detection. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>.
1500â€“1508.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iida
etÂ al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hiroshi Iida, Dung Thai,
Varun Manjunatha, and Mohit Iyyer.
2021.

</span>
<span class="ltx_bibblock">TABBIE: Pretrained Representations of Tabular
Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.02584</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joachims and
Radlinski (2007)</span>
<span class="ltx_bibblock">
Thorsten Joachims and
Filip Radlinski. 2007.

</span>
<span class="ltx_bibblock">Search engines that learn from implicit feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Computer</em> 40,
8 (2007), 34â€“40.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joulin etÂ al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Armand Joulin, Edouard
Grave, Piotr Bojanowski, Matthijs Douze,
HÃ©rve JÃ©gou, and Tomas
Mikolov. 2016.

</span>
<span class="ltx_bibblock">Fasttext. zip: Compressing text classification
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1612.03651</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kouw and Loog (2018)</span>
<span class="ltx_bibblock">
WouterÂ M Kouw and Marco
Loog. 2018.

</span>
<span class="ltx_bibblock">An introduction to domain adaptation and transfer
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.11806</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lample and
Conneau (2019)</span>
<span class="ltx_bibblock">
Guillaume Lample and
Alexis Conneau. 2019.

</span>
<span class="ltx_bibblock">Cross-lingual language model pretraining.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1901.07291</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Langenecker etÂ al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sven Langenecker,
Christoph Sturm, Christian Schalles,
and Carsten Binnig. 2021.

</span>
<span class="ltx_bibblock">Towards Learned Metadata Extraction for Data
Lakes.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">BTW 2021</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lieberman (2001)</span>
<span class="ltx_bibblock">
Henry Lieberman.
2001.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Your wish is my command: Programming by
example</em>.

</span>
<span class="ltx_bibblock">Morgan Kaufmann.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pujara
etÂ al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jay Pujara, Pedro
Szekely, Huan Sun, and Muhao Chen.
2021.

</span>
<span class="ltx_bibblock">From Tables to Knowledge: Recent Advances in Table
Understanding. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM
SIGKDD Conference on Knowledge Discovery &amp; Data Mining</em> (Virtual Event,
Singapore) <em id="bib.bib28.4.2" class="ltx_emph ltx_font_italic">(KDD â€™21)</em>.
Association for Computing Machinery,
4060â€“4061.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabanser
etÂ al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Stephan Rabanser, Stephan
GÃ¼nnemann, and ZacharyÂ C Lipton.
2018.

</span>
<span class="ltx_bibblock">Failing loudly: An empirical study of methods for
detecting dataset shift.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.11953</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ratner
etÂ al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
AlexanderÂ J Ratner,
ChristopherÂ M DeÂ Sa, Sen Wu,
Daniel Selsam, and Christopher RÃ©.
2016.

</span>
<span class="ltx_bibblock">Data programming: Creating large training sets,
quickly.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 29 (2016),
3567â€“3575.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddy
etÂ al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Revanth Reddy, Rahul
Ramesh, Ameet Deshpande, and MiteshÂ M
Khapra. 2019.

</span>
<span class="ltx_bibblock">Figurenet: A deep learning model for
question-answering on scientific plots. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">2019
International Joint Conference on Neural Networks (IJCNN)</em>. IEEE,
1â€“8.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stonebraker etÂ al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Michael Stonebraker,
Daniel Bruckner, IhabÂ F Ilyas,
George Beskales, Mitch Cherniack,
StanleyÂ B Zdonik, Alexander Pagan, and
Shan Xu. 2013.

</span>
<span class="ltx_bibblock">Data Curation at Scale: The Data Tamer System.. In
<em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Cidr</em>, Vol.Â 2013. Citeseer.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stonebraker
etÂ al<span id="bib.bib33.3.3.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Michael Stonebraker,
IhabÂ F Ilyas, etÂ al<span id="bib.bib33.4.1" class="ltx_text">.</span>
2018.

</span>
<span class="ltx_bibblock">Data Integration: The Current Status and the Way
Forward.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.5.1" class="ltx_emph ltx_font_italic">IEEE Data Eng. Bull.</em> 41,
2 (2018), 3â€“9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Superconductive (2020)</span>
<span class="ltx_bibblock">
Superconductive.
2020.

</span>
<span class="ltx_bibblock">Great Expectations: Always know what to expect
from your data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://github.com/great-expectations/great_expectations" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/great-expectations/great_expectations</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suri etÂ al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sahaana Suri, Raghuveer
Chanda, Neslihan Bulut, Pradyumna
Narayana, Yemao Zeng, Peter Bailis,
Sugato Basu, Girija Narlikar,
Christopher RÃ©, and Abishek Sethi.
2020.

</span>
<span class="ltx_bibblock">Leveraging organizational resources to adapt models
to new data modalities.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.09983</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tableau (2021)</span>
<span class="ltx_bibblock">
Tableau. 2021.

</span>
<span class="ltx_bibblock">Tableau.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.tableau.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tableau.com</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talend (2021a)</span>
<span class="ltx_bibblock">
Talend. 2021a.

</span>
<span class="ltx_bibblock">Talend.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.talend.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.talend.com</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talend (2021b)</span>
<span class="ltx_bibblock">
Talend. 2021b.

</span>
<span class="ltx_bibblock">Talend.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://help.talend.com/r/en-US/7.2/studio-user-guide-real-time-big-data-platform/list-of-indexes-and-regex-categories-used-in-semantic-aware-analysis" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://help.talend.com/r/en-US/7.2/studio-user-guide-real-time-big-data-platform/list-of-indexes-and-regex-categories-used-in-semantic-aware-analysis</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tamine-Lechani etÂ al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Lynda Tamine-Lechani,
Mohand Boughanem, and Mariam Daoud.
2010.

</span>
<span class="ltx_bibblock">Evaluation of contextual information retrieval
effectiveness: overview of issues and research.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Knowledge and Information Systems</em>
24, 1 (2010),
1â€“34.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang etÂ al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Nan Tang, Ju Fan,
Fangyi Li, Jianhong Tu,
Xiaoyong Du, Guoliang Li,
Samuel Madden, and Mourad Ouzzani.
2021.

</span>
<span class="ltx_bibblock">RPT: Relational Pre-trained Transformer Is Almost
All You Need towards Democratizing Data Preparation.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em> 14,
8 (2021), 1254â€“1261.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trifacta (2021a)</span>
<span class="ltx_bibblock">
Trifacta.
2012â€“2021a.

</span>
<span class="ltx_bibblock">Trifacta.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.trifacta.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.trifacta.com</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trifacta (2021b)</span>
<span class="ltx_bibblock">
Trifacta.
2021b.

</span>
<span class="ltx_bibblock">Trifacta â€” Overview of the Type System.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://docs.trifacta.com/display/DP/Overview+of+the+Type+System" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.trifacta.com/display/DP/Overview+of+the+Type+System</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, AidanÂ N Gomez,
Åukasz Kaiser, and Illia
Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need. In
<em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em>. 5998â€“6008.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vogelsgesang etÂ al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Adrian Vogelsgesang,
Michael Haubenschild, Jan Finis,
Alfons Kemper, Viktor Leis,
Tobias MÃ¼hlbauer, Thomas Neumann,
and Manuel Then. 2018.

</span>
<span class="ltx_bibblock">Get real: How benchmarks fail to represent the real
world. In <em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop on Testing
Database Systems</em>. 1â€“6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Daheng Wang, Prashant
Shiralkar, Colin Lockard, Binxuan Huang,
XinÂ Luna Dong, and Meng Jiang.
2021b.

</span>
<span class="ltx_bibblock">TCN: Table Convolutional Network for Web Table
Interpretation.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.09460</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
etÂ al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Zhiruo Wang, Haoyu Dong,
Ran Jia, Jia Li, Zhiyi
Fu, Shi Han, and Dongmei Zhang.
2021a.

</span>
<span class="ltx_bibblock">TUTA: Tree-based Transformers for Generally
Structured Table Pre-training. In <em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">KDD</em>.
1780â€“1790.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">WebDataCommons (2021)</span>
<span class="ltx_bibblock">
WebDataCommons.
2021.

</span>
<span class="ltx_bibblock">WDC Web Table Corpus 2012.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://webdatacommons.org/webtables/2012/relationalStatistics.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://webdatacommons.org/webtables/2012/relationalStatistics.html</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin
etÂ al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham
Neubig, Wen-tau Yih, and Sebastian
Riedel. 2020.

</span>
<span class="ltx_bibblock">TaBERT: Pretraining for Joint Understanding of
Textual and Tabular Data. In <em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">ACL</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Dan Zhang, Yoshihiko
Suhara, Jinfeng Li, Madelon Hulsebos,
Ã‡aÄŸatay Demiralp, and
Wang-Chiew Tan. 2020.

</span>
<span class="ltx_bibblock">Sato: contextual semantic type detection in
tables.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em>
13, 12 (2020),
1835â€“1848.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou
etÂ al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mengyu Zhou, Qingtao Li,
Yuejiang Li, Shi Han, and
Dongmei Zhang. 2020.

</span>
<span class="ltx_bibblock">Table2Charts: Learning Shared Representations for
Recommending Charts on Multi-dimensional Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.11015</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou (2021)</span>
<span class="ltx_bibblock">
Zhi-Hua Zhou.
2021.

</span>
<span class="ltx_bibblock">Ensemble learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Machine Learning</em>.
Springer, 181â€“210.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2109.05172" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2109.05173" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2109.05173">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2109.05173" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2109.05174" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 13:58:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
