<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Fine-grained large-scale content recommendations for MSX sellers</title>
<!--Generated on Tue Jul  9 15:40:51 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.06910v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S1" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Large scale semantic matching for content recommendations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS1" title="In 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Prompt engineering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS2" title="In 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Model architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS3" title="In 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Orders of magnitude</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS4" title="In 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Run-time performance optimization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Relevance/performance evaluation of the recommendations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.SS1" title="In 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Human expert evaluation and cross-encoder scores as a proxy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.SS2" title="In 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Ablation study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.SS3" title="In 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>LLM as a judge</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S4" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Integration in MSX</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S5" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S6" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Acknowledgements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#A1" title="In Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix on MSX integration</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Fine-grained large-scale content recommendations for MSX sellers</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">One of the most critical tasks of Microsoft sellers is to meticulously track and nurture potential business opportunities through proactive engagement and tailored solutions. Recommender systems play a central role to help sellers achieve their goals. In this paper, we present a content recommendation model which surfaces various types of content (technical documentation, comparison with competitor products, customer success stories etc.) that sellers can share with their customers or use for their own self-learning. The model operates at the opportunity level which is the lowest possible granularity and the most relevant one for sellers. It is based on semantic matching between metadata from the contents and carefully selected attributes of the opportunities. Considering the volume of seller-managed opportunities in organizations such as Microsoft, we show how to perform efficient semantic matching over a very large number of opportunity-content combinations. The main challenge is to ensure that the top-5 relevant contents for each opportunity are recommended out of a total of <math alttext="\approx 40,000" class="ltx_Math" display="inline" id="id1.1.m1.2"><semantics id="id1.1.m1.2a"><mrow id="id1.1.m1.2.3" xref="id1.1.m1.2.3.cmml"><mi id="id1.1.m1.2.3.2" xref="id1.1.m1.2.3.2.cmml"></mi><mo id="id1.1.m1.2.3.1" xref="id1.1.m1.2.3.1.cmml">≈</mo><mrow id="id1.1.m1.2.3.3.2" xref="id1.1.m1.2.3.3.1.cmml"><mn id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">40</mn><mo id="id1.1.m1.2.3.3.2.1" xref="id1.1.m1.2.3.3.1.cmml">,</mo><mn id="id1.1.m1.2.2" xref="id1.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.2b"><apply id="id1.1.m1.2.3.cmml" xref="id1.1.m1.2.3"><approx id="id1.1.m1.2.3.1.cmml" xref="id1.1.m1.2.3.1"></approx><csymbol cd="latexml" id="id1.1.m1.2.3.2.cmml" xref="id1.1.m1.2.3.2">absent</csymbol><list id="id1.1.m1.2.3.3.1.cmml" xref="id1.1.m1.2.3.3.2"><cn id="id1.1.m1.1.1.cmml" type="integer" xref="id1.1.m1.1.1">40</cn><cn id="id1.1.m1.2.2.cmml" type="integer" xref="id1.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.2c">\approx 40,000</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.2d">≈ 40 , 000</annotation></semantics></math> published contents. We achieve this target through an extensive comparison of different model architectures and feature selection. Finally, we further examine the quality of the recommendations in a quantitative manner using a combination of human domain experts as well as by using the recently proposed “LLM as a judge” framework.</p>
<p class="ltx_p" id="id2.id1"><span class="ltx_text ltx_font_bold" id="id2.id1.1">Keywords:</span> MSX Opportunity, Seismic Contents, Semantic matching, Content Recommendation, BERT models</p>
</div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1">Manpreet Singh
Ravdeep Pasricha
Ravi Prasad Kondapalli
Kiran R
Nitish Singh
Akshita Agarwalla
Manoj R
Manish Prabhakar
Laurent Boué</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In large software organizations, sellers have to nurture, cultivate and maintain relationships with a large ecosystem of partners, customers and dependent stakeholders. At Microsoft, sellers use the Microsoft Sellers Experience - MSX tool to navigate this intricate landscape. Recently, more and more Copilot-inspired systems have been integrated into MSX to help guide sellers and improve their productivity. However, there had not yet been solutions that operate at the lowest level of granularity that sellers work at on a daily basis: the opportunity level.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In a CRM system, an “opportunity” refers to a potential revenue-generating event or transaction that arises during the course of managing customer relationships. It represents a chance for a business to convert a lead into a customer, close a deal, or expand its services to an existing customer. Opportunities are pivotal moments in the sales process that require careful nurturing and management to maximize the likelihood of success. Sharing the right content with the customer at each sales stage is one of the key factors that helps in moving the opportunity to the next stage. It is important to share only a few but relevant documents (pitch decks, customer success stories, battle cards to show the comparison with competitors…) with the customer to help them quickly understand the value of Microsoft products.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper, we show how we have built an opportunity-level recommender system whose purpose is to present the sellers with the top-5 technical documents drawn from the Seismic content repository <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib1" title="">seismic, </a>)</cite> to increase the sale velocity. Comprising of a very large catalog of technical documentation, product descriptions, customer success stories and more, Seismic is a leading content management system widely used across businesses to manage their digital content. In our case, we consider a catalog of approximately <math alttext="\approx 40,000" class="ltx_Math" display="inline" id="S1.p3.1.m1.2"><semantics id="S1.p3.1.m1.2a"><mrow id="S1.p3.1.m1.2.3" xref="S1.p3.1.m1.2.3.cmml"><mi id="S1.p3.1.m1.2.3.2" xref="S1.p3.1.m1.2.3.2.cmml"></mi><mo id="S1.p3.1.m1.2.3.1" xref="S1.p3.1.m1.2.3.1.cmml">≈</mo><mrow id="S1.p3.1.m1.2.3.3.2" xref="S1.p3.1.m1.2.3.3.1.cmml"><mn id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">40</mn><mo id="S1.p3.1.m1.2.3.3.2.1" xref="S1.p3.1.m1.2.3.3.1.cmml">,</mo><mn id="S1.p3.1.m1.2.2" xref="S1.p3.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.2b"><apply id="S1.p3.1.m1.2.3.cmml" xref="S1.p3.1.m1.2.3"><approx id="S1.p3.1.m1.2.3.1.cmml" xref="S1.p3.1.m1.2.3.1"></approx><csymbol cd="latexml" id="S1.p3.1.m1.2.3.2.cmml" xref="S1.p3.1.m1.2.3.2">absent</csymbol><list id="S1.p3.1.m1.2.3.3.1.cmml" xref="S1.p3.1.m1.2.3.3.2"><cn id="S1.p3.1.m1.1.1.cmml" type="integer" xref="S1.p3.1.m1.1.1">40</cn><cn id="S1.p3.1.m1.2.2.cmml" type="integer" xref="S1.p3.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.2c">\approx 40,000</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.2d">≈ 40 , 000</annotation></semantics></math> unique documents. Since those documents are decided upon within the context of a specific opportunity, the goal is that they can be shared by the sellers to their customers in order to move the opportunity towards closure in a more targeted manner. Other than a simple rule-based engine which surfaces too many contents, sellers do not currently have any automated guidance as to which Seismic documents would be good candidates to share with their clients.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We start in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2" title="2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">2</span></a> by discussing how we have formulated the recommender system as a form of semantic matching between opportunities and Seismic documents. Due to the large volume of opportunities, we discuss how we have designed our solution for large-scale semantic matching. Next, we discuss in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3" title="3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">3</span></a> how we evaluate the quality of the recommendations using a mixture of different techniques to alleviate the fact that there is no ground-truth data. Finally, we illustrate in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S4" title="4 Integration in MSX ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">4</span></a> how our solution has been integrated into MSX and is currently being used by real-world Microsoft sellers.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Large scale semantic matching for content recommendations</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">As mentioned in the introduction, the objective of this work is to recommend relevant Seismic documents given the context of a specific MSX opportunity.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">With the democratization of large language models, semantic search has become a well-established technique and we describe in this section how the recommender model can be formulated in these terms. Generally, this formulation differs from traditional recommender systems <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib2" title="">traditionalReco, </a>)</cite> that rely on user-item interactions to make predictions. Collaborative filtering and nearest-neighbor methods analyze users’ behavior and preferences to find similarities and identify recommendations. In contrast, our formulation as a semantic matching method relies on natural language understanding of the description of the Seismic documents and of the sellers.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Prompt engineering</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">To achieve this we follow the approach initiated in <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite> where it was shown that it is possible to produce high-quality recommendations between Seismic documents and the end user of the recommendations. In this previous study, the end user was a real time chatbot conversation agent whereas here it is the context associated with specific opportunity. We use the same technique for metadata prompt engineering based on metadata of the Seismic documents and metadata of the opportunities. Essentially, the idea boils down to summarizing the Seismic documents and the opportunities into a short text-based description that contains the most important attributes.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">In case of Seismic documents we use features like “name”, “description”, “solution area”, “product” etc. Similarly for opportunities we look those features which may match those of the Seismic documents as much as possible. By using features which are common on both sides of the semantic matching, we maximize the chance of successful recommendations. The idea is to capture the most common features on both sides so that the language model based embeddings provide relevant documents for opportunities. More details about the architecture can be found in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS2" title="2.2 Model architecture ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">2.2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Model architecture</h3>
<figure class="ltx_figure" id="S2.F1">
<p class="ltx_p ltx_align_center ltx_align_center" id="S2.F1.1.1"><span class="ltx_text" id="S2.F1.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="535" id="S2.F1.1.1.1.g1" src="extracted/5720501/Figs/modelArchitecture.png" width="1017"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S2.F1.10.1">Top)</span> Seismic documents are summarized into textual descriptions, referred to as “content prompts” based on their metadata. These prompts are then run through a <span class="ltx_text ltx_font_typewriter" id="S2.F1.11.2">DistillBERT</span> language model <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib4" title="">sanh2019distilbert, </a>)</cite> (pre-trained on <span class="ltx_text ltx_font_typewriter" id="S2.F1.12.3">MSMarco</span> dataset). Those embeddings are refreshed on a weekly basis. <span class="ltx_text ltx_font_bold" id="S2.F1.13.4">Bottom)</span> The <math alttext="\delta" class="ltx_Math" display="inline" id="S2.F1.3.3.m1.1"><semantics id="S2.F1.3.3.m1.1b"><mi id="S2.F1.3.3.m1.1.1" xref="S2.F1.3.3.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.F1.3.3.m1.1c"><ci id="S2.F1.3.3.m1.1.1.cmml" xref="S2.F1.3.3.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.3.3.m1.1d">\delta</annotation><annotation encoding="application/x-llamapun" id="S2.F1.3.3.m1.1e">italic_δ</annotation></semantics></math>-opportunities (defined in the main part of the text) are gathered from Nebula <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib5" title="">nebula, </a>)</cite>, which is an in-house ETL system developed by the SPS team. Next, the opportunity prompt (summarized attributes of the opportunity into a textual prompt in a manner similar to content prompts) is run through the same <span class="ltx_text ltx_font_typewriter" id="S2.F1.14.5">DistillBERT</span> language model and compared to content embeddings to generate a list of top-50 candidate documents. Those candidates are re-ranked using the <span class="ltx_text ltx_font_typewriter" id="S2.F1.15.6">MSMarco MiniLM</span> pre-trained cross-encoder. Finally, the top-5 results for each opportunity are stored in ADLS from where the Nebula insights pipeline pushes the results to a Cosmos database. The .NET API then pulls the recommended Seismic documents per opportunity from Cosmos and displays it in the UI (see Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S4" title="4 Integration in MSX ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">4</span></a>).</figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The architecture of the model itself is inspired by the one designed for the real-time Copilot recommender system previously developed and already deployed in MSX production <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">The idea consists of leveraging a 2-stage system for fast (but slightly inaccurate) retrieval of the top-50 relevant documents (for each opportunity) followed by a much slower step of re-ranking using a cross-encoder model. Generally, both language models are pre-trained on the <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.1">MS MARCO</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib6" title="">bajaj2016ms, </a>)</cite> which is known to produce good embeddings for these types of question-answering systems. For more technical details regarding the data flow, we refer the reader to Fig. <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.F1" title="Figure 1 ‣ 2.2 Model architecture ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">1</span></a> and to <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite> for the choice of parameters. One important difference from the Copilot model of <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite> is that the current model is delivered in a daily-refreshed batch mode instead of real-time.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Because of the volume of opportunities for which the recommender system is making predictions, we have decomposed the operations of the model into three distinct parts:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">A one-time pre-population of the recommendations for the entire dataset of <math alttext="\approx 700,000" class="ltx_Math" display="inline" id="S2.I1.i1.p1.1.m1.2"><semantics id="S2.I1.i1.p1.1.m1.2a"><mrow id="S2.I1.i1.p1.1.m1.2.3" xref="S2.I1.i1.p1.1.m1.2.3.cmml"><mi id="S2.I1.i1.p1.1.m1.2.3.2" xref="S2.I1.i1.p1.1.m1.2.3.2.cmml"></mi><mo id="S2.I1.i1.p1.1.m1.2.3.1" xref="S2.I1.i1.p1.1.m1.2.3.1.cmml">≈</mo><mrow id="S2.I1.i1.p1.1.m1.2.3.3.2" xref="S2.I1.i1.p1.1.m1.2.3.3.1.cmml"><mn id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">700</mn><mo id="S2.I1.i1.p1.1.m1.2.3.3.2.1" xref="S2.I1.i1.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S2.I1.i1.p1.1.m1.2.2" xref="S2.I1.i1.p1.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.2b"><apply id="S2.I1.i1.p1.1.m1.2.3.cmml" xref="S2.I1.i1.p1.1.m1.2.3"><approx id="S2.I1.i1.p1.1.m1.2.3.1.cmml" xref="S2.I1.i1.p1.1.m1.2.3.1"></approx><csymbol cd="latexml" id="S2.I1.i1.p1.1.m1.2.3.2.cmml" xref="S2.I1.i1.p1.1.m1.2.3.2">absent</csymbol><list id="S2.I1.i1.p1.1.m1.2.3.3.1.cmml" xref="S2.I1.i1.p1.1.m1.2.3.3.2"><cn id="S2.I1.i1.p1.1.m1.1.1.cmml" type="integer" xref="S2.I1.i1.p1.1.m1.1.1">700</cn><cn id="S2.I1.i1.p1.1.m1.2.2.cmml" type="integer" xref="S2.I1.i1.p1.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.2c">\approx 700,000</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.1.m1.2d">≈ 700 , 000</annotation></semantics></math> opportunities representing the last 6 quarters of open opportunities.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.3">A daily batch-mode refresh of the <math alttext="\delta" class="ltx_Math" display="inline" id="S2.I1.i2.p1.1.m1.1"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i2.p1.1.m1.1d">italic_δ</annotation></semantics></math>-opportunities. Opportunities are classified as <math alttext="\delta" class="ltx_Math" display="inline" id="S2.I1.i2.p1.2.m2.1"><semantics id="S2.I1.i2.p1.2.m2.1a"><mi id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><ci id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i2.p1.2.m2.1d">italic_δ</annotation></semantics></math>-opportunities if they are net-new opportunities or if some critical properties have changed in the last 24 hours since the last refresh <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In our case, those properties are opportunityId, opportunityname, salesplay, salesstagename, primaryproduct, segment, areaname.</span></span></span>. In practice, we deal with <math alttext="\approx 10,000" class="ltx_Math" display="inline" id="S2.I1.i2.p1.3.m3.2"><semantics id="S2.I1.i2.p1.3.m3.2a"><mrow id="S2.I1.i2.p1.3.m3.2.3" xref="S2.I1.i2.p1.3.m3.2.3.cmml"><mi id="S2.I1.i2.p1.3.m3.2.3.2" xref="S2.I1.i2.p1.3.m3.2.3.2.cmml"></mi><mo id="S2.I1.i2.p1.3.m3.2.3.1" xref="S2.I1.i2.p1.3.m3.2.3.1.cmml">≈</mo><mrow id="S2.I1.i2.p1.3.m3.2.3.3.2" xref="S2.I1.i2.p1.3.m3.2.3.3.1.cmml"><mn id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml">10</mn><mo id="S2.I1.i2.p1.3.m3.2.3.3.2.1" xref="S2.I1.i2.p1.3.m3.2.3.3.1.cmml">,</mo><mn id="S2.I1.i2.p1.3.m3.2.2" xref="S2.I1.i2.p1.3.m3.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.2b"><apply id="S2.I1.i2.p1.3.m3.2.3.cmml" xref="S2.I1.i2.p1.3.m3.2.3"><approx id="S2.I1.i2.p1.3.m3.2.3.1.cmml" xref="S2.I1.i2.p1.3.m3.2.3.1"></approx><csymbol cd="latexml" id="S2.I1.i2.p1.3.m3.2.3.2.cmml" xref="S2.I1.i2.p1.3.m3.2.3.2">absent</csymbol><list id="S2.I1.i2.p1.3.m3.2.3.3.1.cmml" xref="S2.I1.i2.p1.3.m3.2.3.3.2"><cn id="S2.I1.i2.p1.3.m3.1.1.cmml" type="integer" xref="S2.I1.i2.p1.3.m3.1.1">10</cn><cn id="S2.I1.i2.p1.3.m3.2.2.cmml" type="integer" xref="S2.I1.i2.p1.3.m3.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.2c">\approx 10,000</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i2.p1.3.m3.2d">≈ 10 , 000</annotation></semantics></math> such opportunities on a daily basis.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">Furthermore, in order to keep up with changes in the Seismic catalog, we refresh the content embeddings on a weekly cadence. The embeddings are stored in ADLS but brought up to memory in an Azure Databricks Spark cluster for the daily opportunity refresh. This activity is a separate module and its frequency can be increased as required.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Orders of magnitude</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Let us now turn our attention to the another aspect related to the scale of the semantic search at play here.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.4">On one hand, the total number of opportunities with “open status” in FY23 and FY24 (i.e. last rolling 6 quarters) is <math alttext="\approx 700,000" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.2"><semantics id="S2.SS3.p2.1.m1.2a"><mrow id="S2.SS3.p2.1.m1.2.3" xref="S2.SS3.p2.1.m1.2.3.cmml"><mi id="S2.SS3.p2.1.m1.2.3.2" xref="S2.SS3.p2.1.m1.2.3.2.cmml"></mi><mo id="S2.SS3.p2.1.m1.2.3.1" xref="S2.SS3.p2.1.m1.2.3.1.cmml">≈</mo><mrow id="S2.SS3.p2.1.m1.2.3.3.2" xref="S2.SS3.p2.1.m1.2.3.3.1.cmml"><mn id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">700</mn><mo id="S2.SS3.p2.1.m1.2.3.3.2.1" xref="S2.SS3.p2.1.m1.2.3.3.1.cmml">,</mo><mn id="S2.SS3.p2.1.m1.2.2" xref="S2.SS3.p2.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.2b"><apply id="S2.SS3.p2.1.m1.2.3.cmml" xref="S2.SS3.p2.1.m1.2.3"><approx id="S2.SS3.p2.1.m1.2.3.1.cmml" xref="S2.SS3.p2.1.m1.2.3.1"></approx><csymbol cd="latexml" id="S2.SS3.p2.1.m1.2.3.2.cmml" xref="S2.SS3.p2.1.m1.2.3.2">absent</csymbol><list id="S2.SS3.p2.1.m1.2.3.3.1.cmml" xref="S2.SS3.p2.1.m1.2.3.3.2"><cn id="S2.SS3.p2.1.m1.1.1.cmml" type="integer" xref="S2.SS3.p2.1.m1.1.1">700</cn><cn id="S2.SS3.p2.1.m1.2.2.cmml" type="integer" xref="S2.SS3.p2.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.2c">\approx 700,000</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.2d">≈ 700 , 000</annotation></semantics></math>. On the other hand, the total number of published documents is <math alttext="\approx 40,000" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.2"><semantics id="S2.SS3.p2.2.m2.2a"><mrow id="S2.SS3.p2.2.m2.2.3" xref="S2.SS3.p2.2.m2.2.3.cmml"><mi id="S2.SS3.p2.2.m2.2.3.2" xref="S2.SS3.p2.2.m2.2.3.2.cmml"></mi><mo id="S2.SS3.p2.2.m2.2.3.1" xref="S2.SS3.p2.2.m2.2.3.1.cmml">≈</mo><mrow id="S2.SS3.p2.2.m2.2.3.3.2" xref="S2.SS3.p2.2.m2.2.3.3.1.cmml"><mn id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">40</mn><mo id="S2.SS3.p2.2.m2.2.3.3.2.1" xref="S2.SS3.p2.2.m2.2.3.3.1.cmml">,</mo><mn id="S2.SS3.p2.2.m2.2.2" xref="S2.SS3.p2.2.m2.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.2b"><apply id="S2.SS3.p2.2.m2.2.3.cmml" xref="S2.SS3.p2.2.m2.2.3"><approx id="S2.SS3.p2.2.m2.2.3.1.cmml" xref="S2.SS3.p2.2.m2.2.3.1"></approx><csymbol cd="latexml" id="S2.SS3.p2.2.m2.2.3.2.cmml" xref="S2.SS3.p2.2.m2.2.3.2">absent</csymbol><list id="S2.SS3.p2.2.m2.2.3.3.1.cmml" xref="S2.SS3.p2.2.m2.2.3.3.2"><cn id="S2.SS3.p2.2.m2.1.1.cmml" type="integer" xref="S2.SS3.p2.2.m2.1.1">40</cn><cn id="S2.SS3.p2.2.m2.2.2.cmml" type="integer" xref="S2.SS3.p2.2.m2.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.2c">\approx 40,000</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.2d">≈ 40 , 000</annotation></semantics></math>. Naïvely, this means that one should consider all <math alttext="\approx 700,000\times 40,000" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.3"><semantics id="S2.SS3.p2.3.m3.3a"><mrow id="S2.SS3.p2.3.m3.3.3" xref="S2.SS3.p2.3.m3.3.3.cmml"><mi id="S2.SS3.p2.3.m3.3.3.3" xref="S2.SS3.p2.3.m3.3.3.3.cmml"></mi><mo id="S2.SS3.p2.3.m3.3.3.2" xref="S2.SS3.p2.3.m3.3.3.2.cmml">≈</mo><mrow id="S2.SS3.p2.3.m3.3.3.1.1" xref="S2.SS3.p2.3.m3.3.3.1.2.cmml"><mn id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">700</mn><mo id="S2.SS3.p2.3.m3.3.3.1.1.2" xref="S2.SS3.p2.3.m3.3.3.1.2.cmml">,</mo><mrow id="S2.SS3.p2.3.m3.3.3.1.1.1" xref="S2.SS3.p2.3.m3.3.3.1.1.1.cmml"><mn id="S2.SS3.p2.3.m3.3.3.1.1.1.2" xref="S2.SS3.p2.3.m3.3.3.1.1.1.2.cmml">000</mn><mo id="S2.SS3.p2.3.m3.3.3.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p2.3.m3.3.3.1.1.1.1.cmml">×</mo><mn id="S2.SS3.p2.3.m3.3.3.1.1.1.3" xref="S2.SS3.p2.3.m3.3.3.1.1.1.3.cmml">40</mn></mrow><mo id="S2.SS3.p2.3.m3.3.3.1.1.3" xref="S2.SS3.p2.3.m3.3.3.1.2.cmml">,</mo><mn id="S2.SS3.p2.3.m3.2.2" xref="S2.SS3.p2.3.m3.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.3b"><apply id="S2.SS3.p2.3.m3.3.3.cmml" xref="S2.SS3.p2.3.m3.3.3"><approx id="S2.SS3.p2.3.m3.3.3.2.cmml" xref="S2.SS3.p2.3.m3.3.3.2"></approx><csymbol cd="latexml" id="S2.SS3.p2.3.m3.3.3.3.cmml" xref="S2.SS3.p2.3.m3.3.3.3">absent</csymbol><list id="S2.SS3.p2.3.m3.3.3.1.2.cmml" xref="S2.SS3.p2.3.m3.3.3.1.1"><cn id="S2.SS3.p2.3.m3.1.1.cmml" type="integer" xref="S2.SS3.p2.3.m3.1.1">700</cn><apply id="S2.SS3.p2.3.m3.3.3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.3.3.1.1.1"><times id="S2.SS3.p2.3.m3.3.3.1.1.1.1.cmml" xref="S2.SS3.p2.3.m3.3.3.1.1.1.1"></times><cn id="S2.SS3.p2.3.m3.3.3.1.1.1.2.cmml" type="integer" xref="S2.SS3.p2.3.m3.3.3.1.1.1.2">000</cn><cn id="S2.SS3.p2.3.m3.3.3.1.1.1.3.cmml" type="integer" xref="S2.SS3.p2.3.m3.3.3.1.1.1.3">40</cn></apply><cn id="S2.SS3.p2.3.m3.2.2.cmml" type="integer" xref="S2.SS3.p2.3.m3.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.3c">\approx 700,000\times 40,000</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.3d">≈ 700 , 000 × 40 , 000</annotation></semantics></math> opportunity-content pairs. This would result in <math alttext="\approx 28\times 10^{9}" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m4.1"><semantics id="S2.SS3.p2.4.m4.1a"><mrow id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><mi id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml"></mi><mo id="S2.SS3.p2.4.m4.1.1.1" xref="S2.SS3.p2.4.m4.1.1.1.cmml">≈</mo><mrow id="S2.SS3.p2.4.m4.1.1.3" xref="S2.SS3.p2.4.m4.1.1.3.cmml"><mn id="S2.SS3.p2.4.m4.1.1.3.2" xref="S2.SS3.p2.4.m4.1.1.3.2.cmml">28</mn><mo id="S2.SS3.p2.4.m4.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p2.4.m4.1.1.3.1.cmml">×</mo><msup id="S2.SS3.p2.4.m4.1.1.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.cmml"><mn id="S2.SS3.p2.4.m4.1.1.3.3.2" xref="S2.SS3.p2.4.m4.1.1.3.3.2.cmml">10</mn><mn id="S2.SS3.p2.4.m4.1.1.3.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.3.cmml">9</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><approx id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1.1"></approx><csymbol cd="latexml" id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">absent</csymbol><apply id="S2.SS3.p2.4.m4.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3"><times id="S2.SS3.p2.4.m4.1.1.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3.1"></times><cn id="S2.SS3.p2.4.m4.1.1.3.2.cmml" type="integer" xref="S2.SS3.p2.4.m4.1.1.3.2">28</cn><apply id="S2.SS3.p2.4.m4.1.1.3.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3">superscript</csymbol><cn id="S2.SS3.p2.4.m4.1.1.3.3.2.cmml" type="integer" xref="S2.SS3.p2.4.m4.1.1.3.3.2">10</cn><cn id="S2.SS3.p2.4.m4.1.1.3.3.3.cmml" type="integer" xref="S2.SS3.p2.4.m4.1.1.3.3.3">9</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">\approx 28\times 10^{9}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m4.1d">≈ 28 × 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT</annotation></semantics></math> combinations. Clearly, one must introduce some filters in order to reduce this large number of combinations.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.3">In the following, we use three features (“sales stage”, “area” and “solution area”) as filters. This allows us to reduce the content search space to roughly <math alttext="\approx 7,000" class="ltx_Math" display="inline" id="S2.SS3.p3.1.m1.2"><semantics id="S2.SS3.p3.1.m1.2a"><mrow id="S2.SS3.p3.1.m1.2.3" xref="S2.SS3.p3.1.m1.2.3.cmml"><mi id="S2.SS3.p3.1.m1.2.3.2" xref="S2.SS3.p3.1.m1.2.3.2.cmml"></mi><mo id="S2.SS3.p3.1.m1.2.3.1" xref="S2.SS3.p3.1.m1.2.3.1.cmml">≈</mo><mrow id="S2.SS3.p3.1.m1.2.3.3.2" xref="S2.SS3.p3.1.m1.2.3.3.1.cmml"><mn id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">7</mn><mo id="S2.SS3.p3.1.m1.2.3.3.2.1" xref="S2.SS3.p3.1.m1.2.3.3.1.cmml">,</mo><mn id="S2.SS3.p3.1.m1.2.2" xref="S2.SS3.p3.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.2b"><apply id="S2.SS3.p3.1.m1.2.3.cmml" xref="S2.SS3.p3.1.m1.2.3"><approx id="S2.SS3.p3.1.m1.2.3.1.cmml" xref="S2.SS3.p3.1.m1.2.3.1"></approx><csymbol cd="latexml" id="S2.SS3.p3.1.m1.2.3.2.cmml" xref="S2.SS3.p3.1.m1.2.3.2">absent</csymbol><list id="S2.SS3.p3.1.m1.2.3.3.1.cmml" xref="S2.SS3.p3.1.m1.2.3.3.2"><cn id="S2.SS3.p3.1.m1.1.1.cmml" type="integer" xref="S2.SS3.p3.1.m1.1.1">7</cn><cn id="S2.SS3.p3.1.m1.2.2.cmml" type="integer" xref="S2.SS3.p3.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.2c">\approx 7,000</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.1.m1.2d">≈ 7 , 000</annotation></semantics></math> Seismic documents. Now we have <math alttext="\approx 5\times 10^{9}" class="ltx_Math" display="inline" id="S2.SS3.p3.2.m2.1"><semantics id="S2.SS3.p3.2.m2.1a"><mrow id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml"><mi id="S2.SS3.p3.2.m2.1.1.2" xref="S2.SS3.p3.2.m2.1.1.2.cmml"></mi><mo id="S2.SS3.p3.2.m2.1.1.1" xref="S2.SS3.p3.2.m2.1.1.1.cmml">≈</mo><mrow id="S2.SS3.p3.2.m2.1.1.3" xref="S2.SS3.p3.2.m2.1.1.3.cmml"><mn id="S2.SS3.p3.2.m2.1.1.3.2" xref="S2.SS3.p3.2.m2.1.1.3.2.cmml">5</mn><mo id="S2.SS3.p3.2.m2.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p3.2.m2.1.1.3.1.cmml">×</mo><msup id="S2.SS3.p3.2.m2.1.1.3.3" xref="S2.SS3.p3.2.m2.1.1.3.3.cmml"><mn id="S2.SS3.p3.2.m2.1.1.3.3.2" xref="S2.SS3.p3.2.m2.1.1.3.3.2.cmml">10</mn><mn id="S2.SS3.p3.2.m2.1.1.3.3.3" xref="S2.SS3.p3.2.m2.1.1.3.3.3.cmml">9</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.1b"><apply id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1"><approx id="S2.SS3.p3.2.m2.1.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1.1"></approx><csymbol cd="latexml" id="S2.SS3.p3.2.m2.1.1.2.cmml" xref="S2.SS3.p3.2.m2.1.1.2">absent</csymbol><apply id="S2.SS3.p3.2.m2.1.1.3.cmml" xref="S2.SS3.p3.2.m2.1.1.3"><times id="S2.SS3.p3.2.m2.1.1.3.1.cmml" xref="S2.SS3.p3.2.m2.1.1.3.1"></times><cn id="S2.SS3.p3.2.m2.1.1.3.2.cmml" type="integer" xref="S2.SS3.p3.2.m2.1.1.3.2">5</cn><apply id="S2.SS3.p3.2.m2.1.1.3.3.cmml" xref="S2.SS3.p3.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS3.p3.2.m2.1.1.3.3.1.cmml" xref="S2.SS3.p3.2.m2.1.1.3.3">superscript</csymbol><cn id="S2.SS3.p3.2.m2.1.1.3.3.2.cmml" type="integer" xref="S2.SS3.p3.2.m2.1.1.3.3.2">10</cn><cn id="S2.SS3.p3.2.m2.1.1.3.3.3.cmml" type="integer" xref="S2.SS3.p3.2.m2.1.1.3.3.3">9</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.1c">\approx 5\times 10^{9}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.2.m2.1d">≈ 5 × 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT</annotation></semantics></math> combinations reducing the overall computational effort required by <math alttext="\approx 80\%" class="ltx_Math" display="inline" id="S2.SS3.p3.3.m3.1"><semantics id="S2.SS3.p3.3.m3.1a"><mrow id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml"><mi id="S2.SS3.p3.3.m3.1.1.2" xref="S2.SS3.p3.3.m3.1.1.2.cmml"></mi><mo id="S2.SS3.p3.3.m3.1.1.1" xref="S2.SS3.p3.3.m3.1.1.1.cmml">≈</mo><mrow id="S2.SS3.p3.3.m3.1.1.3" xref="S2.SS3.p3.3.m3.1.1.3.cmml"><mn id="S2.SS3.p3.3.m3.1.1.3.2" xref="S2.SS3.p3.3.m3.1.1.3.2.cmml">80</mn><mo id="S2.SS3.p3.3.m3.1.1.3.1" xref="S2.SS3.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.1b"><apply id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1"><approx id="S2.SS3.p3.3.m3.1.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1.1"></approx><csymbol cd="latexml" id="S2.SS3.p3.3.m3.1.1.2.cmml" xref="S2.SS3.p3.3.m3.1.1.2">absent</csymbol><apply id="S2.SS3.p3.3.m3.1.1.3.cmml" xref="S2.SS3.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S2.SS3.p3.3.m3.1.1.3.1.cmml" xref="S2.SS3.p3.3.m3.1.1.3.1">percent</csymbol><cn id="S2.SS3.p3.3.m3.1.1.3.2.cmml" type="integer" xref="S2.SS3.p3.3.m3.1.1.3.2">80</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.1c">\approx 80\%</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.3.m3.1d">≈ 80 %</annotation></semantics></math>. Nonetheless, this still leaves us with multiple billions of combinations to perform so this still remains a very large scale semantic matching problem.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Run-time performance optimization</h3>
<figure class="ltx_figure" id="S2.F2">
<p class="ltx_p ltx_align_center ltx_align_center" id="S2.F2.1.1"><span class="ltx_text" id="S2.F2.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="323" id="S2.F2.1.1.1.g1" src="extracted/5720501/Figs/udf_time_slope.png" width="598"/></span></p>
<br class="ltx_break ltx_break"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of the performance gain by using Pandas UDFs on Azure Databricks Spark clusters. As expected, the processing time grows linearly with the number of opportunities. Further incremental gains may be obtained by increasing the size of the Spark cluster. Note that the number of opportunities is not the same as the number of records processed by the cross-encoder. Consider, for instance, that we have <math alttext="1,000" class="ltx_Math" display="inline" id="S2.F2.4.4.m1.2"><semantics id="S2.F2.4.4.m1.2b"><mrow id="S2.F2.4.4.m1.2.3.2" xref="S2.F2.4.4.m1.2.3.1.cmml"><mn id="S2.F2.4.4.m1.1.1" xref="S2.F2.4.4.m1.1.1.cmml">1</mn><mo id="S2.F2.4.4.m1.2.3.2.1" xref="S2.F2.4.4.m1.2.3.1.cmml">,</mo><mn id="S2.F2.4.4.m1.2.2" xref="S2.F2.4.4.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.4.4.m1.2c"><list id="S2.F2.4.4.m1.2.3.1.cmml" xref="S2.F2.4.4.m1.2.3.2"><cn id="S2.F2.4.4.m1.1.1.cmml" type="integer" xref="S2.F2.4.4.m1.1.1">1</cn><cn id="S2.F2.4.4.m1.2.2.cmml" type="integer" xref="S2.F2.4.4.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.4.m1.2d">1,000</annotation><annotation encoding="application/x-llamapun" id="S2.F2.4.4.m1.2e">1 , 000</annotation></semantics></math> opportunities. In that case, the total number of records processed by cross encoder is <math alttext="50\times 1,000=50,000" class="ltx_Math" display="inline" id="S2.F2.5.5.m2.3"><semantics id="S2.F2.5.5.m2.3b"><mrow id="S2.F2.5.5.m2.3.3.1" xref="S2.F2.5.5.m2.3.3.2.cmml"><mrow id="S2.F2.5.5.m2.3.3.1.1" xref="S2.F2.5.5.m2.3.3.1.1.cmml"><mrow id="S2.F2.5.5.m2.3.3.1.1.1.1" xref="S2.F2.5.5.m2.3.3.1.1.1.2.cmml"><mrow id="S2.F2.5.5.m2.3.3.1.1.1.1.1" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.cmml"><mn id="S2.F2.5.5.m2.3.3.1.1.1.1.1.2" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.2.cmml">50</mn><mo id="S2.F2.5.5.m2.3.3.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.1.cmml">×</mo><mn id="S2.F2.5.5.m2.3.3.1.1.1.1.1.3" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S2.F2.5.5.m2.3.3.1.1.1.1.2" xref="S2.F2.5.5.m2.3.3.1.1.1.2.cmml">,</mo><mn id="S2.F2.5.5.m2.1.1" xref="S2.F2.5.5.m2.1.1.cmml">000</mn></mrow><mo id="S2.F2.5.5.m2.3.3.1.1.2" xref="S2.F2.5.5.m2.3.3.1.1.2.cmml">=</mo><mn id="S2.F2.5.5.m2.3.3.1.1.3" xref="S2.F2.5.5.m2.3.3.1.1.3.cmml">50</mn></mrow><mo id="S2.F2.5.5.m2.3.3.1.2" xref="S2.F2.5.5.m2.3.3.2a.cmml">,</mo><mn id="S2.F2.5.5.m2.2.2" xref="S2.F2.5.5.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.5.5.m2.3c"><apply id="S2.F2.5.5.m2.3.3.2.cmml" xref="S2.F2.5.5.m2.3.3.1"><csymbol cd="ambiguous" id="S2.F2.5.5.m2.3.3.2a.cmml" xref="S2.F2.5.5.m2.3.3.1.2">formulae-sequence</csymbol><apply id="S2.F2.5.5.m2.3.3.1.1.cmml" xref="S2.F2.5.5.m2.3.3.1.1"><eq id="S2.F2.5.5.m2.3.3.1.1.2.cmml" xref="S2.F2.5.5.m2.3.3.1.1.2"></eq><list id="S2.F2.5.5.m2.3.3.1.1.1.2.cmml" xref="S2.F2.5.5.m2.3.3.1.1.1.1"><apply id="S2.F2.5.5.m2.3.3.1.1.1.1.1.cmml" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1"><times id="S2.F2.5.5.m2.3.3.1.1.1.1.1.1.cmml" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.1"></times><cn id="S2.F2.5.5.m2.3.3.1.1.1.1.1.2.cmml" type="integer" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.2">50</cn><cn id="S2.F2.5.5.m2.3.3.1.1.1.1.1.3.cmml" type="integer" xref="S2.F2.5.5.m2.3.3.1.1.1.1.1.3">1</cn></apply><cn id="S2.F2.5.5.m2.1.1.cmml" type="integer" xref="S2.F2.5.5.m2.1.1">000</cn></list><cn id="S2.F2.5.5.m2.3.3.1.1.3.cmml" type="integer" xref="S2.F2.5.5.m2.3.3.1.1.3">50</cn></apply><cn id="S2.F2.5.5.m2.2.2.cmml" type="integer" xref="S2.F2.5.5.m2.2.2">000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.5.5.m2.3d">50\times 1,000=50,000</annotation><annotation encoding="application/x-llamapun" id="S2.F2.5.5.m2.3e">50 × 1 , 000 = 50 , 000</annotation></semantics></math> where the factor of 50 corresponds to the number of candidates retrieved in the first stage before re-ranking.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">In order to reduce the computational complexity, an assumption is to consider opportunities as all independent from each other. (We discuss the limitations associated with this assumption in the conclusion.) Under this assumption, generating recommendations for all the opportunities becomes a fundamentally “embarassingly-parallel” task.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">Simple profiling reveals that it is the cross-encoder re-ranking stage which is overwhelmingly the most time-consuming part of the architecture described in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.F1" title="Figure 1 ‣ 2.2 Model architecture ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">1</span></a>. The total number of records that needs to go through this re-ranking is <math alttext="50\times" class="ltx_math_unparsed" display="inline" id="S2.SS4.p2.1.m1.1"><semantics id="S2.SS4.p2.1.m1.1a"><mrow id="S2.SS4.p2.1.m1.1b"><mn id="S2.SS4.p2.1.m1.1.1">50</mn><mo id="S2.SS4.p2.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">50\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.1.m1.1d">50 ×</annotation></semantics></math> the number of opportunites since we retrieve 50 candidates for each opportunity. Each record is a pair of prompts: a content prompt shortlisted by the bi-encoder retriever and an original opportunity prompt.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">Pandas User Defined Functions - UDFs <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib7" title="">pandasUDF, </a>)</cite> in PySpark are a popular technique to combine complex data transformation pipelines leveraging Python libraries that may not be natively available in Spark with the convenient parallelism offered by workloads on Spark cluster infrastructures. Accordingly, we utilize Pandas UDFs to distribute the computation across on an Azure Databricks cluster. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.F2" title="Figure 2 ‣ 2.4 Run-time performance optimization ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">2</span></a> shows the time taken to process number of opportunities with and without Pandas UDFs. This confirms that Pandas UDFs on Spark clusters lead to a consistent gain in performance.</p>
</div>
<div class="ltx_para" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.2">Note that incremental further gains may be obtained by proportionately increasing the size of the allocated Spark clusters. Using a Spark cluster with 96 vcores as required for production deployment of the model, we have reduced the processing time from <math alttext="\approx 2" class="ltx_Math" display="inline" id="S2.SS4.p4.1.m1.1"><semantics id="S2.SS4.p4.1.m1.1a"><mrow id="S2.SS4.p4.1.m1.1.1" xref="S2.SS4.p4.1.m1.1.1.cmml"><mi id="S2.SS4.p4.1.m1.1.1.2" xref="S2.SS4.p4.1.m1.1.1.2.cmml"></mi><mo id="S2.SS4.p4.1.m1.1.1.1" xref="S2.SS4.p4.1.m1.1.1.1.cmml">≈</mo><mn id="S2.SS4.p4.1.m1.1.1.3" xref="S2.SS4.p4.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b"><apply id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1"><approx id="S2.SS4.p4.1.m1.1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S2.SS4.p4.1.m1.1.1.2.cmml" xref="S2.SS4.p4.1.m1.1.1.2">absent</csymbol><cn id="S2.SS4.p4.1.m1.1.1.3.cmml" type="integer" xref="S2.SS4.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">\approx 2</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.1.m1.1d">≈ 2</annotation></semantics></math>s per opportunity to <math alttext="\approx 90" class="ltx_Math" display="inline" id="S2.SS4.p4.2.m2.1"><semantics id="S2.SS4.p4.2.m2.1a"><mrow id="S2.SS4.p4.2.m2.1.1" xref="S2.SS4.p4.2.m2.1.1.cmml"><mi id="S2.SS4.p4.2.m2.1.1.2" xref="S2.SS4.p4.2.m2.1.1.2.cmml"></mi><mo id="S2.SS4.p4.2.m2.1.1.1" xref="S2.SS4.p4.2.m2.1.1.1.cmml">≈</mo><mn id="S2.SS4.p4.2.m2.1.1.3" xref="S2.SS4.p4.2.m2.1.1.3.cmml">90</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b"><apply id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1"><approx id="S2.SS4.p4.2.m2.1.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1.1"></approx><csymbol cd="latexml" id="S2.SS4.p4.2.m2.1.1.2.cmml" xref="S2.SS4.p4.2.m2.1.1.2">absent</csymbol><cn id="S2.SS4.p4.2.m2.1.1.3.cmml" type="integer" xref="S2.SS4.p4.2.m2.1.1.3">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">\approx 90</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.2.m2.1d">≈ 90</annotation></semantics></math>ms.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Relevance/performance evaluation of the recommendations</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Evaluating the quality of recommender systems without ground-truth data poses a challenge due to the absence of a specific objective criteria for assessment. Consequently, it is common to rely on human experts to provide subjective evaluations. Even though this process does offer valuable insights, it can be prohibitively labor-intensive and costly.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We start in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.SS1" title="3.1 Human expert evaluation and cross-encoder scores as a proxy ‣ 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">3.1</span></a> by preparing a set of evaluation queries completed by 3 human domain experts and show how the cross-encoder scores produced by the model are in good agreement with the scores given by those experts. Next, we carry out in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.SS2" title="3.2 Ablation study ‣ 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">3.2</span></a> an ablation study to investigate the relative importance of the features used in the prompts. Finally, we explore the LLM as a judge framework where GPT-4 is used as an independent evaluator in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.SS3" title="3.3 LLM as a judge ‣ 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Human expert evaluation and cross-encoder scores as a proxy</h3>
<figure class="ltx_figure" id="S3.F3">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F3.1.1"><span class="ltx_text" id="S3.F3.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="331" id="S3.F3.1.1.1.g1" src="extracted/5720501/Figs/proxy_cross_encoder.jpg" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of the good alignment between cross-encoder scores and human judgment with a Pearson correlation coefficient of 0.78. Going beyond linear correlations, we have also estimated a rank-based Spearman’s coefficient of 0.64.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We curated a list of 22 queries to be sent for evaluation by 3 human experts. For each of these queries, the recommended Seismic documents are predicted by the model and the top-5 results are presented to the evaluators who are asked to give them a rating from 0 to 5 (higher is better). Once those scores are provided by the experts, we ask the question of how much does the cross-encoder score align with human judgments.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">As presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.F3" title="Figure 3 ‣ 3.1 Human expert evaluation and cross-encoder scores as a proxy ‣ 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">3</span></a>, we see that there is indeed a strong positive Pearson correlation coefficient of <math alttext="0.78" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">0.78</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><cn id="S3.SS1.p2.1.m1.1.1.cmml" type="float" xref="S3.SS1.p2.1.m1.1.1">0.78</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">0.78</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">0.78</annotation></semantics></math> between the cross-encoder score and the scores produced by human experts (averaged over the 5 recommended items). This agreement is very good to separate bad recommendations from the better ones. This means that the cross-encoder score can realistically be used, at least in a binary classifier manner to quickly identify good vs. bad recommendations. Those can then be processed along towards human experts for further analysis with an improved “triage” time.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">In the absence of ground-truth data, those correlation results based on Pearson and Spearman’s statistics are encouraging. Furthermore, we note that the human reviewers confirmed that the documents they expected to see as a response to their queries consistently showed up in the top-5 recommendations. This gives an indication that the recall rate (although not directly measurable without ground-truth data) is at least acceptable from the stakeholder’s perspective.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Ablation study</h3>
<figure class="ltx_figure" id="S3.F4">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F4.1.1"><span class="ltx_text" id="S3.F4.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="284" id="S3.F4.1.1.1.g1" src="extracted/5720501/Figs/feature_selection.png" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Cross-encoder scores (as returned by the model) vs. each one of the 22 evaluation prompts. The dashed vertical lines represent the different groups <span class="ltx_text ltx_font_bold" id="S3.F4.8.1">A</span>, <span class="ltx_text ltx_font_bold" id="S3.F4.9.2">B</span>, <span class="ltx_text ltx_font_bold" id="S3.F4.10.3">C</span>, and <span class="ltx_text ltx_font_bold" id="S3.F4.11.4">D</span>. As explained in the main part of the text, the low performance of group <span class="ltx_text ltx_font_bold" id="S3.F4.12.5">B</span> indicates the importance of <span class="ltx_text ltx_font_sansserif" id="S3.F4.13.6" style="font-size:90%;">“sales play”<span class="ltx_text ltx_font_serif" id="S3.F4.13.6.1"> as a critical feature.</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Now that we have established cross-encoder scores as a good proxy for human judgment of the relevance of the recommendations, we can use these model-produced scores, to assess the relative importance of the features used in the prompts (see Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS1" title="2.1 Prompt engineering ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">2.1</span></a>). For the purpose of the analysis, we have divided the evaluation queries into 4 groups depending on the features that were used to design the prompts. <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p1.1.1">Crucially</span>, note that the human evaluators were never aware of the underlying division of the queries into 4 groups so this division did not influence their scores (nor were the evaluators aware of the cross-encoder scores).</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We denote by <math alttext="\mathcal{F}_{\cap}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">ℱ</mi><mo id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">∩</mo></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ℱ</ci><intersect id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"></intersect></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{F}_{\cap}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ∩ end_POSTSUBSCRIPT</annotation></semantics></math> the set of 3 features that were used both on the documents as well as on the opportunity prompts:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{F}_{\cap}=\big{\{}\small{\textsf{``sales play'', ``solution area'', `%
`product''}}\big{\}}" class="ltx_Math" display="block" id="S3.Ex1.m1.1"><semantics id="S3.Ex1.m1.1a"><mrow id="S3.Ex1.m1.1.2" xref="S3.Ex1.m1.1.2.cmml"><msub id="S3.Ex1.m1.1.2.2" xref="S3.Ex1.m1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.2.2.2" xref="S3.Ex1.m1.1.2.2.2.cmml">ℱ</mi><mo id="S3.Ex1.m1.1.2.2.3" xref="S3.Ex1.m1.1.2.2.3.cmml">∩</mo></msub><mo id="S3.Ex1.m1.1.2.1" xref="S3.Ex1.m1.1.2.1.cmml">=</mo><mrow id="S3.Ex1.m1.1.2.3.2" xref="S3.Ex1.m1.1.2.3.1.cmml"><mo id="S3.Ex1.m1.1.2.3.2.1" maxsize="120%" minsize="120%" xref="S3.Ex1.m1.1.2.3.1.cmml">{</mo><mtext class="ltx_mathvariant_sans-serif" id="S3.Ex1.m1.1.1" mathsize="90%" xref="S3.Ex1.m1.1.1a.cmml">“sales play”, “solution area”, “product”</mtext><mo id="S3.Ex1.m1.1.2.3.2.2" maxsize="120%" minsize="120%" xref="S3.Ex1.m1.1.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.2.cmml" xref="S3.Ex1.m1.1.2"><eq id="S3.Ex1.m1.1.2.1.cmml" xref="S3.Ex1.m1.1.2.1"></eq><apply id="S3.Ex1.m1.1.2.2.cmml" xref="S3.Ex1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.2.1.cmml" xref="S3.Ex1.m1.1.2.2">subscript</csymbol><ci id="S3.Ex1.m1.1.2.2.2.cmml" xref="S3.Ex1.m1.1.2.2.2">ℱ</ci><intersect id="S3.Ex1.m1.1.2.2.3.cmml" xref="S3.Ex1.m1.1.2.2.3"></intersect></apply><set id="S3.Ex1.m1.1.2.3.1.cmml" xref="S3.Ex1.m1.1.2.3.2"><ci id="S3.Ex1.m1.1.1a.cmml" xref="S3.Ex1.m1.1.1"><mtext class="ltx_mathvariant_sans-serif" id="S3.Ex1.m1.1.1.cmml" mathsize="90%" xref="S3.Ex1.m1.1.1">“sales play”, “solution area”, “product”</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">\mathcal{F}_{\cap}=\big{\{}\small{\textsf{``sales play'', ``solution area'', `%
`product''}}\big{\}}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ∩ end_POSTSUBSCRIPT = { “sales play”, “solution area”, “product” }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p2.2">The 22 evaluation queries are divided into 4 groups consisting of:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.1.1.1">A</span></span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">All members of <math alttext="\mathcal{F}_{\cap}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><msub id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml">ℱ</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml">∩</mo></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">ℱ</ci><intersect id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3"></intersect></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">\mathcal{F}_{\cap}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ∩ end_POSTSUBSCRIPT</annotation></semantics></math> are used in the prompts.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.1.1.1">B</span></span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Remove 1 feature so that features from 
<br class="ltx_break"/><math alttext="\mathcal{F}_{\cap}\setminus\small{\textsf{``sales play''}}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><msub id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i2.p1.1.m1.1.1.2.2" xref="S3.I1.i2.p1.1.m1.1.1.2.2.cmml">ℱ</mi><mo id="S3.I1.i2.p1.1.m1.1.1.2.3" xref="S3.I1.i2.p1.1.m1.1.1.2.3.cmml">∩</mo></msub><mo id="S3.I1.i2.p1.1.m1.1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.1.cmml">∖</mo><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i2.p1.1.m1.1.1.3" mathsize="90%" xref="S3.I1.i2.p1.1.m1.1.1.3a.cmml">“sales play”</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><setdiff id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.1"></setdiff><apply id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2.2">ℱ</ci><intersect id="S3.I1.i2.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2.3"></intersect></apply><ci id="S3.I1.i2.p1.1.m1.1.1.3a.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i2.p1.1.m1.1.1.3.cmml" mathsize="90%" xref="S3.I1.i2.p1.1.m1.1.1.3">“sales play”</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">\mathcal{F}_{\cap}\setminus\small{\textsf{``sales play''}}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ∩ end_POSTSUBSCRIPT ∖ “sales play”</annotation></semantics></math>
<br class="ltx_break"/>are used in the prompts.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.1.1.1">C</span></span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Remove 1 feature so that features from 
<br class="ltx_break"/><math alttext="\mathcal{F}_{\cap}\setminus\small{\textsf{``product''}}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mrow id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml"><msub id="S3.I1.i3.p1.1.m1.1.1.2" xref="S3.I1.i3.p1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i3.p1.1.m1.1.1.2.2" xref="S3.I1.i3.p1.1.m1.1.1.2.2.cmml">ℱ</mi><mo id="S3.I1.i3.p1.1.m1.1.1.2.3" xref="S3.I1.i3.p1.1.m1.1.1.2.3.cmml">∩</mo></msub><mo id="S3.I1.i3.p1.1.m1.1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.1.cmml">∖</mo><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i3.p1.1.m1.1.1.3" mathsize="90%" xref="S3.I1.i3.p1.1.m1.1.1.3a.cmml">“product”</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1"><setdiff id="S3.I1.i3.p1.1.m1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1"></setdiff><apply id="S3.I1.i3.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.I1.i3.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2.2">ℱ</ci><intersect id="S3.I1.i3.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2.3"></intersect></apply><ci id="S3.I1.i3.p1.1.m1.1.1.3a.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i3.p1.1.m1.1.1.3.cmml" mathsize="90%" xref="S3.I1.i3.p1.1.m1.1.1.3">“product”</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">\mathcal{F}_{\cap}\setminus\small{\textsf{``product''}}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ∩ end_POSTSUBSCRIPT ∖ “product”</annotation></semantics></math>
<br class="ltx_break"/>are used in the prompts.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.1.1.1">D</span></span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1">Remove 2 features so that features from 
<br class="ltx_break"/><math alttext="\mathcal{F}_{\cap}\setminus\ \small{\textsf{``solution area''}}\setminus\small%
{\textsf{``product''}}" class="ltx_Math" display="inline" id="S3.I1.i4.p1.1.m1.1"><semantics id="S3.I1.i4.p1.1.m1.1a"><mrow id="S3.I1.i4.p1.1.m1.1.1" xref="S3.I1.i4.p1.1.m1.1.1.cmml"><msub id="S3.I1.i4.p1.1.m1.1.1.2" xref="S3.I1.i4.p1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i4.p1.1.m1.1.1.2.2" xref="S3.I1.i4.p1.1.m1.1.1.2.2.cmml">ℱ</mi><mo id="S3.I1.i4.p1.1.m1.1.1.2.3" xref="S3.I1.i4.p1.1.m1.1.1.2.3.cmml">∩</mo></msub><mo id="S3.I1.i4.p1.1.m1.1.1.1" rspace="0.722em" xref="S3.I1.i4.p1.1.m1.1.1.1.cmml">∖</mo><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i4.p1.1.m1.1.1.3" mathsize="90%" xref="S3.I1.i4.p1.1.m1.1.1.3a.cmml">“solution area”</mtext><mo id="S3.I1.i4.p1.1.m1.1.1.1a" rspace="0.722em" xref="S3.I1.i4.p1.1.m1.1.1.1.cmml">∖</mo><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i4.p1.1.m1.1.1.4" mathsize="90%" xref="S3.I1.i4.p1.1.m1.1.1.4a.cmml">“product”</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.1.m1.1b"><apply id="S3.I1.i4.p1.1.m1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.1.1"><setdiff id="S3.I1.i4.p1.1.m1.1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.1.1.1"></setdiff><apply id="S3.I1.i4.p1.1.m1.1.1.2.cmml" xref="S3.I1.i4.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i4.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i4.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.I1.i4.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i4.p1.1.m1.1.1.2.2">ℱ</ci><intersect id="S3.I1.i4.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i4.p1.1.m1.1.1.2.3"></intersect></apply><ci id="S3.I1.i4.p1.1.m1.1.1.3a.cmml" xref="S3.I1.i4.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i4.p1.1.m1.1.1.3.cmml" mathsize="90%" xref="S3.I1.i4.p1.1.m1.1.1.3">“solution area”</mtext></ci><ci id="S3.I1.i4.p1.1.m1.1.1.4a.cmml" xref="S3.I1.i4.p1.1.m1.1.1.4"><mtext class="ltx_mathvariant_sans-serif" id="S3.I1.i4.p1.1.m1.1.1.4.cmml" mathsize="90%" xref="S3.I1.i4.p1.1.m1.1.1.4">“product”</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.1.m1.1c">\mathcal{F}_{\cap}\setminus\ \small{\textsf{``solution area''}}\setminus\small%
{\textsf{``product''}}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT ∩ end_POSTSUBSCRIPT ∖ “solution area” ∖ “product”</annotation></semantics></math>
<br class="ltx_break"/>are used in the prompts.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">As can be seen in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.F4" title="Figure 4 ‣ 3.2 Ablation study ‣ 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">4</span></a>, it is clear that <span class="ltx_text ltx_font_sansserif" id="S3.SS2.p3.1.1" style="font-size:90%;">“sales play”</span> is a critical feature without which the performance of the recommendations is severely affected. Indeed although groups <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.2">A</span>, <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.3">C</span> and <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.4">D</span> have similar performance, group <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.5">B</span> (i.e. the only one for which the <span class="ltx_text ltx_font_sansserif" id="S3.SS2.p3.1.6" style="font-size:90%;">“sales play”</span> is missing) has a significantly lower cross-encoder for almost all of its queries. This confirms the importance of <span class="ltx_text ltx_font_sansserif" id="S3.SS2.p3.1.7" style="font-size:90%;">“sales play”</span> which, as a short descriptive text, (such as “accelerate innovation with low code” or “optimize finance and supply chain” for example) provides a good opportunity to match Seismic documents and opportunities more precisely. This also indicates that improving upon this feature and advising the sellers to make <span class="ltx_text ltx_font_sansserif" id="S3.SS2.p3.1.8" style="font-size:90%;">“sales play”</span> even more descriptive will have a beneficial impact on the relevance of the recommendations.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>LLM as a judge</h3>
<figure class="ltx_figure" id="S3.F5">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F5.1.1"><span class="ltx_text" id="S3.F5.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="469" id="S3.F5.1.1.1.g1" src="extracted/5720501/Figs/LLMjudge.png" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Correlation between average human experts scores and scores as judged by GPT4 for the same 22 evaluation queries. The red line corresponds to a linear fit with a Pearson correlation coefficient of 0.42 confirming the positive correlation between the different sets of scores. We have also estimated a Spearman’s coefficient of 0.57.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">A growing trend in the literature has been the rise of leveraging LLMs as tools to evaluate the performance of tasks solved by other LLMs. Early results have indicated that strong LLM-based evaluators give scores that are in general alignment with those provided by human domain experts <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib8" title="">LLMjudge, </a>; <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib9" title="">AlpacaFarm, </a>; <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib10" title="">llmEmpirical, </a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Following this line of research, we have devised a simple prompt template so that GPT-4 is asked to give its own score for the same set of 22 curated evaluation queries. The actual prompt template is repeated below: 
<br class="ltx_break"/><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span> <span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span>
<span class="ltx_text ltx_font_typewriter" id="S3.SS3.p2.1.1">"role" : "You are an AI assistant that helps people find information". 
<br class="ltx_break"/>
<br class="ltx_break"/>"role" : "user" ; Given the following query about an opportunity:</span></p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.I2.i1.p1.1.1">Opportunity Prompt</span><span class="ltx_text ltx_font_typewriter" id="S3.I2.i1.p1.1.2"></span></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS3.p2.2"><span class="ltx_text ltx_font_typewriter" id="S3.SS3.p2.2.1">And the following documents:</span></p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.I3.i1.p1.1.1">Doc[1]</span><span class="ltx_text ltx_font_typewriter" id="S3.I3.i1.p1.1.2">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.I3.i1.p1.1.3">Doc[2]</span><span class="ltx_text ltx_font_typewriter" id="S3.I3.i1.p1.1.4">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.I3.i1.p1.1.5">Doc[3]</span><span class="ltx_text ltx_font_typewriter" id="S3.I3.i1.p1.1.6">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.I3.i1.p1.1.7">Doc[4]</span><span class="ltx_text ltx_font_typewriter" id="S3.I3.i1.p1.1.8">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.I3.i1.p1.1.9">Doc[5]</span><span class="ltx_text ltx_font_typewriter" id="S3.I3.i1.p1.1.10"></span></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS3.p2.3"><span class="ltx_text ltx_font_typewriter" id="S3.SS3.p2.3.1">Please perform the following tasks:</span></p>
<ul class="ltx_itemize" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.1"><span class="ltx_text ltx_font_typewriter" id="S3.I4.i1.p1.1.1">Calculate the similarity score between the query and each document. The similarity score should reflect how relevant each document is to the information contained in the query. Use a scale from 0 to 5, where 5 indicates a perfect match and 0 indicates no relevance.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1"><span class="ltx_text ltx_font_typewriter" id="S3.I4.i2.p1.1.1">Provide a brief justification for the ranking based on the similarity scores. </span>
<br class="ltx_break"/></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS3.p2.4"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span> <span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span>
where <span class="ltx_text ltx_font_bold" id="S3.SS3.p2.4.1">Opportunity Prompt</span> is replaced by the actual opportunity prompt and the <span class="ltx_text ltx_font_bold" id="S3.SS3.p2.4.2">Doc[i]</span> are replaced with the recommended content for this opportunity as returned by the model.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">As can be seen in Fig <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S3.F5" title="Figure 5 ‣ 3.3 LLM as a judge ‣ 3 Relevance/performance evaluation of the recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">5</span></a>, we do indeed observe a weak correlation between the human expert scores and the scores returned by GPT-4 with a Pearson correlation coefficient of 0.42.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">One challenge we have noticed is that GPT-4 seems “hesitant” to give very low scores even if its textual justification for the scores indicates a poor match between query and documents (this can be detected by seeing words such as “however”, “despite”…). This behavior has been observed anecdotally by others though we have not been able to find a dedicated study to this form of “politeness” bias.</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1">We have also tried different versions of the prompt by putting more emphasis on different aspects (such as rewarding more correct answers or enforcing strict constraints…). Eventually, we converged a prompt design that generated fair scores and refined it even more using GPT-4 to converge to the prompt shown above.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Integration in MSX</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This new recommender model is fully integrated with a pre-existing Copilot interface previously developed in <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite>. The end result, as it is seen by Microsoft sellers, is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#A1.F6" title="Figure 6 ‣ Appendix A Appendix on MSX integration ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">6</span></a> in the appendix.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Whenever a seller opens an opportunity, he/she gets the option to see the recommended contents which can be shared (customer ready) or used by sellers for their private knowledge (i.e. confidential documents that cannot be shared with customers but may still be of value to the sellers). Customer ready contents can be sent to the customer from this window directly. The seller’s email will be composed and “livesendLink” links for the selected contents will be generated automatically. Sellers also get the option to see their own past history with the Seismic documents for an opportunity. They are also offered the possibility to provide feedback about the quality of the recommendations. The “search from all contents” feature allows the sellers to search from all the content space in case they want to search for different/more contents than the recommended ones. This search functionality is powered by the real-time Copilot model <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The recommender model described in this paper is now undergoing its pilot phase where the purpose is to gather feedback from real-world sellers before it is released to the entire MSX community. This phase is expected to last for the next 2 quarters during which we plan to gather telemetry about the documents shared by the sellers.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Meanwhile, there are a number of points we are planning to investigate for further model improvements. For example, it would be interesting to fine-tune the sentence transformer models using different loss functions such as multiple negative ranking loss. In the future, we also plan to incorporate feedback from the sellers to improve the quality of the recommendations. Additionally, programmatic access to the actual content of the Seismic documents is still not available. It is our intention to take this data source into consideration as soon as it is available. This will require to modify the prompt engineering strategy discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS1" title="2.1 Prompt engineering ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">2.1</span></a> into a more elaborate multi-modal system. Finally, we discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#S2.SS4" title="2.4 Run-time performance optimization ‣ 2 Large scale semantic matching for content recommendations ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">2.4</span></a> how we have treated each opportunity as independent of each other. Although this simplification was critical for computational efficiency reasons, it potentially limits the quality of the recommendations. For example, when different opportunities are managed by the same seller, it would be interesting to incorporate seller-specific features and dependencies between the related opportunities. We plan to study this personalization aspect in a future iteration of the model.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We thank our colleagues in CX Data for their feedback and support. In particular, we thank the CX Data ML Review board (Vijay Agneeswaran, Ivan Barrientos, Jane Huang and Hunny Mehrotra) for reviewing the model and giving us useful inputs. We thank Binh “Binnie” Tran from the SPS product management team who helped us with domain knowledge on the Seismic platform and the content space.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
Seismic, “Seismic.” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://seismic.com/" title="">https://seismic.com/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
F. Ricci, L. Rokach, and B. Shapira, “Recommender systems: Techniques, applications, and challenges,” in <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Recommender Systems Handbook - Springer</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
M. Singh, R. Pasricha, N. Singh, R. P. Kondapalli, M. R, K. R, and L. Boué, “A case study of generative ai in msx sales copilot: Improving seller productivity with a real-time question-answering system for content recommendation,” in <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Microsoft Journal of Applied Research</span>, vol. 20, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
V. Sanh, L. Debut, J. Chaumond, and T. Wolf, “Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter,” in <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">NeurIPS</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Microsoft, “Nebula.” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://nebula.microsoft.com/Home" title="">https://nebula.microsoft.com/Home</a> [Last accessed: July 9, 2024].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
P. Bajaj, D. Campos, N. Craswell, L. Deng, J. Gao, X. Liu, R. Majumder, A. McNamara, B. Mitra, T. Nguyen, <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">et al.</span>, “Ms marco: A human generated machine reading comprehension dataset,” <span class="ltx_text ltx_font_italic" id="bib.bib6.2.2">arXiv preprint arXiv:1611.09268</span>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
A. Spark, “Pyspark pandas udf.” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html" title="">https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html</a>[Last accessed: July 9, 2024].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
L. Zheng, W.-L. Chiang, Y. Sheng, S. Zhuang, Z. Wu, Y. Zhuang, Z. Lin, Z. Li, D. Li, E. P, H. Z. Xing, J. E. Gonzalez, and I. Stoica, “Judging llm-as-a-judge with mt-bench and chatbot arena,” in <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">NeurIPS</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
Y. Dubois, X. Li, R. Taori, T. Zhang, I. Gulrajani, J. Ba, C. Guestrin, P. Liang, and T. B. Hashimoto, “Alpacafarm: A simulation framework for methods that learn from human feedback,” in <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">NeurIPS</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
H. Huang, Y. Qu, J. Liu, M. Yang, and T. Zhao, “An empirical study of llm-as-a-judge for llm evaluation: Fine-tuned judge models are task-specific classifiers,” <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">arXiv:2403.02839</span>, 2024.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix on MSX integration</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">We show in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#A1.F6" title="Figure 6 ‣ Appendix A Appendix on MSX integration ‣ Fine-grained large-scale content recommendations for MSX sellers"><span class="ltx_text ltx_ref_tag">6</span></a> an illustration of how the recommender system is integrated into the MSX UI.</p>
</div>
<figure class="ltx_figure" id="A1.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_align_center ltx_figure_panel ltx_align_center" id="A1.F6.1.1"><span class="ltx_text" id="A1.F6.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="587" id="A1.F6.1.1.1.g1" src="extracted/5720501/Figs/MSX1.jpg" width="1196"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_align_center ltx_figure_panel ltx_align_center" id="A1.F6.2.2"><span class="ltx_text" id="A1.F6.2.2.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="586" id="A1.F6.2.2.1.g1" src="extracted/5720501/Figs/MSX2.jpg" width="1196"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Integration into the Microsoft Seller Experience (MSX) UI. The <span class="ltx_text ltx_font_bold" id="A1.F6.5.1">top</span> figure shows a general view of the interface sellers are interacting with to manage opportunities. Notice in the bottom right a link highlighted by a dark-green ellipse. By clicking on this link, sellers can view and browse the recommended Seismic content specific to this opportunity as illustrated in the <span class="ltx_text ltx_font_bold" id="A1.F6.6.2">bottom</span> figure and the highlighted blue rectangle. Immediately to the right, one can see the “search for all contents” tab which invokes the copilot model developed in <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2407.06910v1#bib.bib3" title="">copilotMSX, </a>)</cite> for a more general interactive question-answering experience.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul  9 15:40:51 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
