<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2205.04321] Evaluating the Fairness Impact of Differentially Private Synthetic Data</title><meta property="og:description" content="Differentially private (DP) synthetic data is a promising approach to maximizing the utility of data containing sensitive information. Due to the suppression of underrepresented classes that is often required to achievâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Evaluating the Fairness Impact of Differentially Private Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Evaluating the Fairness Impact of Differentially Private Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2205.04321">

<!--Generated on Mon Mar 11 15:40:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Machine Learning,  ICML">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Evaluating the Fairness Impact of Differentially Private Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Blake Bullwinkel
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kristen Grabarz
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lily Ke
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Scarlett Gong
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chris Tanner
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joshua Allen
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Differentially private (DP) synthetic data is a promising approach to maximizing the utility of data containing sensitive information. Due to the suppression of underrepresented classes that is often required to achieve privacy, however, it may be in conflict with fairness. We evaluate four DP synthesizers and present empirical results indicating that three of these models frequently degrade fairness outcomes on downstream binary classification tasks. We draw a connection between fairness and the proportion of minority groups present in the generated synthetic data, and find that training synthesizers on data that are pre-processed via a multi-label undersampling method can promote more fair outcomes without degrading accuracy.</p>
</div>
<div class="ltx_keywords">Machine Learning, ICML
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Data containing sensitive information on individuals are being collected in an increasing number of domains. In fields such as healthcare, publishing analyses of sensitive data is not only an important part of the research process but also has clear benefits for humanity. However, publicly releasing these analyses creates a privacy risk for the individuals represented in the underlying data sets. Even machine learning models, including neural networks, that perform complex transformations of their input data can leak information about individual records in their outputs <cite class="ltx_cite ltx_citemacro_citep">(Shokri etÂ al., <a href="#bib.bib14" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Differential privacy (DP) has emerged as the gold standard for private data protection and provides strong theoretical guarantees <cite class="ltx_cite ltx_citemacro_citep">(Dwork, <a href="#bib.bib5" title="" class="ltx_ref">2006</a>)</cite>. Specifically, differential privacy bounds privacy loss by a pre-specified parameter and ensures that the output of a computation does not reveal personal information that could not be inferred from population-level statistics.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Recent research has focused on DP implementations of machine learning models, many of which are trained using modified versions of optimization algorithms that add noise to gradient computations <cite class="ltx_cite ltx_citemacro_citep">(Abadi etÂ al., <a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite>. This approach is well established but has a major drawback: after a model has been trained with a certain privacy loss budget, no further computations can be performed on the outputs. This is particularly problematic when it is necessary to perform multi-step computations on complex data sets. Further, it severely limits the ability of machine learning practitioners to understand their data and share their results.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This drawback motivates differentially private synthetic data, a growing research topic focused on training generative models to produce synthetic data that preserve the statistical properties of the original data. By distributing the privacy loss parameter across noise added to gradients during training, these models satisfy the definition of differential privacy while providing data that can be used for an unlimited number of subsequent computations <cite class="ltx_cite ltx_citemacro_citep">(Rosenblatt etÂ al., <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Because synthetic data distributions are mere approximations of the original data, privacy guarantees are often granted at the expense of predictive accuracy <cite class="ltx_cite ltx_citemacro_citep">(Geng &amp; Viswanath, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>)</cite>. Furthermore, recent work has shown that this expense may not be borne equally across protected classes represented in the data. In other words, differentially private machine learning algorithms may be less likely to satisfy common definitions of fairness <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan &amp; Shmatikov, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. In the context of models trained on differentially private <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">synthetic</span> data, however, the interplay between privacy and fairness is not well understood. We investigate this relationship by training binary classification models on DP synthetic data generated by four synthesizers at a range of privacy budgets.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Preliminaries</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The synthesizers we evaluated use different methods to satisfy differential privacy. As described in Definition 1, DP ensures that the output of a computation performed on a data set is statistically indistinguishable from the output of the same computation on the data set with any individualâ€™s information removed, up to some privacy loss parameter <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">Îµ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">ğœ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\varepsilon</annotation></semantics></math>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.5" class="ltx_p"><span id="S2.p2.5.6" class="ltx_text ltx_font_bold">Definition 1.</span> (Differential Privacy <cite class="ltx_cite ltx_citemacro_citep">(Dwork, <a href="#bib.bib5" title="" class="ltx_ref">2006</a>)</cite>) <span id="S2.p2.5.5" class="ltx_text ltx_font_italic">A randomized function <math id="S2.p2.1.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S2.p2.1.1.m1.1a"><mi id="S2.p2.1.1.m1.1.1" xref="S2.p2.1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.1.m1.1b"><ci id="S2.p2.1.1.m1.1.1.cmml" xref="S2.p2.1.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.1.m1.1c">f</annotation></semantics></math> provides <math id="S2.p2.2.2.m2.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S2.p2.2.2.m2.2a"><mrow id="S2.p2.2.2.m2.2.3.2" xref="S2.p2.2.2.m2.2.3.1.cmml"><mo stretchy="false" id="S2.p2.2.2.m2.2.3.2.1" xref="S2.p2.2.2.m2.2.3.1.cmml">(</mo><mi id="S2.p2.2.2.m2.1.1" xref="S2.p2.2.2.m2.1.1.cmml">Ïµ</mi><mo id="S2.p2.2.2.m2.2.3.2.2" xref="S2.p2.2.2.m2.2.3.1.cmml">,</mo><mi id="S2.p2.2.2.m2.2.2" xref="S2.p2.2.2.m2.2.2.cmml">Î´</mi><mo stretchy="false" id="S2.p2.2.2.m2.2.3.2.3" xref="S2.p2.2.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.2.m2.2b"><interval closure="open" id="S2.p2.2.2.m2.2.3.1.cmml" xref="S2.p2.2.2.m2.2.3.2"><ci id="S2.p2.2.2.m2.1.1.cmml" xref="S2.p2.2.2.m2.1.1">italic-Ïµ</ci><ci id="S2.p2.2.2.m2.2.2.cmml" xref="S2.p2.2.2.m2.2.2">ğ›¿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.2.m2.2c">(\epsilon,\delta)</annotation></semantics></math>-differential privacy if <math id="S2.p2.3.3.m3.1" class="ltx_Math" alttext="\forall S\subseteq Range(f)" display="inline"><semantics id="S2.p2.3.3.m3.1a"><mrow id="S2.p2.3.3.m3.1.2" xref="S2.p2.3.3.m3.1.2.cmml"><mrow id="S2.p2.3.3.m3.1.2.2" xref="S2.p2.3.3.m3.1.2.2.cmml"><mo rspace="0.167em" id="S2.p2.3.3.m3.1.2.2.1" xref="S2.p2.3.3.m3.1.2.2.1.cmml">âˆ€</mo><mi id="S2.p2.3.3.m3.1.2.2.2" xref="S2.p2.3.3.m3.1.2.2.2.cmml">S</mi></mrow><mo id="S2.p2.3.3.m3.1.2.1" xref="S2.p2.3.3.m3.1.2.1.cmml">âŠ†</mo><mrow id="S2.p2.3.3.m3.1.2.3" xref="S2.p2.3.3.m3.1.2.3.cmml"><mi id="S2.p2.3.3.m3.1.2.3.2" xref="S2.p2.3.3.m3.1.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.3.m3.1.2.3.1" xref="S2.p2.3.3.m3.1.2.3.1.cmml">â€‹</mo><mi id="S2.p2.3.3.m3.1.2.3.3" xref="S2.p2.3.3.m3.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.3.m3.1.2.3.1a" xref="S2.p2.3.3.m3.1.2.3.1.cmml">â€‹</mo><mi id="S2.p2.3.3.m3.1.2.3.4" xref="S2.p2.3.3.m3.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.3.m3.1.2.3.1b" xref="S2.p2.3.3.m3.1.2.3.1.cmml">â€‹</mo><mi id="S2.p2.3.3.m3.1.2.3.5" xref="S2.p2.3.3.m3.1.2.3.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.3.m3.1.2.3.1c" xref="S2.p2.3.3.m3.1.2.3.1.cmml">â€‹</mo><mi id="S2.p2.3.3.m3.1.2.3.6" xref="S2.p2.3.3.m3.1.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.3.m3.1.2.3.1d" xref="S2.p2.3.3.m3.1.2.3.1.cmml">â€‹</mo><mrow id="S2.p2.3.3.m3.1.2.3.7.2" xref="S2.p2.3.3.m3.1.2.3.cmml"><mo stretchy="false" id="S2.p2.3.3.m3.1.2.3.7.2.1" xref="S2.p2.3.3.m3.1.2.3.cmml">(</mo><mi id="S2.p2.3.3.m3.1.1" xref="S2.p2.3.3.m3.1.1.cmml">f</mi><mo stretchy="false" id="S2.p2.3.3.m3.1.2.3.7.2.2" xref="S2.p2.3.3.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.3.m3.1b"><apply id="S2.p2.3.3.m3.1.2.cmml" xref="S2.p2.3.3.m3.1.2"><subset id="S2.p2.3.3.m3.1.2.1.cmml" xref="S2.p2.3.3.m3.1.2.1"></subset><apply id="S2.p2.3.3.m3.1.2.2.cmml" xref="S2.p2.3.3.m3.1.2.2"><csymbol cd="latexml" id="S2.p2.3.3.m3.1.2.2.1.cmml" xref="S2.p2.3.3.m3.1.2.2.1">for-all</csymbol><ci id="S2.p2.3.3.m3.1.2.2.2.cmml" xref="S2.p2.3.3.m3.1.2.2.2">ğ‘†</ci></apply><apply id="S2.p2.3.3.m3.1.2.3.cmml" xref="S2.p2.3.3.m3.1.2.3"><times id="S2.p2.3.3.m3.1.2.3.1.cmml" xref="S2.p2.3.3.m3.1.2.3.1"></times><ci id="S2.p2.3.3.m3.1.2.3.2.cmml" xref="S2.p2.3.3.m3.1.2.3.2">ğ‘…</ci><ci id="S2.p2.3.3.m3.1.2.3.3.cmml" xref="S2.p2.3.3.m3.1.2.3.3">ğ‘</ci><ci id="S2.p2.3.3.m3.1.2.3.4.cmml" xref="S2.p2.3.3.m3.1.2.3.4">ğ‘›</ci><ci id="S2.p2.3.3.m3.1.2.3.5.cmml" xref="S2.p2.3.3.m3.1.2.3.5">ğ‘”</ci><ci id="S2.p2.3.3.m3.1.2.3.6.cmml" xref="S2.p2.3.3.m3.1.2.3.6">ğ‘’</ci><ci id="S2.p2.3.3.m3.1.1.cmml" xref="S2.p2.3.3.m3.1.1">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.3.m3.1c">\forall S\subseteq Range(f)</annotation></semantics></math>, all neighboring data sets <math id="S2.p2.4.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.p2.4.4.m4.1a"><mi id="S2.p2.4.4.m4.1.1" xref="S2.p2.4.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.4.m4.1b"><ci id="S2.p2.4.4.m4.1.1.cmml" xref="S2.p2.4.4.m4.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.4.m4.1c">D</annotation></semantics></math>, <math id="S2.p2.5.5.m5.1" class="ltx_Math" alttext="\hat{D}" display="inline"><semantics id="S2.p2.5.5.m5.1a"><mover accent="true" id="S2.p2.5.5.m5.1.1" xref="S2.p2.5.5.m5.1.1.cmml"><mi id="S2.p2.5.5.m5.1.1.2" xref="S2.p2.5.5.m5.1.1.2.cmml">D</mi><mo id="S2.p2.5.5.m5.1.1.1" xref="S2.p2.5.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.p2.5.5.m5.1b"><apply id="S2.p2.5.5.m5.1.1.cmml" xref="S2.p2.5.5.m5.1.1"><ci id="S2.p2.5.5.m5.1.1.1.cmml" xref="S2.p2.5.5.m5.1.1.1">^</ci><ci id="S2.p2.5.5.m5.1.1.2.cmml" xref="S2.p2.5.5.m5.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.5.m5.1c">\hat{D}</annotation></semantics></math> differing on a single entry,</span></p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.4" class="ltx_Math" alttext="Pr[f(D)\in S]\leq e^{\epsilon}Pr[f(\hat{D})\in S]+\delta" display="block"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.cmml"><mi id="S2.E1.m1.3.3.1.3" xref="S2.E1.m1.3.3.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.3.3.1.4" xref="S2.E1.m1.3.3.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.2a" xref="S2.E1.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.2" xref="S2.E1.m1.3.3.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mrow id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.2.2" xref="S2.E1.m1.3.3.1.1.1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.1.2.1" xref="S2.E1.m1.3.3.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.2.3.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.2.3.2.1" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">D</mi><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.2.3.2.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">âˆˆ</mo><mi id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.3.3.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml">â‰¤</mo><mrow id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml"><mrow id="S2.E1.m1.4.4.2.1" xref="S2.E1.m1.4.4.2.1.cmml"><msup id="S2.E1.m1.4.4.2.1.3" xref="S2.E1.m1.4.4.2.1.3.cmml"><mi id="S2.E1.m1.4.4.2.1.3.2" xref="S2.E1.m1.4.4.2.1.3.2.cmml">e</mi><mi id="S2.E1.m1.4.4.2.1.3.3" xref="S2.E1.m1.4.4.2.1.3.3.cmml">Ïµ</mi></msup><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.1.2" xref="S2.E1.m1.4.4.2.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.4.4.2.1.4" xref="S2.E1.m1.4.4.2.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.1.2a" xref="S2.E1.m1.4.4.2.1.2.cmml">â€‹</mo><mi id="S2.E1.m1.4.4.2.1.5" xref="S2.E1.m1.4.4.2.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.1.2b" xref="S2.E1.m1.4.4.2.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.4.4.2.1.1.1" xref="S2.E1.m1.4.4.2.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.2.1.1.1.2" xref="S2.E1.m1.4.4.2.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.4.4.2.1.1.1.1" xref="S2.E1.m1.4.4.2.1.1.1.1.cmml"><mrow id="S2.E1.m1.4.4.2.1.1.1.1.2" xref="S2.E1.m1.4.4.2.1.1.1.1.2.cmml"><mi id="S2.E1.m1.4.4.2.1.1.1.1.2.2" xref="S2.E1.m1.4.4.2.1.1.1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.1.1.1.1.2.1" xref="S2.E1.m1.4.4.2.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.4.4.2.1.1.1.1.2.3.2" xref="S2.E1.m1.2.2.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.2.1.1.1.1.2.3.2.1" xref="S2.E1.m1.2.2.cmml">(</mo><mover accent="true" id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mi id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">D</mi><mo id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S2.E1.m1.4.4.2.1.1.1.1.2.3.2.2" xref="S2.E1.m1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2.1.1.1.1.1" xref="S2.E1.m1.4.4.2.1.1.1.1.1.cmml">âˆˆ</mo><mi id="S2.E1.m1.4.4.2.1.1.1.1.3" xref="S2.E1.m1.4.4.2.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S2.E1.m1.4.4.2.1.1.1.3" xref="S2.E1.m1.4.4.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2.2" xref="S2.E1.m1.4.4.2.2.cmml">+</mo><mi id="S2.E1.m1.4.4.2.3" xref="S2.E1.m1.4.4.2.3.cmml">Î´</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><leq id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"></leq><apply id="S2.E1.m1.3.3.1.cmml" xref="S2.E1.m1.3.3.1"><times id="S2.E1.m1.3.3.1.2.cmml" xref="S2.E1.m1.3.3.1.2"></times><ci id="S2.E1.m1.3.3.1.3.cmml" xref="S2.E1.m1.3.3.1.3">ğ‘ƒ</ci><ci id="S2.E1.m1.3.3.1.4.cmml" xref="S2.E1.m1.3.3.1.4">ğ‘Ÿ</ci><apply id="S2.E1.m1.3.3.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.3.3.1.1.2.1.cmml" xref="S2.E1.m1.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><in id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1"></in><apply id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2"><times id="S2.E1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.1"></times><ci id="S2.E1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2.2">ğ‘“</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ·</ci></apply><ci id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3">ğ‘†</ci></apply></apply></apply><apply id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"><plus id="S2.E1.m1.4.4.2.2.cmml" xref="S2.E1.m1.4.4.2.2"></plus><apply id="S2.E1.m1.4.4.2.1.cmml" xref="S2.E1.m1.4.4.2.1"><times id="S2.E1.m1.4.4.2.1.2.cmml" xref="S2.E1.m1.4.4.2.1.2"></times><apply id="S2.E1.m1.4.4.2.1.3.cmml" xref="S2.E1.m1.4.4.2.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.1.3.1.cmml" xref="S2.E1.m1.4.4.2.1.3">superscript</csymbol><ci id="S2.E1.m1.4.4.2.1.3.2.cmml" xref="S2.E1.m1.4.4.2.1.3.2">ğ‘’</ci><ci id="S2.E1.m1.4.4.2.1.3.3.cmml" xref="S2.E1.m1.4.4.2.1.3.3">italic-Ïµ</ci></apply><ci id="S2.E1.m1.4.4.2.1.4.cmml" xref="S2.E1.m1.4.4.2.1.4">ğ‘ƒ</ci><ci id="S2.E1.m1.4.4.2.1.5.cmml" xref="S2.E1.m1.4.4.2.1.5">ğ‘Ÿ</ci><apply id="S2.E1.m1.4.4.2.1.1.2.cmml" xref="S2.E1.m1.4.4.2.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.4.4.2.1.1.2.1.cmml" xref="S2.E1.m1.4.4.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.4.4.2.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1"><in id="S2.E1.m1.4.4.2.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1.1"></in><apply id="S2.E1.m1.4.4.2.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1.2"><times id="S2.E1.m1.4.4.2.1.1.1.1.2.1.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1.2.1"></times><ci id="S2.E1.m1.4.4.2.1.1.1.1.2.2.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1.2.2">ğ‘“</ci><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1.2.3.2"><ci id="S2.E1.m1.2.2.1.cmml" xref="S2.E1.m1.2.2.1">^</ci><ci id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2">ğ·</ci></apply></apply><ci id="S2.E1.m1.4.4.2.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1.3">ğ‘†</ci></apply></apply></apply><ci id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.3">ğ›¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">Pr[f(D)\in S]\leq e^{\epsilon}Pr[f(\hat{D})\in S]+\delta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">DP synthesizers allow us to control exactly how much privacy loss, or privacy risk, we are willing to tolerate. Lower values of <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S2.p3.1.m1.1a"><mi id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">Îµ</mi><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><ci id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">ğœ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">\varepsilon</annotation></semantics></math> are associated with greater privacy protection, whereas higher values typically allow greater statistical similarity to the original data, but preserve less privacy.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Synthesizers.</span> In our experiments, we generated data using four DP synthesizers. One of these is the Multiplicative Weights Exponential Mechanism (MWEM), developed by Hardt et al. (<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib9" title="" class="ltx_ref">2012</a></cite>). Using the Multiplicative Weights update rule and the Exponential Mechanism to select queries, MWEM approximates a target distribution by generating data that maximize agreement with the target on the selected queries. Recent research has found that MWEM is fast and performs well in scenarios where data can be discretized into columns with reasonable dimensionality <cite class="ltx_cite ltx_citemacro_citep">(Rosenblatt etÂ al., <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>. As MWEM was one of the first DP synthesizers published, we include it as a de facto baseline.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Another popular approach to private data generation is to train GAN-based models <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2014</a>)</cite> using DP Stochastic Gradient Descent (DPSGD), which enforces privacy by clipping each gradient in the optimizationâ€™s <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S2.p5.1.m1.1a"><msub id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml"><mi id="S2.p5.1.m1.1.1.2" xref="S2.p5.1.m1.1.1.2.cmml">L</mi><mn id="S2.p5.1.m1.1.1.3" xref="S2.p5.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><apply id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p5.1.m1.1.1.1.cmml" xref="S2.p5.1.m1.1.1">subscript</csymbol><ci id="S2.p5.1.m1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.2">ğ¿</ci><cn type="integer" id="S2.p5.1.m1.1.1.3.cmml" xref="S2.p5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">L_{2}</annotation></semantics></math> norm and then adding noise <cite class="ltx_cite ltx_citemacro_citep">(Abadi etÂ al., <a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite>. We evaluated two synthesizers that fall under this category: DP-CTGAN, a DP version of CTGAN developed to generate private tabular data <cite class="ltx_cite ltx_citemacro_citep">(Xu etÂ al., <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>, and PATE-CTGAN, which combines the Private Aggregation of Teacher Ensembles (PATE) framework with CTGAN <cite class="ltx_cite ltx_citemacro_citep">(Yoon etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>. While GAN-based models can generate high quality synthetic data, we found that their performance is sensitive to hyperparameters, making them difficult to train across data sets. To mitigate this issue, we used QUAIL, an ensemble method proposed by <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib13" title="" class="ltx_ref">Rosenblatt etÂ al.</a></cite> that combines a DP supervised learning algorithm, such as DP logistic regression, with a synthesizer. In our experiments, we augmented MWEM, DP-CTGAN and PATE-CTGAN with QUAIL and refer to these ensembles as QUAIL-MWEM, QUAIL-DPCTGAN and QUAIL-PATECTGAN, respectively. For these synthesizers, we utilized the open-source <a target="_blank" href="https://github.com/opendp/smartnoise-sdk" title="" class="ltx_ref ltx_href">SmartNoise SDK</a>.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Finally, we evaluated MST <cite class="ltx_cite ltx_citemacro_citep">(McKenna etÂ al., <a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite>, a more recent synthesizer that uses the Gaussian mechanism to measure selected marginals and Private-PGM to estimate a distribution from those measurements and generate synthetic data. As a graphical model, Private-PGM tends to work well in high dimensions, provided that the selected marginals are low-dimensional <cite class="ltx_cite ltx_citemacro_citep">(McKenna etÂ al., <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.2" class="ltx_p"><span id="S2.p7.2.1" class="ltx_text ltx_font_bold">Fairness.</span> In this work, we considered the equalized odds notion of fairness. While many definitions of fairness exist, equalized odds provides a measure that is both relevant to our classification tasks and more robust than other definitions. Demographic parity, for example, does not guarantee fairness in all scenarios and can seriously hurt accuracy when enforced <cite class="ltx_cite ltx_citemacro_citep">(Dwork etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2011</a>)</cite>. As implied by Definition 2, equalized odds requires that the true positive rate (<math id="S2.p7.1.m1.2" class="ltx_Math" alttext="\hat{Y}=1,y=1" display="inline"><semantics id="S2.p7.1.m1.2a"><mrow id="S2.p7.1.m1.2.2.2" xref="S2.p7.1.m1.2.2.3.cmml"><mrow id="S2.p7.1.m1.1.1.1.1" xref="S2.p7.1.m1.1.1.1.1.cmml"><mover accent="true" id="S2.p7.1.m1.1.1.1.1.2" xref="S2.p7.1.m1.1.1.1.1.2.cmml"><mi id="S2.p7.1.m1.1.1.1.1.2.2" xref="S2.p7.1.m1.1.1.1.1.2.2.cmml">Y</mi><mo id="S2.p7.1.m1.1.1.1.1.2.1" xref="S2.p7.1.m1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.p7.1.m1.1.1.1.1.1" xref="S2.p7.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S2.p7.1.m1.1.1.1.1.3" xref="S2.p7.1.m1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S2.p7.1.m1.2.2.2.3" xref="S2.p7.1.m1.2.2.3a.cmml">,</mo><mrow id="S2.p7.1.m1.2.2.2.2" xref="S2.p7.1.m1.2.2.2.2.cmml"><mi id="S2.p7.1.m1.2.2.2.2.2" xref="S2.p7.1.m1.2.2.2.2.2.cmml">y</mi><mo id="S2.p7.1.m1.2.2.2.2.1" xref="S2.p7.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S2.p7.1.m1.2.2.2.2.3" xref="S2.p7.1.m1.2.2.2.2.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p7.1.m1.2b"><apply id="S2.p7.1.m1.2.2.3.cmml" xref="S2.p7.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.p7.1.m1.2.2.3a.cmml" xref="S2.p7.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p7.1.m1.1.1.1.1.cmml" xref="S2.p7.1.m1.1.1.1.1"><eq id="S2.p7.1.m1.1.1.1.1.1.cmml" xref="S2.p7.1.m1.1.1.1.1.1"></eq><apply id="S2.p7.1.m1.1.1.1.1.2.cmml" xref="S2.p7.1.m1.1.1.1.1.2"><ci id="S2.p7.1.m1.1.1.1.1.2.1.cmml" xref="S2.p7.1.m1.1.1.1.1.2.1">^</ci><ci id="S2.p7.1.m1.1.1.1.1.2.2.cmml" xref="S2.p7.1.m1.1.1.1.1.2.2">ğ‘Œ</ci></apply><cn type="integer" id="S2.p7.1.m1.1.1.1.1.3.cmml" xref="S2.p7.1.m1.1.1.1.1.3">1</cn></apply><apply id="S2.p7.1.m1.2.2.2.2.cmml" xref="S2.p7.1.m1.2.2.2.2"><eq id="S2.p7.1.m1.2.2.2.2.1.cmml" xref="S2.p7.1.m1.2.2.2.2.1"></eq><ci id="S2.p7.1.m1.2.2.2.2.2.cmml" xref="S2.p7.1.m1.2.2.2.2.2">ğ‘¦</ci><cn type="integer" id="S2.p7.1.m1.2.2.2.2.3.cmml" xref="S2.p7.1.m1.2.2.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.1.m1.2c">\hat{Y}=1,y=1</annotation></semantics></math>) and false positive rate (<math id="S2.p7.2.m2.2" class="ltx_Math" alttext="\hat{Y}=1,y=0" display="inline"><semantics id="S2.p7.2.m2.2a"><mrow id="S2.p7.2.m2.2.2.2" xref="S2.p7.2.m2.2.2.3.cmml"><mrow id="S2.p7.2.m2.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.cmml"><mover accent="true" id="S2.p7.2.m2.1.1.1.1.2" xref="S2.p7.2.m2.1.1.1.1.2.cmml"><mi id="S2.p7.2.m2.1.1.1.1.2.2" xref="S2.p7.2.m2.1.1.1.1.2.2.cmml">Y</mi><mo id="S2.p7.2.m2.1.1.1.1.2.1" xref="S2.p7.2.m2.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.p7.2.m2.1.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.1.cmml">=</mo><mn id="S2.p7.2.m2.1.1.1.1.3" xref="S2.p7.2.m2.1.1.1.1.3.cmml">1</mn></mrow><mo id="S2.p7.2.m2.2.2.2.3" xref="S2.p7.2.m2.2.2.3a.cmml">,</mo><mrow id="S2.p7.2.m2.2.2.2.2" xref="S2.p7.2.m2.2.2.2.2.cmml"><mi id="S2.p7.2.m2.2.2.2.2.2" xref="S2.p7.2.m2.2.2.2.2.2.cmml">y</mi><mo id="S2.p7.2.m2.2.2.2.2.1" xref="S2.p7.2.m2.2.2.2.2.1.cmml">=</mo><mn id="S2.p7.2.m2.2.2.2.2.3" xref="S2.p7.2.m2.2.2.2.2.3.cmml">0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p7.2.m2.2b"><apply id="S2.p7.2.m2.2.2.3.cmml" xref="S2.p7.2.m2.2.2.2"><csymbol cd="ambiguous" id="S2.p7.2.m2.2.2.3a.cmml" xref="S2.p7.2.m2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p7.2.m2.1.1.1.1.cmml" xref="S2.p7.2.m2.1.1.1.1"><eq id="S2.p7.2.m2.1.1.1.1.1.cmml" xref="S2.p7.2.m2.1.1.1.1.1"></eq><apply id="S2.p7.2.m2.1.1.1.1.2.cmml" xref="S2.p7.2.m2.1.1.1.1.2"><ci id="S2.p7.2.m2.1.1.1.1.2.1.cmml" xref="S2.p7.2.m2.1.1.1.1.2.1">^</ci><ci id="S2.p7.2.m2.1.1.1.1.2.2.cmml" xref="S2.p7.2.m2.1.1.1.1.2.2">ğ‘Œ</ci></apply><cn type="integer" id="S2.p7.2.m2.1.1.1.1.3.cmml" xref="S2.p7.2.m2.1.1.1.1.3">1</cn></apply><apply id="S2.p7.2.m2.2.2.2.2.cmml" xref="S2.p7.2.m2.2.2.2.2"><eq id="S2.p7.2.m2.2.2.2.2.1.cmml" xref="S2.p7.2.m2.2.2.2.2.1"></eq><ci id="S2.p7.2.m2.2.2.2.2.2.cmml" xref="S2.p7.2.m2.2.2.2.2.2">ğ‘¦</ci><cn type="integer" id="S2.p7.2.m2.2.2.2.2.3.cmml" xref="S2.p7.2.m2.2.2.2.2.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.2.m2.2c">\hat{Y}=1,y=0</annotation></semantics></math>) across groups (e.g. gender, race) are equal.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.6" class="ltx_p"><span id="S2.p8.6.7" class="ltx_text ltx_font_bold">Definition 2.</span> (Equalized Odds) <span id="S2.p8.6.6" class="ltx_text ltx_font_italic">A classifier <math id="S2.p8.1.1.m1.1" class="ltx_Math" alttext="\widehat{Y}" display="inline"><semantics id="S2.p8.1.1.m1.1a"><mover accent="true" id="S2.p8.1.1.m1.1.1" xref="S2.p8.1.1.m1.1.1.cmml"><mi id="S2.p8.1.1.m1.1.1.2" xref="S2.p8.1.1.m1.1.1.2.cmml">Y</mi><mo id="S2.p8.1.1.m1.1.1.1" xref="S2.p8.1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.p8.1.1.m1.1b"><apply id="S2.p8.1.1.m1.1.1.cmml" xref="S2.p8.1.1.m1.1.1"><ci id="S2.p8.1.1.m1.1.1.1.cmml" xref="S2.p8.1.1.m1.1.1.1">^</ci><ci id="S2.p8.1.1.m1.1.1.2.cmml" xref="S2.p8.1.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.1.m1.1c">\widehat{Y}</annotation></semantics></math> satisfies equalized odds with respect to a protected attribute <math id="S2.p8.2.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.p8.2.2.m2.1a"><mi id="S2.p8.2.2.m2.1.1" xref="S2.p8.2.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.p8.2.2.m2.1b"><ci id="S2.p8.2.2.m2.1.1.cmml" xref="S2.p8.2.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.2.2.m2.1c">A</annotation></semantics></math> and outcome <math id="S2.p8.3.3.m3.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S2.p8.3.3.m3.1a"><mi id="S2.p8.3.3.m3.1.1" xref="S2.p8.3.3.m3.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S2.p8.3.3.m3.1b"><ci id="S2.p8.3.3.m3.1.1.cmml" xref="S2.p8.3.3.m3.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.3.3.m3.1c">Y</annotation></semantics></math> if <math id="S2.p8.4.4.m4.1" class="ltx_Math" alttext="\widehat{Y}" display="inline"><semantics id="S2.p8.4.4.m4.1a"><mover accent="true" id="S2.p8.4.4.m4.1.1" xref="S2.p8.4.4.m4.1.1.cmml"><mi id="S2.p8.4.4.m4.1.1.2" xref="S2.p8.4.4.m4.1.1.2.cmml">Y</mi><mo id="S2.p8.4.4.m4.1.1.1" xref="S2.p8.4.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.p8.4.4.m4.1b"><apply id="S2.p8.4.4.m4.1.1.cmml" xref="S2.p8.4.4.m4.1.1"><ci id="S2.p8.4.4.m4.1.1.1.cmml" xref="S2.p8.4.4.m4.1.1.1">^</ci><ci id="S2.p8.4.4.m4.1.1.2.cmml" xref="S2.p8.4.4.m4.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.4.4.m4.1c">\widehat{Y}</annotation></semantics></math> and <math id="S2.p8.5.5.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.p8.5.5.m5.1a"><mi id="S2.p8.5.5.m5.1.1" xref="S2.p8.5.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.p8.5.5.m5.1b"><ci id="S2.p8.5.5.m5.1.1.cmml" xref="S2.p8.5.5.m5.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.5.5.m5.1c">A</annotation></semantics></math> are independent, conditional on <math id="S2.p8.6.6.m6.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S2.p8.6.6.m6.1a"><mi id="S2.p8.6.6.m6.1.1" xref="S2.p8.6.6.m6.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S2.p8.6.6.m6.1b"><ci id="S2.p8.6.6.m6.1.1.cmml" xref="S2.p8.6.6.m6.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.6.6.m6.1c">Y</annotation></semantics></math>,</span></p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.39" class="ltx_math_unparsed" alttext="Pr[\widehat{Y}=1|A=0,Y=y]\\
=Pr[\widehat{Y}=1|A=1,Y=y],\quad y\in\{0,1\}" display="block"><semantics id="S2.E2.m1.39a"><mtable displaystyle="true" rowspacing="0pt" id="S2.E2.m1.39.39"><mtr id="S2.E2.m1.39.39a"><mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.39.39b"><mrow id="S2.E2.m1.15.15.15.15.15"><mi id="S2.E2.m1.1.1.1.1.1.1">P</mi><mi id="S2.E2.m1.2.2.2.2.2.2">r</mi><mrow id="S2.E2.m1.15.15.15.15.15.16"><mo stretchy="false" id="S2.E2.m1.3.3.3.3.3.3">[</mo><mover accent="true" id="S2.E2.m1.4.4.4.4.4.4"><mi id="S2.E2.m1.4.4.4.4.4.4.2">Y</mi><mo id="S2.E2.m1.4.4.4.4.4.4.1">^</mo></mover><mo id="S2.E2.m1.5.5.5.5.5.5">=</mo><mn id="S2.E2.m1.6.6.6.6.6.6">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E2.m1.7.7.7.7.7.7">|</mo><mi id="S2.E2.m1.8.8.8.8.8.8">A</mi><mo id="S2.E2.m1.9.9.9.9.9.9">=</mo><mn id="S2.E2.m1.10.10.10.10.10.10">0</mn><mo id="S2.E2.m1.11.11.11.11.11.11">,</mo><mi id="S2.E2.m1.12.12.12.12.12.12">Y</mi><mo id="S2.E2.m1.13.13.13.13.13.13">=</mo><mi id="S2.E2.m1.14.14.14.14.14.14">y</mi><mo stretchy="false" id="S2.E2.m1.15.15.15.15.15.15">]</mo></mrow></mrow></mtd></mtr><mtr id="S2.E2.m1.39.39c"><mtd class="ltx_align_right" columnalign="right" id="S2.E2.m1.39.39d"><mrow id="S2.E2.m1.39.39.39.24.24"><mo id="S2.E2.m1.16.16.16.1.1.1">=</mo><mi id="S2.E2.m1.17.17.17.2.2.2">P</mi><mi id="S2.E2.m1.18.18.18.3.3.3">r</mi><mrow id="S2.E2.m1.39.39.39.24.24.25"><mo stretchy="false" id="S2.E2.m1.19.19.19.4.4.4">[</mo><mover accent="true" id="S2.E2.m1.20.20.20.5.5.5"><mi id="S2.E2.m1.20.20.20.5.5.5.2">Y</mi><mo id="S2.E2.m1.20.20.20.5.5.5.1">^</mo></mover><mo id="S2.E2.m1.21.21.21.6.6.6">=</mo><mn id="S2.E2.m1.22.22.22.7.7.7">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E2.m1.23.23.23.8.8.8">|</mo><mi id="S2.E2.m1.24.24.24.9.9.9">A</mi><mo id="S2.E2.m1.25.25.25.10.10.10">=</mo><mn id="S2.E2.m1.26.26.26.11.11.11">1</mn><mo id="S2.E2.m1.27.27.27.12.12.12">,</mo><mi id="S2.E2.m1.28.28.28.13.13.13">Y</mi><mo id="S2.E2.m1.29.29.29.14.14.14">=</mo><mi id="S2.E2.m1.30.30.30.15.15.15">y</mi><mo stretchy="false" id="S2.E2.m1.31.31.31.16.16.16">]</mo></mrow><mo rspace="1.167em" id="S2.E2.m1.32.32.32.17.17.17">,</mo><mi id="S2.E2.m1.33.33.33.18.18.18">y</mi><mo id="S2.E2.m1.34.34.34.19.19.19">âˆˆ</mo><mrow id="S2.E2.m1.39.39.39.24.24.26"><mo stretchy="false" id="S2.E2.m1.35.35.35.20.20.20">{</mo><mn id="S2.E2.m1.36.36.36.21.21.21">0</mn><mo id="S2.E2.m1.37.37.37.22.22.22">,</mo><mn id="S2.E2.m1.38.38.38.23.23.23">1</mn><mo stretchy="false" id="S2.E2.m1.39.39.39.24.24.24">}</mo></mrow></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex" id="S2.E2.m1.39b">Pr[\widehat{Y}=1|A=0,Y=y]\\
=Pr[\widehat{Y}=1|A=1,Y=y],\quad y\in\{0,1\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.4" class="ltx_p">Note that in our analyses, we labeled the unprivileged group <math id="S2.p9.1.m1.1" class="ltx_Math" alttext="A=0" display="inline"><semantics id="S2.p9.1.m1.1a"><mrow id="S2.p9.1.m1.1.1" xref="S2.p9.1.m1.1.1.cmml"><mi id="S2.p9.1.m1.1.1.2" xref="S2.p9.1.m1.1.1.2.cmml">A</mi><mo id="S2.p9.1.m1.1.1.1" xref="S2.p9.1.m1.1.1.1.cmml">=</mo><mn id="S2.p9.1.m1.1.1.3" xref="S2.p9.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.1.m1.1b"><apply id="S2.p9.1.m1.1.1.cmml" xref="S2.p9.1.m1.1.1"><eq id="S2.p9.1.m1.1.1.1.cmml" xref="S2.p9.1.m1.1.1.1"></eq><ci id="S2.p9.1.m1.1.1.2.cmml" xref="S2.p9.1.m1.1.1.2">ğ´</ci><cn type="integer" id="S2.p9.1.m1.1.1.3.cmml" xref="S2.p9.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.1.m1.1c">A=0</annotation></semantics></math> and the privileged group <math id="S2.p9.2.m2.1" class="ltx_Math" alttext="A=1" display="inline"><semantics id="S2.p9.2.m2.1a"><mrow id="S2.p9.2.m2.1.1" xref="S2.p9.2.m2.1.1.cmml"><mi id="S2.p9.2.m2.1.1.2" xref="S2.p9.2.m2.1.1.2.cmml">A</mi><mo id="S2.p9.2.m2.1.1.1" xref="S2.p9.2.m2.1.1.1.cmml">=</mo><mn id="S2.p9.2.m2.1.1.3" xref="S2.p9.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.2.m2.1b"><apply id="S2.p9.2.m2.1.1.cmml" xref="S2.p9.2.m2.1.1"><eq id="S2.p9.2.m2.1.1.1.cmml" xref="S2.p9.2.m2.1.1.1"></eq><ci id="S2.p9.2.m2.1.1.2.cmml" xref="S2.p9.2.m2.1.1.2">ğ´</ci><cn type="integer" id="S2.p9.2.m2.1.1.3.cmml" xref="S2.p9.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.2.m2.1c">A=1</annotation></semantics></math>. In all four data sets analyzed, the true positive and false positive rates are aligned with real-world fairness concerns. In the context of the COMPAS data set, for example, a higher false positive rate for group <math id="S2.p9.3.m3.1" class="ltx_Math" alttext="A=0" display="inline"><semantics id="S2.p9.3.m3.1a"><mrow id="S2.p9.3.m3.1.1" xref="S2.p9.3.m3.1.1.cmml"><mi id="S2.p9.3.m3.1.1.2" xref="S2.p9.3.m3.1.1.2.cmml">A</mi><mo id="S2.p9.3.m3.1.1.1" xref="S2.p9.3.m3.1.1.1.cmml">=</mo><mn id="S2.p9.3.m3.1.1.3" xref="S2.p9.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.3.m3.1b"><apply id="S2.p9.3.m3.1.1.cmml" xref="S2.p9.3.m3.1.1"><eq id="S2.p9.3.m3.1.1.1.cmml" xref="S2.p9.3.m3.1.1.1"></eq><ci id="S2.p9.3.m3.1.1.2.cmml" xref="S2.p9.3.m3.1.1.2">ğ´</ci><cn type="integer" id="S2.p9.3.m3.1.1.3.cmml" xref="S2.p9.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.3.m3.1c">A=0</annotation></semantics></math> than <math id="S2.p9.4.m4.1" class="ltx_Math" alttext="A=1" display="inline"><semantics id="S2.p9.4.m4.1a"><mrow id="S2.p9.4.m4.1.1" xref="S2.p9.4.m4.1.1.cmml"><mi id="S2.p9.4.m4.1.1.2" xref="S2.p9.4.m4.1.1.2.cmml">A</mi><mo id="S2.p9.4.m4.1.1.1" xref="S2.p9.4.m4.1.1.1.cmml">=</mo><mn id="S2.p9.4.m4.1.1.3" xref="S2.p9.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.4.m4.1b"><apply id="S2.p9.4.m4.1.1.cmml" xref="S2.p9.4.m4.1.1"><eq id="S2.p9.4.m4.1.1.1.cmml" xref="S2.p9.4.m4.1.1.1"></eq><ci id="S2.p9.4.m4.1.1.2.cmml" xref="S2.p9.4.m4.1.1.2">ğ´</ci><cn type="integer" id="S2.p9.4.m4.1.1.3.cmml" xref="S2.p9.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.4.m4.1c">A=1</annotation></semantics></math> implies that a classifier is more likely to incorrectly predict that individuals in the unprivileged group will recommit a crime compared to individuals in the privileged group.</p>
</div>
<div id="S2.p10" class="ltx_para">
<p id="S2.p10.3" class="ltx_p">To measure the degree of <em id="S2.p10.3.1" class="ltx_emph ltx_font_italic">unfairness</em> between groups, we calculated the difference between their true positive rates and false positive rates, i.e. <math id="S2.p10.1.m1.1" class="ltx_math_unparsed" alttext="Pr[\widehat{Y}=1|A=1,Y=y]-Pr[\widehat{Y}=1|A=0,Y=y]" display="inline"><semantics id="S2.p10.1.m1.1a"><mrow id="S2.p10.1.m1.1b"><mi id="S2.p10.1.m1.1.1">P</mi><mi id="S2.p10.1.m1.1.2">r</mi><mrow id="S2.p10.1.m1.1.3"><mo stretchy="false" id="S2.p10.1.m1.1.3.1">[</mo><mover accent="true" id="S2.p10.1.m1.1.3.2"><mi id="S2.p10.1.m1.1.3.2.2">Y</mi><mo id="S2.p10.1.m1.1.3.2.1">^</mo></mover><mo id="S2.p10.1.m1.1.3.3">=</mo><mn id="S2.p10.1.m1.1.3.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.p10.1.m1.1.3.5">|</mo><mi id="S2.p10.1.m1.1.3.6">A</mi><mo id="S2.p10.1.m1.1.3.7">=</mo><mn id="S2.p10.1.m1.1.3.8">1</mn><mo id="S2.p10.1.m1.1.3.9">,</mo><mi id="S2.p10.1.m1.1.3.10">Y</mi><mo id="S2.p10.1.m1.1.3.11">=</mo><mi id="S2.p10.1.m1.1.3.12">y</mi><mo stretchy="false" id="S2.p10.1.m1.1.3.13">]</mo></mrow><mo id="S2.p10.1.m1.1.4">âˆ’</mo><mi id="S2.p10.1.m1.1.5">P</mi><mi id="S2.p10.1.m1.1.6">r</mi><mrow id="S2.p10.1.m1.1.7"><mo stretchy="false" id="S2.p10.1.m1.1.7.1">[</mo><mover accent="true" id="S2.p10.1.m1.1.7.2"><mi id="S2.p10.1.m1.1.7.2.2">Y</mi><mo id="S2.p10.1.m1.1.7.2.1">^</mo></mover><mo id="S2.p10.1.m1.1.7.3">=</mo><mn id="S2.p10.1.m1.1.7.4">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S2.p10.1.m1.1.7.5">|</mo><mi id="S2.p10.1.m1.1.7.6">A</mi><mo id="S2.p10.1.m1.1.7.7">=</mo><mn id="S2.p10.1.m1.1.7.8">0</mn><mo id="S2.p10.1.m1.1.7.9">,</mo><mi id="S2.p10.1.m1.1.7.10">Y</mi><mo id="S2.p10.1.m1.1.7.11">=</mo><mi id="S2.p10.1.m1.1.7.12">y</mi><mo stretchy="false" id="S2.p10.1.m1.1.7.13">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.p10.1.m1.1c">Pr[\widehat{Y}=1|A=1,Y=y]-Pr[\widehat{Y}=1|A=0,Y=y]</annotation></semantics></math>, where <math id="S2.p10.2.m2.2" class="ltx_Math" alttext="y\in\{0,1\}" display="inline"><semantics id="S2.p10.2.m2.2a"><mrow id="S2.p10.2.m2.2.3" xref="S2.p10.2.m2.2.3.cmml"><mi id="S2.p10.2.m2.2.3.2" xref="S2.p10.2.m2.2.3.2.cmml">y</mi><mo id="S2.p10.2.m2.2.3.1" xref="S2.p10.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S2.p10.2.m2.2.3.3.2" xref="S2.p10.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S2.p10.2.m2.2.3.3.2.1" xref="S2.p10.2.m2.2.3.3.1.cmml">{</mo><mn id="S2.p10.2.m2.1.1" xref="S2.p10.2.m2.1.1.cmml">0</mn><mo id="S2.p10.2.m2.2.3.3.2.2" xref="S2.p10.2.m2.2.3.3.1.cmml">,</mo><mn id="S2.p10.2.m2.2.2" xref="S2.p10.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S2.p10.2.m2.2.3.3.2.3" xref="S2.p10.2.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p10.2.m2.2b"><apply id="S2.p10.2.m2.2.3.cmml" xref="S2.p10.2.m2.2.3"><in id="S2.p10.2.m2.2.3.1.cmml" xref="S2.p10.2.m2.2.3.1"></in><ci id="S2.p10.2.m2.2.3.2.cmml" xref="S2.p10.2.m2.2.3.2">ğ‘¦</ci><set id="S2.p10.2.m2.2.3.3.1.cmml" xref="S2.p10.2.m2.2.3.3.2"><cn type="integer" id="S2.p10.2.m2.1.1.cmml" xref="S2.p10.2.m2.1.1">0</cn><cn type="integer" id="S2.p10.2.m2.2.2.cmml" xref="S2.p10.2.m2.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.2.m2.2c">y\in\{0,1\}</annotation></semantics></math>. We refer to these differences as the equalized odds distances, smaller values of which indicate more fair outcomes. Note that in addition to fairness, we also measured accuracy using F1-scores because a classifier that always predicts <math id="S2.p10.3.m3.1" class="ltx_Math" alttext="\hat{Y}=0" display="inline"><semantics id="S2.p10.3.m3.1a"><mrow id="S2.p10.3.m3.1.1" xref="S2.p10.3.m3.1.1.cmml"><mover accent="true" id="S2.p10.3.m3.1.1.2" xref="S2.p10.3.m3.1.1.2.cmml"><mi id="S2.p10.3.m3.1.1.2.2" xref="S2.p10.3.m3.1.1.2.2.cmml">Y</mi><mo id="S2.p10.3.m3.1.1.2.1" xref="S2.p10.3.m3.1.1.2.1.cmml">^</mo></mover><mo id="S2.p10.3.m3.1.1.1" xref="S2.p10.3.m3.1.1.1.cmml">=</mo><mn id="S2.p10.3.m3.1.1.3" xref="S2.p10.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p10.3.m3.1b"><apply id="S2.p10.3.m3.1.1.cmml" xref="S2.p10.3.m3.1.1"><eq id="S2.p10.3.m3.1.1.1.cmml" xref="S2.p10.3.m3.1.1.1"></eq><apply id="S2.p10.3.m3.1.1.2.cmml" xref="S2.p10.3.m3.1.1.2"><ci id="S2.p10.3.m3.1.1.2.1.cmml" xref="S2.p10.3.m3.1.1.2.1">^</ci><ci id="S2.p10.3.m3.1.1.2.2.cmml" xref="S2.p10.3.m3.1.1.2.2">ğ‘Œ</ci></apply><cn type="integer" id="S2.p10.3.m3.1.1.3.cmml" xref="S2.p10.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.3.m3.1c">\hat{Y}=0</annotation></semantics></math> would perfectly satisfy equalized odds, thereby appearing very fair but offering no predictive value.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2205.04321/assets/data_pipeline.jpg" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="175" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data pipeline used to evaluate the downstream fairness outcomes of classifiers trained on DP synthetic data. Note that separate pipelines were used to train DP synthesizers on the original non-private training data and pre-processed non-private training data.</figcaption>
</figure>
<div id="S2.p11" class="ltx_para">
<p id="S2.p11.1" class="ltx_p"><span id="S2.p11.1.1" class="ltx_text ltx_font_bold">Data.</span> We ran experiments on three data sets, including the ProPublica COMPAS data set <cite class="ltx_cite ltx_citemacro_citep">(ProPublica, <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite> and the UCI Adult data set <cite class="ltx_cite ltx_citemacro_citep">(Dua &amp; Graff, <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite>. We also used the ACS Income data set, which has been proposed as a substitute for Adult <cite class="ltx_cite ltx_citemacro_citep">(Ding etÂ al., <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>. For each data set, we focused on a particular binary classification task (predicting recidivism in COMPAS and income category in Adult and ACS Income), and measured equalized odds distances with respect to a binary protected attribute of interest (race in COMPAS and gender in Adult and ACS Income).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.3" class="ltx_p">Our results pipeline is summarized in Figure <a href="#S2.F1" title="Figure 1 â€£ 2 Background and Preliminaries â€£ Evaluating the Fairness Impact of Differentially Private Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For each synthesizer and data set, we split the original data into train and test sets. This allowed us to train a synthesizer and generate DP synthetic data while holding out some non-private data for evaluation. We then trained logistic regression binary classifiers with <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S3.p1.1.m1.1a"><msub id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">L</mi><mn id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ğ¿</ci><cn type="integer" id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">L_{2}</annotation></semantics></math> regularization on the synthetic data and evaluated their predictions on the original, non-private data. We repeated this procedure across <math id="S3.p1.2.m2.4" class="ltx_Math" alttext="\varepsilon=[1.0,2.0,\dots,8.0]" display="inline"><semantics id="S3.p1.2.m2.4a"><mrow id="S3.p1.2.m2.4.5" xref="S3.p1.2.m2.4.5.cmml"><mi id="S3.p1.2.m2.4.5.2" xref="S3.p1.2.m2.4.5.2.cmml">Îµ</mi><mo id="S3.p1.2.m2.4.5.1" xref="S3.p1.2.m2.4.5.1.cmml">=</mo><mrow id="S3.p1.2.m2.4.5.3.2" xref="S3.p1.2.m2.4.5.3.1.cmml"><mo stretchy="false" id="S3.p1.2.m2.4.5.3.2.1" xref="S3.p1.2.m2.4.5.3.1.cmml">[</mo><mn id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">1.0</mn><mo id="S3.p1.2.m2.4.5.3.2.2" xref="S3.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S3.p1.2.m2.2.2" xref="S3.p1.2.m2.2.2.cmml">2.0</mn><mo id="S3.p1.2.m2.4.5.3.2.3" xref="S3.p1.2.m2.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.p1.2.m2.3.3" xref="S3.p1.2.m2.3.3.cmml">â€¦</mi><mo id="S3.p1.2.m2.4.5.3.2.4" xref="S3.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S3.p1.2.m2.4.4" xref="S3.p1.2.m2.4.4.cmml">8.0</mn><mo stretchy="false" id="S3.p1.2.m2.4.5.3.2.5" xref="S3.p1.2.m2.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.4b"><apply id="S3.p1.2.m2.4.5.cmml" xref="S3.p1.2.m2.4.5"><eq id="S3.p1.2.m2.4.5.1.cmml" xref="S3.p1.2.m2.4.5.1"></eq><ci id="S3.p1.2.m2.4.5.2.cmml" xref="S3.p1.2.m2.4.5.2">ğœ€</ci><list id="S3.p1.2.m2.4.5.3.1.cmml" xref="S3.p1.2.m2.4.5.3.2"><cn type="float" id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">1.0</cn><cn type="float" id="S3.p1.2.m2.2.2.cmml" xref="S3.p1.2.m2.2.2">2.0</cn><ci id="S3.p1.2.m2.3.3.cmml" xref="S3.p1.2.m2.3.3">â€¦</ci><cn type="float" id="S3.p1.2.m2.4.4.cmml" xref="S3.p1.2.m2.4.4">8.0</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.4c">\varepsilon=[1.0,2.0,\dots,8.0]</annotation></semantics></math>. To understand the variability of our results, we performed ten trials at each privacy budget, generating a total of <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S3.p1.3.m3.1a"><mn id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><cn type="integer" id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">80</annotation></semantics></math> synthetic data sets.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.3" class="ltx_p">To mitigate unfairness in downstream classifiers, we repeated these experiments on pre-processed training sets that balanced the number of observations with respect to both the relevant protected attribute <math id="S3.p2.1.m1.2" class="ltx_Math" alttext="A\in\{0,1\}" display="inline"><semantics id="S3.p2.1.m1.2a"><mrow id="S3.p2.1.m1.2.3" xref="S3.p2.1.m1.2.3.cmml"><mi id="S3.p2.1.m1.2.3.2" xref="S3.p2.1.m1.2.3.2.cmml">A</mi><mo id="S3.p2.1.m1.2.3.1" xref="S3.p2.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S3.p2.1.m1.2.3.3.2" xref="S3.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.p2.1.m1.2.3.3.2.1" xref="S3.p2.1.m1.2.3.3.1.cmml">{</mo><mn id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">0</mn><mo id="S3.p2.1.m1.2.3.3.2.2" xref="S3.p2.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.p2.1.m1.2.2" xref="S3.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.p2.1.m1.2.3.3.2.3" xref="S3.p2.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.2b"><apply id="S3.p2.1.m1.2.3.cmml" xref="S3.p2.1.m1.2.3"><in id="S3.p2.1.m1.2.3.1.cmml" xref="S3.p2.1.m1.2.3.1"></in><ci id="S3.p2.1.m1.2.3.2.cmml" xref="S3.p2.1.m1.2.3.2">ğ´</ci><set id="S3.p2.1.m1.2.3.3.1.cmml" xref="S3.p2.1.m1.2.3.3.2"><cn type="integer" id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">0</cn><cn type="integer" id="S3.p2.1.m1.2.2.cmml" xref="S3.p2.1.m1.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.2c">A\in\{0,1\}</annotation></semantics></math> and label <math id="S3.p2.2.m2.2" class="ltx_Math" alttext="Y\in\{0,1\}" display="inline"><semantics id="S3.p2.2.m2.2a"><mrow id="S3.p2.2.m2.2.3" xref="S3.p2.2.m2.2.3.cmml"><mi id="S3.p2.2.m2.2.3.2" xref="S3.p2.2.m2.2.3.2.cmml">Y</mi><mo id="S3.p2.2.m2.2.3.1" xref="S3.p2.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S3.p2.2.m2.2.3.3.2" xref="S3.p2.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.p2.2.m2.2.3.3.2.1" xref="S3.p2.2.m2.2.3.3.1.cmml">{</mo><mn id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">0</mn><mo id="S3.p2.2.m2.2.3.3.2.2" xref="S3.p2.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.p2.2.m2.2.2" xref="S3.p2.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.p2.2.m2.2.3.3.2.3" xref="S3.p2.2.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.2b"><apply id="S3.p2.2.m2.2.3.cmml" xref="S3.p2.2.m2.2.3"><in id="S3.p2.2.m2.2.3.1.cmml" xref="S3.p2.2.m2.2.3.1"></in><ci id="S3.p2.2.m2.2.3.2.cmml" xref="S3.p2.2.m2.2.3.2">ğ‘Œ</ci><set id="S3.p2.2.m2.2.3.3.1.cmml" xref="S3.p2.2.m2.2.3.3.2"><cn type="integer" id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">0</cn><cn type="integer" id="S3.p2.2.m2.2.2.cmml" xref="S3.p2.2.m2.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.2c">Y\in\{0,1\}</annotation></semantics></math>. This simple pre-processing method, which we call â€œmulti-label undersampling,â€ identifies the minority group <math id="S3.p2.3.m3.2" class="ltx_Math" alttext="\{a,y\}\in A\times Y" display="inline"><semantics id="S3.p2.3.m3.2a"><mrow id="S3.p2.3.m3.2.3" xref="S3.p2.3.m3.2.3.cmml"><mrow id="S3.p2.3.m3.2.3.2.2" xref="S3.p2.3.m3.2.3.2.1.cmml"><mo stretchy="false" id="S3.p2.3.m3.2.3.2.2.1" xref="S3.p2.3.m3.2.3.2.1.cmml">{</mo><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">a</mi><mo id="S3.p2.3.m3.2.3.2.2.2" xref="S3.p2.3.m3.2.3.2.1.cmml">,</mo><mi id="S3.p2.3.m3.2.2" xref="S3.p2.3.m3.2.2.cmml">y</mi><mo stretchy="false" id="S3.p2.3.m3.2.3.2.2.3" xref="S3.p2.3.m3.2.3.2.1.cmml">}</mo></mrow><mo id="S3.p2.3.m3.2.3.1" xref="S3.p2.3.m3.2.3.1.cmml">âˆˆ</mo><mrow id="S3.p2.3.m3.2.3.3" xref="S3.p2.3.m3.2.3.3.cmml"><mi id="S3.p2.3.m3.2.3.3.2" xref="S3.p2.3.m3.2.3.3.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p2.3.m3.2.3.3.1" xref="S3.p2.3.m3.2.3.3.1.cmml">Ã—</mo><mi id="S3.p2.3.m3.2.3.3.3" xref="S3.p2.3.m3.2.3.3.3.cmml">Y</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.2b"><apply id="S3.p2.3.m3.2.3.cmml" xref="S3.p2.3.m3.2.3"><in id="S3.p2.3.m3.2.3.1.cmml" xref="S3.p2.3.m3.2.3.1"></in><set id="S3.p2.3.m3.2.3.2.1.cmml" xref="S3.p2.3.m3.2.3.2.2"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">ğ‘</ci><ci id="S3.p2.3.m3.2.2.cmml" xref="S3.p2.3.m3.2.2">ğ‘¦</ci></set><apply id="S3.p2.3.m3.2.3.3.cmml" xref="S3.p2.3.m3.2.3.3"><times id="S3.p2.3.m3.2.3.3.1.cmml" xref="S3.p2.3.m3.2.3.3.1"></times><ci id="S3.p2.3.m3.2.3.3.2.cmml" xref="S3.p2.3.m3.2.3.3.2">ğ´</ci><ci id="S3.p2.3.m3.2.3.3.3.cmml" xref="S3.p2.3.m3.2.3.3.3">ğ‘Œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.2c">\{a,y\}\in A\times Y</annotation></semantics></math> and randomly undersamples observations from the other three groups until the counts of all four are equal. The resulting data set is still non-private but removes pre-existing class imbalances. As discussed below, this encourages synthesizers to generate more balanced data and binary classification models trained on those data to make more fair predictions.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">For each data set and synthesizer, therefore, we generated a total of 160 synthetic data sets (80 with pre-processing, and 80 without it). In the following section, we describe the differences among these data sets and the fairness and accuracy of logistic regression classifiers trained on them.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<figure id="S4.F2" class="ltx_figure"><img src="/html/2205.04321/assets/proportions_boxplots.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distributions of the proportion of the minority group (with respect to the relevant protected attribute <math id="S4.F2.3.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.F2.3.m1.1b"><mi id="S4.F2.3.m1.1.1" xref="S4.F2.3.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F2.3.m1.1c"><ci id="S4.F2.3.m1.1.1.cmml" xref="S4.F2.3.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.3.m1.1d">A</annotation></semantics></math> and label <math id="S4.F2.4.m2.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S4.F2.4.m2.1b"><mi id="S4.F2.4.m2.1.1" xref="S4.F2.4.m2.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S4.F2.4.m2.1c"><ci id="S4.F2.4.m2.1.1.cmml" xref="S4.F2.4.m2.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.4.m2.1d">Y</annotation></semantics></math>) in synthetic data generated across data sets and synthesizers. Each blue boxplot corresponds to 80 synthetic data sets generated on the original data, while each orange boxplot shows the results for 80 synthetic data sets obtained by training synthesizers on pre-processed data. The black dotted lines represent the proportion of the minority group present in the original, non-private training data.</figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">In our experiments, we found that privacy budget did not have a significant impact on the fairness and accuracy of downstream classifiers. More specifically, the variation in the results obtained across trials at fixed epsilon values was generally larger than the differences between them. Therefore, we analyzed the 80 synthetic data sets for each synthesizer and data set in aggregate. We note that restricting the privacy budget to lower <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">Îµ</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">ğœ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\varepsilon</annotation></semantics></math> values yielded similar results, so we include our results up to <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="\varepsilon=8.0" display="inline"><semantics id="S4.p1.2.m2.1a"><mrow id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mi id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">Îµ</mi><mo id="S4.p1.2.m2.1.1.1" xref="S4.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml">8.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><eq id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1"></eq><ci id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2">ğœ€</ci><cn type="float" id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3">8.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\varepsilon=8.0</annotation></semantics></math> for completeness.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The differences observed among synthesizers, however, were more significant and are the focus of our discussion below. QUAIL-DPCTGAN and QUAIL-PATECTGAN showed highly variable performance, indicating that hyperparameter tuning may be required to reliably use GAN-based synthesizers in practice, even when they are augmented with QUAIL.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Synthetic Data Distributions</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">To understand how DP synthesizers might affect fairness outcomes on downstream classification tasks, we first analyzed the proportion of the minority group <math id="S4.SS1.p1.1.m1.2" class="ltx_Math" alttext="\{a,y\}\in A\times Y" display="inline"><semantics id="S4.SS1.p1.1.m1.2a"><mrow id="S4.SS1.p1.1.m1.2.3" xref="S4.SS1.p1.1.m1.2.3.cmml"><mrow id="S4.SS1.p1.1.m1.2.3.2.2" xref="S4.SS1.p1.1.m1.2.3.2.1.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.2.3.2.2.1" xref="S4.SS1.p1.1.m1.2.3.2.1.cmml">{</mo><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">a</mi><mo id="S4.SS1.p1.1.m1.2.3.2.2.2" xref="S4.SS1.p1.1.m1.2.3.2.1.cmml">,</mo><mi id="S4.SS1.p1.1.m1.2.2" xref="S4.SS1.p1.1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S4.SS1.p1.1.m1.2.3.2.2.3" xref="S4.SS1.p1.1.m1.2.3.2.1.cmml">}</mo></mrow><mo id="S4.SS1.p1.1.m1.2.3.1" xref="S4.SS1.p1.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S4.SS1.p1.1.m1.2.3.3" xref="S4.SS1.p1.1.m1.2.3.3.cmml"><mi id="S4.SS1.p1.1.m1.2.3.3.2" xref="S4.SS1.p1.1.m1.2.3.3.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.1.m1.2.3.3.1" xref="S4.SS1.p1.1.m1.2.3.3.1.cmml">Ã—</mo><mi id="S4.SS1.p1.1.m1.2.3.3.3" xref="S4.SS1.p1.1.m1.2.3.3.3.cmml">Y</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.2b"><apply id="S4.SS1.p1.1.m1.2.3.cmml" xref="S4.SS1.p1.1.m1.2.3"><in id="S4.SS1.p1.1.m1.2.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.1"></in><set id="S4.SS1.p1.1.m1.2.3.2.1.cmml" xref="S4.SS1.p1.1.m1.2.3.2.2"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ‘</ci><ci id="S4.SS1.p1.1.m1.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2">ğ‘¦</ci></set><apply id="S4.SS1.p1.1.m1.2.3.3.cmml" xref="S4.SS1.p1.1.m1.2.3.3"><times id="S4.SS1.p1.1.m1.2.3.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.3.1"></times><ci id="S4.SS1.p1.1.m1.2.3.3.2.cmml" xref="S4.SS1.p1.1.m1.2.3.3.2">ğ´</ci><ci id="S4.SS1.p1.1.m1.2.3.3.3.cmml" xref="S4.SS1.p1.1.m1.2.3.3.3">ğ‘Œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.2c">\{a,y\}\in A\times Y</annotation></semantics></math> present in the synthetic data sets. As shown in Figure <a href="#S4.F2" title="Figure 2 â€£ 4 Experimental Results â€£ Evaluating the Fairness Impact of Differentially Private Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, QUAIL-MWEM, QUAIL-DPCTGAN, and QUAIL-PATECTGAN frequently <em id="S4.SS1.p1.1.1" class="ltx_emph ltx_font_italic">decreased</em> this proportion relative to the original, non-private data. This suggests that these synthesizers may exacerbate pre-existing class imbalances in the original data. However, training synthesizers on data that were pre-processed with multi-label undersampling mitigated this issue, yielding synthetic data sets with minority proportions closer to 0.25.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Interestingly, MST does not appear to suffer from this issue and generated synthetic data with minority proportions almost exactly equal to the non-private proportions in Adult, ACS Income, and COMPAS. Further, the variation in the MST minority proportions is significantly smaller than those yielded by the other three synthesizers. These observations indicate that pre-processing the non-private data may not be necessary when using MST.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Binary Classification</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Having analyzed the differences among various DP synthetic data sets in terms of their minority group proportions, we turn our attention to how these differences manifest in the fairness and accuracy of downstream logistic regression classifiers.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 â€£ 4.2 Binary Classification â€£ 4 Experimental Results â€£ Evaluating the Fairness Impact of Differentially Private Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> indicates that, on average, classifiers trained on data generated by QUAIL-MWEM, QUAIL-DPCTGAN, and QUAIL-PATECTGAN had higher equalized odds distances (i.e., were less fair) than those trained on non-private training data. This is particularly evident on the ACS Income data, where the average equalized odds distances are nearly twice the non-private metric. Similar results, not shown here, were obtained on the Adult data set.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Further, we observed a strong association between the minority group proportions visualized in Figure <a href="#S4.F2" title="Figure 2 â€£ 4 Experimental Results â€£ Evaluating the Fairness Impact of Differentially Private Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and the downstream fairness outcomes shown in Figure <a href="#S4.F3" title="Figure 3 â€£ 4.2 Binary Classification â€£ 4 Experimental Results â€£ Evaluating the Fairness Impact of Differentially Private Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In particular, synthetic data sets with lower minority proportions than non-private data (such as those generated on ACS Income) are associated with less fair outcomes, while synthetic data sets that do not decrease this proportion (such as those generated on COMPAS), are less likely to degrade fairness. Intuitively, classifiers trained on data sets containing fewer observations of a particular group are more likely to make incorrect predictions with respect to that group.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">The same reasoning can be used to explain the reverse outcome. In particular, our pre-processing method, which encourages synthesizers to generate data with higher proportions of the minority group, is also associated with lower equalized odds distances (more fair outcomes). Similarly, MST did not significantly alter the minority group proportions in comparison to non-private data and therefore did not degrade fairness.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">Contrary to the frequently cited trade-off between fairness and accuracy, Figure <a href="#S4.F3" title="Figure 3 â€£ 4.2 Binary Classification â€£ 4 Experimental Results â€£ Evaluating the Fairness Impact of Differentially Private Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> also shows that improvements in fairness were granted with virtually no reductions in accuracy. In fact, the most fair and accurate results were both achieved by MST, which had F1-scores nearly equivalent to those obtained on non-private data. The average accuracies achieved by the other three synthesizers, however, were significantly lower.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2205.04321/assets/metrics_barcharts.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="284" height="215" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Average fairness and accuracy metrics obtained across synthesizers on the ACS Income and COMPAS data sets. Each orange and blue bar indicates the average metric obtained with and without pre-processing, respectively, while the dotted line shows the metric obtained using the original, non-private training data.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we studied the effect of differentially private synthetic data on downstream fairness outcomes. We found that three out of the four synthesizers investigated frequently degrade fairness and drew an association between less fair outcomes and decreased proportions of minority groups in the generated synthetic data. This motivated our method of pre-processing the non-private training data, which encouraged synthesizers to generate more balanced classes and mitigated unfair outcomes while retaining predictive accuracy. However, The MST synthesizer achieved fairness and accuracy metrics that were close to those obtained using non-private data â€“ even without pre-processing â€“ and may be a preferable option for real-world applications involving DP synthetic data.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi etÂ al. (2016)</span>
<span class="ltx_bibblock">
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.Â B., Mironov, I., Talwar, K.,
and Zhang, L.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security</em>, Oct 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/2976749.2978318</span>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan &amp; Shmatikov (2019)</span>
<span class="ltx_bibblock">
Bagdasaryan, E. and Shmatikov, V.

</span>
<span class="ltx_bibblock">Differential privacy has disparate impact on model accuracy, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding etÂ al. (2021)</span>
<span class="ltx_bibblock">
Ding, F., Hardt, M., Miller, J., and Schmidt, L.

</span>
<span class="ltx_bibblock">Retiring adult: New datasets for fair machine learning, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua &amp; Graff (2017)</span>
<span class="ltx_bibblock">
Dua, D. and Graff, C.

</span>
<span class="ltx_bibblock">UCI machine learning repository, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://archive.ics.uci.edu/ml" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://archive.ics.uci.edu/ml</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork (2006)</span>
<span class="ltx_bibblock">
Dwork, C.

</span>
<span class="ltx_bibblock">Differential privacy.

</span>
<span class="ltx_bibblock">In Bugliesi, M., Preneel, B., Sassone, V., and Wegener, I. (eds.),
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Automata, Languages and Programming</em>, pp.Â  1â€“12, Berlin, Heidelberg,
2006. Springer Berlin Heidelberg.

</span>
<span class="ltx_bibblock">ISBN 978-3-540-35908-1.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork etÂ al. (2011)</span>
<span class="ltx_bibblock">
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R.

</span>
<span class="ltx_bibblock">Fairness through awareness, 2011.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng &amp; Viswanath (2014)</span>
<span class="ltx_bibblock">
Geng, Q. and Viswanath, P.

</span>
<span class="ltx_bibblock">The optimal mechanism in differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2014 IEEE International Symposium on Information Theory</em>,
pp.Â  2371â€“2375, 2014.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ISIT.2014.6875258</span>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow etÂ al. (2014)</span>
<span class="ltx_bibblock">
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
S., Courville, A., and Bengio, Y.

</span>
<span class="ltx_bibblock">Generative adversarial nets.

</span>
<span class="ltx_bibblock">In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N., and
Weinberger, K.Â Q. (eds.), <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, volumeÂ 27. Curran Associates, Inc., 2014.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt etÂ al. (2012)</span>
<span class="ltx_bibblock">
Hardt, M., Ligett, K., and McSherry, F.

</span>
<span class="ltx_bibblock">A simple and practical algorithm for differentially private data
release, 2012.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKenna etÂ al. (2019)</span>
<span class="ltx_bibblock">
McKenna, R., Sheldon, D., and Miklau, G.

</span>
<span class="ltx_bibblock">Graphical-model based estimation and inference for differential
privacy, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/1901.09136" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1901.09136</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKenna etÂ al. (2021)</span>
<span class="ltx_bibblock">
McKenna, R., Miklau, G., and Sheldon, D.

</span>
<span class="ltx_bibblock">Winning the nist contest: A scalable and general approach to
differentially private synthetic data, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2108.04978" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2108.04978</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ProPublica (2021)</span>
<span class="ltx_bibblock">
ProPublica.

</span>
<span class="ltx_bibblock">Compas recidivism risk score data and analysis.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis</a>,
2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rosenblatt etÂ al. (2020)</span>
<span class="ltx_bibblock">
Rosenblatt, L., Liu, X., Pouyanfar, S., deÂ Leon, E., Desai, A., and Allen, J.

</span>
<span class="ltx_bibblock">Differentially private synthetic data: Applied evaluations and
enhancements, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri etÂ al. (2017)</span>
<span class="ltx_bibblock">
Shokri, R., Stronati, M., Song, C., and Shmatikov, V.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Symposium on Security and Privacy (SP)</em>, pp.Â 3â€“18, 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/SP.2017.41</span>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2019)</span>
<span class="ltx_bibblock">
Xu, L., Skoularidou, M., Cuesta-Infante, A., and Veeramachaneni, K.

</span>
<span class="ltx_bibblock">Modeling tabular data using conditional gan, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon etÂ al. (2019)</span>
<span class="ltx_bibblock">
Yoon, J., Jordon, J., and vanÂ der Schaar, M.

</span>
<span class="ltx_bibblock">PATE-GAN: Generating synthetic data with differential privacy
guarantees.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2205.04320" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2205.04321" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2205.04321">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2205.04321" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2205.04322" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 15:40:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
