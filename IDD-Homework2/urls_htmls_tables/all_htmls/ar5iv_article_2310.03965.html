<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Thought Propagation:
  <br class="ltx_break"/>
  An Analogical Approach to Complex Reasoning with Large Language Models
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Junchi Yu &amp; Ran He
    <br class="ltx_break"/>
    Institute of Automation
    <br class="ltx_break"/>
    Chinese Academy of Sciences
    <br class="ltx_break"/>
    Beijing, China
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id1.1.id1">
     yujunchi2019@ia.ac.cn
    </span>
    ,
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id2.2.id2">
     rhe@nlpr.ia.ac.cn
    </span>
    <br class="ltx_break"/>
    &amp;Rex Ying
    <br class="ltx_break"/>
    Department of Computer Sciences
    <br class="ltx_break"/>
    Yale University
    <br class="ltx_break"/>
    New Haven, USA
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id3.3.id3">
     rex.ying@yale.edu
    </span>
    <br class="ltx_break"/>
   </span>
   <span class="ltx_author_notes">
    Corresponding Author.
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id4.id1">
   Large Language Models (LLMs) have achieved remarkable success in reasoning tasks with the development of prompting methods.
However, existing prompting approaches cannot reuse insights of solving similar problems and suffer from accumulated errors in multi-step reasoning, since they prompt LLMs to reason
   <span class="ltx_text ltx_font_italic" id="id4.id1.1">
    from scratch
   </span>
   .
To address these issues, we propose
   <span class="ltx_text ltx_font_bold ltx_font_italic" id="id4.id1.2">
    Thought Propagation
    <span class="ltx_text ltx_font_upright" id="id4.id1.2.1">
     (TP)
    </span>
   </span>
   , which explores the analogous problems and leverages their solutions to enhance the complex reasoning ability of LLMs.
These analogous problems are related to the input one, with reusable solutions and problem-solving strategies.
Thus, it is promising to propagate insights of solving previous analogous problems to inspire new problem-solving.
To achieve this, TP first prompts LLMs to propose and solve a set of analogous problems that are related to the input one.
Then, TP reuses the results of analogous problems to directly yield a new solution or derive a knowledge-intensive plan for execution to amend the initial solution obtained from scratch.
TP is compatible with existing prompting approaches, allowing plug-and-play generalization and enhancement in a wide range of tasks without much labor in task-specific prompt engineering.
Experiments across three challenging tasks demonstrate TP enjoys a substantial improvement over the baselines by an average of 12% absolute increase in finding the optimal solutions in Shortest-path Reasoning, 13% improvement of human preference in Creative Writing, and 15% enhancement in the task completion rate of LLM-Agent Planning.
  </p>
 </div>
 <figure class="ltx_figure" id="S0.F1">
  <p class="ltx_p ltx_align_center ltx_align_center" id="S0.F1.1.1">
   <span class="ltx_text" id="S0.F1.1.1.1">
    <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="161" id="S0.F1.1.1.1.g1" src="/html/2310.03965/assets/x1.png" width="461"/>
   </span>
  </p>
  <figcaption class="ltx_caption">
   <span class="ltx_tag ltx_tag_figure">
    Figure 1:
   </span>
   Reasoning from scratch cannot reuse insight of solving similar problems and suffers from accumulated errors in intermediate reasoning stages. Thought Propagation explores analogous problems that are related to the input one and derives insights from solutions to analogous problems.
  </figcaption>
 </figure>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para ltx_noindent" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    The scaling-up Large Language Models (LLMs)
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023
     </a>
     )
    </cite>
    have achieved notable success in logical
    <cite class="ltx_cite ltx_citemacro_citep">
     (Khot et al.,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     )
    </cite>
    , arithmetic
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2022
     </a>
     )
    </cite>
    , and commonsense
    <cite class="ltx_cite ltx_citemacro_citep">
     (Liu et al.,
     <a class="ltx_ref" href="#bib.bib28" title="">
      2021
     </a>
     )
    </cite>
    reasoning with the development of prompting methods
    <cite class="ltx_cite ltx_citemacro_citep">
     (Qiao et al.,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2022
     </a>
     )
    </cite>
    . The early works employ few-shot input and output exemplars to prompt the LLM to perform simple reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2020
     </a>
     )
    </cite>
    . Recent methods decompose the complex reasoning process into intermediate reasoning steps to enable LLMs with multi-step reasoning abilities
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2022
     </a>
     ; Wang et al.,
     <a class="ltx_ref" href="#bib.bib46" title="">
      2022a
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Although many efforts are made to improve complex reasoning with LLMs by crafted prompt design
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhang et al.,
     <a class="ltx_ref" href="#bib.bib57" title="">
      2022b
     </a>
     )
    </cite>
    , delicate decomposition
    <cite class="ltx_cite ltx_citemacro_citep">
     (Khot et al.,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     ; Zhou et al.,
     <a class="ltx_ref" href="#bib.bib59" title="">
      2022
     </a>
     )
    </cite>
    , and advanced searching scheme
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     )
    </cite>
    , these methods prompt the LLM to reason
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">
     from scratch
    </span>
    .
This scheme is problematic to complex reasoning for two reasons.
First, reasoning from scratch cannot reuse the insights of solving similar problems
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hall,
     <a class="ltx_ref" href="#bib.bib18" title="">
      1989
     </a>
     )
    </cite>
    .
Using such insights as prior knowledge can ease the difficulty of solving complex problems and develop new solutions
    <cite class="ltx_cite ltx_citemacro_citep">
     (Carbonell,
     <a class="ltx_ref" href="#bib.bib10" title="">
      1985
     </a>
     )
    </cite>
    .
One can further assess new solutions with rough ones obtained from scratch and yield refined solutions.
Second, reasoning from scratch is sensitive to the errors made in intermediate stages when facing tasks involving multi-step reasoning.
As shown in Figure
    <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    , these errors will accumulate as they misguide the searching and planning afterward, which eventually leads to invalid reasoning outcome
    <cite class="ltx_cite ltx_citemacro_citep">
     (Dziri et al.,
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023
     </a>
     ; Yao et al.,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2022
     </a>
     )
    </cite>
    .
These two challenges motivate us to develop an alternative framework for LLM reasoning to amend the limitations of reasoning from scratch.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    The study of human cognition presents a promising way to amend the limitations of reasoning from scratch, primarily through the application of analogy
    <cite class="ltx_cite ltx_citemacro_citep">
     (Bartha,
     <a class="ltx_ref" href="#bib.bib3" title="">
      2013
     </a>
     )
    </cite>
    .
The analogy highlights the occurrence of entities’ relationship in the form of ”A is to B what C is to D”.
By discerning and applying such analogical reasoning, humans can stand on the shoulder of existing knowledge to pioneer new concepts in novel domains.
A compelling historical example is the discovery of Coulomb’s Law, which can be traced back to the analogy drawn between gravitational forces governing celestial bodies and electrical forces acting upon charged particles
    <cite class="ltx_cite ltx_citemacro_citep">
     (Priestley,
     <a class="ltx_ref" href="#bib.bib35" title="">
      1775
     </a>
     )
    </cite>
    .
Such a framework has been recently proven to be efficient in relational reasoning between entities on knowledge graphs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhang et al.,
     <a class="ltx_ref" href="#bib.bib56" title="">
      2022a
     </a>
     ; Yuan et al.,
     <a class="ltx_ref" href="#bib.bib55" title="">
      2023
     </a>
     )
    </cite>
    . However, a general framework of harnessing analogies among problems to facilitate LLM reasoning, to the best of our knowledge, is yet to be explored.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    Hence, we advance the traditional analogical reasoning and propose a novel
    <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p4.1.1">
     Thought Propagation
     <span class="ltx_text ltx_font_upright" id="S1.p4.1.1.1">
      (TP)
     </span>
    </span>
    framework to amend existing reasoning-from-scratch methods and enhance the complex reasoning ability of LLMs.
Given an input problem, TP first prompts LLMs to propose a set of analogous problems that are related to the input one.
Then, the input problem with its analogous counterpart is solved by existing prompting approaches such as Chain-of-Thought (CoT)
    <cite class="ltx_cite ltx_citemacro_cite">
     Wei et al. (
     <a class="ltx_ref" href="#bib.bib50" title="">
      2022
     </a>
     )
    </cite>
    .
An aggregation module further aggregates the solutions from these analogous problems, facilitating input problem-solving through two distinct avenues.
First, this module reuses the solutions derived from analogous problems to generate a new solution to the input problem.
The aggregation module assesses the new solution produced by the analogical approach with the initial one obtained from scratch to output a refined result for the input problem.
Second, this module compares the input problem with its analogous counterparts and devises high-level plans based on the results of analogous problems.
These plans are then executed by the LLM to rectify its intermediate reasoning steps when addressing the input problem.
TP is compatible with existing approaches, allowing plug-and-play generalization and enhancement to various tasks ranging from optimization problems to autonomous agent planning.
Thus, it reduces intensive labor in task-specific prompt engineering.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    We test the proposed method on three tasks, including Shortest-path Reasoning, Creative Writing, and LLM-Agent Planning. These tasks require searching over graph-structure data, open-ended writing, and long-trial planning, which challenge existing methods for LLM reasoning. Experimental results show that Thought Propagation can generalize to a wide range of different reasoning tasks and enjoys superior performances on all of them.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <div class="ltx_para ltx_noindent" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">
     Graph Neural Network
    </span>
    .
Graph neural networks (GNNs) are expressive network backbones of deep graph learning due to their inductive bias on graph-structured data
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hamilton et al.,
     <a class="ltx_ref" href="#bib.bib19" title="">
      2017
     </a>
     ; Kipf &amp; Welling,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2017
     </a>
     )
    </cite>
    . GNNs aggregate the neighborhood node messages to obtain node embeddings
    <cite class="ltx_cite ltx_citemacro_citep">
     (Gilmer et al.,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2017
     </a>
     )
    </cite>
    . Recent works incorporate parameterized GNNs with Large Language Models (LLMs) for graph-related tasks, such as graph explainability
    <cite class="ltx_cite ltx_citemacro_citep">
     (He et al.,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023
     </a>
     )
    </cite>
    , classification
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chen et al.,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2023b
     </a>
     ; Qian et al.,
     <a class="ltx_ref" href="#bib.bib36" title="">
      2023
     </a>
     )
    </cite>
    , and question answering
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jiang et al.,
     <a class="ltx_ref" href="#bib.bib22" title="">
      2023
     </a>
     )
    </cite>
    . Differently, our work aims to improve the general reasoning ability of LLMs using problem analogy without fine-tuning.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p2">
   <p class="ltx_p" id="S2.p2.1">
    <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">
     Analogical Reasoning
    </span>
    . The analogical reasoning has been applied to visual reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Małkiński &amp; Mańdziuk,
     <a class="ltx_ref" href="#bib.bib31" title="">
      2022
     </a>
     )
    </cite>
    , natural language reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chen et al.,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2022
     </a>
     ; Sultan &amp; Shahaf,
     <a class="ltx_ref" href="#bib.bib43" title="">
      2022
     </a>
     )
    </cite>
    , and knowledge graph reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhang et al.,
     <a class="ltx_ref" href="#bib.bib56" title="">
      2022a
     </a>
     )
    </cite>
    . These methods train parameterized neural networks to perform relational reasoning between entities. Early attempts have shown LLMs can do analogical reasoning just like humans by case study
    <cite class="ltx_cite ltx_citemacro_citep">
     (Webb et al.,
     <a class="ltx_ref" href="#bib.bib49" title="">
      2023
     </a>
     )
    </cite>
    . Recent works explore analogy generation and analogy reasoning with knowledge graphs on LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yuan et al.,
     <a class="ltx_ref" href="#bib.bib55" title="">
      2023
     </a>
     ; Bhavya et al.,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib6" title="">
      2023
     </a>
     )
    </cite>
    . However, they focus on different applications instead of general reasoning problems. Moreover, they rely on large-scale external knowledge bases to store entity relationships to perform analogical reasoning, which is expensive for general reasoning tasks. Thus, a general analogical approach for LLM complex reasoning on general tasks is still in its vacuum.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p3">
   <p class="ltx_p" id="S2.p3.1">
    <span class="ltx_text ltx_font_bold" id="S2.p3.1.1">
     Prompt-based Large Language Model Reasoning
    </span>
    . Originally designed for text generation, the Large Language Models (LLMs) have succeeded in many applications with prompting methods
    <cite class="ltx_cite ltx_citemacro_citep">
     (Liu et al.,
     <a class="ltx_ref" href="#bib.bib29" title="">
      2023b
     </a>
     ; Zhao et al.,
     <a class="ltx_ref" href="#bib.bib58" title="">
      2023
     </a>
     )
    </cite>
    . Early methods employ input and output (IO) prompting that appends pairs of problems and solutions exemplars on top of the input problem
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2020
     </a>
     )
    </cite>
    . Recent methods decompose the complex reasoning process into intermediate reasoning steps. They use multi-step prompting
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2022
     </a>
     ; Wang et al.,
     <a class="ltx_ref" href="#bib.bib46" title="">
      2022a
     </a>
     ; Zhang et al.,
     <a class="ltx_ref" href="#bib.bib57" title="">
      2022b
     </a>
     )
    </cite>
    or recursive problem decomposition
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhou et al.,
     <a class="ltx_ref" href="#bib.bib59" title="">
      2022
     </a>
     ; Khot et al.,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     )
    </cite>
    to enable multi-step LLMs reasoning. Others design searching schemes for LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     ; Besta et al.,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2023
     </a>
     )
    </cite>
    . However, they solve each problem from scratch. Thus, they cannot reuse the insights of solving similar problems. Moreover, they suffer from accumulated errors in intermediate reasoning steps.
   </p>
  </div>
  <figure class="ltx_figure" id="S2.F2">
   <p class="ltx_p ltx_align_center ltx_align_center" id="S2.F2.1.1">
    <span class="ltx_text" id="S2.F2.1.1.1">
     <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="112" id="S2.F2.1.1.1.g1" src="/html/2310.03965/assets/x2.png" width="438"/>
    </span>
   </p>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    An example of existing methods on shortest path reasoning task. Although the graph in (a) is quite simple, these methods only prompt the LLM to find the sub-optimal solutions (b,c), and even repeatedly visit intermediate nodes (d), due to reasoning from scratch.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S2.p4">
   <p class="ltx_p" id="S2.p4.1">
    <span class="ltx_text ltx_font_bold" id="S2.p4.1.1">
     LLM as Autonomous Agents
    </span>
    . LLM-Agents can interface with tools
    <cite class="ltx_cite ltx_citemacro_citep">
     (Cai et al.,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     ; Schick et al.,
     <a class="ltx_ref" href="#bib.bib38" title="">
      2023
     </a>
     ; Chen et al.,
     <a class="ltx_ref" href="#bib.bib13" title="">
      2023a
     </a>
     ; Liu et al.,
     <a class="ltx_ref" href="#bib.bib30" title="">
      2022
     </a>
     )
    </cite>
    , other LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wu et al.,
     <a class="ltx_ref" href="#bib.bib51" title="">
      2023
     </a>
     ; Li et al.,
     <a class="ltx_ref" href="#bib.bib26" title="">
      2023
     </a>
     ; Chan et al.,
     <a class="ltx_ref" href="#bib.bib11" title="">
      2023
     </a>
     )
    </cite>
    , and humans
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al.,
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023c
     </a>
     ; Liu et al.,
     <a class="ltx_ref" href="#bib.bib27" title="">
      2023a
     </a>
     )
    </cite>
    to autonomously make decisions and formulate planning to solve tasks with feedback. The key component of LLM-Agents is the LLM-based planning module to process the environmental feedback and make planning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al.,
     <a class="ltx_ref" href="#bib.bib45" title="">
      2023b
     </a>
     ; Zhu et al.,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023a
     </a>
     )
    </cite>
    . When deployed in long-trial decisions and planning scenarios, LLM-Agents should make multiple rounds of action and planning. As LLMs are likely to hallucinate, LLM-Agents will accumulate errors and finally fail to complete planning tasks
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2022
     </a>
     )
    </cite>
    . Recent work amends this issue by reflecting on its previous failures in completing the same task when LLM-Agents start one more try for task completion
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shinn et al.,
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023
     </a>
     )
    </cite>
    . Differently, we apply the proposed method to help LLM-Agents summarize their successful experience in completing other similar tasks and formulate a plan to improve task completion.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p5">
   <p class="ltx_p" id="S2.p5.1">
    <span class="ltx_text ltx_font_bold" id="S2.p5.1.1">
     More Discussion with Retrieval-augmented LLMs
    </span>
    .
The retrieval-augmented LLM is proposed to alleviate the hallucination phenomenon and improve the output quality of LLM
    <cite class="ltx_cite ltx_citemacro_citep">
     (Asai et al.,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2023
     </a>
     ; Mialon et al.,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2023
     </a>
     ; Shi et al.,
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     )
    </cite>
    .
For an input question, the retrieval-augmented LLM first queries an external database with billion-level tokens
    <cite class="ltx_cite ltx_citemacro_citep">
     (Borgeaud et al.,
     <a class="ltx_ref" href="#bib.bib7" title="">
      2022
     </a>
     ; Lan et al.,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     ; Zhu et al.,
     <a class="ltx_ref" href="#bib.bib61" title="">
      2023b
     </a>
     )
    </cite>
    to retrieve a subset of the text corpus to construct the output answer.
The retrieval-augmented LLM achieves improved question-answering quality with fewer parameters than standard LLM
    <cite class="ltx_cite ltx_citemacro_citep">
     (Mialon et al.,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2023
     </a>
     )
    </cite>
    and has been applied to many downstream tasks such as text/multi-modal generation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lan et al.,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     ; Yasunaga et al.,
     <a class="ltx_ref" href="#bib.bib54" title="">
      2023
     </a>
     )
    </cite>
    , question answering
    <cite class="ltx_cite ltx_citemacro_citep">
     (Borgeaud et al.,
     <a class="ltx_ref" href="#bib.bib7" title="">
      2022
     </a>
     ; Izacard et al.,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2022
     </a>
     )
    </cite>
    and biomedical applications
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al.,
     <a class="ltx_ref" href="#bib.bib48" title="">
      2022b
     </a>
     )
    </cite>
    .
The retrieval-augmented LLM has been widely applied to many tasks
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lan et al.,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     ; Yasunaga et al.,
     <a class="ltx_ref" href="#bib.bib54" title="">
      2023
     </a>
     ; Izacard et al.,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2022
     </a>
     ; Wang et al.,
     <a class="ltx_ref" href="#bib.bib48" title="">
      2022b
     </a>
     )
    </cite>
    .
Differently, the proposed method requires no external database to query from but
aggregates the knowledge of solving analogous problems to hint at reasoning.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Preliminaries
  </h2>
  <figure class="ltx_figure" id="S3.F3">
   <p class="ltx_p ltx_align_center ltx_align_center" id="S3.F3.1.1">
    <span class="ltx_text" id="S3.F3.1.1.1">
     <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="226" id="S3.F3.1.1.1.g1" src="/html/2310.03965/assets/x3.png" width="369"/>
    </span>
   </p>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 3:
    </span>
    The illustrative comparison between Thought Propagation (TP) and other representative methods. For an input problem
    <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S3.F3.4.m1.1">
     <semantics id="S3.F3.4.m1.1b">
      <mi id="S3.F3.4.m1.1.1" xref="S3.F3.4.m1.1.1.cmml">
       𝐩
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.F3.4.m1.1c">
       <ci id="S3.F3.4.m1.1.1.cmml" xref="S3.F3.4.m1.1.1">
        𝐩
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.F3.4.m1.1d">
       \mathbf{p}
      </annotation>
     </semantics>
    </math>
    , IO, CoT, and ToT reason from scratch to yield the solution
    <math alttext="\mathbf{s}" class="ltx_Math" display="inline" id="S3.F3.5.m2.1">
     <semantics id="S3.F3.5.m2.1b">
      <mi id="S3.F3.5.m2.1.1" xref="S3.F3.5.m2.1.1.cmml">
       𝐬
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.F3.5.m2.1c">
       <ci id="S3.F3.5.m2.1.1.cmml" xref="S3.F3.5.m2.1.1">
        𝐬
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.F3.5.m2.1d">
       \mathbf{s}
      </annotation>
     </semantics>
    </math>
    . Differently, TP explores analogous problems to improve solving the input problem.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S3.p1">
   <p class="ltx_p" id="S3.p1.6">
    Denote the reasoning problem and the solution as
    <math alttext="\mathbf{p}\in\mathbf{\mathcal{P}}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1">
     <semantics id="S3.p1.1.m1.1a">
      <mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">
       <mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">
        𝐩
       </mi>
       <mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">
        ∈
       </mo>
       <mi class="ltx_font_mathcaligraphic" id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">
        𝒫
       </mi>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b">
       <apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">
        <in id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1">
        </in>
        <ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">
         𝐩
        </ci>
        <ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">
         𝒫
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">
       \mathbf{p}\in\mathbf{\mathcal{P}}
      </annotation>
     </semantics>
    </math>
    and
    <math alttext="\mathbf{s}\in\mathbf{\mathcal{S}}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1">
     <semantics id="S3.p1.2.m2.1a">
      <mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">
       <mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">
        𝐬
       </mi>
       <mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">
        ∈
       </mo>
       <mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">
        𝒮
       </mi>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b">
       <apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">
        <in id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1">
        </in>
        <ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">
         𝐬
        </ci>
        <ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">
         𝒮
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">
       \mathbf{s}\in\mathbf{\mathcal{S}}
      </annotation>
     </semantics>
    </math>
    .
    <math alttext="\mathbf{\mathcal{P}}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1">
     <semantics id="S3.p1.3.m3.1a">
      <mi class="ltx_font_mathcaligraphic" id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">
       𝒫
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b">
       <ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">
        𝒫
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">
       \mathbf{\mathcal{P}}
      </annotation>
     </semantics>
    </math>
    and
    <math alttext="\mathbf{\mathcal{S}}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1">
     <semantics id="S3.p1.4.m4.1a">
      <mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">
       𝒮
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b">
       <ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">
        𝒮
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">
       \mathbf{\mathcal{S}}
      </annotation>
     </semantics>
    </math>
    are the problem and solution space. Let the LLM be
    <math alttext="f_{\theta}" class="ltx_Math" display="inline" id="S3.p1.5.m5.1">
     <semantics id="S3.p1.5.m5.1a">
      <msub id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">
       <mi id="S3.p1.5.m5.1.1.2" xref="S3.p1.5.m5.1.1.2.cmml">
        f
       </mi>
       <mi id="S3.p1.5.m5.1.1.3" xref="S3.p1.5.m5.1.1.3.cmml">
        θ
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b">
       <apply id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">
        <csymbol cd="ambiguous" id="S3.p1.5.m5.1.1.1.cmml" xref="S3.p1.5.m5.1.1">
         subscript
        </csymbol>
        <ci id="S3.p1.5.m5.1.1.2.cmml" xref="S3.p1.5.m5.1.1.2">
         𝑓
        </ci>
        <ci id="S3.p1.5.m5.1.1.3.cmml" xref="S3.p1.5.m5.1.1.3">
         𝜃
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">
       f_{\theta}
      </annotation>
     </semantics>
    </math>
    where
    <math alttext="\theta" class="ltx_Math" display="inline" id="S3.p1.6.m6.1">
     <semantics id="S3.p1.6.m6.1a">
      <mi id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">
       θ
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b">
       <ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">
        𝜃
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">
       \theta
      </annotation>
     </semantics>
    </math>
    denotes model weights.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p2">
   <p class="ltx_p" id="S3.p2.3">
    <span class="ltx_text ltx_font_bold" id="S3.p2.3.1">
     IO Prompting
    </span>
    . IO prompting
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2020
     </a>
     )
    </cite>
    uses task descriptions and few-shot pairs of Input and Output (IO) prompting demonstrations to assist LLMs in reasoning to solve the input problem
    <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1">
     <semantics id="S3.p2.1.m1.1a">
      <mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">
       𝐩
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b">
       <ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">
        𝐩
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">
       \mathbf{p}
      </annotation>
     </semantics>
    </math>
    by
    <math alttext="\mathbf{s}=f_{\theta}(\mathbf{p})" class="ltx_Math" display="inline" id="S3.p2.2.m2.1">
     <semantics id="S3.p2.2.m2.1a">
      <mrow id="S3.p2.2.m2.1.2" xref="S3.p2.2.m2.1.2.cmml">
       <mi id="S3.p2.2.m2.1.2.2" xref="S3.p2.2.m2.1.2.2.cmml">
        𝐬
       </mi>
       <mo id="S3.p2.2.m2.1.2.1" xref="S3.p2.2.m2.1.2.1.cmml">
        =
       </mo>
       <mrow id="S3.p2.2.m2.1.2.3" xref="S3.p2.2.m2.1.2.3.cmml">
        <msub id="S3.p2.2.m2.1.2.3.2" xref="S3.p2.2.m2.1.2.3.2.cmml">
         <mi id="S3.p2.2.m2.1.2.3.2.2" xref="S3.p2.2.m2.1.2.3.2.2.cmml">
          f
         </mi>
         <mi id="S3.p2.2.m2.1.2.3.2.3" xref="S3.p2.2.m2.1.2.3.2.3.cmml">
          θ
         </mi>
        </msub>
        <mo id="S3.p2.2.m2.1.2.3.1" lspace="0em" rspace="0em" xref="S3.p2.2.m2.1.2.3.1.cmml">
         ​
        </mo>
        <mrow id="S3.p2.2.m2.1.2.3.3.2" xref="S3.p2.2.m2.1.2.3.cmml">
         <mo id="S3.p2.2.m2.1.2.3.3.2.1" stretchy="false" xref="S3.p2.2.m2.1.2.3.cmml">
          (
         </mo>
         <mi id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">
          𝐩
         </mi>
         <mo id="S3.p2.2.m2.1.2.3.3.2.2" stretchy="false" xref="S3.p2.2.m2.1.2.3.cmml">
          )
         </mo>
        </mrow>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b">
       <apply id="S3.p2.2.m2.1.2.cmml" xref="S3.p2.2.m2.1.2">
        <eq id="S3.p2.2.m2.1.2.1.cmml" xref="S3.p2.2.m2.1.2.1">
        </eq>
        <ci id="S3.p2.2.m2.1.2.2.cmml" xref="S3.p2.2.m2.1.2.2">
         𝐬
        </ci>
        <apply id="S3.p2.2.m2.1.2.3.cmml" xref="S3.p2.2.m2.1.2.3">
         <times id="S3.p2.2.m2.1.2.3.1.cmml" xref="S3.p2.2.m2.1.2.3.1">
         </times>
         <apply id="S3.p2.2.m2.1.2.3.2.cmml" xref="S3.p2.2.m2.1.2.3.2">
          <csymbol cd="ambiguous" id="S3.p2.2.m2.1.2.3.2.1.cmml" xref="S3.p2.2.m2.1.2.3.2">
           subscript
          </csymbol>
          <ci id="S3.p2.2.m2.1.2.3.2.2.cmml" xref="S3.p2.2.m2.1.2.3.2.2">
           𝑓
          </ci>
          <ci id="S3.p2.2.m2.1.2.3.2.3.cmml" xref="S3.p2.2.m2.1.2.3.2.3">
           𝜃
          </ci>
         </apply>
         <ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">
          𝐩
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">
       \mathbf{s}=f_{\theta}(\mathbf{p})
      </annotation>
     </semantics>
    </math>
    . Thus, we denote the reasoning path of IO prompting as
    <math alttext="\mathbf{p}\rightarrow\mathbf{s}" class="ltx_Math" display="inline" id="S3.p2.3.m3.1">
     <semantics id="S3.p2.3.m3.1a">
      <mrow id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">
       <mi id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">
        𝐩
       </mi>
       <mo id="S3.p2.3.m3.1.1.1" stretchy="false" xref="S3.p2.3.m3.1.1.1.cmml">
        →
       </mo>
       <mi id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">
        𝐬
       </mi>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b">
       <apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">
        <ci id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1.1">
         →
        </ci>
        <ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">
         𝐩
        </ci>
        <ci id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">
         𝐬
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">
       \mathbf{p}\rightarrow\mathbf{s}
      </annotation>
     </semantics>
    </math>
    . As shown in Figure
    <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3 Preliminaries ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    (a), the reasoning path of IO prompting is one-step. One-step reasoning is insufficient to solve complex problems which involve multi-step reasoning.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p3">
   <p class="ltx_p" id="S3.p3.5">
    <span class="ltx_text ltx_font_bold" id="S3.p3.5.1">
     Chain-of-Thought Prompting
    </span>
    . Chain-of-Thought (CoT) Prompting
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2022
     </a>
     )
    </cite>
    enables complex reasoning ability with LLMs by decomposing the reasoning path of these problems into multi-step:
    <math alttext="\mathbf{p}\rightarrow\mathbf{z}_{1}\cdots\mathbf{z}_{k}\rightarrow\mathbf{s}" class="ltx_Math" display="inline" id="S3.p3.1.m1.1">
     <semantics id="S3.p3.1.m1.1a">
      <mrow id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">
       <mi id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">
        𝐩
       </mi>
       <mo id="S3.p3.1.m1.1.1.3" stretchy="false" xref="S3.p3.1.m1.1.1.3.cmml">
        →
       </mo>
       <mrow id="S3.p3.1.m1.1.1.4" xref="S3.p3.1.m1.1.1.4.cmml">
        <msub id="S3.p3.1.m1.1.1.4.2" xref="S3.p3.1.m1.1.1.4.2.cmml">
         <mi id="S3.p3.1.m1.1.1.4.2.2" xref="S3.p3.1.m1.1.1.4.2.2.cmml">
          𝐳
         </mi>
         <mn id="S3.p3.1.m1.1.1.4.2.3" xref="S3.p3.1.m1.1.1.4.2.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S3.p3.1.m1.1.1.4.1" lspace="0em" rspace="0em" xref="S3.p3.1.m1.1.1.4.1.cmml">
         ​
        </mo>
        <mi id="S3.p3.1.m1.1.1.4.3" mathvariant="normal" xref="S3.p3.1.m1.1.1.4.3.cmml">
         ⋯
        </mi>
        <mo id="S3.p3.1.m1.1.1.4.1a" lspace="0em" rspace="0em" xref="S3.p3.1.m1.1.1.4.1.cmml">
         ​
        </mo>
        <msub id="S3.p3.1.m1.1.1.4.4" xref="S3.p3.1.m1.1.1.4.4.cmml">
         <mi id="S3.p3.1.m1.1.1.4.4.2" xref="S3.p3.1.m1.1.1.4.4.2.cmml">
          𝐳
         </mi>
         <mi id="S3.p3.1.m1.1.1.4.4.3" xref="S3.p3.1.m1.1.1.4.4.3.cmml">
          k
         </mi>
        </msub>
       </mrow>
       <mo id="S3.p3.1.m1.1.1.5" stretchy="false" xref="S3.p3.1.m1.1.1.5.cmml">
        →
       </mo>
       <mi id="S3.p3.1.m1.1.1.6" xref="S3.p3.1.m1.1.1.6.cmml">
        𝐬
       </mi>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b">
       <apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">
        <and id="S3.p3.1.m1.1.1a.cmml" xref="S3.p3.1.m1.1.1">
        </and>
        <apply id="S3.p3.1.m1.1.1b.cmml" xref="S3.p3.1.m1.1.1">
         <ci id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3">
          →
         </ci>
         <ci id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">
          𝐩
         </ci>
         <apply id="S3.p3.1.m1.1.1.4.cmml" xref="S3.p3.1.m1.1.1.4">
          <times id="S3.p3.1.m1.1.1.4.1.cmml" xref="S3.p3.1.m1.1.1.4.1">
          </times>
          <apply id="S3.p3.1.m1.1.1.4.2.cmml" xref="S3.p3.1.m1.1.1.4.2">
           <csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.4.2.1.cmml" xref="S3.p3.1.m1.1.1.4.2">
            subscript
           </csymbol>
           <ci id="S3.p3.1.m1.1.1.4.2.2.cmml" xref="S3.p3.1.m1.1.1.4.2.2">
            𝐳
           </ci>
           <cn id="S3.p3.1.m1.1.1.4.2.3.cmml" type="integer" xref="S3.p3.1.m1.1.1.4.2.3">
            1
           </cn>
          </apply>
          <ci id="S3.p3.1.m1.1.1.4.3.cmml" xref="S3.p3.1.m1.1.1.4.3">
           ⋯
          </ci>
          <apply id="S3.p3.1.m1.1.1.4.4.cmml" xref="S3.p3.1.m1.1.1.4.4">
           <csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.4.4.1.cmml" xref="S3.p3.1.m1.1.1.4.4">
            subscript
           </csymbol>
           <ci id="S3.p3.1.m1.1.1.4.4.2.cmml" xref="S3.p3.1.m1.1.1.4.4.2">
            𝐳
           </ci>
           <ci id="S3.p3.1.m1.1.1.4.4.3.cmml" xref="S3.p3.1.m1.1.1.4.4.3">
            𝑘
           </ci>
          </apply>
         </apply>
        </apply>
        <apply id="S3.p3.1.m1.1.1c.cmml" xref="S3.p3.1.m1.1.1">
         <ci id="S3.p3.1.m1.1.1.5.cmml" xref="S3.p3.1.m1.1.1.5">
          →
         </ci>
         <share href="#S3.p3.1.m1.1.1.4.cmml" id="S3.p3.1.m1.1.1d.cmml" xref="S3.p3.1.m1.1.1">
         </share>
         <ci id="S3.p3.1.m1.1.1.6.cmml" xref="S3.p3.1.m1.1.1.6">
          𝐬
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">
       \mathbf{p}\rightarrow\mathbf{z}_{1}\cdots\mathbf{z}_{k}\rightarrow\mathbf{s}
      </annotation>
     </semantics>
    </math>
    . Here
    <math alttext="\mathbf{z}_{1}\cdots\mathbf{z}_{k}" class="ltx_Math" display="inline" id="S3.p3.2.m2.1">
     <semantics id="S3.p3.2.m2.1a">
      <mrow id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">
       <msub id="S3.p3.2.m2.1.1.2" xref="S3.p3.2.m2.1.1.2.cmml">
        <mi id="S3.p3.2.m2.1.1.2.2" xref="S3.p3.2.m2.1.1.2.2.cmml">
         𝐳
        </mi>
        <mn id="S3.p3.2.m2.1.1.2.3" xref="S3.p3.2.m2.1.1.2.3.cmml">
         1
        </mn>
       </msub>
       <mo id="S3.p3.2.m2.1.1.1" lspace="0em" rspace="0em" xref="S3.p3.2.m2.1.1.1.cmml">
        ​
       </mo>
       <mi id="S3.p3.2.m2.1.1.3" mathvariant="normal" xref="S3.p3.2.m2.1.1.3.cmml">
        ⋯
       </mi>
       <mo id="S3.p3.2.m2.1.1.1a" lspace="0em" rspace="0em" xref="S3.p3.2.m2.1.1.1.cmml">
        ​
       </mo>
       <msub id="S3.p3.2.m2.1.1.4" xref="S3.p3.2.m2.1.1.4.cmml">
        <mi id="S3.p3.2.m2.1.1.4.2" xref="S3.p3.2.m2.1.1.4.2.cmml">
         𝐳
        </mi>
        <mi id="S3.p3.2.m2.1.1.4.3" xref="S3.p3.2.m2.1.1.4.3.cmml">
         k
        </mi>
       </msub>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b">
       <apply id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">
        <times id="S3.p3.2.m2.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1">
        </times>
        <apply id="S3.p3.2.m2.1.1.2.cmml" xref="S3.p3.2.m2.1.1.2">
         <csymbol cd="ambiguous" id="S3.p3.2.m2.1.1.2.1.cmml" xref="S3.p3.2.m2.1.1.2">
          subscript
         </csymbol>
         <ci id="S3.p3.2.m2.1.1.2.2.cmml" xref="S3.p3.2.m2.1.1.2.2">
          𝐳
         </ci>
         <cn id="S3.p3.2.m2.1.1.2.3.cmml" type="integer" xref="S3.p3.2.m2.1.1.2.3">
          1
         </cn>
        </apply>
        <ci id="S3.p3.2.m2.1.1.3.cmml" xref="S3.p3.2.m2.1.1.3">
         ⋯
        </ci>
        <apply id="S3.p3.2.m2.1.1.4.cmml" xref="S3.p3.2.m2.1.1.4">
         <csymbol cd="ambiguous" id="S3.p3.2.m2.1.1.4.1.cmml" xref="S3.p3.2.m2.1.1.4">
          subscript
         </csymbol>
         <ci id="S3.p3.2.m2.1.1.4.2.cmml" xref="S3.p3.2.m2.1.1.4.2">
          𝐳
         </ci>
         <ci id="S3.p3.2.m2.1.1.4.3.cmml" xref="S3.p3.2.m2.1.1.4.3">
          𝑘
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">
       \mathbf{z}_{1}\cdots\mathbf{z}_{k}
      </annotation>
     </semantics>
    </math>
    are sub-solutions in intermediate reasoning steps, a.k.a ’thoughts’. CoT uses few-shot prompts to prompt LLM to output reasoning results together with its intermediate reasoning steps:
    <math alttext="\{\mathbf{z}_{1},\cdots\mathbf{z}_{k},\mathbf{s}\}=f_{\theta}(\mathbf{p})" class="ltx_Math" display="inline" id="S3.p3.3.m3.4">
     <semantics id="S3.p3.3.m3.4a">
      <mrow id="S3.p3.3.m3.4.4" xref="S3.p3.3.m3.4.4.cmml">
       <mrow id="S3.p3.3.m3.4.4.2.2" xref="S3.p3.3.m3.4.4.2.3.cmml">
        <mo id="S3.p3.3.m3.4.4.2.2.3" stretchy="false" xref="S3.p3.3.m3.4.4.2.3.cmml">
         {
        </mo>
        <msub id="S3.p3.3.m3.3.3.1.1.1" xref="S3.p3.3.m3.3.3.1.1.1.cmml">
         <mi id="S3.p3.3.m3.3.3.1.1.1.2" xref="S3.p3.3.m3.3.3.1.1.1.2.cmml">
          𝐳
         </mi>
         <mn id="S3.p3.3.m3.3.3.1.1.1.3" xref="S3.p3.3.m3.3.3.1.1.1.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S3.p3.3.m3.4.4.2.2.4" xref="S3.p3.3.m3.4.4.2.3.cmml">
         ,
        </mo>
        <mrow id="S3.p3.3.m3.4.4.2.2.2" xref="S3.p3.3.m3.4.4.2.2.2.cmml">
         <mi id="S3.p3.3.m3.4.4.2.2.2.2" mathvariant="normal" xref="S3.p3.3.m3.4.4.2.2.2.2.cmml">
          ⋯
         </mi>
         <mo id="S3.p3.3.m3.4.4.2.2.2.1" lspace="0em" rspace="0em" xref="S3.p3.3.m3.4.4.2.2.2.1.cmml">
          ​
         </mo>
         <msub id="S3.p3.3.m3.4.4.2.2.2.3" xref="S3.p3.3.m3.4.4.2.2.2.3.cmml">
          <mi id="S3.p3.3.m3.4.4.2.2.2.3.2" xref="S3.p3.3.m3.4.4.2.2.2.3.2.cmml">
           𝐳
          </mi>
          <mi id="S3.p3.3.m3.4.4.2.2.2.3.3" xref="S3.p3.3.m3.4.4.2.2.2.3.3.cmml">
           k
          </mi>
         </msub>
        </mrow>
        <mo id="S3.p3.3.m3.4.4.2.2.5" xref="S3.p3.3.m3.4.4.2.3.cmml">
         ,
        </mo>
        <mi id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml">
         𝐬
        </mi>
        <mo id="S3.p3.3.m3.4.4.2.2.6" stretchy="false" xref="S3.p3.3.m3.4.4.2.3.cmml">
         }
        </mo>
       </mrow>
       <mo id="S3.p3.3.m3.4.4.3" xref="S3.p3.3.m3.4.4.3.cmml">
        =
       </mo>
       <mrow id="S3.p3.3.m3.4.4.4" xref="S3.p3.3.m3.4.4.4.cmml">
        <msub id="S3.p3.3.m3.4.4.4.2" xref="S3.p3.3.m3.4.4.4.2.cmml">
         <mi id="S3.p3.3.m3.4.4.4.2.2" xref="S3.p3.3.m3.4.4.4.2.2.cmml">
          f
         </mi>
         <mi id="S3.p3.3.m3.4.4.4.2.3" xref="S3.p3.3.m3.4.4.4.2.3.cmml">
          θ
         </mi>
        </msub>
        <mo id="S3.p3.3.m3.4.4.4.1" lspace="0em" rspace="0em" xref="S3.p3.3.m3.4.4.4.1.cmml">
         ​
        </mo>
        <mrow id="S3.p3.3.m3.4.4.4.3.2" xref="S3.p3.3.m3.4.4.4.cmml">
         <mo id="S3.p3.3.m3.4.4.4.3.2.1" stretchy="false" xref="S3.p3.3.m3.4.4.4.cmml">
          (
         </mo>
         <mi id="S3.p3.3.m3.2.2" xref="S3.p3.3.m3.2.2.cmml">
          𝐩
         </mi>
         <mo id="S3.p3.3.m3.4.4.4.3.2.2" stretchy="false" xref="S3.p3.3.m3.4.4.4.cmml">
          )
         </mo>
        </mrow>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.4b">
       <apply id="S3.p3.3.m3.4.4.cmml" xref="S3.p3.3.m3.4.4">
        <eq id="S3.p3.3.m3.4.4.3.cmml" xref="S3.p3.3.m3.4.4.3">
        </eq>
        <set id="S3.p3.3.m3.4.4.2.3.cmml" xref="S3.p3.3.m3.4.4.2.2">
         <apply id="S3.p3.3.m3.3.3.1.1.1.cmml" xref="S3.p3.3.m3.3.3.1.1.1">
          <csymbol cd="ambiguous" id="S3.p3.3.m3.3.3.1.1.1.1.cmml" xref="S3.p3.3.m3.3.3.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.p3.3.m3.3.3.1.1.1.2.cmml" xref="S3.p3.3.m3.3.3.1.1.1.2">
           𝐳
          </ci>
          <cn id="S3.p3.3.m3.3.3.1.1.1.3.cmml" type="integer" xref="S3.p3.3.m3.3.3.1.1.1.3">
           1
          </cn>
         </apply>
         <apply id="S3.p3.3.m3.4.4.2.2.2.cmml" xref="S3.p3.3.m3.4.4.2.2.2">
          <times id="S3.p3.3.m3.4.4.2.2.2.1.cmml" xref="S3.p3.3.m3.4.4.2.2.2.1">
          </times>
          <ci id="S3.p3.3.m3.4.4.2.2.2.2.cmml" xref="S3.p3.3.m3.4.4.2.2.2.2">
           ⋯
          </ci>
          <apply id="S3.p3.3.m3.4.4.2.2.2.3.cmml" xref="S3.p3.3.m3.4.4.2.2.2.3">
           <csymbol cd="ambiguous" id="S3.p3.3.m3.4.4.2.2.2.3.1.cmml" xref="S3.p3.3.m3.4.4.2.2.2.3">
            subscript
           </csymbol>
           <ci id="S3.p3.3.m3.4.4.2.2.2.3.2.cmml" xref="S3.p3.3.m3.4.4.2.2.2.3.2">
            𝐳
           </ci>
           <ci id="S3.p3.3.m3.4.4.2.2.2.3.3.cmml" xref="S3.p3.3.m3.4.4.2.2.2.3.3">
            𝑘
           </ci>
          </apply>
         </apply>
         <ci id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1">
          𝐬
         </ci>
        </set>
        <apply id="S3.p3.3.m3.4.4.4.cmml" xref="S3.p3.3.m3.4.4.4">
         <times id="S3.p3.3.m3.4.4.4.1.cmml" xref="S3.p3.3.m3.4.4.4.1">
         </times>
         <apply id="S3.p3.3.m3.4.4.4.2.cmml" xref="S3.p3.3.m3.4.4.4.2">
          <csymbol cd="ambiguous" id="S3.p3.3.m3.4.4.4.2.1.cmml" xref="S3.p3.3.m3.4.4.4.2">
           subscript
          </csymbol>
          <ci id="S3.p3.3.m3.4.4.4.2.2.cmml" xref="S3.p3.3.m3.4.4.4.2.2">
           𝑓
          </ci>
          <ci id="S3.p3.3.m3.4.4.4.2.3.cmml" xref="S3.p3.3.m3.4.4.4.2.3">
           𝜃
          </ci>
         </apply>
         <ci id="S3.p3.3.m3.2.2.cmml" xref="S3.p3.3.m3.2.2">
          𝐩
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p3.3.m3.4c">
       \{\mathbf{z}_{1},\cdots\mathbf{z}_{k},\mathbf{s}\}=f_{\theta}(\mathbf{p})
      </annotation>
     </semantics>
    </math>
    . Notice this framework can be done sequentially by
    <math alttext="\mathbf{z}_{i}=f_{\theta}(\mathbf{p};\{\mathbf{z}_{j}|j&lt;i\})" class="ltx_Math" display="inline" id="S3.p3.4.m4.2">
     <semantics id="S3.p3.4.m4.2a">
      <mrow id="S3.p3.4.m4.2.2" xref="S3.p3.4.m4.2.2.cmml">
       <msub id="S3.p3.4.m4.2.2.3" xref="S3.p3.4.m4.2.2.3.cmml">
        <mi id="S3.p3.4.m4.2.2.3.2" xref="S3.p3.4.m4.2.2.3.2.cmml">
         𝐳
        </mi>
        <mi id="S3.p3.4.m4.2.2.3.3" xref="S3.p3.4.m4.2.2.3.3.cmml">
         i
        </mi>
       </msub>
       <mo id="S3.p3.4.m4.2.2.2" xref="S3.p3.4.m4.2.2.2.cmml">
        =
       </mo>
       <mrow id="S3.p3.4.m4.2.2.1" xref="S3.p3.4.m4.2.2.1.cmml">
        <msub id="S3.p3.4.m4.2.2.1.3" xref="S3.p3.4.m4.2.2.1.3.cmml">
         <mi id="S3.p3.4.m4.2.2.1.3.2" xref="S3.p3.4.m4.2.2.1.3.2.cmml">
          f
         </mi>
         <mi id="S3.p3.4.m4.2.2.1.3.3" xref="S3.p3.4.m4.2.2.1.3.3.cmml">
          θ
         </mi>
        </msub>
        <mo id="S3.p3.4.m4.2.2.1.2" lspace="0em" rspace="0em" xref="S3.p3.4.m4.2.2.1.2.cmml">
         ​
        </mo>
        <mrow id="S3.p3.4.m4.2.2.1.1.1" xref="S3.p3.4.m4.2.2.1.1.2.cmml">
         <mo id="S3.p3.4.m4.2.2.1.1.1.2" stretchy="false" xref="S3.p3.4.m4.2.2.1.1.2.cmml">
          (
         </mo>
         <mi id="S3.p3.4.m4.1.1" xref="S3.p3.4.m4.1.1.cmml">
          𝐩
         </mi>
         <mo id="S3.p3.4.m4.2.2.1.1.1.3" xref="S3.p3.4.m4.2.2.1.1.2.cmml">
          ;
         </mo>
         <mrow id="S3.p3.4.m4.2.2.1.1.1.1.2" xref="S3.p3.4.m4.2.2.1.1.1.1.3.cmml">
          <mo id="S3.p3.4.m4.2.2.1.1.1.1.2.3" stretchy="false" xref="S3.p3.4.m4.2.2.1.1.1.1.3.1.cmml">
           {
          </mo>
          <msub id="S3.p3.4.m4.2.2.1.1.1.1.1.1" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1.cmml">
           <mi id="S3.p3.4.m4.2.2.1.1.1.1.1.1.2" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1.2.cmml">
            𝐳
           </mi>
           <mi id="S3.p3.4.m4.2.2.1.1.1.1.1.1.3" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1.3.cmml">
            j
           </mi>
          </msub>
          <mo id="S3.p3.4.m4.2.2.1.1.1.1.2.4" lspace="0em" rspace="0em" xref="S3.p3.4.m4.2.2.1.1.1.1.3.1.cmml">
           |
          </mo>
          <mrow id="S3.p3.4.m4.2.2.1.1.1.1.2.2" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.cmml">
           <mi id="S3.p3.4.m4.2.2.1.1.1.1.2.2.2" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.2.cmml">
            j
           </mi>
           <mo id="S3.p3.4.m4.2.2.1.1.1.1.2.2.1" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.1.cmml">
            &lt;
           </mo>
           <mi id="S3.p3.4.m4.2.2.1.1.1.1.2.2.3" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.3.cmml">
            i
           </mi>
          </mrow>
          <mo id="S3.p3.4.m4.2.2.1.1.1.1.2.5" stretchy="false" xref="S3.p3.4.m4.2.2.1.1.1.1.3.1.cmml">
           }
          </mo>
         </mrow>
         <mo id="S3.p3.4.m4.2.2.1.1.1.4" stretchy="false" xref="S3.p3.4.m4.2.2.1.1.2.cmml">
          )
         </mo>
        </mrow>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.2b">
       <apply id="S3.p3.4.m4.2.2.cmml" xref="S3.p3.4.m4.2.2">
        <eq id="S3.p3.4.m4.2.2.2.cmml" xref="S3.p3.4.m4.2.2.2">
        </eq>
        <apply id="S3.p3.4.m4.2.2.3.cmml" xref="S3.p3.4.m4.2.2.3">
         <csymbol cd="ambiguous" id="S3.p3.4.m4.2.2.3.1.cmml" xref="S3.p3.4.m4.2.2.3">
          subscript
         </csymbol>
         <ci id="S3.p3.4.m4.2.2.3.2.cmml" xref="S3.p3.4.m4.2.2.3.2">
          𝐳
         </ci>
         <ci id="S3.p3.4.m4.2.2.3.3.cmml" xref="S3.p3.4.m4.2.2.3.3">
          𝑖
         </ci>
        </apply>
        <apply id="S3.p3.4.m4.2.2.1.cmml" xref="S3.p3.4.m4.2.2.1">
         <times id="S3.p3.4.m4.2.2.1.2.cmml" xref="S3.p3.4.m4.2.2.1.2">
         </times>
         <apply id="S3.p3.4.m4.2.2.1.3.cmml" xref="S3.p3.4.m4.2.2.1.3">
          <csymbol cd="ambiguous" id="S3.p3.4.m4.2.2.1.3.1.cmml" xref="S3.p3.4.m4.2.2.1.3">
           subscript
          </csymbol>
          <ci id="S3.p3.4.m4.2.2.1.3.2.cmml" xref="S3.p3.4.m4.2.2.1.3.2">
           𝑓
          </ci>
          <ci id="S3.p3.4.m4.2.2.1.3.3.cmml" xref="S3.p3.4.m4.2.2.1.3.3">
           𝜃
          </ci>
         </apply>
         <list id="S3.p3.4.m4.2.2.1.1.2.cmml" xref="S3.p3.4.m4.2.2.1.1.1">
          <ci id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1">
           𝐩
          </ci>
          <apply id="S3.p3.4.m4.2.2.1.1.1.1.3.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.2">
           <csymbol cd="latexml" id="S3.p3.4.m4.2.2.1.1.1.1.3.1.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.2.3">
            conditional-set
           </csymbol>
           <apply id="S3.p3.4.m4.2.2.1.1.1.1.1.1.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S3.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.p3.4.m4.2.2.1.1.1.1.1.1.2.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1.2">
             𝐳
            </ci>
            <ci id="S3.p3.4.m4.2.2.1.1.1.1.1.1.3.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.1.1.3">
             𝑗
            </ci>
           </apply>
           <apply id="S3.p3.4.m4.2.2.1.1.1.1.2.2.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2">
            <lt id="S3.p3.4.m4.2.2.1.1.1.1.2.2.1.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.1">
            </lt>
            <ci id="S3.p3.4.m4.2.2.1.1.1.1.2.2.2.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.2">
             𝑗
            </ci>
            <ci id="S3.p3.4.m4.2.2.1.1.1.1.2.2.3.cmml" xref="S3.p3.4.m4.2.2.1.1.1.1.2.2.3">
             𝑖
            </ci>
           </apply>
          </apply>
         </list>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p3.4.m4.2c">
       \mathbf{z}_{i}=f_{\theta}(\mathbf{p};\{\mathbf{z}_{j}|j&lt;i\})
      </annotation>
     </semantics>
    </math>
    until reaches the final solution
    <math alttext="\mathbf{s}" class="ltx_Math" display="inline" id="S3.p3.5.m5.1">
     <semantics id="S3.p3.5.m5.1a">
      <mi id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml">
       𝐬
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.1b">
       <ci id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1">
        𝐬
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p3.5.m5.1c">
       \mathbf{s}
      </annotation>
     </semantics>
    </math>
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhou et al.,
     <a class="ltx_ref" href="#bib.bib59" title="">
      2022
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p4">
   <p class="ltx_p" id="S3.p4.5">
    <span class="ltx_text ltx_font_bold" id="S3.p4.5.1">
     Tree-of-Thought Prompting
    </span>
    . Tree-of-Thought (ToT) Prompting formulates LLM reasoning as searching in the solution space with heuristics, such as breadth-first searching (BFS) and depth-first searching (DFS)
    <cite class="ltx_cite ltx_citemacro_cite">
     Yao et al. (
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     )
    </cite>
    . When it reaches the sub-solution
    <math alttext="\mathbf{z}_{i}" class="ltx_Math" display="inline" id="S3.p4.1.m1.1">
     <semantics id="S3.p4.1.m1.1a">
      <msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">
       <mi id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">
        𝐳
       </mi>
       <mi id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml">
        i
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b">
       <apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">
        <csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">
         subscript
        </csymbol>
        <ci id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">
         𝐳
        </ci>
        <ci id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">
         𝑖
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">
       \mathbf{z}_{i}
      </annotation>
     </semantics>
    </math>
    at
    <math alttext="i" class="ltx_Math" display="inline" id="S3.p4.2.m2.1">
     <semantics id="S3.p4.2.m2.1a">
      <mi id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">
       i
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b">
       <ci id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">
        𝑖
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">
       i
      </annotation>
     </semantics>
    </math>
    -th step, ToT employ an LLM to propose sub-solution candidates
    <math alttext="\{\mathbf{z}_{i+1}^{n}|n=1\cdots N\}=f_{\theta}(\mathbf{p};\{\mathbf{z}_{j}|j\leq i\})" class="ltx_Math" display="inline" id="S3.p4.3.m3.4">
     <semantics id="S3.p4.3.m3.4a">
      <mrow id="S3.p4.3.m3.4.4" xref="S3.p4.3.m3.4.4.cmml">
       <mrow id="S3.p4.3.m3.3.3.2.2" xref="S3.p4.3.m3.3.3.2.3.cmml">
        <mo id="S3.p4.3.m3.3.3.2.2.3" stretchy="false" xref="S3.p4.3.m3.3.3.2.3.1.cmml">
         {
        </mo>
        <msubsup id="S3.p4.3.m3.2.2.1.1.1" xref="S3.p4.3.m3.2.2.1.1.1.cmml">
         <mi id="S3.p4.3.m3.2.2.1.1.1.2.2" xref="S3.p4.3.m3.2.2.1.1.1.2.2.cmml">
          𝐳
         </mi>
         <mrow id="S3.p4.3.m3.2.2.1.1.1.2.3" xref="S3.p4.3.m3.2.2.1.1.1.2.3.cmml">
          <mi id="S3.p4.3.m3.2.2.1.1.1.2.3.2" xref="S3.p4.3.m3.2.2.1.1.1.2.3.2.cmml">
           i
          </mi>
          <mo id="S3.p4.3.m3.2.2.1.1.1.2.3.1" xref="S3.p4.3.m3.2.2.1.1.1.2.3.1.cmml">
           +
          </mo>
          <mn id="S3.p4.3.m3.2.2.1.1.1.2.3.3" xref="S3.p4.3.m3.2.2.1.1.1.2.3.3.cmml">
           1
          </mn>
         </mrow>
         <mi id="S3.p4.3.m3.2.2.1.1.1.3" xref="S3.p4.3.m3.2.2.1.1.1.3.cmml">
          n
         </mi>
        </msubsup>
        <mo id="S3.p4.3.m3.3.3.2.2.4" lspace="0em" rspace="0em" xref="S3.p4.3.m3.3.3.2.3.1.cmml">
         |
        </mo>
        <mrow id="S3.p4.3.m3.3.3.2.2.2" xref="S3.p4.3.m3.3.3.2.2.2.cmml">
         <mi id="S3.p4.3.m3.3.3.2.2.2.2" xref="S3.p4.3.m3.3.3.2.2.2.2.cmml">
          n
         </mi>
         <mo id="S3.p4.3.m3.3.3.2.2.2.1" xref="S3.p4.3.m3.3.3.2.2.2.1.cmml">
          =
         </mo>
         <mrow id="S3.p4.3.m3.3.3.2.2.2.3" xref="S3.p4.3.m3.3.3.2.2.2.3.cmml">
          <mn id="S3.p4.3.m3.3.3.2.2.2.3.2" xref="S3.p4.3.m3.3.3.2.2.2.3.2.cmml">
           1
          </mn>
          <mo id="S3.p4.3.m3.3.3.2.2.2.3.1" lspace="0em" rspace="0em" xref="S3.p4.3.m3.3.3.2.2.2.3.1.cmml">
           ​
          </mo>
          <mi id="S3.p4.3.m3.3.3.2.2.2.3.3" mathvariant="normal" xref="S3.p4.3.m3.3.3.2.2.2.3.3.cmml">
           ⋯
          </mi>
          <mo id="S3.p4.3.m3.3.3.2.2.2.3.1a" lspace="0em" rspace="0em" xref="S3.p4.3.m3.3.3.2.2.2.3.1.cmml">
           ​
          </mo>
          <mi id="S3.p4.3.m3.3.3.2.2.2.3.4" xref="S3.p4.3.m3.3.3.2.2.2.3.4.cmml">
           N
          </mi>
         </mrow>
        </mrow>
        <mo id="S3.p4.3.m3.3.3.2.2.5" stretchy="false" xref="S3.p4.3.m3.3.3.2.3.1.cmml">
         }
        </mo>
       </mrow>
       <mo id="S3.p4.3.m3.4.4.4" xref="S3.p4.3.m3.4.4.4.cmml">
        =
       </mo>
       <mrow id="S3.p4.3.m3.4.4.3" xref="S3.p4.3.m3.4.4.3.cmml">
        <msub id="S3.p4.3.m3.4.4.3.3" xref="S3.p4.3.m3.4.4.3.3.cmml">
         <mi id="S3.p4.3.m3.4.4.3.3.2" xref="S3.p4.3.m3.4.4.3.3.2.cmml">
          f
         </mi>
         <mi id="S3.p4.3.m3.4.4.3.3.3" xref="S3.p4.3.m3.4.4.3.3.3.cmml">
          θ
         </mi>
        </msub>
        <mo id="S3.p4.3.m3.4.4.3.2" lspace="0em" rspace="0em" xref="S3.p4.3.m3.4.4.3.2.cmml">
         ​
        </mo>
        <mrow id="S3.p4.3.m3.4.4.3.1.1" xref="S3.p4.3.m3.4.4.3.1.2.cmml">
         <mo id="S3.p4.3.m3.4.4.3.1.1.2" stretchy="false" xref="S3.p4.3.m3.4.4.3.1.2.cmml">
          (
         </mo>
         <mi id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml">
          𝐩
         </mi>
         <mo id="S3.p4.3.m3.4.4.3.1.1.3" xref="S3.p4.3.m3.4.4.3.1.2.cmml">
          ;
         </mo>
         <mrow id="S3.p4.3.m3.4.4.3.1.1.1.2" xref="S3.p4.3.m3.4.4.3.1.1.1.3.cmml">
          <mo id="S3.p4.3.m3.4.4.3.1.1.1.2.3" stretchy="false" xref="S3.p4.3.m3.4.4.3.1.1.1.3.1.cmml">
           {
          </mo>
          <msub id="S3.p4.3.m3.4.4.3.1.1.1.1.1" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1.cmml">
           <mi id="S3.p4.3.m3.4.4.3.1.1.1.1.1.2" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1.2.cmml">
            𝐳
           </mi>
           <mi id="S3.p4.3.m3.4.4.3.1.1.1.1.1.3" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1.3.cmml">
            j
           </mi>
          </msub>
          <mo id="S3.p4.3.m3.4.4.3.1.1.1.2.4" lspace="0em" rspace="0em" xref="S3.p4.3.m3.4.4.3.1.1.1.3.1.cmml">
           |
          </mo>
          <mrow id="S3.p4.3.m3.4.4.3.1.1.1.2.2" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.cmml">
           <mi id="S3.p4.3.m3.4.4.3.1.1.1.2.2.2" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.2.cmml">
            j
           </mi>
           <mo id="S3.p4.3.m3.4.4.3.1.1.1.2.2.1" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.1.cmml">
            ≤
           </mo>
           <mi id="S3.p4.3.m3.4.4.3.1.1.1.2.2.3" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.3.cmml">
            i
           </mi>
          </mrow>
          <mo id="S3.p4.3.m3.4.4.3.1.1.1.2.5" stretchy="false" xref="S3.p4.3.m3.4.4.3.1.1.1.3.1.cmml">
           }
          </mo>
         </mrow>
         <mo id="S3.p4.3.m3.4.4.3.1.1.4" stretchy="false" xref="S3.p4.3.m3.4.4.3.1.2.cmml">
          )
         </mo>
        </mrow>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.4b">
       <apply id="S3.p4.3.m3.4.4.cmml" xref="S3.p4.3.m3.4.4">
        <eq id="S3.p4.3.m3.4.4.4.cmml" xref="S3.p4.3.m3.4.4.4">
        </eq>
        <apply id="S3.p4.3.m3.3.3.2.3.cmml" xref="S3.p4.3.m3.3.3.2.2">
         <csymbol cd="latexml" id="S3.p4.3.m3.3.3.2.3.1.cmml" xref="S3.p4.3.m3.3.3.2.2.3">
          conditional-set
         </csymbol>
         <apply id="S3.p4.3.m3.2.2.1.1.1.cmml" xref="S3.p4.3.m3.2.2.1.1.1">
          <csymbol cd="ambiguous" id="S3.p4.3.m3.2.2.1.1.1.1.cmml" xref="S3.p4.3.m3.2.2.1.1.1">
           superscript
          </csymbol>
          <apply id="S3.p4.3.m3.2.2.1.1.1.2.cmml" xref="S3.p4.3.m3.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S3.p4.3.m3.2.2.1.1.1.2.1.cmml" xref="S3.p4.3.m3.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.p4.3.m3.2.2.1.1.1.2.2.cmml" xref="S3.p4.3.m3.2.2.1.1.1.2.2">
            𝐳
           </ci>
           <apply id="S3.p4.3.m3.2.2.1.1.1.2.3.cmml" xref="S3.p4.3.m3.2.2.1.1.1.2.3">
            <plus id="S3.p4.3.m3.2.2.1.1.1.2.3.1.cmml" xref="S3.p4.3.m3.2.2.1.1.1.2.3.1">
            </plus>
            <ci id="S3.p4.3.m3.2.2.1.1.1.2.3.2.cmml" xref="S3.p4.3.m3.2.2.1.1.1.2.3.2">
             𝑖
            </ci>
            <cn id="S3.p4.3.m3.2.2.1.1.1.2.3.3.cmml" type="integer" xref="S3.p4.3.m3.2.2.1.1.1.2.3.3">
             1
            </cn>
           </apply>
          </apply>
          <ci id="S3.p4.3.m3.2.2.1.1.1.3.cmml" xref="S3.p4.3.m3.2.2.1.1.1.3">
           𝑛
          </ci>
         </apply>
         <apply id="S3.p4.3.m3.3.3.2.2.2.cmml" xref="S3.p4.3.m3.3.3.2.2.2">
          <eq id="S3.p4.3.m3.3.3.2.2.2.1.cmml" xref="S3.p4.3.m3.3.3.2.2.2.1">
          </eq>
          <ci id="S3.p4.3.m3.3.3.2.2.2.2.cmml" xref="S3.p4.3.m3.3.3.2.2.2.2">
           𝑛
          </ci>
          <apply id="S3.p4.3.m3.3.3.2.2.2.3.cmml" xref="S3.p4.3.m3.3.3.2.2.2.3">
           <times id="S3.p4.3.m3.3.3.2.2.2.3.1.cmml" xref="S3.p4.3.m3.3.3.2.2.2.3.1">
           </times>
           <cn id="S3.p4.3.m3.3.3.2.2.2.3.2.cmml" type="integer" xref="S3.p4.3.m3.3.3.2.2.2.3.2">
            1
           </cn>
           <ci id="S3.p4.3.m3.3.3.2.2.2.3.3.cmml" xref="S3.p4.3.m3.3.3.2.2.2.3.3">
            ⋯
           </ci>
           <ci id="S3.p4.3.m3.3.3.2.2.2.3.4.cmml" xref="S3.p4.3.m3.3.3.2.2.2.3.4">
            𝑁
           </ci>
          </apply>
         </apply>
        </apply>
        <apply id="S3.p4.3.m3.4.4.3.cmml" xref="S3.p4.3.m3.4.4.3">
         <times id="S3.p4.3.m3.4.4.3.2.cmml" xref="S3.p4.3.m3.4.4.3.2">
         </times>
         <apply id="S3.p4.3.m3.4.4.3.3.cmml" xref="S3.p4.3.m3.4.4.3.3">
          <csymbol cd="ambiguous" id="S3.p4.3.m3.4.4.3.3.1.cmml" xref="S3.p4.3.m3.4.4.3.3">
           subscript
          </csymbol>
          <ci id="S3.p4.3.m3.4.4.3.3.2.cmml" xref="S3.p4.3.m3.4.4.3.3.2">
           𝑓
          </ci>
          <ci id="S3.p4.3.m3.4.4.3.3.3.cmml" xref="S3.p4.3.m3.4.4.3.3.3">
           𝜃
          </ci>
         </apply>
         <list id="S3.p4.3.m3.4.4.3.1.2.cmml" xref="S3.p4.3.m3.4.4.3.1.1">
          <ci id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1">
           𝐩
          </ci>
          <apply id="S3.p4.3.m3.4.4.3.1.1.1.3.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.2">
           <csymbol cd="latexml" id="S3.p4.3.m3.4.4.3.1.1.1.3.1.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.2.3">
            conditional-set
           </csymbol>
           <apply id="S3.p4.3.m3.4.4.3.1.1.1.1.1.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S3.p4.3.m3.4.4.3.1.1.1.1.1.1.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.p4.3.m3.4.4.3.1.1.1.1.1.2.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1.2">
             𝐳
            </ci>
            <ci id="S3.p4.3.m3.4.4.3.1.1.1.1.1.3.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.1.1.3">
             𝑗
            </ci>
           </apply>
           <apply id="S3.p4.3.m3.4.4.3.1.1.1.2.2.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2">
            <leq id="S3.p4.3.m3.4.4.3.1.1.1.2.2.1.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.1">
            </leq>
            <ci id="S3.p4.3.m3.4.4.3.1.1.1.2.2.2.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.2">
             𝑗
            </ci>
            <ci id="S3.p4.3.m3.4.4.3.1.1.1.2.2.3.cmml" xref="S3.p4.3.m3.4.4.3.1.1.1.2.2.3">
             𝑖
            </ci>
           </apply>
          </apply>
         </list>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p4.3.m3.4c">
       \{\mathbf{z}_{i+1}^{n}|n=1\cdots N\}=f_{\theta}(\mathbf{p};\{\mathbf{z}_{j}|j\leq i\})
      </annotation>
     </semantics>
    </math>
    . Then, it leverages an LLM to evaluate
    <math alttext="\{\mathbf{z}_{i+1}^{n}|n=1\cdots N\}" class="ltx_Math" display="inline" id="S3.p4.4.m4.2">
     <semantics id="S3.p4.4.m4.2a">
      <mrow id="S3.p4.4.m4.2.2.2" xref="S3.p4.4.m4.2.2.3.cmml">
       <mo id="S3.p4.4.m4.2.2.2.3" stretchy="false" xref="S3.p4.4.m4.2.2.3.1.cmml">
        {
       </mo>
       <msubsup id="S3.p4.4.m4.1.1.1.1" xref="S3.p4.4.m4.1.1.1.1.cmml">
        <mi id="S3.p4.4.m4.1.1.1.1.2.2" xref="S3.p4.4.m4.1.1.1.1.2.2.cmml">
         𝐳
        </mi>
        <mrow id="S3.p4.4.m4.1.1.1.1.2.3" xref="S3.p4.4.m4.1.1.1.1.2.3.cmml">
         <mi id="S3.p4.4.m4.1.1.1.1.2.3.2" xref="S3.p4.4.m4.1.1.1.1.2.3.2.cmml">
          i
         </mi>
         <mo id="S3.p4.4.m4.1.1.1.1.2.3.1" xref="S3.p4.4.m4.1.1.1.1.2.3.1.cmml">
          +
         </mo>
         <mn id="S3.p4.4.m4.1.1.1.1.2.3.3" xref="S3.p4.4.m4.1.1.1.1.2.3.3.cmml">
          1
         </mn>
        </mrow>
        <mi id="S3.p4.4.m4.1.1.1.1.3" xref="S3.p4.4.m4.1.1.1.1.3.cmml">
         n
        </mi>
       </msubsup>
       <mo id="S3.p4.4.m4.2.2.2.4" lspace="0em" rspace="0em" xref="S3.p4.4.m4.2.2.3.1.cmml">
        |
       </mo>
       <mrow id="S3.p4.4.m4.2.2.2.2" xref="S3.p4.4.m4.2.2.2.2.cmml">
        <mi id="S3.p4.4.m4.2.2.2.2.2" xref="S3.p4.4.m4.2.2.2.2.2.cmml">
         n
        </mi>
        <mo id="S3.p4.4.m4.2.2.2.2.1" xref="S3.p4.4.m4.2.2.2.2.1.cmml">
         =
        </mo>
        <mrow id="S3.p4.4.m4.2.2.2.2.3" xref="S3.p4.4.m4.2.2.2.2.3.cmml">
         <mn id="S3.p4.4.m4.2.2.2.2.3.2" xref="S3.p4.4.m4.2.2.2.2.3.2.cmml">
          1
         </mn>
         <mo id="S3.p4.4.m4.2.2.2.2.3.1" lspace="0em" rspace="0em" xref="S3.p4.4.m4.2.2.2.2.3.1.cmml">
          ​
         </mo>
         <mi id="S3.p4.4.m4.2.2.2.2.3.3" mathvariant="normal" xref="S3.p4.4.m4.2.2.2.2.3.3.cmml">
          ⋯
         </mi>
         <mo id="S3.p4.4.m4.2.2.2.2.3.1a" lspace="0em" rspace="0em" xref="S3.p4.4.m4.2.2.2.2.3.1.cmml">
          ​
         </mo>
         <mi id="S3.p4.4.m4.2.2.2.2.3.4" xref="S3.p4.4.m4.2.2.2.2.3.4.cmml">
          N
         </mi>
        </mrow>
       </mrow>
       <mo id="S3.p4.4.m4.2.2.2.5" stretchy="false" xref="S3.p4.4.m4.2.2.3.1.cmml">
        }
       </mo>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.2b">
       <apply id="S3.p4.4.m4.2.2.3.cmml" xref="S3.p4.4.m4.2.2.2">
        <csymbol cd="latexml" id="S3.p4.4.m4.2.2.3.1.cmml" xref="S3.p4.4.m4.2.2.2.3">
         conditional-set
        </csymbol>
        <apply id="S3.p4.4.m4.1.1.1.1.cmml" xref="S3.p4.4.m4.1.1.1.1">
         <csymbol cd="ambiguous" id="S3.p4.4.m4.1.1.1.1.1.cmml" xref="S3.p4.4.m4.1.1.1.1">
          superscript
         </csymbol>
         <apply id="S3.p4.4.m4.1.1.1.1.2.cmml" xref="S3.p4.4.m4.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.p4.4.m4.1.1.1.1.2.1.cmml" xref="S3.p4.4.m4.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.p4.4.m4.1.1.1.1.2.2.cmml" xref="S3.p4.4.m4.1.1.1.1.2.2">
           𝐳
          </ci>
          <apply id="S3.p4.4.m4.1.1.1.1.2.3.cmml" xref="S3.p4.4.m4.1.1.1.1.2.3">
           <plus id="S3.p4.4.m4.1.1.1.1.2.3.1.cmml" xref="S3.p4.4.m4.1.1.1.1.2.3.1">
           </plus>
           <ci id="S3.p4.4.m4.1.1.1.1.2.3.2.cmml" xref="S3.p4.4.m4.1.1.1.1.2.3.2">
            𝑖
           </ci>
           <cn id="S3.p4.4.m4.1.1.1.1.2.3.3.cmml" type="integer" xref="S3.p4.4.m4.1.1.1.1.2.3.3">
            1
           </cn>
          </apply>
         </apply>
         <ci id="S3.p4.4.m4.1.1.1.1.3.cmml" xref="S3.p4.4.m4.1.1.1.1.3">
          𝑛
         </ci>
        </apply>
        <apply id="S3.p4.4.m4.2.2.2.2.cmml" xref="S3.p4.4.m4.2.2.2.2">
         <eq id="S3.p4.4.m4.2.2.2.2.1.cmml" xref="S3.p4.4.m4.2.2.2.2.1">
         </eq>
         <ci id="S3.p4.4.m4.2.2.2.2.2.cmml" xref="S3.p4.4.m4.2.2.2.2.2">
          𝑛
         </ci>
         <apply id="S3.p4.4.m4.2.2.2.2.3.cmml" xref="S3.p4.4.m4.2.2.2.2.3">
          <times id="S3.p4.4.m4.2.2.2.2.3.1.cmml" xref="S3.p4.4.m4.2.2.2.2.3.1">
          </times>
          <cn id="S3.p4.4.m4.2.2.2.2.3.2.cmml" type="integer" xref="S3.p4.4.m4.2.2.2.2.3.2">
           1
          </cn>
          <ci id="S3.p4.4.m4.2.2.2.2.3.3.cmml" xref="S3.p4.4.m4.2.2.2.2.3.3">
           ⋯
          </ci>
          <ci id="S3.p4.4.m4.2.2.2.2.3.4.cmml" xref="S3.p4.4.m4.2.2.2.2.3.4">
           𝑁
          </ci>
         </apply>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p4.4.m4.2c">
       \{\mathbf{z}_{i+1}^{n}|n=1\cdots N\}
      </annotation>
     </semantics>
    </math>
    for the best one and choose it as the next sub-solution
    <math alttext="\mathbf{z}_{i+1}" class="ltx_Math" display="inline" id="S3.p4.5.m5.1">
     <semantics id="S3.p4.5.m5.1a">
      <msub id="S3.p4.5.m5.1.1" xref="S3.p4.5.m5.1.1.cmml">
       <mi id="S3.p4.5.m5.1.1.2" xref="S3.p4.5.m5.1.1.2.cmml">
        𝐳
       </mi>
       <mrow id="S3.p4.5.m5.1.1.3" xref="S3.p4.5.m5.1.1.3.cmml">
        <mi id="S3.p4.5.m5.1.1.3.2" xref="S3.p4.5.m5.1.1.3.2.cmml">
         i
        </mi>
        <mo id="S3.p4.5.m5.1.1.3.1" xref="S3.p4.5.m5.1.1.3.1.cmml">
         +
        </mo>
        <mn id="S3.p4.5.m5.1.1.3.3" xref="S3.p4.5.m5.1.1.3.3.cmml">
         1
        </mn>
       </mrow>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S3.p4.5.m5.1b">
       <apply id="S3.p4.5.m5.1.1.cmml" xref="S3.p4.5.m5.1.1">
        <csymbol cd="ambiguous" id="S3.p4.5.m5.1.1.1.cmml" xref="S3.p4.5.m5.1.1">
         subscript
        </csymbol>
        <ci id="S3.p4.5.m5.1.1.2.cmml" xref="S3.p4.5.m5.1.1.2">
         𝐳
        </ci>
        <apply id="S3.p4.5.m5.1.1.3.cmml" xref="S3.p4.5.m5.1.1.3">
         <plus id="S3.p4.5.m5.1.1.3.1.cmml" xref="S3.p4.5.m5.1.1.3.1">
         </plus>
         <ci id="S3.p4.5.m5.1.1.3.2.cmml" xref="S3.p4.5.m5.1.1.3.2">
          𝑖
         </ci>
         <cn id="S3.p4.5.m5.1.1.3.3.cmml" type="integer" xref="S3.p4.5.m5.1.1.3.3">
          1
         </cn>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p4.5.m5.1c">
       \mathbf{z}_{i+1}
      </annotation>
     </semantics>
    </math>
    . The above searching process is repeated until ToT obtains a satisfying solution.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p5">
   <p class="ltx_p" id="S3.p5.1">
    Although these methods improve the complex reasoning ability of LLMs with different prompting, they all prompt the LLM to reason from scratch. This reasoning scheme cannot reuse the prior knowledge in problem-solving and suffers from accumulated errors during multi-step reasoning. Thus, they fall short in tasks involving optimization and multi-step searching.
As shown in Figure
    <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    , IO, CoT, and ToT prompting all fail to find the optimal shortest path
    <math alttext="0\rightarrow 3\rightarrow 4" class="ltx_Math" display="inline" id="S3.p5.1.m1.1">
     <semantics id="S3.p5.1.m1.1a">
      <mrow id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml">
       <mn id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">
        0
       </mn>
       <mo id="S3.p5.1.m1.1.1.3" stretchy="false" xref="S3.p5.1.m1.1.1.3.cmml">
        →
       </mo>
       <mn id="S3.p5.1.m1.1.1.4" xref="S3.p5.1.m1.1.1.4.cmml">
        3
       </mn>
       <mo id="S3.p5.1.m1.1.1.5" stretchy="false" xref="S3.p5.1.m1.1.1.5.cmml">
        →
       </mo>
       <mn id="S3.p5.1.m1.1.1.6" xref="S3.p5.1.m1.1.1.6.cmml">
        4
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b">
       <apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1">
        <and id="S3.p5.1.m1.1.1a.cmml" xref="S3.p5.1.m1.1.1">
        </and>
        <apply id="S3.p5.1.m1.1.1b.cmml" xref="S3.p5.1.m1.1.1">
         <ci id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">
          →
         </ci>
         <cn id="S3.p5.1.m1.1.1.2.cmml" type="integer" xref="S3.p5.1.m1.1.1.2">
          0
         </cn>
         <cn id="S3.p5.1.m1.1.1.4.cmml" type="integer" xref="S3.p5.1.m1.1.1.4">
          3
         </cn>
        </apply>
        <apply id="S3.p5.1.m1.1.1c.cmml" xref="S3.p5.1.m1.1.1">
         <ci id="S3.p5.1.m1.1.1.5.cmml" xref="S3.p5.1.m1.1.1.5">
          →
         </ci>
         <share href="#S3.p5.1.m1.1.1.4.cmml" id="S3.p5.1.m1.1.1d.cmml" xref="S3.p5.1.m1.1.1">
         </share>
         <cn id="S3.p5.1.m1.1.1.6.cmml" type="integer" xref="S3.p5.1.m1.1.1.6">
          4
         </cn>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">
       0\rightarrow 3\rightarrow 4
      </annotation>
     </semantics>
    </math>
    from Node 0 to Node 4 in a very simple graph, which can be easily solved by humans. When using multi-step searching for this task with ToT, it even falsely searches backward and visits Node 3 two times. The result of ToT on a more complex graph is shown in Figure
    <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4 Methodology ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    (b.2).
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Methodology
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    When humans encounter a new problem, they often compare it to familiar ones with similar characteristics, a process known as analogical reasoning
    <cite class="ltx_cite ltx_citemacro_cite">
     Carbonell (
     <a class="ltx_ref" href="#bib.bib10" title="">
      1985
     </a>
     )
    </cite>
    .
Thus, we aim to leverage insights in exploring some problems that are analogous to the input problem, i.e. analogous problems, to facilitate input problem-solving.
We introduce Thought Propagation (TP), a versatile analogical framework for LLM reasoning. As shown in Figure
    <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3 Preliminaries ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    (d), TP actively generates analogous problems related to the input problem during the reasoning process, all without relying on external knowledge bases. It then combines the solutions from these proposed analogous problems to facilitate solving the input problem by creating an updated solution or formulating a high-level plan. We introduce the three modules of TP:
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.1">
     LLM Propose
    </span>
    ,
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.2">
     LLM Solve
    </span>
    , and
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.3">
     LLM Aggregate
    </span>
    . Then, we give a general setup of the proposed framework and leave the implementation for each task in Section
    <a class="ltx_ref" href="#S5" title="5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S4.F4">
   <p class="ltx_p ltx_align_center ltx_align_center" id="S4.F4.1.1">
    <span class="ltx_text" id="S4.F4.1.1.1">
     <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="196" id="S4.F4.1.1.1.g1" src="/html/2310.03965/assets/x4.png" width="396"/>
    </span>
   </p>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 4:
    </span>
    An example of TP and ToT for the Shortest-path Task. ToT (b) fails to solve the problem in (a) due to the accumulated errors in intermediate reasoning steps. Building upon solutions from analogous problems, TP (c) refines the initial sub-optimal solution and finally finds the optimal one.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S4.p2">
   <p class="ltx_p" id="S4.p2.1">
    <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.p2.1.1">
     LLM Propose
    </span>
    .
Given an input problem,
    <span class="ltx_text ltx_font_typewriter" id="S4.p2.1.2">
     LLM Propose
    </span>
    generates a set of analogous problems.
Solving these analogous problems should provide distinctive insights to help solve the input one.
Thus,
    <span class="ltx_text ltx_font_typewriter" id="S4.p2.1.3">
     LLM Propose
    </span>
    generates analogous problems in two perspectives.
First, the solutions from analogous problems can be transferred to yield new solutions to the input problem.
In this manner, TP can reuse the solutions from analogous problems to develop new solutions to the input problem in an analogical approach instead of reasoning from scratch.
Second, solving analogous problems can produce high-level plans for the input problem-solving.
In this way, TP can rectify the errors during planning and improve the multi-step reasoning of the input problem. Both ways to generate analogous problems are instantiated using few-shot problem exemplars or zero-shot prompting.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S4.p3">
   <p class="ltx_p" id="S4.p3.1">
    <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.p3.1.1">
     LLM Solve
    </span>
    .
    <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.2">
     LLM Solve
    </span>
    serves a dual purpose: solving the input problem to produce an initial solution and solving the analogous problems proposed by
    <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.3">
     LLM Propose
    </span>
    . This module can be instantiated using existing prompting approaches such as CoT
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2022
     </a>
     )
    </cite>
    . Although the solutions to analogous problems are not expert-level, the following aggregation module can assess these solutions and use the most promising one to instantiate analogical reasoning. Moreover, we introduce a multi-layer implementation of TP to improve solutions to analogous problems further.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S4.p4">
   <p class="ltx_p" id="S4.p4.1">
    <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.p4.1.1">
     LLM Aggregate
    </span>
    .
    <span class="ltx_text ltx_font_typewriter" id="S4.p4.1.2">
     LLM Aggregate
    </span>
    aggregates solutions from analogous problems to enhance solving the input problem.
This module is conjugated to the
    <span class="ltx_text ltx_font_typewriter" id="S4.p4.1.3">
     LLM Propose
    </span>
    module, since it depends on the relationship between the input problem and its analogous counterparts generated by
    <span class="ltx_text ltx_font_typewriter" id="S4.p4.1.4">
     LLM Propose
    </span>
    . Thus,
    <span class="ltx_text ltx_font_typewriter" id="S4.p4.1.5">
     LLM Aggregate
    </span>
    utilizes the solutions from analogous problems in two ways.
First, it prompts the LLM to develop new solutions to the input problems based on the results of analogous problems.
An example of this manner is shown in Figure
    <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4 Methodology ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    . (c). If we already obtain the shortest paths to the neighborhood nodes of the target node, only one-step reasoning is required to yield a new path to the target node.
Notice this manner is different from recursive problem decomposition
    <cite class="ltx_cite ltx_citemacro_cite">
     Khot et al. (
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     )
    </cite>
    since it only requires one-step reasoning to develop a new solution to the input problem.
Second, this module prompts the LLM to derive high-level plans to solve the input problem using the solutions from analogous problems.
The plan is knowledge-intensive, thus the LLM can carry this plan in every round of decision-making when solving long-trial planning tasks.
After generating new solutions or plans using the results of analogous problems, the LLM evaluates these outputs and chooses the best one to improve input problem-solving.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S4.p5">
   <p class="ltx_p" id="S4.p5.10">
    <span class="ltx_text ltx_font_bold" id="S4.p5.10.1">
     Multi-layer Implementation
    </span>
    . As shown in Figure
    <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3 Preliminaries ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    (d), we can stack
    <math alttext="K" class="ltx_Math" display="inline" id="S4.p5.1.m1.1">
     <semantics id="S4.p5.1.m1.1a">
      <mi id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml">
       K
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b">
       <ci id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1">
        𝐾
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">
       K
      </annotation>
     </semantics>
    </math>
    layers of TP to leverage the solutions from
    <math alttext="K" class="ltx_Math" display="inline" id="S4.p5.2.m2.1">
     <semantics id="S4.p5.2.m2.1a">
      <mi id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml">
       K
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b">
       <ci id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1">
        𝐾
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">
       K
      </annotation>
     </semantics>
    </math>
    -hop analogous problems to improve the solution to the input problem. Thus, existing methods, such as IO, CoT, ToT, etc., can be viewed as the special cases of TP by setting
    <math alttext="K=0" class="ltx_Math" display="inline" id="S4.p5.3.m3.1">
     <semantics id="S4.p5.3.m3.1a">
      <mrow id="S4.p5.3.m3.1.1" xref="S4.p5.3.m3.1.1.cmml">
       <mi id="S4.p5.3.m3.1.1.2" xref="S4.p5.3.m3.1.1.2.cmml">
        K
       </mi>
       <mo id="S4.p5.3.m3.1.1.1" xref="S4.p5.3.m3.1.1.1.cmml">
        =
       </mo>
       <mn id="S4.p5.3.m3.1.1.3" xref="S4.p5.3.m3.1.1.3.cmml">
        0
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.3.m3.1b">
       <apply id="S4.p5.3.m3.1.1.cmml" xref="S4.p5.3.m3.1.1">
        <eq id="S4.p5.3.m3.1.1.1.cmml" xref="S4.p5.3.m3.1.1.1">
        </eq>
        <ci id="S4.p5.3.m3.1.1.2.cmml" xref="S4.p5.3.m3.1.1.2">
         𝐾
        </ci>
        <cn id="S4.p5.3.m3.1.1.3.cmml" type="integer" xref="S4.p5.3.m3.1.1.3">
         0
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.3.m3.1c">
       K=0
      </annotation>
     </semantics>
    </math>
    since they solve each problem from scratch and do not instantiate analogical reasoning. By setting
    <math alttext="K=1" class="ltx_Math" display="inline" id="S4.p5.4.m4.1">
     <semantics id="S4.p5.4.m4.1a">
      <mrow id="S4.p5.4.m4.1.1" xref="S4.p5.4.m4.1.1.cmml">
       <mi id="S4.p5.4.m4.1.1.2" xref="S4.p5.4.m4.1.1.2.cmml">
        K
       </mi>
       <mo id="S4.p5.4.m4.1.1.1" xref="S4.p5.4.m4.1.1.1.cmml">
        =
       </mo>
       <mn id="S4.p5.4.m4.1.1.3" xref="S4.p5.4.m4.1.1.3.cmml">
        1
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.4.m4.1b">
       <apply id="S4.p5.4.m4.1.1.cmml" xref="S4.p5.4.m4.1.1">
        <eq id="S4.p5.4.m4.1.1.1.cmml" xref="S4.p5.4.m4.1.1.1">
        </eq>
        <ci id="S4.p5.4.m4.1.1.2.cmml" xref="S4.p5.4.m4.1.1.2">
         𝐾
        </ci>
        <cn id="S4.p5.4.m4.1.1.3.cmml" type="integer" xref="S4.p5.4.m4.1.1.3">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.4.m4.1c">
       K=1
      </annotation>
     </semantics>
    </math>
    , TP aggregates the solutions from 1-hop analogous problems to refine the solution to the input one. TP further allows hierarchical refinement by setting
    <math alttext="K\geq 2" class="ltx_Math" display="inline" id="S4.p5.5.m5.1">
     <semantics id="S4.p5.5.m5.1a">
      <mrow id="S4.p5.5.m5.1.1" xref="S4.p5.5.m5.1.1.cmml">
       <mi id="S4.p5.5.m5.1.1.2" xref="S4.p5.5.m5.1.1.2.cmml">
        K
       </mi>
       <mo id="S4.p5.5.m5.1.1.1" xref="S4.p5.5.m5.1.1.1.cmml">
        ≥
       </mo>
       <mn id="S4.p5.5.m5.1.1.3" xref="S4.p5.5.m5.1.1.3.cmml">
        2
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.5.m5.1b">
       <apply id="S4.p5.5.m5.1.1.cmml" xref="S4.p5.5.m5.1.1">
        <geq id="S4.p5.5.m5.1.1.1.cmml" xref="S4.p5.5.m5.1.1.1">
        </geq>
        <ci id="S4.p5.5.m5.1.1.2.cmml" xref="S4.p5.5.m5.1.1.2">
         𝐾
        </ci>
        <cn id="S4.p5.5.m5.1.1.3.cmml" type="integer" xref="S4.p5.5.m5.1.1.3">
         2
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.5.m5.1c">
       K\geq 2
      </annotation>
     </semantics>
    </math>
    . In this case, the problems in
    <math alttext="i" class="ltx_Math" display="inline" id="S4.p5.6.m6.1">
     <semantics id="S4.p5.6.m6.1a">
      <mi id="S4.p5.6.m6.1.1" xref="S4.p5.6.m6.1.1.cmml">
       i
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p5.6.m6.1b">
       <ci id="S4.p5.6.m6.1.1.cmml" xref="S4.p5.6.m6.1.1">
        𝑖
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.6.m6.1c">
       i
      </annotation>
     </semantics>
    </math>
    -th layer are the analogous problems in
    <math alttext="(i-1)" class="ltx_Math" display="inline" id="S4.p5.7.m7.1">
     <semantics id="S4.p5.7.m7.1a">
      <mrow id="S4.p5.7.m7.1.1.1" xref="S4.p5.7.m7.1.1.1.1.cmml">
       <mo id="S4.p5.7.m7.1.1.1.2" stretchy="false" xref="S4.p5.7.m7.1.1.1.1.cmml">
        (
       </mo>
       <mrow id="S4.p5.7.m7.1.1.1.1" xref="S4.p5.7.m7.1.1.1.1.cmml">
        <mi id="S4.p5.7.m7.1.1.1.1.2" xref="S4.p5.7.m7.1.1.1.1.2.cmml">
         i
        </mi>
        <mo id="S4.p5.7.m7.1.1.1.1.1" xref="S4.p5.7.m7.1.1.1.1.1.cmml">
         −
        </mo>
        <mn id="S4.p5.7.m7.1.1.1.1.3" xref="S4.p5.7.m7.1.1.1.1.3.cmml">
         1
        </mn>
       </mrow>
       <mo id="S4.p5.7.m7.1.1.1.3" stretchy="false" xref="S4.p5.7.m7.1.1.1.1.cmml">
        )
       </mo>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.7.m7.1b">
       <apply id="S4.p5.7.m7.1.1.1.1.cmml" xref="S4.p5.7.m7.1.1.1">
        <minus id="S4.p5.7.m7.1.1.1.1.1.cmml" xref="S4.p5.7.m7.1.1.1.1.1">
        </minus>
        <ci id="S4.p5.7.m7.1.1.1.1.2.cmml" xref="S4.p5.7.m7.1.1.1.1.2">
         𝑖
        </ci>
        <cn id="S4.p5.7.m7.1.1.1.1.3.cmml" type="integer" xref="S4.p5.7.m7.1.1.1.1.3">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.7.m7.1c">
       (i-1)
      </annotation>
     </semantics>
    </math>
    -th layer (
    <math alttext="i\geq 1" class="ltx_Math" display="inline" id="S4.p5.8.m8.1">
     <semantics id="S4.p5.8.m8.1a">
      <mrow id="S4.p5.8.m8.1.1" xref="S4.p5.8.m8.1.1.cmml">
       <mi id="S4.p5.8.m8.1.1.2" xref="S4.p5.8.m8.1.1.2.cmml">
        i
       </mi>
       <mo id="S4.p5.8.m8.1.1.1" xref="S4.p5.8.m8.1.1.1.cmml">
        ≥
       </mo>
       <mn id="S4.p5.8.m8.1.1.3" xref="S4.p5.8.m8.1.1.3.cmml">
        1
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.8.m8.1b">
       <apply id="S4.p5.8.m8.1.1.cmml" xref="S4.p5.8.m8.1.1">
        <geq id="S4.p5.8.m8.1.1.1.cmml" xref="S4.p5.8.m8.1.1.1">
        </geq>
        <ci id="S4.p5.8.m8.1.1.2.cmml" xref="S4.p5.8.m8.1.1.2">
         𝑖
        </ci>
        <cn id="S4.p5.8.m8.1.1.3.cmml" type="integer" xref="S4.p5.8.m8.1.1.3">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.8.m8.1c">
       i\geq 1
      </annotation>
     </semantics>
    </math>
    ). Thus, we can use the solutions from
    <math alttext="(i)" class="ltx_Math" display="inline" id="S4.p5.9.m9.1">
     <semantics id="S4.p5.9.m9.1a">
      <mrow id="S4.p5.9.m9.1.2.2">
       <mo id="S4.p5.9.m9.1.2.2.1" stretchy="false">
        (
       </mo>
       <mi id="S4.p5.9.m9.1.1" xref="S4.p5.9.m9.1.1.cmml">
        i
       </mi>
       <mo id="S4.p5.9.m9.1.2.2.2" stretchy="false">
        )
       </mo>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.9.m9.1b">
       <ci id="S4.p5.9.m9.1.1.cmml" xref="S4.p5.9.m9.1.1">
        𝑖
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.9.m9.1c">
       (i)
      </annotation>
     </semantics>
    </math>
    -th-layer analogous problems to refine
    <math alttext="(i-1)" class="ltx_Math" display="inline" id="S4.p5.10.m10.1">
     <semantics id="S4.p5.10.m10.1a">
      <mrow id="S4.p5.10.m10.1.1.1" xref="S4.p5.10.m10.1.1.1.1.cmml">
       <mo id="S4.p5.10.m10.1.1.1.2" stretchy="false" xref="S4.p5.10.m10.1.1.1.1.cmml">
        (
       </mo>
       <mrow id="S4.p5.10.m10.1.1.1.1" xref="S4.p5.10.m10.1.1.1.1.cmml">
        <mi id="S4.p5.10.m10.1.1.1.1.2" xref="S4.p5.10.m10.1.1.1.1.2.cmml">
         i
        </mi>
        <mo id="S4.p5.10.m10.1.1.1.1.1" xref="S4.p5.10.m10.1.1.1.1.1.cmml">
         −
        </mo>
        <mn id="S4.p5.10.m10.1.1.1.1.3" xref="S4.p5.10.m10.1.1.1.1.3.cmml">
         1
        </mn>
       </mrow>
       <mo id="S4.p5.10.m10.1.1.1.3" stretchy="false" xref="S4.p5.10.m10.1.1.1.1.cmml">
        )
       </mo>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p5.10.m10.1b">
       <apply id="S4.p5.10.m10.1.1.1.1.cmml" xref="S4.p5.10.m10.1.1.1">
        <minus id="S4.p5.10.m10.1.1.1.1.1.cmml" xref="S4.p5.10.m10.1.1.1.1.1">
        </minus>
        <ci id="S4.p5.10.m10.1.1.1.1.2.cmml" xref="S4.p5.10.m10.1.1.1.1.2">
         𝑖
        </ci>
        <cn id="S4.p5.10.m10.1.1.1.1.3.cmml" type="integer" xref="S4.p5.10.m10.1.1.1.1.3">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p5.10.m10.1c">
       (i-1)
      </annotation>
     </semantics>
    </math>
    -th-layer analogous problems’ solutions. This hierarchical refinement finishes until the solution to the input problem is refined.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S4.p6">
   <p class="ltx_p" id="S4.p6.1">
    <span class="ltx_text ltx_font_bold" id="S4.p6.1.1">
     General Setup and Recipe
    </span>
    . TP allows plug-and-play generalization and enhancement to different tasks, since we can use existing prompting methods for LLM reasoning to instantiate
    <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S4.p6.1.2">
     LLM Solve
    </span>
    . Using IO prompting and CoT for most tasks is sufficient in our experiments. For more complex problems involving autonomous planning and exploration, prompting methods that synergize thinking and action such as ReAct
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2022
     </a>
     )
    </cite>
    is needed. Although TP builds upon existing prompting methods, it aids their reasoning-from-scratch manner with the hint of solving analogous problems and leads to significant performance gain.
   </p>
  </div>
  <figure class="ltx_table" id="S4.T1">
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    The performance of TP and other baselines on Shortest-path Reasoning Task.
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.9">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="S4.T1.9.10.1">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T1.9.10.1.1" rowspan="2">
       <span class="ltx_text" id="S4.T1.9.10.1.1.1">
        LLM-Backend
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T1.9.10.1.2" rowspan="2">
       <span class="ltx_text" id="S4.T1.9.10.1.2.1">
        Method
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S4.T1.9.10.1.3">
       0-shot
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S4.T1.9.10.1.4">
       1-shot
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.9.10.1.5">
       5-shot
      </th>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.9">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1">
       OR
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1">
        <semantics id="S4.T1.1.1.1.m1.1a">
         <mo id="S4.T1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b">
          <ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.2">
       FR
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.m1.1">
        <semantics id="S4.T1.2.2.2.m1.1a">
         <mo id="S4.T1.2.2.2.m1.1.1" stretchy="false" xref="S4.T1.2.2.2.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b">
          <ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.3.3.3">
       OLR
       <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.m1.1">
        <semantics id="S4.T1.3.3.3.m1.1a">
         <mo id="S4.T1.3.3.3.m1.1.1" stretchy="false" xref="S4.T1.3.3.3.m1.1.1.cmml">
          ↓
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b">
          <ci id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">
           ↓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">
          \downarrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4">
       OR
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.4.4.4.m1.1">
        <semantics id="S4.T1.4.4.4.m1.1a">
         <mo id="S4.T1.4.4.4.m1.1.1" stretchy="false" xref="S4.T1.4.4.4.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b">
          <ci id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.5.5">
       FR
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.5.5.5.m1.1">
        <semantics id="S4.T1.5.5.5.m1.1a">
         <mo id="S4.T1.5.5.5.m1.1.1" stretchy="false" xref="S4.T1.5.5.5.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.m1.1b">
          <ci id="S4.T1.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.5.5.5.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.6.6.6">
       OLR
       <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.6.6.6.m1.1">
        <semantics id="S4.T1.6.6.6.m1.1a">
         <mo id="S4.T1.6.6.6.m1.1.1" stretchy="false" xref="S4.T1.6.6.6.m1.1.1.cmml">
          ↓
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.m1.1b">
          <ci id="S4.T1.6.6.6.m1.1.1.cmml" xref="S4.T1.6.6.6.m1.1.1">
           ↓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.6.6.6.m1.1c">
          \downarrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.7.7">
       OR
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.7.7.7.m1.1">
        <semantics id="S4.T1.7.7.7.m1.1a">
         <mo id="S4.T1.7.7.7.m1.1.1" stretchy="false" xref="S4.T1.7.7.7.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.m1.1b">
          <ci id="S4.T1.7.7.7.m1.1.1.cmml" xref="S4.T1.7.7.7.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.7.7.7.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.8.8.8">
       FR
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.8.8.8.m1.1">
        <semantics id="S4.T1.8.8.8.m1.1a">
         <mo id="S4.T1.8.8.8.m1.1.1" stretchy="false" xref="S4.T1.8.8.8.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.m1.1b">
          <ci id="S4.T1.8.8.8.m1.1.1.cmml" xref="S4.T1.8.8.8.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.8.8.8.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.9.9.9">
       OLR
       <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.9.9.9.m1.1">
        <semantics id="S4.T1.9.9.9.m1.1a">
         <mo id="S4.T1.9.9.9.m1.1.1" stretchy="false" xref="S4.T1.9.9.9.m1.1.1.cmml">
          ↓
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T1.9.9.9.m1.1b">
          <ci id="S4.T1.9.9.9.m1.1.1.cmml" xref="S4.T1.9.9.9.m1.1.1">
           ↓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T1.9.9.9.m1.1c">
          \downarrow
         </annotation>
        </semantics>
       </math>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="S4.T1.9.11.1">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.9.11.1.1" rowspan="5">
       <span class="ltx_text" id="S4.T1.9.11.1.1.1">
        PaLM-2
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.9.11.1.2">
       IO
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.3">
       0.14
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.4">
       0.37
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.11.1.5">
       0.62
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.6">
       0.28
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.7">
       0.48
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.11.1.8">
       0.43
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.9">
       0.26
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.10">
       0.41
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.11.1.11">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.11.1.11.1">
        0.35
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.12.2">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.12.2.1">
       CoT
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.2">
       0.24
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.3">
       0.52
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.12.2.4">
       0.40
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.5">
       0.33
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.6">
       0.45
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.12.2.7">
       0.41
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.8">
       0.29
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.9">
       0.56
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.12.2.10">
       0.39
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.13.3">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.13.3.1">
       BaG
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.2">
       0.23
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.3">
       0.47
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.13.3.4">
       0.44
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.5">
       0.28
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.6">
       0.52
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.13.3.7">
       0.45
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.8">
       0.26
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.9">
       0.52
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.13.3.10">
       0.51
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.14.4">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.14.4.1">
       ToT
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.2">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.3">
       -
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.14.4.4">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.5">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.6">
       -
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.14.4.7">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.8">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.9">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.14.4.10">
       -
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.15.5">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.15.5.1">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.1.1">
        TP
       </span>
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.2">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.2.1">
        0.36
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.3">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.3.1">
        0.57
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.15.5.4">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.4.1">
        0.37
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.5">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.5.1">
        0.38
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.6">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.6.1">
        0.59
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.15.5.7">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.7.1">
        0.36
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.8">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.8.1">
        0.37
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.9">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.15.5.9.1">
        0.62
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.15.5.10">
       0.36
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.16.6">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.9.16.6.1" rowspan="5">
       <span class="ltx_text" id="S4.T1.9.16.6.1.1">
        GPT-3.5
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.9.16.6.2">
       IO
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.3">
       0.33
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.4">
       0.50
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.16.6.5">
       0.17
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.6">
       0.62
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.7">
       0.86
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.16.6.8">
       0.15
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.9">
       0.61
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.10">
       0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.16.6.11">
       0.27
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.17.7">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.17.7.1">
       CoT
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.2">
       0.26
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.3">
       0.35
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.17.7.4">
       0.13
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.5">
       0.58
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.6">
       0.85
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.17.7.7">
       0.16
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.8">
       0.52
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.9">
       0.85
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.17.7.10">
       0.32
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.18.8">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.18.8.1">
       BaG
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.2">
       0.25
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.3">
       0.32
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.18.8.4">
       0.13
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.5">
       0.61
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.6">
       0.87
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.18.8.7">
       0.14
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.8">
       0.64
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.9">
       0.86
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.18.8.10">
       0.13
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.19.9">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.19.9.1">
       ToT
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.2">
       0.22
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.3">
       0.42
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.19.9.4">
       0.82
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.5">
       0.38
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.6">
       0.79
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.19.9.7">
       0.72
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.8">
       0.58
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.9">
       0.93
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.19.9.10">
       0.32
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.20.10">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.20.10.1">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.1.1">
        TP
       </span>
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.2">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.2.1">
        0.65
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.3">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.3.1">
        0.89
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.20.10.4">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.4.1">
        0.12
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.5">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.5.1">
        0.74
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.6">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.6.1">
        0.89
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.20.10.7">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.7.1">
        0.07
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.8">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.8.1">
        0.73
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.9">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.9.1">
        0.91
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.20.10.10">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.20.10.10.1">
        0.10
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.21.11">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S4.T1.9.21.11.1" rowspan="5">
       <span class="ltx_text" id="S4.T1.9.21.11.1.1">
        GPT-4
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.9.21.11.2">
       IO
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.3">
       0.78
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.4">
       1.00
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.21.11.5">
       0.10
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.6">
       0.80
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.7">
       0.99
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.21.11.8">
       0.08
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.9">
       0.81
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.10">
       1.00
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.21.11.11">
       0.08
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.22.12">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.22.12.1">
       CoT
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.2">
       0.76
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.3">
       1.00
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.22.12.4">
       0.10
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.5">
       0.75
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.6">
       1.00
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.22.12.7">
       0.11
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.8">
       0.78
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.9">
       1.00
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.22.12.10">
       0.08
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.23.13">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.23.13.1">
       BaG
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.2">
       0.77
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.3">
       0.98
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.23.13.4">
       0.09
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.5">
       0.80
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.6">
       0.99
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.23.13.7">
       0.09
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.8">
       0.78
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.9">
       1.00
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.23.13.10">
       0.11
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.24.14">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.9.24.14.1">
       ToT
      </th>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.2">
       0.46
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.3">
       0.84
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.24.14.4">
       0.52
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.5">
       0.46
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.6">
       0.73
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.9.24.14.7">
       0.40
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.8">
       0.77
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.9">
       1.00
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T1.9.24.14.10">
       0.07
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T1.9.25.15">
      <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T1.9.25.15.1">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.1.1">
        TP
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.2">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.2.1">
        0.88
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.3">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.3.1">
        1.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.9.25.15.4">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.4.1">
        0.05
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.5">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.5.1">
        0.88
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.6">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.6.1">
        1.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.9.25.15.7">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.7.1">
        0.04
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.8">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.8.1">
        0.86
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.9">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.9.1">
        1.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.9.25.15.10">
       <span class="ltx_text ltx_font_bold" id="S4.T1.9.25.15.10.1">
        0.05
       </span>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <div class="ltx_para ltx_noindent" id="S4.p7">
   <p class="ltx_p" id="S4.p7.2">
    <span class="ltx_text ltx_font_bold" id="S4.p7.2.1">
     Complexity Analysis
    </span>
    .
The complexity of Thought Propagation mainly comes from two perspectives. Firstly, the complexity exponentially increases as the layer number
    <math alttext="k" class="ltx_Math" display="inline" id="S4.p7.1.m1.1">
     <semantics id="S4.p7.1.m1.1a">
      <mi id="S4.p7.1.m1.1.1" xref="S4.p7.1.m1.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p7.1.m1.1b">
       <ci id="S4.p7.1.m1.1.1.cmml" xref="S4.p7.1.m1.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p7.1.m1.1c">
       k
      </annotation>
     </semantics>
    </math>
    increases. However, the
    <math alttext="K" class="ltx_Math" display="inline" id="S4.p7.2.m2.1">
     <semantics id="S4.p7.2.m2.1a">
      <mi id="S4.p7.2.m2.1.1" xref="S4.p7.2.m2.1.1.cmml">
       K
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p7.2.m2.1b">
       <ci id="S4.p7.2.m2.1.1.cmml" xref="S4.p7.2.m2.1.1">
        𝐾
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p7.2.m2.1c">
       K
      </annotation>
     </semantics>
    </math>
    -hop analogous problems are intuitively less related to the input problem, and considering such long-range analogous problems only leads to marginal performance gain. Thus, we only consider implementing up to 2-layers of TP to trade off performance between complexity. We find the performance gain in 2-layer TP is marginal when compared with 1-layer TP, but 2-layer TP leads to more token expenses. 1-layer TP achieves very competitive performances against the baselines with no significant increase in token expenses. For example, 1-layer TP outperforms ToT by a large margin in different LLM backends but shares similar token expenses.
Secondly, instantiating
    <span class="ltx_text ltx_font_typewriter" id="S4.p7.2.2">
     LLM Solve
    </span>
    under 5-shot setting is more expensive than 0-shot setting due to increasing prompting exemplars. We provide a detailed quantitative complexity analysis in Section
    <a class="ltx_ref" href="#S5.SS1" title="5.1 Shortest-path Reasoning ‣ 5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      5.1
     </span>
    </a>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Experiments
  </h2>
  <div class="ltx_para ltx_noindent" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    We employ three challenging tasks, such as Shortest-Path Reasoning, Creative Writing, and LLM-Agent Planning, to evaluate the proposed method (TP). We generate 100 shortest-path problems with non-trivial solutions for the Shortest-Path Reasoning task. We employ the dataset proposed by Yao et. al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     )
    </cite>
    with 100 writing problems for the Creative Writing task. And we use ALFWorld
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shridhar et al.,
     <a class="ltx_ref" href="#bib.bib42" title="">
      2021
     </a>
     )
    </cite>
    game suite to instantiate the LLM-Agent Planning task with 134 environments. TP finds the most optimal shortest paths, generates the most coherent messages, and achieves the highest task completion rate in three tasks.
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Shortest-path Reasoning
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     The Shortest-path Reasoning task is to find the shortest path from the source node to the target node in a weighted undirected graph. This task is challenging for LLMs since 1. the graph structure does not conform to the sequential corpus for training LLMs, and 2. this discrete optimization problem requires searching in an explosively large space.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p2">
    <p class="ltx_p" id="S5.SS1.p2.3">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.3.1">
      Task Setup
     </span>
     . For an input graph, LLM is required to find the shortest path from the source node to the target node using the baselines and TP. For a graph with
     <math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1">
      <semantics id="S5.SS1.p2.1.m1.1a">
       <mi id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">
        N
       </mi>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b">
        <ci id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">
         𝑁
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">
        N
       </annotation>
      </semantics>
     </math>
     nodes, the source node is set to Node
     <math alttext="0" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1">
      <semantics id="S5.SS1.p2.2.m2.1a">
       <mn id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">
        0
       </mn>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b">
        <cn id="S5.SS1.p2.2.m2.1.1.cmml" type="integer" xref="S5.SS1.p2.2.m2.1.1">
         0
        </cn>
       </annotation-xml>
      </semantics>
     </math>
     , and the target node is set to Node
     <math alttext="(N-1)" class="ltx_Math" display="inline" id="S5.SS1.p2.3.m3.1">
      <semantics id="S5.SS1.p2.3.m3.1a">
       <mrow id="S5.SS1.p2.3.m3.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.1.cmml">
        <mo id="S5.SS1.p2.3.m3.1.1.1.2" stretchy="false" xref="S5.SS1.p2.3.m3.1.1.1.1.cmml">
         (
        </mo>
        <mrow id="S5.SS1.p2.3.m3.1.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.1.cmml">
         <mi id="S5.SS1.p2.3.m3.1.1.1.1.2" xref="S5.SS1.p2.3.m3.1.1.1.1.2.cmml">
          N
         </mi>
         <mo id="S5.SS1.p2.3.m3.1.1.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.1.1.cmml">
          −
         </mo>
         <mn id="S5.SS1.p2.3.m3.1.1.1.1.3" xref="S5.SS1.p2.3.m3.1.1.1.1.3.cmml">
          1
         </mn>
        </mrow>
        <mo id="S5.SS1.p2.3.m3.1.1.1.3" stretchy="false" xref="S5.SS1.p2.3.m3.1.1.1.1.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b">
        <apply id="S5.SS1.p2.3.m3.1.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1.1">
         <minus id="S5.SS1.p2.3.m3.1.1.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1.1.1.1">
         </minus>
         <ci id="S5.SS1.p2.3.m3.1.1.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.1.1.2">
          𝑁
         </ci>
         <cn id="S5.SS1.p2.3.m3.1.1.1.1.3.cmml" type="integer" xref="S5.SS1.p2.3.m3.1.1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">
        (N-1)
       </annotation>
      </semantics>
     </math>
     . We filter out the trivial cases where the shortest path only contains one edge. Detailed task setup is in Appendix.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p3">
    <p class="ltx_p" id="S5.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">
      Baselines and LLM Backends
     </span>
     .
We use standard (IO) prompting
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brown et al.,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2020
      </a>
      )
     </cite>
     , Chain-of-Thought (CoT)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib50" title="">
       2022
      </a>
      )
     </cite>
     , Build-a-Graph (BaG)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al.,
      <a class="ltx_ref" href="#bib.bib44" title="">
       2023a
      </a>
      )
     </cite>
     , and Tree-of-Thought (ToT)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib53" title="">
       2023
      </a>
      )
     </cite>
     as the baseline methods. The implementation and prompting exemplars of all the baselines are shown in Appendix.
We evaluate all the methods under 0-shot, 1-shot, and 5-shot prompting settings. We conduct experiments on three LLM backends such as PaLM 2 (Bison)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Anil et al.,
      <a class="ltx_ref" href="#bib.bib1" title="">
       2023
      </a>
      )
     </cite>
     , GPT-3.5
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2022
      </a>
      )
     </cite>
     , and GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p4">
    <p class="ltx_p" id="S5.SS1.p4.6">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p4.6.1">
      Thought Propagation Setup
     </span>
     .
Suppose the input problem is finding the shortest path from Node
     <math alttext="0" class="ltx_Math" display="inline" id="S5.SS1.p4.1.m1.1">
      <semantics id="S5.SS1.p4.1.m1.1a">
       <mn id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">
        0
       </mn>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b">
        <cn id="S5.SS1.p4.1.m1.1.1.cmml" type="integer" xref="S5.SS1.p4.1.m1.1.1">
         0
        </cn>
       </annotation-xml>
      </semantics>
     </math>
     to Node
     <math alttext="(N-1)" class="ltx_Math" display="inline" id="S5.SS1.p4.2.m2.1">
      <semantics id="S5.SS1.p4.2.m2.1a">
       <mrow id="S5.SS1.p4.2.m2.1.1.1" xref="S5.SS1.p4.2.m2.1.1.1.1.cmml">
        <mo id="S5.SS1.p4.2.m2.1.1.1.2" stretchy="false" xref="S5.SS1.p4.2.m2.1.1.1.1.cmml">
         (
        </mo>
        <mrow id="S5.SS1.p4.2.m2.1.1.1.1" xref="S5.SS1.p4.2.m2.1.1.1.1.cmml">
         <mi id="S5.SS1.p4.2.m2.1.1.1.1.2" xref="S5.SS1.p4.2.m2.1.1.1.1.2.cmml">
          N
         </mi>
         <mo id="S5.SS1.p4.2.m2.1.1.1.1.1" xref="S5.SS1.p4.2.m2.1.1.1.1.1.cmml">
          −
         </mo>
         <mn id="S5.SS1.p4.2.m2.1.1.1.1.3" xref="S5.SS1.p4.2.m2.1.1.1.1.3.cmml">
          1
         </mn>
        </mrow>
        <mo id="S5.SS1.p4.2.m2.1.1.1.3" stretchy="false" xref="S5.SS1.p4.2.m2.1.1.1.1.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b">
        <apply id="S5.SS1.p4.2.m2.1.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1.1">
         <minus id="S5.SS1.p4.2.m2.1.1.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1.1.1.1">
         </minus>
         <ci id="S5.SS1.p4.2.m2.1.1.1.1.2.cmml" xref="S5.SS1.p4.2.m2.1.1.1.1.2">
          𝑁
         </ci>
         <cn id="S5.SS1.p4.2.m2.1.1.1.1.3.cmml" type="integer" xref="S5.SS1.p4.2.m2.1.1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">
        (N-1)
       </annotation>
      </semantics>
     </math>
     in the graph
     <math alttext="G_{i}" class="ltx_Math" display="inline" id="S5.SS1.p4.3.m3.1">
      <semantics id="S5.SS1.p4.3.m3.1a">
       <msub id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml">
        <mi id="S5.SS1.p4.3.m3.1.1.2" xref="S5.SS1.p4.3.m3.1.1.2.cmml">
         G
        </mi>
        <mi id="S5.SS1.p4.3.m3.1.1.3" xref="S5.SS1.p4.3.m3.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b">
        <apply id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p4.3.m3.1.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS1.p4.3.m3.1.1.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2">
          𝐺
         </ci>
         <ci id="S5.SS1.p4.3.m3.1.1.3.cmml" xref="S5.SS1.p4.3.m3.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">
        G_{i}
       </annotation>
      </semantics>
     </math>
     with
     <math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.p4.4.m4.1">
      <semantics id="S5.SS1.p4.4.m4.1a">
       <mi id="S5.SS1.p4.4.m4.1.1" xref="S5.SS1.p4.4.m4.1.1.cmml">
        N
       </mi>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.4.m4.1b">
        <ci id="S5.SS1.p4.4.m4.1.1.cmml" xref="S5.SS1.p4.4.m4.1.1">
         𝑁
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p4.4.m4.1c">
        N
       </annotation>
      </semantics>
     </math>
     nodes.
     <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.6.2">
      LLM Propose
     </span>
     prompts the LLM to propose analogous
problems of finding the shortest path from Node
     <math alttext="0" class="ltx_Math" display="inline" id="S5.SS1.p4.5.m5.1">
      <semantics id="S5.SS1.p4.5.m5.1a">
       <mn id="S5.SS1.p4.5.m5.1.1" xref="S5.SS1.p4.5.m5.1.1.cmml">
        0
       </mn>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.5.m5.1b">
        <cn id="S5.SS1.p4.5.m5.1.1.cmml" type="integer" xref="S5.SS1.p4.5.m5.1.1">
         0
        </cn>
       </annotation-xml>
      </semantics>
     </math>
     to the neighborhood nodes of Node
     <math alttext="(N-1)" class="ltx_Math" display="inline" id="S5.SS1.p4.6.m6.1">
      <semantics id="S5.SS1.p4.6.m6.1a">
       <mrow id="S5.SS1.p4.6.m6.1.1.1" xref="S5.SS1.p4.6.m6.1.1.1.1.cmml">
        <mo id="S5.SS1.p4.6.m6.1.1.1.2" stretchy="false" xref="S5.SS1.p4.6.m6.1.1.1.1.cmml">
         (
        </mo>
        <mrow id="S5.SS1.p4.6.m6.1.1.1.1" xref="S5.SS1.p4.6.m6.1.1.1.1.cmml">
         <mi id="S5.SS1.p4.6.m6.1.1.1.1.2" xref="S5.SS1.p4.6.m6.1.1.1.1.2.cmml">
          N
         </mi>
         <mo id="S5.SS1.p4.6.m6.1.1.1.1.1" xref="S5.SS1.p4.6.m6.1.1.1.1.1.cmml">
          −
         </mo>
         <mn id="S5.SS1.p4.6.m6.1.1.1.1.3" xref="S5.SS1.p4.6.m6.1.1.1.1.3.cmml">
          1
         </mn>
        </mrow>
        <mo id="S5.SS1.p4.6.m6.1.1.1.3" stretchy="false" xref="S5.SS1.p4.6.m6.1.1.1.1.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.6.m6.1b">
        <apply id="S5.SS1.p4.6.m6.1.1.1.1.cmml" xref="S5.SS1.p4.6.m6.1.1.1">
         <minus id="S5.SS1.p4.6.m6.1.1.1.1.1.cmml" xref="S5.SS1.p4.6.m6.1.1.1.1.1">
         </minus>
         <ci id="S5.SS1.p4.6.m6.1.1.1.1.2.cmml" xref="S5.SS1.p4.6.m6.1.1.1.1.2">
          𝑁
         </ci>
         <cn id="S5.SS1.p4.6.m6.1.1.1.1.3.cmml" type="integer" xref="S5.SS1.p4.6.m6.1.1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p4.6.m6.1c">
        (N-1)
       </annotation>
      </semantics>
     </math>
     .
     <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.6.3">
      LLM Solve
     </span>
     is implemented with IO prompting with 0-shot/1-shot/5-shot prompting. This module outputs the initial solutions to the input problem and analogous problems.
Afterward,
     <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.6.4">
      LLM Aggregate
     </span>
     uses the results of analogous problems to develop a new path to the input problem. Then, it compares the new path with the initial path and outputs a better one. The implementation and prompts are shown in Appendix.
    </p>
   </div>
   <figure class="ltx_figure" id="S5.F5">
    <p class="ltx_p ltx_align_center ltx_align_center" id="S5.F5.1.1">
     <span class="ltx_text" id="S5.F5.1.1.1">
      <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="105" id="S5.F5.1.1.1.g1" src="/html/2310.03965/assets/x5.png" width="415"/>
     </span>
    </p>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     Study on the complexity and performance of TP under different configurations.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p5">
    <p class="ltx_p" id="S5.SS1.p5.9">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p5.9.1">
      Evaluation Metrics
     </span>
     .
Denote the length of shortest path of graph
     <math alttext="G_{i}" class="ltx_Math" display="inline" id="S5.SS1.p5.1.m1.1">
      <semantics id="S5.SS1.p5.1.m1.1a">
       <msub id="S5.SS1.p5.1.m1.1.1" xref="S5.SS1.p5.1.m1.1.1.cmml">
        <mi id="S5.SS1.p5.1.m1.1.1.2" xref="S5.SS1.p5.1.m1.1.1.2.cmml">
         G
        </mi>
        <mi id="S5.SS1.p5.1.m1.1.1.3" xref="S5.SS1.p5.1.m1.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.1.m1.1b">
        <apply id="S5.SS1.p5.1.m1.1.1.cmml" xref="S5.SS1.p5.1.m1.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p5.1.m1.1.1.1.cmml" xref="S5.SS1.p5.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS1.p5.1.m1.1.1.2.cmml" xref="S5.SS1.p5.1.m1.1.1.2">
          𝐺
         </ci>
         <ci id="S5.SS1.p5.1.m1.1.1.3.cmml" xref="S5.SS1.p5.1.m1.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.1.m1.1c">
        G_{i}
       </annotation>
      </semantics>
     </math>
     as
     <math alttext="L_{i}^{*}" class="ltx_Math" display="inline" id="S5.SS1.p5.2.m2.1">
      <semantics id="S5.SS1.p5.2.m2.1a">
       <msubsup id="S5.SS1.p5.2.m2.1.1" xref="S5.SS1.p5.2.m2.1.1.cmml">
        <mi id="S5.SS1.p5.2.m2.1.1.2.2" xref="S5.SS1.p5.2.m2.1.1.2.2.cmml">
         L
        </mi>
        <mi id="S5.SS1.p5.2.m2.1.1.2.3" xref="S5.SS1.p5.2.m2.1.1.2.3.cmml">
         i
        </mi>
        <mo id="S5.SS1.p5.2.m2.1.1.3" xref="S5.SS1.p5.2.m2.1.1.3.cmml">
         ∗
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.2.m2.1b">
        <apply id="S5.SS1.p5.2.m2.1.1.cmml" xref="S5.SS1.p5.2.m2.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p5.2.m2.1.1.1.cmml" xref="S5.SS1.p5.2.m2.1.1">
          superscript
         </csymbol>
         <apply id="S5.SS1.p5.2.m2.1.1.2.cmml" xref="S5.SS1.p5.2.m2.1.1">
          <csymbol cd="ambiguous" id="S5.SS1.p5.2.m2.1.1.2.1.cmml" xref="S5.SS1.p5.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S5.SS1.p5.2.m2.1.1.2.2.cmml" xref="S5.SS1.p5.2.m2.1.1.2.2">
           𝐿
          </ci>
          <ci id="S5.SS1.p5.2.m2.1.1.2.3.cmml" xref="S5.SS1.p5.2.m2.1.1.2.3">
           𝑖
          </ci>
         </apply>
         <times id="S5.SS1.p5.2.m2.1.1.3.cmml" xref="S5.SS1.p5.2.m2.1.1.3">
         </times>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.2.m2.1c">
        L_{i}^{*}
       </annotation>
      </semantics>
     </math>
     . Let the length of the valid path output by LLM be
     <math alttext="L_{i}" class="ltx_Math" display="inline" id="S5.SS1.p5.3.m3.1">
      <semantics id="S5.SS1.p5.3.m3.1a">
       <msub id="S5.SS1.p5.3.m3.1.1" xref="S5.SS1.p5.3.m3.1.1.cmml">
        <mi id="S5.SS1.p5.3.m3.1.1.2" xref="S5.SS1.p5.3.m3.1.1.2.cmml">
         L
        </mi>
        <mi id="S5.SS1.p5.3.m3.1.1.3" xref="S5.SS1.p5.3.m3.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.3.m3.1b">
        <apply id="S5.SS1.p5.3.m3.1.1.cmml" xref="S5.SS1.p5.3.m3.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p5.3.m3.1.1.1.cmml" xref="S5.SS1.p5.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS1.p5.3.m3.1.1.2.cmml" xref="S5.SS1.p5.3.m3.1.1.2">
          𝐿
         </ci>
         <ci id="S5.SS1.p5.3.m3.1.1.3.cmml" xref="S5.SS1.p5.3.m3.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.3.m3.1c">
        L_{i}
       </annotation>
      </semantics>
     </math>
     .
     <math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.p5.4.m4.1">
      <semantics id="S5.SS1.p5.4.m4.1a">
       <mi id="S5.SS1.p5.4.m4.1.1" xref="S5.SS1.p5.4.m4.1.1.cmml">
        N
       </mi>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.4.m4.1b">
        <ci id="S5.SS1.p5.4.m4.1.1.cmml" xref="S5.SS1.p5.4.m4.1.1">
         𝑁
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.4.m4.1c">
        N
       </annotation>
      </semantics>
     </math>
     is the total number of graphs.
     <math alttext="N_{optimal}" class="ltx_Math" display="inline" id="S5.SS1.p5.5.m5.1">
      <semantics id="S5.SS1.p5.5.m5.1a">
       <msub id="S5.SS1.p5.5.m5.1.1" xref="S5.SS1.p5.5.m5.1.1.cmml">
        <mi id="S5.SS1.p5.5.m5.1.1.2" xref="S5.SS1.p5.5.m5.1.1.2.cmml">
         N
        </mi>
        <mrow id="S5.SS1.p5.5.m5.1.1.3" xref="S5.SS1.p5.5.m5.1.1.3.cmml">
         <mi id="S5.SS1.p5.5.m5.1.1.3.2" xref="S5.SS1.p5.5.m5.1.1.3.2.cmml">
          o
         </mi>
         <mo id="S5.SS1.p5.5.m5.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS1.p5.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.5.m5.1.1.3.3" xref="S5.SS1.p5.5.m5.1.1.3.3.cmml">
          p
         </mi>
         <mo id="S5.SS1.p5.5.m5.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.SS1.p5.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.5.m5.1.1.3.4" xref="S5.SS1.p5.5.m5.1.1.3.4.cmml">
          t
         </mi>
         <mo id="S5.SS1.p5.5.m5.1.1.3.1b" lspace="0em" rspace="0em" xref="S5.SS1.p5.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.5.m5.1.1.3.5" xref="S5.SS1.p5.5.m5.1.1.3.5.cmml">
          i
         </mi>
         <mo id="S5.SS1.p5.5.m5.1.1.3.1c" lspace="0em" rspace="0em" xref="S5.SS1.p5.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.5.m5.1.1.3.6" xref="S5.SS1.p5.5.m5.1.1.3.6.cmml">
          m
         </mi>
         <mo id="S5.SS1.p5.5.m5.1.1.3.1d" lspace="0em" rspace="0em" xref="S5.SS1.p5.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.5.m5.1.1.3.7" xref="S5.SS1.p5.5.m5.1.1.3.7.cmml">
          a
         </mi>
         <mo id="S5.SS1.p5.5.m5.1.1.3.1e" lspace="0em" rspace="0em" xref="S5.SS1.p5.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.5.m5.1.1.3.8" xref="S5.SS1.p5.5.m5.1.1.3.8.cmml">
          l
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.5.m5.1b">
        <apply id="S5.SS1.p5.5.m5.1.1.cmml" xref="S5.SS1.p5.5.m5.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p5.5.m5.1.1.1.cmml" xref="S5.SS1.p5.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS1.p5.5.m5.1.1.2.cmml" xref="S5.SS1.p5.5.m5.1.1.2">
          𝑁
         </ci>
         <apply id="S5.SS1.p5.5.m5.1.1.3.cmml" xref="S5.SS1.p5.5.m5.1.1.3">
          <times id="S5.SS1.p5.5.m5.1.1.3.1.cmml" xref="S5.SS1.p5.5.m5.1.1.3.1">
          </times>
          <ci id="S5.SS1.p5.5.m5.1.1.3.2.cmml" xref="S5.SS1.p5.5.m5.1.1.3.2">
           𝑜
          </ci>
          <ci id="S5.SS1.p5.5.m5.1.1.3.3.cmml" xref="S5.SS1.p5.5.m5.1.1.3.3">
           𝑝
          </ci>
          <ci id="S5.SS1.p5.5.m5.1.1.3.4.cmml" xref="S5.SS1.p5.5.m5.1.1.3.4">
           𝑡
          </ci>
          <ci id="S5.SS1.p5.5.m5.1.1.3.5.cmml" xref="S5.SS1.p5.5.m5.1.1.3.5">
           𝑖
          </ci>
          <ci id="S5.SS1.p5.5.m5.1.1.3.6.cmml" xref="S5.SS1.p5.5.m5.1.1.3.6">
           𝑚
          </ci>
          <ci id="S5.SS1.p5.5.m5.1.1.3.7.cmml" xref="S5.SS1.p5.5.m5.1.1.3.7">
           𝑎
          </ci>
          <ci id="S5.SS1.p5.5.m5.1.1.3.8.cmml" xref="S5.SS1.p5.5.m5.1.1.3.8">
           𝑙
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.5.m5.1c">
        N_{optimal}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="N_{feasible}" class="ltx_Math" display="inline" id="S5.SS1.p5.6.m6.1">
      <semantics id="S5.SS1.p5.6.m6.1a">
       <msub id="S5.SS1.p5.6.m6.1.1" xref="S5.SS1.p5.6.m6.1.1.cmml">
        <mi id="S5.SS1.p5.6.m6.1.1.2" xref="S5.SS1.p5.6.m6.1.1.2.cmml">
         N
        </mi>
        <mrow id="S5.SS1.p5.6.m6.1.1.3" xref="S5.SS1.p5.6.m6.1.1.3.cmml">
         <mi id="S5.SS1.p5.6.m6.1.1.3.2" xref="S5.SS1.p5.6.m6.1.1.3.2.cmml">
          f
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.3" xref="S5.SS1.p5.6.m6.1.1.3.3.cmml">
          e
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.4" xref="S5.SS1.p5.6.m6.1.1.3.4.cmml">
          a
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1b" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.5" xref="S5.SS1.p5.6.m6.1.1.3.5.cmml">
          s
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1c" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.6" xref="S5.SS1.p5.6.m6.1.1.3.6.cmml">
          i
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1d" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.7" xref="S5.SS1.p5.6.m6.1.1.3.7.cmml">
          b
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1e" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.8" xref="S5.SS1.p5.6.m6.1.1.3.8.cmml">
          l
         </mi>
         <mo id="S5.SS1.p5.6.m6.1.1.3.1f" lspace="0em" rspace="0em" xref="S5.SS1.p5.6.m6.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S5.SS1.p5.6.m6.1.1.3.9" xref="S5.SS1.p5.6.m6.1.1.3.9.cmml">
          e
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.6.m6.1b">
        <apply id="S5.SS1.p5.6.m6.1.1.cmml" xref="S5.SS1.p5.6.m6.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p5.6.m6.1.1.1.cmml" xref="S5.SS1.p5.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS1.p5.6.m6.1.1.2.cmml" xref="S5.SS1.p5.6.m6.1.1.2">
          𝑁
         </ci>
         <apply id="S5.SS1.p5.6.m6.1.1.3.cmml" xref="S5.SS1.p5.6.m6.1.1.3">
          <times id="S5.SS1.p5.6.m6.1.1.3.1.cmml" xref="S5.SS1.p5.6.m6.1.1.3.1">
          </times>
          <ci id="S5.SS1.p5.6.m6.1.1.3.2.cmml" xref="S5.SS1.p5.6.m6.1.1.3.2">
           𝑓
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.3.cmml" xref="S5.SS1.p5.6.m6.1.1.3.3">
           𝑒
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.4.cmml" xref="S5.SS1.p5.6.m6.1.1.3.4">
           𝑎
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.5.cmml" xref="S5.SS1.p5.6.m6.1.1.3.5">
           𝑠
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.6.cmml" xref="S5.SS1.p5.6.m6.1.1.3.6">
           𝑖
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.7.cmml" xref="S5.SS1.p5.6.m6.1.1.3.7">
           𝑏
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.8.cmml" xref="S5.SS1.p5.6.m6.1.1.3.8">
           𝑙
          </ci>
          <ci id="S5.SS1.p5.6.m6.1.1.3.9.cmml" xref="S5.SS1.p5.6.m6.1.1.3.9">
           𝑒
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.6.m6.1c">
        N_{feasible}
       </annotation>
      </semantics>
     </math>
     are the number of optimal paths and valid paths output by LLMs. We propose to use three metrics to evaluate the performance of different methods in Shortest-path Reasoning.
     <math alttext="\textbf{Optimal Rate (OR)}={N_{optimal}}/{N}" class="ltx_Math" display="inline" id="S5.SS1.p5.7.m7.1">
      <semantics id="S5.SS1.p5.7.m7.1a">
       <mrow id="S5.SS1.p5.7.m7.1.1" xref="S5.SS1.p5.7.m7.1.1.cmml">
        <mtext class="ltx_mathvariant_bold" id="S5.SS1.p5.7.m7.1.1.2" xref="S5.SS1.p5.7.m7.1.1.2a.cmml">
         Optimal Rate (OR)
        </mtext>
        <mo id="S5.SS1.p5.7.m7.1.1.1" xref="S5.SS1.p5.7.m7.1.1.1.cmml">
         =
        </mo>
        <mrow id="S5.SS1.p5.7.m7.1.1.3" xref="S5.SS1.p5.7.m7.1.1.3.cmml">
         <msub id="S5.SS1.p5.7.m7.1.1.3.2" xref="S5.SS1.p5.7.m7.1.1.3.2.cmml">
          <mi id="S5.SS1.p5.7.m7.1.1.3.2.2" xref="S5.SS1.p5.7.m7.1.1.3.2.2.cmml">
           N
          </mi>
          <mrow id="S5.SS1.p5.7.m7.1.1.3.2.3" xref="S5.SS1.p5.7.m7.1.1.3.2.3.cmml">
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.2" xref="S5.SS1.p5.7.m7.1.1.3.2.3.2.cmml">
            o
           </mi>
           <mo id="S5.SS1.p5.7.m7.1.1.3.2.3.1" lspace="0em" rspace="0em" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.3" xref="S5.SS1.p5.7.m7.1.1.3.2.3.3.cmml">
            p
           </mi>
           <mo id="S5.SS1.p5.7.m7.1.1.3.2.3.1a" lspace="0em" rspace="0em" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.4" xref="S5.SS1.p5.7.m7.1.1.3.2.3.4.cmml">
            t
           </mi>
           <mo id="S5.SS1.p5.7.m7.1.1.3.2.3.1b" lspace="0em" rspace="0em" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.5" xref="S5.SS1.p5.7.m7.1.1.3.2.3.5.cmml">
            i
           </mi>
           <mo id="S5.SS1.p5.7.m7.1.1.3.2.3.1c" lspace="0em" rspace="0em" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.6" xref="S5.SS1.p5.7.m7.1.1.3.2.3.6.cmml">
            m
           </mi>
           <mo id="S5.SS1.p5.7.m7.1.1.3.2.3.1d" lspace="0em" rspace="0em" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.7" xref="S5.SS1.p5.7.m7.1.1.3.2.3.7.cmml">
            a
           </mi>
           <mo id="S5.SS1.p5.7.m7.1.1.3.2.3.1e" lspace="0em" rspace="0em" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.7.m7.1.1.3.2.3.8" xref="S5.SS1.p5.7.m7.1.1.3.2.3.8.cmml">
            l
           </mi>
          </mrow>
         </msub>
         <mo id="S5.SS1.p5.7.m7.1.1.3.1" xref="S5.SS1.p5.7.m7.1.1.3.1.cmml">
          /
         </mo>
         <mi id="S5.SS1.p5.7.m7.1.1.3.3" xref="S5.SS1.p5.7.m7.1.1.3.3.cmml">
          N
         </mi>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.7.m7.1b">
        <apply id="S5.SS1.p5.7.m7.1.1.cmml" xref="S5.SS1.p5.7.m7.1.1">
         <eq id="S5.SS1.p5.7.m7.1.1.1.cmml" xref="S5.SS1.p5.7.m7.1.1.1">
         </eq>
         <ci id="S5.SS1.p5.7.m7.1.1.2a.cmml" xref="S5.SS1.p5.7.m7.1.1.2">
          <mtext class="ltx_mathvariant_bold" id="S5.SS1.p5.7.m7.1.1.2.cmml" xref="S5.SS1.p5.7.m7.1.1.2">
           Optimal Rate (OR)
          </mtext>
         </ci>
         <apply id="S5.SS1.p5.7.m7.1.1.3.cmml" xref="S5.SS1.p5.7.m7.1.1.3">
          <divide id="S5.SS1.p5.7.m7.1.1.3.1.cmml" xref="S5.SS1.p5.7.m7.1.1.3.1">
          </divide>
          <apply id="S5.SS1.p5.7.m7.1.1.3.2.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2">
           <csymbol cd="ambiguous" id="S5.SS1.p5.7.m7.1.1.3.2.1.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2">
            subscript
           </csymbol>
           <ci id="S5.SS1.p5.7.m7.1.1.3.2.2.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.2">
            𝑁
           </ci>
           <apply id="S5.SS1.p5.7.m7.1.1.3.2.3.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3">
            <times id="S5.SS1.p5.7.m7.1.1.3.2.3.1.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.1">
            </times>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.2.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.2">
             𝑜
            </ci>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.3.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.3">
             𝑝
            </ci>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.4.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.4">
             𝑡
            </ci>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.5.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.5">
             𝑖
            </ci>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.6.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.6">
             𝑚
            </ci>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.7.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.7">
             𝑎
            </ci>
            <ci id="S5.SS1.p5.7.m7.1.1.3.2.3.8.cmml" xref="S5.SS1.p5.7.m7.1.1.3.2.3.8">
             𝑙
            </ci>
           </apply>
          </apply>
          <ci id="S5.SS1.p5.7.m7.1.1.3.3.cmml" xref="S5.SS1.p5.7.m7.1.1.3.3">
           𝑁
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.7.m7.1c">
        \textbf{Optimal Rate (OR)}={N_{optimal}}/{N}
       </annotation>
      </semantics>
     </math>
     measures the percentage of paths generated by LLMs being the optimal paths. The higher the better.
     <math alttext="\textbf{Feasible Rate (FR)}={N_{feasible}}/{N}" class="ltx_Math" display="inline" id="S5.SS1.p5.8.m8.1">
      <semantics id="S5.SS1.p5.8.m8.1a">
       <mrow id="S5.SS1.p5.8.m8.1.1" xref="S5.SS1.p5.8.m8.1.1.cmml">
        <mtext class="ltx_mathvariant_bold" id="S5.SS1.p5.8.m8.1.1.2" xref="S5.SS1.p5.8.m8.1.1.2a.cmml">
         Feasible Rate (FR)
        </mtext>
        <mo id="S5.SS1.p5.8.m8.1.1.1" xref="S5.SS1.p5.8.m8.1.1.1.cmml">
         =
        </mo>
        <mrow id="S5.SS1.p5.8.m8.1.1.3" xref="S5.SS1.p5.8.m8.1.1.3.cmml">
         <msub id="S5.SS1.p5.8.m8.1.1.3.2" xref="S5.SS1.p5.8.m8.1.1.3.2.cmml">
          <mi id="S5.SS1.p5.8.m8.1.1.3.2.2" xref="S5.SS1.p5.8.m8.1.1.3.2.2.cmml">
           N
          </mi>
          <mrow id="S5.SS1.p5.8.m8.1.1.3.2.3" xref="S5.SS1.p5.8.m8.1.1.3.2.3.cmml">
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.2" xref="S5.SS1.p5.8.m8.1.1.3.2.3.2.cmml">
            f
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.3" xref="S5.SS1.p5.8.m8.1.1.3.2.3.3.cmml">
            e
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1a" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.4" xref="S5.SS1.p5.8.m8.1.1.3.2.3.4.cmml">
            a
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1b" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.5" xref="S5.SS1.p5.8.m8.1.1.3.2.3.5.cmml">
            s
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1c" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.6" xref="S5.SS1.p5.8.m8.1.1.3.2.3.6.cmml">
            i
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1d" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.7" xref="S5.SS1.p5.8.m8.1.1.3.2.3.7.cmml">
            b
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1e" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.8" xref="S5.SS1.p5.8.m8.1.1.3.2.3.8.cmml">
            l
           </mi>
           <mo id="S5.SS1.p5.8.m8.1.1.3.2.3.1f" lspace="0em" rspace="0em" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml">
            ​
           </mo>
           <mi id="S5.SS1.p5.8.m8.1.1.3.2.3.9" xref="S5.SS1.p5.8.m8.1.1.3.2.3.9.cmml">
            e
           </mi>
          </mrow>
         </msub>
         <mo id="S5.SS1.p5.8.m8.1.1.3.1" xref="S5.SS1.p5.8.m8.1.1.3.1.cmml">
          /
         </mo>
         <mi id="S5.SS1.p5.8.m8.1.1.3.3" xref="S5.SS1.p5.8.m8.1.1.3.3.cmml">
          N
         </mi>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.8.m8.1b">
        <apply id="S5.SS1.p5.8.m8.1.1.cmml" xref="S5.SS1.p5.8.m8.1.1">
         <eq id="S5.SS1.p5.8.m8.1.1.1.cmml" xref="S5.SS1.p5.8.m8.1.1.1">
         </eq>
         <ci id="S5.SS1.p5.8.m8.1.1.2a.cmml" xref="S5.SS1.p5.8.m8.1.1.2">
          <mtext class="ltx_mathvariant_bold" id="S5.SS1.p5.8.m8.1.1.2.cmml" xref="S5.SS1.p5.8.m8.1.1.2">
           Feasible Rate (FR)
          </mtext>
         </ci>
         <apply id="S5.SS1.p5.8.m8.1.1.3.cmml" xref="S5.SS1.p5.8.m8.1.1.3">
          <divide id="S5.SS1.p5.8.m8.1.1.3.1.cmml" xref="S5.SS1.p5.8.m8.1.1.3.1">
          </divide>
          <apply id="S5.SS1.p5.8.m8.1.1.3.2.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2">
           <csymbol cd="ambiguous" id="S5.SS1.p5.8.m8.1.1.3.2.1.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2">
            subscript
           </csymbol>
           <ci id="S5.SS1.p5.8.m8.1.1.3.2.2.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.2">
            𝑁
           </ci>
           <apply id="S5.SS1.p5.8.m8.1.1.3.2.3.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3">
            <times id="S5.SS1.p5.8.m8.1.1.3.2.3.1.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.1">
            </times>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.2.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.2">
             𝑓
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.3.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.3">
             𝑒
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.4.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.4">
             𝑎
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.5.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.5">
             𝑠
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.6.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.6">
             𝑖
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.7.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.7">
             𝑏
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.8.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.8">
             𝑙
            </ci>
            <ci id="S5.SS1.p5.8.m8.1.1.3.2.3.9.cmml" xref="S5.SS1.p5.8.m8.1.1.3.2.3.9">
             𝑒
            </ci>
           </apply>
          </apply>
          <ci id="S5.SS1.p5.8.m8.1.1.3.3.cmml" xref="S5.SS1.p5.8.m8.1.1.3.3">
           𝑁
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.8.m8.1c">
        \textbf{Feasible Rate (FR)}={N_{feasible}}/{N}
       </annotation>
      </semantics>
     </math>
     measures the percentage of paths generated by LLMs being the valid paths. The higher the better.
     <math alttext="\textbf{Over-Length Rate (OLR)}=\sum_{i=1}^{N_{feasible}}{(L_{i}-L_{i}^{*})}/{L_{i}^{*}}" class="ltx_Math" display="inline" id="S5.SS1.p5.9.m9.1">
      <semantics id="S5.SS1.p5.9.m9.1a">
       <mrow id="S5.SS1.p5.9.m9.1.1" xref="S5.SS1.p5.9.m9.1.1.cmml">
        <mtext class="ltx_mathvariant_bold" id="S5.SS1.p5.9.m9.1.1.3" xref="S5.SS1.p5.9.m9.1.1.3a.cmml">
         Over-Length Rate (OLR)
        </mtext>
        <mo id="S5.SS1.p5.9.m9.1.1.2" rspace="0.111em" xref="S5.SS1.p5.9.m9.1.1.2.cmml">
         =
        </mo>
        <mrow id="S5.SS1.p5.9.m9.1.1.1" xref="S5.SS1.p5.9.m9.1.1.1.cmml">
         <msubsup id="S5.SS1.p5.9.m9.1.1.1.2" xref="S5.SS1.p5.9.m9.1.1.1.2.cmml">
          <mo id="S5.SS1.p5.9.m9.1.1.1.2.2.2" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.2.2.cmml">
           ∑
          </mo>
          <mrow id="S5.SS1.p5.9.m9.1.1.1.2.2.3" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.cmml">
           <mi id="S5.SS1.p5.9.m9.1.1.1.2.2.3.2" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.2.cmml">
            i
           </mi>
           <mo id="S5.SS1.p5.9.m9.1.1.1.2.2.3.1" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.1.cmml">
            =
           </mo>
           <mn id="S5.SS1.p5.9.m9.1.1.1.2.2.3.3" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.3.cmml">
            1
           </mn>
          </mrow>
          <msub id="S5.SS1.p5.9.m9.1.1.1.2.3" xref="S5.SS1.p5.9.m9.1.1.1.2.3.cmml">
           <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.2" xref="S5.SS1.p5.9.m9.1.1.1.2.3.2.cmml">
            N
           </mi>
           <mrow id="S5.SS1.p5.9.m9.1.1.1.2.3.3" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.cmml">
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.2" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.2.cmml">
             f
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.3" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.3.cmml">
             e
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1a" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.4" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.4.cmml">
             a
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1b" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.5" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.5.cmml">
             s
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1c" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.6" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.6.cmml">
             i
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1d" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.7" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.7.cmml">
             b
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1e" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.8" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.8.cmml">
             l
            </mi>
            <mo id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1f" lspace="0em" rspace="0em" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml">
             ​
            </mo>
            <mi id="S5.SS1.p5.9.m9.1.1.1.2.3.3.9" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.9.cmml">
             e
            </mi>
           </mrow>
          </msub>
         </msubsup>
         <mrow id="S5.SS1.p5.9.m9.1.1.1.1" xref="S5.SS1.p5.9.m9.1.1.1.1.cmml">
          <mrow id="S5.SS1.p5.9.m9.1.1.1.1.1.1" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.cmml">
           <mo id="S5.SS1.p5.9.m9.1.1.1.1.1.1.2" stretchy="false" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.cmml">
            (
           </mo>
           <mrow id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.cmml">
            <msub id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.cmml">
             <mi id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.2" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.2.cmml">
              L
             </mi>
             <mi id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.3" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.3.cmml">
              i
             </mi>
            </msub>
            <mo id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.1" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.1.cmml">
             −
            </mo>
            <msubsup id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.cmml">
             <mi id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.2" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.2.cmml">
              L
             </mi>
             <mi id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.3" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.3.cmml">
              i
             </mi>
             <mo id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.3" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.3.cmml">
              ∗
             </mo>
            </msubsup>
           </mrow>
           <mo id="S5.SS1.p5.9.m9.1.1.1.1.1.1.3" stretchy="false" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.cmml">
            )
           </mo>
          </mrow>
          <mo id="S5.SS1.p5.9.m9.1.1.1.1.2" xref="S5.SS1.p5.9.m9.1.1.1.1.2.cmml">
           /
          </mo>
          <msubsup id="S5.SS1.p5.9.m9.1.1.1.1.3" xref="S5.SS1.p5.9.m9.1.1.1.1.3.cmml">
           <mi id="S5.SS1.p5.9.m9.1.1.1.1.3.2.2" xref="S5.SS1.p5.9.m9.1.1.1.1.3.2.2.cmml">
            L
           </mi>
           <mi id="S5.SS1.p5.9.m9.1.1.1.1.3.2.3" xref="S5.SS1.p5.9.m9.1.1.1.1.3.2.3.cmml">
            i
           </mi>
           <mo id="S5.SS1.p5.9.m9.1.1.1.1.3.3" xref="S5.SS1.p5.9.m9.1.1.1.1.3.3.cmml">
            ∗
           </mo>
          </msubsup>
         </mrow>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p5.9.m9.1b">
        <apply id="S5.SS1.p5.9.m9.1.1.cmml" xref="S5.SS1.p5.9.m9.1.1">
         <eq id="S5.SS1.p5.9.m9.1.1.2.cmml" xref="S5.SS1.p5.9.m9.1.1.2">
         </eq>
         <ci id="S5.SS1.p5.9.m9.1.1.3a.cmml" xref="S5.SS1.p5.9.m9.1.1.3">
          <mtext class="ltx_mathvariant_bold" id="S5.SS1.p5.9.m9.1.1.3.cmml" xref="S5.SS1.p5.9.m9.1.1.3">
           Over-Length Rate (OLR)
          </mtext>
         </ci>
         <apply id="S5.SS1.p5.9.m9.1.1.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1">
          <apply id="S5.SS1.p5.9.m9.1.1.1.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2">
           <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.2.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2">
            superscript
           </csymbol>
           <apply id="S5.SS1.p5.9.m9.1.1.1.2.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2">
            <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.2.2.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2">
             subscript
            </csymbol>
            <sum id="S5.SS1.p5.9.m9.1.1.1.2.2.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.2.2">
            </sum>
            <apply id="S5.SS1.p5.9.m9.1.1.1.2.2.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3">
             <eq id="S5.SS1.p5.9.m9.1.1.1.2.2.3.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.1">
             </eq>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.2.3.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.2">
              𝑖
             </ci>
             <cn id="S5.SS1.p5.9.m9.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.SS1.p5.9.m9.1.1.1.2.2.3.3">
              1
             </cn>
            </apply>
           </apply>
           <apply id="S5.SS1.p5.9.m9.1.1.1.2.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3">
            <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.2.3.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3">
             subscript
            </csymbol>
            <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.2">
             𝑁
            </ci>
            <apply id="S5.SS1.p5.9.m9.1.1.1.2.3.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3">
             <times id="S5.SS1.p5.9.m9.1.1.1.2.3.3.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.1">
             </times>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.2">
              𝑓
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.3">
              𝑒
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.4.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.4">
              𝑎
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.5.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.5">
              𝑠
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.6.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.6">
              𝑖
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.7.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.7">
              𝑏
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.8.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.8">
              𝑙
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.2.3.3.9.cmml" xref="S5.SS1.p5.9.m9.1.1.1.2.3.3.9">
              𝑒
             </ci>
            </apply>
           </apply>
          </apply>
          <apply id="S5.SS1.p5.9.m9.1.1.1.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1">
           <divide id="S5.SS1.p5.9.m9.1.1.1.1.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.2">
           </divide>
           <apply id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1">
            <minus id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.1">
            </minus>
            <apply id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2">
             <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2">
              subscript
             </csymbol>
             <ci id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.2">
              𝐿
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.2.3">
              𝑖
             </ci>
            </apply>
            <apply id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3">
             <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3">
              superscript
             </csymbol>
             <apply id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3">
              <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3">
               subscript
              </csymbol>
              <ci id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.2">
               𝐿
              </ci>
              <ci id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.2.3">
               𝑖
              </ci>
             </apply>
             <times id="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.1.1.1.3.3">
             </times>
            </apply>
           </apply>
           <apply id="S5.SS1.p5.9.m9.1.1.1.1.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3">
            <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.1.3.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3">
             superscript
            </csymbol>
            <apply id="S5.SS1.p5.9.m9.1.1.1.1.3.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3">
             <csymbol cd="ambiguous" id="S5.SS1.p5.9.m9.1.1.1.1.3.2.1.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3">
              subscript
             </csymbol>
             <ci id="S5.SS1.p5.9.m9.1.1.1.1.3.2.2.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3.2.2">
              𝐿
             </ci>
             <ci id="S5.SS1.p5.9.m9.1.1.1.1.3.2.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3.2.3">
              𝑖
             </ci>
            </apply>
            <times id="S5.SS1.p5.9.m9.1.1.1.1.3.3.cmml" xref="S5.SS1.p5.9.m9.1.1.1.1.3.3">
            </times>
           </apply>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p5.9.m9.1c">
        \textbf{Over-Length Rate (OLR)}=\sum_{i=1}^{N_{feasible}}{(L_{i}-L_{i}^{*})}/{L_{i}^{*}}
       </annotation>
      </semantics>
     </math>
     measures the over-length of valid paths generated by LLMs over the optimal ones. The lower the better. These metrics take the following forms.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p6">
    <p class="ltx_p" id="S5.SS1.p6.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p6.1.1">
      Results
     </span>
     .
The quantitative results of TP and the baselines are shown in Table
     <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ 4 Methodology ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . TP achieves a significant performance gain over the baselines by generating the most optimal and valid shortest paths when testing on three LLM backends with different model capacities. Moreover, the valid paths generated by TP are the closest to the optimal paths when compared with the baselines due to the lowest Over-Length Rate (OLR). On the PaLM-2 backend, ToT fails to find valid paths from source nodes to target nodes. For GPT-3.5 and GPT-4 backends, ToT underperforms IO prompting. We find ToT sometimes searches backward or even fails to find the valid path due to the accumulated error shown in Figure
     <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4 Methodology ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . CoT only outperforms IO on PaLM-2 where IO performs badly. Nevertheless, we observe no significant preference gain of CoT over IO on the other LLM backends.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p7">
    <p class="ltx_p" id="S5.SS1.p7.1">
     Although the 1-shot setting leads to performance gains over 0-shot on most prompting methods, the performance gains of 5-shot over 1-shot setting are unexpectedly marginal, or sometimes worse than 1-shot setting. There are two reasons for this phenomenon. Firstly, the 5-shot setting feeds long prompting exemplars to LLM, which potentially contains more redundant information.
Secondly, the 5-shot setting sometimes leads to output cutoff due to the maximal token limit of LLMs. We leave the in-depth exploration of this phenomenon in our future work.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p8">
    <p class="ltx_p" id="S5.SS1.p8.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p8.1.1">
      Impact of Layers on Performance
     </span>
     . We further study the influence of layer numbers of TP on the complexity and performance in the Shortest-path Task.
As shown in Figure
     <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.1 Shortest-path Reasoning ‣ 5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     , 1-layer TP has similar token costs as ToT in different settings. However, 1-layer TP already achieves very competitive performance in finding the optimal shortest path. Also, the performance gain of 1-layer TP over 0-layer TP (IO) is significant. Although 2-layer TP achieves the best performance as shown in Table
     <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ 4 Methodology ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     , the performance gain of 2-layer TP over 1-layer TP is less significant. And Figure
     <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.1 Shortest-path Reasoning ‣ 5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     (a). indicates the increase in the token cost of TP with 2 layers. Thus we aim to harness multi-hop analogous problems with decreased expenses in our future work. More results are shown in Appendix.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Creative Writing
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     We proceed to evaluate Thought Propagation on the Creative Writing task
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib53" title="">
       2023
      </a>
      )
     </cite>
     . Given 4 randomly sampled sentences, the goal of this task is to generate 4 paragraphs ending with these sentences respectively to construct a coherent message. Such task challenges LLM reasoning by highly creative thinking and planning.
    </p>
   </div>
   <figure class="ltx_table" id="S5.T2">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     The performance of Thought Propagation (TP) and baselines on Creative Writing Task.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T2.8">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T2.8.9.1">
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.8.9.1.1">
        Metric
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S5.T2.8.9.1.2">
        Coherent Score
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T2.8.9.1.3">
        User Study
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.8.10.2">
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.10.2.1">
        LLM-Backend
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.10.2.2">
        GPT-3.5
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.10.2.3">
        GPT-4
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.8.10.2.4">
        GPT-3.5
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.8.10.2.5">
        GPT-4
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.2.2">
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.2.2.3">
        IO
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.1">
        6.087
        <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1">
         <semantics id="S5.T2.1.1.1.m1.1a">
          <mo id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b">
           <csymbol cd="latexml" id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">
           \pm
          </annotation>
         </semantics>
        </math>
        2.229
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.2.2.2">
        6.193
        <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.2.2.2.m1.1">
         <semantics id="S5.T2.2.2.2.m1.1a">
          <mo id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b">
           <csymbol cd="latexml" id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">
           \pm
          </annotation>
         </semantics>
        </math>
        1.953
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.2.2.4">
        14%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.2.2.5">
        7%
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.4">
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.4.4.3">
        CoT
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.3.3.1">
        6.654
        <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.3.3.1.m1.1">
         <semantics id="S5.T2.3.3.1.m1.1a">
          <mo id="S5.T2.3.3.1.m1.1.1" xref="S5.T2.3.3.1.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="S5.T2.3.3.1.m1.1b">
           <csymbol cd="latexml" id="S5.T2.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.1.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.3.3.1.m1.1c">
           \pm
          </annotation>
         </semantics>
        </math>
        2.201
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.4.4.2">
        6.927
        <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.4.4.2.m1.1">
         <semantics id="S5.T2.4.4.2.m1.1a">
          <mo id="S5.T2.4.4.2.m1.1.1" xref="S5.T2.4.4.2.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="S5.T2.4.4.2.m1.1b">
           <csymbol cd="latexml" id="S5.T2.4.4.2.m1.1.1.cmml" xref="S5.T2.4.4.2.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.4.4.2.m1.1c">
           \pm
          </annotation>
         </semantics>
        </math>
        1.508
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.4.4.4">
        21%
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.4.5">
        15%
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.6.6">
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.6.6.3">
        ToT
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.5.5.1">
        6.856
        <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.5.5.1.m1.1">
         <semantics id="S5.T2.5.5.1.m1.1a">
          <mo id="S5.T2.5.5.1.m1.1.1" xref="S5.T2.5.5.1.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.m1.1b">
           <csymbol cd="latexml" id="S5.T2.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.5.5.1.m1.1c">
           \pm
          </annotation>
         </semantics>
        </math>
        1.975
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.6.6.2">
        7.684
        <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.6.6.2.m1.1">
         <semantics id="S5.T2.6.6.2.m1.1a">
          <mo id="S5.T2.6.6.2.m1.1.1" xref="S5.T2.6.6.2.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="S5.T2.6.6.2.m1.1b">
           <csymbol cd="latexml" id="S5.T2.6.6.2.m1.1.1.cmml" xref="S5.T2.6.6.2.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.6.6.2.m1.1c">
           \pm
          </annotation>
         </semantics>
        </math>
        1.141
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.6.6.4">
        26%
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.6.6.5">
        33%
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.8.8">
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.8.8.3">
        <span class="ltx_text ltx_font_bold" id="S5.T2.8.8.3.1">
         TP
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.7.7.1">
        <span class="ltx_text ltx_font_bold" id="S5.T2.7.7.1.1">
         7.000
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.7.7.1.1.m1.1">
          <semantics id="S5.T2.7.7.1.1.m1.1a">
           <mo id="S5.T2.7.7.1.1.m1.1.1" xref="S5.T2.7.7.1.1.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T2.7.7.1.1.m1.1b">
            <csymbol cd="latexml" id="S5.T2.7.7.1.1.m1.1.1.cmml" xref="S5.T2.7.7.1.1.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T2.7.7.1.1.m1.1c">
            \pm
           </annotation>
          </semantics>
         </math>
         1.783
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.8.8.2">
        <span class="ltx_text ltx_font_bold" id="S5.T2.8.8.2.1">
         7.989
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.8.8.2.1.m1.1">
          <semantics id="S5.T2.8.8.2.1.m1.1a">
           <mo id="S5.T2.8.8.2.1.m1.1.1" xref="S5.T2.8.8.2.1.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T2.8.8.2.1.m1.1b">
            <csymbol cd="latexml" id="S5.T2.8.8.2.1.m1.1.1.cmml" xref="S5.T2.8.8.2.1.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T2.8.8.2.1.m1.1c">
            \pm
           </annotation>
          </semantics>
         </math>
         1.453
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.8.8.4">
        <span class="ltx_text ltx_font_bold" id="S5.T2.8.8.4.1">
         39%
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.8.8.5">
        <span class="ltx_text ltx_font_bold" id="S5.T2.8.8.5.1">
         45%
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p2">
    <p class="ltx_p" id="S5.SS2.p2.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">
      Task Setup
     </span>
     .
We follow the task setup proposed by Yao et. al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib53" title="">
       2023
      </a>
      )
     </cite>
     that consists of 100 test instances. We use the coherent score (1-10 scalar score generated by GPT-4) and user study to
evaluate the coherence of generated messages. The details of the evaluation are in Appendix.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p3">
    <p class="ltx_p" id="S5.SS2.p3.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">
      Baselines and LLM Backends
     </span>
     .
We consider three baselines: IO prompting
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brown et al.,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2020
      </a>
      )
     </cite>
     , CoT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib50" title="">
       2022
      </a>
      )
     </cite>
     and ToT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib53" title="">
       2023
      </a>
      )
     </cite>
     . All these methods use zero-shot prompts due to the creative nature of writing
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib53" title="">
       2023
      </a>
      )
     </cite>
     . The baseline setup and prompting exemplars are shown in Appendix. We instantiate each method using GPT-3.5 and GPT-4 backends.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p4">
    <p class="ltx_p" id="S5.SS2.p4.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">
      Thought Propagation Setup
     </span>
     .
We build Thought Propagation with one layer for this task to maintain a fair comparison with the baselines. Every module of Thought Propagation is implemented with zero-shot prompts.
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.2">
      LLM Propose
     </span>
     rephrases the four input sentences using the simple prompt: ”Rephrase the input sentences but do not change their meanings or orders.”, and produces the analogical problem which is to generate a writing plan to write a message with the rephrased sentences.
This module generates 5 analogous problems to ensure a fair comparison with baselines.
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.3">
      LLM Solve
     </span>
     uses CoT prompting to generate writing plans to write four paragraphs that end with four given sentences. This module is employed to solve the input and proposed analogous problems, leading to 6 plans.
Since the rephrased sentences share similar contextual information with the input sentences, their writing plans potentially apply to the input ones.
Thus
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.4">
      LLM Aggregate
     </span>
     evaluates all 6 plans output by
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.5">
      LLM Solve
     </span>
     and outputs the most promising plan for the input problem.
Finally, the LLM is asked to write the whole message in four paragraphs using the most promising plan. The prompting exemplars of TP in the Creative Writing task are shown in Appendix.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p5">
    <p class="ltx_p" id="S5.SS2.p5.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p5.1.1">
      Results
     </span>
     . Table
     <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Creative Writing ‣ 5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     shows the performance of TP and baselines with GPT-3.5 and GPT-4. Thought Propagation outperforms the baselines with the highest coherent scores on both GPT-3.5 and GPT-4 backends. Moreover, TP achieves the highest human preference in user study. Additional findings are all the methods achieve better performance on GPT-4 due to the improved model capability.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    LLM-Agent Planning
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     LLM-Agents use LLMs as the core component to interact with environments and autonomously make plans and decisions. We study the capability of TP to formulate high-level, knowledge-intensive plans for LLM-Agents in an analogical way to improve the task completion rate.
    </p>
   </div>
   <figure class="ltx_table" id="S5.T3">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     The performance of different variant models of Thought Propagation (TP) and baselines on LLM-Agent planning in the ALFWORLD dataset
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shridhar et al.,
      <a class="ltx_ref" href="#bib.bib42" title="">
       2021
      </a>
      )
     </cite>
     . We reproduce the result of Reflexion
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     . Other baseline results are quoted from ReACT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib52" title="">
       2022
      </a>
      )
     </cite>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T3.1.1.1">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1">
        Method
       </th>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.2">
        Pick
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.3">
        Clean
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.4">
        Heat
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.5">
        Cool
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.6">
        Look
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.7">
        Pick 2
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.8">
        All
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.2.2">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.1.2.2.1">
        BULTER
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.2">
        33
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.3">
        26
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.4">
        70
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.5">
        76
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.6">
        17
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.7">
        12
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2.8">
        22
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.3.3">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.3.3.1">
        BULTER_G
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.2">
        46
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.3">
        39
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.4">
        74
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.5">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.3.3.5.1">
         100
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.6">
        22
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.7">
        24
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.3.8">
        37
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.4.4">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.4.4.1">
        Act (best of 6)
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.2">
        88
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.3">
        42
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.4">
        74
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.5">
        67
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.6">
        72
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.7">
        41
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.4.8">
        45
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.5.5">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.5.5.1">
        ReAct (avg)
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.2">
        65
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.3">
        39
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.4">
        83
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.5">
        76
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.6">
        55
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.7">
        24
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.5.5.8">
        57
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.6.6">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.6.6.1">
        ReAct (best of 6)
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.2">
        92
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.3">
        58
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.4">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.6.6.4.1">
         96
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.5">
        86
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.6">
        78
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.7">
        41
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.6.6.8">
        71
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.7.7">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.7.7.1">
        Reflexion
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.2">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.7.7.2.1">
         100.00
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.3">
        74.19
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.4">
        73.91
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.5">
        85.71
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.6">
        66.67
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.7">
        70.59
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.7.7.8">
        79.1
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.8.8">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.1.8.8.1">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.8.8.1.1">
         TP-SR-SE
        </span>
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.2">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.8.8.2.1">
         100.00
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.3">
        77.42
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.4">
        65.22
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.5">
        95.24
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.6">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.8.8.6.1">
         94.44
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.7">
        82.35
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.8.8.8">
        85.82
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.9.9">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.9.9.1">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.9.9.1.1">
         TP-SE
        </span>
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.2">
        91.67
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.3">
        83.87
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.4">
        69.56
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.5">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.9.9.5.1">
         100.00
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.6">
        83.3
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.7">
        70.59
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.9.9.8">
        83.68
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.10.10">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T3.1.10.10.1">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.10.10.1.1">
         TP-SR-SM
        </span>
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.2">
        95.83
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.3">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.10.10.3.1">
         96.77
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.4">
        78.26
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.5">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.10.10.5.1">
         100.00
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.6">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.10.10.6.1">
         94.44
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.7">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.10.10.7.1">
         88.24
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T3.1.10.10.8">
        92.54
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.11.11">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T3.1.11.11.1">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.11.11.1.1">
         TP-SM
        </span>
       </th>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.2">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.11.11.2.1">
         100.00
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.3">
        93.55
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.4">
        86.96
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.5">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.11.11.5.1">
         100.00
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.6">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.11.11.6.1">
         94.44
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.7">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.11.11.7.1">
         88.24
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.11.11.8">
        <span class="ltx_text ltx_font_bold" id="S5.T3.1.11.11.8.1">
         94.78
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p2">
    <p class="ltx_p" id="S5.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">
      Task Setup
     </span>
     . ALFWorld
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shridhar et al.,
      <a class="ltx_ref" href="#bib.bib42" title="">
       2021
      </a>
      )
     </cite>
     is a text-based game suite with various interactive housework environments aligned with ALFRED and TextWorld
     <cite class="ltx_cite ltx_citemacro_citep">
      (Côté et al.,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2019
      </a>
      ; Shridhar et al.,
      <a class="ltx_ref" href="#bib.bib41" title="">
       2020
      </a>
      )
     </cite>
     . It contains six types of tasks with 134 unseen environments for evaluation
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib52" title="">
       2022
      </a>
      ; Shinn et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p3">
    <p class="ltx_p" id="S5.SS3.p3.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p3.1.1">
      Baselines and LLM Backends
     </span>
     . BULTER is a trainable parameterized method based on reinforcement learning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shridhar et al.,
      <a class="ltx_ref" href="#bib.bib42" title="">
       2021
      </a>
      )
     </cite>
     . ReAct
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib52" title="">
       2022
      </a>
      )
     </cite>
     builds LLM-Agents with synergy between reasoning traces and action trials. Act
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib52" title="">
       2022
      </a>
      )
     </cite>
     removes the reasoning trace of ReAct. Reflexion improves ReAct with verbal reflections on previous failures in the same task to refine the planning of new trials
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     . We run Reflexion for 6 trials since its performance is stable after 4 trials. We use GPT-3 for LLM-Agents following Shinn et. al.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p4">
    <p class="ltx_p" id="S5.SS3.p4.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.1">
      Thought Propagation Setup
     </span>
     .
Unlike Reflexion which reflects upon previous failure in the
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.2">
      same task
     </span>
     to help task completion in the next planning trial, Thought Propagation aims to aggregate useful information from successful trials in
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.3">
      similar but different tasks
     </span>
     to improve task completion.
    </p>
   </div>
   <figure class="ltx_figure ltx_align_floatright" id="S5.F6">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="102" id="S5.F6.1.g1" src="/html/2310.03965/assets/x6.png" width="169"/>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 6:
     </span>
     The success rate of task completion in different trials.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p5">
    <p class="ltx_p" id="S5.SS3.p5.1">
     Thus,
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p5.1.1">
      LLM Propose
     </span>
     uses a zero-shot prompt to assess the similarity score between the original task and the rest with successful planning trials. The rest tasks with the top two
similarity scores are treated as two analogical problems.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p6">
    <p class="ltx_p" id="S5.SS3.p6.1">
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p6.1.1">
      LLM Solve
     </span>
     employs ReAct to instantiate LLM-Agent planning in the original task following Reflexion
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     .
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p6.1.2">
      LLM Aggregate
     </span>
     uses a zero-shot prompt to formulate two plans to help complete the original problem based on the successful trials of analogical problems and the planning trial of the original problem.
Then, it evaluates the two plans and outputs the better one to guide the LLM-Agent to complete the task. We run Thought Propagation for 6 trials to maintain consistency with Reflexion. The prompt exemplars are shown in Appendix.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p7">
    <p class="ltx_p" id="S5.SS3.p7.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p7.1.1">
      Variant Models
     </span>
     . We introduce two strategies for
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p7.1.2">
      LLM Aggregate
     </span>
     for plan evaluation: 1. Self-Evaluation (SE): The LLM evaluates two plans by zero-shot prompt and outputs the better one; 2. Simulation (SM): The LLM-Agent executes new planning trials in the task environment using two plans and outputs a better one. We additionally add Self-Reflection (SR) modules to reflect LLM-Agent on its own failures just like Reflexion. These implementations lead to four variant models of Thought Propagation: 1). TP-SR-SE: Thought Propagation with Self-Reflection and Self-Evaluation; 2). TP-SE: Thought Propagation with Self-Evaluation; 3). TP-SR-SM: Thought Propagation with Self-Reflection and Simulation; 4). TP-SM: Thought Propagation with Simulation.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p8">
    <p class="ltx_p" id="S5.SS3.p8.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p8.1.1">
      Results
     </span>
     . Table
     <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.3 LLM-Agent Planning ‣ 5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     shows good performance of Thought Propagation over the learnable parameterized method and other LLM-Agent baselines. Thought Propagation achieves large performance gains even without a memory module to store its previous failures (TP-SE/TP-SM). This shows the superiority of the reflection upon successful planning in completing similar tasks. Moreover, Thought Propagation also works well with the additional memory module to store previous failures (TP-SR-SE/TP-SR-SM). Figure
     <a class="ltx_ref" href="#S5.F6" title="Figure 6 ‣ 5.3 LLM-Agent Planning ‣ 5 Experiments ‣ Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     shows that different variant models of Thought Propagation achieve consistent performance improvement by iterative reflecting on successful planning in similar tasks.
We show how TP formulates a constructive plan from solving
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p8.1.2">
      ”examine the alarmclock with the desklamp”
     </span>
     task to successfully complete
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p8.1.3">
      ”examine the book with the desklamp”
     </span>
     task, where ReAct and Reflexion are trapped in a loop, in Appendix.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusions
  </h2>
  <div class="ltx_para ltx_noindent" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    Existing prompting approaches for LLM reasoning cannot leverage the insights of solving similar problems and suffer from accumulated errors in multi-step reasoning, due to reasoning from scratch.
To address these issues, we propose Thought Propagation (TP), which explores analogous problems to yield a refined solution or a knowledge-intensive plan in an analogical approach to facilitate new problem-solving.
TP is compatible with existing prompting methods, showing plug-and-play generalization and enhancement to a wide range of tasks such as Shortest-path Planning, Creative Writing, and LLM-Agent Planning.
Future directions would further enhance the performance and efficiency of the proposed framework.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Anil et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al.
    </span>
    <span class="ltx_bibblock">
     Palm 2 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2305.10403
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Asai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen.
    </span>
    <span class="ltx_bibblock">
     Retrieval-based language models and applications.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 6: Tutorial Abstracts)
     </em>
     , pp.  41–46, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bartha (2013)
    </span>
    <span class="ltx_bibblock">
     Paul Bartha.
    </span>
    <span class="ltx_bibblock">
     Analogy and analogical reasoning.
    </span>
    <span class="ltx_bibblock">
     2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Besta et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al.
    </span>
    <span class="ltx_bibblock">
     Graph of thoughts: Solving elaborate problems with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2308.09687
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bhavya et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Bhavya Bhavya, Jinjun Xiong, and Chengxiang Zhai.
    </span>
    <span class="ltx_bibblock">
     Analogy generation by prompting large language models: A case study of instructgpt.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2210.04186
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bhavya et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Bhavya Bhavya, Jinjun Xiong, and Chengxiang Zhai.
    </span>
    <span class="ltx_bibblock">
     Cam: A large language model-based creative analogy mining framework.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Proceedings of the ACM Web Conference 2023
     </em>
     , pp.  3903–3914, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Borgeaud et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al.
    </span>
    <span class="ltx_bibblock">
     Improving language models by retrieving from trillions of tokens.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      International conference on machine learning
     </em>
     , pp.  2206–2240. PMLR, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      Advances in neural information processing systems
     </em>
     , 33:1877–1901, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Large language models as tool makers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2305.17126
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Carbonell (1985)
    </span>
    <span class="ltx_bibblock">
     Jaime Guillermo Carbonell.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Derivational analogy: A theory of reconstructive problem solving and expertise acquisition
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Carnegie-Mellon University, Department of Computer Science, 1985.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu.
    </span>
    <span class="ltx_bibblock">
     Chateval: Towards better llm-based evaluators through multi-agent debate.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2308.07201
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jiangjie Chen, Rui Xu, Ziquan Fu, Wei Shi, Zhongqiao Li, Xinbo Zhang, Changzhi Sun, Lei Li, Yanghua Xiao, and Hao Zhou.
    </span>
    <span class="ltx_bibblock">
     E-kar: A benchmark for rationalizing natural language analogical reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      arXiv preprint arXiv:2203.08480
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Teaching large language models to self-debug.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2304.05128
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, et al.
    </span>
    <span class="ltx_bibblock">
     Exploring the potential of large language models (llms) in learning on graphs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      arXiv preprint arXiv:2307.03393
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Côté et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud Adada, et al.
    </span>
    <span class="ltx_bibblock">
     Textworld: A learning environment for text-based games.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      Computer Games: 7th Workshop, CGW 2018, Held in Conjunction with the 27th International Conference on Artificial Intelligence, IJCAI 2018, Stockholm, Sweden, July 13, 2018, Revised Selected Papers 7
     </em>
     , pp.  41–75. Springer, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dziri et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jian, Bill Yuchen Lin, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D Hwang, et al.
    </span>
    <span class="ltx_bibblock">
     Faith and fate: Limits of transformers on compositionality.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2305.18654
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gilmer et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl.
    </span>
    <span class="ltx_bibblock">
     Neural message passing for quantum chemistry.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      International conference on machine learning
     </em>
     , pp.  1263–1272. PMLR, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hall (1989)
    </span>
    <span class="ltx_bibblock">
     Rogers P Hall.
    </span>
    <span class="ltx_bibblock">
     Computational approaches to analogical reasoning: A comparative analysis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      Artificial intelligence
     </em>
     , 39(1):39–120, 1989.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hamilton et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Will Hamilton, Zhitao Ying, and Jure Leskovec.
    </span>
    <span class="ltx_bibblock">
     Inductive representation learning on large graphs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      Advances in neural information processing systems
     </em>
     , 30, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     He et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xiaoxin He, Xavier Bresson, Thomas Laurent, and Bryan Hooi.
    </span>
    <span class="ltx_bibblock">
     Explanations as features: Llm-based features for text-attributed graphs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2305.19523
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Izacard et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave.
    </span>
    <span class="ltx_bibblock">
     Few-shot learning with retrieval augmented language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2208.03299
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-Rong Wen.
    </span>
    <span class="ltx_bibblock">
     Structgpt: A general framework for large language model to reason over structured data.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      arXiv preprint arXiv:2305.09645
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Khot et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal.
    </span>
    <span class="ltx_bibblock">
     Decomposed prompting: A modular approach for solving complex tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:2210.02406
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kipf &amp; Welling (2017)
    </span>
    <span class="ltx_bibblock">
     Thomas N. Kipf and Max Welling.
    </span>
    <span class="ltx_bibblock">
     Semi-supervised classification with graph convolutional networks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      The International Conference on Representation Learning
     </em>
     , 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tian Lan, Deng Cai, Yan Wang, Heyan Huang, and Xian-Ling Mao.
    </span>
    <span class="ltx_bibblock">
     Copy is all you need.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      The Eleventh International Conference on Learning Representations
     </em>
     , 2023.
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=CROlOA9Nd8C" target="_blank" title="">
      https://openreview.net/forum?id=CROlOA9Nd8C
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for” mind” exploration of large scale language model society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:2303.17760
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Hao Liu, Carmelo Sferrazza, and Pieter Abbeel.
    </span>
    <span class="ltx_bibblock">
     Chain of hindsight aligns language models with feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2302.02676
     </em>
     , 3, 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, and Hannaneh Hajishirzi.
    </span>
    <span class="ltx_bibblock">
     Generated knowledge prompting for commonsense reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      arXiv preprint arXiv:2110.08387
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig.
    </span>
    <span class="ltx_bibblock">
     Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      ACM Computing Surveys
     </em>
     , 55(9):1–35, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, and Andrew M Dai.
    </span>
    <span class="ltx_bibblock">
     Mind’s eye: Grounded language model reasoning through simulation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      arXiv preprint arXiv:2210.05359
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Małkiński &amp; Mańdziuk (2022)
    </span>
    <span class="ltx_bibblock">
     Mikołaj Małkiński and Jacek Mańdziuk.
    </span>
    <span class="ltx_bibblock">
     Deep learning methods for abstract visual reasoning: A survey on raven’s progressive matrices.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:2201.12382
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mialon et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al.
    </span>
    <span class="ltx_bibblock">
     Augmented language models: a survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2302.07842
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2022)
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     https://platform.openai.com/docs/models/gpt-3-5.
    </span>
    <span class="ltx_bibblock">
     2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Priestley (1775)
    </span>
    <span class="ltx_bibblock">
     Joseph Priestley.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      “The” History and Present State of Electricity: With Original Experiments
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     C. Bathurst and T. Lowndes, in Fleet-Street, J. Rivington and J. Johnson, in …, 1775.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qian et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chen Qian, Huayi Tang, Zhirui Yang, Hong Liang, and Yong Liu.
    </span>
    <span class="ltx_bibblock">
     Can large language models empower molecular property prediction?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2307.07443
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qiao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen.
    </span>
    <span class="ltx_bibblock">
     Reasoning with language model prompting: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2212.09597
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schick et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    </span>
    <span class="ltx_bibblock">
     Toolformer: Language models can teach themselves to use tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2302.04761
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shi et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.
    </span>
    <span class="ltx_bibblock">
     Replug: Retrieval-augmented black-box language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2301.12652
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Beck Labash, and Ashwin Gopinath.
    </span>
    <span class="ltx_bibblock">
     Reflexion: an autonomous agent with dynamic memory and self-reflection.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2303.11366
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox.
    </span>
    <span class="ltx_bibblock">
     Alfred: A benchmark for interpreting grounded instructions for everyday tasks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      Proceedings of the IEEE/CVF conference on computer vision and pattern recognition
     </em>
     , pp.  10740–10749, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht.
    </span>
    <span class="ltx_bibblock">
     Alfworld: Aligning text and embodied environments for interactive learning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      International Conference on Learning Representations
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sultan &amp; Shahaf (2022)
    </span>
    <span class="ltx_bibblock">
     Oren Sultan and Dafna Shahaf.
    </span>
    <span class="ltx_bibblock">
     Life is a circus and we are the clowns: Automatically finding analogies between situations and processes.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2210.12197
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, and Yulia Tsvetkov.
    </span>
    <span class="ltx_bibblock">
     Can language models solve graph problems in natural language?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      arXiv preprint arXiv:2305.10037
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al.
    </span>
    <span class="ltx_bibblock">
     A survey on large language model based autonomous agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      arXiv preprint arXiv:2308.11432
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Self-consistency improves chain of thought reasoning in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      arXiv preprint arXiv:2203.11171
     </em>
     , 2022a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, and Qun Liu.
    </span>
    <span class="ltx_bibblock">
     Aligning large language models with human: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2307.12966
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Zichao Wang, Weili Nie, Zhuoran Qiao, Chaowei Xiao, Richard Baraniuk, and Anima Anandkumar.
    </span>
    <span class="ltx_bibblock">
     Retrieval-based controllable molecule generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      arXiv preprint arXiv:2208.11126
     </em>
     , 2022b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Webb et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Taylor Webb, Keith J Holyoak, and Hongjing Lu.
    </span>
    <span class="ltx_bibblock">
     Emergent analogical reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      Nature Human Behaviour
     </em>
     , pp.  1–16, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:24824–24837, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang.
    </span>
    <span class="ltx_bibblock">
     Autogen: Enabling next-gen llm applications via multi-agent conversation framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2308.08155
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      arXiv preprint arXiv:2210.03629
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      arXiv preprint arXiv:2305.10601
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yasunaga et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Richard James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented multimodal language modeling.
    </span>
    <span class="ltx_bibblock">
     2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yuan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Siyu Yuan, Jiangjie Chen, Changzhi Sun, Jiaqing Liang, Yanghua Xiao, and Deqing Yang.
    </span>
    <span class="ltx_bibblock">
     Analogykb: Unlocking analogical reasoning of language models with a million-scale knowledge base.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">
      arXiv preprint arXiv:2305.05994
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Ningyu Zhang, Lei Li, Xiang Chen, Xiaozhuan Liang, Shumin Deng, and Huajun Chen.
    </span>
    <span class="ltx_bibblock">
     Multimodal analogical reasoning over knowledge graphs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">
      arXiv preprint arXiv:2210.00312
     </em>
     , 2022a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola.
    </span>
    <span class="ltx_bibblock">
     Automatic chain of thought prompting in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">
      arXiv preprint arXiv:2210.03493
     </em>
     , 2022b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
    </span>
    <span class="ltx_bibblock">
     A survey of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">
      arXiv preprint arXiv:2303.18223
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al.
    </span>
    <span class="ltx_bibblock">
     Least-to-most prompting enables complex reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">
      arXiv preprint arXiv:2205.10625
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al.
    </span>
    <span class="ltx_bibblock">
     Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">
      arXiv preprint arXiv:2305.17144
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen.
    </span>
    <span class="ltx_bibblock">
     Large language models for information retrieval: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      arXiv preprint arXiv:2308.07107
     </em>
     , 2023b.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
