<!DOCTYPE html><html lang="en-GB">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2304.05673] Precise localization of corneal reflections in eye images using deep learning trained on synthetic data</title><meta property="og:description" content="We present a deep learning method for accurately localizing the center of a single corneal reflection (CR) in an eye image. Unlike previous approaches, we use a convolutional neural network (CNN) that was trained solel‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Precise localization of corneal reflections in eye images using deep learning trained on synthetic data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Precise localization of corneal reflections in eye images using deep learning trained on synthetic data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2304.05673">

<!--Generated on Thu Feb 29 14:43:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en-GB">
<h1 class="ltx_title ltx_title_document">Precise localization of corneal reflections in eye images using deep learning trained on synthetic data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Sean Anthony Byrne
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">MoMiLab, IMT School for Advanced Studies Lucca, Lucca, Italy
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marcus Nystr√∂m
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Lund University Humanities Lab, Lund University, Lund, Sweden
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Virmarie Maquiling
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Human-Centered Technologies for Learning, Technical University of Munich, Munich, Germany
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Enkelejda Kasneci
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Human-Centered Technologies for Learning, Technical University of Munich, Munich, Germany
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Diederick C. Niehorster
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Lund University Humanities Lab, Lund University, Lund, Sweden
</span>
<span class="ltx_contact ltx_role_affiliation">Department of Psychology, Lund University, Lund, Sweden
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.1" class="ltx_p"><span id="id2.1.1" class="ltx_text">We present a deep learning method for accurately localizing the center of a single corneal reflection (CR) in an eye image. Unlike previous approaches, we use a convolutional neural network (CNN) that was trained solely using synthetic data. Using only synthetic data has the benefit of completely sidestepping the time-consuming process of manual annotation that is required for supervised training on real eye images.
To systematically evaluate the accuracy of our method, we first tested it on images with synthetic CRs placed on different backgrounds and embedded in varying levels of noise. Second, we tested the method on two datasets consisting of high-quality videos captured from real eyes.
Our method outperformed state-of-the-art algorithmic methods on real eye images with a <math id="id2.1.1.m1.3" class="ltx_Math" alttext="1341.5\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="id2.1.1.m1.3a"><mrow id="id2.1.1.m1.3.3" xref="id2.1.1.m1.3.3.cmml"><mrow id="id2.1.1.m1.1.1.1.1.1.1.4" xref="id2.1.1.m1.1.1.1.1.1.1.3.cmml"><mn id="id2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="id2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">13</mn><mtext id="id2.1.1.m1.1.1.1.1.1.1.4.1" xref="id2.1.1.m1.1.1.1.1.1.1.3.1.cmml">‚Äì</mtext><mn id="id2.1.1.m1.1.1.1.1.1.1.2.2.2.2.2" xref="id2.1.1.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">41.5</mn></mrow><mtext id="id2.1.1.m1.2.2.2.2.2.2" xref="id2.1.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="id2.1.1.m1.3.3.3.3.3.3" xref="id2.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="id2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1" xref="id2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.cmml">%</mi><mtext id="id2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2" xref="id2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.cmml">/</mtext><mi id="id2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3" xref="id2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="id2.1.1.m1.3b"><apply id="id2.1.1.m1.3.3.cmml" xref="id2.1.1.m1.3.3"><csymbol cd="latexml" id="id2.1.1.m1.2.2.2.2.2.2.cmml" xref="id2.1.1.m1.2.2.2.2.2.2">times</csymbol><apply id="id2.1.1.m1.1.1.1.1.1.1.3.cmml" xref="id2.1.1.m1.1.1.1.1.1.1.4"><csymbol cd="latexml" id="id2.1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="id2.1.1.m1.1.1.1.1.1.1.4.1">range</csymbol><cn type="integer" id="id2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="id2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1">13</cn><cn type="float" id="id2.1.1.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="id2.1.1.m1.1.1.1.1.1.1.2.2.2.2.2">41.5</cn></apply><apply id="id2.1.1.m1.3.3.3.3.3.3.cmml" xref="id2.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="id2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.cmml" xref="id2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="id2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.cmml" xref="id2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="id2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="id2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.1.1.m1.3c">1341.5\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math>reduction in terms of spatial precision across data sets, and performed on par with state-of-the-art on synthetic images in terms of spatial accuracy. We conclude that our method provides a precise method for CR center localization and provides a solution to the data availability problem which is one of the important common roadblocks in the development of deep learning models for gaze estimation. Due to the superior CR center localization and ease of application, our method has the potential to improve the accuracy and precision of CR-based eye trackers.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">An important part of the image processing pipeline in many video-based eye trackers is to localize the center of certain features in the eye image, typically the pupil <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>, <a href="#bib.bibx6" title="" class="ltx_ref">6</a>]</cite> and one or multiple corneal reflections (CRs)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>, <a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>. Accurate localization of these features is a prerequisite for an accurate gaze signal produced by the eye tracker. In this paper we focus on localizing the center of a single CR, which together with the pupil (P) center constitute the input for the dominant principle for video-based eye tracking over the past decades <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>]</cite>. This principle is known as P-CR eye tracking, and is used in high-end commercial systems like the EyeLink from SR Research (Ontario, Canada), where the head is typically constrained relative to the eye camera with a chin and forehead rest.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Conventionally, researchers have relied on using algorithmic methods which require a series of hard coded steps to yield a feature center estimate from the input image. Recent work has however shown that these traditional methods are limited in how accurately a pupil or CR can be localized in an eye image, in particular in the presence of image noise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>.
To overcome these challenges, we introduce a deep learning method that‚Äîtrained on a set of synthetic eye images‚Äîis able to accurately locate CR centers in real-world eye images. From a deep learning perspective, using synthetic data tackles the longstanding problem of finding or creating large, annotated databases that deep learning models are traditionally trained on. Our approach not only outperforms the traditional algorithmic methods used by many commercial eye-trackers,
but also introduces a new paradigm for
researchers interested in training deep learning models for gaze estimation. Our approach is not only simple to train, but also offers the flexibility to change the synthetic images used for training to suit the specific needs of the user. Additionally, our approach eliminates the need for large datasets and the time-consuming act of hand labeling images, which are often impractical for smaller research labs due to time and financial constraints.
</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">There are several algorithmic methods to detecting CRs in eye images and localizing their center, such as thresholding followed by center of mass calculations or ellipse fitting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>, <a href="#bib.bibx3" title="" class="ltx_ref">3</a>]</cite>. Many commercial eye trackers use these approaches, however they tend to suffer from inaccuracies and poor resolution, such as mis-estimating the amplitude of small eye movements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">24</a>]</cite>. Based on their results, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">24</a>]</cite> hypothesized that these problems could be ascribed to mislocalization of the CR center. Recent theoretical work has indeed shown that accurate localization of the center of the CR with thresholding techniques requires that the CR spans a sufficient number of pixels in the eye images and that the level of image noise remains low¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>. Besides simple thresholding of the CR in the eye image, other algorithmic methods for CR center localization have been proposed. Recently, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">40</a>]</cite> showed that radial symmetry <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite>, a particle tracking method stemming from the field of microscopy, outperformed simple thresholding in terms of CR localization. However, they only tested the radial symmetry method on eye images where the CR was located fully inside the pupil and thus appeared on a uniform dark background. Depending on the range of gaze directions in the task and the geometry of the setup, the CR will also often be located on the iris or on the border between the pupil and the iris. Since this case was not evaluated by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">40</a>]</cite> who only used a limited range of gaze directions, it remains unclear how the radial symmetry method would perform on real eye images recorded during unconstrained viewing.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this study, we aimed to improve the accuracy and precision of high-end P-CR eye tracking in controlled laboratory settings to allow even more robust estimation of small and slow eye movements. We use a two-stage approach, where a traditional method is used for rough localization, followed by a CNN-based method for more accurate localization. Specifically, to simplify the training procedure, and since traditional algorithmic methods such as thresholding are already quite good at CR localization, we first use thresholding followed by centroid calculation to make an initial estimate of CR center location, and then use the CNN on image patches centered around these locations. We compared the performance of our deep learning method to traditional methods such as radial symmetry and thresholding. We predicted that a CNN, when trained effectively, will be able to surpass traditional methods and achieve improved localization performance
<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, <em id="S1.p4.1.1.1" class="ltx_emph ltx_font_italic">cf.</em>,]</cite>]helgadottir2019digital.
In order to train this model effectively we synthesized CRs using 2D Gaussian distributions with different sizes and positions on a background with varying levels of noise (see the ‚Äú<a href="#S2.SS3" title="In 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref ltx_refmacro_nameref"><span class="ltx_text ltx_ref_title">Generating Synthetic Images</span></a>‚Äù section below for a detailed description).</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We use a deep learning framework known as DeepTrack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">22</a>]</cite>, originally developed for particle tracking in a microscopy setting. This framework utilizes a CNN trained on synthetic data to track single particles and also includes a U-Net model for tracking multiple particles. Subsequent work using this framework has also incorporated single-shot self-supervised object detection and geometric deep learning models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx37" title="" class="ltx_ref">37</a>, <a href="#bib.bibx39" title="" class="ltx_ref">39</a>]</cite>. The DeepTrack 2.1 Python library <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite> makes it easy to generate a synthetic dataset and train a deep learning model in the same pipeline. To the best of our knowledge, this is the first time the DeepTrack 2.1 library has been used outside of digital microscopy.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">While many gaze estimation studies deploy deep learning architectures, we focus our literature review specifically on models whose aim is to locate the CR or who create synthetic data used to train the model. We could find only three other deep learning models that have been developed for locating CRs in eye images. First, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">23</a>]</cite> used a three-level CNN network to locate CRs and match their locations in the eye image to the physical locations of the light sources used the generate the CRs. The model included a CNN backbone with feature pyramid outputs as the base architecture. The output was passed into two additional networks, one for identity matching and another for localization. Second, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">30</a>]</cite> trained a U-Net model on 4000 hand-labeled real eye images to accurately detect multiple CRs within the same image. The authors relied on several data augmentation techniques to develop a total of 40,000 samples for training. Third, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">35</a>]</cite> proposed a lightweight model that both localizes and matches corneal reflections. This model employs an attention mechanism to identify both the pupil center and CRs. They demonstrated improved performance in CR localization and matching when compared to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">30</a>]</cite>. It should be noted that by design, the work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">23</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">35</a>]</cite> was limited to localizing CR centers with pixel resolution, making their approaches unsuitable for our setting where we aim to recover the CR position at higher accuracy. The approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">30</a>]</cite> is theoretically able to provide sub-pixel level CR localizations, but in practice achieved an average error of 1.5 pixels, and requires training the model for a specific CR size.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">To overcome the need for large data sets to enable effective training of machine learning models for gaze estimation, previous studies have successfully used synthetic data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">29</a>]</cite>. For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">12</a>]</cite> proposed a ‚Äúlearning-by-synthesis‚Äù approach that trained random regression forests on a dataset of 3D reconstructions of eye regions created using a patch-based multi-view stereo (MVS) algorithm. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">13</a>]</cite> also used a similar approach of generating photo-realistic eye images to be used for a wide range of head poses, gaze directions and illuminations to develop a robust gaze estimation algorithm, and in a separate study generated a dataset of 1 million synthetic eye images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">15</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">14</a>]</cite> proposed an unsupervised learning paradigm using generative adversarial networks improving realism of a simulator‚Äôs output by using unlabeled real data. They argue synthetic data may not achieve the desired performance due to a gap between synthetic and real eye image distributions. The method was tested for gaze and hand pose estimation, showing a significant improvement over using synthetic data alone.
Our study diverges from these previous approaches as we demonstrate that models can be trained to achieve high accuracy using simple, highly controllable synthetic images that are substantially different from real eye images, avoiding the need for sophisticated and time-consuming techniques such as data augmentation or reconstruction methods.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">This paper addresses the following questions regarding deep learning methods for CR center localization: 1) Can a CNN trained on synthetic images perform CR center localization in real eye images? and if so, 2) Is our method able to locate the CR center more accurately than commonly used algorithmic approaches when applied to synthetic data? and 3) Does our method deliver a CR position signal with higher precision than the algorithmic approaches when applied to real eye images? We focus specifically on high resolution and high quality eye images, since accurate CR localization in high-end eye trackers is key to recording high-precision data where even the smallest and slowest of eye movements, e.g., microsaccades and slow pursuit, can be robustly distinguished from noise <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, c.f.,]</cite>]holmqvist2020small, Nystroem2022, niehorster2020apparent. Nevertheless, to assess the potential generalizability of our method to lower resolution eye images, in a second experiment reported in this paper we also evaluate our approach on spatially downsampled eye images.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Model Architecture</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In a preliminary test, we implemented the original DeepTrack CNN model as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">22</a>]</cite>. This model consisted of three convolutional layers and two dense layers, and we employed the same optimizer and hyperparameter choices as described in the original work. However, when we evaluated this model on our synthetic images that simulated a corneal reflection captured in a video-based eye tracking setup, we were unable to achieve sub-pixel level accuracy. The minimum validation error we reached was 2.95 pixels. To enhance the accuracy of our predictions, we developed our own CNN model. Our model included seven convolutional layers connected to two dense layers. The input to our model is 180 x 180 pixels grayscale images, and it outputs the subpixel location of the corneal reflection center. Figure <a href="#S2.F1" title="Figure 1 ‚Ä£ 2.1 Model Architecture ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides a visual representation of the complete architecture of our model.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2304.05673/assets/model.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of our method: A CNN model with seven convolutional layers that increase in filter size from 64 to 512 and two dense layers returning the Cartesian coordinates of the CR center.</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Model Training</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.2" class="ltx_p">We implemented a two-stage training approach for our model to achieve sub-pixel level accuracy. In the first stage, to ensure good generalization, we trained the model on a broader range of CR center locations than the model would typically encounter during inference. We describe the process of generating the images in detail in the following section of the paper. We utilized the Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">18</a>]</cite> and a mean squared error (MSE) loss function along with a very small batch size of four. The training was conducted for a maximum of 700 epochs, with an early stopping function implemented to prevent overfitting, achieving a validation error of 0.2338 pixels after 127 epochs. The second stage of training was performed on a dataset containing a smaller range of synthetic CR center locations. During this stage, we fine tuned the model by freezing the first two convolutional blocks while all subsequent layers of the model were set to trainable (i.e unfrozen), and we initialized the model with the weights from the first training stage. For selecting the layers to freeze, we followed an iterative process where we gradually increased the number of trainable layers. We initiated the process with a fully frozen model and subsequently unfroze the layer closest to the model head at each iteration. Additionally, we lowered the learning rate of the Adam optimiser from <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="1\mathrm{e}^{-4}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mn id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.SS2.p1.1.m1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.cmml">‚Äã</mo><msup id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml"><mi mathvariant="normal" id="S2.SS2.p1.1.m1.1.1.3.2" xref="S2.SS2.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S2.SS2.p1.1.m1.1.1.3.3" xref="S2.SS2.p1.1.m1.1.1.3.3.cmml"><mo id="S2.SS2.p1.1.m1.1.1.3.3a" xref="S2.SS2.p1.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="S2.SS2.p1.1.m1.1.1.3.3.2" xref="S2.SS2.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><times id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">1</cn><apply id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.p1.1.m1.1.1.3.2">e</ci><apply id="S2.SS2.p1.1.m1.1.1.3.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3.3"><minus id="S2.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S2.SS2.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S2.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S2.SS2.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">1\mathrm{e}^{-4}</annotation></semantics></math> to <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="1\mathrm{e}^{-6}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mrow id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mn id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.SS2.p1.2.m2.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.cmml">‚Äã</mo><msup id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml"><mi mathvariant="normal" id="S2.SS2.p1.2.m2.1.1.3.2" xref="S2.SS2.p1.2.m2.1.1.3.2.cmml">e</mi><mrow id="S2.SS2.p1.2.m2.1.1.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.cmml"><mo id="S2.SS2.p1.2.m2.1.1.3.3a" xref="S2.SS2.p1.2.m2.1.1.3.3.cmml">‚àí</mo><mn id="S2.SS2.p1.2.m2.1.1.3.3.2" xref="S2.SS2.p1.2.m2.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><times id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1"></times><cn type="integer" id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">1</cn><apply id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2">e</ci><apply id="S2.SS2.p1.2.m2.1.1.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3"><minus id="S2.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="S2.SS2.p1.2.m2.1.1.3.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">1\mathrm{e}^{-6}</annotation></semantics></math>. The second stage of training resulted in a sub-pixel accuracy of 0.085 after 187 epochs on the validation set.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">The DeepTrack 2.1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite> package provides a generator function which we used to efficiently generate and feed images into the model for training. We set up the generator such that the model only saw each training image one time, meaning that every image the model saw for training was unique. We additionally generated 300 synthetic images for the validation set. The fully trained model was saved and model evaluations were conducted on an Intel Xeon W-10885M CPU @ 2.40GHz with a prediction time of 13ms per image.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Generating Synthetic Images</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2304.05673/assets/simulated_crs.png" id="S2.F2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="286" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Example simulated CRs. Top row: example images used during model training and for the validation set. Left column: different values of Gaussian amplitude <math id="S2.F2.7.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.F2.7.m1.1b"><mi id="S2.F2.7.m1.1.1" xref="S2.F2.7.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.F2.7.m1.1c"><ci id="S2.F2.7.m1.1.1.cmml" xref="S2.F2.7.m1.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.m1.1d">A</annotation></semantics></math>. Right column: different pixel noise values <math id="S2.F2.8.m2.1" class="ltx_Math" alttext="\sigma_{n}^{2}" display="inline"><semantics id="S2.F2.8.m2.1b"><msubsup id="S2.F2.8.m2.1.1" xref="S2.F2.8.m2.1.1.cmml"><mi id="S2.F2.8.m2.1.1.2.2" xref="S2.F2.8.m2.1.1.2.2.cmml">œÉ</mi><mi id="S2.F2.8.m2.1.1.2.3" xref="S2.F2.8.m2.1.1.2.3.cmml">n</mi><mn id="S2.F2.8.m2.1.1.3" xref="S2.F2.8.m2.1.1.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.F2.8.m2.1c"><apply id="S2.F2.8.m2.1.1.cmml" xref="S2.F2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.8.m2.1.1.1.cmml" xref="S2.F2.8.m2.1.1">superscript</csymbol><apply id="S2.F2.8.m2.1.1.2.cmml" xref="S2.F2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.8.m2.1.1.2.1.cmml" xref="S2.F2.8.m2.1.1">subscript</csymbol><ci id="S2.F2.8.m2.1.1.2.2.cmml" xref="S2.F2.8.m2.1.1.2.2">ùúé</ci><ci id="S2.F2.8.m2.1.1.2.3.cmml" xref="S2.F2.8.m2.1.1.2.3">ùëõ</ci></apply><cn type="integer" id="S2.F2.8.m2.1.1.3.cmml" xref="S2.F2.8.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.m2.1d">\sigma_{n}^{2}</annotation></semantics></math> (image levels). For both columns, random positions (within <math id="S2.F2.9.m3.2" class="ltx_Math" alttext="[-1.5r,1.5r]" display="inline"><semantics id="S2.F2.9.m3.2b"><mrow id="S2.F2.9.m3.2.2.2" xref="S2.F2.9.m3.2.2.3.cmml"><mo stretchy="false" id="S2.F2.9.m3.2.2.2.3" xref="S2.F2.9.m3.2.2.3.cmml">[</mo><mrow id="S2.F2.9.m3.1.1.1.1" xref="S2.F2.9.m3.1.1.1.1.cmml"><mo id="S2.F2.9.m3.1.1.1.1b" xref="S2.F2.9.m3.1.1.1.1.cmml">‚àí</mo><mrow id="S2.F2.9.m3.1.1.1.1.2" xref="S2.F2.9.m3.1.1.1.1.2.cmml"><mn id="S2.F2.9.m3.1.1.1.1.2.2" xref="S2.F2.9.m3.1.1.1.1.2.2.cmml">1.5</mn><mo lspace="0em" rspace="0em" id="S2.F2.9.m3.1.1.1.1.2.1" xref="S2.F2.9.m3.1.1.1.1.2.1.cmml">‚Äã</mo><mi id="S2.F2.9.m3.1.1.1.1.2.3" xref="S2.F2.9.m3.1.1.1.1.2.3.cmml">r</mi></mrow></mrow><mo id="S2.F2.9.m3.2.2.2.4" xref="S2.F2.9.m3.2.2.3.cmml">,</mo><mrow id="S2.F2.9.m3.2.2.2.2" xref="S2.F2.9.m3.2.2.2.2.cmml"><mn id="S2.F2.9.m3.2.2.2.2.2" xref="S2.F2.9.m3.2.2.2.2.2.cmml">1.5</mn><mo lspace="0em" rspace="0em" id="S2.F2.9.m3.2.2.2.2.1" xref="S2.F2.9.m3.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.F2.9.m3.2.2.2.2.3" xref="S2.F2.9.m3.2.2.2.2.3.cmml">r</mi></mrow><mo stretchy="false" id="S2.F2.9.m3.2.2.2.5" xref="S2.F2.9.m3.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.9.m3.2c"><interval closure="closed" id="S2.F2.9.m3.2.2.3.cmml" xref="S2.F2.9.m3.2.2.2"><apply id="S2.F2.9.m3.1.1.1.1.cmml" xref="S2.F2.9.m3.1.1.1.1"><minus id="S2.F2.9.m3.1.1.1.1.1.cmml" xref="S2.F2.9.m3.1.1.1.1"></minus><apply id="S2.F2.9.m3.1.1.1.1.2.cmml" xref="S2.F2.9.m3.1.1.1.1.2"><times id="S2.F2.9.m3.1.1.1.1.2.1.cmml" xref="S2.F2.9.m3.1.1.1.1.2.1"></times><cn type="float" id="S2.F2.9.m3.1.1.1.1.2.2.cmml" xref="S2.F2.9.m3.1.1.1.1.2.2">1.5</cn><ci id="S2.F2.9.m3.1.1.1.1.2.3.cmml" xref="S2.F2.9.m3.1.1.1.1.2.3">ùëü</ci></apply></apply><apply id="S2.F2.9.m3.2.2.2.2.cmml" xref="S2.F2.9.m3.2.2.2.2"><times id="S2.F2.9.m3.2.2.2.2.1.cmml" xref="S2.F2.9.m3.2.2.2.2.1"></times><cn type="float" id="S2.F2.9.m3.2.2.2.2.2.cmml" xref="S2.F2.9.m3.2.2.2.2.2">1.5</cn><ci id="S2.F2.9.m3.2.2.2.2.3.cmml" xref="S2.F2.9.m3.2.2.2.2.3">ùëü</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.m3.2d">[-1.5r,1.5r]</annotation></semantics></math>) and orientations of the dividing line between the dark and light sections of the background are shown. Bottom row: example images used for evaluation, showing different background locations <math id="S2.F2.10.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.F2.10.m4.1b"><mi id="S2.F2.10.m4.1.1" xref="S2.F2.10.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.F2.10.m4.1c"><ci id="S2.F2.10.m4.1.1.cmml" xref="S2.F2.10.m4.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.m4.1d">E</annotation></semantics></math> as well as a CR image without a gray background. The value for the varied parameter is denoted on the panels. <math id="S2.F2.11.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.F2.11.m5.1b"><mi id="S2.F2.11.m5.1.1" xref="S2.F2.11.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.F2.11.m5.1c"><ci id="S2.F2.11.m5.1.1.cmml" xref="S2.F2.11.m5.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.11.m5.1d">A</annotation></semantics></math> was set to 10000 for all panels except the top-left. For illustration purposes, the CR radius (<math id="S2.F2.12.m6.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.F2.12.m6.1b"><mi id="S2.F2.12.m6.1.1" xref="S2.F2.12.m6.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.F2.12.m6.1c"><ci id="S2.F2.12.m6.1.1.cmml" xref="S2.F2.12.m6.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.12.m6.1d">r</annotation></semantics></math>) in these panels is 50 pixels. During both training and evaluation the pixel intensity of the lighter section of the background was also varied (not shown).</figcaption>
</figure>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Features of the synthetic images</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">As in previous work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>, the light distribution of the CR in an eye image is modeled as a 2D Gaussian distribution, as is supported by optical modeling¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">40</a>]</cite>. CRs in real eye images have at least two further important features: 1) The CR in an eye image is normally heavily oversaturated¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">40</a>, <a href="#bib.bibx8" title="" class="ltx_ref">8</a>]</cite>; and 2) depending on the physical geometry of the setup and the orientation of the eye, the CR is often overlaid on a non-uniform background, such as the iris or the edge of the pupil. We, therefore, extend the approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite> by introducing saturation that truncates the Gaussian distribution and leaves it with an area of maximum brightness surrounded by shallow tails, and by introducing a non-uniform background.</p>
</div>
<div id="S2.SS3.SSS1.p2" class="ltx_para">
<p id="S2.SS3.SSS1.p2.6" class="ltx_p">More formally, the saturated CR is generated from a Gaussian distribution</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.4" class="ltx_Math" alttext="G(x,y)=Ae^{-\left(\frac{(x-x_{c})^{2}+(y-y_{c})^{2}}{2\sigma_{w}^{2}}\right)}" display="block"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.5" xref="S2.E1.m1.4.5.cmml"><mrow id="S2.E1.m1.4.5.2" xref="S2.E1.m1.4.5.2.cmml"><mi id="S2.E1.m1.4.5.2.2" xref="S2.E1.m1.4.5.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.5.2.1" xref="S2.E1.m1.4.5.2.1.cmml">‚Äã</mo><mrow id="S2.E1.m1.4.5.2.3.2" xref="S2.E1.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S2.E1.m1.4.5.2.3.2.1" xref="S2.E1.m1.4.5.2.3.1.cmml">(</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">x</mi><mo id="S2.E1.m1.4.5.2.3.2.2" xref="S2.E1.m1.4.5.2.3.1.cmml">,</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">y</mi><mo stretchy="false" id="S2.E1.m1.4.5.2.3.2.3" xref="S2.E1.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.5.1" xref="S2.E1.m1.4.5.1.cmml">=</mo><mrow id="S2.E1.m1.4.5.3" xref="S2.E1.m1.4.5.3.cmml"><mi id="S2.E1.m1.4.5.3.2" xref="S2.E1.m1.4.5.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.5.3.1" xref="S2.E1.m1.4.5.3.1.cmml">‚Äã</mo><msup id="S2.E1.m1.4.5.3.3" xref="S2.E1.m1.4.5.3.3.cmml"><mi id="S2.E1.m1.4.5.3.3.2" xref="S2.E1.m1.4.5.3.3.2.cmml">e</mi><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><mo id="S2.E1.m1.2.2.2a" xref="S2.E1.m1.2.2.2.cmml">‚àí</mo><mrow id="S2.E1.m1.2.2.2.4.2" xref="S2.E1.m1.2.2.2.2.cmml"><mo id="S2.E1.m1.2.2.2.4.2.1" xref="S2.E1.m1.2.2.2.2.cmml">(</mo><mfrac id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml"><mrow id="S2.E1.m1.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.cmml"><msup id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S2.E1.m1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S2.E1.m1.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.3.cmml">+</mo><msup id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.cmml"><mrow id="S2.E1.m1.2.2.2.2.2.2.1.1" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.2.2.2.2.1.1.2" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.2.2.2.2.1.1.1" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.1.1.1.2" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml">y</mi><mo id="S2.E1.m1.2.2.2.2.2.2.1.1.1.1" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.1.cmml">‚àí</mo><msub id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.2" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.2.cmml">y</mi><mi id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.3" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S2.E1.m1.2.2.2.2.2.2.1.1.3" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.cmml">)</mo></mrow><mn id="S2.E1.m1.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.2.3.cmml">2</mn></msup></mrow><mrow id="S2.E1.m1.2.2.2.2.4" xref="S2.E1.m1.2.2.2.2.4.cmml"><mn id="S2.E1.m1.2.2.2.2.4.2" xref="S2.E1.m1.2.2.2.2.4.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.4.1" xref="S2.E1.m1.2.2.2.2.4.1.cmml">‚Äã</mo><msubsup id="S2.E1.m1.2.2.2.2.4.3" xref="S2.E1.m1.2.2.2.2.4.3.cmml"><mi id="S2.E1.m1.2.2.2.2.4.3.2.2" xref="S2.E1.m1.2.2.2.2.4.3.2.2.cmml">œÉ</mi><mi id="S2.E1.m1.2.2.2.2.4.3.2.3" xref="S2.E1.m1.2.2.2.2.4.3.2.3.cmml">w</mi><mn id="S2.E1.m1.2.2.2.2.4.3.3" xref="S2.E1.m1.2.2.2.2.4.3.3.cmml">2</mn></msubsup></mrow></mfrac><mo id="S2.E1.m1.2.2.2.4.2.2" xref="S2.E1.m1.2.2.2.2.cmml">)</mo></mrow></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.5.cmml" xref="S2.E1.m1.4.5"><eq id="S2.E1.m1.4.5.1.cmml" xref="S2.E1.m1.4.5.1"></eq><apply id="S2.E1.m1.4.5.2.cmml" xref="S2.E1.m1.4.5.2"><times id="S2.E1.m1.4.5.2.1.cmml" xref="S2.E1.m1.4.5.2.1"></times><ci id="S2.E1.m1.4.5.2.2.cmml" xref="S2.E1.m1.4.5.2.2">ùê∫</ci><interval closure="open" id="S2.E1.m1.4.5.2.3.1.cmml" xref="S2.E1.m1.4.5.2.3.2"><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ùë•</ci><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ùë¶</ci></interval></apply><apply id="S2.E1.m1.4.5.3.cmml" xref="S2.E1.m1.4.5.3"><times id="S2.E1.m1.4.5.3.1.cmml" xref="S2.E1.m1.4.5.3.1"></times><ci id="S2.E1.m1.4.5.3.2.cmml" xref="S2.E1.m1.4.5.3.2">ùê¥</ci><apply id="S2.E1.m1.4.5.3.3.cmml" xref="S2.E1.m1.4.5.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.5.3.3.1.cmml" xref="S2.E1.m1.4.5.3.3">superscript</csymbol><ci id="S2.E1.m1.4.5.3.3.2.cmml" xref="S2.E1.m1.4.5.3.3.2">ùëí</ci><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><minus id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2"></minus><apply id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.4.2"><divide id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4.2"></divide><apply id="S2.E1.m1.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2"><plus id="S2.E1.m1.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.3"></plus><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1"></minus><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2">ùë•</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.2">ùë•</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.3">ùëê</ci></apply></apply><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.3">2</cn></apply><apply id="S2.E1.m1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2">superscript</csymbol><apply id="S2.E1.m1.2.2.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1"><minus id="S2.E1.m1.2.2.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.1"></minus><ci id="S2.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.2">ùë¶</ci><apply id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.2">ùë¶</ci><ci id="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1.1.3.3">ùëê</ci></apply></apply><cn type="integer" id="S2.E1.m1.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3">2</cn></apply></apply><apply id="S2.E1.m1.2.2.2.2.4.cmml" xref="S2.E1.m1.2.2.2.2.4"><times id="S2.E1.m1.2.2.2.2.4.1.cmml" xref="S2.E1.m1.2.2.2.2.4.1"></times><cn type="integer" id="S2.E1.m1.2.2.2.2.4.2.cmml" xref="S2.E1.m1.2.2.2.2.4.2">2</cn><apply id="S2.E1.m1.2.2.2.2.4.3.cmml" xref="S2.E1.m1.2.2.2.2.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.4.3.1.cmml" xref="S2.E1.m1.2.2.2.2.4.3">superscript</csymbol><apply id="S2.E1.m1.2.2.2.2.4.3.2.cmml" xref="S2.E1.m1.2.2.2.2.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.4.3.2.1.cmml" xref="S2.E1.m1.2.2.2.2.4.3">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.4.3.2.2.cmml" xref="S2.E1.m1.2.2.2.2.4.3.2.2">ùúé</ci><ci id="S2.E1.m1.2.2.2.2.4.3.2.3.cmml" xref="S2.E1.m1.2.2.2.2.4.3.2.3">ùë§</ci></apply><cn type="integer" id="S2.E1.m1.2.2.2.2.4.3.3.cmml" xref="S2.E1.m1.2.2.2.2.4.3.3">2</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">G(x,y)=Ae^{-\left(\frac{(x-x_{c})^{2}+(y-y_{c})^{2}}{2\sigma_{w}^{2}}\right)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS3.SSS1.p2.7" class="ltx_p">where the following parameters are varied in the simulation:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">The center of the input light distribution <math id="S2.I1.i1.p1.1.m1.2" class="ltx_Math" alttext="(x_{c},y_{c})" display="inline"><semantics id="S2.I1.i1.p1.1.m1.2a"><mrow id="S2.I1.i1.p1.1.m1.2.2.2" xref="S2.I1.i1.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S2.I1.i1.p1.1.m1.2.2.2.3" xref="S2.I1.i1.p1.1.m1.2.2.3.cmml">(</mo><msub id="S2.I1.i1.p1.1.m1.1.1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.1.1.2.cmml">x</mi><mi id="S2.I1.i1.p1.1.m1.1.1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.1.1.3.cmml">c</mi></msub><mo id="S2.I1.i1.p1.1.m1.2.2.2.4" xref="S2.I1.i1.p1.1.m1.2.2.3.cmml">,</mo><msub id="S2.I1.i1.p1.1.m1.2.2.2.2" xref="S2.I1.i1.p1.1.m1.2.2.2.2.cmml"><mi id="S2.I1.i1.p1.1.m1.2.2.2.2.2" xref="S2.I1.i1.p1.1.m1.2.2.2.2.2.cmml">y</mi><mi id="S2.I1.i1.p1.1.m1.2.2.2.2.3" xref="S2.I1.i1.p1.1.m1.2.2.2.2.3.cmml">c</mi></msub><mo stretchy="false" id="S2.I1.i1.p1.1.m1.2.2.2.5" xref="S2.I1.i1.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.2b"><interval closure="open" id="S2.I1.i1.p1.1.m1.2.2.3.cmml" xref="S2.I1.i1.p1.1.m1.2.2.2"><apply id="S2.I1.i1.p1.1.m1.1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1.1.2">ùë•</ci><ci id="S2.I1.i1.p1.1.m1.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1.1.3">ùëê</ci></apply><apply id="S2.I1.i1.p1.1.m1.2.2.2.2.cmml" xref="S2.I1.i1.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.2.2.2.2.1.cmml" xref="S2.I1.i1.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.2.2.2.2.2.cmml" xref="S2.I1.i1.p1.1.m1.2.2.2.2.2">ùë¶</ci><ci id="S2.I1.i1.p1.1.m1.2.2.2.2.3.cmml" xref="S2.I1.i1.p1.1.m1.2.2.2.2.3">ùëê</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.2c">(x_{c},y_{c})</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.2" class="ltx_p">The amplitude <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">A</annotation></semantics></math> of the Gaussian distribution. Saturation is achieved when <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><mi id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><ci id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">A</annotation></semantics></math> is set to amplitudes larger than 1 since image values are limited to 1 at the end of the image generation pipeline (see below). Figure <a href="#S2.F2" title="Figure 2 ‚Ä£ 2.3 Generating Synthetic Images ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (top-left) shows CRs at three different amplitudes. Notice that larger amplitudes lead to shallower tails.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.3" class="ltx_p">The radius <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><mi id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><ci id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">r</annotation></semantics></math> of the resulting CR. This is parameterized such that for a given value, the radius of the saturated portion of the CR is kept constant irrespective of the amplitude (<math id="S2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.I1.i3.p1.2.m2.1a"><mi id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><ci id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">A</annotation></semantics></math>) of the underlying Gaussian. This is achieved by setting <math id="S2.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="\sigma_{w}=r/\sqrt{-2\log\frac{1}{A}}" display="inline"><semantics id="S2.I1.i3.p1.3.m3.1a"><mrow id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml"><msub id="S2.I1.i3.p1.3.m3.1.1.2" xref="S2.I1.i3.p1.3.m3.1.1.2.cmml"><mi id="S2.I1.i3.p1.3.m3.1.1.2.2" xref="S2.I1.i3.p1.3.m3.1.1.2.2.cmml">œÉ</mi><mi id="S2.I1.i3.p1.3.m3.1.1.2.3" xref="S2.I1.i3.p1.3.m3.1.1.2.3.cmml">w</mi></msub><mo id="S2.I1.i3.p1.3.m3.1.1.1" xref="S2.I1.i3.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S2.I1.i3.p1.3.m3.1.1.3" xref="S2.I1.i3.p1.3.m3.1.1.3.cmml"><mi id="S2.I1.i3.p1.3.m3.1.1.3.2" xref="S2.I1.i3.p1.3.m3.1.1.3.2.cmml">r</mi><mo id="S2.I1.i3.p1.3.m3.1.1.3.1" xref="S2.I1.i3.p1.3.m3.1.1.3.1.cmml">/</mo><msqrt id="S2.I1.i3.p1.3.m3.1.1.3.3" xref="S2.I1.i3.p1.3.m3.1.1.3.3.cmml"><mrow id="S2.I1.i3.p1.3.m3.1.1.3.3.2" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.cmml"><mo id="S2.I1.i3.p1.3.m3.1.1.3.3.2a" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.cmml">‚àí</mo><mrow id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.cmml"><mn id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.2" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.2.cmml">2</mn><mo lspace="0.167em" rspace="0em" id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.1" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.1.cmml">‚Äã</mo><mrow id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.cmml"><mi id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.1" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3a" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.cmml">‚Å°</mo><mfrac id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.cmml"><mn id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.2" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.2.cmml">1</mn><mi id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.3" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.3.cmml">A</mi></mfrac></mrow></mrow></mrow></msqrt></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.1b"><apply id="S2.I1.i3.p1.3.m3.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1"><eq id="S2.I1.i3.p1.3.m3.1.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.1"></eq><apply id="S2.I1.i3.p1.3.m3.1.1.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.3.m3.1.1.2.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.2">subscript</csymbol><ci id="S2.I1.i3.p1.3.m3.1.1.2.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.2.2">ùúé</ci><ci id="S2.I1.i3.p1.3.m3.1.1.2.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.2.3">ùë§</ci></apply><apply id="S2.I1.i3.p1.3.m3.1.1.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3"><divide id="S2.I1.i3.p1.3.m3.1.1.3.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.1"></divide><ci id="S2.I1.i3.p1.3.m3.1.1.3.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.2">ùëü</ci><apply id="S2.I1.i3.p1.3.m3.1.1.3.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3"><root id="S2.I1.i3.p1.3.m3.1.1.3.3a.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3"></root><apply id="S2.I1.i3.p1.3.m3.1.1.3.3.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2"><minus id="S2.I1.i3.p1.3.m3.1.1.3.3.2.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2"></minus><apply id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2"><times id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.1"></times><cn type="integer" id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.2">2</cn><apply id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3"><log id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.1"></log><apply id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2"><divide id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2"></divide><cn type="integer" id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.2">1</cn><ci id="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3.3.2.2.3.2.3">ùê¥</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.1c">\sigma_{w}=r/\sqrt{-2\log\frac{1}{A}}</annotation></semantics></math>.</p>
</div>
</li>
</ol>
<p id="S2.SS3.SSS1.p2.5" class="ltx_p">Two further aspects were varied to generate the final synthetic images. First, to simulate the pupil-iris border, a background was generated that consisted of two sections of different luminance, and the line dividing the two sections was randomly placed near the CR and randomly oriented. The image of the synthetic CR was added to this background using the following operation: <math id="S2.SS3.SSS1.p2.1.m1.2" class="ltx_Math" alttext="max(CR,background)" display="inline"><semantics id="S2.SS3.SSS1.p2.1.m1.2a"><mrow id="S2.SS3.SSS1.p2.1.m1.2.2" xref="S2.SS3.SSS1.p2.1.m1.2.2.cmml"><mi id="S2.SS3.SSS1.p2.1.m1.2.2.4" xref="S2.SS3.SSS1.p2.1.m1.2.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.3" xref="S2.SS3.SSS1.p2.1.m1.2.2.3.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.5" xref="S2.SS3.SSS1.p2.1.m1.2.2.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.3a" xref="S2.SS3.SSS1.p2.1.m1.2.2.3.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.6" xref="S2.SS3.SSS1.p2.1.m1.2.2.6.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.3b" xref="S2.SS3.SSS1.p2.1.m1.2.2.3.cmml">‚Äã</mo><mrow id="S2.SS3.SSS1.p2.1.m1.2.2.2.2" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.3" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.3.cmml">(</mo><mrow id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.2" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.1" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.3" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.3.cmml">R</mi></mrow><mo id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.4" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.3.cmml">,</mo><mrow id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.cmml"><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.2" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.3" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1a" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.4" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1b" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.5" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.5.cmml">k</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1c" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.6" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1d" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.7" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1e" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.8" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1f" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.9" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1g" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.10" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.10.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1h" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml">‚Äã</mo><mi id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.11" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.11.cmml">d</mi></mrow><mo stretchy="false" id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.5" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.1.m1.2b"><apply id="S2.SS3.SSS1.p2.1.m1.2.2.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2"><times id="S2.SS3.SSS1.p2.1.m1.2.2.3.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.3"></times><ci id="S2.SS3.SSS1.p2.1.m1.2.2.4.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.4">ùëö</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.5.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.5">ùëé</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.6.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.6">ùë•</ci><interval closure="open" id="S2.SS3.SSS1.p2.1.m1.2.2.2.3.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2"><apply id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1"><times id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.1"></times><ci id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.2">ùê∂</ci><ci id="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS3.SSS1.p2.1.m1.1.1.1.1.1.3">ùëÖ</ci></apply><apply id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2"><times id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.1"></times><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.2">ùëè</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.3">ùëé</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.4.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.4">ùëê</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.5.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.5">ùëò</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.6.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.6">ùëî</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.7.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.7">ùëü</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.8.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.8">ùëú</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.9.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.9">ùë¢</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.10.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.10">ùëõ</ci><ci id="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.11.cmml" xref="S2.SS3.SSS1.p2.1.m1.2.2.2.2.2.11">ùëë</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.1.m1.2c">max(CR,background)</annotation></semantics></math>. The top row of Figure <a href="#S2.F2" title="Figure 2 ‚Ä£ 2.3 Generating Synthetic Images ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows synthetic CRs on various example backgrounds. Furthermore, noise was added to the images by adding a value drawn from a Gaussian distribution <math id="S2.SS3.SSS1.p2.2.m2.2" class="ltx_Math" alttext="X\sim\mathcal{N}(0,\,\sigma_{n}^{2})" display="inline"><semantics id="S2.SS3.SSS1.p2.2.m2.2a"><mrow id="S2.SS3.SSS1.p2.2.m2.2.2" xref="S2.SS3.SSS1.p2.2.m2.2.2.cmml"><mi id="S2.SS3.SSS1.p2.2.m2.2.2.3" xref="S2.SS3.SSS1.p2.2.m2.2.2.3.cmml">X</mi><mo id="S2.SS3.SSS1.p2.2.m2.2.2.2" xref="S2.SS3.SSS1.p2.2.m2.2.2.2.cmml">‚àº</mo><mrow id="S2.SS3.SSS1.p2.2.m2.2.2.1" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS1.p2.2.m2.2.2.1.3" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.3.cmml">ùí©</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.2.m2.2.2.1.2" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.2.cmml">‚Äã</mo><mrow id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.2" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml">(</mo><mn id="S2.SS3.SSS1.p2.2.m2.1.1" xref="S2.SS3.SSS1.p2.2.m2.1.1.cmml">0</mn><mo rspace="0.337em" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.3" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml">,</mo><msubsup id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.cmml"><mi id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.2" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.2.cmml">œÉ</mi><mi id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.3" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.3.cmml">n</mi><mn id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.3" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.3.cmml">2</mn></msubsup><mo stretchy="false" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.4" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.2.m2.2b"><apply id="S2.SS3.SSS1.p2.2.m2.2.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2"><csymbol cd="latexml" id="S2.SS3.SSS1.p2.2.m2.2.2.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.2">similar-to</csymbol><ci id="S2.SS3.SSS1.p2.2.m2.2.2.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.3">ùëã</ci><apply id="S2.SS3.SSS1.p2.2.m2.2.2.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1"><times id="S2.SS3.SSS1.p2.2.m2.2.2.1.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.2"></times><ci id="S2.SS3.SSS1.p2.2.m2.2.2.1.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.3">ùí©</ci><interval closure="open" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1"><cn type="integer" id="S2.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.1.1">0</cn><apply id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1">superscript</csymbol><apply id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.2">ùúé</ci><ci id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.2.3">ùëõ</ci></apply><cn type="integer" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.3">2</cn></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.2.m2.2c">X\sim\mathcal{N}(0,\,\sigma_{n}^{2})</annotation></semantics></math> for each individual pixel of the image. The parameter <math id="S2.SS3.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\sigma_{n}^{2}" display="inline"><semantics id="S2.SS3.SSS1.p2.3.m3.1a"><msubsup id="S2.SS3.SSS1.p2.3.m3.1.1" xref="S2.SS3.SSS1.p2.3.m3.1.1.cmml"><mi id="S2.SS3.SSS1.p2.3.m3.1.1.2.2" xref="S2.SS3.SSS1.p2.3.m3.1.1.2.2.cmml">œÉ</mi><mi id="S2.SS3.SSS1.p2.3.m3.1.1.2.3" xref="S2.SS3.SSS1.p2.3.m3.1.1.2.3.cmml">n</mi><mn id="S2.SS3.SSS1.p2.3.m3.1.1.3" xref="S2.SS3.SSS1.p2.3.m3.1.1.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.3.m3.1b"><apply id="S2.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.3.m3.1.1.1.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1">superscript</csymbol><apply id="S2.SS3.SSS1.p2.3.m3.1.1.2.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.3.m3.1.1.2.1.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.3.m3.1.1.2.2.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1.2.2">ùúé</ci><ci id="S2.SS3.SSS1.p2.3.m3.1.1.2.3.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1.2.3">ùëõ</ci></apply><cn type="integer" id="S2.SS3.SSS1.p2.3.m3.1.1.3.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.3.m3.1c">\sigma_{n}^{2}</annotation></semantics></math> was varied (see Figure <a href="#S2.F2" title="Figure 2 ‚Ä£ 2.3 Generating Synthetic Images ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, top-right).
Finally, the intensity values in the resulting images were limited to the range <math id="S2.SS3.SSS1.p2.4.m4.2" class="ltx_Math" alttext="[0,255]" display="inline"><semantics id="S2.SS3.SSS1.p2.4.m4.2a"><mrow id="S2.SS3.SSS1.p2.4.m4.2.3.2" xref="S2.SS3.SSS1.p2.4.m4.2.3.1.cmml"><mo stretchy="false" id="S2.SS3.SSS1.p2.4.m4.2.3.2.1" xref="S2.SS3.SSS1.p2.4.m4.2.3.1.cmml">[</mo><mn id="S2.SS3.SSS1.p2.4.m4.1.1" xref="S2.SS3.SSS1.p2.4.m4.1.1.cmml">0</mn><mo id="S2.SS3.SSS1.p2.4.m4.2.3.2.2" xref="S2.SS3.SSS1.p2.4.m4.2.3.1.cmml">,</mo><mn id="S2.SS3.SSS1.p2.4.m4.2.2" xref="S2.SS3.SSS1.p2.4.m4.2.2.cmml">255</mn><mo stretchy="false" id="S2.SS3.SSS1.p2.4.m4.2.3.2.3" xref="S2.SS3.SSS1.p2.4.m4.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.4.m4.2b"><interval closure="closed" id="S2.SS3.SSS1.p2.4.m4.2.3.1.cmml" xref="S2.SS3.SSS1.p2.4.m4.2.3.2"><cn type="integer" id="S2.SS3.SSS1.p2.4.m4.1.1.cmml" xref="S2.SS3.SSS1.p2.4.m4.1.1">0</cn><cn type="integer" id="S2.SS3.SSS1.p2.4.m4.2.2.cmml" xref="S2.SS3.SSS1.p2.4.m4.2.2">255</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.4.m4.2c">[0,255]</annotation></semantics></math>, scaled to the range <math id="S2.SS3.SSS1.p2.5.m5.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="S2.SS3.SSS1.p2.5.m5.2a"><mrow id="S2.SS3.SSS1.p2.5.m5.2.3.2" xref="S2.SS3.SSS1.p2.5.m5.2.3.1.cmml"><mo stretchy="false" id="S2.SS3.SSS1.p2.5.m5.2.3.2.1" xref="S2.SS3.SSS1.p2.5.m5.2.3.1.cmml">[</mo><mn id="S2.SS3.SSS1.p2.5.m5.1.1" xref="S2.SS3.SSS1.p2.5.m5.1.1.cmml">0</mn><mo id="S2.SS3.SSS1.p2.5.m5.2.3.2.2" xref="S2.SS3.SSS1.p2.5.m5.2.3.1.cmml">,</mo><mn id="S2.SS3.SSS1.p2.5.m5.2.2" xref="S2.SS3.SSS1.p2.5.m5.2.2.cmml">1</mn><mo stretchy="false" id="S2.SS3.SSS1.p2.5.m5.2.3.2.3" xref="S2.SS3.SSS1.p2.5.m5.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.5.m5.2b"><interval closure="closed" id="S2.SS3.SSS1.p2.5.m5.2.3.1.cmml" xref="S2.SS3.SSS1.p2.5.m5.2.3.2"><cn type="integer" id="S2.SS3.SSS1.p2.5.m5.1.1.cmml" xref="S2.SS3.SSS1.p2.5.m5.1.1">0</cn><cn type="integer" id="S2.SS3.SSS1.p2.5.m5.2.2.cmml" xref="S2.SS3.SSS1.p2.5.m5.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.5.m5.2c">[0,1]</annotation></semantics></math> and the image was discretized to 256 levels, corresponding to 8-bit camera images.</p>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Model of image information for CR center localization</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.2" class="ltx_p">Since the aim of the current work is to develop a high-accuracy CR center localization method, it is important to develop a model of what accuracy an optimal localization method could achieve. As shown by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>, CR localization accuracy depends on the number of pixels spanned by the CR in the image as well as the shape of the light distribution.
Theoretically, the lower the spatial pixel resolution or bit-depth of the CR image, the lower is the maximum achievable localization accuracy of the CR center.
This follows from the logic that the coarser the digital representation of the CR, the bigger the change in its position needs to be before an observable change occurs in the CR image <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, <span id="S2.SS3.SSS2.p1.2.1.1" class="ltx_text ltx_font_italic">cf</span>.,]</cite>]mulligan1997. Therefore, to provide a benchmark for the results presented in this paper, we determined the theoretically optimal center localization performance as a function of CR size and Gaussian amplitude (i.e. tail width). To do so, we took a set of CR images generated with the Cartesian product of <math id="S2.SS3.SSS2.p1.1.m1.5" class="ltx_Math" alttext="r=\{2,\allowbreak 4,\allowbreak 6,\allowbreak...,\allowbreak 18\}" display="inline"><semantics id="S2.SS3.SSS2.p1.1.m1.5a"><mrow id="S2.SS3.SSS2.p1.1.m1.5.6" xref="S2.SS3.SSS2.p1.1.m1.5.6.cmml"><mi id="S2.SS3.SSS2.p1.1.m1.5.6.2" xref="S2.SS3.SSS2.p1.1.m1.5.6.2.cmml">r</mi><mo id="S2.SS3.SSS2.p1.1.m1.5.6.1" xref="S2.SS3.SSS2.p1.1.m1.5.6.1.cmml">=</mo><mrow id="S2.SS3.SSS2.p1.1.m1.5.6.3.2" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml"><mo stretchy="false" id="S2.SS3.SSS2.p1.1.m1.5.6.3.2.1" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">{</mo><mn id="S2.SS3.SSS2.p1.1.m1.1.1" xref="S2.SS3.SSS2.p1.1.m1.1.1.cmml">2</mn><mo id="S2.SS3.SSS2.p1.1.m1.5.6.3.2.2" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.1.m1.2.2" xref="S2.SS3.SSS2.p1.1.m1.2.2.cmml">4</mn><mo id="S2.SS3.SSS2.p1.1.m1.5.6.3.2.3" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.1.m1.3.3" xref="S2.SS3.SSS2.p1.1.m1.3.3.cmml">6</mn><mo id="S2.SS3.SSS2.p1.1.m1.5.6.3.2.4" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS3.SSS2.p1.1.m1.4.4" xref="S2.SS3.SSS2.p1.1.m1.4.4.cmml">‚Ä¶</mi><mo id="S2.SS3.SSS2.p1.1.m1.5.6.3.2.5" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.1.m1.5.5" xref="S2.SS3.SSS2.p1.1.m1.5.5.cmml">18</mn><mo stretchy="false" id="S2.SS3.SSS2.p1.1.m1.5.6.3.2.6" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.1.m1.5b"><apply id="S2.SS3.SSS2.p1.1.m1.5.6.cmml" xref="S2.SS3.SSS2.p1.1.m1.5.6"><eq id="S2.SS3.SSS2.p1.1.m1.5.6.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.5.6.1"></eq><ci id="S2.SS3.SSS2.p1.1.m1.5.6.2.cmml" xref="S2.SS3.SSS2.p1.1.m1.5.6.2">ùëü</ci><set id="S2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.5.6.3.2"><cn type="integer" id="S2.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1">2</cn><cn type="integer" id="S2.SS3.SSS2.p1.1.m1.2.2.cmml" xref="S2.SS3.SSS2.p1.1.m1.2.2">4</cn><cn type="integer" id="S2.SS3.SSS2.p1.1.m1.3.3.cmml" xref="S2.SS3.SSS2.p1.1.m1.3.3">6</cn><ci id="S2.SS3.SSS2.p1.1.m1.4.4.cmml" xref="S2.SS3.SSS2.p1.1.m1.4.4">‚Ä¶</ci><cn type="integer" id="S2.SS3.SSS2.p1.1.m1.5.5.cmml" xref="S2.SS3.SSS2.p1.1.m1.5.5">18</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.1.m1.5c">r=\{2,\allowbreak 4,\allowbreak 6,\allowbreak...,\allowbreak 18\}</annotation></semantics></math> and <math id="S2.SS3.SSS2.p1.2.m2.5" class="ltx_Math" alttext="A=\{10,\allowbreak 50,\allowbreak 200,\allowbreak 1000,\allowbreak 10000\}" display="inline"><semantics id="S2.SS3.SSS2.p1.2.m2.5a"><mrow id="S2.SS3.SSS2.p1.2.m2.5.6" xref="S2.SS3.SSS2.p1.2.m2.5.6.cmml"><mi id="S2.SS3.SSS2.p1.2.m2.5.6.2" xref="S2.SS3.SSS2.p1.2.m2.5.6.2.cmml">A</mi><mo id="S2.SS3.SSS2.p1.2.m2.5.6.1" xref="S2.SS3.SSS2.p1.2.m2.5.6.1.cmml">=</mo><mrow id="S2.SS3.SSS2.p1.2.m2.5.6.3.2" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml"><mo stretchy="false" id="S2.SS3.SSS2.p1.2.m2.5.6.3.2.1" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml">{</mo><mn id="S2.SS3.SSS2.p1.2.m2.1.1" xref="S2.SS3.SSS2.p1.2.m2.1.1.cmml">10</mn><mo id="S2.SS3.SSS2.p1.2.m2.5.6.3.2.2" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.2.m2.2.2" xref="S2.SS3.SSS2.p1.2.m2.2.2.cmml">50</mn><mo id="S2.SS3.SSS2.p1.2.m2.5.6.3.2.3" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.2.m2.3.3" xref="S2.SS3.SSS2.p1.2.m2.3.3.cmml">200</mn><mo id="S2.SS3.SSS2.p1.2.m2.5.6.3.2.4" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.2.m2.4.4" xref="S2.SS3.SSS2.p1.2.m2.4.4.cmml">1000</mn><mo id="S2.SS3.SSS2.p1.2.m2.5.6.3.2.5" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S2.SS3.SSS2.p1.2.m2.5.5" xref="S2.SS3.SSS2.p1.2.m2.5.5.cmml">10000</mn><mo stretchy="false" id="S2.SS3.SSS2.p1.2.m2.5.6.3.2.6" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.2.m2.5b"><apply id="S2.SS3.SSS2.p1.2.m2.5.6.cmml" xref="S2.SS3.SSS2.p1.2.m2.5.6"><eq id="S2.SS3.SSS2.p1.2.m2.5.6.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.5.6.1"></eq><ci id="S2.SS3.SSS2.p1.2.m2.5.6.2.cmml" xref="S2.SS3.SSS2.p1.2.m2.5.6.2">ùê¥</ci><set id="S2.SS3.SSS2.p1.2.m2.5.6.3.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.5.6.3.2"><cn type="integer" id="S2.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1">10</cn><cn type="integer" id="S2.SS3.SSS2.p1.2.m2.2.2.cmml" xref="S2.SS3.SSS2.p1.2.m2.2.2">50</cn><cn type="integer" id="S2.SS3.SSS2.p1.2.m2.3.3.cmml" xref="S2.SS3.SSS2.p1.2.m2.3.3">200</cn><cn type="integer" id="S2.SS3.SSS2.p1.2.m2.4.4.cmml" xref="S2.SS3.SSS2.p1.2.m2.4.4">1000</cn><cn type="integer" id="S2.SS3.SSS2.p1.2.m2.5.5.cmml" xref="S2.SS3.SSS2.p1.2.m2.5.5">10000</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.2.m2.5c">A=\{10,\allowbreak 50,\allowbreak 200,\allowbreak 1000,\allowbreak 10000\}</annotation></semantics></math>, i.e., the same parameters as used for the evaluation on synthetic images (see the section ‚Äú<a href="#S2.SS4.SSS1" title="In 2.4 Evaluation ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref ltx_refmacro_nameref"><span class="ltx_text ltx_ref_title">Evaluation on synthetic images</span></a>‚Äù below). The center of each CR image was then estimated as the center-of-mass of all the pixels in the discretized CR image, using their intensity values¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>, <a href="#bib.bibx3" title="" class="ltx_ref">3</a>]</cite>. Unlike the synthetic images used for model evaluation, these images had a completely black background such that only pixel intensity values associated with the CR would influence the center estimate.</p>
</div>
</section>
<section id="S2.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3 </span>First &amp; Second Training Stages</h4>

<div id="S2.SS3.SSS3.p1" class="ltx_para">
<p id="S2.SS3.SSS3.p1.1" class="ltx_p">During the first training stage, the following parameters were used. Where possible, the parameters were set to ranges significantly larger than the set used for evaluation.</p>
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.3" class="ltx_p">CR radius <math id="S2.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.I2.i1.p1.1.m1.1a"><mi id="S2.I2.i1.p1.1.m1.1.1" xref="S2.I2.i1.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.1.m1.1b"><ci id="S2.I2.i1.p1.1.m1.1.1.cmml" xref="S2.I2.i1.p1.1.m1.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.1.m1.1c">r</annotation></semantics></math> was drawn from a uniform distribution with range <math id="S2.I2.i1.p1.2.m2.2" class="ltx_Math" alttext="[1,30]" display="inline"><semantics id="S2.I2.i1.p1.2.m2.2a"><mrow id="S2.I2.i1.p1.2.m2.2.3.2" xref="S2.I2.i1.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S2.I2.i1.p1.2.m2.2.3.2.1" xref="S2.I2.i1.p1.2.m2.2.3.1.cmml">[</mo><mn id="S2.I2.i1.p1.2.m2.1.1" xref="S2.I2.i1.p1.2.m2.1.1.cmml">1</mn><mo id="S2.I2.i1.p1.2.m2.2.3.2.2" xref="S2.I2.i1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.I2.i1.p1.2.m2.2.2" xref="S2.I2.i1.p1.2.m2.2.2.cmml">30</mn><mo stretchy="false" id="S2.I2.i1.p1.2.m2.2.3.2.3" xref="S2.I2.i1.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.2.m2.2b"><interval closure="closed" id="S2.I2.i1.p1.2.m2.2.3.1.cmml" xref="S2.I2.i1.p1.2.m2.2.3.2"><cn type="integer" id="S2.I2.i1.p1.2.m2.1.1.cmml" xref="S2.I2.i1.p1.2.m2.1.1">1</cn><cn type="integer" id="S2.I2.i1.p1.2.m2.2.2.cmml" xref="S2.I2.i1.p1.2.m2.2.2">30</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.2.m2.2c">[1,30]</annotation></semantics></math> pixels. This was chosen to be wider than our testing range of <math id="S2.I2.i1.p1.3.m3.2" class="ltx_Math" alttext="[2,18]" display="inline"><semantics id="S2.I2.i1.p1.3.m3.2a"><mrow id="S2.I2.i1.p1.3.m3.2.3.2" xref="S2.I2.i1.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S2.I2.i1.p1.3.m3.2.3.2.1" xref="S2.I2.i1.p1.3.m3.2.3.1.cmml">[</mo><mn id="S2.I2.i1.p1.3.m3.1.1" xref="S2.I2.i1.p1.3.m3.1.1.cmml">2</mn><mo id="S2.I2.i1.p1.3.m3.2.3.2.2" xref="S2.I2.i1.p1.3.m3.2.3.1.cmml">,</mo><mn id="S2.I2.i1.p1.3.m3.2.2" xref="S2.I2.i1.p1.3.m3.2.2.cmml">18</mn><mo stretchy="false" id="S2.I2.i1.p1.3.m3.2.3.2.3" xref="S2.I2.i1.p1.3.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.3.m3.2b"><interval closure="closed" id="S2.I2.i1.p1.3.m3.2.3.1.cmml" xref="S2.I2.i1.p1.3.m3.2.3.2"><cn type="integer" id="S2.I2.i1.p1.3.m3.1.1.cmml" xref="S2.I2.i1.p1.3.m3.1.1">2</cn><cn type="integer" id="S2.I2.i1.p1.3.m3.2.2.cmml" xref="S2.I2.i1.p1.3.m3.2.2">18</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.3.m3.2c">[2,18]</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, like was used in]</cite>]Nystroem2022 and also encompasses the range of CR sizes one may reasonably expect to encounter in real eye images.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.2" class="ltx_p">Location: Horizontal and vertical CR center locations were drawn from uniform distributions. To ensure that the CR would not be significantly cut off by the edge of the image, the range of both uniform distributions depended on the CR size (<math id="S2.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.I2.i2.p1.1.m1.1a"><mi id="S2.I2.i2.p1.1.m1.1.1" xref="S2.I2.i2.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.1.m1.1b"><ci id="S2.I2.i2.p1.1.m1.1.1.cmml" xref="S2.I2.i2.p1.1.m1.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.1.m1.1c">r</annotation></semantics></math>). Specifically, they spanned <math id="S2.I2.i2.p1.2.m2.2" class="ltx_Math" alttext="[r,180-r]" display="inline"><semantics id="S2.I2.i2.p1.2.m2.2a"><mrow id="S2.I2.i2.p1.2.m2.2.2.1" xref="S2.I2.i2.p1.2.m2.2.2.2.cmml"><mo stretchy="false" id="S2.I2.i2.p1.2.m2.2.2.1.2" xref="S2.I2.i2.p1.2.m2.2.2.2.cmml">[</mo><mi id="S2.I2.i2.p1.2.m2.1.1" xref="S2.I2.i2.p1.2.m2.1.1.cmml">r</mi><mo id="S2.I2.i2.p1.2.m2.2.2.1.3" xref="S2.I2.i2.p1.2.m2.2.2.2.cmml">,</mo><mrow id="S2.I2.i2.p1.2.m2.2.2.1.1" xref="S2.I2.i2.p1.2.m2.2.2.1.1.cmml"><mn id="S2.I2.i2.p1.2.m2.2.2.1.1.2" xref="S2.I2.i2.p1.2.m2.2.2.1.1.2.cmml">180</mn><mo id="S2.I2.i2.p1.2.m2.2.2.1.1.1" xref="S2.I2.i2.p1.2.m2.2.2.1.1.1.cmml">‚àí</mo><mi id="S2.I2.i2.p1.2.m2.2.2.1.1.3" xref="S2.I2.i2.p1.2.m2.2.2.1.1.3.cmml">r</mi></mrow><mo stretchy="false" id="S2.I2.i2.p1.2.m2.2.2.1.4" xref="S2.I2.i2.p1.2.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.2.m2.2b"><interval closure="closed" id="S2.I2.i2.p1.2.m2.2.2.2.cmml" xref="S2.I2.i2.p1.2.m2.2.2.1"><ci id="S2.I2.i2.p1.2.m2.1.1.cmml" xref="S2.I2.i2.p1.2.m2.1.1">ùëü</ci><apply id="S2.I2.i2.p1.2.m2.2.2.1.1.cmml" xref="S2.I2.i2.p1.2.m2.2.2.1.1"><minus id="S2.I2.i2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.I2.i2.p1.2.m2.2.2.1.1.1"></minus><cn type="integer" id="S2.I2.i2.p1.2.m2.2.2.1.1.2.cmml" xref="S2.I2.i2.p1.2.m2.2.2.1.1.2">180</cn><ci id="S2.I2.i2.p1.2.m2.2.2.1.1.3.cmml" xref="S2.I2.i2.p1.2.m2.2.2.1.1.3">ùëü</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.2.m2.2c">[r,180-r]</annotation></semantics></math> pixels, where 180 pixels is the image size.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.2" class="ltx_p">Gaussian amplitudes <math id="S2.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.I2.i3.p1.1.m1.1a"><mi id="S2.I2.i3.p1.1.m1.1.1" xref="S2.I2.i3.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i3.p1.1.m1.1b"><ci id="S2.I2.i3.p1.1.m1.1.1.cmml" xref="S2.I2.i3.p1.1.m1.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i3.p1.1.m1.1c">A</annotation></semantics></math> were drawn from a uniform distribution with range <math id="S2.I2.i3.p1.2.m2.2" class="ltx_Math" alttext="[2,20000]" display="inline"><semantics id="S2.I2.i3.p1.2.m2.2a"><mrow id="S2.I2.i3.p1.2.m2.2.3.2" xref="S2.I2.i3.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S2.I2.i3.p1.2.m2.2.3.2.1" xref="S2.I2.i3.p1.2.m2.2.3.1.cmml">[</mo><mn id="S2.I2.i3.p1.2.m2.1.1" xref="S2.I2.i3.p1.2.m2.1.1.cmml">2</mn><mo id="S2.I2.i3.p1.2.m2.2.3.2.2" xref="S2.I2.i3.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.I2.i3.p1.2.m2.2.2" xref="S2.I2.i3.p1.2.m2.2.2.cmml">20000</mn><mo stretchy="false" id="S2.I2.i3.p1.2.m2.2.3.2.3" xref="S2.I2.i3.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i3.p1.2.m2.2b"><interval closure="closed" id="S2.I2.i3.p1.2.m2.2.3.1.cmml" xref="S2.I2.i3.p1.2.m2.2.3.2"><cn type="integer" id="S2.I2.i3.p1.2.m2.1.1.cmml" xref="S2.I2.i3.p1.2.m2.1.1">2</cn><cn type="integer" id="S2.I2.i3.p1.2.m2.2.2.cmml" xref="S2.I2.i3.p1.2.m2.2.2">20000</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i3.p1.2.m2.2c">[2,20000]</annotation></semantics></math>. The range of this parameter was decided by means of manual inspection of the output to provide a range of different tail widths (c.f. Figure <a href="#S2.F2" title="Figure 2 ‚Ä£ 2.3 Generating Synthetic Images ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.4" class="ltx_p">The horizontal and vertical coordinates of a point on the line dividing the two sections of the background were drawn from a normal distribution centered on the CR center location and spanning a standard deviation of <math id="S2.I2.i4.p1.1.m1.1" class="ltx_Math" alttext="-1.5r" display="inline"><semantics id="S2.I2.i4.p1.1.m1.1a"><mrow id="S2.I2.i4.p1.1.m1.1.1" xref="S2.I2.i4.p1.1.m1.1.1.cmml"><mo id="S2.I2.i4.p1.1.m1.1.1a" xref="S2.I2.i4.p1.1.m1.1.1.cmml">‚àí</mo><mrow id="S2.I2.i4.p1.1.m1.1.1.2" xref="S2.I2.i4.p1.1.m1.1.1.2.cmml"><mn id="S2.I2.i4.p1.1.m1.1.1.2.2" xref="S2.I2.i4.p1.1.m1.1.1.2.2.cmml">1.5</mn><mo lspace="0em" rspace="0em" id="S2.I2.i4.p1.1.m1.1.1.2.1" xref="S2.I2.i4.p1.1.m1.1.1.2.1.cmml">‚Äã</mo><mi id="S2.I2.i4.p1.1.m1.1.1.2.3" xref="S2.I2.i4.p1.1.m1.1.1.2.3.cmml">r</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i4.p1.1.m1.1b"><apply id="S2.I2.i4.p1.1.m1.1.1.cmml" xref="S2.I2.i4.p1.1.m1.1.1"><minus id="S2.I2.i4.p1.1.m1.1.1.1.cmml" xref="S2.I2.i4.p1.1.m1.1.1"></minus><apply id="S2.I2.i4.p1.1.m1.1.1.2.cmml" xref="S2.I2.i4.p1.1.m1.1.1.2"><times id="S2.I2.i4.p1.1.m1.1.1.2.1.cmml" xref="S2.I2.i4.p1.1.m1.1.1.2.1"></times><cn type="float" id="S2.I2.i4.p1.1.m1.1.1.2.2.cmml" xref="S2.I2.i4.p1.1.m1.1.1.2.2">1.5</cn><ci id="S2.I2.i4.p1.1.m1.1.1.2.3.cmml" xref="S2.I2.i4.p1.1.m1.1.1.2.3">ùëü</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i4.p1.1.m1.1c">-1.5r</annotation></semantics></math>. A random orientation of this line was then drawn from a uniform distribution with range <math id="S2.I2.i4.p1.2.m2.2" class="ltx_Math" alttext="[0,2\pi]" display="inline"><semantics id="S2.I2.i4.p1.2.m2.2a"><mrow id="S2.I2.i4.p1.2.m2.2.2.1" xref="S2.I2.i4.p1.2.m2.2.2.2.cmml"><mo stretchy="false" id="S2.I2.i4.p1.2.m2.2.2.1.2" xref="S2.I2.i4.p1.2.m2.2.2.2.cmml">[</mo><mn id="S2.I2.i4.p1.2.m2.1.1" xref="S2.I2.i4.p1.2.m2.1.1.cmml">0</mn><mo id="S2.I2.i4.p1.2.m2.2.2.1.3" xref="S2.I2.i4.p1.2.m2.2.2.2.cmml">,</mo><mrow id="S2.I2.i4.p1.2.m2.2.2.1.1" xref="S2.I2.i4.p1.2.m2.2.2.1.1.cmml"><mn id="S2.I2.i4.p1.2.m2.2.2.1.1.2" xref="S2.I2.i4.p1.2.m2.2.2.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.I2.i4.p1.2.m2.2.2.1.1.1" xref="S2.I2.i4.p1.2.m2.2.2.1.1.1.cmml">‚Äã</mo><mi id="S2.I2.i4.p1.2.m2.2.2.1.1.3" xref="S2.I2.i4.p1.2.m2.2.2.1.1.3.cmml">œÄ</mi></mrow><mo stretchy="false" id="S2.I2.i4.p1.2.m2.2.2.1.4" xref="S2.I2.i4.p1.2.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i4.p1.2.m2.2b"><interval closure="closed" id="S2.I2.i4.p1.2.m2.2.2.2.cmml" xref="S2.I2.i4.p1.2.m2.2.2.1"><cn type="integer" id="S2.I2.i4.p1.2.m2.1.1.cmml" xref="S2.I2.i4.p1.2.m2.1.1">0</cn><apply id="S2.I2.i4.p1.2.m2.2.2.1.1.cmml" xref="S2.I2.i4.p1.2.m2.2.2.1.1"><times id="S2.I2.i4.p1.2.m2.2.2.1.1.1.cmml" xref="S2.I2.i4.p1.2.m2.2.2.1.1.1"></times><cn type="integer" id="S2.I2.i4.p1.2.m2.2.2.1.1.2.cmml" xref="S2.I2.i4.p1.2.m2.2.2.1.1.2">2</cn><ci id="S2.I2.i4.p1.2.m2.2.2.1.1.3.cmml" xref="S2.I2.i4.p1.2.m2.2.2.1.1.3">ùúã</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i4.p1.2.m2.2c">[0,2\pi]</annotation></semantics></math>. The edge between the two segments was smoothed with a raised cosine profile spanning 4 pixels. The pixel intensity value of the dark section of the background was drawn from an exponential distribution with its scale parameter set to 10 pixel intensity values, and offset 1 (so that full black did not occur). The pixel intensity level of the lighter section <math id="S2.I2.i4.p1.3.m3.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S2.I2.i4.p1.3.m3.1a"><mi id="S2.I2.i4.p1.3.m3.1.1" xref="S2.I2.i4.p1.3.m3.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i4.p1.3.m3.1b"><ci id="S2.I2.i4.p1.3.m3.1.1.cmml" xref="S2.I2.i4.p1.3.m3.1.1">ùêº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i4.p1.3.m3.1c">I</annotation></semantics></math> was drawn from a uniform distribution with a range of <math id="S2.I2.i4.p1.4.m4.2" class="ltx_Math" alttext="[32,153]" display="inline"><semantics id="S2.I2.i4.p1.4.m4.2a"><mrow id="S2.I2.i4.p1.4.m4.2.3.2" xref="S2.I2.i4.p1.4.m4.2.3.1.cmml"><mo stretchy="false" id="S2.I2.i4.p1.4.m4.2.3.2.1" xref="S2.I2.i4.p1.4.m4.2.3.1.cmml">[</mo><mn id="S2.I2.i4.p1.4.m4.1.1" xref="S2.I2.i4.p1.4.m4.1.1.cmml">32</mn><mo id="S2.I2.i4.p1.4.m4.2.3.2.2" xref="S2.I2.i4.p1.4.m4.2.3.1.cmml">,</mo><mn id="S2.I2.i4.p1.4.m4.2.2" xref="S2.I2.i4.p1.4.m4.2.2.cmml">153</mn><mo stretchy="false" id="S2.I2.i4.p1.4.m4.2.3.2.3" xref="S2.I2.i4.p1.4.m4.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i4.p1.4.m4.2b"><interval closure="closed" id="S2.I2.i4.p1.4.m4.2.3.1.cmml" xref="S2.I2.i4.p1.4.m4.2.3.2"><cn type="integer" id="S2.I2.i4.p1.4.m4.1.1.cmml" xref="S2.I2.i4.p1.4.m4.1.1">32</cn><cn type="integer" id="S2.I2.i4.p1.4.m4.2.2.cmml" xref="S2.I2.i4.p1.4.m4.2.2">153</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i4.p1.4.m4.2c">[32,153]</annotation></semantics></math> pixel intensity values.</p>
</div>
</li>
<li id="S2.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S2.I2.i5.p1" class="ltx_para">
<p id="S2.I2.i5.p1.2" class="ltx_p">The pixel noise <math id="S2.I2.i5.p1.1.m1.1" class="ltx_Math" alttext="\sigma_{n}" display="inline"><semantics id="S2.I2.i5.p1.1.m1.1a"><msub id="S2.I2.i5.p1.1.m1.1.1" xref="S2.I2.i5.p1.1.m1.1.1.cmml"><mi id="S2.I2.i5.p1.1.m1.1.1.2" xref="S2.I2.i5.p1.1.m1.1.1.2.cmml">œÉ</mi><mi id="S2.I2.i5.p1.1.m1.1.1.3" xref="S2.I2.i5.p1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I2.i5.p1.1.m1.1b"><apply id="S2.I2.i5.p1.1.m1.1.1.cmml" xref="S2.I2.i5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i5.p1.1.m1.1.1.1.cmml" xref="S2.I2.i5.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I2.i5.p1.1.m1.1.1.2.cmml" xref="S2.I2.i5.p1.1.m1.1.1.2">ùúé</ci><ci id="S2.I2.i5.p1.1.m1.1.1.3.cmml" xref="S2.I2.i5.p1.1.m1.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i5.p1.1.m1.1c">\sigma_{n}</annotation></semantics></math> was drawn from a uniform distribution with range <math id="S2.I2.i5.p1.2.m2.2" class="ltx_Math" alttext="[0,30]" display="inline"><semantics id="S2.I2.i5.p1.2.m2.2a"><mrow id="S2.I2.i5.p1.2.m2.2.3.2" xref="S2.I2.i5.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S2.I2.i5.p1.2.m2.2.3.2.1" xref="S2.I2.i5.p1.2.m2.2.3.1.cmml">[</mo><mn id="S2.I2.i5.p1.2.m2.1.1" xref="S2.I2.i5.p1.2.m2.1.1.cmml">0</mn><mo id="S2.I2.i5.p1.2.m2.2.3.2.2" xref="S2.I2.i5.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.I2.i5.p1.2.m2.2.2" xref="S2.I2.i5.p1.2.m2.2.2.cmml">30</mn><mo stretchy="false" id="S2.I2.i5.p1.2.m2.2.3.2.3" xref="S2.I2.i5.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i5.p1.2.m2.2b"><interval closure="closed" id="S2.I2.i5.p1.2.m2.2.3.1.cmml" xref="S2.I2.i5.p1.2.m2.2.3.2"><cn type="integer" id="S2.I2.i5.p1.2.m2.1.1.cmml" xref="S2.I2.i5.p1.2.m2.1.1">0</cn><cn type="integer" id="S2.I2.i5.p1.2.m2.2.2.cmml" xref="S2.I2.i5.p1.2.m2.2.2">30</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i5.p1.2.m2.2c">[0,30]</annotation></semantics></math> pixel intensity values.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS3.SSS3.p2" class="ltx_para">
<p id="S2.SS3.SSS3.p2.1" class="ltx_p">In the second training stage, all parameters except CR location were set to the same ranges as were used in the first stage. Since the CNN will only be used on image patches where the CR has already been centered, horizontal and vertical CR center locations in this second pass were drawn from uniform distributions with ranges spanning 1.5 pixels around the center of the output image, i.e. <math id="S2.SS3.SSS3.p2.1.m1.2" class="ltx_Math" alttext="[89.25,90.75]" display="inline"><semantics id="S2.SS3.SSS3.p2.1.m1.2a"><mrow id="S2.SS3.SSS3.p2.1.m1.2.3.2" xref="S2.SS3.SSS3.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S2.SS3.SSS3.p2.1.m1.2.3.2.1" xref="S2.SS3.SSS3.p2.1.m1.2.3.1.cmml">[</mo><mn id="S2.SS3.SSS3.p2.1.m1.1.1" xref="S2.SS3.SSS3.p2.1.m1.1.1.cmml">89.25</mn><mo id="S2.SS3.SSS3.p2.1.m1.2.3.2.2" xref="S2.SS3.SSS3.p2.1.m1.2.3.1.cmml">,</mo><mn id="S2.SS3.SSS3.p2.1.m1.2.2" xref="S2.SS3.SSS3.p2.1.m1.2.2.cmml">90.75</mn><mo stretchy="false" id="S2.SS3.SSS3.p2.1.m1.2.3.2.3" xref="S2.SS3.SSS3.p2.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS3.p2.1.m1.2b"><interval closure="closed" id="S2.SS3.SSS3.p2.1.m1.2.3.1.cmml" xref="S2.SS3.SSS3.p2.1.m1.2.3.2"><cn type="float" id="S2.SS3.SSS3.p2.1.m1.1.1.cmml" xref="S2.SS3.SSS3.p2.1.m1.1.1">89.25</cn><cn type="float" id="S2.SS3.SSS3.p2.1.m1.2.2.cmml" xref="S2.SS3.SSS3.p2.1.m1.2.2">90.75</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS3.p2.1.m1.2c">[89.25,90.75]</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Evaluation</h3>

<section id="S2.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1 </span>Evaluation on synthetic images</h4>

<div id="S2.SS4.SSS1.p1" class="ltx_para">
<p id="S2.SS4.SSS1.p1.2" class="ltx_p">To investigate how accurately the center of the CR can be located by the various methods, an input light distribution with horizontal center <math id="S2.SS4.SSS1.p1.1.m1.1" class="ltx_Math" alttext="x_{c}" display="inline"><semantics id="S2.SS4.SSS1.p1.1.m1.1a"><msub id="S2.SS4.SSS1.p1.1.m1.1.1" xref="S2.SS4.SSS1.p1.1.m1.1.1.cmml"><mi id="S2.SS4.SSS1.p1.1.m1.1.1.2" xref="S2.SS4.SSS1.p1.1.m1.1.1.2.cmml">x</mi><mi id="S2.SS4.SSS1.p1.1.m1.1.1.3" xref="S2.SS4.SSS1.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.1.m1.1b"><apply id="S2.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.1.m1.1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p1.1.m1.1.1.2.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1.2">ùë•</ci><ci id="S2.SS4.SSS1.p1.1.m1.1.1.3.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.1.m1.1c">x_{c}</annotation></semantics></math> was moved in small steps (<math id="S2.SS4.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\delta_{x_{c}}=0.01" display="inline"><semantics id="S2.SS4.SSS1.p1.2.m2.1a"><mrow id="S2.SS4.SSS1.p1.2.m2.1.1" xref="S2.SS4.SSS1.p1.2.m2.1.1.cmml"><msub id="S2.SS4.SSS1.p1.2.m2.1.1.2" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.cmml"><mi id="S2.SS4.SSS1.p1.2.m2.1.1.2.2" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.2.cmml">Œ¥</mi><msub id="S2.SS4.SSS1.p1.2.m2.1.1.2.3" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3.cmml"><mi id="S2.SS4.SSS1.p1.2.m2.1.1.2.3.2" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3.2.cmml">x</mi><mi id="S2.SS4.SSS1.p1.2.m2.1.1.2.3.3" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3.3.cmml">c</mi></msub></msub><mo id="S2.SS4.SSS1.p1.2.m2.1.1.1" xref="S2.SS4.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S2.SS4.SSS1.p1.2.m2.1.1.3" xref="S2.SS4.SSS1.p1.2.m2.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.2.m2.1b"><apply id="S2.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1"><eq id="S2.SS4.SSS1.p1.2.m2.1.1.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.1"></eq><apply id="S2.SS4.SSS1.p1.2.m2.1.1.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS4.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.2">ùõø</ci><apply id="S2.SS4.SSS1.p1.2.m2.1.1.2.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.2.m2.1.1.2.3.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3">subscript</csymbol><ci id="S2.SS4.SSS1.p1.2.m2.1.1.2.3.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3.2">ùë•</ci><ci id="S2.SS4.SSS1.p1.2.m2.1.1.2.3.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.2.3.3">ùëê</ci></apply></apply><cn type="float" id="S2.SS4.SSS1.p1.2.m2.1.1.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.2.m2.1c">\delta_{x_{c}}=0.01</annotation></semantics></math>) over a one-pixel range (100 steps). The input position was then compared to the output of three methods: 1) the traditional thresholding method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>; 2) the radial symmetry algorithm of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite>; and 3) the CNN developed in this paper. A fourth method which simply computes the center of mass of all the pixels in the input image <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, called the intensity-based method in]</cite>]Nystroem2022 was discarded after initial investigation since this method produced very large errors on our evaluation images due to the partially grey background.</p>
</div>
<div id="S2.SS4.SSS1.p2" class="ltx_para">
<p id="S2.SS4.SSS1.p2.16" class="ltx_p">The evaluation was performed at several CR radii <math id="S2.SS4.SSS1.p2.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.SS4.SSS1.p2.1.m1.1a"><mi id="S2.SS4.SSS1.p2.1.m1.1.1" xref="S2.SS4.SSS1.p2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.1.m1.1b"><ci id="S2.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p2.1.m1.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.1.m1.1c">r</annotation></semantics></math>, Gaussian amplitudes <math id="S2.SS4.SSS1.p2.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.SS4.SSS1.p2.2.m2.1a"><mi id="S2.SS4.SSS1.p2.2.m2.1.1" xref="S2.SS4.SSS1.p2.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.2.m2.1b"><ci id="S2.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p2.2.m2.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.2.m2.1c">A</annotation></semantics></math>, gray background locations <math id="S2.SS4.SSS1.p2.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.SS4.SSS1.p2.3.m3.1a"><mi id="S2.SS4.SSS1.p2.3.m3.1.1" xref="S2.SS4.SSS1.p2.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.3.m3.1b"><ci id="S2.SS4.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS4.SSS1.p2.3.m3.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.3.m3.1c">E</annotation></semantics></math>, pixel intensity values <math id="S2.SS4.SSS1.p2.4.m4.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S2.SS4.SSS1.p2.4.m4.1a"><mi id="S2.SS4.SSS1.p2.4.m4.1.1" xref="S2.SS4.SSS1.p2.4.m4.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.4.m4.1b"><ci id="S2.SS4.SSS1.p2.4.m4.1.1.cmml" xref="S2.SS4.SSS1.p2.4.m4.1.1">ùêº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.4.m4.1c">I</annotation></semantics></math> of the lighter part of the background and noise levels <math id="S2.SS4.SSS1.p2.5.m5.1" class="ltx_Math" alttext="\sigma_{n}" display="inline"><semantics id="S2.SS4.SSS1.p2.5.m5.1a"><msub id="S2.SS4.SSS1.p2.5.m5.1.1" xref="S2.SS4.SSS1.p2.5.m5.1.1.cmml"><mi id="S2.SS4.SSS1.p2.5.m5.1.1.2" xref="S2.SS4.SSS1.p2.5.m5.1.1.2.cmml">œÉ</mi><mi id="S2.SS4.SSS1.p2.5.m5.1.1.3" xref="S2.SS4.SSS1.p2.5.m5.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.5.m5.1b"><apply id="S2.SS4.SSS1.p2.5.m5.1.1.cmml" xref="S2.SS4.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p2.5.m5.1.1.1.cmml" xref="S2.SS4.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p2.5.m5.1.1.2.cmml" xref="S2.SS4.SSS1.p2.5.m5.1.1.2">ùúé</ci><ci id="S2.SS4.SSS1.p2.5.m5.1.1.3.cmml" xref="S2.SS4.SSS1.p2.5.m5.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.5.m5.1c">\sigma_{n}</annotation></semantics></math>. Specifically, the testing set consisted of the Cartesian product of <math id="S2.SS4.SSS1.p2.6.m6.5" class="ltx_Math" alttext="r=\{2,\allowbreak 4,\allowbreak 6,\allowbreak...,\allowbreak 18\}" display="inline"><semantics id="S2.SS4.SSS1.p2.6.m6.5a"><mrow id="S2.SS4.SSS1.p2.6.m6.5.6" xref="S2.SS4.SSS1.p2.6.m6.5.6.cmml"><mi id="S2.SS4.SSS1.p2.6.m6.5.6.2" xref="S2.SS4.SSS1.p2.6.m6.5.6.2.cmml">r</mi><mo id="S2.SS4.SSS1.p2.6.m6.5.6.1" xref="S2.SS4.SSS1.p2.6.m6.5.6.1.cmml">=</mo><mrow id="S2.SS4.SSS1.p2.6.m6.5.6.3.2" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml"><mo stretchy="false" id="S2.SS4.SSS1.p2.6.m6.5.6.3.2.1" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml">{</mo><mn id="S2.SS4.SSS1.p2.6.m6.1.1" xref="S2.SS4.SSS1.p2.6.m6.1.1.cmml">2</mn><mo id="S2.SS4.SSS1.p2.6.m6.5.6.3.2.2" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.6.m6.2.2" xref="S2.SS4.SSS1.p2.6.m6.2.2.cmml">4</mn><mo id="S2.SS4.SSS1.p2.6.m6.5.6.3.2.3" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.6.m6.3.3" xref="S2.SS4.SSS1.p2.6.m6.3.3.cmml">6</mn><mo id="S2.SS4.SSS1.p2.6.m6.5.6.3.2.4" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS4.SSS1.p2.6.m6.4.4" xref="S2.SS4.SSS1.p2.6.m6.4.4.cmml">‚Ä¶</mi><mo id="S2.SS4.SSS1.p2.6.m6.5.6.3.2.5" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.6.m6.5.5" xref="S2.SS4.SSS1.p2.6.m6.5.5.cmml">18</mn><mo stretchy="false" id="S2.SS4.SSS1.p2.6.m6.5.6.3.2.6" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.6.m6.5b"><apply id="S2.SS4.SSS1.p2.6.m6.5.6.cmml" xref="S2.SS4.SSS1.p2.6.m6.5.6"><eq id="S2.SS4.SSS1.p2.6.m6.5.6.1.cmml" xref="S2.SS4.SSS1.p2.6.m6.5.6.1"></eq><ci id="S2.SS4.SSS1.p2.6.m6.5.6.2.cmml" xref="S2.SS4.SSS1.p2.6.m6.5.6.2">ùëü</ci><set id="S2.SS4.SSS1.p2.6.m6.5.6.3.1.cmml" xref="S2.SS4.SSS1.p2.6.m6.5.6.3.2"><cn type="integer" id="S2.SS4.SSS1.p2.6.m6.1.1.cmml" xref="S2.SS4.SSS1.p2.6.m6.1.1">2</cn><cn type="integer" id="S2.SS4.SSS1.p2.6.m6.2.2.cmml" xref="S2.SS4.SSS1.p2.6.m6.2.2">4</cn><cn type="integer" id="S2.SS4.SSS1.p2.6.m6.3.3.cmml" xref="S2.SS4.SSS1.p2.6.m6.3.3">6</cn><ci id="S2.SS4.SSS1.p2.6.m6.4.4.cmml" xref="S2.SS4.SSS1.p2.6.m6.4.4">‚Ä¶</ci><cn type="integer" id="S2.SS4.SSS1.p2.6.m6.5.5.cmml" xref="S2.SS4.SSS1.p2.6.m6.5.5">18</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.6.m6.5c">r=\{2,\allowbreak 4,\allowbreak 6,\allowbreak...,\allowbreak 18\}</annotation></semantics></math>, <math id="S2.SS4.SSS1.p2.7.m7.5" class="ltx_Math" alttext="A=\{10,\allowbreak 50,\allowbreak 200,\allowbreak 1000,\allowbreak 10000\}" display="inline"><semantics id="S2.SS4.SSS1.p2.7.m7.5a"><mrow id="S2.SS4.SSS1.p2.7.m7.5.6" xref="S2.SS4.SSS1.p2.7.m7.5.6.cmml"><mi id="S2.SS4.SSS1.p2.7.m7.5.6.2" xref="S2.SS4.SSS1.p2.7.m7.5.6.2.cmml">A</mi><mo id="S2.SS4.SSS1.p2.7.m7.5.6.1" xref="S2.SS4.SSS1.p2.7.m7.5.6.1.cmml">=</mo><mrow id="S2.SS4.SSS1.p2.7.m7.5.6.3.2" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml"><mo stretchy="false" id="S2.SS4.SSS1.p2.7.m7.5.6.3.2.1" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml">{</mo><mn id="S2.SS4.SSS1.p2.7.m7.1.1" xref="S2.SS4.SSS1.p2.7.m7.1.1.cmml">10</mn><mo id="S2.SS4.SSS1.p2.7.m7.5.6.3.2.2" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.7.m7.2.2" xref="S2.SS4.SSS1.p2.7.m7.2.2.cmml">50</mn><mo id="S2.SS4.SSS1.p2.7.m7.5.6.3.2.3" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.7.m7.3.3" xref="S2.SS4.SSS1.p2.7.m7.3.3.cmml">200</mn><mo id="S2.SS4.SSS1.p2.7.m7.5.6.3.2.4" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.7.m7.4.4" xref="S2.SS4.SSS1.p2.7.m7.4.4.cmml">1000</mn><mo id="S2.SS4.SSS1.p2.7.m7.5.6.3.2.5" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.7.m7.5.5" xref="S2.SS4.SSS1.p2.7.m7.5.5.cmml">10000</mn><mo stretchy="false" id="S2.SS4.SSS1.p2.7.m7.5.6.3.2.6" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.7.m7.5b"><apply id="S2.SS4.SSS1.p2.7.m7.5.6.cmml" xref="S2.SS4.SSS1.p2.7.m7.5.6"><eq id="S2.SS4.SSS1.p2.7.m7.5.6.1.cmml" xref="S2.SS4.SSS1.p2.7.m7.5.6.1"></eq><ci id="S2.SS4.SSS1.p2.7.m7.5.6.2.cmml" xref="S2.SS4.SSS1.p2.7.m7.5.6.2">ùê¥</ci><set id="S2.SS4.SSS1.p2.7.m7.5.6.3.1.cmml" xref="S2.SS4.SSS1.p2.7.m7.5.6.3.2"><cn type="integer" id="S2.SS4.SSS1.p2.7.m7.1.1.cmml" xref="S2.SS4.SSS1.p2.7.m7.1.1">10</cn><cn type="integer" id="S2.SS4.SSS1.p2.7.m7.2.2.cmml" xref="S2.SS4.SSS1.p2.7.m7.2.2">50</cn><cn type="integer" id="S2.SS4.SSS1.p2.7.m7.3.3.cmml" xref="S2.SS4.SSS1.p2.7.m7.3.3">200</cn><cn type="integer" id="S2.SS4.SSS1.p2.7.m7.4.4.cmml" xref="S2.SS4.SSS1.p2.7.m7.4.4">1000</cn><cn type="integer" id="S2.SS4.SSS1.p2.7.m7.5.5.cmml" xref="S2.SS4.SSS1.p2.7.m7.5.5">10000</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.7.m7.5c">A=\{10,\allowbreak 50,\allowbreak 200,\allowbreak 1000,\allowbreak 10000\}</annotation></semantics></math>, <math id="S2.SS4.SSS1.p2.8.m8.5" class="ltx_Math" alttext="\sigma_{n}=\{0,\allowbreak 2,\allowbreak 4,\allowbreak...,\allowbreak 18\}" display="inline"><semantics id="S2.SS4.SSS1.p2.8.m8.5a"><mrow id="S2.SS4.SSS1.p2.8.m8.5.6" xref="S2.SS4.SSS1.p2.8.m8.5.6.cmml"><msub id="S2.SS4.SSS1.p2.8.m8.5.6.2" xref="S2.SS4.SSS1.p2.8.m8.5.6.2.cmml"><mi id="S2.SS4.SSS1.p2.8.m8.5.6.2.2" xref="S2.SS4.SSS1.p2.8.m8.5.6.2.2.cmml">œÉ</mi><mi id="S2.SS4.SSS1.p2.8.m8.5.6.2.3" xref="S2.SS4.SSS1.p2.8.m8.5.6.2.3.cmml">n</mi></msub><mo id="S2.SS4.SSS1.p2.8.m8.5.6.1" xref="S2.SS4.SSS1.p2.8.m8.5.6.1.cmml">=</mo><mrow id="S2.SS4.SSS1.p2.8.m8.5.6.3.2" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml"><mo stretchy="false" id="S2.SS4.SSS1.p2.8.m8.5.6.3.2.1" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml">{</mo><mn id="S2.SS4.SSS1.p2.8.m8.1.1" xref="S2.SS4.SSS1.p2.8.m8.1.1.cmml">0</mn><mo id="S2.SS4.SSS1.p2.8.m8.5.6.3.2.2" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.8.m8.2.2" xref="S2.SS4.SSS1.p2.8.m8.2.2.cmml">2</mn><mo id="S2.SS4.SSS1.p2.8.m8.5.6.3.2.3" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.8.m8.3.3" xref="S2.SS4.SSS1.p2.8.m8.3.3.cmml">4</mn><mo id="S2.SS4.SSS1.p2.8.m8.5.6.3.2.4" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS4.SSS1.p2.8.m8.4.4" xref="S2.SS4.SSS1.p2.8.m8.4.4.cmml">‚Ä¶</mi><mo id="S2.SS4.SSS1.p2.8.m8.5.6.3.2.5" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.8.m8.5.5" xref="S2.SS4.SSS1.p2.8.m8.5.5.cmml">18</mn><mo stretchy="false" id="S2.SS4.SSS1.p2.8.m8.5.6.3.2.6" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.8.m8.5b"><apply id="S2.SS4.SSS1.p2.8.m8.5.6.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6"><eq id="S2.SS4.SSS1.p2.8.m8.5.6.1.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6.1"></eq><apply id="S2.SS4.SSS1.p2.8.m8.5.6.2.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6.2"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p2.8.m8.5.6.2.1.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6.2">subscript</csymbol><ci id="S2.SS4.SSS1.p2.8.m8.5.6.2.2.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6.2.2">ùúé</ci><ci id="S2.SS4.SSS1.p2.8.m8.5.6.2.3.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6.2.3">ùëõ</ci></apply><set id="S2.SS4.SSS1.p2.8.m8.5.6.3.1.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.6.3.2"><cn type="integer" id="S2.SS4.SSS1.p2.8.m8.1.1.cmml" xref="S2.SS4.SSS1.p2.8.m8.1.1">0</cn><cn type="integer" id="S2.SS4.SSS1.p2.8.m8.2.2.cmml" xref="S2.SS4.SSS1.p2.8.m8.2.2">2</cn><cn type="integer" id="S2.SS4.SSS1.p2.8.m8.3.3.cmml" xref="S2.SS4.SSS1.p2.8.m8.3.3">4</cn><ci id="S2.SS4.SSS1.p2.8.m8.4.4.cmml" xref="S2.SS4.SSS1.p2.8.m8.4.4">‚Ä¶</ci><cn type="integer" id="S2.SS4.SSS1.p2.8.m8.5.5.cmml" xref="S2.SS4.SSS1.p2.8.m8.5.5">18</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.8.m8.5c">\sigma_{n}=\{0,\allowbreak 2,\allowbreak 4,\allowbreak...,\allowbreak 18\}</annotation></semantics></math>, grey background locations <math id="S2.SS4.SSS1.p2.9.m9.8" class="ltx_Math" alttext="E=\{nogray,\allowbreak-1.5,\allowbreak-1,\allowbreak-.5,\allowbreak 0,\allowbreak 0.5,\allowbreak 1,\allowbreak 1.5\}" display="inline"><semantics id="S2.SS4.SSS1.p2.9.m9.8a"><mrow id="S2.SS4.SSS1.p2.9.m9.8.8" xref="S2.SS4.SSS1.p2.9.m9.8.8.cmml"><mi id="S2.SS4.SSS1.p2.9.m9.8.8.6" xref="S2.SS4.SSS1.p2.9.m9.8.8.6.cmml">E</mi><mo id="S2.SS4.SSS1.p2.9.m9.8.8.5" xref="S2.SS4.SSS1.p2.9.m9.8.8.5.cmml">=</mo><mrow id="S2.SS4.SSS1.p2.9.m9.8.8.4.4" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml"><mo stretchy="false" id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.5" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">{</mo><mrow id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.cmml"><mi id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.2" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.3" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1a" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.4" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1b" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.5" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1c" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.6" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1d" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.7" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.7.cmml">y</mi></mrow><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.6" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mrow id="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2" xref="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.cmml"><mo id="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2a" xref="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.cmml">‚àí</mo><mn id="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.2" xref="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.2.cmml">1.5</mn></mrow><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.7" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mrow id="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3" xref="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.cmml"><mo id="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3a" xref="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.cmml">‚àí</mo><mn id="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.2" xref="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.2.cmml">1</mn></mrow><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.8" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mrow id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.cmml"><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4a" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.cmml">‚àí</mo><mn id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.2" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.2.cmml">.5</mn></mrow><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.9" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mn id="S2.SS4.SSS1.p2.9.m9.1.1" xref="S2.SS4.SSS1.p2.9.m9.1.1.cmml">0</mn><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.10" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mn id="S2.SS4.SSS1.p2.9.m9.2.2" xref="S2.SS4.SSS1.p2.9.m9.2.2.cmml">0.5</mn><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.11" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mn id="S2.SS4.SSS1.p2.9.m9.3.3" xref="S2.SS4.SSS1.p2.9.m9.3.3.cmml">1</mn><mo id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.12" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">,</mo><mn id="S2.SS4.SSS1.p2.9.m9.4.4" xref="S2.SS4.SSS1.p2.9.m9.4.4.cmml">1.5</mn><mo stretchy="false" id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.13" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.9.m9.8b"><apply id="S2.SS4.SSS1.p2.9.m9.8.8.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8"><eq id="S2.SS4.SSS1.p2.9.m9.8.8.5.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8.5"></eq><ci id="S2.SS4.SSS1.p2.9.m9.8.8.6.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8.6">ùê∏</ci><set id="S2.SS4.SSS1.p2.9.m9.8.8.4.5.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4"><apply id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1"><times id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.1"></times><ci id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.2.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.2">ùëõ</ci><ci id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.3.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.3">ùëú</ci><ci id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.4.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.4">ùëî</ci><ci id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.5.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.5">ùëü</ci><ci id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.6.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.6">ùëé</ci><ci id="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.7.cmml" xref="S2.SS4.SSS1.p2.9.m9.5.5.1.1.1.7">ùë¶</ci></apply><apply id="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.cmml" xref="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2"><minus id="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.1.cmml" xref="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2"></minus><cn type="float" id="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.2.cmml" xref="S2.SS4.SSS1.p2.9.m9.6.6.2.2.2.2">1.5</cn></apply><apply id="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.cmml" xref="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3"><minus id="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.1.cmml" xref="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3"></minus><cn type="integer" id="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.2.cmml" xref="S2.SS4.SSS1.p2.9.m9.7.7.3.3.3.2">1</cn></apply><apply id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4"><minus id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.1.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4"></minus><cn type="float" id="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.2.cmml" xref="S2.SS4.SSS1.p2.9.m9.8.8.4.4.4.2">.5</cn></apply><cn type="integer" id="S2.SS4.SSS1.p2.9.m9.1.1.cmml" xref="S2.SS4.SSS1.p2.9.m9.1.1">0</cn><cn type="float" id="S2.SS4.SSS1.p2.9.m9.2.2.cmml" xref="S2.SS4.SSS1.p2.9.m9.2.2">0.5</cn><cn type="integer" id="S2.SS4.SSS1.p2.9.m9.3.3.cmml" xref="S2.SS4.SSS1.p2.9.m9.3.3">1</cn><cn type="float" id="S2.SS4.SSS1.p2.9.m9.4.4.cmml" xref="S2.SS4.SSS1.p2.9.m9.4.4">1.5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.9.m9.8c">E=\{nogray,\allowbreak-1.5,\allowbreak-1,\allowbreak-.5,\allowbreak 0,\allowbreak 0.5,\allowbreak 1,\allowbreak 1.5\}</annotation></semantics></math>, and pixel intensity levels of the lighter background section <math id="S2.SS4.SSS1.p2.10.m10.10" class="ltx_Math" alttext="I=\{38,\allowbreak 51,\allowbreak 64,\allowbreak 77,\allowbreak 89,\allowbreak 102,\allowbreak 115,\allowbreak 128,\allowbreak 140,\allowbreak 153\}" display="inline"><semantics id="S2.SS4.SSS1.p2.10.m10.10a"><mrow id="S2.SS4.SSS1.p2.10.m10.10.11" xref="S2.SS4.SSS1.p2.10.m10.10.11.cmml"><mi id="S2.SS4.SSS1.p2.10.m10.10.11.2" xref="S2.SS4.SSS1.p2.10.m10.10.11.2.cmml">I</mi><mo id="S2.SS4.SSS1.p2.10.m10.10.11.1" xref="S2.SS4.SSS1.p2.10.m10.10.11.1.cmml">=</mo><mrow id="S2.SS4.SSS1.p2.10.m10.10.11.3.2" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml"><mo stretchy="false" id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.1" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">{</mo><mn id="S2.SS4.SSS1.p2.10.m10.1.1" xref="S2.SS4.SSS1.p2.10.m10.1.1.cmml">38</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.2" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.2.2" xref="S2.SS4.SSS1.p2.10.m10.2.2.cmml">51</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.3" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.3.3" xref="S2.SS4.SSS1.p2.10.m10.3.3.cmml">64</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.4" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.4.4" xref="S2.SS4.SSS1.p2.10.m10.4.4.cmml">77</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.5" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.5.5" xref="S2.SS4.SSS1.p2.10.m10.5.5.cmml">89</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.6" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.6.6" xref="S2.SS4.SSS1.p2.10.m10.6.6.cmml">102</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.7" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.7.7" xref="S2.SS4.SSS1.p2.10.m10.7.7.cmml">115</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.8" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.8.8" xref="S2.SS4.SSS1.p2.10.m10.8.8.cmml">128</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.9" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.9.9" xref="S2.SS4.SSS1.p2.10.m10.9.9.cmml">140</mn><mo id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.10" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p2.10.m10.10.10" xref="S2.SS4.SSS1.p2.10.m10.10.10.cmml">153</mn><mo stretchy="false" id="S2.SS4.SSS1.p2.10.m10.10.11.3.2.11" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.10.m10.10b"><apply id="S2.SS4.SSS1.p2.10.m10.10.11.cmml" xref="S2.SS4.SSS1.p2.10.m10.10.11"><eq id="S2.SS4.SSS1.p2.10.m10.10.11.1.cmml" xref="S2.SS4.SSS1.p2.10.m10.10.11.1"></eq><ci id="S2.SS4.SSS1.p2.10.m10.10.11.2.cmml" xref="S2.SS4.SSS1.p2.10.m10.10.11.2">ùêº</ci><set id="S2.SS4.SSS1.p2.10.m10.10.11.3.1.cmml" xref="S2.SS4.SSS1.p2.10.m10.10.11.3.2"><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.1.1.cmml" xref="S2.SS4.SSS1.p2.10.m10.1.1">38</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.2.2.cmml" xref="S2.SS4.SSS1.p2.10.m10.2.2">51</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.3.3.cmml" xref="S2.SS4.SSS1.p2.10.m10.3.3">64</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.4.4.cmml" xref="S2.SS4.SSS1.p2.10.m10.4.4">77</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.5.5.cmml" xref="S2.SS4.SSS1.p2.10.m10.5.5">89</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.6.6.cmml" xref="S2.SS4.SSS1.p2.10.m10.6.6">102</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.7.7.cmml" xref="S2.SS4.SSS1.p2.10.m10.7.7">115</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.8.8.cmml" xref="S2.SS4.SSS1.p2.10.m10.8.8">128</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.9.9.cmml" xref="S2.SS4.SSS1.p2.10.m10.9.9">140</cn><cn type="integer" id="S2.SS4.SSS1.p2.10.m10.10.10.cmml" xref="S2.SS4.SSS1.p2.10.m10.10.10">153</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.10.m10.10c">I=\{38,\allowbreak 51,\allowbreak 64,\allowbreak 77,\allowbreak 89,\allowbreak 102,\allowbreak 115,\allowbreak 128,\allowbreak 140,\allowbreak 153\}</annotation></semantics></math>, i.e., it included all combinations of these parameters. At each combination of parameters, the horizontal center of the CR <math id="S2.SS4.SSS1.p2.11.m11.1" class="ltx_Math" alttext="x_{c}" display="inline"><semantics id="S2.SS4.SSS1.p2.11.m11.1a"><msub id="S2.SS4.SSS1.p2.11.m11.1.1" xref="S2.SS4.SSS1.p2.11.m11.1.1.cmml"><mi id="S2.SS4.SSS1.p2.11.m11.1.1.2" xref="S2.SS4.SSS1.p2.11.m11.1.1.2.cmml">x</mi><mi id="S2.SS4.SSS1.p2.11.m11.1.1.3" xref="S2.SS4.SSS1.p2.11.m11.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.11.m11.1b"><apply id="S2.SS4.SSS1.p2.11.m11.1.1.cmml" xref="S2.SS4.SSS1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p2.11.m11.1.1.1.cmml" xref="S2.SS4.SSS1.p2.11.m11.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p2.11.m11.1.1.2.cmml" xref="S2.SS4.SSS1.p2.11.m11.1.1.2">ùë•</ci><ci id="S2.SS4.SSS1.p2.11.m11.1.1.3.cmml" xref="S2.SS4.SSS1.p2.11.m11.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.11.m11.1c">x_{c}</annotation></semantics></math> was moved through 100 steps of <math id="S2.SS4.SSS1.p2.12.m12.1" class="ltx_Math" alttext="\delta_{x}=0.01" display="inline"><semantics id="S2.SS4.SSS1.p2.12.m12.1a"><mrow id="S2.SS4.SSS1.p2.12.m12.1.1" xref="S2.SS4.SSS1.p2.12.m12.1.1.cmml"><msub id="S2.SS4.SSS1.p2.12.m12.1.1.2" xref="S2.SS4.SSS1.p2.12.m12.1.1.2.cmml"><mi id="S2.SS4.SSS1.p2.12.m12.1.1.2.2" xref="S2.SS4.SSS1.p2.12.m12.1.1.2.2.cmml">Œ¥</mi><mi id="S2.SS4.SSS1.p2.12.m12.1.1.2.3" xref="S2.SS4.SSS1.p2.12.m12.1.1.2.3.cmml">x</mi></msub><mo id="S2.SS4.SSS1.p2.12.m12.1.1.1" xref="S2.SS4.SSS1.p2.12.m12.1.1.1.cmml">=</mo><mn id="S2.SS4.SSS1.p2.12.m12.1.1.3" xref="S2.SS4.SSS1.p2.12.m12.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.12.m12.1b"><apply id="S2.SS4.SSS1.p2.12.m12.1.1.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1"><eq id="S2.SS4.SSS1.p2.12.m12.1.1.1.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1.1"></eq><apply id="S2.SS4.SSS1.p2.12.m12.1.1.2.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1.2"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p2.12.m12.1.1.2.1.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1.2">subscript</csymbol><ci id="S2.SS4.SSS1.p2.12.m12.1.1.2.2.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1.2.2">ùõø</ci><ci id="S2.SS4.SSS1.p2.12.m12.1.1.2.3.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1.2.3">ùë•</ci></apply><cn type="float" id="S2.SS4.SSS1.p2.12.m12.1.1.3.cmml" xref="S2.SS4.SSS1.p2.12.m12.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.12.m12.1c">\delta_{x}=0.01</annotation></semantics></math> pixels as described above. The dividing line between the two sections of the background was always vertical and it was positioned relative to the synthetic CR such that <math id="S2.SS4.SSS1.p2.13.m13.1" class="ltx_Math" alttext="E=0" display="inline"><semantics id="S2.SS4.SSS1.p2.13.m13.1a"><mrow id="S2.SS4.SSS1.p2.13.m13.1.1" xref="S2.SS4.SSS1.p2.13.m13.1.1.cmml"><mi id="S2.SS4.SSS1.p2.13.m13.1.1.2" xref="S2.SS4.SSS1.p2.13.m13.1.1.2.cmml">E</mi><mo id="S2.SS4.SSS1.p2.13.m13.1.1.1" xref="S2.SS4.SSS1.p2.13.m13.1.1.1.cmml">=</mo><mn id="S2.SS4.SSS1.p2.13.m13.1.1.3" xref="S2.SS4.SSS1.p2.13.m13.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.13.m13.1b"><apply id="S2.SS4.SSS1.p2.13.m13.1.1.cmml" xref="S2.SS4.SSS1.p2.13.m13.1.1"><eq id="S2.SS4.SSS1.p2.13.m13.1.1.1.cmml" xref="S2.SS4.SSS1.p2.13.m13.1.1.1"></eq><ci id="S2.SS4.SSS1.p2.13.m13.1.1.2.cmml" xref="S2.SS4.SSS1.p2.13.m13.1.1.2">ùê∏</ci><cn type="integer" id="S2.SS4.SSS1.p2.13.m13.1.1.3.cmml" xref="S2.SS4.SSS1.p2.13.m13.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.13.m13.1c">E=0</annotation></semantics></math> meant the border between the two sections coincided with the CR center, <math id="S2.SS4.SSS1.p2.14.m14.1" class="ltx_Math" alttext="E=-1" display="inline"><semantics id="S2.SS4.SSS1.p2.14.m14.1a"><mrow id="S2.SS4.SSS1.p2.14.m14.1.1" xref="S2.SS4.SSS1.p2.14.m14.1.1.cmml"><mi id="S2.SS4.SSS1.p2.14.m14.1.1.2" xref="S2.SS4.SSS1.p2.14.m14.1.1.2.cmml">E</mi><mo id="S2.SS4.SSS1.p2.14.m14.1.1.1" xref="S2.SS4.SSS1.p2.14.m14.1.1.1.cmml">=</mo><mrow id="S2.SS4.SSS1.p2.14.m14.1.1.3" xref="S2.SS4.SSS1.p2.14.m14.1.1.3.cmml"><mo id="S2.SS4.SSS1.p2.14.m14.1.1.3a" xref="S2.SS4.SSS1.p2.14.m14.1.1.3.cmml">‚àí</mo><mn id="S2.SS4.SSS1.p2.14.m14.1.1.3.2" xref="S2.SS4.SSS1.p2.14.m14.1.1.3.2.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.14.m14.1b"><apply id="S2.SS4.SSS1.p2.14.m14.1.1.cmml" xref="S2.SS4.SSS1.p2.14.m14.1.1"><eq id="S2.SS4.SSS1.p2.14.m14.1.1.1.cmml" xref="S2.SS4.SSS1.p2.14.m14.1.1.1"></eq><ci id="S2.SS4.SSS1.p2.14.m14.1.1.2.cmml" xref="S2.SS4.SSS1.p2.14.m14.1.1.2">ùê∏</ci><apply id="S2.SS4.SSS1.p2.14.m14.1.1.3.cmml" xref="S2.SS4.SSS1.p2.14.m14.1.1.3"><minus id="S2.SS4.SSS1.p2.14.m14.1.1.3.1.cmml" xref="S2.SS4.SSS1.p2.14.m14.1.1.3"></minus><cn type="integer" id="S2.SS4.SSS1.p2.14.m14.1.1.3.2.cmml" xref="S2.SS4.SSS1.p2.14.m14.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.14.m14.1c">E=-1</annotation></semantics></math> that it was placed 1 CR radius <math id="S2.SS4.SSS1.p2.15.m15.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.SS4.SSS1.p2.15.m15.1a"><mi id="S2.SS4.SSS1.p2.15.m15.1.1" xref="S2.SS4.SSS1.p2.15.m15.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.15.m15.1b"><ci id="S2.SS4.SSS1.p2.15.m15.1.1.cmml" xref="S2.SS4.SSS1.p2.15.m15.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.15.m15.1c">r</annotation></semantics></math> to the left of the CR center, and <math id="S2.SS4.SSS1.p2.16.m16.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S2.SS4.SSS1.p2.16.m16.1a"><mrow id="S2.SS4.SSS1.p2.16.m16.1.1" xref="S2.SS4.SSS1.p2.16.m16.1.1.cmml"><mi id="S2.SS4.SSS1.p2.16.m16.1.1.2" xref="S2.SS4.SSS1.p2.16.m16.1.1.2.cmml">E</mi><mo id="S2.SS4.SSS1.p2.16.m16.1.1.1" xref="S2.SS4.SSS1.p2.16.m16.1.1.1.cmml">=</mo><mn id="S2.SS4.SSS1.p2.16.m16.1.1.3" xref="S2.SS4.SSS1.p2.16.m16.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.16.m16.1b"><apply id="S2.SS4.SSS1.p2.16.m16.1.1.cmml" xref="S2.SS4.SSS1.p2.16.m16.1.1"><eq id="S2.SS4.SSS1.p2.16.m16.1.1.1.cmml" xref="S2.SS4.SSS1.p2.16.m16.1.1.1"></eq><ci id="S2.SS4.SSS1.p2.16.m16.1.1.2.cmml" xref="S2.SS4.SSS1.p2.16.m16.1.1.2">ùê∏</ci><cn type="integer" id="S2.SS4.SSS1.p2.16.m16.1.1.3.cmml" xref="S2.SS4.SSS1.p2.16.m16.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.16.m16.1c">E=1</annotation></semantics></math>, 1 CR radius to the right of the CR center (see bottom row of Figure <a href="#S2.F2" title="Figure 2 ‚Ä£ 2.3 Generating Synthetic Images ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
</section>
<section id="S2.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2 </span>Evaluation on real eye-images</h4>

<div id="S2.SS4.SSS2.p1" class="ltx_para">
<p id="S2.SS4.SSS2.p1.1" class="ltx_p">How well does our approach perform on real eye images? To answer this question we tested our method against the thresholding and the radial symmetry methods when localizing the center of the CR in high resolution, high framerate videos of real eyes performing a collection of fixation tasks. Two different datasets were collected.</p>
</div>
<section id="S2.SS4.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset one</h5>

<div id="S2.SS4.SSS2.Px1.p1" class="ltx_para">
<p id="S2.SS4.SSS2.Px1.p1.1" class="ltx_p"><span id="S2.SS4.SSS2.Px1.p1.1.1" class="ltx_text ltx_font_italic">Participants</span>. Eye videos were recorded from three participants. Two are authors of the current paper and the third is an experienced participant in fixation tasks. None of the participants wore glasses or contact lenses. Videos were recorded from the left eye. The study was approved by the Ethical Review Board in Sweden (Dnr: 2019-01081).</p>
</div>
<div id="S2.SS4.SSS2.Px1.p2" class="ltx_para">
<p id="S2.SS4.SSS2.Px1.p2.2" class="ltx_p"><span id="S2.SS4.SSS2.Px1.p2.2.1" class="ltx_text ltx_font_italic">Apparatus</span>. The visual stimuli were presented on an ASUS VG248QE screen (531 x 299 mm; 1920 x 1080 pixels; <math id="S2.SS4.SSS2.Px1.p2.1.m1.3" class="ltx_Math" alttext="60\text{\,}\mathrm{H}\mathrm{z}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p2.1.m1.3a"><mrow id="S2.SS4.SSS2.Px1.p2.1.m1.3.3" xref="S2.SS4.SSS2.Px1.p2.1.m1.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p2.1.m1.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p2.1.m1.1.1.1.1.1.1.cmml">60</mn><mtext id="S2.SS4.SSS2.Px1.p2.1.m1.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p2.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px1.p2.1.m1.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p2.1.m1.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p2.1.m1.3b"><apply id="S2.SS4.SSS2.Px1.p2.1.m1.3.3.cmml" xref="S2.SS4.SSS2.Px1.p2.1.m1.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p2.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p2.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p2.1.m1.1.1.1.1.1.1">60</cn><ci id="S2.SS4.SSS2.Px1.p2.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p2.1.m1.3.3.3.3.3.3">Hz</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p2.1.m1.3c">60\text{\,}\mathrm{H}\mathrm{z}</annotation></semantics></math> refresh rate) at a viewing distance of <math id="S2.SS4.SSS2.Px1.p2.2.m2.3" class="ltx_Math" alttext="79\text{\,}\mathrm{c}\mathrm{m}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p2.2.m2.3a"><mrow id="S2.SS4.SSS2.Px1.p2.2.m2.3.3" xref="S2.SS4.SSS2.Px1.p2.2.m2.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p2.2.m2.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p2.2.m2.1.1.1.1.1.1.cmml">79</mn><mtext id="S2.SS4.SSS2.Px1.p2.2.m2.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p2.2.m2.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px1.p2.2.m2.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p2.2.m2.3.3.3.3.3.3.cmml">cm</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p2.2.m2.3b"><apply id="S2.SS4.SSS2.Px1.p2.2.m2.3.3.cmml" xref="S2.SS4.SSS2.Px1.p2.2.m2.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p2.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p2.2.m2.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px1.p2.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p2.2.m2.1.1.1.1.1.1">79</cn><ci id="S2.SS4.SSS2.Px1.p2.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p2.2.m2.3.3.3.3.3.3">cm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p2.2.m2.3c">79\text{\,}\mathrm{c}\mathrm{m}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS4.SSS2.Px1.p3" class="ltx_para">
<p id="S2.SS4.SSS2.Px1.p3.4" class="ltx_p">Videos of the subject‚Äôs left eye were acquired using our FLEX setup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">31</a>, <a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>, a self-built eye tracker. The setup consisted of a Basler camera (Basler Ace acA2500-60um) fitted with a <math id="S2.SS4.SSS2.Px1.p3.1.m1.3" class="ltx_Math" alttext="50\text{\,}\mathrm{m}\mathrm{m}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p3.1.m1.3a"><mrow id="S2.SS4.SSS2.Px1.p3.1.m1.3.3" xref="S2.SS4.SSS2.Px1.p3.1.m1.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p3.1.m1.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p3.1.m1.1.1.1.1.1.1.cmml">50</mn><mtext id="S2.SS4.SSS2.Px1.p3.1.m1.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p3.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px1.p3.1.m1.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p3.1.m1.3.3.3.3.3.3.cmml">mm</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p3.1.m1.3b"><apply id="S2.SS4.SSS2.Px1.p3.1.m1.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.1.m1.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p3.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p3.1.m1.1.1.1.1.1.1">50</cn><ci id="S2.SS4.SSS2.Px1.p3.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.1.m1.3.3.3.3.3.3">mm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p3.1.m1.3c">50\text{\,}\mathrm{m}\mathrm{m}</annotation></semantics></math> lens (AZURE-5022ML12M) and a Near-IR Long pass Filter (MIDOPT LP715-37.5). Eye videos were recorded at <math id="S2.SS4.SSS2.Px1.p3.2.m2.3" class="ltx_Math" alttext="500\text{\,}\mathrm{H}\mathrm{z}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p3.2.m2.3a"><mrow id="S2.SS4.SSS2.Px1.p3.2.m2.3.3" xref="S2.SS4.SSS2.Px1.p3.2.m2.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p3.2.m2.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p3.2.m2.1.1.1.1.1.1.cmml">500</mn><mtext id="S2.SS4.SSS2.Px1.p3.2.m2.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p3.2.m2.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px1.p3.2.m2.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p3.2.m2.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p3.2.m2.3b"><apply id="S2.SS4.SSS2.Px1.p3.2.m2.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.2.m2.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p3.2.m2.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px1.p3.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p3.2.m2.1.1.1.1.1.1">500</cn><ci id="S2.SS4.SSS2.Px1.p3.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.2.m2.3.3.3.3.3.3">Hz</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p3.2.m2.3c">500\text{\,}\mathrm{H}\mathrm{z}</annotation></semantics></math> at a resolution of 896 √ó 600 pixels (exposure time: <math id="S2.SS4.SSS2.Px1.p3.3.m3.3" class="ltx_Math" alttext="1876\text{\,}\mathrm{\SIUnitSymbolMicro s}\text{/}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p3.3.m3.3a"><mrow id="S2.SS4.SSS2.Px1.p3.3.m3.3.3" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p3.3.m3.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p3.3.m3.1.1.1.1.1.1.cmml">1876</mn><mtext id="S2.SS4.SSS2.Px1.p3.3.m3.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p3.3.m3.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.cmml"><mrow class="ltx_unit" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.2" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬µ</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml">‚Äã</mo><mi mathvariant="normal" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.3" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml">s</mi></mrow><mtext id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p3.3.m3.3b"><apply id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.1.1.1.1.1.1">1876</cn><apply id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.1.1.1.1.1.1">microsecond</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.3.m3.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p3.3.m3.3c">1876\text{\,}\mathrm{\SIUnitSymbolMicro s}\text{/}</annotation></semantics></math>, Gain: 10 dB), and were streamed into mp4-files with custom software using libavcodec (ffmpeg) 5.1.2 and the libx264 h.264 encoder (preset: veryfast, crf: 0 (lossless), pixel format: gray). Videos were acquired and stored at 8-bit luminance resolution. The EyeLink <math id="S2.SS4.SSS2.Px1.p3.4.m4.3" class="ltx_Math" alttext="890\text{\,}\mathrm{n}\mathrm{m}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p3.4.m4.3a"><mrow id="S2.SS4.SSS2.Px1.p3.4.m4.3.3" xref="S2.SS4.SSS2.Px1.p3.4.m4.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p3.4.m4.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p3.4.m4.1.1.1.1.1.1.cmml">890</mn><mtext id="S2.SS4.SSS2.Px1.p3.4.m4.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p3.4.m4.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px1.p3.4.m4.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p3.4.m4.3.3.3.3.3.3.cmml">nm</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p3.4.m4.3b"><apply id="S2.SS4.SSS2.Px1.p3.4.m4.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.4.m4.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p3.4.m4.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p3.4.m4.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px1.p3.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p3.4.m4.1.1.1.1.1.1">890</cn><ci id="S2.SS4.SSS2.Px1.p3.4.m4.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p3.4.m4.3.3.3.3.3.3">nm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p3.4.m4.3c">890\text{\,}\mathrm{n}\mathrm{m}</annotation></semantics></math> illuminator was used (at 75% power) to deliver illumination to the eye and to generate a reflection on the cornea that can be tracked in the eye image. An example eye image is shown in the left panel of Figure <a href="#S2.F3" title="Figure 3 ‚Ä£ Dataset one ‚Ä£ 2.4.2 Evaluation on real eye-images ‚Ä£ 2.4 Evaluation ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S2.SS4.SSS2.Px1.p4" class="ltx_para">
<p id="S2.SS4.SSS2.Px1.p4.2" class="ltx_p"><span id="S2.SS4.SSS2.Px1.p4.2.1" class="ltx_text ltx_font_italic">Procedure</span>. The subjects performed the following tasks where they looked at a fixation point consisting of a blue disk (<math id="S2.SS4.SSS2.Px1.p4.1.m1.3" class="ltx_Math" alttext="1.2\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p4.1.m1.3a"><mrow id="S2.SS4.SSS2.Px1.p4.1.m1.3.3" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p4.1.m1.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p4.1.m1.1.1.1.1.1.1.cmml">1.2</mn><mtext id="S2.SS4.SSS2.Px1.p4.1.m1.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p4.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬∞</mi><mtext id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p4.1.m1.3b"><apply id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.2.2.2.2.2.2">times</csymbol><cn type="float" id="S2.SS4.SSS2.Px1.p4.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.1.1.1.1.1.1">1.2</cn><apply id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">degree</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p4.1.m1.3c">1.2\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}</annotation></semantics></math> diameter), with a red point (<math id="S2.SS4.SSS2.Px1.p4.2.m2.3" class="ltx_Math" alttext="0.2\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}" display="inline"><semantics id="S2.SS4.SSS2.Px1.p4.2.m2.3a"><mrow id="S2.SS4.SSS2.Px1.p4.2.m2.3.3" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.cmml"><mn id="S2.SS4.SSS2.Px1.p4.2.m2.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p4.2.m2.1.1.1.1.1.1.cmml">0.2</mn><mtext id="S2.SS4.SSS2.Px1.p4.2.m2.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p4.2.m2.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬∞</mi><mtext id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px1.p4.2.m2.3b"><apply id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.2.2.2.2.2.2">times</csymbol><cn type="float" id="S2.SS4.SSS2.Px1.p4.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.1.1.1.1.1.1">0.2</cn><apply id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1">degree</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px1.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px1.p4.2.m2.3c">0.2\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}</annotation></semantics></math> diameter) overlaid:</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/eye_image_full_715.png" id="S2.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="224" height="150" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/eye_image_masked_715.png" id="S2.F3.2.g1" class="ltx_graphics ltx_img_square" width="150" height="150" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Full eye image (left) and masked cutout as processed by the radial symmetry and CNN methods (right).</figcaption>
</figure>
</section>
<section id="S2.SS4.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset two</h5>

<div id="S2.SS4.SSS2.Px2.p1" class="ltx_para">
<p id="S2.SS4.SSS2.Px2.p1.1" class="ltx_p">An abbreviated protocol was used to collect additional eye videos from the left eye of 17 participants (age 30-61 yrs (mean 45.4 yrs), five females, eleven males, one non-binary) who did not wear glasses or contact lenses. The study was approved by the Ethical Review Board in Sweden (Dnr: 2019-01081). Two are authors of the current paper. One participant was excluded because an impurity on their cornea caused an additional corneal reflection that none of the examined methods could handle.</p>
</div>
<div id="S2.SS4.SSS2.Px2.p2" class="ltx_para">
<p id="S2.SS4.SSS2.Px2.p2.3" class="ltx_p">To further examine the robustness of our method to variations in the luminance profile of the input eye images, this second recording was performed with the FLEX setup set to acquire images at <math id="S2.SS4.SSS2.Px2.p2.1.m1.3" class="ltx_Math" alttext="1000\text{\,}\mathrm{H}\mathrm{z}" display="inline"><semantics id="S2.SS4.SSS2.Px2.p2.1.m1.3a"><mrow id="S2.SS4.SSS2.Px2.p2.1.m1.3.3" xref="S2.SS4.SSS2.Px2.p2.1.m1.3.3.cmml"><mn id="S2.SS4.SSS2.Px2.p2.1.m1.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px2.p2.1.m1.1.1.1.1.1.1.cmml">1000</mn><mtext id="S2.SS4.SSS2.Px2.p2.1.m1.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px2.p2.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px2.p2.1.m1.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px2.p2.1.m1.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px2.p2.1.m1.3b"><apply id="S2.SS4.SSS2.Px2.p2.1.m1.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.1.m1.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px2.p2.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px2.p2.1.m1.1.1.1.1.1.1">1000</cn><ci id="S2.SS4.SSS2.Px2.p2.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.1.m1.3.3.3.3.3.3">Hz</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px2.p2.1.m1.3c">1000\text{\,}\mathrm{H}\mathrm{z}</annotation></semantics></math>. The captured eye images were less bright at this higher sampling rate due to the shorter possible exposure time. The videos were acquired at a resolution of 672 √ó 340 pixels (exposure time: <math id="S2.SS4.SSS2.Px2.p2.2.m2.3" class="ltx_Math" alttext="882\text{\,}\mathrm{\SIUnitSymbolMicro s}\text{/}" display="inline"><semantics id="S2.SS4.SSS2.Px2.p2.2.m2.3a"><mrow id="S2.SS4.SSS2.Px2.p2.2.m2.3.3" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.cmml"><mn id="S2.SS4.SSS2.Px2.p2.2.m2.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px2.p2.2.m2.1.1.1.1.1.1.cmml">882</mn><mtext id="S2.SS4.SSS2.Px2.p2.2.m2.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px2.p2.2.m2.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.cmml"><mrow class="ltx_unit" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.2" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬µ</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">‚Äã</mo><mi mathvariant="normal" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.3" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">s</mi></mrow><mtext id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px2.p2.2.m2.3b"><apply id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px2.p2.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.1.1.1.1.1.1">882</cn><apply id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.1.1.1.1.1.1">microsecond</csymbol><csymbol cd="latexml" id="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.2.m2.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px2.p2.2.m2.3c">882\text{\,}\mathrm{\SIUnitSymbolMicro s}\text{/}</annotation></semantics></math>, Gain: 12 dB). The EyeLink <math id="S2.SS4.SSS2.Px2.p2.3.m3.3" class="ltx_Math" alttext="890\text{\,}\mathrm{n}\mathrm{m}" display="inline"><semantics id="S2.SS4.SSS2.Px2.p2.3.m3.3a"><mrow id="S2.SS4.SSS2.Px2.p2.3.m3.3.3" xref="S2.SS4.SSS2.Px2.p2.3.m3.3.3.cmml"><mn id="S2.SS4.SSS2.Px2.p2.3.m3.1.1.1.1.1.1" xref="S2.SS4.SSS2.Px2.p2.3.m3.1.1.1.1.1.1.cmml">890</mn><mtext id="S2.SS4.SSS2.Px2.p2.3.m3.2.2.2.2.2.2" xref="S2.SS4.SSS2.Px2.p2.3.m3.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S2.SS4.SSS2.Px2.p2.3.m3.3.3.3.3.3.3" xref="S2.SS4.SSS2.Px2.p2.3.m3.3.3.3.3.3.3.cmml">nm</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px2.p2.3.m3.3b"><apply id="S2.SS4.SSS2.Px2.p2.3.m3.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.3.m3.3.3"><csymbol cd="latexml" id="S2.SS4.SSS2.Px2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS4.SSS2.Px2.p2.3.m3.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS4.SSS2.Px2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.Px2.p2.3.m3.1.1.1.1.1.1">890</cn><ci id="S2.SS4.SSS2.Px2.p2.3.m3.3.3.3.3.3.3.cmml" xref="S2.SS4.SSS2.Px2.p2.3.m3.3.3.3.3.3.3">nm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px2.p2.3.m3.3c">890\text{\,}\mathrm{n}\mathrm{m}</annotation></semantics></math> illuminator was used (at 100% power) to deliver illumination to the eye.</p>
</div>
<div id="S2.SS4.SSS2.Px2.p3" class="ltx_para">
<p id="S2.SS4.SSS2.Px2.p3.1" class="ltx_p">This data collection used the same displays as the previous, and the reduced protocol consisted of:</p>
<ol id="S2.I3" class="ltx_enumerate">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.2" class="ltx_p">Nine 1-second fixations on a 3√ó3 grid of fixation points positioned at <math id="S2.I3.i1.p1.1.m1.3" class="ltx_Math" alttext="h=\{-7,\allowbreak 0,\allowbreak 7\}" display="inline"><semantics id="S2.I3.i1.p1.1.m1.3a"><mrow id="S2.I3.i1.p1.1.m1.3.3" xref="S2.I3.i1.p1.1.m1.3.3.cmml"><mi id="S2.I3.i1.p1.1.m1.3.3.3" xref="S2.I3.i1.p1.1.m1.3.3.3.cmml">h</mi><mo id="S2.I3.i1.p1.1.m1.3.3.2" xref="S2.I3.i1.p1.1.m1.3.3.2.cmml">=</mo><mrow id="S2.I3.i1.p1.1.m1.3.3.1.1" xref="S2.I3.i1.p1.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="S2.I3.i1.p1.1.m1.3.3.1.1.2" xref="S2.I3.i1.p1.1.m1.3.3.1.2.cmml">{</mo><mrow id="S2.I3.i1.p1.1.m1.3.3.1.1.1" xref="S2.I3.i1.p1.1.m1.3.3.1.1.1.cmml"><mo id="S2.I3.i1.p1.1.m1.3.3.1.1.1a" xref="S2.I3.i1.p1.1.m1.3.3.1.1.1.cmml">‚àí</mo><mn id="S2.I3.i1.p1.1.m1.3.3.1.1.1.2" xref="S2.I3.i1.p1.1.m1.3.3.1.1.1.2.cmml">7</mn></mrow><mo id="S2.I3.i1.p1.1.m1.3.3.1.1.3" xref="S2.I3.i1.p1.1.m1.3.3.1.2.cmml">,</mo><mn id="S2.I3.i1.p1.1.m1.1.1" xref="S2.I3.i1.p1.1.m1.1.1.cmml">0</mn><mo id="S2.I3.i1.p1.1.m1.3.3.1.1.4" xref="S2.I3.i1.p1.1.m1.3.3.1.2.cmml">,</mo><mn id="S2.I3.i1.p1.1.m1.2.2" xref="S2.I3.i1.p1.1.m1.2.2.cmml">7</mn><mo stretchy="false" id="S2.I3.i1.p1.1.m1.3.3.1.1.5" xref="S2.I3.i1.p1.1.m1.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I3.i1.p1.1.m1.3b"><apply id="S2.I3.i1.p1.1.m1.3.3.cmml" xref="S2.I3.i1.p1.1.m1.3.3"><eq id="S2.I3.i1.p1.1.m1.3.3.2.cmml" xref="S2.I3.i1.p1.1.m1.3.3.2"></eq><ci id="S2.I3.i1.p1.1.m1.3.3.3.cmml" xref="S2.I3.i1.p1.1.m1.3.3.3">‚Ñé</ci><set id="S2.I3.i1.p1.1.m1.3.3.1.2.cmml" xref="S2.I3.i1.p1.1.m1.3.3.1.1"><apply id="S2.I3.i1.p1.1.m1.3.3.1.1.1.cmml" xref="S2.I3.i1.p1.1.m1.3.3.1.1.1"><minus id="S2.I3.i1.p1.1.m1.3.3.1.1.1.1.cmml" xref="S2.I3.i1.p1.1.m1.3.3.1.1.1"></minus><cn type="integer" id="S2.I3.i1.p1.1.m1.3.3.1.1.1.2.cmml" xref="S2.I3.i1.p1.1.m1.3.3.1.1.1.2">7</cn></apply><cn type="integer" id="S2.I3.i1.p1.1.m1.1.1.cmml" xref="S2.I3.i1.p1.1.m1.1.1">0</cn><cn type="integer" id="S2.I3.i1.p1.1.m1.2.2.cmml" xref="S2.I3.i1.p1.1.m1.2.2">7</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i1.p1.1.m1.3c">h=\{-7,\allowbreak 0,\allowbreak 7\}</annotation></semantics></math> deg and <math id="S2.I3.i1.p1.2.m2.3" class="ltx_Math" alttext="v=\{-5,\allowbreak 0,\allowbreak 5\}" display="inline"><semantics id="S2.I3.i1.p1.2.m2.3a"><mrow id="S2.I3.i1.p1.2.m2.3.3" xref="S2.I3.i1.p1.2.m2.3.3.cmml"><mi id="S2.I3.i1.p1.2.m2.3.3.3" xref="S2.I3.i1.p1.2.m2.3.3.3.cmml">v</mi><mo id="S2.I3.i1.p1.2.m2.3.3.2" xref="S2.I3.i1.p1.2.m2.3.3.2.cmml">=</mo><mrow id="S2.I3.i1.p1.2.m2.3.3.1.1" xref="S2.I3.i1.p1.2.m2.3.3.1.2.cmml"><mo stretchy="false" id="S2.I3.i1.p1.2.m2.3.3.1.1.2" xref="S2.I3.i1.p1.2.m2.3.3.1.2.cmml">{</mo><mrow id="S2.I3.i1.p1.2.m2.3.3.1.1.1" xref="S2.I3.i1.p1.2.m2.3.3.1.1.1.cmml"><mo id="S2.I3.i1.p1.2.m2.3.3.1.1.1a" xref="S2.I3.i1.p1.2.m2.3.3.1.1.1.cmml">‚àí</mo><mn id="S2.I3.i1.p1.2.m2.3.3.1.1.1.2" xref="S2.I3.i1.p1.2.m2.3.3.1.1.1.2.cmml">5</mn></mrow><mo id="S2.I3.i1.p1.2.m2.3.3.1.1.3" xref="S2.I3.i1.p1.2.m2.3.3.1.2.cmml">,</mo><mn id="S2.I3.i1.p1.2.m2.1.1" xref="S2.I3.i1.p1.2.m2.1.1.cmml">0</mn><mo id="S2.I3.i1.p1.2.m2.3.3.1.1.4" xref="S2.I3.i1.p1.2.m2.3.3.1.2.cmml">,</mo><mn id="S2.I3.i1.p1.2.m2.2.2" xref="S2.I3.i1.p1.2.m2.2.2.cmml">5</mn><mo stretchy="false" id="S2.I3.i1.p1.2.m2.3.3.1.1.5" xref="S2.I3.i1.p1.2.m2.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I3.i1.p1.2.m2.3b"><apply id="S2.I3.i1.p1.2.m2.3.3.cmml" xref="S2.I3.i1.p1.2.m2.3.3"><eq id="S2.I3.i1.p1.2.m2.3.3.2.cmml" xref="S2.I3.i1.p1.2.m2.3.3.2"></eq><ci id="S2.I3.i1.p1.2.m2.3.3.3.cmml" xref="S2.I3.i1.p1.2.m2.3.3.3">ùë£</ci><set id="S2.I3.i1.p1.2.m2.3.3.1.2.cmml" xref="S2.I3.i1.p1.2.m2.3.3.1.1"><apply id="S2.I3.i1.p1.2.m2.3.3.1.1.1.cmml" xref="S2.I3.i1.p1.2.m2.3.3.1.1.1"><minus id="S2.I3.i1.p1.2.m2.3.3.1.1.1.1.cmml" xref="S2.I3.i1.p1.2.m2.3.3.1.1.1"></minus><cn type="integer" id="S2.I3.i1.p1.2.m2.3.3.1.1.1.2.cmml" xref="S2.I3.i1.p1.2.m2.3.3.1.1.1.2">5</cn></apply><cn type="integer" id="S2.I3.i1.p1.2.m2.1.1.cmml" xref="S2.I3.i1.p1.2.m2.1.1">0</cn><cn type="integer" id="S2.I3.i1.p1.2.m2.2.2.cmml" xref="S2.I3.i1.p1.2.m2.2.2">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i1.p1.2.m2.3c">v=\{-5,\allowbreak 0,\allowbreak 5\}</annotation></semantics></math> deg in random order.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p">One 30-second fixation on a dot that was presented at <math id="S2.I3.i2.p1.1.m1.2" class="ltx_Math" alttext="(0,0)" display="inline"><semantics id="S2.I3.i2.p1.1.m1.2a"><mrow id="S2.I3.i2.p1.1.m1.2.3.2" xref="S2.I3.i2.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S2.I3.i2.p1.1.m1.2.3.2.1" xref="S2.I3.i2.p1.1.m1.2.3.1.cmml">(</mo><mn id="S2.I3.i2.p1.1.m1.1.1" xref="S2.I3.i2.p1.1.m1.1.1.cmml">0</mn><mo id="S2.I3.i2.p1.1.m1.2.3.2.2" xref="S2.I3.i2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S2.I3.i2.p1.1.m1.2.2" xref="S2.I3.i2.p1.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S2.I3.i2.p1.1.m1.2.3.2.3" xref="S2.I3.i2.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I3.i2.p1.1.m1.2b"><interval closure="open" id="S2.I3.i2.p1.1.m1.2.3.1.cmml" xref="S2.I3.i2.p1.1.m1.2.3.2"><cn type="integer" id="S2.I3.i2.p1.1.m1.1.1.cmml" xref="S2.I3.i2.p1.1.m1.1.1">0</cn><cn type="integer" id="S2.I3.i2.p1.1.m1.2.2.cmml" xref="S2.I3.i2.p1.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i2.p1.1.m1.2c">(0,0)</annotation></semantics></math> deg on a middle gray background.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.2" class="ltx_p">Two blocks of fifteen 1.5-second fixations on a 5√ó3 grid of fixation points positioned at <math id="S2.I3.i3.p1.1.m1.5" class="ltx_Math" alttext="h=\{-7,\allowbreak-3.5,\allowbreak 0,\allowbreak 3.5,\allowbreak 7\}" display="inline"><semantics id="S2.I3.i3.p1.1.m1.5a"><mrow id="S2.I3.i3.p1.1.m1.5.5" xref="S2.I3.i3.p1.1.m1.5.5.cmml"><mi id="S2.I3.i3.p1.1.m1.5.5.4" xref="S2.I3.i3.p1.1.m1.5.5.4.cmml">h</mi><mo id="S2.I3.i3.p1.1.m1.5.5.3" xref="S2.I3.i3.p1.1.m1.5.5.3.cmml">=</mo><mrow id="S2.I3.i3.p1.1.m1.5.5.2.2" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml"><mo stretchy="false" id="S2.I3.i3.p1.1.m1.5.5.2.2.3" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml">{</mo><mrow id="S2.I3.i3.p1.1.m1.4.4.1.1.1" xref="S2.I3.i3.p1.1.m1.4.4.1.1.1.cmml"><mo id="S2.I3.i3.p1.1.m1.4.4.1.1.1a" xref="S2.I3.i3.p1.1.m1.4.4.1.1.1.cmml">‚àí</mo><mn id="S2.I3.i3.p1.1.m1.4.4.1.1.1.2" xref="S2.I3.i3.p1.1.m1.4.4.1.1.1.2.cmml">7</mn></mrow><mo id="S2.I3.i3.p1.1.m1.5.5.2.2.4" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml">,</mo><mrow id="S2.I3.i3.p1.1.m1.5.5.2.2.2" xref="S2.I3.i3.p1.1.m1.5.5.2.2.2.cmml"><mo id="S2.I3.i3.p1.1.m1.5.5.2.2.2a" xref="S2.I3.i3.p1.1.m1.5.5.2.2.2.cmml">‚àí</mo><mn id="S2.I3.i3.p1.1.m1.5.5.2.2.2.2" xref="S2.I3.i3.p1.1.m1.5.5.2.2.2.2.cmml">3.5</mn></mrow><mo id="S2.I3.i3.p1.1.m1.5.5.2.2.5" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml">,</mo><mn id="S2.I3.i3.p1.1.m1.1.1" xref="S2.I3.i3.p1.1.m1.1.1.cmml">0</mn><mo id="S2.I3.i3.p1.1.m1.5.5.2.2.6" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml">,</mo><mn id="S2.I3.i3.p1.1.m1.2.2" xref="S2.I3.i3.p1.1.m1.2.2.cmml">3.5</mn><mo id="S2.I3.i3.p1.1.m1.5.5.2.2.7" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml">,</mo><mn id="S2.I3.i3.p1.1.m1.3.3" xref="S2.I3.i3.p1.1.m1.3.3.cmml">7</mn><mo stretchy="false" id="S2.I3.i3.p1.1.m1.5.5.2.2.8" xref="S2.I3.i3.p1.1.m1.5.5.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I3.i3.p1.1.m1.5b"><apply id="S2.I3.i3.p1.1.m1.5.5.cmml" xref="S2.I3.i3.p1.1.m1.5.5"><eq id="S2.I3.i3.p1.1.m1.5.5.3.cmml" xref="S2.I3.i3.p1.1.m1.5.5.3"></eq><ci id="S2.I3.i3.p1.1.m1.5.5.4.cmml" xref="S2.I3.i3.p1.1.m1.5.5.4">‚Ñé</ci><set id="S2.I3.i3.p1.1.m1.5.5.2.3.cmml" xref="S2.I3.i3.p1.1.m1.5.5.2.2"><apply id="S2.I3.i3.p1.1.m1.4.4.1.1.1.cmml" xref="S2.I3.i3.p1.1.m1.4.4.1.1.1"><minus id="S2.I3.i3.p1.1.m1.4.4.1.1.1.1.cmml" xref="S2.I3.i3.p1.1.m1.4.4.1.1.1"></minus><cn type="integer" id="S2.I3.i3.p1.1.m1.4.4.1.1.1.2.cmml" xref="S2.I3.i3.p1.1.m1.4.4.1.1.1.2">7</cn></apply><apply id="S2.I3.i3.p1.1.m1.5.5.2.2.2.cmml" xref="S2.I3.i3.p1.1.m1.5.5.2.2.2"><minus id="S2.I3.i3.p1.1.m1.5.5.2.2.2.1.cmml" xref="S2.I3.i3.p1.1.m1.5.5.2.2.2"></minus><cn type="float" id="S2.I3.i3.p1.1.m1.5.5.2.2.2.2.cmml" xref="S2.I3.i3.p1.1.m1.5.5.2.2.2.2">3.5</cn></apply><cn type="integer" id="S2.I3.i3.p1.1.m1.1.1.cmml" xref="S2.I3.i3.p1.1.m1.1.1">0</cn><cn type="float" id="S2.I3.i3.p1.1.m1.2.2.cmml" xref="S2.I3.i3.p1.1.m1.2.2">3.5</cn><cn type="integer" id="S2.I3.i3.p1.1.m1.3.3.cmml" xref="S2.I3.i3.p1.1.m1.3.3">7</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i3.p1.1.m1.5c">h=\{-7,\allowbreak-3.5,\allowbreak 0,\allowbreak 3.5,\allowbreak 7\}</annotation></semantics></math> deg and <math id="S2.I3.i3.p1.2.m2.3" class="ltx_Math" alttext="v=\{-5,\allowbreak 0,\allowbreak 5\}" display="inline"><semantics id="S2.I3.i3.p1.2.m2.3a"><mrow id="S2.I3.i3.p1.2.m2.3.3" xref="S2.I3.i3.p1.2.m2.3.3.cmml"><mi id="S2.I3.i3.p1.2.m2.3.3.3" xref="S2.I3.i3.p1.2.m2.3.3.3.cmml">v</mi><mo id="S2.I3.i3.p1.2.m2.3.3.2" xref="S2.I3.i3.p1.2.m2.3.3.2.cmml">=</mo><mrow id="S2.I3.i3.p1.2.m2.3.3.1.1" xref="S2.I3.i3.p1.2.m2.3.3.1.2.cmml"><mo stretchy="false" id="S2.I3.i3.p1.2.m2.3.3.1.1.2" xref="S2.I3.i3.p1.2.m2.3.3.1.2.cmml">{</mo><mrow id="S2.I3.i3.p1.2.m2.3.3.1.1.1" xref="S2.I3.i3.p1.2.m2.3.3.1.1.1.cmml"><mo id="S2.I3.i3.p1.2.m2.3.3.1.1.1a" xref="S2.I3.i3.p1.2.m2.3.3.1.1.1.cmml">‚àí</mo><mn id="S2.I3.i3.p1.2.m2.3.3.1.1.1.2" xref="S2.I3.i3.p1.2.m2.3.3.1.1.1.2.cmml">5</mn></mrow><mo id="S2.I3.i3.p1.2.m2.3.3.1.1.3" xref="S2.I3.i3.p1.2.m2.3.3.1.2.cmml">,</mo><mn id="S2.I3.i3.p1.2.m2.1.1" xref="S2.I3.i3.p1.2.m2.1.1.cmml">0</mn><mo id="S2.I3.i3.p1.2.m2.3.3.1.1.4" xref="S2.I3.i3.p1.2.m2.3.3.1.2.cmml">,</mo><mn id="S2.I3.i3.p1.2.m2.2.2" xref="S2.I3.i3.p1.2.m2.2.2.cmml">5</mn><mo stretchy="false" id="S2.I3.i3.p1.2.m2.3.3.1.1.5" xref="S2.I3.i3.p1.2.m2.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I3.i3.p1.2.m2.3b"><apply id="S2.I3.i3.p1.2.m2.3.3.cmml" xref="S2.I3.i3.p1.2.m2.3.3"><eq id="S2.I3.i3.p1.2.m2.3.3.2.cmml" xref="S2.I3.i3.p1.2.m2.3.3.2"></eq><ci id="S2.I3.i3.p1.2.m2.3.3.3.cmml" xref="S2.I3.i3.p1.2.m2.3.3.3">ùë£</ci><set id="S2.I3.i3.p1.2.m2.3.3.1.2.cmml" xref="S2.I3.i3.p1.2.m2.3.3.1.1"><apply id="S2.I3.i3.p1.2.m2.3.3.1.1.1.cmml" xref="S2.I3.i3.p1.2.m2.3.3.1.1.1"><minus id="S2.I3.i3.p1.2.m2.3.3.1.1.1.1.cmml" xref="S2.I3.i3.p1.2.m2.3.3.1.1.1"></minus><cn type="integer" id="S2.I3.i3.p1.2.m2.3.3.1.1.1.2.cmml" xref="S2.I3.i3.p1.2.m2.3.3.1.1.1.2">5</cn></apply><cn type="integer" id="S2.I3.i3.p1.2.m2.1.1.cmml" xref="S2.I3.i3.p1.2.m2.1.1">0</cn><cn type="integer" id="S2.I3.i3.p1.2.m2.2.2.cmml" xref="S2.I3.i3.p1.2.m2.2.2">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i3.p1.2.m2.3c">v=\{-5,\allowbreak 0,\allowbreak 5\}</annotation></semantics></math> deg. Fixation locations were randomly ordered within each block.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS4.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Image analysis</h5>

<div id="S2.SS4.SSS2.Px3.p1" class="ltx_para">
<p id="S2.SS4.SSS2.Px3.p1.1" class="ltx_p">Image analysis was performed frame-wise. A first stage was performed using the steps described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite>. Briefly, an analysis ROI and fixed pupil and CR thresholds were set manually for each participant‚Äôs videos to identify the pupil and CR in the images, as is commonly performed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>, <a href="#bib.bibx7" title="" class="ltx_ref">7</a>, <a href="#bib.bibx19" title="" class="ltx_ref">19</a>, <a href="#bib.bibx16" title="" class="ltx_ref">16</a>, <a href="#bib.bibx32" title="" class="ltx_ref">32</a>, <a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite>. We ran the analyses at different CR and pupil thresholds and selected the thresholds that maximized the precision of the signals. These thresholds were used to binarize the images and after morphological operations to fill holes, the pupil and CR were selected based on shape and size criteria. The center of the pupil and CR were then computed as the center of mass of the binary blobs. The CR center provided by this method will be referred to as the CR center localized using the thresholding method.</p>
</div>
<div id="S2.SS4.SSS2.Px3.p2" class="ltx_para">
<p id="S2.SS4.SSS2.Px3.p2.1" class="ltx_p">In a second stage, a 180√ó180 pixel cutout centered on the center location identified by the thresholding method was made. A black circular mask with a radius of 48 pixels (about three times the horizontal size of the CR blob) was furthermore applied to the input image (see right panel in Figure <a href="#S2.F3" title="Figure 3 ‚Ä£ Dataset one ‚Ä£ 2.4.2 Evaluation on real eye-images ‚Ä£ 2.4 Evaluation ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). These masked images were then fed into the radial symmetry and CNN methods and their indicated CR centers stored.</p>
</div>
<div id="S2.SS4.SSS2.Px3.p3" class="ltx_para">
<p id="S2.SS4.SSS2.Px3.p3.1" class="ltx_p">To assess whether our method also works on lower resolution eye images as may be delivered by other eye tracking setups, we reran the image analysis described above with all input images downsampled by a factor of 2. The processing method and parameters were identical to those for the full resolution eye videos, except that the radius of the black circular mask applied to the CNN‚Äôs input images was also halved.</p>
</div>
</section>
<section id="S2.SS4.SSS2.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data analysis</h5>

<div id="S2.SS4.SSS2.Px4.p1" class="ltx_para">
<p id="S2.SS4.SSS2.Px4.p1.1" class="ltx_p">To investigate the data quality of the resulting signals, the following metrics were calculated.</p>
</div>
<div id="S2.SS4.SSS2.Px4.p2" class="ltx_para">
<p id="S2.SS4.SSS2.Px4.p2.1" class="ltx_p">First, RMS-S2S precision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">10</a>, <a href="#bib.bibx28" title="" class="ltx_ref">28</a>, <a href="#bib.bibx27" title="" class="ltx_ref">27</a>]</cite> of the CR center signals estimated using the three methods was computed in camera pixels for all the collected gaze data using a moving 200-ms window, after which for each trial the median RMS from all these windows was taken <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>, <a href="#bib.bibx20" title="" class="ltx_ref">20</a>, <a href="#bib.bibx36" title="" class="ltx_ref">36</a>]</cite>. The same calculation was performed for the pupil center signal.</p>
</div>
<div id="S2.SS4.SSS2.Px4.p3" class="ltx_para">
<p id="S2.SS4.SSS2.Px4.p3.2" class="ltx_p">Then, the accuracy, RMS-S2S precision of the calibrated gaze signal computed based on the three CR center signals were estimated. For this, gaze location was determined using standard P‚ÄìCR methods: after subtracting the CR center location from the pupil center location, the resulting P‚ÄìCR gaze data were calibrated using the gaze data collected on the 3√ó3 grid of the first task. Calibration was performed with second-order polynomials in <math id="S2.SS4.SSS2.Px4.p3.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS4.SSS2.Px4.p3.1.m1.1a"><mi id="S2.SS4.SSS2.Px4.p3.1.m1.1.1" xref="S2.SS4.SSS2.Px4.p3.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px4.p3.1.m1.1b"><ci id="S2.SS4.SSS2.Px4.p3.1.m1.1.1.cmml" xref="S2.SS4.SSS2.Px4.p3.1.m1.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px4.p3.1.m1.1c">x</annotation></semantics></math> and <math id="S2.SS4.SSS2.Px4.p3.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS4.SSS2.Px4.p3.2.m2.1a"><mi id="S2.SS4.SSS2.Px4.p3.2.m2.1.1" xref="S2.SS4.SSS2.Px4.p3.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px4.p3.2.m2.1b"><ci id="S2.SS4.SSS2.Px4.p3.2.m2.1.1.cmml" xref="S2.SS4.SSS2.Px4.p3.2.m2.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px4.p3.2.m2.1c">y</annotation></semantics></math> including first-order interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">2</a>, <a href="#bib.bibx9" title="" class="ltx_ref">9</a>]</cite>:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="p_{gaze}=a+bx+cy+dx^{2}+ey^{2}+fxy," display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><msub id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.2.2.cmml">p</mi><mrow id="S2.E2.m1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.3.1" xref="S2.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.3.1a" xref="S2.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.2.3.4" xref="S2.E2.m1.1.1.1.1.2.3.4.cmml">z</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.3.1b" xref="S2.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.2.3.5" xref="S2.E2.m1.1.1.1.1.2.3.5.cmml">e</mi></mrow></msub><mo id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.3.2.cmml">a</mi><mo id="S2.E2.m1.1.1.1.1.3.1" xref="S2.E2.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.3.3.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.1.3.3.3.cmml">x</mi></mrow><mo id="S2.E2.m1.1.1.1.1.3.1a" xref="S2.E2.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.3.4" xref="S2.E2.m1.1.1.1.1.3.4.cmml"><mi id="S2.E2.m1.1.1.1.1.3.4.2" xref="S2.E2.m1.1.1.1.1.3.4.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.4.1" xref="S2.E2.m1.1.1.1.1.3.4.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.3.4.3" xref="S2.E2.m1.1.1.1.1.3.4.3.cmml">y</mi></mrow><mo id="S2.E2.m1.1.1.1.1.3.1b" xref="S2.E2.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.3.5" xref="S2.E2.m1.1.1.1.1.3.5.cmml"><mi id="S2.E2.m1.1.1.1.1.3.5.2" xref="S2.E2.m1.1.1.1.1.3.5.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.5.1" xref="S2.E2.m1.1.1.1.1.3.5.1.cmml">‚Äã</mo><msup id="S2.E2.m1.1.1.1.1.3.5.3" xref="S2.E2.m1.1.1.1.1.3.5.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.5.3.2" xref="S2.E2.m1.1.1.1.1.3.5.3.2.cmml">x</mi><mn id="S2.E2.m1.1.1.1.1.3.5.3.3" xref="S2.E2.m1.1.1.1.1.3.5.3.3.cmml">2</mn></msup></mrow><mo id="S2.E2.m1.1.1.1.1.3.1c" xref="S2.E2.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.3.6" xref="S2.E2.m1.1.1.1.1.3.6.cmml"><mi id="S2.E2.m1.1.1.1.1.3.6.2" xref="S2.E2.m1.1.1.1.1.3.6.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.6.1" xref="S2.E2.m1.1.1.1.1.3.6.1.cmml">‚Äã</mo><msup id="S2.E2.m1.1.1.1.1.3.6.3" xref="S2.E2.m1.1.1.1.1.3.6.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.6.3.2" xref="S2.E2.m1.1.1.1.1.3.6.3.2.cmml">y</mi><mn id="S2.E2.m1.1.1.1.1.3.6.3.3" xref="S2.E2.m1.1.1.1.1.3.6.3.3.cmml">2</mn></msup></mrow><mo id="S2.E2.m1.1.1.1.1.3.1d" xref="S2.E2.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.3.7" xref="S2.E2.m1.1.1.1.1.3.7.cmml"><mi id="S2.E2.m1.1.1.1.1.3.7.2" xref="S2.E2.m1.1.1.1.1.3.7.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.7.1" xref="S2.E2.m1.1.1.1.1.3.7.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.3.7.3" xref="S2.E2.m1.1.1.1.1.3.7.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.7.1a" xref="S2.E2.m1.1.1.1.1.3.7.1.cmml">‚Äã</mo><mi id="S2.E2.m1.1.1.1.1.3.7.4" xref="S2.E2.m1.1.1.1.1.3.7.4.cmml">y</mi></mrow></mrow></mrow><mo id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><eq id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"></eq><apply id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2">ùëù</ci><apply id="S2.E2.m1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3"><times id="S2.E2.m1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.2.3.1"></times><ci id="S2.E2.m1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2">ùëî</ci><ci id="S2.E2.m1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3.3">ùëé</ci><ci id="S2.E2.m1.1.1.1.1.2.3.4.cmml" xref="S2.E2.m1.1.1.1.1.2.3.4">ùëß</ci><ci id="S2.E2.m1.1.1.1.1.2.3.5.cmml" xref="S2.E2.m1.1.1.1.1.2.3.5">ùëí</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"><plus id="S2.E2.m1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1"></plus><ci id="S2.E2.m1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2">ùëé</ci><apply id="S2.E2.m1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3"><times id="S2.E2.m1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1"></times><ci id="S2.E2.m1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2">ùëè</ci><ci id="S2.E2.m1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3">ùë•</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.4.cmml" xref="S2.E2.m1.1.1.1.1.3.4"><times id="S2.E2.m1.1.1.1.1.3.4.1.cmml" xref="S2.E2.m1.1.1.1.1.3.4.1"></times><ci id="S2.E2.m1.1.1.1.1.3.4.2.cmml" xref="S2.E2.m1.1.1.1.1.3.4.2">ùëê</ci><ci id="S2.E2.m1.1.1.1.1.3.4.3.cmml" xref="S2.E2.m1.1.1.1.1.3.4.3">ùë¶</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.5.cmml" xref="S2.E2.m1.1.1.1.1.3.5"><times id="S2.E2.m1.1.1.1.1.3.5.1.cmml" xref="S2.E2.m1.1.1.1.1.3.5.1"></times><ci id="S2.E2.m1.1.1.1.1.3.5.2.cmml" xref="S2.E2.m1.1.1.1.1.3.5.2">ùëë</ci><apply id="S2.E2.m1.1.1.1.1.3.5.3.cmml" xref="S2.E2.m1.1.1.1.1.3.5.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.5.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.5.3">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.5.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.5.3.2">ùë•</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.3.5.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.5.3.3">2</cn></apply></apply><apply id="S2.E2.m1.1.1.1.1.3.6.cmml" xref="S2.E2.m1.1.1.1.1.3.6"><times id="S2.E2.m1.1.1.1.1.3.6.1.cmml" xref="S2.E2.m1.1.1.1.1.3.6.1"></times><ci id="S2.E2.m1.1.1.1.1.3.6.2.cmml" xref="S2.E2.m1.1.1.1.1.3.6.2">ùëí</ci><apply id="S2.E2.m1.1.1.1.1.3.6.3.cmml" xref="S2.E2.m1.1.1.1.1.3.6.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.6.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.6.3">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.6.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.6.3.2">ùë¶</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.3.6.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.6.3.3">2</cn></apply></apply><apply id="S2.E2.m1.1.1.1.1.3.7.cmml" xref="S2.E2.m1.1.1.1.1.3.7"><times id="S2.E2.m1.1.1.1.1.3.7.1.cmml" xref="S2.E2.m1.1.1.1.1.3.7.1"></times><ci id="S2.E2.m1.1.1.1.1.3.7.2.cmml" xref="S2.E2.m1.1.1.1.1.3.7.2">ùëì</ci><ci id="S2.E2.m1.1.1.1.1.3.7.3.cmml" xref="S2.E2.m1.1.1.1.1.3.7.3">ùë•</ci><ci id="S2.E2.m1.1.1.1.1.3.7.4.cmml" xref="S2.E2.m1.1.1.1.1.3.7.4">ùë¶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">p_{gaze}=a+bx+cy+dx^{2}+ey^{2}+fxy,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS4.SSS2.Px4.p3.3" class="ltx_p">where <math id="S2.SS4.SSS2.Px4.p3.3.m1.1" class="ltx_Math" alttext="p_{gaze}" display="inline"><semantics id="S2.SS4.SSS2.Px4.p3.3.m1.1a"><msub id="S2.SS4.SSS2.Px4.p3.3.m1.1.1" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.cmml"><mi id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.2" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.2.cmml">p</mi><mrow id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.cmml"><mi id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.2" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.3" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1a" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.4" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.4.cmml">z</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1b" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1.cmml">‚Äã</mo><mi id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.5" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.Px4.p3.3.m1.1b"><apply id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.1.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1">subscript</csymbol><ci id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.2.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.2">ùëù</ci><apply id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3"><times id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.1"></times><ci id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.2.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.2">ùëî</ci><ci id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.3.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.3">ùëé</ci><ci id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.4.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.4">ùëß</ci><ci id="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.5.cmml" xref="S2.SS4.SSS2.Px4.p3.3.m1.1.1.3.5">ùëí</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.Px4.p3.3.m1.1c">p_{gaze}</annotation></semantics></math> is the gaze position in degrees. The same formula was applied to compute the horizontal and vertical gaze positions. The accuracy of the gaze signal was then computed for each trial as the offset between the median estimated gaze location and the fixation point location for the data of task 4 in dataset one and task 3 in dataset two. The accuracy values for the repeated fixations on the 15 fixation targets were averaged. Similarly to the CR and pupil center signals, RMS-S2S and also STD precision of the gaze signal was computed in moving 200-ms windows for all the collected gaze data, after which for each trial the median RMS or STD value from all these windows was taken.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Optimal CR center localization performance</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Figure <a href="#S3.F4" title="Figure 4 ‚Ä£ 3.1 Optimal CR center localization performance ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the best obtainable CR center localization performance based on the information in the synthetic CR images for the different Gaussian amplitudes (different panels) and CR sizes (lines within each panel). As can be seen, appreciable errors in CR center location occur at all examined Gaussian amplitudes for the smallest CR size (2), and also for CR size 4 for higher Gaussian amplitudes (i.e. images containing narrower tails). Furthermore, error increases as a function of Gaussian amplitude (narrower tails). To illustrate how close the different CR center localization methods are to their optimal performance, the results of this examination will be used as reference lines when presenting the evaluation on synthetic images in the ‚Äú<a href="#S3.SS2" title="In 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref ltx_refmacro_nameref"><span class="ltx_text ltx_ref_title">Evaluation on synthetic CRs</span></a>‚Äù section below.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size_amplitude10.png" id="S3.F4.1.g1" class="ltx_graphics ltx_img_square" width="188" height="182" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size_amplitude50.png" id="S3.F4.2.g1" class="ltx_graphics ltx_img_square" width="167" height="182" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size_amplitude200.png" id="S3.F4.3.g1" class="ltx_graphics ltx_img_square" width="188" height="206" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size_amplitude1000.png" id="S3.F4.4.g1" class="ltx_graphics ltx_img_square" width="167" height="182" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size_amplitude10000.png" id="S3.F4.5.g1" class="ltx_graphics ltx_img_square" width="167" height="182" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Best achievable CR center localization errors for different Gaussian amplitudes <math id="S3.F4.8.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.F4.8.m1.1b"><mi id="S3.F4.8.m1.1.1" xref="S3.F4.8.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.F4.8.m1.1c"><ci id="S3.F4.8.m1.1.1.cmml" xref="S3.F4.8.m1.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.8.m1.1d">A</annotation></semantics></math> (different panels) and CR radii <math id="S3.F4.9.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.F4.9.m2.1b"><mi id="S3.F4.9.m2.1.1" xref="S3.F4.9.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.F4.9.m2.1c"><ci id="S3.F4.9.m2.1.1.cmml" xref="S3.F4.9.m2.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.9.m2.1d">r</annotation></semantics></math> (different lines in each panel).</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation on synthetic CRs</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p">First we set out to examine whether our method was able to locate the CR center more accurately than two commonly used algorithmic approaches when applied to synthetic data.
Figure <a href="#S3.F5" title="Figure 5 ‚Ä£ 3.2 Evaluation on synthetic CRs ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the error in CR center localization achieved by the three methods for three different CR sizes. Negative errors are leftward, and positive rightward. For illustration purposes, results are shown for Gaussian amplitude <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="A=10000" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">A</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">10000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ùê¥</ci><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">10000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">A=10000</annotation></semantics></math> and a half-grey background (<math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="E=0" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">E</mi><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><eq id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></eq><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ùê∏</ci><cn type="integer" id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">E=0</annotation></semantics></math>, <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="I=128" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">I</mi><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><eq id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></eq><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ùêº</ci><cn type="integer" id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">I=128</annotation></semantics></math>). As can be seen, for the smallest CR size, the CNN and thresholding methods perform similarly, while the radial symmetry method shows a larger bias towards the left of the image, which is the gray side. As CR size increases, this bias towards the grey side of the image for the radial symmetry method only slightly decreases. For these larger CR sizes, the center localization output of the threshold and CNN methods becomes more smooth, and the CNN by and large shows a lower error than the threshold method.</p>
</div>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size2_amplitude10000.png" id="S3.F5.1.g1" class="ltx_graphics ltx_img_square" width="214" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size10_amplitude10000.png" id="S3.F5.2.g1" class="ltx_graphics ltx_img_square" width="189" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F5.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/error_size18_amplitude10000.png" id="S3.F5.3.g1" class="ltx_graphics ltx_img_square" width="189" height="210" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Errors in CR center localization for different CR sizes <math id="S3.F5.8.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.F5.8.m1.1b"><mi id="S3.F5.8.m1.1.1" xref="S3.F5.8.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.F5.8.m1.1c"><ci id="S3.F5.8.m1.1.1.cmml" xref="S3.F5.8.m1.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.8.m1.1d">r</annotation></semantics></math> for three methods. The panel insets show boxplots of
the CR center localization error for each estimated input position. For all these simulations, <math id="S3.F5.9.m2.1" class="ltx_Math" alttext="A=10000" display="inline"><semantics id="S3.F5.9.m2.1b"><mrow id="S3.F5.9.m2.1.1" xref="S3.F5.9.m2.1.1.cmml"><mi id="S3.F5.9.m2.1.1.2" xref="S3.F5.9.m2.1.1.2.cmml">A</mi><mo id="S3.F5.9.m2.1.1.1" xref="S3.F5.9.m2.1.1.1.cmml">=</mo><mn id="S3.F5.9.m2.1.1.3" xref="S3.F5.9.m2.1.1.3.cmml">10000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.9.m2.1c"><apply id="S3.F5.9.m2.1.1.cmml" xref="S3.F5.9.m2.1.1"><eq id="S3.F5.9.m2.1.1.1.cmml" xref="S3.F5.9.m2.1.1.1"></eq><ci id="S3.F5.9.m2.1.1.2.cmml" xref="S3.F5.9.m2.1.1.2">ùê¥</ci><cn type="integer" id="S3.F5.9.m2.1.1.3.cmml" xref="S3.F5.9.m2.1.1.3">10000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.9.m2.1d">A=10000</annotation></semantics></math>, <math id="S3.F5.10.m3.1" class="ltx_Math" alttext="E=0" display="inline"><semantics id="S3.F5.10.m3.1b"><mrow id="S3.F5.10.m3.1.1" xref="S3.F5.10.m3.1.1.cmml"><mi id="S3.F5.10.m3.1.1.2" xref="S3.F5.10.m3.1.1.2.cmml">E</mi><mo id="S3.F5.10.m3.1.1.1" xref="S3.F5.10.m3.1.1.1.cmml">=</mo><mn id="S3.F5.10.m3.1.1.3" xref="S3.F5.10.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.10.m3.1c"><apply id="S3.F5.10.m3.1.1.cmml" xref="S3.F5.10.m3.1.1"><eq id="S3.F5.10.m3.1.1.1.cmml" xref="S3.F5.10.m3.1.1.1"></eq><ci id="S3.F5.10.m3.1.1.2.cmml" xref="S3.F5.10.m3.1.1.2">ùê∏</ci><cn type="integer" id="S3.F5.10.m3.1.1.3.cmml" xref="S3.F5.10.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.10.m3.1d">E=0</annotation></semantics></math>, <math id="S3.F5.11.m4.1" class="ltx_Math" alttext="I=128" display="inline"><semantics id="S3.F5.11.m4.1b"><mrow id="S3.F5.11.m4.1.1" xref="S3.F5.11.m4.1.1.cmml"><mi id="S3.F5.11.m4.1.1.2" xref="S3.F5.11.m4.1.1.2.cmml">I</mi><mo id="S3.F5.11.m4.1.1.1" xref="S3.F5.11.m4.1.1.1.cmml">=</mo><mn id="S3.F5.11.m4.1.1.3" xref="S3.F5.11.m4.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.11.m4.1c"><apply id="S3.F5.11.m4.1.1.cmml" xref="S3.F5.11.m4.1.1"><eq id="S3.F5.11.m4.1.1.1.cmml" xref="S3.F5.11.m4.1.1.1"></eq><ci id="S3.F5.11.m4.1.1.2.cmml" xref="S3.F5.11.m4.1.1.2">ùêº</ci><cn type="integer" id="S3.F5.11.m4.1.1.3.cmml" xref="S3.F5.11.m4.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.11.m4.1d">I=128</annotation></semantics></math></figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Localization performance of the three methods as a function of CR size for three different pixel noise levels is plotted in Figure <a href="#S3.F6" title="Figure 6 ‚Ä£ 3.2 Evaluation on synthetic CRs ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (top-left panel). As can be seen, error in localization is almost independent of CR size for the threshold and CNN methods while error decreases as a function of CR size for the radial symmetry method. The thresholding and CNN methods are not affected by noise in the input image in the range that we examined and achieve similar CR center localization error. On the other hand, the radial symmetry method was strongly affected by pixel noise level (errors were mostly over 0.5 pixels at noise level 8 and ranged from 3‚Äì8 pixels at noise level 18, not shown). As such, further plots show results at noise level 0 to highlight the best possible performance of the radial symmetry method.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">The effect of the pixel intensity level of the lighter background section is shown in Figure <a href="#S3.F6" title="Figure 6 ‚Ä£ 3.2 Evaluation on synthetic CRs ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (top-right panel). Similar to the effect of pixel noise level, the localization error of the threshold and CNN methods, but not the radial symmetry method, is almost independent of CR size and background pixel intensity level. Furthermore, performance of the CNN method is very close to that of the threshold method, with both achieving errors of around to well below 0.1 pixels across CR sizes.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">The effect of the location of the grey background on localization performance is shown in Figure <a href="#S3.F6" title="Figure 6 ‚Ä£ 3.2 Evaluation on synthetic CRs ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (bottom-left panel). While all methods performed nearly perfectly when the background was fully black, only the threshold and CNN methods are stable over different locations of the gray background. The performance of the radial symmetry method is strongly affected by the position of the gray background, and overall shows much larger errors than when no gray background was present.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">The effect of the width of the tail of the CR is shown in Figure <a href="#S3.F6" title="Figure 6 ‚Ä£ 3.2 Evaluation on synthetic CRs ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (bottom-right panel). Recall that more saturated Gaussians (those with larger amplitude <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">A</annotation></semantics></math>) have narrower tails (c.f. Figure <a href="#S2.F2" title="Figure 2 ‚Ä£ 2.3 Generating Synthetic Images ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). As can be seen, the effect of tail width on CR localization performance is minimal for the three methods. Taken together, importantly, the localization performance of the CNN is on par with the best-performing algorithmic approach to CR localization, achieving average errors of around or well below 0.1 pixels in all cases.</p>
</div>
<figure id="S3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F6.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/cr_area_vs_error_noiselevel.png" id="S3.F6.1.g1" class="ltx_graphics ltx_img_square" width="228" height="229" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F6.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/cr_area_vs_error_gray_level.png" id="S3.F6.2.g1" class="ltx_graphics ltx_img_square" width="199" height="225" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F6.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/cr_area_vs_error_bg_pos.png" id="S3.F6.3.g1" class="ltx_graphics ltx_img_square" width="203" height="229" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F6.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/cr_area_vs_error_gauss_amp.png" id="S3.F6.4.g1" class="ltx_graphics ltx_img_square" width="199" height="225" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Errors in CR center localization for the three methods as a function of CR radius, for different noise levels (top-left), pixel intensity levels of the lighter background section (top-right), locations of the gray background (bottom-left) and Gaussian amplitudes (bottom-right). For the top-left panel, average error of the radial symmetry method ranged from 3‚Äì8 pixels at noise level 18, not shown. For the top-right and bottom panels, the noise level was 0. For the bottom panels, the pixel intensity level of the lighter background section <math id="S3.F6.7.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.F6.7.m1.1b"><mi id="S3.F6.7.m1.1.1" xref="S3.F6.7.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.F6.7.m1.1c"><ci id="S3.F6.7.m1.1.1.cmml" xref="S3.F6.7.m1.1.1">ùêº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.7.m1.1d">I</annotation></semantics></math> was 128. For the bottom-right panel, the background location <math id="S3.F6.8.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.F6.8.m2.1b"><mi id="S3.F6.8.m2.1.1" xref="S3.F6.8.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.F6.8.m2.1c"><ci id="S3.F6.8.m2.1.1.cmml" xref="S3.F6.8.m2.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.8.m2.1d">E</annotation></semantics></math> was 0.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation on real eye images.</h3>

<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/signals_raw_paper_.png" id="S3.F7.1.g1" class="ltx_graphics ltx_img_landscape" width="356" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_raw_rms_.png" id="S3.F7.2.g1" class="ltx_graphics ltx_img_square" width="216" height="210" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Real eye CR and pupil center signals of dataset one</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F7.6" class="ltx_p ltx_figure_panel ltx_align_center">. Left: representative segment of pupil and CR center signals from S03 in camera pixels. For the CR center, the signals produced by three different CR center localization methods are shown. The signals contain two small saccades and have been vertically offset for clarity. RMS precision for the shown segments are <math id="S3.F7.3.m1.3" class="ltx_Math" alttext="0.081\text{\,}\mathrm{px}\text{/}" display="inline"><semantics id="S3.F7.3.m1.3a"><mrow id="S3.F7.3.m1.3.3" xref="S3.F7.3.m1.3.3.cmml"><mn id="S3.F7.3.m1.1.1.1.1.1.1" xref="S3.F7.3.m1.1.1.1.1.1.1.cmml">0.081</mn><mtext id="S3.F7.3.m1.2.2.2.2.2.2" xref="S3.F7.3.m1.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F7.3.m1.3.3.3.3.3.3" xref="S3.F7.3.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S3.F7.3.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F7.3.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">px</mi><mtext id="S3.F7.3.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F7.3.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F7.3.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F7.3.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F7.3.m1.3b"><apply id="S3.F7.3.m1.3.3.cmml" xref="S3.F7.3.m1.3.3"><csymbol cd="latexml" id="S3.F7.3.m1.2.2.2.2.2.2.cmml" xref="S3.F7.3.m1.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F7.3.m1.1.1.1.1.1.1.cmml" xref="S3.F7.3.m1.1.1.1.1.1.1">0.081</cn><apply id="S3.F7.3.m1.3.3.3.3.3.3.cmml" xref="S3.F7.3.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F7.3.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F7.3.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F7.3.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F7.3.m1.3.3.3.3.3.3.1.1.1.1.1.1">pixel</csymbol><csymbol cd="latexml" id="S3.F7.3.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F7.3.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F7.3.m1.3c">0.081\text{\,}\mathrm{px}\text{/}</annotation></semantics></math> for the Threshold signal, <math id="S3.F7.4.m2.3" class="ltx_Math" alttext="0.061\text{\,}\mathrm{px}\text{/}" display="inline"><semantics id="S3.F7.4.m2.3a"><mrow id="S3.F7.4.m2.3.3" xref="S3.F7.4.m2.3.3.cmml"><mn id="S3.F7.4.m2.1.1.1.1.1.1" xref="S3.F7.4.m2.1.1.1.1.1.1.cmml">0.061</mn><mtext id="S3.F7.4.m2.2.2.2.2.2.2" xref="S3.F7.4.m2.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F7.4.m2.3.3.3.3.3.3" xref="S3.F7.4.m2.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S3.F7.4.m2.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F7.4.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">px</mi><mtext id="S3.F7.4.m2.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F7.4.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F7.4.m2.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F7.4.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F7.4.m2.3b"><apply id="S3.F7.4.m2.3.3.cmml" xref="S3.F7.4.m2.3.3"><csymbol cd="latexml" id="S3.F7.4.m2.2.2.2.2.2.2.cmml" xref="S3.F7.4.m2.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F7.4.m2.1.1.1.1.1.1.cmml" xref="S3.F7.4.m2.1.1.1.1.1.1">0.061</cn><apply id="S3.F7.4.m2.3.3.3.3.3.3.cmml" xref="S3.F7.4.m2.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F7.4.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F7.4.m2.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F7.4.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F7.4.m2.3.3.3.3.3.3.1.1.1.1.1.1">pixel</csymbol><csymbol cd="latexml" id="S3.F7.4.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F7.4.m2.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F7.4.m2.3c">0.061\text{\,}\mathrm{px}\text{/}</annotation></semantics></math> for CNN, and <math id="S3.F7.5.m3.3" class="ltx_Math" alttext="0.096\text{\,}\mathrm{px}\text{/}" display="inline"><semantics id="S3.F7.5.m3.3a"><mrow id="S3.F7.5.m3.3.3" xref="S3.F7.5.m3.3.3.cmml"><mn id="S3.F7.5.m3.1.1.1.1.1.1" xref="S3.F7.5.m3.1.1.1.1.1.1.cmml">0.096</mn><mtext id="S3.F7.5.m3.2.2.2.2.2.2" xref="S3.F7.5.m3.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F7.5.m3.3.3.3.3.3.3" xref="S3.F7.5.m3.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S3.F7.5.m3.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F7.5.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml">px</mi><mtext id="S3.F7.5.m3.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F7.5.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F7.5.m3.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F7.5.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F7.5.m3.3b"><apply id="S3.F7.5.m3.3.3.cmml" xref="S3.F7.5.m3.3.3"><csymbol cd="latexml" id="S3.F7.5.m3.2.2.2.2.2.2.cmml" xref="S3.F7.5.m3.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F7.5.m3.1.1.1.1.1.1.cmml" xref="S3.F7.5.m3.1.1.1.1.1.1">0.096</cn><apply id="S3.F7.5.m3.3.3.3.3.3.3.cmml" xref="S3.F7.5.m3.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F7.5.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F7.5.m3.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F7.5.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F7.5.m3.3.3.3.3.3.3.1.1.1.1.1.1">pixel</csymbol><csymbol cd="latexml" id="S3.F7.5.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F7.5.m3.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F7.5.m3.3c">0.096\text{\,}\mathrm{px}\text{/}</annotation></semantics></math> for Radial symmetry and <math id="S3.F7.6.m4.3" class="ltx_Math" alttext="0.121\text{\,}\mathrm{px}\text{/}" display="inline"><semantics id="S3.F7.6.m4.3a"><mrow id="S3.F7.6.m4.3.3" xref="S3.F7.6.m4.3.3.cmml"><mn id="S3.F7.6.m4.1.1.1.1.1.1" xref="S3.F7.6.m4.1.1.1.1.1.1.cmml">0.121</mn><mtext id="S3.F7.6.m4.2.2.2.2.2.2" xref="S3.F7.6.m4.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F7.6.m4.3.3.3.3.3.3" xref="S3.F7.6.m4.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S3.F7.6.m4.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F7.6.m4.3.3.3.3.3.3.1.1.1.1.1.1.cmml">px</mi><mtext id="S3.F7.6.m4.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F7.6.m4.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F7.6.m4.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F7.6.m4.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F7.6.m4.3b"><apply id="S3.F7.6.m4.3.3.cmml" xref="S3.F7.6.m4.3.3"><csymbol cd="latexml" id="S3.F7.6.m4.2.2.2.2.2.2.cmml" xref="S3.F7.6.m4.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F7.6.m4.1.1.1.1.1.1.cmml" xref="S3.F7.6.m4.1.1.1.1.1.1">0.121</cn><apply id="S3.F7.6.m4.3.3.3.3.3.3.cmml" xref="S3.F7.6.m4.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F7.6.m4.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F7.6.m4.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F7.6.m4.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F7.6.m4.3.3.3.3.3.3.1.1.1.1.1.1">pixel</csymbol><csymbol cd="latexml" id="S3.F7.6.m4.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F7.6.m4.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F7.6.m4.3c">0.121\text{\,}\mathrm{px}\text{/}</annotation></semantics></math> for the pupil signal. Further, an RMS precision comparison (right panel) between the three methods and the pupil signal on all data of three participants is shown. Error bars depict standard error of the mean.</p>
</div>
</div>
</figure>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Dataset one</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Next, we set out to test whether our method is able to perform CR center localization in real eye images and if so, whether it delivers a CR position signal with higher precision than two algorithmic approaches.
To test how well our method works on real eye images, we first performed CR and pupil center localization on dataset one, which consisted of <math id="S3.SS3.SSS1.p1.1.m1.3" class="ltx_Math" alttext="500\text{\,}\mathrm{H}\mathrm{z}" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.3a"><mrow id="S3.SS3.SSS1.p1.1.m1.3.3" xref="S3.SS3.SSS1.p1.1.m1.3.3.cmml"><mn id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.cmml">500</mn><mtext id="S3.SS3.SSS1.p1.1.m1.2.2.2.2.2.2" xref="S3.SS3.SSS1.p1.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mi id="S3.SS3.SSS1.p1.1.m1.3.3.3.3.3.3" xref="S3.SS3.SSS1.p1.1.m1.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.3b"><apply id="S3.SS3.SSS1.p1.1.m1.3.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.3.3"><csymbol cd="latexml" id="S3.SS3.SSS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1">500</cn><ci id="S3.SS3.SSS1.p1.1.m1.3.3.3.3.3.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.3.3.3.3.3.3">Hz</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.3c">500\text{\,}\mathrm{H}\mathrm{z}</annotation></semantics></math> videos of eye movements made by three participants. CR localization was performed by three methods.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">The left panel of Figure <a href="#S3.F7" title="Figure 7 ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows an example segment of CR center locations estimated using the three methods, along with the estimated pupil center location. A can be seen, the CR center signal from the CNN method appears smoother than the signal from the threshold method, while the signal from the radial symmetry method looks less smooth than the threshold signal. The pupil center signal by and large looks similarly noisy as the CR signal from the radial symmetry method.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">To quantify these observations, we calculated the RMS precision of all four signals for all recorded videos of three participants. The results of this analysis are shown in Figure¬†<a href="#S3.F7" title="Figure 7 ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (right panel). While there were differences in overall noise level between participants, a clear pattern in results for the CR center localization methods is seen. The CNN method consistently delivers signals with a better precision (lower values) than the thresholding method, while the radial symmetry method delivers signals with worse precision (higher values). Precision of the pupil center signal is consistently much worse than that of the CNN- or thresholding-based CR center signals. It is important to note here that all methods processed each video frame independently, and that improved precision could thus not be due to any form of temporal information being used from previous or future frames <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, c.f.]</cite>]niehorster2020apparent,niehorster2020characterizing.</p>
</div>
<figure id="S3.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/signals_paper_.png" id="S3.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="358" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_acc_.png" id="S3.F8.2.g1" class="ltx_graphics ltx_img_square" width="186" height="180" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F8.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_rms_.png" id="S3.F8.3.g1" class="ltx_graphics ltx_img_square" width="186" height="183" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F8.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_std_.png" id="S3.F8.4.g1" class="ltx_graphics ltx_img_square" width="186" height="183" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Real eye calibrated gaze signals of dataset one</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<p id="S3.F8.7" class="ltx_p ltx_figure_panel ltx_align_center">. Top: representative segment of calibrated P-CR signals from S03 as processed by three different CR center localization methods. The signals contain two small saccades and have been vertically offset for clarity. RMS precision for the shown segments are <math id="S3.F8.5.m1.3" class="ltx_Math" alttext="0.040\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}" display="inline"><semantics id="S3.F8.5.m1.3a"><mrow id="S3.F8.5.m1.3.3" xref="S3.F8.5.m1.3.3.cmml"><mn id="S3.F8.5.m1.1.1.1.1.1.1" xref="S3.F8.5.m1.1.1.1.1.1.1.cmml">0.040</mn><mtext id="S3.F8.5.m1.2.2.2.2.2.2" xref="S3.F8.5.m1.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F8.5.m1.3.3.3.3.3.3" xref="S3.F8.5.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.F8.5.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F8.5.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬∞</mi><mtext id="S3.F8.5.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F8.5.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F8.5.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F8.5.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F8.5.m1.3b"><apply id="S3.F8.5.m1.3.3.cmml" xref="S3.F8.5.m1.3.3"><csymbol cd="latexml" id="S3.F8.5.m1.2.2.2.2.2.2.cmml" xref="S3.F8.5.m1.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F8.5.m1.1.1.1.1.1.1.cmml" xref="S3.F8.5.m1.1.1.1.1.1.1">0.040</cn><apply id="S3.F8.5.m1.3.3.3.3.3.3.cmml" xref="S3.F8.5.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F8.5.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F8.5.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F8.5.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F8.5.m1.3.3.3.3.3.3.1.1.1.1.1.1">degree</csymbol><csymbol cd="latexml" id="S3.F8.5.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F8.5.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F8.5.m1.3c">0.040\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}</annotation></semantics></math> for the Threshold signal, <math id="S3.F8.6.m2.3" class="ltx_Math" alttext="0.034\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}" display="inline"><semantics id="S3.F8.6.m2.3a"><mrow id="S3.F8.6.m2.3.3" xref="S3.F8.6.m2.3.3.cmml"><mn id="S3.F8.6.m2.1.1.1.1.1.1" xref="S3.F8.6.m2.1.1.1.1.1.1.cmml">0.034</mn><mtext id="S3.F8.6.m2.2.2.2.2.2.2" xref="S3.F8.6.m2.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F8.6.m2.3.3.3.3.3.3" xref="S3.F8.6.m2.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.F8.6.m2.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F8.6.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬∞</mi><mtext id="S3.F8.6.m2.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F8.6.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F8.6.m2.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F8.6.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F8.6.m2.3b"><apply id="S3.F8.6.m2.3.3.cmml" xref="S3.F8.6.m2.3.3"><csymbol cd="latexml" id="S3.F8.6.m2.2.2.2.2.2.2.cmml" xref="S3.F8.6.m2.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F8.6.m2.1.1.1.1.1.1.cmml" xref="S3.F8.6.m2.1.1.1.1.1.1">0.034</cn><apply id="S3.F8.6.m2.3.3.3.3.3.3.cmml" xref="S3.F8.6.m2.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F8.6.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F8.6.m2.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F8.6.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F8.6.m2.3.3.3.3.3.3.1.1.1.1.1.1">degree</csymbol><csymbol cd="latexml" id="S3.F8.6.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F8.6.m2.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F8.6.m2.3c">0.034\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}</annotation></semantics></math> for CNN, and <math id="S3.F8.7.m3.3" class="ltx_Math" alttext="0.046\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}" display="inline"><semantics id="S3.F8.7.m3.3a"><mrow id="S3.F8.7.m3.3.3" xref="S3.F8.7.m3.3.3.cmml"><mn id="S3.F8.7.m3.1.1.1.1.1.1" xref="S3.F8.7.m3.1.1.1.1.1.1.cmml">0.046</mn><mtext id="S3.F8.7.m3.2.2.2.2.2.2" xref="S3.F8.7.m3.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S3.F8.7.m3.3.3.3.3.3.3" xref="S3.F8.7.m3.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.F8.7.m3.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F8.7.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml">¬∞</mi><mtext id="S3.F8.7.m3.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F8.7.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.F8.7.m3.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F8.7.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F8.7.m3.3b"><apply id="S3.F8.7.m3.3.3.cmml" xref="S3.F8.7.m3.3.3"><csymbol cd="latexml" id="S3.F8.7.m3.2.2.2.2.2.2.cmml" xref="S3.F8.7.m3.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.F8.7.m3.1.1.1.1.1.1.cmml" xref="S3.F8.7.m3.1.1.1.1.1.1">0.046</cn><apply id="S3.F8.7.m3.3.3.3.3.3.3.cmml" xref="S3.F8.7.m3.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F8.7.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F8.7.m3.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.F8.7.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F8.7.m3.3.3.3.3.3.3.1.1.1.1.1.1">degree</csymbol><csymbol cd="latexml" id="S3.F8.7.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F8.7.m3.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F8.7.m3.3c">0.046\text{\,}\mathrm{\SIUnitSymbolDegree}\text{/}</annotation></semantics></math> for Radial symmetry. Further, an accuracy comparison (bottom left panel), an RMS precision comparison (bottom middle panel) and an STD precision comparison (bottom right panel) between the three methods on data of three participants are shown. Error bars depict standard error of the mean.</p>
</div>
</div>
</figure>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.p4.1" class="ltx_p">How does the improved CR center localization of our method impact the gaze signal? To answer this question, we performed a similar analysis as above, but on the calibrated gaze signals. The top panel of Figure <a href="#S3.F8" title="Figure 8 ‚Ä£ 3.3.1 Dataset one ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows an example segment of gaze data computed from the three signals. As can be seen, the gaze signals derived from the three different CR localization methods look much more similar than the CR center signals in Figure <a href="#S3.F7" title="Figure 7 ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (left panel). This is likely due to the fact that derivation of the gaze signal involves subtracting the estimated CR center location from the much noisier pupil center location estimate <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, c.f.]</cite>]niehorster2018rawclassify. The noise in the pupil center location estimate likely is the dominant component of noise in the derived gaze signal, to a large extent swamping the differences in precision between the CR center location signals.</p>
</div>
<div id="S3.SS3.SSS1.p5" class="ltx_para">
<p id="S3.SS3.SSS1.p5.1" class="ltx_p">The bottom panels of Figure <a href="#S3.F8" title="Figure 8 ‚Ä£ 3.3.1 Dataset one ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> show the accuracy, RMS-S2S, and STD precision achieved with the three CR center localization methods. While there were small differences between the participants, no systematic differences in accuracy between the three methods were observed. Overall, both the RMS-S2S and the STD precision of the gaze signals derived from the CR center localization estimates of the CNN was a little lower than for the gaze signal derived from the threshold-based CR center, while that for the gaze signal derived from the radial symmetry method for CR center localization showed worse precision.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Dataset two</h4>

<figure id="S3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_rms_d2.png" id="S3.F9.1.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_rms_d2_scale2.png" id="S3.F9.2.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>RMS-S2S precision of the raw signals for dataset two. An RMS precision comparison between the CR center signals derived from the three methods and the pupil center signal is shown for all participants (colored symbols) along with the mean across participants (black circles) for analyses run both at full video resolution (left panel) and at half resolution (right panel). Error bars depict standard error of the mean.</figcaption>
</figure>
<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">To examine how our method performs on real eye images across a wider range of participants with different eye physiology and for lower resolution eye images, we have collected a new set of 17 participants (one of which was excluded from analysis, see methods) and analyzed the videos captured both at full and at half resolution.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">Figure <a href="#S3.F9" title="Figure 9 ‚Ä£ 3.3.2 Dataset two ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows the calculated RMS precision of the CR signal processed using three different methods, and the pupil signal, for all recorded videos of all participants. The same pattern emerges for the full resolution and the half resolution videos. As we saw for dataset one, while there were differences in overall noise level between participants, a clear pattern of results emerges where the CNN method delivers signals with a better precision (lower values) than the thresholding method, and the radial symmetry method performs worse (higher values) than the CNN method. As before, the precision of the pupil center signal is worse than that of the CNN- or thresholding-based CR center signals.</p>
</div>
<figure id="S3.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F10.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_rms_d2.png" id="S3.F10.1.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F10.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_rms_d2_scale2.png" id="S3.F10.2.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F10.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_std_d2.png" id="S3.F10.3.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F10.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_std_d2_scale2.png" id="S3.F10.4.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F10.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_acc_d2.png" id="S3.F10.5.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F10.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.05673/assets/paper_acc_d2_scale2.png" id="S3.F10.6.g1" class="ltx_graphics ltx_img_square" width="224" height="210" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Data quality of calibrated gaze signals of dataset two. RMS-S2S precision (top panels), STD precision (middle panels) and accuracy (bottom panels) comparisons of the calibrated gaze signals derived from the three CR center localization methods is shown for all participants (colored symbols) along with the mean across participants (black circles) for analyses run both at full video resolution (left panels) and at half resolution (right panels). Error bars depict standard error of the mean.</figcaption>
</figure>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p">To examine how the CR center localization methods impact the resulting calibrated gaze signals, we computed the RMS-S2S and STD precision, and the accuracy of the calibrated gaze signals of each participant for both the full resolution and half resolution video analyses. As for dataset one, in most cases there were only small differences in RMS-S2S and STD precision (Figure <a href="#S3.F10" title="Figure 10 ‚Ä£ 3.3.2 Dataset two ‚Ä£ 3.3 Evaluation on real eye images. ‚Ä£ 3 Results ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, top and middle rows) between the three CR center localization methods for both video resolutions, with the CNN method showing slightly better precision (lower values) than the other methods. Only for the half-resolution analysis was the STD precision of the gaze signal derived from the threshold method clearly worse (higher values) than for the signals derived from the CNN and radial symmetry methods. Accuracy did not vary systematically between the three methods.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we have developed a CNN architecture and training regime for localizing single CRs in eye images. We have furthermore analyzed the spatial accuracy and precision obtained with this new method using synthetic and real eye images. Regarding the research questions posed in the introduction, the contributions of this paper are: that 1) we provide a simple method using only synthetic images to train a CNN to perform CR center localization and demonstrate that a CNN trained using this method can perform CR center localization in real eye images; 2) we show that our method is able to locate the CR center similarly accurately as a commonly used algorithmic approach when applied to synthetic data; and 3) we demonstrate that our method can outperform algorithmic approaches to CR center localization in terms of spatial precision when applied to real eye images.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Specifically, the paper has shown that our CNN-based method consistently outperforms the popular thresholding method for CR center localization as well as the radial symmetry method that was recently adopted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">40</a>]</cite>. As <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">38</a>]</cite> have recently shown, binarizing an eye image using a thresholding operation reduces the CR center localization accuracy compared to methods that use the full range of pixel intensity values in the image of the CR <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">[</span>, c.f. also]</cite>who show this in the context of microscopy]helgadottir2019digital. The radial symmetry method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite> uses the full range of intensity values and has been shown to outperform thresholding for localization of the center of image features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">40</a>, <a href="#bib.bibx22" title="" class="ltx_ref">22</a>, <a href="#bib.bibx37" title="" class="ltx_ref">37</a>]</cite>. However, these results were obtained with features on a uniform background. Our simulations show that the radial symmetry method is consistently considerably worse when used on images with a background consisting of two regions with different luminance. It is therefore not suitable for use in more general eye tracking scenarios, where the CR is often overlaid on a non-uniform background, such as the iris or the edge of the pupil.
In contrast, our CNN was trained on highly simplified images that contained such backgrounds, and shows performance that is robust to their presence in both synthetic and real eye images. This demonstrates that the CNN approach, if appropriately trained, is able to use the pixel intensity information contained in the image of the CR to localize its center while effectively ignoring the background. Our CNN method consistently outperformed the other methods across evaluations performed on two different datasets and also when fed eye images that were downsampled to half resolution, showing that the method is applicable to many participants with differing eye physiology and generalizes to lower resolution eye images.
</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">This paper has demonstrated that simple simulations can be used to effectively train deep learning models that work on real eye images, raising questions about the need for heavy data augmentation techniques and time-consuming data collection as well as hand labeling efforts or reconstruction methods. However, it is worth emphasizing that we have so far employed this approach only on high quality eye images (see Figure¬†<a href="#S2.F3" title="Figure 3 ‚Ä£ Dataset one ‚Ä£ 2.4.2 Evaluation on real eye-images ‚Ä£ 2.4 Evaluation ‚Ä£ 2 Methods ‚Ä£ Precise localization of corneal reflections in eye images using deep learning trained on synthetic data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) encountered in high-end lab-based eye tracking scenarios where researchers are interested in microsaccades and other fixational eye movements, as well as other aspects of eye movements that require high data quality, such as slow pursuit. While our approach shows promise for these research scenarios, other scenarios in which eye trackers are frequently applied such as virtual reality or wearable eye tracker settings face eye images of significantly worse quality. Our approach should thus be tested on more challenging targets (e.g. localizing the center of the pupil or iris), more complex situations (e.g. involving multiple CRs and spurious reflections) and images of lower quality to further test the hypothesis that effective gaze estimation methods in a broader context can be trained using simple simulations alone.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.12" class="ltx_p">Our results show that while our method offered significantly reduced RMS precision in the CR center signal (<math id="S4.p4.1.m1.3" class="ltx_Math" alttext="28.034.9\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.1.m1.3a"><mrow id="S4.p4.1.m1.3.3" xref="S4.p4.1.m1.3.3.cmml"><mrow id="S4.p4.1.m1.1.1.1.1.1.1.4" xref="S4.p4.1.m1.1.1.1.1.1.1.3.cmml"><mn id="S4.p4.1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.p4.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">28.0</mn><mtext id="S4.p4.1.m1.1.1.1.1.1.1.4.1" xref="S4.p4.1.m1.1.1.1.1.1.1.3.1.cmml">‚Äì</mtext><mn id="S4.p4.1.m1.1.1.1.1.1.1.2.2.2.2.2" xref="S4.p4.1.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">34.9</mn></mrow><mtext id="S4.p4.1.m1.2.2.2.2.2.2" xref="S4.p4.1.m1.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.1.m1.3.3.3.3.3.3" xref="S4.p4.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1" xref="S4.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2" xref="S4.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.3b"><apply id="S4.p4.1.m1.3.3.cmml" xref="S4.p4.1.m1.3.3"><csymbol cd="latexml" id="S4.p4.1.m1.2.2.2.2.2.2.cmml" xref="S4.p4.1.m1.2.2.2.2.2.2">times</csymbol><apply id="S4.p4.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.p4.1.m1.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S4.p4.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.p4.1.m1.1.1.1.1.1.1.4.1">range</csymbol><cn type="float" id="S4.p4.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.p4.1.m1.1.1.1.1.1.1.1.1.1.1.1">28.0</cn><cn type="float" id="S4.p4.1.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.p4.1.m1.1.1.1.1.1.1.2.2.2.2.2">34.9</cn></apply><apply id="S4.p4.1.m1.3.3.3.3.3.3.cmml" xref="S4.p4.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2.cmml" xref="S4.p4.1.m1.3.3.3.3.3.3.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1.cmml" xref="S4.p4.1.m1.3.3.3.3.3.3.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.1.m1.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.3c">28.034.9\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> lower than thresholding for dataset one, and on average <math id="S4.p4.2.m2.3" class="ltx_Math" alttext="13.0\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.2.m2.3a"><mrow id="S4.p4.2.m2.3.3" xref="S4.p4.2.m2.3.3.cmml"><mn id="S4.p4.2.m2.1.1.1.1.1.1" xref="S4.p4.2.m2.1.1.1.1.1.1.cmml">13.0</mn><mtext id="S4.p4.2.m2.2.2.2.2.2.2" xref="S4.p4.2.m2.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.2.m2.3.3.3.3.3.3" xref="S4.p4.2.m2.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.3b"><apply id="S4.p4.2.m2.3.3.cmml" xref="S4.p4.2.m2.3.3"><csymbol cd="latexml" id="S4.p4.2.m2.2.2.2.2.2.2.cmml" xref="S4.p4.2.m2.2.2.2.2.2.2">times</csymbol><cn type="float" id="S4.p4.2.m2.1.1.1.1.1.1.cmml" xref="S4.p4.2.m2.1.1.1.1.1.1">13.0</cn><apply id="S4.p4.2.m2.3.3.3.3.3.3.cmml" xref="S4.p4.2.m2.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.2.m2.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.2.m2.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.2.m2.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.3c">13.0\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> and <math id="S4.p4.3.m3.3" class="ltx_Math" alttext="41.5\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.3.m3.3a"><mrow id="S4.p4.3.m3.3.3" xref="S4.p4.3.m3.3.3.cmml"><mn id="S4.p4.3.m3.1.1.1.1.1.1" xref="S4.p4.3.m3.1.1.1.1.1.1.cmml">41.5</mn><mtext id="S4.p4.3.m3.2.2.2.2.2.2" xref="S4.p4.3.m3.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.3.m3.3.3.3.3.3.3" xref="S4.p4.3.m3.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.3.m3.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.3.m3.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.3.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.3.m3.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.3.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.3b"><apply id="S4.p4.3.m3.3.3.cmml" xref="S4.p4.3.m3.3.3"><csymbol cd="latexml" id="S4.p4.3.m3.2.2.2.2.2.2.cmml" xref="S4.p4.3.m3.2.2.2.2.2.2">times</csymbol><cn type="float" id="S4.p4.3.m3.1.1.1.1.1.1.cmml" xref="S4.p4.3.m3.1.1.1.1.1.1">41.5</cn><apply id="S4.p4.3.m3.3.3.3.3.3.3.cmml" xref="S4.p4.3.m3.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.3.m3.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.3.m3.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.3.m3.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.3.m3.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.3.m3.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.3.m3.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.3c">41.5\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> lower for the full and half resolution analyses of dataset two, respectively), this translated to an improvement in RMS precision of the gaze signal that ranged only between <math id="S4.p4.4.m4.3" class="ltx_Math" alttext="7.28.6\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.4.m4.3a"><mrow id="S4.p4.4.m4.3.3" xref="S4.p4.4.m4.3.3.cmml"><mrow id="S4.p4.4.m4.1.1.1.1.1.1.4" xref="S4.p4.4.m4.1.1.1.1.1.1.3.cmml"><mn id="S4.p4.4.m4.1.1.1.1.1.1.1.1.1.1.1" xref="S4.p4.4.m4.1.1.1.1.1.1.1.1.1.1.1.cmml">7.2</mn><mtext id="S4.p4.4.m4.1.1.1.1.1.1.4.1" xref="S4.p4.4.m4.1.1.1.1.1.1.3.1.cmml">‚Äì</mtext><mn id="S4.p4.4.m4.1.1.1.1.1.1.2.2.2.2.2" xref="S4.p4.4.m4.1.1.1.1.1.1.2.2.2.2.2.cmml">8.6</mn></mrow><mtext id="S4.p4.4.m4.2.2.2.2.2.2" xref="S4.p4.4.m4.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.4.m4.3.3.3.3.3.3" xref="S4.p4.4.m4.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.4.m4.3.3.3.3.3.3.1.1.1.1.1" xref="S4.p4.4.m4.3.3.3.3.3.3.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.4.m4.3.3.3.3.3.3.2.2.2.2.2" xref="S4.p4.4.m4.3.3.3.3.3.3.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.4.m4.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.4.m4.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.4.m4.3b"><apply id="S4.p4.4.m4.3.3.cmml" xref="S4.p4.4.m4.3.3"><csymbol cd="latexml" id="S4.p4.4.m4.2.2.2.2.2.2.cmml" xref="S4.p4.4.m4.2.2.2.2.2.2">times</csymbol><apply id="S4.p4.4.m4.1.1.1.1.1.1.3.cmml" xref="S4.p4.4.m4.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S4.p4.4.m4.1.1.1.1.1.1.3.1.cmml" xref="S4.p4.4.m4.1.1.1.1.1.1.4.1">range</csymbol><cn type="float" id="S4.p4.4.m4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.p4.4.m4.1.1.1.1.1.1.1.1.1.1.1">7.2</cn><cn type="float" id="S4.p4.4.m4.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.p4.4.m4.1.1.1.1.1.1.2.2.2.2.2">8.6</cn></apply><apply id="S4.p4.4.m4.3.3.3.3.3.3.cmml" xref="S4.p4.4.m4.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.4.m4.3.3.3.3.3.3.2.2.2.2.2.cmml" xref="S4.p4.4.m4.3.3.3.3.3.3.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.4.m4.3.3.3.3.3.3.1.1.1.1.1.cmml" xref="S4.p4.4.m4.3.3.3.3.3.3.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.4.m4.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.4.m4.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.4.m4.3c">7.28.6\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> for dataset one, and on average <math id="S4.p4.5.m5.3" class="ltx_Math" alttext="2.9\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.5.m5.3a"><mrow id="S4.p4.5.m5.3.3" xref="S4.p4.5.m5.3.3.cmml"><mn id="S4.p4.5.m5.1.1.1.1.1.1" xref="S4.p4.5.m5.1.1.1.1.1.1.cmml">2.9</mn><mtext id="S4.p4.5.m5.2.2.2.2.2.2" xref="S4.p4.5.m5.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.5.m5.3.3.3.3.3.3" xref="S4.p4.5.m5.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.5.m5.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.5.m5.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.5.m5.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.5.m5.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.5.m5.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.5.m5.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.5.m5.3b"><apply id="S4.p4.5.m5.3.3.cmml" xref="S4.p4.5.m5.3.3"><csymbol cd="latexml" id="S4.p4.5.m5.2.2.2.2.2.2.cmml" xref="S4.p4.5.m5.2.2.2.2.2.2">times</csymbol><cn type="float" id="S4.p4.5.m5.1.1.1.1.1.1.cmml" xref="S4.p4.5.m5.1.1.1.1.1.1">2.9</cn><apply id="S4.p4.5.m5.3.3.3.3.3.3.cmml" xref="S4.p4.5.m5.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.5.m5.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.5.m5.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.5.m5.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.5.m5.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.5.m5.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.5.m5.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.5.m5.3c">2.9\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> for the full resolution and <math id="S4.p4.6.m6.3" class="ltx_Math" alttext="13.0\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.6.m6.3a"><mrow id="S4.p4.6.m6.3.3" xref="S4.p4.6.m6.3.3.cmml"><mn id="S4.p4.6.m6.1.1.1.1.1.1" xref="S4.p4.6.m6.1.1.1.1.1.1.cmml">13.0</mn><mtext id="S4.p4.6.m6.2.2.2.2.2.2" xref="S4.p4.6.m6.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.6.m6.3.3.3.3.3.3" xref="S4.p4.6.m6.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.6.m6.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.6.m6.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.6.m6.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.6.m6.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.6.m6.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.6.m6.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.6.m6.3b"><apply id="S4.p4.6.m6.3.3.cmml" xref="S4.p4.6.m6.3.3"><csymbol cd="latexml" id="S4.p4.6.m6.2.2.2.2.2.2.cmml" xref="S4.p4.6.m6.2.2.2.2.2.2">times</csymbol><cn type="float" id="S4.p4.6.m6.1.1.1.1.1.1.cmml" xref="S4.p4.6.m6.1.1.1.1.1.1">13.0</cn><apply id="S4.p4.6.m6.3.3.3.3.3.3.cmml" xref="S4.p4.6.m6.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.6.m6.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.6.m6.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.6.m6.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.6.m6.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.6.m6.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.6.m6.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.6.m6.3c">13.0\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> for the half resolution analysis of dataset two. Indeed, for a gaze signal that is derived using the P-CR principle, CR center localization performance is only half the story. P-CR eye trackers typically use the vector between the pupil and CR centers and as such noise in the pupil signal also plays an important role in determining the precision of the gaze signal. As shown in our results, for dataset one the noise in the pupil signal was between <math id="S4.p4.7.m7.3" class="ltx_Math" alttext="5566\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.7.m7.3a"><mrow id="S4.p4.7.m7.3.3" xref="S4.p4.7.m7.3.3.cmml"><mrow id="S4.p4.7.m7.1.1.1.1.1.1.4" xref="S4.p4.7.m7.1.1.1.1.1.1.3.cmml"><mn id="S4.p4.7.m7.1.1.1.1.1.1.1.1.1.1.1" xref="S4.p4.7.m7.1.1.1.1.1.1.1.1.1.1.1.cmml">55</mn><mtext id="S4.p4.7.m7.1.1.1.1.1.1.4.1" xref="S4.p4.7.m7.1.1.1.1.1.1.3.1.cmml">‚Äì</mtext><mn id="S4.p4.7.m7.1.1.1.1.1.1.2.2.2.2.2" xref="S4.p4.7.m7.1.1.1.1.1.1.2.2.2.2.2.cmml">66</mn></mrow><mtext id="S4.p4.7.m7.2.2.2.2.2.2" xref="S4.p4.7.m7.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.7.m7.3.3.3.3.3.3" xref="S4.p4.7.m7.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.7.m7.3.3.3.3.3.3.1.1.1.1.1" xref="S4.p4.7.m7.3.3.3.3.3.3.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.7.m7.3.3.3.3.3.3.2.2.2.2.2" xref="S4.p4.7.m7.3.3.3.3.3.3.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.7.m7.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.7.m7.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.7.m7.3b"><apply id="S4.p4.7.m7.3.3.cmml" xref="S4.p4.7.m7.3.3"><csymbol cd="latexml" id="S4.p4.7.m7.2.2.2.2.2.2.cmml" xref="S4.p4.7.m7.2.2.2.2.2.2">times</csymbol><apply id="S4.p4.7.m7.1.1.1.1.1.1.3.cmml" xref="S4.p4.7.m7.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S4.p4.7.m7.1.1.1.1.1.1.3.1.cmml" xref="S4.p4.7.m7.1.1.1.1.1.1.4.1">range</csymbol><cn type="integer" id="S4.p4.7.m7.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.p4.7.m7.1.1.1.1.1.1.1.1.1.1.1">55</cn><cn type="integer" id="S4.p4.7.m7.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.p4.7.m7.1.1.1.1.1.1.2.2.2.2.2">66</cn></apply><apply id="S4.p4.7.m7.3.3.3.3.3.3.cmml" xref="S4.p4.7.m7.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.7.m7.3.3.3.3.3.3.2.2.2.2.2.cmml" xref="S4.p4.7.m7.3.3.3.3.3.3.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.7.m7.3.3.3.3.3.3.1.1.1.1.1.cmml" xref="S4.p4.7.m7.3.3.3.3.3.3.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.7.m7.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.7.m7.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.7.m7.3c">5566\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> higher than in the CR center signal based on thresholding (average <math id="S4.p4.8.m8.3" class="ltx_Math" alttext="127\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.8.m8.3a"><mrow id="S4.p4.8.m8.3.3" xref="S4.p4.8.m8.3.3.cmml"><mn id="S4.p4.8.m8.1.1.1.1.1.1" xref="S4.p4.8.m8.1.1.1.1.1.1.cmml">127</mn><mtext id="S4.p4.8.m8.2.2.2.2.2.2" xref="S4.p4.8.m8.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.8.m8.3.3.3.3.3.3" xref="S4.p4.8.m8.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.8.m8.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.8.m8.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.8.m8.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.8.m8.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.8.m8.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.8.m8.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.8.m8.3b"><apply id="S4.p4.8.m8.3.3.cmml" xref="S4.p4.8.m8.3.3"><csymbol cd="latexml" id="S4.p4.8.m8.2.2.2.2.2.2.cmml" xref="S4.p4.8.m8.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S4.p4.8.m8.1.1.1.1.1.1.cmml" xref="S4.p4.8.m8.1.1.1.1.1.1">127</cn><apply id="S4.p4.8.m8.3.3.3.3.3.3.cmml" xref="S4.p4.8.m8.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.8.m8.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.8.m8.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.8.m8.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.8.m8.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.8.m8.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.8.m8.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.8.m8.3c">127\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> at full and <math id="S4.p4.9.m9.3" class="ltx_Math" alttext="32.1\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.9.m9.3a"><mrow id="S4.p4.9.m9.3.3" xref="S4.p4.9.m9.3.3.cmml"><mn id="S4.p4.9.m9.1.1.1.1.1.1" xref="S4.p4.9.m9.1.1.1.1.1.1.cmml">32.1</mn><mtext id="S4.p4.9.m9.2.2.2.2.2.2" xref="S4.p4.9.m9.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.9.m9.3.3.3.3.3.3" xref="S4.p4.9.m9.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.9.m9.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.9.m9.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.9.m9.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.9.m9.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.9.m9.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.9.m9.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.9.m9.3b"><apply id="S4.p4.9.m9.3.3.cmml" xref="S4.p4.9.m9.3.3"><csymbol cd="latexml" id="S4.p4.9.m9.2.2.2.2.2.2.cmml" xref="S4.p4.9.m9.2.2.2.2.2.2">times</csymbol><cn type="float" id="S4.p4.9.m9.1.1.1.1.1.1.cmml" xref="S4.p4.9.m9.1.1.1.1.1.1">32.1</cn><apply id="S4.p4.9.m9.3.3.3.3.3.3.cmml" xref="S4.p4.9.m9.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.9.m9.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.9.m9.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.9.m9.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.9.m9.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.9.m9.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.9.m9.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.9.m9.3c">32.1\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> at half resolution for dataset two). This ratio only worsens to between <math id="S4.p4.10.m10.3" class="ltx_Math" alttext="126151\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.10.m10.3a"><mrow id="S4.p4.10.m10.3.3" xref="S4.p4.10.m10.3.3.cmml"><mrow id="S4.p4.10.m10.1.1.1.1.1.1.4" xref="S4.p4.10.m10.1.1.1.1.1.1.3.cmml"><mn id="S4.p4.10.m10.1.1.1.1.1.1.1.1.1.1.1" xref="S4.p4.10.m10.1.1.1.1.1.1.1.1.1.1.1.cmml">126</mn><mtext id="S4.p4.10.m10.1.1.1.1.1.1.4.1" xref="S4.p4.10.m10.1.1.1.1.1.1.3.1.cmml">‚Äì</mtext><mn id="S4.p4.10.m10.1.1.1.1.1.1.2.2.2.2.2" xref="S4.p4.10.m10.1.1.1.1.1.1.2.2.2.2.2.cmml">151</mn></mrow><mtext id="S4.p4.10.m10.2.2.2.2.2.2" xref="S4.p4.10.m10.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.10.m10.3.3.3.3.3.3" xref="S4.p4.10.m10.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.10.m10.3.3.3.3.3.3.1.1.1.1.1" xref="S4.p4.10.m10.3.3.3.3.3.3.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.10.m10.3.3.3.3.3.3.2.2.2.2.2" xref="S4.p4.10.m10.3.3.3.3.3.3.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.10.m10.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.10.m10.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.10.m10.3b"><apply id="S4.p4.10.m10.3.3.cmml" xref="S4.p4.10.m10.3.3"><csymbol cd="latexml" id="S4.p4.10.m10.2.2.2.2.2.2.cmml" xref="S4.p4.10.m10.2.2.2.2.2.2">times</csymbol><apply id="S4.p4.10.m10.1.1.1.1.1.1.3.cmml" xref="S4.p4.10.m10.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S4.p4.10.m10.1.1.1.1.1.1.3.1.cmml" xref="S4.p4.10.m10.1.1.1.1.1.1.4.1">range</csymbol><cn type="integer" id="S4.p4.10.m10.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.p4.10.m10.1.1.1.1.1.1.1.1.1.1.1">126</cn><cn type="integer" id="S4.p4.10.m10.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.p4.10.m10.1.1.1.1.1.1.2.2.2.2.2">151</cn></apply><apply id="S4.p4.10.m10.3.3.3.3.3.3.cmml" xref="S4.p4.10.m10.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.10.m10.3.3.3.3.3.3.2.2.2.2.2.cmml" xref="S4.p4.10.m10.3.3.3.3.3.3.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.10.m10.3.3.3.3.3.3.1.1.1.1.1.cmml" xref="S4.p4.10.m10.3.3.3.3.3.3.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.10.m10.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.10.m10.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.10.m10.3c">126151\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> when considering the CR center signal produced by our CNN method for dataset one (average <math id="S4.p4.11.m11.3" class="ltx_Math" alttext="165\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.11.m11.3a"><mrow id="S4.p4.11.m11.3.3" xref="S4.p4.11.m11.3.3.cmml"><mn id="S4.p4.11.m11.1.1.1.1.1.1" xref="S4.p4.11.m11.1.1.1.1.1.1.cmml">165</mn><mtext id="S4.p4.11.m11.2.2.2.2.2.2" xref="S4.p4.11.m11.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.11.m11.3.3.3.3.3.3" xref="S4.p4.11.m11.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.11.m11.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.11.m11.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.11.m11.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.11.m11.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.11.m11.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.11.m11.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.11.m11.3b"><apply id="S4.p4.11.m11.3.3.cmml" xref="S4.p4.11.m11.3.3"><csymbol cd="latexml" id="S4.p4.11.m11.2.2.2.2.2.2.cmml" xref="S4.p4.11.m11.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S4.p4.11.m11.1.1.1.1.1.1.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1">165</cn><apply id="S4.p4.11.m11.3.3.3.3.3.3.cmml" xref="S4.p4.11.m11.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.11.m11.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.11.m11.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.11.m11.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.11.m11.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.11.m11.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.11.m11.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.11.m11.3c">165\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> at full and <math id="S4.p4.12.m12.3" class="ltx_Math" alttext="130\text{\,}\mathrm{\char 37\relax}\text{/}" display="inline"><semantics id="S4.p4.12.m12.3a"><mrow id="S4.p4.12.m12.3.3" xref="S4.p4.12.m12.3.3.cmml"><mn id="S4.p4.12.m12.1.1.1.1.1.1" xref="S4.p4.12.m12.1.1.1.1.1.1.cmml">130</mn><mtext id="S4.p4.12.m12.2.2.2.2.2.2" xref="S4.p4.12.m12.2.2.2.2.2.2.cmml">¬†</mtext><mrow id="S4.p4.12.m12.3.3.3.3.3.3" xref="S4.p4.12.m12.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S4.p4.12.m12.3.3.3.3.3.3.1.1.1.1.1.1" xref="S4.p4.12.m12.3.3.3.3.3.3.1.1.1.1.1.1.cmml">%</mi><mtext id="S4.p4.12.m12.3.3.3.3.3.3.2.2.2.2.2.2" xref="S4.p4.12.m12.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S4.p4.12.m12.3.3.3.3.3.3.3.3.3.3.3.3" xref="S4.p4.12.m12.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.12.m12.3b"><apply id="S4.p4.12.m12.3.3.cmml" xref="S4.p4.12.m12.3.3"><csymbol cd="latexml" id="S4.p4.12.m12.2.2.2.2.2.2.cmml" xref="S4.p4.12.m12.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S4.p4.12.m12.1.1.1.1.1.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.1">130</cn><apply id="S4.p4.12.m12.3.3.3.3.3.3.cmml" xref="S4.p4.12.m12.3.3.3.3.3.3"><csymbol cd="latexml" id="S4.p4.12.m12.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S4.p4.12.m12.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S4.p4.12.m12.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.p4.12.m12.3.3.3.3.3.3.1.1.1.1.1.1">percent</csymbol><csymbol cd="latexml" id="S4.p4.12.m12.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S4.p4.12.m12.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.12.m12.3c">130\text{\,}\mathrm{\char 37\relax}\text{/}</annotation></semantics></math> at half resolution for dataset two). As such, further improvements in CR center localization precision will be of little practical use for P-CR eye trackers until the precision of pupil center localization is also improved.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">In summary, our results indicate that our method for training deep learning models for eye tracking applications using only simple synthetic images shows great promise. However, much of the road ahead to a fully deep-learning based eye tracking method trained using only synthetic images remains unexplored. As the next endeavor, we plan to extend our approach to localization of the pupil center. If successful, this will not only provide a much needed improvement in precision of the pupil signal that will translate into increased quality of the P-CR gaze signal, but will also provide a further and more ambitious test of the hypothesis that effective gaze estimation methods can be trained using simple simulations alone. Why does localizing the pupil center provide a more ambitious test? While a CR has approximately the same size, shape and pixel intensity profile in all eye images for a given eye tracking setup and is thus easy to design a representative simulation for, this is not the case for the pupil. The luminance of the pupil in the eye image can vary significantly, and its apparent shape can change radically as it changes size, is imaged from different angles when the eye rotates and one or multiple CRs overlap it.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">We further plan to develop our framework to handle more challenging tasks such as detecting multiple CRs and matching their positions in the eye image to the corresponding physical configuration of light sources, similar to the work in¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">30</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">35</a>]</cite>. This would enable using our method to be used in eye tracking scenarios outside of laboratory settings.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We thank Ignace Hooge for helpful discussion. We gratefully acknowledge the Lund University Humanities Lab where data were recorded.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Open practices statement</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The experiments were not preregistered. We have made our simulation and model training code, the trained model and the code for evaluating the model on simulated and real images available at the following link: <a target="_blank" href="https://github.com/dcnieho/Byrneetal_CR_CNN" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/dcnieho/Byrneetal_CR_CNN</a>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">John Merchant, Richard Morrissette and James L Porterfield
</span>
<span class="ltx_bibblock">‚ÄúRemote measurement of eye direction allowing subject motion over one cubic foot of space‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx1.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on biomedical engineering</em>
</span>
<span class="ltx_bibblock">IEEE, 1974, pp. 309‚Äì317
</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">Dave M Stampe
</span>
<span class="ltx_bibblock">‚ÄúHeuristic filtering and reliable calibration methods for video-based pupil-tracking systems‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx2.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods, Instruments, &amp; Computers</em> <span id="bib.bibx2.2.2" class="ltx_text ltx_font_bold">25.2</span>
</span>
<span class="ltx_bibblock">Springer, 1993, pp. 137‚Äì142
</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">Mark R Shortis, Timothy A Clarke and Tim Short
</span>
<span class="ltx_bibblock">‚ÄúComparison of some techniques for the subpixel location of discrete target images‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx3.1.1" class="ltx_emph ltx_font_italic">Videometrics III</em> <span id="bib.bibx3.2.2" class="ltx_text ltx_font_bold">2350</span>, 1994, pp. 239‚Äì250
</span>
<span class="ltx_bibblock">SPIE
</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">J.. Mulligan
</span>
<span class="ltx_bibblock">‚ÄúImage processing for improved eye-tracking accuracy‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx4.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods, Instruments, &amp; Computers</em> <span id="bib.bibx4.2.2" class="ltx_text ltx_font_bold">29</span>, 1997, pp. 54‚Äì65
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.3758/BF03200567" title="" class="ltx_ref ltx_href">10.3758/BF03200567</a>
</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">Antonio Per√©z et al.
</span>
<span class="ltx_bibblock">‚ÄúA precise eye-gaze detection and tracking system‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx5.1.1" class="ltx_emph ltx_font_italic">Proceedings of The 11th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision</em>, WSCG‚Äô2003, 2003, pp. 1‚Äì4
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="http://wscg.zcu.cz/wscg2003/Papers_2003/A83.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://wscg.zcu.cz/wscg2003/Papers_2003/A83.pdf</a>
</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">Dongheng Li, D. Winfield and D.J. Parkhurst
</span>
<span class="ltx_bibblock">‚ÄúStarburst: A hybrid algorithm for video-based eye tracking combining feature-based and model-based approaches‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx6.1.1" class="ltx_emph ltx_font_italic">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR‚Äô05) - Workshops</em>, 2005, pp. 79‚Äì79
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1109/CVPR.2005.531" title="" class="ltx_ref ltx_href">10.1109/CVPR.2005.531</a>
</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">Javier San Agustin et al.
</span>
<span class="ltx_bibblock">‚ÄúEvaluation of a Low-Cost Open-Source Gaze Tracker‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2010 Symposium on Eye-Tracking Research &amp; Applications</em>, ETRA ‚Äô10
</span>
<span class="ltx_bibblock">Austin, Texas: Association for Computing Machinery, 2010, pp. 77‚Äì80
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1145/1743666.1743685" title="" class="ltx_ref ltx_href">10.1145/1743666.1743685</a>
</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">K. Holmqvist et al.
</span>
<span class="ltx_bibblock">‚ÄúEye tracking: a comprehensive guide to methods and measures‚Äù
</span>
<span class="ltx_bibblock">Oxford University Press, 2011
</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">Juan J Cerrolaza, Arantxa Villanueva, Maria Villanueva and Rafael Cabeza
</span>
<span class="ltx_bibblock">‚ÄúError characterization and compensation in eye tracking systems‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the symposium on eye tracking research and applications</em>, 2012, pp. 205‚Äì208
</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">Kenneth Holmqvist, Marcus Nystr√∂m and Fiona Mulvey
</span>
<span class="ltx_bibblock">‚ÄúEye tracker data quality: What it is and how to measure it‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Symposium on Eye Tracking Research and Applications</em>, 2012, pp. 45‚Äì52
</span>
<span class="ltx_bibblock">ACM
</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">Raghuveer Parthasarathy
</span>
<span class="ltx_bibblock">‚ÄúRapid, accurate particle tracking by calculation of radial symmetry centers‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx11.1.1" class="ltx_emph ltx_font_italic">Nature methods</em> <span id="bib.bibx11.2.2" class="ltx_text ltx_font_bold">9.7</span>
</span>
<span class="ltx_bibblock">Nature Publishing Group, 2012, pp. 724‚Äì726
</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">Yusuke Sugano, Yasuyuki Matsushita and Yoichi Sato
</span>
<span class="ltx_bibblock">‚ÄúLearning-by-Synthesis for Appearance-Based 3D Gaze Estimation‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx12.1.1" class="ltx_emph ltx_font_italic">2014 IEEE Conference on Computer Vision and Pattern Recognition</em>, 2014, pp. 1821‚Äì1828
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1109/CVPR.2014.235" title="" class="ltx_ref ltx_href">10.1109/CVPR.2014.235</a>
</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">Erroll Wood et al.
</span>
<span class="ltx_bibblock">‚ÄúRendering of Eyes for Eye-Shape Registration and Gaze Estimation‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx13.1.1" class="ltx_emph ltx_font_italic">CoRR</em> <span id="bib.bibx13.2.2" class="ltx_text ltx_font_bold">abs/1505.05916</span>, 2015
</span>
<span class="ltx_bibblock">arXiv: <a target="_blank" href="http://arxiv.org/abs/1505.05916" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1505.05916</a>
</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">Ashish Shrivastava et al.
</span>
<span class="ltx_bibblock">‚ÄúLearning from Simulated and Unsupervised Images through Adversarial Training‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx14.1.1" class="ltx_emph ltx_font_italic">CoRR</em> <span id="bib.bibx14.2.2" class="ltx_text ltx_font_bold">abs/1612.07828</span>, 2016
</span>
<span class="ltx_bibblock">arXiv: <a target="_blank" href="http://arxiv.org/abs/1612.07828" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1612.07828</a>
</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">Erroll Wood et al.
</span>
<span class="ltx_bibblock">‚ÄúLearning an Appearance-Based Gaze Estimator from One Million Synthesised Images‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research &amp; Applications</em>, ETRA ‚Äô16
</span>
<span class="ltx_bibblock">Charleston, South Carolina: Association for Computing Machinery, 2016, pp. 131‚Äì138
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1145/2857491.2857492" title="" class="ltx_ref ltx_href">10.1145/2857491.2857492</a>
</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">Jan Zimmermann et al.
</span>
<span class="ltx_bibblock">‚ÄúOculomatic: High speed, reliable, and accurate open-source eye tracking for humans and non-human primates‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx16.1.1" class="ltx_emph ltx_font_italic">Journal of Neuroscience Methods</em> <span id="bib.bibx16.2.2" class="ltx_text ltx_font_bold">270</span>, 2016, pp. 138‚Äì146
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1016/j.jneumeth.2016.06.016" title="" class="ltx_ref ltx_href">10.1016/j.jneumeth.2016.06.016</a>
</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">Wolfgang Fuhl et al.
</span>
<span class="ltx_bibblock">‚ÄúPupilNet v2.0: Convolutional Neural Networks for CPU based real time Robust Pupil Detection‚Äù, 2017
</span>
<span class="ltx_bibblock">arXiv:<a target="_blank" href="https://arxiv.org/abs/1711.00112" title="" class="ltx_ref ltx_href">1711.00112 [cs.CV]</a>
</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">Diederik P. Kingma and Jimmy Ba
</span>
<span class="ltx_bibblock">‚ÄúAdam: A Method for Stochastic Optimization‚Äù, 2017
</span>
<span class="ltx_bibblock">arXiv:<a target="_blank" href="https://arxiv.org/abs/1412.6980" title="" class="ltx_ref ltx_href">1412.6980 [cs.LG]</a>
</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">A.. Barsingerhorn, F.. Boonstra and J. Goossens
</span>
<span class="ltx_bibblock">‚ÄúDevelopment and validation of a high-speed stereoscopic eyetracker‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx19.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx19.2.2" class="ltx_text ltx_font_bold">50.6</span>
</span>
<span class="ltx_bibblock">Springer, 2018, pp. 2480‚Äì2497
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.3758/s13428-018-1026-7" title="" class="ltx_ref ltx_href">10.3758/s13428-018-1026-7</a>
</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">Ignace T C Hooge et al.
</span>
<span class="ltx_bibblock">‚ÄúIs human classification by experienced untrained observers a gold standard in fixation detection?‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx20.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx20.2.2" class="ltx_text ltx_font_bold">50.5</span>
</span>
<span class="ltx_bibblock">Springer, 2018, pp. 1864‚Äì1881
</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">Diederick C Niehorster and Marcus Nystr√∂m
</span>
<span class="ltx_bibblock">‚ÄúMicrosaccade Detection Using Pupil and Corneal Reflection Signals‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM Symposium on Eye Tracking Research &amp; Applications</em>, ETRA ‚Äô18
</span>
<span class="ltx_bibblock">Warsaw, Poland: Association for Computing Machinery, 2018
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1145/3204493.3204573" title="" class="ltx_ref ltx_href">10.1145/3204493.3204573</a>
</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">Saga Helgadottir, Aykut Argun and Giovanni Volpe
</span>
<span class="ltx_bibblock">‚ÄúDigital video microscopy enhanced by deep learning‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx22.1.1" class="ltx_emph ltx_font_italic">Optica</em> <span id="bib.bibx22.2.2" class="ltx_text ltx_font_bold">6.4</span>
</span>
<span class="ltx_bibblock">Optica Publishing Group, 2019, pp. 506‚Äì513
</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">Zhengyang Wu et al.
</span>
<span class="ltx_bibblock">‚ÄúEyenet: A multi-task deep network for off-axis eye gaze estimation‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx23.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</em>, 2019, pp. 3683‚Äì3687
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">Kenneth Holmqvist and Pieter Blignaut
</span>
<span class="ltx_bibblock">‚ÄúSmall eye movements cannot be reliably measured by video-based P-CR eye-trackers‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx24.1.1" class="ltx_emph ltx_font_italic">Behavior research methods</em> <span id="bib.bibx24.2.2" class="ltx_text ltx_font_bold">52.5</span>
</span>
<span class="ltx_bibblock">Springer, 2020, pp. 2098‚Äì2121
</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">Benedikt Hosp et al.
</span>
<span class="ltx_bibblock">‚ÄúRemoteEye: An open-source high-speed remote eye tracker‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx25.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx25.2.2" class="ltx_text ltx_font_bold">52.3</span>
</span>
<span class="ltx_bibblock">Springer, 2020, pp. 1387‚Äì1401
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.3758/s13428-019-01305-2" title="" class="ltx_ref ltx_href">10.3758/s13428-019-01305-2</a>
</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">Diederick C Niehorster, Roy S Hessels and Jeroen S Benjamins
</span>
<span class="ltx_bibblock">‚ÄúGlassesViewer: Open-source software for viewing and analyzing data from the Tobii Pro Glasses 2 eye tracker‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx26.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx26.2.2" class="ltx_text ltx_font_bold">52.3</span>
</span>
<span class="ltx_bibblock">Springer, 2020, pp. 1244‚Äì1253
</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">Diederick C Niehorster et al.
</span>
<span class="ltx_bibblock">‚ÄúThe impact of slippage on the data quality of head-worn eye trackers‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx27.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx27.2.2" class="ltx_text ltx_font_bold">52.3</span>
</span>
<span class="ltx_bibblock">Springer, 2020, pp. 1140‚Äì1160
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.3758/s13428-019-01307-0" title="" class="ltx_ref ltx_href">10.3758/s13428-019-01307-0</a>
</span>
</li>
<li id="bib.bibx28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">Diederick C Niehorster, Raimondas Zemblys, Tanya Beelders and Kenneth Holmqvist
</span>
<span class="ltx_bibblock">‚ÄúCharacterizing gaze position signals and synthesizing noise during fixations in eye-tracking data‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx28.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx28.2.2" class="ltx_text ltx_font_bold">52.6</span>
</span>
<span class="ltx_bibblock">Springer, 2020, pp. 2515‚Äì2534
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.3758/s13428-020-01400-9" title="" class="ltx_ref ltx_href">10.3758/s13428-020-01400-9</a>
</span>
</li>
<li id="bib.bibx29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">Yihua Cheng, Haofei Wang, Yiwei Bao and Feng Lu
</span>
<span class="ltx_bibblock">‚ÄúAppearance-based Gaze Estimation With Deep Learning: A Review and Benchmark‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx29.1.1" class="ltx_emph ltx_font_italic">CoRR</em> <span id="bib.bibx29.2.2" class="ltx_text ltx_font_bold">abs/2104.12668</span>, 2021
</span>
<span class="ltx_bibblock">arXiv: <a target="_blank" href="https://arxiv.org/abs/2104.12668" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2104.12668</a>
</span>
</li>
<li id="bib.bibx30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">Soumil Chugh, Braiden Brousseau, Jonathan Rose and Moshe Eizenman
</span>
<span class="ltx_bibblock">‚ÄúDetection and Correspondence Matching of Corneal Reflections for Eye Tracking Using Deep Learning‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx30.1.1" class="ltx_emph ltx_font_italic">2020 25th International Conference on Pattern Recognition (ICPR)</em>, 2021, pp. 2210‚Äì2217
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">Ignace T C Hooge et al.
</span>
<span class="ltx_bibblock">‚ÄúThe pupil-size artefact (PSA) across time, viewing direction, and different eye trackers‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx31.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx31.2.2" class="ltx_text ltx_font_bold">53.5</span>
</span>
<span class="ltx_bibblock">Springer, 2021, pp. 1986‚Äì2006
</span>
</li>
<li id="bib.bibx32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">Daria Ivanchenko, Katharina Rifai, Ziad M. Hafed and Frank Schaeffel
</span>
<span class="ltx_bibblock">‚ÄúA low-cost, high-performance video-based binocular eye tracker for psychophysical research‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx32.1.1" class="ltx_emph ltx_font_italic">Journal of Eye Movement Research</em> <span id="bib.bibx32.2.2" class="ltx_text ltx_font_bold">14.3</span>, 2021
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.16910/jemr.14.3.3" title="" class="ltx_ref ltx_href">10.16910/jemr.14.3.3</a>
</span>
</li>
<li id="bib.bibx33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">Benjamin Midtvedt et al.
</span>
<span class="ltx_bibblock">‚ÄúQuantitative digital microscopy with deep learning‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx33.1.1" class="ltx_emph ltx_font_italic">Applied Physics Reviews</em> <span id="bib.bibx33.2.2" class="ltx_text ltx_font_bold">8.1</span>
</span>
<span class="ltx_bibblock">AIP Publishing LLC, 2021, pp. 011310
</span>
</li>
<li id="bib.bibx34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">Diederick C Niehorster, Raimondas Zemblys and Kenneth Holmqvist
</span>
<span class="ltx_bibblock">‚ÄúIs apparent fixational drift in eye-tracking data due to filters or eyeball rotation?‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx34.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em> <span id="bib.bibx34.2.2" class="ltx_text ltx_font_bold">53.1</span>
</span>
<span class="ltx_bibblock">Springer, 2021, pp. 311‚Äì324
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.3758/s13428-020-01414-3" title="" class="ltx_ref ltx_href">10.3758/s13428-020-01414-3</a>
</span>
</li>
<li id="bib.bibx35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">Lijinliang Niu, Zhaopeng Gu, Juntao Ye and Qiulei Dong
</span>
<span class="ltx_bibblock">‚ÄúReal-Time Localization and Matching of Corneal Reflections for Eye Gaze Estimation via a Lightweight Network‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx35.1.1" class="ltx_emph ltx_font_italic">The Ninth International Symposium of Chinese CHI</em>, 2021, pp. 33‚Äì40
</span>
</li>
<li id="bib.bibx36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">Ignace T C Hooge et al.
</span>
<span class="ltx_bibblock">‚ÄúHow robust are wearable eye trackers to slow and fast head and body movements?‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx36.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em>
</span>
<span class="ltx_bibblock">Springer, 2022, pp. 1‚Äì15
</span>
</li>
<li id="bib.bibx37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">Benjamin Midtvedt et al.
</span>
<span class="ltx_bibblock">‚ÄúSingle-shot self-supervised object detection in microscopy‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx37.1.1" class="ltx_emph ltx_font_italic">Nature Communications</em> <span id="bib.bibx37.2.2" class="ltx_text ltx_font_bold">13.1</span>
</span>
<span class="ltx_bibblock">Nature Publishing Group, 2022, pp. 1‚Äì13
</span>
</li>
<li id="bib.bibx38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">Marcus Nystr√∂m et al.
</span>
<span class="ltx_bibblock">‚ÄúThe amplitude of small eye movements can be accurately estimated with video-based eye trackers‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx38.1.1" class="ltx_emph ltx_font_italic">Behavior Research Methods</em>
</span>
<span class="ltx_bibblock">Springer, 2022, pp. 1‚Äì13
</span>
</li>
<li id="bib.bibx39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">Jes√∫s Pineda et al.
</span>
<span class="ltx_bibblock">‚ÄúGeometric deep learning reveals the spatiotemporal fingerprint of microscopic motion‚Äù
</span>
<span class="ltx_bibblock">arXiv, 2022
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.48550/ARXIV.2202.06355" title="" class="ltx_ref ltx_href">10.48550/ARXIV.2202.06355</a>
</span>
</li>
<li id="bib.bibx40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">Ruei-Jr Wu et al.
</span>
<span class="ltx_bibblock">‚ÄúHigh-resolution eye-tracking via digital imaging of Purkinje reflections‚Äù
</span>
<span class="ltx_bibblock">In <em id="bib.bibx40.1.1" class="ltx_emph ltx_font_italic">bioRxiv</em>
</span>
<span class="ltx_bibblock">Cold Spring Harbor Laboratory, 2022
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1101/2022.08.16.504076" title="" class="ltx_ref ltx_href">10.1101/2022.08.16.504076</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2304.05672" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2304.05673" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2304.05673">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2304.05673" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2304.05674" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 14:43:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
