<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models</title>
<!--Generated on Thu Oct 10 11:32:23 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.07830v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S1" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S2" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S3" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proposed Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S3.SS1" title="In 3 Proposed Method ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Continued Pre-Training and SFT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S3.SS2" title="In 3 Proposed Method ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>LLM-based Data Preprocessor</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S3.SS3" title="In 3 Proposed Method ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Backtranslation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.SS1" title="In 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.SS2" title="In 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Training Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.SS3" title="In 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>A Balinese Case Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.SS4" title="In 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Benchmarking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S5" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S6" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1" title="In NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS1" title="In Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Prompts</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS1.SSS1" title="In A.1 Prompts ‣ Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1.1 </span>Translation Prompt</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS1.SSS2" title="In A.1 Prompts ‣ Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1.2 </span>Cleaner Prompt</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS2" title="In Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Filtering</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">William Tan  Kevin Zhu

<br class="ltx_break"/>Algoverse AI Research
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">william@tan.id, kevin@algoverse.us</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Large Language Models (LLMs) have demonstrated exceptional promise in translation tasks for high-resource languages. However, their performance in low-resource languages is limited by the scarcity of both parallel and monolingual corpora, as well as the presence of noise. Consequently, such LLMs suffer with alignment and have lagged behind State-of-The-Art (SoTA) neural machine translation (NMT) models in these settings. This paper introduces NusaMT-7B, an LLM-based machine translation model for low-resource Indonesian languages, starting with Balinese and Minangkabau. Leveraging the pretrained LLaMA2-7B, our approach integrates continued pre-training on monolingual data, Supervised Fine-Tuning (SFT), self-learning, and an LLM-based data cleaner to reduce noise in parallel sentences. In the FLORES-200 multilingual translation benchmark, NusaMT-7B outperforms SoTA models in the spBLEU metric by up to +6.69 spBLEU in translations into Balinese and Minangkabau, but underperforms by up to -3.38 spBLEU in translations into higher-resource languages. Our results show that fine-tuned LLMs can enhance translation quality for low-resource languages, aiding in linguistic preservation and cross-cultural communication.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Indonesia is home to 726 recorded regional languages, accounting for about 10% of the world’s languages <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">a20</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2024a</span></a>)</cite>. While the official language, Indonesian, is spoken by 80.4% of the population, a significant portion of these Indonesian speakers—about 70.9%—are multilingual, often fluent in various regional languages <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">a20</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">2024c</span></a>)</cite>. However, predictions suggest that in 100 years, 90% of these languages will either be extinct or on the verge of extinction <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Miyaoka et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">2007</span></a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Machine translation systems have the potential to preserve endangered languages, serving as crucial tools for conservation efforts and fostering cross-cultural communication. However, low-resource languages, by definition, lack parallel corpora, which are crucial for traditional Neural Machine Translation (NMT) systems that often need millions of sentences for optimal performance. <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Goyle et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>. While bitext mining datasets like CCMatrix <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zong et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> and NLLB can extract 1.4 million pairs, for instance, in the Minangkabau to English direction, a substantial portion of these datasets—98.7% in this case—is plagued by noise and mismatched pairs.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recent advancements in generative (decoder-only) Large Language Models (LLMs) have shown promise in machine translation. OpenAI’s GPT-3.5 and GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Brown et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, along with advanced fine-tuned LLMs like ALMA-R <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xu et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">2024b</span></a>)</cite> and Unbabel’s TowerInstruct <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Alves et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>, have demonstrated remarkable performance in high-resource language translation, outperforming state-of-the-art (SoTA) models like NLLB-200 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Team et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> and commercial translation products like Google Translate <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">a20</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2024b</span></a>)</cite> in the FLORES-200 translation benchmark. However, for low-resource languages, even very large models like GPT-4 lag significantly behind SoTA models like NLLB-200. Indeed, recent literature indicates that fine-tuned LLMs in machine translation are extremely sensitive to noisy data, easily picking up on erroneous biases and misalignments when noise is introduced <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zhu et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">2024a</span></a>)</cite>. Thus, the primary bottleneck is likely not the inherent performance of LLMs, but the lack of high-quality, clean translation data typically found in low-resource language datasets.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Our proposed solution aims to bridge this gap. We introduce NusaMT-7B, a model focused on Indonesian low-resource languages, starting with Balinese and Minangkabau. Built on LLaMa2-7B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Touvron et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, NusaMT-7B incorporates continued pre-training on non-English monolingual data, supervised fine-tuning, data preprocessing for cleaning parallel sentences, and synthetic data generation. We open-source NusaMT-7B on Huggingface<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://huggingface.co/xxx/xxx</span></span></span> and deploy a free translation web application<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>http://indonesiaku.com/</span></span></span> to showcase our model. We also release the training code<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/xxx/xxx</span></span></span> and compiled dataset<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://huggingface.co/xxx/xxx</span></span></span>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our findings present three key takeaways:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Monolingual pre-training and a cleaner, smaller dataset both contribute to improved performance.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Backtranslation, a self-learning approach, boosts performance in LLM-based translation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Our combined methods enable our model to outperform most SoTAs in the FLORES-200 benchmark for translation directions into low-resource languages.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">This paper includes a case study on the Balinese language to compare our proposed methods. We then extend our model to another low-resource Indonesian language, Minangkabau, and compare its performance against existing SoTA models.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">LLM-based machine translation has seen several innovative developments in low-resource languages. Previous research has focused on improving translation performance by incorporating human preference feedback <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Jiao et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">Zhu et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">2024b</span></a>)</cite>. Other approaches have leveraged monolingual data for continued pretraining <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xu et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">2024b</span></a>; <span class="ltx_text" style="font-size:90%;">Alves et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>. Additionally, LLMs like GPT-4 have been used to clean noisy translation data, closely aligning with human cleaning and boosted performance when used to train NMT systems <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bolding et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In the context of Indonesian low-resource languages, Komodo-7B-Instruct—a fine-tuned version of Komodo-7B-Base—has been trained on various tasks, including translation for languages like Balinese and Minangkabau. However, this model remains closed-source and has not been benchmarked against existing SoTA models in low-resource languages <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Owen et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Our work, however, focuses on enhancing LLM performance through the integration of multiple paradigms, including parallel corpora cleaning, synthetic sentence pair generation, and monolingual pretraining. Together, we provide a comprehensive comparison against various SoTA models on the FLORES-200 benchmark in directions involving Balinese and Minangkabau.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Method</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Continued Pre-Training and SFT</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Most pretrained LLMs are unfamiliar with low-resource languages, making continued pre-training in the target low-resource language essential for teaching the LLM the linguistic principles of these previously unseen languages <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Kuulmets et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>. However, due to limited GPU resources required to pretrain on billions of tokens, we utilize Komodo-7B-base <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Owen et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>, a version of LLaMA2-7B further pretrained with Masked-Language Modeling (MLM) on 8.79 billion tokens. These tokens span a diverse set of multilingual corpora, including school textbooks and news articles from 11 regional Indonesian languages, such as Balinese and Minangkabau.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">During SFT, we use the same translation prompt as ALMA <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xu et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">2024a</span></a>)</cite>, detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS1.SSS1" title="A.1.1 Translation Prompt ‣ A.1 Prompts ‣ Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">A.1.1</span></a>. The model is tasked with translating a sentence from a source language to a target language, with the loss computed only on the model’s generated tokens. Based on Xu et al.’s ablation study on training objectives for LLMs in machine translation, we employ Causal Language Modeling (CLM) loss for fine-tuning, which predicts the next word based only on the preceding context.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>LLM-based Data Preprocessor</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We propose an LLM data preprocessor tasked with (1) determining if two sentences share the same underlying meaning and, if so, (2) cleaning the parallel sentences to improve sentence alignment. We selected GPT-4o mini for this task due to its cost-efficiency and the superior performance in data preprocessing tasks demonstrated by its predecessor, GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">OpenAI et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>. Initially, we instruct the LLM on the tasks of data cleaning and aligning parallel sentences. We then use few-shot prompting to provide the LLM with representative examples of data cleaning, as shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS1.SSS2" title="A.1.2 Cleaner Prompt ‣ A.1 Prompts ‣ Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">A.1.2</span></a>. Batch prompting is used to process multiple parallel sentences in a single prompt to reduce overall token size.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Backtranslation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Backtranslation is a self-training method used to generate additional training data for SFT. It is a data-efficient method to augment new parallel sentence pairs and generate additional training data on more diverse linguistic structures and contexts. To generate synthetic sentence pairs from a source to a target language, we select high-quality sentences from monolingual datasets in the target language. After initially training our primary model with SFT, we run inference to translate the target monolingual data back into the source language. Subsequently, we apply our filtering methods and our LLM cleaner a second time to this new synthetic sentence pair to ensure proper alignment. Finally, we fine-tune the model to translate the source sentence back into the target sentence.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data</h3>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Parallel sentence counts before and after LLM cleaning across datasets and language pairs including English (en), Indonesian (id), Balinese (ban), and Minangkabau (min)</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.8" style="width:433.6pt;height:123.1pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.5pt,10.9pt) scale(0.849170193754829,0.849170193754829) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.8.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.8.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T1.8.8.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.9.1.1.1">Dataset</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T1.8.8.9.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.9.1.2.1">Before Cleaning</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T1.8.8.9.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.9.1.3.1">After Cleaning</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.8">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.8.8.8.9"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">ban <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.1.m1.1d">↔</annotation></semantics></math> en</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.2.2.1">ban <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.2.1.m1.1"><semantics id="S4.T1.2.2.2.2.1.m1.1a"><mo id="S4.T1.2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T1.2.2.2.2.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.1.m1.1b"><ci id="S4.T1.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.2.1.m1.1d">↔</annotation></semantics></math> id</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.3.3.1">min <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.3.1.m1.1"><semantics id="S4.T1.3.3.3.3.1.m1.1a"><mo id="S4.T1.3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T1.3.3.3.3.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.1.m1.1b"><ci id="S4.T1.3.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.3.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.3.1.m1.1d">↔</annotation></semantics></math> en</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.1">min <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.4.4.4.4.1.m1.1"><semantics id="S4.T1.4.4.4.4.1.m1.1a"><mo id="S4.T1.4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T1.4.4.4.4.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.1.m1.1b"><ci id="S4.T1.4.4.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.4.4.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.4.4.1.m1.1d">↔</annotation></semantics></math> id</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T1.5.5.5.5.1">ban <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.5.5.5.5.1.m1.1"><semantics id="S4.T1.5.5.5.5.1.m1.1a"><mo id="S4.T1.5.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T1.5.5.5.5.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.1.m1.1b"><ci id="S4.T1.5.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.5.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.5.5.1.m1.1d">↔</annotation></semantics></math> en</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.6.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T1.6.6.6.6.1">ban <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.6.6.6.6.1.m1.1"><semantics id="S4.T1.6.6.6.6.1.m1.1a"><mo id="S4.T1.6.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T1.6.6.6.6.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.6.1.m1.1b"><ci id="S4.T1.6.6.6.6.1.m1.1.1.cmml" xref="S4.T1.6.6.6.6.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.6.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.6.6.1.m1.1d">↔</annotation></semantics></math> id</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T1.7.7.7.7.1">min <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.7.7.7.7.1.m1.1"><semantics id="S4.T1.7.7.7.7.1.m1.1a"><mo id="S4.T1.7.7.7.7.1.m1.1.1" stretchy="false" xref="S4.T1.7.7.7.7.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.7.1.m1.1b"><ci id="S4.T1.7.7.7.7.1.m1.1.1.cmml" xref="S4.T1.7.7.7.7.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.7.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.7.7.1.m1.1d">↔</annotation></semantics></math> en</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.8.8"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.8.8.1">min <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.T1.8.8.8.8.1.m1.1"><semantics id="S4.T1.8.8.8.8.1.m1.1a"><mo id="S4.T1.8.8.8.8.1.m1.1.1" stretchy="false" xref="S4.T1.8.8.8.8.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.8.1.m1.1b"><ci id="S4.T1.8.8.8.8.1.m1.1.1.cmml" xref="S4.T1.8.8.8.8.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.8.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.8.8.8.1.m1.1d">↔</annotation></semantics></math> id</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.10.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.8.8.10.2.1">NLLB Mined</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.2">7.4k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.3">2.2k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.4">5.7k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.5">16.5k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.6">4.4k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.7">1.5k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.8">3.4k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.8.8.10.2.9">9.9k</td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.11.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.8.8.11.3.1">NLLB SEED</th>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.2">6.0k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.3">6.0k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.4">6.0k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.5">6.0k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.6">5.8k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.7">5.8k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.8">5.7k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.11.3.9">5.8k</td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.12.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.8.8.12.4.1">BASAbaliWiki</th>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.2">23.4k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.3">36.6k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.4">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.5">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.6">18.7k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.7">29.3k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.8">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.12.4.9">0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.13.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.8.8.13.5.1">Bible verses</th>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.2">7.1k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.3">9.3k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.4">8.2k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.5">7.6k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.6">5.9k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.7">7.5k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.8">6.6k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.13.5.9">6.0k</td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.14.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.8.8.14.6.1">NusaX</th>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.2">0.9k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.3">1k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.4">1k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.5">0.9k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.6">0.8k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.7">0.8k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.8">0.9k</td>
<td class="ltx_td ltx_align_center" id="S4.T1.8.8.14.6.9">0.7k</td>
</tr>
<tr class="ltx_tr" id="S4.T1.8.8.15.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.1"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.1.1">TOTAL</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.2"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.2.1">44.9k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.3"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.3.1">55.2k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.4"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.4.1">20.9k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.5"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.5.1">31.0k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.6"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.6.1">35.6k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.7"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.7.1">44.9k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.8"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.8.1">16.6k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.8.8.15.7.9"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.15.7.9.1">22.4k</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">For our parallel data, we aggregated both human-annotated and automatically matched bitext datasets. We initially selected Balinese for our ablation study and subsequently expanded to Minangkabau using the best-performing method for additional benchmarking. Each low-resource language has four translation directions: to and from English and Indonesian. The number of parallel sentences for each dataset is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.T1" title="Table 1 ‣ 4.1 Data ‣ 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>. It is important to note that all parallel sentences undergo a filtering pipeline as described in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.SS2" title="A.2 Filtering ‣ Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We used AllenAI’s NLLB bitext dataset <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">AllenAI</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> (licensed under ODC-BY), sourced from metadata released by Meta AI as part of the NLLB project, as it is the largest dataset available for low-resource languages. Additionally, we used the human-annotated NLLB SEED dataset <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Maillard et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> (licensed under CC-BY-SA), which contains 6,062 sentences across English and multiple low-resource languages, including Balinese and Minangkabau.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Since SEED does not include Indonesian, and given the SoTA performance for en<math alttext="\rightarrow" class="ltx_Math" display="inline" id="footnote5.m1.1"><semantics id="footnote5.m1.1b"><mo id="footnote5.m1.1.1" stretchy="false" xref="footnote5.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="footnote5.m1.1c"><ci id="footnote5.m1.1.1.cmml" xref="footnote5.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote5.m1.1d">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="footnote5.m1.1e">→</annotation></semantics></math>id, English SEED sentences were translated into Indonesian with the NLLB-3.3B model for additional bitext <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Team et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.</span></span></span> We also extracted Bible verse bitexts from Alkitab.mobi <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Yayasan Lembaga SABDA (2018)</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">YLSA</span></a>)</cite> (released under copyright for non-profit scholarly and personal use only), a collection of Bibles translated into regional Indonesian languages, where parallel sentences were generated automatically based on identical Bible line numbers. Finally, we used NusaX (licensed under CC-BY-SA), a parallel corpus annotated by Indonesian language experts across English and 10 Indonesian languages, including Balinese and Minangkabau <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Indra Winata et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>. For Balinese directions, we also sourced BASAbaliWiki (licensed under CC-BY-SA), a Balinese wiki containing articles with translations in Indonesian and English <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">a20</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>. In each article, we generated bitext by using LASER3 to find the nearest neighbors of each sentence and create possible sentence pairs, setting a similarity threshold of 0.7.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">For monolingual data used in backtranslation, we aggregated sentences from Wikipedia dumps (CC BY-SA) and the Glot500 dataset, which was collected from other existing multilingual datasets (all of which we used were licensed under CC BY-NC or CC BY) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Rogers et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">We also report the parallel sentence counts before and after LLM cleaning in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.T1" title="Table 1 ‣ 4.1 Data ‣ 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>. Across all language pairs, there is a significant decrease in total parallel sentences—most notably from 31k to 22.4k sentences in the min<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mo id="S4.SS1.p4.1.m1.1.1" stretchy="false" xref="S4.SS1.p4.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">↔</annotation></semantics></math>id pair. However, in human-annotated datasets like NLLB SEED and NusaX, minimal parallel sentences were filtered out, indicating that the LLM cleaner was proficient in retaining truly aligned sentence pairs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Training Setup</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In the initial SFT stage, we trained the model across all language directions simultaneously. To reduce GPU memory usage, we utilized Low-Rank Adaptation (LoRA) with a rank of 16, which reduces the number of trainable parameters to only 0.1% (7.7 million from 7 billion parameters) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Hu et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>. We also used Deepspeed with ZeRO stage 2 offloading using bfloat16 to further optimize memory usage and enable multi-GPU training <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">SC </span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>. The dataset was randomly split into training, testing, and validation sets with 90%, 5% and 5% splits respectively. Training was conducted over 3 epochs with a learning rate of 0.002 and a per-device batch size of 10. The best model weights were selected based on the lowest CLM loss on the validation set. For training, two Nvidia RTX 4090 GPUs were rented through the <a class="ltx_ref ltx_href" href="https://vast.ai/" title="">vast.ai</a> cloud GPU platform. Training took 18 hours on our combined dataset, which includes Balinese and Minangkabau.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>A Balinese Case Study</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>spBLEU score comparison of the LLaMA2-7B SFT model with various enhancements, including monolingual pre-training (+ Mono), backtranslation (+ BT), and LLM cleaning (+ Cleaner)</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.5.1">Models</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1">ban <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">→</annotation></semantics></math> en</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.1">en <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.1.m1.1"><semantics id="S4.T2.2.2.2.1.m1.1a"><mo id="S4.T2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.1.m1.1b"><ci id="S4.T2.2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.1.m1.1d">→</annotation></semantics></math> ban</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.3.3.3.1">ban <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.1.m1.1"><semantics id="S4.T2.3.3.3.1.m1.1a"><mo id="S4.T2.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T2.3.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.1.m1.1b"><ci id="S4.T2.3.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.1.m1.1d">→</annotation></semantics></math> id</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.1">id <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T2.4.4.4.1.m1.1"><semantics id="S4.T2.4.4.4.1.m1.1a"><mo id="S4.T2.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T2.4.4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.1.m1.1b"><ci id="S4.T2.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.1.m1.1d">→</annotation></semantics></math> ban</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.4.5.1.1">Llama2-7B SFT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.5.1.2">27.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.5.1.3">13.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.5.1.4">27.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.5.1.5">13.68</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.6.2.1">+ Mono</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.6.2.2">31.28</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.6.2.3">18.92</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.6.2.4">28.75</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.6.2.5">20.11</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.7.3.1">+ Mono + BT</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.7.3.2">33.97</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.7.3.3">20.27</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.7.3.4">29.62</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.7.3.5">20.67</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.8.4.1">+ Mono + Cleaner</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.8.4.2">33.23</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.8.4.3">19.75</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.8.4.4">29.02</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.8.4.5">21.16</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.4.9.5.1">+ Mono + Cleaner + BT</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.9.5.2"><span class="ltx_text ltx_font_bold" id="S4.T2.4.9.5.2.1">35.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.9.5.3"><span class="ltx_text ltx_font_bold" id="S4.T2.4.9.5.3.1">22.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.9.5.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.9.5.4.1">31.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.9.5.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.9.5.5.1">22.95</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To study the effects of our proposed method, we compare fine-tuning the base LLaMA2-7B model with the addition of monolingual pre-training, LLM cleaning, and backtranslation methods. We present our findings in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.T2" title="Table 2 ‣ 4.3 A Balinese Case Study ‣ 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>, using the spBLEU metric, which is the traditional BLEU metric applied over text tokenized by the FLORES-200 SentencePiece <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Goyal et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The results indicate that the Komodo-7B-base model, with additional monolingual pre-training, achieves substantial gains over the base LLaMA2-7B model across all translation directions. Notably, we observe up to a 45% increase in spBLEU in the Indonesian to Balinese direction. Additionally, we find that the LLM cleaning method alone raises spBLEU scores by an average of 5%. This suggests that a reduced training size with reduced noise can indeed boost model performance, supporting the LIMA hypothesis. We also report a 4.7% increase in spBLEU through backtranslation, demonstrating the LLM’s capacity to continue learning through synthetically generated data. Furthermore, when applying both methods in conjunction, we observe an average performance increase of 13% spBLEU over the Mono + SFT baseline.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Benchmarking</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.1">Baselines.</span> We now evaluate and benchmark NusaMT-7B, our model with the LLM cleaner and backtranslation, additionally trained on Minangkabau language directions. First, we benchmark the SoTA NLLB-200 models, including the 3.3B, 1.3B, and the distilled 600M variant. Additionally, we benchmark the very large GPTs from OpenAI—GPT-3.5-turbo, GPT-4, and the latest GPT-4o—using zero-shot prompts.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>spBLEU scores of NusaMT-7B compared against SoTA models (NLLB-600M, NLLB-1.3B, NLLB-3.3B) and large GPT models (GPT-3.5-turbo, GPT-4o, GPT-4)</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.8" style="width:433.6pt;height:121.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.7pt,11.6pt) scale(0.838834778589625,0.838834778589625) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.8.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T3.8.8.8.9"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.8.9.1">Models</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1">ban <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.1.m1.1d">→</annotation></semantics></math> en</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.2.1">en <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.2.1.m1.1"><semantics id="S4.T3.2.2.2.2.1.m1.1a"><mo id="S4.T3.2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T3.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.2.1.m1.1d">→</annotation></semantics></math> ban</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.3.1">ban <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.3.3.3.3.1.m1.1"><semantics id="S4.T3.3.3.3.3.1.m1.1a"><mo id="S4.T3.3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T3.3.3.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.1.m1.1b"><ci id="S4.T3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.3.1.m1.1d">→</annotation></semantics></math> id</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.4.1">id <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.4.4.4.4.1.m1.1"><semantics id="S4.T3.4.4.4.4.1.m1.1a"><mo id="S4.T3.4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T3.4.4.4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.1.m1.1b"><ci id="S4.T3.4.4.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.4.1.m1.1d">→</annotation></semantics></math> ban</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.5.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.1">min <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.5.5.5.5.1.m1.1"><semantics id="S4.T3.5.5.5.5.1.m1.1a"><mo id="S4.T3.5.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T3.5.5.5.5.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.5.1.m1.1b"><ci id="S4.T3.5.5.5.5.1.m1.1.1.cmml" xref="S4.T3.5.5.5.5.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.5.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.5.1.m1.1d">→</annotation></semantics></math> en</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.6.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.6.1">en <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.6.6.6.6.1.m1.1"><semantics id="S4.T3.6.6.6.6.1.m1.1a"><mo id="S4.T3.6.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T3.6.6.6.6.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.6.1.m1.1b"><ci id="S4.T3.6.6.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.6.6.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.6.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.6.1.m1.1d">→</annotation></semantics></math> min</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T3.7.7.7.7.1">min <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.7.7.7.7.1.m1.1"><semantics id="S4.T3.7.7.7.7.1.m1.1a"><mo id="S4.T3.7.7.7.7.1.m1.1.1" stretchy="false" xref="S4.T3.7.7.7.7.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.7.1.m1.1b"><ci id="S4.T3.7.7.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.7.7.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.7.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.7.7.1.m1.1d">→</annotation></semantics></math> id</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.8.8.8.8"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.8.8.1">id <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T3.8.8.8.8.1.m1.1"><semantics id="S4.T3.8.8.8.8.1.m1.1a"><mo id="S4.T3.8.8.8.8.1.m1.1.1" stretchy="false" xref="S4.T3.8.8.8.8.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.8.1.m1.1b"><ci id="S4.T3.8.8.8.8.1.m1.1.1.cmml" xref="S4.T3.8.8.8.8.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.8.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.8.8.8.1.m1.1d">→</annotation></semantics></math> min</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.8.8.9.1.1">GPT-3.5-turbo, zero-shot</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.2">27.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.3">11.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.4">28.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.5">13.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.6">28.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.7">11.07</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.8">31.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.9.1.9">11.05</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.10.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.8.8.10.2.1">GPT-4o, zero-shot</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.2">27.11</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.3">11.45</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.4">27.89</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.5">13.08</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.6">28.63</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.7">11.00</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.8">31.27</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.10.2.9">11.00</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.11.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.8.8.11.3.1">GPT-4, zero-shot</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.2">27.20</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.3">11.59</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.4">28.41</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.5">13.24</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.6">28.51</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.7">10.99</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.8">31.00</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.11.3.9">10.93</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.12.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.8.8.12.4.1">NLLB-600M</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.2">33.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.3">16.86</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.4">30.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.5">15.15</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.6">35.05</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.7">19.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.8">31.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.8.12.4.9">17.72</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.13.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.8.8.13.5.1">NLLB-1.3B</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.2">37.24</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.3">17.73</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.4">32.42</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.5">16.21</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.6">38.59</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.7">22.79</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.8">34.68</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.13.5.9">20.89</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.14.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.8.8.14.6.1">NLLB-3.3B</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.2"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.14.6.2.1">38.57</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.3">17.09</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.4"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.14.6.4.1">33.35</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.5">14.85</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.6"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.14.6.6.1">40.61</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.7"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.14.6.7.1">24.71</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.8"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.14.6.8.1">35.20</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.14.6.9">22.44</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.8.15.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.1">NusaMT-7B (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.2">35.42</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.3"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.15.7.3.1">22.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.4">31.56</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.5"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.15.7.5.1">22.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.6">37.23</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.7">24.32</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.8">34.29</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.8.8.15.7.9"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.15.7.9.1">23.27</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">We report our benchmarking in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.T3" title="Table 3 ‣ 4.4 Benchmarking ‣ 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>. For all translations into higher-resource languages, NusaMT-7B scores higher than the GPT models and NLLB-600M, but is either outperformed by NLLB-1.3B or NLLB-3.3B. This could be due to the additional learning that NLLB models transferred from the directions involving similar languages—besides Minangkabau and Balinese—into high-resource languages. However, in translations into Balinese, NusaMT-7B achieves spBLEU scores of 22.1 and 22.9 spBLEU score from English and Indonesian directions, respectively, outperforming all the SoTA models, including the larger NLLB-3.3B by up to +6.69 spBLEU. Similarly, in the Indonesian to Minangkabau direction, NusaMT-7B outperforms NLLB-3.3B by +0.83 spBLEU. Overall, while NusaMT-7B still lags behind SoTAs in translations toward high-resource languages, we observe significant performance gains in translations toward low-resource languages.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we introduced NusaMT-7B, a large language model fine-tuned for low-resource Indonesian languages, with a focus on Balinese and Minangkabau. Our method combines continued pre-training on monolingual data, SFT, and data manipulation techniques using our LLM cleaner and backtranslation. The results from our experiments demonstrate significant performance improvements in translation quality, particularly in directions toward Balinese. Our findings also support the LIMA hypothesis, showing that a smaller, higher-quality dataset can indeed increase model performance. This study presents a promising direction for enhancing machine translation in low-resource settings, contributing to the preservation and revitalization of the many endangered languages in Indonesia and beyond.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">There are several limitations to our study. Due to limited GPU resources, we used the Komodo-7B-base model, which constrains our ability to determine the exact number of monolingual tokens each language was pretrained on and prevents us from fully assessing the required content and size of monolingual data for optimal performance. We also did not benchmark against the NLLB-54B Mixture of Experts (MOE) model, NLLB’s largest model <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Team et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>. In addition, comparisons with models like NLLB are limited by differences in training data, as our model incorporates additional external sources beyond NLLB’s SEED and mined bitext datasets. Our findings are also based solely on the spBLEU metric, which may not fully align with translation performance. Furthermore, the ablation study discussed in <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#S4.SS3" title="4.3 A Balinese Case Study ‣ 4 Experiments ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a> was conducted only on language directions involving Balinese; therefore, the performance gains from our chosen techniques may not generalize to other low-resource languages. It is also important to note that, compared to NMT models, our model utilizes significantly more parameters (7 billion), and thus is less computationally efficient during training and inference.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.4.4.1" style="font-size:90%;">a20 [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.6.1" style="font-size:90%;">
Basabaliwiki, 02 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.7.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dictionary.basabali.org/Main_Page" style="font-size:90%;" title="">https://dictionary.basabali.org/Main_Page</a><span class="ltx_text" id="bib.bib1.8.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.4.4.1" style="font-size:90%;">a20 [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.6.1" style="font-size:90%;">
Data bahasa - peta bahasa, 2024a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://petabahasa.kemdikbud.go.id/databahasa.php" style="font-size:90%;" title="">https://petabahasa.kemdikbud.go.id/databahasa.php</a><span class="ltx_text" id="bib.bib2.8.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.4.4.1" style="font-size:90%;">a20 [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.6.1" style="font-size:90%;">
Google translate, 2024b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.7.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://translate.google.com/?sl=id&amp;tl=en&amp;op=translate" style="font-size:90%;" title="">https://translate.google.com/?sl=id&amp;tl=en&amp;op=translate</a><span class="ltx_text" id="bib.bib3.8.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.4.4.1" style="font-size:90%;">a20 [2024c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.6.1" style="font-size:90%;">
Indonesia, 2024c.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.7.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.ethnologue.com/country/ID/" style="font-size:90%;" title="">https://www.ethnologue.com/country/ID/</a><span class="ltx_text" id="bib.bib4.8.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.4.4.1" style="font-size:90%;">AllenAI [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.6.1" style="font-size:90%;">
AllenAI.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">Nllb, 04 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.8.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/allenai/nllb" style="font-size:90%;" title="">https://huggingface.co/datasets/allenai/nllb</a><span class="ltx_text" id="bib.bib5.9.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">Alves et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
Duarte M Alves, José Pombal, Nuno M Guerreiro, Pedro H Martins, João Alves, Amin Farajian, Ben Peters, Ricardo Rei, Patrick Fernandes, Sweta Agrawal, Pierre Colombo, and Martins de.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">Tower: An open multilingual large language model for translation-related tasks, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.17733" style="font-size:90%;" title="">https://arxiv.org/abs/2402.17733</a><span class="ltx_text" id="bib.bib6.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.4.4.1" style="font-size:90%;">Artetxe and Schwenk [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.6.1" style="font-size:90%;">
Mikel Artetxe and Holger Schwenk.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.7.1" style="font-size:90%;">Margin-based parallel corpus mining with multilingual sentence embeddings, 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.8.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P19-1309.pdf" style="font-size:90%;" title="">https://aclanthology.org/P19-1309.pdf</a><span class="ltx_text" id="bib.bib7.9.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">Bolding et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.7.1" style="font-size:90%;">
Quinten Bolding, Baohao Liao, Brandon Denis, Jun Luo, and Christof Monz.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.8.1" style="font-size:90%;">Ask language model to clean your noisy translation data, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-emnlp.212.pdf" style="font-size:90%;" title="">https://aclanthology.org/2023.findings-emnlp.212.pdf</a><span class="ltx_text" id="bib.bib8.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.5.5.1" style="font-size:90%;">Brown et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.7.1" style="font-size:90%;">
Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, and … Dario Neelakantan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.8.1" style="font-size:90%;">Language models are few-shot learners, 2020.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2005.14165" style="font-size:90%;" title="">https://arxiv.org/abs/2005.14165</a><span class="ltx_text" id="bib.bib9.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.4.4.1" style="font-size:90%;">Celikyilmaz and Wen [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.6.1" style="font-size:90%;">
Asli Celikyilmaz and Tsung-Hsien Wen, editors.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.7.1" style="font-size:90%;">OpusFilter: A configurable parallel corpus filtering toolbox</em><span class="ltx_text" id="bib.bib10.8.2" style="font-size:90%;">, 07 2020. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.9.1" style="font-size:90%;">doi: </span><span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self" style="font-size:90%;">10.18653/v1/2020.acl-demos.20</span><span class="ltx_text" id="bib.bib10.10.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.11.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.acl-demos.20" style="font-size:90%;" title="">https://aclanthology.org/2020.acl-demos.20</a><span class="ltx_text" id="bib.bib10.12.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">Goyal et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.7.1" style="font-size:90%;">
Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán, and Angela Fan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.8.1" style="font-size:90%;">The &lt;scp&gt;flores-101&lt;/scp&gt; evaluation benchmark for low-resource and multilingual machine translation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.9.1" style="font-size:90%;">Transactions of the Association for Computational Linguistics</em><span class="ltx_text" id="bib.bib11.10.2" style="font-size:90%;">, 10:522–538, 01 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.11.1" style="font-size:90%;">doi: </span><span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self" style="font-size:90%;">10.1162/tacl_a_00474</span><span class="ltx_text" id="bib.bib11.12.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.13.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00474/110993/The-Flores-101-Evaluation-Benchmark-for-Low" style="font-size:90%;" title="">https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00474/110993/The-Flores-101-Evaluation-Benchmark-for-Low</a><span class="ltx_text" id="bib.bib11.14.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">Goyle et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
Vakul Goyle, Parvathy Krishnaswamy, Kannan Girija Ravikumar, Utsa Chattopadhyay, and Kartikay Goyle.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">Neural machine translation for low resource languages, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2304.07869" style="font-size:90%;" title="">https://arxiv.org/abs/2304.07869</a><span class="ltx_text" id="bib.bib12.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.5.5.1" style="font-size:90%;">Hossein et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">
Amir Hossein, François Yvon, and Hinrich Schütze.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.8.1" style="font-size:90%;">Glotlid: Language identification for low-resource languages, 06 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/pdf/2310.16248v3" style="font-size:90%;" title="">https://arxiv.org/pdf/2310.16248v3</a><span class="ltx_text" id="bib.bib13.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">Hu et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.7.1" style="font-size:90%;">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.8.1" style="font-size:90%;">Lora: Low-rank adaptation of large language models, 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2106.09685" style="font-size:90%;" title="">https://arxiv.org/abs/2106.09685</a><span class="ltx_text" id="bib.bib14.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">Indra Winata et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.7.1" style="font-size:90%;">
Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Rahmad Mahendra, Fajri Koto, Ade Romadhony, Kemal Kurniawan, David Moeljadi, Radityo Prasojo, Pascale Fung, Timothy Baldwin, Jey Lau, Rico Sennrich, and Kata Ai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.8.1" style="font-size:90%;">Nusax: Multilingual parallel sentiment dataset for 10 indonesian local languages, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.eacl-main.57.pdf" style="font-size:90%;" title="">https://aclanthology.org/2023.eacl-main.57.pdf</a><span class="ltx_text" id="bib.bib15.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.5.5.1" style="font-size:90%;">Jiao et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">
Wenxiang Jiao, Jen-tse Huang, Wenxuan Wang, Zhiwei He, Tian Liang, Xing Wang, Shuming Shi, and Zhaopeng Tu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">Parrot: Translating during chat using large language models tuned with human translation and feedback.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.9.1" style="font-size:90%;">arXiv (Cornell University)</em><span class="ltx_text" id="bib.bib16.10.2" style="font-size:90%;">, 12 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.11.1" style="font-size:90%;">doi: </span><span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self" style="font-size:90%;">10.18653/v1/2023.findings-emnlp.1001</span><span class="ltx_text" id="bib.bib16.12.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.13.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-emnlp.1001/" style="font-size:90%;" title="">https://aclanthology.org/2023.findings-emnlp.1001/</a><span class="ltx_text" id="bib.bib16.14.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">Kuulmets et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.7.1" style="font-size:90%;">
Hele-Andra Kuulmets, Taido Purason, Agnes Luhtaru, and Mark Fishel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.8.1" style="font-size:90%;">Teaching llama a new language through cross-lingual knowledge transfer, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.04042" style="font-size:90%;" title="">https://arxiv.org/abs/2404.04042</a><span class="ltx_text" id="bib.bib17.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.5.5.1" style="font-size:90%;">Maillard et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">
Jean Maillard, Cynthia Gao, Elahe Kalbassi, Kaushik Ram Sadagopan, Vedanuj Goswami, Philipp Koehn, Angela Fan, and Francisco Guzmán.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.8.1" style="font-size:90%;">Small data, big impact: Leveraging minimal data for effective machine translation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib18.10.2" style="font-size:90%;">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em><span class="ltx_text" id="bib.bib18.11.3" style="font-size:90%;">, pages 2740–2756, Toronto, Canada, 2023. Association for Computational Linguistics.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.12.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.acl-long.154" style="font-size:90%;" title="">https://aclanthology.org/2023.acl-long.154</a><span class="ltx_text" id="bib.bib18.13.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.5.5.1" style="font-size:90%;">Miyaoka et al. [2007]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">
Osahito Miyaoka, Osamu Sakiyama, and Michael E Krauss.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.8.1" style="font-size:90%;">The Vanishing Languages of the Pacific Rim</em><span class="ltx_text" id="bib.bib19.9.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.10.1" style="font-size:90%;">Oxford University Press, 04 2007.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">OpenAI et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, and … Barret Altenschmidt.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">Gpt-4 technical report, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2303.08774" style="font-size:90%;" title="">https://arxiv.org/abs/2303.08774</a><span class="ltx_text" id="bib.bib20.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.5.5.1" style="font-size:90%;">Owen et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.7.1" style="font-size:90%;">
Louis Owen, Vishesh Tripathi, Abhay Kumar, and Biddwan Ahmed.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.8.1" style="font-size:90%;">Komodo: A linguistic expedition into indonesia’s regional languages, 03 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/pdf/2403.09362" style="font-size:90%;" title="">https://arxiv.org/pdf/2403.09362</a><span class="ltx_text" id="bib.bib21.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.5.5.1" style="font-size:90%;">Rogers et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.7.1" style="font-size:90%;">
Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.8.1" style="font-size:90%;">Glot500: Scaling multilingual corpora and language models to 500 languages</em><span class="ltx_text" id="bib.bib22.9.2" style="font-size:90%;">, volume 1, 07 2023. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Association for Computational Linguistics.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.10.1" style="font-size:90%;">doi: </span><span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self" style="font-size:90%;">10.18653/v1/2023.acl-long.61</span><span class="ltx_text" id="bib.bib22.11.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.12.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.acl-long.61" style="font-size:90%;" title="">https://aclanthology.org/2023.acl-long.61</a><span class="ltx_text" id="bib.bib22.13.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.4.4.1" style="font-size:90%;">SC  [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.6.1" style="font-size:90%;">
</span><em class="ltx_emph ltx_font_italic" id="bib.bib23.7.2" style="font-size:90%;">ZeRO: memory optimizations toward training trillion parameter models</em><span class="ltx_text" id="bib.bib23.8.3" style="font-size:90%;">, 11 2020. SC ’20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.5555/3433701.3433727" style="font-size:90%;" title="">https://dl.acm.org/doi/10.5555/3433701.3433727</a><span class="ltx_text" id="bib.bib23.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">Tan et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
Weiting Tan, Kevin Heffernan holger, and Schwenk philipp Koehn.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">Multilingual representation distillation with contrastive learning, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.eacl-main.108.pdf" style="font-size:90%;" title="">https://aclanthology.org/2023.eacl-main.108.pdf</a><span class="ltx_text" id="bib.bib24.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">Team et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
NLLB Team, Marta R Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, and … Jeff Licht.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">No language left behind: Scaling human-centered machine translation, 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2207.04672" style="font-size:90%;" title="">https://arxiv.org/abs/2207.04672</a><span class="ltx_text" id="bib.bib25.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">Touvron et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, and … Thomas Bhosale.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">Llama 2: Open foundation and fine-tuned chat models, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2307.09288" style="font-size:90%;" title="">https://arxiv.org/abs/2307.09288</a><span class="ltx_text" id="bib.bib26.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">Xu et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.7.1" style="font-size:90%;">
Haoran Xu, Young Kim, Amr Sharaf, Hassan Hany, and Awadalla.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.8.1" style="font-size:90%;">A paradigm shift in machine translation: Boosting translation performance of large language models, 02 2024a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/pdf/2309.11674" style="font-size:90%;" title="">https://arxiv.org/pdf/2309.11674</a><span class="ltx_text" id="bib.bib27.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">Xu et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Van Durme, Kenton Murray, and Young Jin Kim.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation, 2024b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2401.08417" style="font-size:90%;" title="">https://arxiv.org/abs/2401.08417</a><span class="ltx_text" id="bib.bib28.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.5.5.1" style="font-size:90%;">Yayasan Lembaga SABDA (2018) [YLSA]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.6.1" style="font-size:90%;">Yayasan Lembaga SABDA (YLSA).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">Alkitab yang terbuka (ayt), 2018.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.8.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://alkitab.mobi/" style="font-size:90%;" title="">http://alkitab.mobi/</a><span class="ltx_text" id="bib.bib29.9.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.10.1" style="font-size:90%;">Copyright © 2018 Yayasan Lembaga SABDA (YLSA). For non-profit scholarly and personal use only.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">Zhu et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.7.1" style="font-size:90%;">
Dawei Zhu, Pinzhen Chen, Miaoran Zhang, Barry Haddow, Xiaoyu Shen, and Dietrich Klakow.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.8.1" style="font-size:90%;">Fine-tuning large language models to translate: Will a touch of noisy data in misaligned languages suffice?, 2024a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.14122" style="font-size:90%;" title="">https://arxiv.org/abs/2404.14122</a><span class="ltx_text" id="bib.bib30.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">Zhu et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.7.1" style="font-size:90%;">
Dawei Zhu, Sony Trenous, Xiaoyu Shen, Dietrich Klakow, Bill Byrne, and Eva Hasler.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.8.1" style="font-size:90%;">A preference-driven paradigm for enhanced translation with large language models, 2024b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.9.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.11288" style="font-size:90%;" title="">https://arxiv.org/abs/2404.11288</a><span class="ltx_text" id="bib.bib31.10.2" style="font-size:90%;">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">Zong et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.7.1" style="font-size:90%;">
Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.8.1" style="font-size:90%;">CCMatrix: Mining billions of high-quality parallel sentences on the web</em><span class="ltx_text" id="bib.bib32.9.2" style="font-size:90%;">, 08 2021. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.10.1" style="font-size:90%;">doi: </span><span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self" style="font-size:90%;">10.18653/v1/2021.acl-long.507</span><span class="ltx_text" id="bib.bib32.11.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.12.1" style="font-size:90%;">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.acl-long.507" style="font-size:90%;" title="">https://aclanthology.org/2021.acl-long.507</a><span class="ltx_text" id="bib.bib32.13.2" style="font-size:90%;">.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Prompts</h3>
<section class="ltx_subsubsection" id="A1.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1 </span>Translation Prompt</h4>
<div class="ltx_para" id="A1.SS1.SSS1.p1">
<pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.SSS1.p1.1">
Translate this from [source language] to [target language]:
[source language]: [source]
[target language]:
</pre>
</div>
<div class="ltx_para" id="A1.SS1.SSS1.p2">
<p class="ltx_p" id="A1.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS1.SSS1.p2.1.1">[Few-shot prompt]</span>:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.SSS1.p2.2">
Translate this from English to Balinese:
English: Astaire continued to act in the 1970s.
Balinese: Astaire sasai maakting ring warsa 1970-an.
</pre>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2 </span>Cleaner Prompt</h4>
<div class="ltx_para" id="A1.SS1.SSS2.p1">
<pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.SSS2.p1.1">
You are an expert in aligning and cleaning parallel sentences in different
languages. You will receive two sentences: one in a source language and
one in a target language.

Your task is:
1. On the first line, respond with "True" if the sentences have the same
meaning, otherwise respond with "False".
2. If the first line is "True", provide the cleaned and aligned sentences
on the second and third lines respectively by fixing syntax errors, removing
noise (such as unnecessary phrases, punctuation or ambiguous
numbers), and normalizing text (e.g., capitalization).

Here are some examples to guide you:
[Few-shot prompt]

Now, clean the following sentence pairs:
[Batch-prompt]
</pre>
</div>
<div class="ltx_para" id="A1.SS1.SSS2.p2">
<p class="ltx_p" id="A1.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS1.SSS2.p2.1.1">[Few-shot prompt]</span>:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.SSS2.p2.2">
Indonesian: Dengan harga yang bisa dibilang menengah, apa saja yang ditwarkannya?
Balinese: Suratan puniki nnten indik Kabupatn miwah kota ring Kepulauan Riau.

Indonesian: Bahasa daerah memiliki karakteristik yang unik.
Balinese: (32:2) Basa daerah madue "karakteristik" sane soleh.

False

True
Indonesian: Bahasa daerah memiliki karakteristik yang unik.
Balinese: Basa daerah madue karakteristik sane soleh.
</pre>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Filtering</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">We used OpusFilter, a parallel corpus processing toolkit, <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Celikyilmaz and Wen</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite> to implement several simple filtering methods to remove noisy, low-quality or erroneous parallel sentences.</p>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p2.1.1">Heuristics.</span> We apply a few simple heuristics to remove likely noisy sentences. Specifically, we set a length filter between 15 and 500 characters to remove sentences with less than approximately three words and those above the maximum 256 tokens (given an approximate 2.5 characters per token). We also specify a word length ratio of 2 and remove sentences containing words longer than 20 characters, as they often indicate errors. Finally, we deduplicate sentence pairs and remove sentences with excessive punctuation or numerical content beyond a 20% threshold.</p>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p3.1.1">Language Identification (LID).</span> We intend to preserve only the sentences clearly in the desired source or target language. Thus, we apply the GlotLid V3 LID <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Hossein et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> on both monolingual and parallel corpora, using only sentences with a language score above a 0.9 threshold, therefore removing sentence pairs that may contain ambiguity and noise.</p>
</div>
<div class="ltx_para" id="A1.SS2.p4">
<p class="ltx_p" id="A1.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p4.1.1">Laser Score.</span> The LASER3 encoder <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Team et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> was chosen due to its availability in all the FLORES-200 languages, including Balinese and Minangkabau, as well as its low error rate compared to other multilingual sentence encoders <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Tan et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>. LASER3 encodes sentences in multiple languages and evaluates the quality of a sentence using xsim <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Artetxe and Schwenk</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, as shown in  <a class="ltx_ref" href="https://arxiv.org/html/2410.07830v1#A1.E1" title="In A.2 Filtering ‣ Appendix A Appendix ‣ NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>,</p>
</div>
<div class="ltx_para" id="A1.SS2.p5">
<table class="ltx_equation ltx_eqn_table" id="A1.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{score}(x,y)=\text{margin}\left(\cos(x,y),\left(\sum_{z\in\text{NN}_{k}(x%
)}\frac{\cos(x,z)}{2k}+\sum_{z\in\text{NN}_{k}(y)}\frac{\cos(y,z)}{2k}\right)\right)" class="ltx_Math" display="block" id="A1.E1.m1.15"><semantics id="A1.E1.m1.15a"><mrow id="A1.E1.m1.15.15" xref="A1.E1.m1.15.15.cmml"><mrow id="A1.E1.m1.15.15.4" xref="A1.E1.m1.15.15.4.cmml"><mtext id="A1.E1.m1.15.15.4.2" xref="A1.E1.m1.15.15.4.2a.cmml">score</mtext><mo id="A1.E1.m1.15.15.4.1" xref="A1.E1.m1.15.15.4.1.cmml">⁢</mo><mrow id="A1.E1.m1.15.15.4.3.2" xref="A1.E1.m1.15.15.4.3.1.cmml"><mo id="A1.E1.m1.15.15.4.3.2.1" stretchy="false" xref="A1.E1.m1.15.15.4.3.1.cmml">(</mo><mi id="A1.E1.m1.9.9" xref="A1.E1.m1.9.9.cmml">x</mi><mo id="A1.E1.m1.15.15.4.3.2.2" xref="A1.E1.m1.15.15.4.3.1.cmml">,</mo><mi id="A1.E1.m1.10.10" xref="A1.E1.m1.10.10.cmml">y</mi><mo id="A1.E1.m1.15.15.4.3.2.3" stretchy="false" xref="A1.E1.m1.15.15.4.3.1.cmml">)</mo></mrow></mrow><mo id="A1.E1.m1.15.15.3" xref="A1.E1.m1.15.15.3.cmml">=</mo><mrow id="A1.E1.m1.15.15.2" xref="A1.E1.m1.15.15.2.cmml"><mtext id="A1.E1.m1.15.15.2.4" xref="A1.E1.m1.15.15.2.4a.cmml">margin</mtext><mo id="A1.E1.m1.15.15.2.3" xref="A1.E1.m1.15.15.2.3.cmml">⁢</mo><mrow id="A1.E1.m1.15.15.2.2.2" xref="A1.E1.m1.15.15.2.2.3.cmml"><mo id="A1.E1.m1.15.15.2.2.2.3" xref="A1.E1.m1.15.15.2.2.3.cmml">(</mo><mrow id="A1.E1.m1.14.14.1.1.1.1.2" xref="A1.E1.m1.14.14.1.1.1.1.1.cmml"><mi id="A1.E1.m1.11.11" xref="A1.E1.m1.11.11.cmml">cos</mi><mo id="A1.E1.m1.14.14.1.1.1.1.2a" xref="A1.E1.m1.14.14.1.1.1.1.1.cmml">⁡</mo><mrow id="A1.E1.m1.14.14.1.1.1.1.2.1" xref="A1.E1.m1.14.14.1.1.1.1.1.cmml"><mo id="A1.E1.m1.14.14.1.1.1.1.2.1.1" stretchy="false" xref="A1.E1.m1.14.14.1.1.1.1.1.cmml">(</mo><mi id="A1.E1.m1.12.12" xref="A1.E1.m1.12.12.cmml">x</mi><mo id="A1.E1.m1.14.14.1.1.1.1.2.1.2" xref="A1.E1.m1.14.14.1.1.1.1.1.cmml">,</mo><mi id="A1.E1.m1.13.13" xref="A1.E1.m1.13.13.cmml">y</mi><mo id="A1.E1.m1.14.14.1.1.1.1.2.1.3" stretchy="false" xref="A1.E1.m1.14.14.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E1.m1.15.15.2.2.2.4" xref="A1.E1.m1.15.15.2.2.3.cmml">,</mo><mrow id="A1.E1.m1.15.15.2.2.2.2.1" xref="A1.E1.m1.15.15.2.2.2.2.1.1.cmml"><mo id="A1.E1.m1.15.15.2.2.2.2.1.2" xref="A1.E1.m1.15.15.2.2.2.2.1.1.cmml">(</mo><mrow id="A1.E1.m1.15.15.2.2.2.2.1.1" xref="A1.E1.m1.15.15.2.2.2.2.1.1.cmml"><mrow id="A1.E1.m1.15.15.2.2.2.2.1.1.2" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2.cmml"><munder id="A1.E1.m1.15.15.2.2.2.2.1.1.2.1" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.cmml"><mo id="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.2" lspace="0em" movablelimits="false" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.2.cmml">∑</mo><mrow id="A1.E1.m1.1.1.1" xref="A1.E1.m1.1.1.1.cmml"><mi id="A1.E1.m1.1.1.1.3" xref="A1.E1.m1.1.1.1.3.cmml">z</mi><mo id="A1.E1.m1.1.1.1.2" xref="A1.E1.m1.1.1.1.2.cmml">∈</mo><mrow id="A1.E1.m1.1.1.1.4" xref="A1.E1.m1.1.1.1.4.cmml"><msub id="A1.E1.m1.1.1.1.4.2" xref="A1.E1.m1.1.1.1.4.2.cmml"><mtext id="A1.E1.m1.1.1.1.4.2.2" xref="A1.E1.m1.1.1.1.4.2.2a.cmml">NN</mtext><mi id="A1.E1.m1.1.1.1.4.2.3" xref="A1.E1.m1.1.1.1.4.2.3.cmml">k</mi></msub><mo id="A1.E1.m1.1.1.1.4.1" xref="A1.E1.m1.1.1.1.4.1.cmml">⁢</mo><mrow id="A1.E1.m1.1.1.1.4.3.2" xref="A1.E1.m1.1.1.1.4.cmml"><mo id="A1.E1.m1.1.1.1.4.3.2.1" stretchy="false" xref="A1.E1.m1.1.1.1.4.cmml">(</mo><mi id="A1.E1.m1.1.1.1.1" xref="A1.E1.m1.1.1.1.1.cmml">x</mi><mo id="A1.E1.m1.1.1.1.4.3.2.2" stretchy="false" xref="A1.E1.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mfrac id="A1.E1.m1.4.4" xref="A1.E1.m1.4.4.cmml"><mrow id="A1.E1.m1.4.4.3.5" xref="A1.E1.m1.4.4.3.4.cmml"><mi id="A1.E1.m1.2.2.1.1" xref="A1.E1.m1.2.2.1.1.cmml">cos</mi><mo id="A1.E1.m1.4.4.3.5a" xref="A1.E1.m1.4.4.3.4.cmml">⁡</mo><mrow id="A1.E1.m1.4.4.3.5.1" xref="A1.E1.m1.4.4.3.4.cmml"><mo id="A1.E1.m1.4.4.3.5.1.1" stretchy="false" xref="A1.E1.m1.4.4.3.4.cmml">(</mo><mi id="A1.E1.m1.3.3.2.2" xref="A1.E1.m1.3.3.2.2.cmml">x</mi><mo id="A1.E1.m1.4.4.3.5.1.2" xref="A1.E1.m1.4.4.3.4.cmml">,</mo><mi id="A1.E1.m1.4.4.3.3" xref="A1.E1.m1.4.4.3.3.cmml">z</mi><mo id="A1.E1.m1.4.4.3.5.1.3" stretchy="false" xref="A1.E1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><mrow id="A1.E1.m1.4.4.5" xref="A1.E1.m1.4.4.5.cmml"><mn id="A1.E1.m1.4.4.5.2" xref="A1.E1.m1.4.4.5.2.cmml">2</mn><mo id="A1.E1.m1.4.4.5.1" xref="A1.E1.m1.4.4.5.1.cmml">⁢</mo><mi id="A1.E1.m1.4.4.5.3" xref="A1.E1.m1.4.4.5.3.cmml">k</mi></mrow></mfrac></mrow><mo id="A1.E1.m1.15.15.2.2.2.2.1.1.1" rspace="0.055em" xref="A1.E1.m1.15.15.2.2.2.2.1.1.1.cmml">+</mo><mrow id="A1.E1.m1.15.15.2.2.2.2.1.1.3" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3.cmml"><munder id="A1.E1.m1.15.15.2.2.2.2.1.1.3.1" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.cmml"><mo id="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.2" movablelimits="false" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.2.cmml">∑</mo><mrow id="A1.E1.m1.5.5.1" xref="A1.E1.m1.5.5.1.cmml"><mi id="A1.E1.m1.5.5.1.3" xref="A1.E1.m1.5.5.1.3.cmml">z</mi><mo id="A1.E1.m1.5.5.1.2" xref="A1.E1.m1.5.5.1.2.cmml">∈</mo><mrow id="A1.E1.m1.5.5.1.4" xref="A1.E1.m1.5.5.1.4.cmml"><msub id="A1.E1.m1.5.5.1.4.2" xref="A1.E1.m1.5.5.1.4.2.cmml"><mtext id="A1.E1.m1.5.5.1.4.2.2" xref="A1.E1.m1.5.5.1.4.2.2a.cmml">NN</mtext><mi id="A1.E1.m1.5.5.1.4.2.3" xref="A1.E1.m1.5.5.1.4.2.3.cmml">k</mi></msub><mo id="A1.E1.m1.5.5.1.4.1" xref="A1.E1.m1.5.5.1.4.1.cmml">⁢</mo><mrow id="A1.E1.m1.5.5.1.4.3.2" xref="A1.E1.m1.5.5.1.4.cmml"><mo id="A1.E1.m1.5.5.1.4.3.2.1" stretchy="false" xref="A1.E1.m1.5.5.1.4.cmml">(</mo><mi id="A1.E1.m1.5.5.1.1" xref="A1.E1.m1.5.5.1.1.cmml">y</mi><mo id="A1.E1.m1.5.5.1.4.3.2.2" stretchy="false" xref="A1.E1.m1.5.5.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mfrac id="A1.E1.m1.8.8" xref="A1.E1.m1.8.8.cmml"><mrow id="A1.E1.m1.8.8.3.5" xref="A1.E1.m1.8.8.3.4.cmml"><mi id="A1.E1.m1.6.6.1.1" xref="A1.E1.m1.6.6.1.1.cmml">cos</mi><mo id="A1.E1.m1.8.8.3.5a" xref="A1.E1.m1.8.8.3.4.cmml">⁡</mo><mrow id="A1.E1.m1.8.8.3.5.1" xref="A1.E1.m1.8.8.3.4.cmml"><mo id="A1.E1.m1.8.8.3.5.1.1" stretchy="false" xref="A1.E1.m1.8.8.3.4.cmml">(</mo><mi id="A1.E1.m1.7.7.2.2" xref="A1.E1.m1.7.7.2.2.cmml">y</mi><mo id="A1.E1.m1.8.8.3.5.1.2" xref="A1.E1.m1.8.8.3.4.cmml">,</mo><mi id="A1.E1.m1.8.8.3.3" xref="A1.E1.m1.8.8.3.3.cmml">z</mi><mo id="A1.E1.m1.8.8.3.5.1.3" stretchy="false" xref="A1.E1.m1.8.8.3.4.cmml">)</mo></mrow></mrow><mrow id="A1.E1.m1.8.8.5" xref="A1.E1.m1.8.8.5.cmml"><mn id="A1.E1.m1.8.8.5.2" xref="A1.E1.m1.8.8.5.2.cmml">2</mn><mo id="A1.E1.m1.8.8.5.1" xref="A1.E1.m1.8.8.5.1.cmml">⁢</mo><mi id="A1.E1.m1.8.8.5.3" xref="A1.E1.m1.8.8.5.3.cmml">k</mi></mrow></mfrac></mrow></mrow><mo id="A1.E1.m1.15.15.2.2.2.2.1.3" xref="A1.E1.m1.15.15.2.2.2.2.1.1.cmml">)</mo></mrow><mo id="A1.E1.m1.15.15.2.2.2.5" xref="A1.E1.m1.15.15.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E1.m1.15b"><apply id="A1.E1.m1.15.15.cmml" xref="A1.E1.m1.15.15"><eq id="A1.E1.m1.15.15.3.cmml" xref="A1.E1.m1.15.15.3"></eq><apply id="A1.E1.m1.15.15.4.cmml" xref="A1.E1.m1.15.15.4"><times id="A1.E1.m1.15.15.4.1.cmml" xref="A1.E1.m1.15.15.4.1"></times><ci id="A1.E1.m1.15.15.4.2a.cmml" xref="A1.E1.m1.15.15.4.2"><mtext id="A1.E1.m1.15.15.4.2.cmml" xref="A1.E1.m1.15.15.4.2">score</mtext></ci><interval closure="open" id="A1.E1.m1.15.15.4.3.1.cmml" xref="A1.E1.m1.15.15.4.3.2"><ci id="A1.E1.m1.9.9.cmml" xref="A1.E1.m1.9.9">𝑥</ci><ci id="A1.E1.m1.10.10.cmml" xref="A1.E1.m1.10.10">𝑦</ci></interval></apply><apply id="A1.E1.m1.15.15.2.cmml" xref="A1.E1.m1.15.15.2"><times id="A1.E1.m1.15.15.2.3.cmml" xref="A1.E1.m1.15.15.2.3"></times><ci id="A1.E1.m1.15.15.2.4a.cmml" xref="A1.E1.m1.15.15.2.4"><mtext id="A1.E1.m1.15.15.2.4.cmml" xref="A1.E1.m1.15.15.2.4">margin</mtext></ci><interval closure="open" id="A1.E1.m1.15.15.2.2.3.cmml" xref="A1.E1.m1.15.15.2.2.2"><apply id="A1.E1.m1.14.14.1.1.1.1.1.cmml" xref="A1.E1.m1.14.14.1.1.1.1.2"><cos id="A1.E1.m1.11.11.cmml" xref="A1.E1.m1.11.11"></cos><ci id="A1.E1.m1.12.12.cmml" xref="A1.E1.m1.12.12">𝑥</ci><ci id="A1.E1.m1.13.13.cmml" xref="A1.E1.m1.13.13">𝑦</ci></apply><apply id="A1.E1.m1.15.15.2.2.2.2.1.1.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1"><plus id="A1.E1.m1.15.15.2.2.2.2.1.1.1.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.1"></plus><apply id="A1.E1.m1.15.15.2.2.2.2.1.1.2.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2"><apply id="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2.1"><csymbol cd="ambiguous" id="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.1.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2.1">subscript</csymbol><sum id="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.2.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.2.1.2"></sum><apply id="A1.E1.m1.1.1.1.cmml" xref="A1.E1.m1.1.1.1"><in id="A1.E1.m1.1.1.1.2.cmml" xref="A1.E1.m1.1.1.1.2"></in><ci id="A1.E1.m1.1.1.1.3.cmml" xref="A1.E1.m1.1.1.1.3">𝑧</ci><apply id="A1.E1.m1.1.1.1.4.cmml" xref="A1.E1.m1.1.1.1.4"><times id="A1.E1.m1.1.1.1.4.1.cmml" xref="A1.E1.m1.1.1.1.4.1"></times><apply id="A1.E1.m1.1.1.1.4.2.cmml" xref="A1.E1.m1.1.1.1.4.2"><csymbol cd="ambiguous" id="A1.E1.m1.1.1.1.4.2.1.cmml" xref="A1.E1.m1.1.1.1.4.2">subscript</csymbol><ci id="A1.E1.m1.1.1.1.4.2.2a.cmml" xref="A1.E1.m1.1.1.1.4.2.2"><mtext id="A1.E1.m1.1.1.1.4.2.2.cmml" mathsize="70%" xref="A1.E1.m1.1.1.1.4.2.2">NN</mtext></ci><ci id="A1.E1.m1.1.1.1.4.2.3.cmml" xref="A1.E1.m1.1.1.1.4.2.3">𝑘</ci></apply><ci id="A1.E1.m1.1.1.1.1.cmml" xref="A1.E1.m1.1.1.1.1">𝑥</ci></apply></apply></apply><apply id="A1.E1.m1.4.4.cmml" xref="A1.E1.m1.4.4"><divide id="A1.E1.m1.4.4.4.cmml" xref="A1.E1.m1.4.4"></divide><apply id="A1.E1.m1.4.4.3.4.cmml" xref="A1.E1.m1.4.4.3.5"><cos id="A1.E1.m1.2.2.1.1.cmml" xref="A1.E1.m1.2.2.1.1"></cos><ci id="A1.E1.m1.3.3.2.2.cmml" xref="A1.E1.m1.3.3.2.2">𝑥</ci><ci id="A1.E1.m1.4.4.3.3.cmml" xref="A1.E1.m1.4.4.3.3">𝑧</ci></apply><apply id="A1.E1.m1.4.4.5.cmml" xref="A1.E1.m1.4.4.5"><times id="A1.E1.m1.4.4.5.1.cmml" xref="A1.E1.m1.4.4.5.1"></times><cn id="A1.E1.m1.4.4.5.2.cmml" type="integer" xref="A1.E1.m1.4.4.5.2">2</cn><ci id="A1.E1.m1.4.4.5.3.cmml" xref="A1.E1.m1.4.4.5.3">𝑘</ci></apply></apply></apply><apply id="A1.E1.m1.15.15.2.2.2.2.1.1.3.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3"><apply id="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3.1"><csymbol cd="ambiguous" id="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.1.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3.1">subscript</csymbol><sum id="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.2.cmml" xref="A1.E1.m1.15.15.2.2.2.2.1.1.3.1.2"></sum><apply id="A1.E1.m1.5.5.1.cmml" xref="A1.E1.m1.5.5.1"><in id="A1.E1.m1.5.5.1.2.cmml" xref="A1.E1.m1.5.5.1.2"></in><ci id="A1.E1.m1.5.5.1.3.cmml" xref="A1.E1.m1.5.5.1.3">𝑧</ci><apply id="A1.E1.m1.5.5.1.4.cmml" xref="A1.E1.m1.5.5.1.4"><times id="A1.E1.m1.5.5.1.4.1.cmml" xref="A1.E1.m1.5.5.1.4.1"></times><apply id="A1.E1.m1.5.5.1.4.2.cmml" xref="A1.E1.m1.5.5.1.4.2"><csymbol cd="ambiguous" id="A1.E1.m1.5.5.1.4.2.1.cmml" xref="A1.E1.m1.5.5.1.4.2">subscript</csymbol><ci id="A1.E1.m1.5.5.1.4.2.2a.cmml" xref="A1.E1.m1.5.5.1.4.2.2"><mtext id="A1.E1.m1.5.5.1.4.2.2.cmml" mathsize="70%" xref="A1.E1.m1.5.5.1.4.2.2">NN</mtext></ci><ci id="A1.E1.m1.5.5.1.4.2.3.cmml" xref="A1.E1.m1.5.5.1.4.2.3">𝑘</ci></apply><ci id="A1.E1.m1.5.5.1.1.cmml" xref="A1.E1.m1.5.5.1.1">𝑦</ci></apply></apply></apply><apply id="A1.E1.m1.8.8.cmml" xref="A1.E1.m1.8.8"><divide id="A1.E1.m1.8.8.4.cmml" xref="A1.E1.m1.8.8"></divide><apply id="A1.E1.m1.8.8.3.4.cmml" xref="A1.E1.m1.8.8.3.5"><cos id="A1.E1.m1.6.6.1.1.cmml" xref="A1.E1.m1.6.6.1.1"></cos><ci id="A1.E1.m1.7.7.2.2.cmml" xref="A1.E1.m1.7.7.2.2">𝑦</ci><ci id="A1.E1.m1.8.8.3.3.cmml" xref="A1.E1.m1.8.8.3.3">𝑧</ci></apply><apply id="A1.E1.m1.8.8.5.cmml" xref="A1.E1.m1.8.8.5"><times id="A1.E1.m1.8.8.5.1.cmml" xref="A1.E1.m1.8.8.5.1"></times><cn id="A1.E1.m1.8.8.5.2.cmml" type="integer" xref="A1.E1.m1.8.8.5.2">2</cn><ci id="A1.E1.m1.8.8.5.3.cmml" xref="A1.E1.m1.8.8.5.3">𝑘</ci></apply></apply></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E1.m1.15c">\text{score}(x,y)=\text{margin}\left(\cos(x,y),\left(\sum_{z\in\text{NN}_{k}(x%
)}\frac{\cos(x,z)}{2k}+\sum_{z\in\text{NN}_{k}(y)}\frac{\cos(y,z)}{2k}\right)\right)</annotation><annotation encoding="application/x-llamapun" id="A1.E1.m1.15d">score ( italic_x , italic_y ) = margin ( roman_cos ( italic_x , italic_y ) , ( ∑ start_POSTSUBSCRIPT italic_z ∈ NN start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x ) end_POSTSUBSCRIPT divide start_ARG roman_cos ( italic_x , italic_z ) end_ARG start_ARG 2 italic_k end_ARG + ∑ start_POSTSUBSCRIPT italic_z ∈ NN start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_y ) end_POSTSUBSCRIPT divide start_ARG roman_cos ( italic_y , italic_z ) end_ARG start_ARG 2 italic_k end_ARG ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A1.SS2.p6">
<p class="ltx_p" id="A1.SS2.p6.9">where <math alttext="x" class="ltx_Math" display="inline" id="A1.SS2.p6.1.m1.1"><semantics id="A1.SS2.p6.1.m1.1a"><mi id="A1.SS2.p6.1.m1.1.1" xref="A1.SS2.p6.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.1.m1.1b"><ci id="A1.SS2.p6.1.m1.1.1.cmml" xref="A1.SS2.p6.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.1.m1.1d">italic_x</annotation></semantics></math> denotes the source, <math alttext="y" class="ltx_Math" display="inline" id="A1.SS2.p6.2.m2.1"><semantics id="A1.SS2.p6.2.m2.1a"><mi id="A1.SS2.p6.2.m2.1.1" xref="A1.SS2.p6.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.2.m2.1b"><ci id="A1.SS2.p6.2.m2.1.1.cmml" xref="A1.SS2.p6.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.2.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.2.m2.1d">italic_y</annotation></semantics></math> denotes the target sentence embeddings, and <math alttext="NN_{k}" class="ltx_Math" display="inline" id="A1.SS2.p6.3.m3.1"><semantics id="A1.SS2.p6.3.m3.1a"><mrow id="A1.SS2.p6.3.m3.1.1" xref="A1.SS2.p6.3.m3.1.1.cmml"><mi id="A1.SS2.p6.3.m3.1.1.2" xref="A1.SS2.p6.3.m3.1.1.2.cmml">N</mi><mo id="A1.SS2.p6.3.m3.1.1.1" xref="A1.SS2.p6.3.m3.1.1.1.cmml">⁢</mo><msub id="A1.SS2.p6.3.m3.1.1.3" xref="A1.SS2.p6.3.m3.1.1.3.cmml"><mi id="A1.SS2.p6.3.m3.1.1.3.2" xref="A1.SS2.p6.3.m3.1.1.3.2.cmml">N</mi><mi id="A1.SS2.p6.3.m3.1.1.3.3" xref="A1.SS2.p6.3.m3.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.3.m3.1b"><apply id="A1.SS2.p6.3.m3.1.1.cmml" xref="A1.SS2.p6.3.m3.1.1"><times id="A1.SS2.p6.3.m3.1.1.1.cmml" xref="A1.SS2.p6.3.m3.1.1.1"></times><ci id="A1.SS2.p6.3.m3.1.1.2.cmml" xref="A1.SS2.p6.3.m3.1.1.2">𝑁</ci><apply id="A1.SS2.p6.3.m3.1.1.3.cmml" xref="A1.SS2.p6.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.p6.3.m3.1.1.3.1.cmml" xref="A1.SS2.p6.3.m3.1.1.3">subscript</csymbol><ci id="A1.SS2.p6.3.m3.1.1.3.2.cmml" xref="A1.SS2.p6.3.m3.1.1.3.2">𝑁</ci><ci id="A1.SS2.p6.3.m3.1.1.3.3.cmml" xref="A1.SS2.p6.3.m3.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.3.m3.1c">NN_{k}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.3.m3.1d">italic_N italic_N start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> represents the <math alttext="k" class="ltx_Math" display="inline" id="A1.SS2.p6.4.m4.1"><semantics id="A1.SS2.p6.4.m4.1a"><mi id="A1.SS2.p6.4.m4.1.1" xref="A1.SS2.p6.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.4.m4.1b"><ci id="A1.SS2.p6.4.m4.1.1.cmml" xref="A1.SS2.p6.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.4.m4.1d">italic_k</annotation></semantics></math> nearest neighbors of <math alttext="x" class="ltx_Math" display="inline" id="A1.SS2.p6.5.m5.1"><semantics id="A1.SS2.p6.5.m5.1a"><mi id="A1.SS2.p6.5.m5.1.1" xref="A1.SS2.p6.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.5.m5.1b"><ci id="A1.SS2.p6.5.m5.1.1.cmml" xref="A1.SS2.p6.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.5.m5.1c">x</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.5.m5.1d">italic_x</annotation></semantics></math> in other languages. We chose to use the ratio margin function, which is defined as (<math alttext="\text{margin}(a,b)=\dfrac{a}{b}" class="ltx_Math" display="inline" id="A1.SS2.p6.6.m6.2"><semantics id="A1.SS2.p6.6.m6.2a"><mrow id="A1.SS2.p6.6.m6.2.3" xref="A1.SS2.p6.6.m6.2.3.cmml"><mrow id="A1.SS2.p6.6.m6.2.3.2" xref="A1.SS2.p6.6.m6.2.3.2.cmml"><mtext id="A1.SS2.p6.6.m6.2.3.2.2" xref="A1.SS2.p6.6.m6.2.3.2.2a.cmml">margin</mtext><mo id="A1.SS2.p6.6.m6.2.3.2.1" xref="A1.SS2.p6.6.m6.2.3.2.1.cmml">⁢</mo><mrow id="A1.SS2.p6.6.m6.2.3.2.3.2" xref="A1.SS2.p6.6.m6.2.3.2.3.1.cmml"><mo id="A1.SS2.p6.6.m6.2.3.2.3.2.1" stretchy="false" xref="A1.SS2.p6.6.m6.2.3.2.3.1.cmml">(</mo><mi id="A1.SS2.p6.6.m6.1.1" xref="A1.SS2.p6.6.m6.1.1.cmml">a</mi><mo id="A1.SS2.p6.6.m6.2.3.2.3.2.2" xref="A1.SS2.p6.6.m6.2.3.2.3.1.cmml">,</mo><mi id="A1.SS2.p6.6.m6.2.2" xref="A1.SS2.p6.6.m6.2.2.cmml">b</mi><mo id="A1.SS2.p6.6.m6.2.3.2.3.2.3" stretchy="false" xref="A1.SS2.p6.6.m6.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="A1.SS2.p6.6.m6.2.3.1" xref="A1.SS2.p6.6.m6.2.3.1.cmml">=</mo><mstyle displaystyle="true" id="A1.SS2.p6.6.m6.2.3.3" xref="A1.SS2.p6.6.m6.2.3.3.cmml"><mfrac id="A1.SS2.p6.6.m6.2.3.3a" xref="A1.SS2.p6.6.m6.2.3.3.cmml"><mi id="A1.SS2.p6.6.m6.2.3.3.2" xref="A1.SS2.p6.6.m6.2.3.3.2.cmml">a</mi><mi id="A1.SS2.p6.6.m6.2.3.3.3" xref="A1.SS2.p6.6.m6.2.3.3.3.cmml">b</mi></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.6.m6.2b"><apply id="A1.SS2.p6.6.m6.2.3.cmml" xref="A1.SS2.p6.6.m6.2.3"><eq id="A1.SS2.p6.6.m6.2.3.1.cmml" xref="A1.SS2.p6.6.m6.2.3.1"></eq><apply id="A1.SS2.p6.6.m6.2.3.2.cmml" xref="A1.SS2.p6.6.m6.2.3.2"><times id="A1.SS2.p6.6.m6.2.3.2.1.cmml" xref="A1.SS2.p6.6.m6.2.3.2.1"></times><ci id="A1.SS2.p6.6.m6.2.3.2.2a.cmml" xref="A1.SS2.p6.6.m6.2.3.2.2"><mtext id="A1.SS2.p6.6.m6.2.3.2.2.cmml" xref="A1.SS2.p6.6.m6.2.3.2.2">margin</mtext></ci><interval closure="open" id="A1.SS2.p6.6.m6.2.3.2.3.1.cmml" xref="A1.SS2.p6.6.m6.2.3.2.3.2"><ci id="A1.SS2.p6.6.m6.1.1.cmml" xref="A1.SS2.p6.6.m6.1.1">𝑎</ci><ci id="A1.SS2.p6.6.m6.2.2.cmml" xref="A1.SS2.p6.6.m6.2.2">𝑏</ci></interval></apply><apply id="A1.SS2.p6.6.m6.2.3.3.cmml" xref="A1.SS2.p6.6.m6.2.3.3"><divide id="A1.SS2.p6.6.m6.2.3.3.1.cmml" xref="A1.SS2.p6.6.m6.2.3.3"></divide><ci id="A1.SS2.p6.6.m6.2.3.3.2.cmml" xref="A1.SS2.p6.6.m6.2.3.3.2">𝑎</ci><ci id="A1.SS2.p6.6.m6.2.3.3.3.cmml" xref="A1.SS2.p6.6.m6.2.3.3.3">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.6.m6.2c">\text{margin}(a,b)=\dfrac{a}{b}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.6.m6.2d">margin ( italic_a , italic_b ) = divide start_ARG italic_a end_ARG start_ARG italic_b end_ARG</annotation></semantics></math>) and set <math alttext="k=3" class="ltx_Math" display="inline" id="A1.SS2.p6.7.m7.1"><semantics id="A1.SS2.p6.7.m7.1a"><mrow id="A1.SS2.p6.7.m7.1.1" xref="A1.SS2.p6.7.m7.1.1.cmml"><mi id="A1.SS2.p6.7.m7.1.1.2" xref="A1.SS2.p6.7.m7.1.1.2.cmml">k</mi><mo id="A1.SS2.p6.7.m7.1.1.1" xref="A1.SS2.p6.7.m7.1.1.1.cmml">=</mo><mn id="A1.SS2.p6.7.m7.1.1.3" xref="A1.SS2.p6.7.m7.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.7.m7.1b"><apply id="A1.SS2.p6.7.m7.1.1.cmml" xref="A1.SS2.p6.7.m7.1.1"><eq id="A1.SS2.p6.7.m7.1.1.1.cmml" xref="A1.SS2.p6.7.m7.1.1.1"></eq><ci id="A1.SS2.p6.7.m7.1.1.2.cmml" xref="A1.SS2.p6.7.m7.1.1.2">𝑘</ci><cn id="A1.SS2.p6.7.m7.1.1.3.cmml" type="integer" xref="A1.SS2.p6.7.m7.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.7.m7.1c">k=3</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.7.m7.1d">italic_k = 3</annotation></semantics></math>. Then, a threshold of <math alttext="1.09" class="ltx_Math" display="inline" id="A1.SS2.p6.8.m8.1"><semantics id="A1.SS2.p6.8.m8.1a"><mn id="A1.SS2.p6.8.m8.1.1" xref="A1.SS2.p6.8.m8.1.1.cmml">1.09</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.8.m8.1b"><cn id="A1.SS2.p6.8.m8.1.1.cmml" type="float" xref="A1.SS2.p6.8.m8.1.1">1.09</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.8.m8.1c">1.09</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.8.m8.1d">1.09</annotation></semantics></math> was chosen, a slightly higher threshold than NLLB’s <math alttext="1.06" class="ltx_Math" display="inline" id="A1.SS2.p6.9.m9.1"><semantics id="A1.SS2.p6.9.m9.1a"><mn id="A1.SS2.p6.9.m9.1.1" xref="A1.SS2.p6.9.m9.1.1.cmml">1.06</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p6.9.m9.1b"><cn id="A1.SS2.p6.9.m9.1.1.cmml" type="float" xref="A1.SS2.p6.9.m9.1.1">1.06</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p6.9.m9.1c">1.06</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p6.9.m9.1d">1.06</annotation></semantics></math>, since we only want to select high-quality sentence pairs. Bitext with scores lower than this threshold value is filtered out.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">NeurIPS Paper Checklist</h2>
<div class="ltx_para" id="Ax1.p1">
<ol class="ltx_enumerate" id="Ax1.I1">
<li class="ltx_item" id="Ax1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="Ax1.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i1.p1.1.1">Claims</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix1.p1">
<p class="ltx_p" id="Ax1.I1.ix1.p1.1">Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix2.p1">
<p class="ltx_p" id="Ax1.I1.ix2.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix2.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix3.p1">
<p class="ltx_p" id="Ax1.I1.ix3.p1.1">Justification: The abstract and introduction accurately reflect the paper’s contributions, detailing the development of NusaMT-7B for low-resource languages, including specific methods like monolingual pre-training, supervised fine-tuning, and data cleaning, which are all validated by the results presented. The abstract also highlights how the methods can be applied to other languages and datasets.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix4.p1">
<p class="ltx_p" id="Ax1.I1.ix4.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix4.I1">
<li class="ltx_item" id="Ax1.I1.ix4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix4.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix4.I1.i1.p1.1">The answer NA means that the abstract and introduction do not include the claims made in the paper.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix4.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix4.I1.i2.p1.1">The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix4.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix4.I1.i3.p1.1">The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix4.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix4.I1.i4.p1.1">It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="Ax1.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i2.p1.1.1">Limitations</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix5.p1">
<p class="ltx_p" id="Ax1.I1.ix5.p1.1">Question: Does the paper discuss the limitations of the work performed by the authors?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix6.p1">
<p class="ltx_p" id="Ax1.I1.ix6.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix6.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix7.p1">
<p class="ltx_p" id="Ax1.I1.ix7.p1.1">Justification: The paper discusses limitations such as the lack of resources for monolingual pre-training, not evaluating more advanced models, and constraints in assessing the optimal size of monolingual data with Komodo-7B-base. Additionally, it reflects on the scope of the claims, referring to the language directions and metrics used, and notes on the model’s computational efficiency in comparison to NMT models.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix8.p1">
<p class="ltx_p" id="Ax1.I1.ix8.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix8.I1">
<li class="ltx_item" id="Ax1.I1.ix8.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i1.p1.1">The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i2.p1.1">The authors are encouraged to create a separate "Limitations" section in their paper.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i3.p1.1">The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i4.p1.1">The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i5.p1.1">The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i6.p1.1">The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i7.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i7.p1.1">If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix8.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix8.I1.i8.p1">
<p class="ltx_p" id="Ax1.I1.ix8.I1.i8.p1.1">While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren’t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="Ax1.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i3.p1.1.1">Theory Assumptions and Proofs</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix9.p1">
<p class="ltx_p" id="Ax1.I1.ix9.p1.1">Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix10.p1">
<p class="ltx_p" id="Ax1.I1.ix10.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix10.p1.1.1" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix11.p1">
<p class="ltx_p" id="Ax1.I1.ix11.p1.1">Justification: The paper is empirical in nature and does not propose new theoretical results or proofs, focusing instead on practical implementation and evaluation of machine translation methods.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix12" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix12.p1">
<p class="ltx_p" id="Ax1.I1.ix12.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix12.I1">
<li class="ltx_item" id="Ax1.I1.ix12.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix12.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix12.I1.i1.p1.1">The answer NA means that the paper does not include theoretical results.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix12.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix12.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix12.I1.i2.p1.1">All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix12.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix12.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix12.I1.i3.p1.1">All assumptions should be clearly stated or referenced in the statement of any theorems.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix12.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix12.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix12.I1.i4.p1.1">The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix12.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix12.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix12.I1.i5.p1.1">Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix12.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix12.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.ix12.I1.i6.p1.1">Theorems and Lemmas that the proof relies upon should be properly referenced.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="Ax1.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i4.p1.1.1">Experimental Result Reproducibility</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix13" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix13.p1">
<p class="ltx_p" id="Ax1.I1.ix13.p1.1">Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix14" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix14.p1">
<p class="ltx_p" id="Ax1.I1.ix14.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix14.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix15" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix15.p1">
<p class="ltx_p" id="Ax1.I1.ix15.p1.1">Justification: The paper provides detailed descriptions of the datasets, training setup, and we release our model and datasets used, making it feasible for others to reproduce the experimental results.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix16.p1">
<p class="ltx_p" id="Ax1.I1.ix16.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix16.I1">
<li class="ltx_item" id="Ax1.I1.ix16.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i1.p1.1">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i2.p1.1">If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i3.p1.1">If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i4.p1.1">Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i5.p1.1">While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example</p>
<ol class="ltx_enumerate" id="Ax1.I1.ix16.I1.i5.I1">
<li class="ltx_item" id="Ax1.I1.ix16.I1.i5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i5.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i5.I1.i1.p1.1">If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i5.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i5.I1.i2.p1.1">If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i5.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i5.I1.i3.p1.1">If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix16.I1.i5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span>
<div class="ltx_para" id="Ax1.I1.ix16.I1.i5.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix16.I1.i5.I1.i4.p1.1">We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.</p>
</div>
</li>
</ol>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="Ax1.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i5.p1.1.1">Open access to data and code</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix17" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix17.p1">
<p class="ltx_p" id="Ax1.I1.ix17.p1.1">Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix18" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix18.p1">
<p class="ltx_p" id="Ax1.I1.ix18.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix18.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix19" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix19.p1">
<p class="ltx_p" id="Ax1.I1.ix19.p1.1">Justification: We release the code for model training on github with specific instructions for the environment and training setup. The data sources are outlined clearly and the compiled parallel sentence dataset is released through huggingface.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix20.p1">
<p class="ltx_p" id="Ax1.I1.ix20.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix20.I1">
<li class="ltx_item" id="Ax1.I1.ix20.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i1.p1.1">The answer NA means that paper does not include experiments requiring code.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i2.p1.1">Please see the NeurIPS code and data submission guidelines (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://nips.cc/public/guides/CodeSubmissionPolicy" title="">https://nips.cc/public/guides/CodeSubmissionPolicy</a>) for more details.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i3.p1.1">While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i4.p1.1">The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://nips.cc/public/guides/CodeSubmissionPolicy" title="">https://nips.cc/public/guides/CodeSubmissionPolicy</a>) for more details.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i5.p1.1">The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i6.p1.1">The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i7.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i7.p1.1">At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix20.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix20.I1.i8.p1">
<p class="ltx_p" id="Ax1.I1.ix20.I1.i8.p1.1">Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="Ax1.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i6.p1.1.1">Experimental Setting/Details</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix21" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix21.p1">
<p class="ltx_p" id="Ax1.I1.ix21.p1.1">Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix22" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix22.p1">
<p class="ltx_p" id="Ax1.I1.ix22.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix22.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix23" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix23.p1">
<p class="ltx_p" id="Ax1.I1.ix23.p1.1">Justification: All critical experimental details, such as the data splits, specific hyperparameters (learning rates, batch sizes, lora rank), and loss functions are thoroughly documented.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix24" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix24.p1">
<p class="ltx_p" id="Ax1.I1.ix24.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix24.I1">
<li class="ltx_item" id="Ax1.I1.ix24.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix24.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix24.I1.i1.p1.1">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix24.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix24.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix24.I1.i2.p1.1">The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix24.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix24.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix24.I1.i3.p1.1">The full details can be provided either with the code, in appendix, or as supplemental material.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span>
<div class="ltx_para" id="Ax1.I1.i7.p1">
<p class="ltx_p" id="Ax1.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i7.p1.1.1">Experiment Statistical Significance</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix25" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix25.p1">
<p class="ltx_p" id="Ax1.I1.ix25.p1.1">Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix26" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix26.p1">
<p class="ltx_p" id="Ax1.I1.ix26.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix26.p1.1.1" style="color:#FF8000;">[No] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix27" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix27.p1">
<p class="ltx_p" id="Ax1.I1.ix27.p1.1">Justification: The paper does not provide statistical significance measures like error bars or confidence intervals.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix28.p1">
<p class="ltx_p" id="Ax1.I1.ix28.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix28.I1">
<li class="ltx_item" id="Ax1.I1.ix28.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i1.p1.1">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i2.p1.1">The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i3.p1.1">The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i4.p1.1">The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i5.p1.1">The assumptions made should be given (e.g., Normally distributed errors).</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i6.p1.1">It should be clear whether the error bar is the standard deviation or the standard error of the mean.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i7.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i7.p1.1">It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i8.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i8.p1.1">For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix28.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix28.I1.i9.p1">
<p class="ltx_p" id="Ax1.I1.ix28.I1.i9.p1.1">If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">8.</span>
<div class="ltx_para" id="Ax1.I1.i8.p1">
<p class="ltx_p" id="Ax1.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i8.p1.1.1">Experiments Compute Resources</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix29" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix29.p1">
<p class="ltx_p" id="Ax1.I1.ix29.p1.1">Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix30" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix30.p1">
<p class="ltx_p" id="Ax1.I1.ix30.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix30.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix31" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix31.p1">
<p class="ltx_p" id="Ax1.I1.ix31.p1.1">Justification: The paper specifies the use of two Nvidia RTX 4090 GPUs and provides estimates of training duration, giving a clear picture of the computational resources required for the experiments.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix32" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix32.p1">
<p class="ltx_p" id="Ax1.I1.ix32.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix32.I1">
<li class="ltx_item" id="Ax1.I1.ix32.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix32.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix32.I1.i1.p1.1">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix32.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix32.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix32.I1.i2.p1.1">The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix32.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix32.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix32.I1.i3.p1.1">The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix32.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix32.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix32.I1.i4.p1.1">The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it into the paper).</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">9.</span>
<div class="ltx_para" id="Ax1.I1.i9.p1">
<p class="ltx_p" id="Ax1.I1.i9.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i9.p1.1.1">Code Of Ethics</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix33" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix33.p1">
<p class="ltx_p" id="Ax1.I1.ix33.p1.1">Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://neurips.cc/public/EthicsGuidelines" title="">https://neurips.cc/public/EthicsGuidelines</a>?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix34" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix34.p1">
<p class="ltx_p" id="Ax1.I1.ix34.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix34.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix35" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix35.p1">
<p class="ltx_p" id="Ax1.I1.ix35.p1.1">Justification: The research complies with the NeurIPS Code of Ethics by ensuring responsible use of data, addressing potential biases, and emphasizing the model’s intended use for language preservation without harmful applications.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix36" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix36.p1">
<p class="ltx_p" id="Ax1.I1.ix36.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix36.I1">
<li class="ltx_item" id="Ax1.I1.ix36.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix36.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix36.I1.i1.p1.1">The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix36.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix36.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix36.I1.i2.p1.1">If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix36.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix36.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix36.I1.i3.p1.1">The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">10.</span>
<div class="ltx_para" id="Ax1.I1.i10.p1">
<p class="ltx_p" id="Ax1.I1.i10.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i10.p1.1.1">Broader Impacts</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix37" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix37.p1">
<p class="ltx_p" id="Ax1.I1.ix37.p1.1">Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix38" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix38.p1">
<p class="ltx_p" id="Ax1.I1.ix38.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix38.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix39" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix39.p1">
<p class="ltx_p" id="Ax1.I1.ix39.p1.1">Justification: The paper briefly discusses the positive impact on language preservation and cross-cultural communication. However, since this paper focuses on foundational research, a large emphasis is not tied to particular applications.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix40" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix40.p1">
<p class="ltx_p" id="Ax1.I1.ix40.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix40.I1">
<li class="ltx_item" id="Ax1.I1.ix40.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix40.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix40.I1.i1.p1.1">The answer NA means that there is no societal impact of the work performed.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix40.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix40.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix40.I1.i2.p1.1">If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix40.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix40.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix40.I1.i3.p1.1">Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix40.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix40.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix40.I1.i4.p1.1">The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix40.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix40.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix40.I1.i5.p1.1">The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix40.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix40.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.ix40.I1.i6.p1.1">If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">11.</span>
<div class="ltx_para" id="Ax1.I1.i11.p1">
<p class="ltx_p" id="Ax1.I1.i11.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i11.p1.1.1">Safeguards</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix41" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix41.p1">
<p class="ltx_p" id="Ax1.I1.ix41.p1.1">Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix42" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix42.p1">
<p class="ltx_p" id="Ax1.I1.ix42.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix42.p1.1.1" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix43" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix43.p1">
<p class="ltx_p" id="Ax1.I1.ix43.p1.1">Justification: The paper does not release assets that pose high risks for misuse, and therefore, the need for specific safeguards is not applicable.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix44" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix44.p1">
<p class="ltx_p" id="Ax1.I1.ix44.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix44.I1">
<li class="ltx_item" id="Ax1.I1.ix44.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix44.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix44.I1.i1.p1.1">The answer NA means that the paper poses no such risks.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix44.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix44.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix44.I1.i2.p1.1">Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix44.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix44.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix44.I1.i3.p1.1">Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix44.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix44.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix44.I1.i4.p1.1">We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i12" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">12.</span>
<div class="ltx_para" id="Ax1.I1.i12.p1">
<p class="ltx_p" id="Ax1.I1.i12.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i12.p1.1.1">Licenses for existing assets</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix45" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix45.p1">
<p class="ltx_p" id="Ax1.I1.ix45.p1.1">Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix46" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix46.p1">
<p class="ltx_p" id="Ax1.I1.ix46.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix46.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix47" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix47.p1">
<p class="ltx_p" id="Ax1.I1.ix47.p1.1">Justification: The paper appropriately credits existing datasets and models, mentioning the sources and licenses where applicable, ensuring proper use and acknowledgment of all assets.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix48.p1">
<p class="ltx_p" id="Ax1.I1.ix48.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix48.I1">
<li class="ltx_item" id="Ax1.I1.ix48.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i1.p1.1">The answer NA means that the paper does not use existing assets.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i2.p1.1">The authors should cite the original paper that produced the code package or dataset.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i3.p1.1">The authors should state which version of the asset is used and, if possible, include a URL.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i4.p1.1">The name of the license (e.g., CC-BY 4.0) should be included for each asset.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i5.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i5.p1.1">For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i6.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i6.p1.1">If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, <a class="ltx_ref ltx_url ltx_font_typewriter" href="paperswithcode.com/datasets" title="">paperswithcode.com/datasets</a> has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i7.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i7.p1.1">For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix48.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix48.I1.i8.p1">
<p class="ltx_p" id="Ax1.I1.ix48.I1.i8.p1.1">If this information is not available online, the authors are encouraged to reach out to the asset’s creators.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i13" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">13.</span>
<div class="ltx_para" id="Ax1.I1.i13.p1">
<p class="ltx_p" id="Ax1.I1.i13.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i13.p1.1.1">New Assets</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix49" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix49.p1">
<p class="ltx_p" id="Ax1.I1.ix49.p1.1">Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix50" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix50.p1">
<p class="ltx_p" id="Ax1.I1.ix50.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix50.p1.1.1" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix51" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix51.p1">
<p class="ltx_p" id="Ax1.I1.ix51.p1.1">Justification: We release our model and compiled dataset through huggingface and included details such as training and dataset sources in the README. The code also provides simple documentation regarding the methods to run the training and validation scripts.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix52" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix52.p1">
<p class="ltx_p" id="Ax1.I1.ix52.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix52.I1">
<li class="ltx_item" id="Ax1.I1.ix52.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix52.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix52.I1.i1.p1.1">The answer NA means that the paper does not release new assets.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix52.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix52.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix52.I1.i2.p1.1">Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix52.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix52.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix52.I1.i3.p1.1">The paper should discuss whether and how consent was obtained from people whose asset is used.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix52.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix52.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix52.I1.i4.p1.1">At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i14" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">14.</span>
<div class="ltx_para" id="Ax1.I1.i14.p1">
<p class="ltx_p" id="Ax1.I1.i14.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i14.p1.1.1">Crowdsourcing and Research with Human Subjects</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix53" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix53.p1">
<p class="ltx_p" id="Ax1.I1.ix53.p1.1">Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix54" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix54.p1">
<p class="ltx_p" id="Ax1.I1.ix54.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix54.p1.1.1" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix55" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix55.p1">
<p class="ltx_p" id="Ax1.I1.ix55.p1.1">Justification: The paper does not involve crowdsourcing or human subjects, so this consideration does not apply.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix56" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix56.p1">
<p class="ltx_p" id="Ax1.I1.ix56.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix56.I1">
<li class="ltx_item" id="Ax1.I1.ix56.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix56.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix56.I1.i1.p1.1">The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix56.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix56.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix56.I1.i2.p1.1">Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix56.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix56.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix56.I1.i3.p1.1">According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i15" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">15.</span>
<div class="ltx_para" id="Ax1.I1.i15.p1">
<p class="ltx_p" id="Ax1.I1.i15.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i15.p1.1.1">Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects</span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix57" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix57.p1">
<p class="ltx_p" id="Ax1.I1.ix57.p1.1">Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix58" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix58.p1">
<p class="ltx_p" id="Ax1.I1.ix58.p1.1">Answer: <span class="ltx_text" id="Ax1.I1.ix58.p1.1.1" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix59" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix59.p1">
<p class="ltx_p" id="Ax1.I1.ix59.p1.1">Justification: The research does not involve human subjects or require IRB approval.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix60" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="Ax1.I1.ix60.p1">
<p class="ltx_p" id="Ax1.I1.ix60.p1.1">Guidelines:</p>
<ul class="ltx_itemize" id="Ax1.I1.ix60.I1">
<li class="ltx_item" id="Ax1.I1.ix60.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix60.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.ix60.I1.i1.p1.1">The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix60.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix60.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.ix60.I1.i2.p1.1">Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix60.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix60.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.ix60.I1.i3.p1.1">We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.ix60.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ax1.I1.ix60.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.ix60.I1.i4.p1.1">For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.</p>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct 10 11:32:23 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
