<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.07855] MSMF: Multi-Scale Multi-Modal Fusion for Enhanced Stock Market Prediction</title><meta property="og:description" content="This paper presents MSMF (Multi-Scale Multi-Modal Fusion), a novel approach for enhanced stock market prediction. MSMF addresses key challenges in multi-modal stock analysis by integrating a modality completion encoderâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MSMF: Multi-Scale Multi-Modal Fusion for Enhanced Stock Market Prediction">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MSMF: Multi-Scale Multi-Modal Fusion for Enhanced Stock Market Prediction">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.07855">

<!--Generated on Sat Oct  5 18:32:41 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">MSMF: Multi-Scale Multi-Modal Fusion for Enhanced Stock Market Prediction</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiahao Qin
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">This paper presents MSMF (Multi-Scale Multi-Modal Fusion), a novel approach for enhanced stock market prediction. MSMF addresses key challenges in multi-modal stock analysis by integrating a modality completion encoder, multi-scale feature extraction, and an innovative fusion mechanism. Our model leverages blank learning and progressive fusion to balance complementarity and redundancy across modalities, while multi-scale alignment facilitates direct correlations between heterogeneous data types. We introduce Multi-Granularity Gates and a specialized architecture to optimize the integration of local and global information for different tasks. Additionally, a Task-targeted Prediction layer is employed to preserve both coarse and fine-grained features during fusion. Experimental results demonstrate that MSMF outperforms existing methods, achieving significant improvements in accuracy and reducing prediction errors across various stock market forecasting tasks. This research contributes valuable insights to the field of multi-modal financial analysis and offers a robust framework for enhanced market prediction.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Multi-grained learning, Blank learning, Modality Completion learning.

</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journal: </span>Nuclear Physics B</span></span></span>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\affiliation</span>
<p id="p1.2" class="ltx_p">organization=jiahao.qin19@gmail.com,
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Predicting stock market behavior has long fascinated investors and researchers alike. The potential for significant profits has driven numerous studies aimed at improving predictability and efficiency. Previous research has shown that stock price fluctuations are influenced by various information sources, including trading data, news reports, social media activities, and online search patterns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.
Recent advancements in deep learning and natural language processing have opened new avenues for stock market prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. The integration of multiple data modalities has become increasingly important, with approaches such as dynamic residual deep learning and iterative global-local fusion showing promise in addressing challenges like missing data and heterogeneity between different data modalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
However, several challenges persist in multi-modal stock price prediction:</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Heterogeneity in sampling time between different modalities, with fundamental data sampled regularly and news information sampled irregularly <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
Balancing global and local information in prediction models, considering both overall market trends and specific stock fluctuations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
Effectively integrating information from multiple modalities while managing redundancy and potential conflicts.
Enabling encoders to understand and fuse information across modalities with different feature structures and properties.
Addressing the varying proportions of local and global information within the same modality for different tasks, and determining appropriate weightings for each modality across tasks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Our research makes the following key contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix1.1.1.m1.1b"><mo id="S1.I1.ix1.1.1.m1.1.1" xref="S1.I1.ix1.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix1.1.1.m1.1c"><ci id="S1.I1.ix1.1.1.m1.1.1.cmml" xref="S1.I1.ix1.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p">A modality completion encoder to handle sampling time heterogeneity.</p>
</div>
</li>
<li id="S1.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix2.1.1.m1.1b"><mo id="S1.I1.ix2.1.1.m1.1.1" xref="S1.I1.ix2.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix2.1.1.m1.1c"><ci id="S1.I1.ix2.1.1.m1.1.1.cmml" xref="S1.I1.ix2.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix2.p1" class="ltx_para">
<p id="S1.I1.ix2.p1.1" class="ltx_p">A multi-scale encoder combining coarse-to-fine cascading and multi-scale fusion.</p>
</div>
</li>
<li id="S1.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix3.1.1.m1.1b"><mo id="S1.I1.ix3.1.1.m1.1.1" xref="S1.I1.ix3.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix3.1.1.m1.1c"><ci id="S1.I1.ix3.1.1.m1.1.1.cmml" xref="S1.I1.ix3.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix3.p1" class="ltx_para">
<p id="S1.I1.ix3.p1.1" class="ltx_p">Blank learning and progressive fusion concepts to balance complementarity and redundancy between modalities.</p>
</div>
</li>
<li id="S1.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix4.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix4.1.1.m1.1b"><mo id="S1.I1.ix4.1.1.m1.1.1" xref="S1.I1.ix4.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix4.1.1.m1.1c"><ci id="S1.I1.ix4.1.1.m1.1.1.cmml" xref="S1.I1.ix4.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix4.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix4.p1" class="ltx_para">
<p id="S1.I1.ix4.p1.1" class="ltx_p">Multi-scale alignment to establish correlations between data types with different structures.</p>
</div>
</li>
<li id="S1.I1.ix5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix5.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix5.1.1.m1.1b"><mo id="S1.I1.ix5.1.1.m1.1.1" xref="S1.I1.ix5.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix5.1.1.m1.1c"><ci id="S1.I1.ix5.1.1.m1.1.1.cmml" xref="S1.I1.ix5.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix5.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix5.p1" class="ltx_para">
<p id="S1.I1.ix5.p1.1" class="ltx_p">Multi-Granularity Gates and MTS architecture to address varying proportions of local and global information across tasks.</p>
</div>
</li>
<li id="S1.I1.ix6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix6.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix6.1.1.m1.1b"><mo id="S1.I1.ix6.1.1.m1.1.1" xref="S1.I1.ix6.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix6.1.1.m1.1c"><ci id="S1.I1.ix6.1.1.m1.1.1.cmml" xref="S1.I1.ix6.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix6.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix6.p1" class="ltx_para">
<p id="S1.I1.ix6.p1.1" class="ltx_p">A Task-targeted Prediction layer to preserve coarse-grained and fine-grained features during fusion.</p>
</div>
</li>
</ul>
<p id="S1.p3.2" class="ltx_p">These contributions aim to advance the field of multi-modal stock prediction by addressing key challenges and providing novel solutions for more accurate and robust forecasting.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Deep learning has shown remarkable potential in capturing media-aware stock movements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Recent studies have explored various techniques, including event-driven LSTM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, multi-module feature fusion methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and knowledge graph-based approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. These methods aim to integrate diverse information sources and capture complex market dynamics.
Multi-task learning (MTL) has been effectively applied in stock prediction, showing promise in capturing both individual stock characteristics and inter-stock correlations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Recent advancements include the development of numeric-oriented hierarchical transformer models and federated multi-task stock predictors.
To capture both long-term and short-term patterns, researchers have developed various multi-scale feature extraction techniques. These include the use of Inception modules <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, combinations of CNN and RNN architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, and multi-granularity hierarchical networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. These innovations enhance modelsâ€™ ability to capture temporal dynamics at different scales.
These advancements in stock market prediction, multi-task learning, and multi-scale feature extraction provide a solid foundation for our research, informing the development of more sophisticated and effective prediction models.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our MSMF (Multi-Scale Multi-Modal Fusion) approach integrates multi-task learning with advanced modal fusion techniques for stock prediction. The model architecture is illustrated in Figure <a href="#S3.F1" title="Figure 1 â€£ 3 Methodology â€£ MSMF: Multi-Scale Multi-Modal Fusion for Enhanced Stock Market Prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2409.07855/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="377" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the MSMF architecture.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Modality Completion</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.4" class="ltx_p">To address modality heterogeneity, we employ a Restricted Boltzmann Machine (RBM) based completion module. The joint distribution of modalities is modeled as:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E1.m1.6" class="ltx_Math" alttext="P(v_{i},v_{t},v_{n}|\theta)=\frac{1}{Z(\theta)}\exp(-E(v_{i},v_{t},v_{n},h|\theta))" display="block"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mrow id="S3.E1.m1.5.5.3" xref="S3.E1.m1.5.5.3.cmml"><mi id="S3.E1.m1.5.5.3.5" xref="S3.E1.m1.5.5.3.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.3.4" xref="S3.E1.m1.5.5.3.4.cmml">â€‹</mo><mrow id="S3.E1.m1.5.5.3.3.3" xref="S3.E1.m1.5.5.3.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.3.3.3.4" xref="S3.E1.m1.5.5.3.3.4.cmml">(</mo><msub id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml">v</mi><mi id="S3.E1.m1.3.3.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.5.5.3.3.3.5" xref="S3.E1.m1.5.5.3.3.4.cmml">,</mo><msub id="S3.E1.m1.4.4.2.2.2.2" xref="S3.E1.m1.4.4.2.2.2.2.cmml"><mi id="S3.E1.m1.4.4.2.2.2.2.2" xref="S3.E1.m1.4.4.2.2.2.2.2.cmml">v</mi><mi id="S3.E1.m1.4.4.2.2.2.2.3" xref="S3.E1.m1.4.4.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.5.5.3.3.3.6" xref="S3.E1.m1.5.5.3.3.4.cmml">,</mo><mrow id="S3.E1.m1.5.5.3.3.3.3" xref="S3.E1.m1.5.5.3.3.3.3.cmml"><msub id="S3.E1.m1.5.5.3.3.3.3.2" xref="S3.E1.m1.5.5.3.3.3.3.2.cmml"><mi id="S3.E1.m1.5.5.3.3.3.3.2.2" xref="S3.E1.m1.5.5.3.3.3.3.2.2.cmml">v</mi><mi id="S3.E1.m1.5.5.3.3.3.3.2.3" xref="S3.E1.m1.5.5.3.3.3.3.2.3.cmml">n</mi></msub><mo fence="false" id="S3.E1.m1.5.5.3.3.3.3.1" xref="S3.E1.m1.5.5.3.3.3.3.1.cmml">|</mo><mi id="S3.E1.m1.5.5.3.3.3.3.3" xref="S3.E1.m1.5.5.3.3.3.3.3.cmml">Î¸</mi></mrow><mo stretchy="false" id="S3.E1.m1.5.5.3.3.3.7" xref="S3.E1.m1.5.5.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.5" xref="S3.E1.m1.6.6.5.cmml">=</mo><mrow id="S3.E1.m1.6.6.4" xref="S3.E1.m1.6.6.4.cmml"><mfrac id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mn id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">1</mn><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">Z</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.4.2.1" xref="S3.E1.m1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">Î¸</mi><mo stretchy="false" id="S3.E1.m1.1.1.1.4.2.2" xref="S3.E1.m1.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo lspace="0.167em" rspace="0em" id="S3.E1.m1.6.6.4.2" xref="S3.E1.m1.6.6.4.2.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.4.1.1" xref="S3.E1.m1.6.6.4.1.2.cmml"><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">exp</mi><mo id="S3.E1.m1.6.6.4.1.1a" xref="S3.E1.m1.6.6.4.1.2.cmml">â¡</mo><mrow id="S3.E1.m1.6.6.4.1.1.1" xref="S3.E1.m1.6.6.4.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.4.1.1.1.2" xref="S3.E1.m1.6.6.4.1.2.cmml">(</mo><mrow id="S3.E1.m1.6.6.4.1.1.1.1" xref="S3.E1.m1.6.6.4.1.1.1.1.cmml"><mo id="S3.E1.m1.6.6.4.1.1.1.1a" xref="S3.E1.m1.6.6.4.1.1.1.1.cmml">âˆ’</mo><mrow id="S3.E1.m1.6.6.4.1.1.1.1.4" xref="S3.E1.m1.6.6.4.1.1.1.1.4.cmml"><mi id="S3.E1.m1.6.6.4.1.1.1.1.4.6" xref="S3.E1.m1.6.6.4.1.1.1.1.4.6.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.4.1.1.1.1.4.5" xref="S3.E1.m1.6.6.4.1.1.1.1.4.5.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.5" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml">(</mo><msub id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.6" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml">,</mo><msub id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.2.cmml">v</mi><mi id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.7" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml">,</mo><msub id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.2" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.2.cmml">v</mi><mi id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.3" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.3.cmml">n</mi></msub><mo id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.8" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml">,</mo><mrow id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.cmml"><mi id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.2" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.2.cmml">h</mi><mo fence="false" id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.1" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.1.cmml">|</mo><mi id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.3" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.3.cmml">Î¸</mi></mrow><mo stretchy="false" id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.9" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E1.m1.6.6.4.1.1.1.3" xref="S3.E1.m1.6.6.4.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.5.cmml" xref="S3.E1.m1.6.6.5"></eq><apply id="S3.E1.m1.5.5.3.cmml" xref="S3.E1.m1.5.5.3"><times id="S3.E1.m1.5.5.3.4.cmml" xref="S3.E1.m1.5.5.3.4"></times><ci id="S3.E1.m1.5.5.3.5.cmml" xref="S3.E1.m1.5.5.3.5">ğ‘ƒ</ci><vector id="S3.E1.m1.5.5.3.3.4.cmml" xref="S3.E1.m1.5.5.3.3.3"><apply id="S3.E1.m1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2">ğ‘£</ci><ci id="S3.E1.m1.3.3.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.4.4.2.2.2.2.cmml" xref="S3.E1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.4.4.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.2.2.2.2.2">ğ‘£</ci><ci id="S3.E1.m1.4.4.2.2.2.2.3.cmml" xref="S3.E1.m1.4.4.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.5.5.3.3.3.3.cmml" xref="S3.E1.m1.5.5.3.3.3.3"><csymbol cd="latexml" id="S3.E1.m1.5.5.3.3.3.3.1.cmml" xref="S3.E1.m1.5.5.3.3.3.3.1">conditional</csymbol><apply id="S3.E1.m1.5.5.3.3.3.3.2.cmml" xref="S3.E1.m1.5.5.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.3.3.3.3.2.1.cmml" xref="S3.E1.m1.5.5.3.3.3.3.2">subscript</csymbol><ci id="S3.E1.m1.5.5.3.3.3.3.2.2.cmml" xref="S3.E1.m1.5.5.3.3.3.3.2.2">ğ‘£</ci><ci id="S3.E1.m1.5.5.3.3.3.3.2.3.cmml" xref="S3.E1.m1.5.5.3.3.3.3.2.3">ğ‘›</ci></apply><ci id="S3.E1.m1.5.5.3.3.3.3.3.cmml" xref="S3.E1.m1.5.5.3.3.3.3.3">ğœƒ</ci></apply></vector></apply><apply id="S3.E1.m1.6.6.4.cmml" xref="S3.E1.m1.6.6.4"><times id="S3.E1.m1.6.6.4.2.cmml" xref="S3.E1.m1.6.6.4.2"></times><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><cn type="integer" id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">1</cn><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğœƒ</ci></apply></apply><apply id="S3.E1.m1.6.6.4.1.2.cmml" xref="S3.E1.m1.6.6.4.1.1"><exp id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"></exp><apply id="S3.E1.m1.6.6.4.1.1.1.1.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1"><minus id="S3.E1.m1.6.6.4.1.1.1.1.5.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1"></minus><apply id="S3.E1.m1.6.6.4.1.1.1.1.4.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4"><times id="S3.E1.m1.6.6.4.1.1.1.1.4.5.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.5"></times><ci id="S3.E1.m1.6.6.4.1.1.1.1.4.6.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.6">ğ¸</ci><vector id="S3.E1.m1.6.6.4.1.1.1.1.4.4.5.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4"><apply id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.2">ğ‘£</ci><ci id="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.2">ğ‘£</ci><ci id="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.3.3.3.3.3">ğ‘›</ci></apply><apply id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4"><csymbol cd="latexml" id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.1.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.1">conditional</csymbol><ci id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.2.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.2">â„</ci><ci id="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.3.cmml" xref="S3.E1.m1.6.6.4.1.1.1.1.4.4.4.4.3">ğœƒ</ci></apply></vector></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">P(v_{i},v_{t},v_{n}|\theta)=\frac{1}{Z(\theta)}\exp(-E(v_{i},v_{t},v_{n},h|\theta))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.3" class="ltx_p">where <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">E</annotation></semantics></math> is the energy function, <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="Z(\theta)" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.2.2" xref="S3.SS1.p1.2.m2.1.2.2.cmml">Z</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.1.2.1" xref="S3.SS1.p1.2.m2.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p1.2.m2.1.2.3.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.1.2.3.2.1" xref="S3.SS1.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">Î¸</mi><mo stretchy="false" id="S3.SS1.p1.2.m2.1.2.3.2.2" xref="S3.SS1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.2.cmml" xref="S3.SS1.p1.2.m2.1.2"><times id="S3.SS1.p1.2.m2.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.2.1"></times><ci id="S3.SS1.p1.2.m2.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.2.2">ğ‘</ci><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">Z(\theta)</annotation></semantics></math> is the partition function, and <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">h</annotation></semantics></math> represents hidden units.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multi-grained Input Processing</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">We employ multi-scale encoders for each modality:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E2.m1.2" class="ltx_Math" alttext="F_{m}=\mathcal{F}\text{fine}(X_{m})\oplus\mathcal{F}\text{coarse}(X_{m})" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><msub id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml"><mi id="S3.E2.m1.2.2.4.2" xref="S3.E2.m1.2.2.4.2.cmml">F</mi><mi id="S3.E2.m1.2.2.4.3" xref="S3.E2.m1.2.2.4.3.cmml">m</mi></msub><mo id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml">=</mo><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">â„±</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">â€‹</mo><mtext id="S3.E2.m1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.4a.cmml">fine</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2a" xref="S3.E2.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">âŠ•</mo><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">â„±</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.cmml">â€‹</mo><mtext id="S3.E2.m1.2.2.2.2.4" xref="S3.E2.m1.2.2.2.2.4a.cmml">coarse</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2a" xref="S3.E2.m1.2.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E2.m1.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.1.2.cmml">X</mi><mi id="S3.E2.m1.2.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S3.E2.m1.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"></eq><apply id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.4.2">ğ¹</ci><ci id="S3.E2.m1.2.2.4.3.cmml" xref="S3.E2.m1.2.2.4.3">ğ‘š</ci></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><csymbol cd="latexml" id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3">direct-sum</csymbol><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3">â„±</ci><ci id="S3.E2.m1.1.1.1.1.4a.cmml" xref="S3.E2.m1.1.1.1.1.4"><mtext id="S3.E2.m1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.4">fine</mtext></ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">ğ‘‹</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">ğ‘š</ci></apply></apply><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><times id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2"></times><ci id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3">â„±</ci><ci id="S3.E2.m1.2.2.2.2.4a.cmml" xref="S3.E2.m1.2.2.2.2.4"><mtext id="S3.E2.m1.2.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.2.4">coarse</mtext></ci><apply id="S3.E2.m1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.2">ğ‘‹</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.3">ğ‘š</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">F_{m}=\mathcal{F}\text{fine}(X_{m})\oplus\mathcal{F}\text{coarse}(X_{m})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.3" class="ltx_p">where <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{F}\text{fine}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">â„±</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mtext id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3a.cmml">fine</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">â„±</ci><ci id="S3.SS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><mtext id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">fine</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{F}\text{fine}</annotation></semantics></math> and <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{F}\text{coarse}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">â„±</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mtext id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3a.cmml">coarse</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><times id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></times><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">â„±</ci><ci id="S3.SS2.p1.2.m2.1.1.3a.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><mtext id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">coarse</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathcal{F}\text{coarse}</annotation></semantics></math> are fine and coarse-grained encoders respectively, and <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\oplus" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mo id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">âŠ•</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><csymbol cd="latexml" id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\oplus</annotation></semantics></math> denotes feature concatenation.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Multimodal Fusion</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.3" class="ltx_p">The Multi-scale Alignment and Blank Learning (MSA-BL) module fuses multi-modal information:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E3.m1.2" class="ltx_Math" alttext="X_{\text{all}}=\text{MSA}({F_{m}})\odot\text{BL}({F_{m}})" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">X</mi><mtext id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3a.cmml">all</mtext></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mtext id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3a.cmml">MSA</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml">F</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo rspace="0.055em" stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">âŠ™</mo><mtext id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3a.cmml">BL</mtext></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.2.2.1.2" xref="S3.E3.m1.2.2.2.2.1.1.cmml">(</mo><msub id="S3.E3.m1.2.2.2.2.1.1" xref="S3.E3.m1.2.2.2.2.1.1.cmml"><mi id="S3.E3.m1.2.2.2.2.1.1.2" xref="S3.E3.m1.2.2.2.2.1.1.2.cmml">F</mi><mi id="S3.E3.m1.2.2.2.2.1.1.3" xref="S3.E3.m1.2.2.2.2.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S3.E3.m1.2.2.2.2.1.3" xref="S3.E3.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">ğ‘‹</ci><ci id="S3.E3.m1.2.2.4.3a.cmml" xref="S3.E3.m1.2.2.4.3"><mtext mathsize="70%" id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3">all</mtext></ci></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2">direct-product</csymbol><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.1.3"><mtext id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">MSA</mtext></ci><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">ğ¹</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">ğ‘š</ci></apply></apply><ci id="S3.E3.m1.1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.3"><mtext id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3">BL</mtext></ci></apply><apply id="S3.E3.m1.2.2.2.2.1.1.cmml" xref="S3.E3.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.2.2.1">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.2.2.1.1.2">ğ¹</ci><ci id="S3.E3.m1.2.2.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.2.2.1.1.3">ğ‘š</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">X_{\text{all}}=\text{MSA}({F_{m}})\odot\text{BL}({F_{m}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.2" class="ltx_p">where <span id="S3.SS3.p1.2.1" class="ltx_text ltx_markedasmath">MSA</span> is the multi-scale alignment operator and <span id="S3.SS3.p1.2.2" class="ltx_text ltx_markedasmath">BL</span> is the blank learning mechanism.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Multi-task Learning</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">For each task <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">t</annotation></semantics></math>, we employ Task-targeted Gates (TTG):</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E4.m1.3" class="ltx_Math" alttext="h_{t}=\sum_{i=1}^{K}g_{t,i}\cdot f_{i}(X_{\text{all}})" display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><msub id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml"><mi id="S3.E4.m1.3.3.3.2" xref="S3.E4.m1.3.3.3.2.cmml">h</mi><mi id="S3.E4.m1.3.3.3.3" xref="S3.E4.m1.3.3.3.3.cmml">t</mi></msub><mo rspace="0.111em" id="S3.E4.m1.3.3.2" xref="S3.E4.m1.3.3.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.cmml"><munderover id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.2.cmml"><mo movablelimits="false" id="S3.E4.m1.3.3.1.2.2.2" xref="S3.E4.m1.3.3.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.3.3.1.2.2.3" xref="S3.E4.m1.3.3.1.2.2.3.cmml"><mi id="S3.E4.m1.3.3.1.2.2.3.2" xref="S3.E4.m1.3.3.1.2.2.3.2.cmml">i</mi><mo id="S3.E4.m1.3.3.1.2.2.3.1" xref="S3.E4.m1.3.3.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.3.3.1.2.2.3.3" xref="S3.E4.m1.3.3.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.3.3.1.2.3" xref="S3.E4.m1.3.3.1.2.3.cmml">K</mi></munderover><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><msub id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.cmml">g</mi><mrow id="S3.E4.m1.2.2.2.4" xref="S3.E4.m1.2.2.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml">t</mi><mo id="S3.E4.m1.2.2.2.4.1" xref="S3.E4.m1.2.2.2.3.cmml">,</mo><mi id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.3.3.1.1.3.1" xref="S3.E4.m1.3.3.1.1.3.1.cmml">â‹…</mo><msub id="S3.E4.m1.3.3.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.3.2.cmml">f</mi><mi id="S3.E4.m1.3.3.1.1.3.3.3" xref="S3.E4.m1.3.3.1.1.3.3.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.3.3.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">X</mi><mtext id="S3.E4.m1.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3a.cmml">all</mtext></msub><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><eq id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.2"></eq><apply id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.3.1.cmml" xref="S3.E4.m1.3.3.3">subscript</csymbol><ci id="S3.E4.m1.3.3.3.2.cmml" xref="S3.E4.m1.3.3.3.2">â„</ci><ci id="S3.E4.m1.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3">ğ‘¡</ci></apply><apply id="S3.E4.m1.3.3.1.cmml" xref="S3.E4.m1.3.3.1"><apply id="S3.E4.m1.3.3.1.2.cmml" xref="S3.E4.m1.3.3.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.2.1.cmml" xref="S3.E4.m1.3.3.1.2">superscript</csymbol><apply id="S3.E4.m1.3.3.1.2.2.cmml" xref="S3.E4.m1.3.3.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.2">subscript</csymbol><sum id="S3.E4.m1.3.3.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.2.2.2"></sum><apply id="S3.E4.m1.3.3.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.2.2.3"><eq id="S3.E4.m1.3.3.1.2.2.3.1.cmml" xref="S3.E4.m1.3.3.1.2.2.3.1"></eq><ci id="S3.E4.m1.3.3.1.2.2.3.2.cmml" xref="S3.E4.m1.3.3.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E4.m1.3.3.1.2.2.3.3.cmml" xref="S3.E4.m1.3.3.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.3.3.1.2.3.cmml" xref="S3.E4.m1.3.3.1.2.3">ğ¾</ci></apply><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1"><times id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"></times><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><ci id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.1">â‹…</ci><apply id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2">ğ‘”</ci><list id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.4"><ci id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1">ğ‘¡</ci><ci id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2">ğ‘–</ci></list></apply><apply id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2">ğ‘“</ci><ci id="S3.E4.m1.3.3.1.1.3.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3.3">ğ‘–</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2">ğ‘‹</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.3a.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E4.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3">all</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">h_{t}=\sum_{i=1}^{K}g_{t,i}\cdot f_{i}(X_{\text{all}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.3" class="ltx_p">where <math id="S3.SS4.p1.2.m1.2" class="ltx_Math" alttext="g_{t,i}" display="inline"><semantics id="S3.SS4.p1.2.m1.2a"><msub id="S3.SS4.p1.2.m1.2.3" xref="S3.SS4.p1.2.m1.2.3.cmml"><mi id="S3.SS4.p1.2.m1.2.3.2" xref="S3.SS4.p1.2.m1.2.3.2.cmml">g</mi><mrow id="S3.SS4.p1.2.m1.2.2.2.4" xref="S3.SS4.p1.2.m1.2.2.2.3.cmml"><mi id="S3.SS4.p1.2.m1.1.1.1.1" xref="S3.SS4.p1.2.m1.1.1.1.1.cmml">t</mi><mo id="S3.SS4.p1.2.m1.2.2.2.4.1" xref="S3.SS4.p1.2.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS4.p1.2.m1.2.2.2.2" xref="S3.SS4.p1.2.m1.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m1.2b"><apply id="S3.SS4.p1.2.m1.2.3.cmml" xref="S3.SS4.p1.2.m1.2.3"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m1.2.3.1.cmml" xref="S3.SS4.p1.2.m1.2.3">subscript</csymbol><ci id="S3.SS4.p1.2.m1.2.3.2.cmml" xref="S3.SS4.p1.2.m1.2.3.2">ğ‘”</ci><list id="S3.SS4.p1.2.m1.2.2.2.3.cmml" xref="S3.SS4.p1.2.m1.2.2.2.4"><ci id="S3.SS4.p1.2.m1.1.1.1.1.cmml" xref="S3.SS4.p1.2.m1.1.1.1.1">ğ‘¡</ci><ci id="S3.SS4.p1.2.m1.2.2.2.2.cmml" xref="S3.SS4.p1.2.m1.2.2.2.2">ğ‘–</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m1.2c">g_{t,i}</annotation></semantics></math> are task-specific gate values and <math id="S3.SS4.p1.3.m2.1" class="ltx_Math" alttext="f_{i}" display="inline"><semantics id="S3.SS4.p1.3.m2.1a"><msub id="S3.SS4.p1.3.m2.1.1" xref="S3.SS4.p1.3.m2.1.1.cmml"><mi id="S3.SS4.p1.3.m2.1.1.2" xref="S3.SS4.p1.3.m2.1.1.2.cmml">f</mi><mi id="S3.SS4.p1.3.m2.1.1.3" xref="S3.SS4.p1.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m2.1b"><apply id="S3.SS4.p1.3.m2.1.1.cmml" xref="S3.SS4.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m2.1.1.1.cmml" xref="S3.SS4.p1.3.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.3.m2.1.1.2.cmml" xref="S3.SS4.p1.3.m2.1.1.2">ğ‘“</ci><ci id="S3.SS4.p1.3.m2.1.1.3.cmml" xref="S3.SS4.p1.3.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m2.1c">f_{i}</annotation></semantics></math> are expert networks.
The final predictions are obtained through Task-targeted Prediction Layers (TTPL):</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\hat{y}_{t}=\text{TTPL}_{t}(h_{t})" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><mover accent="true" id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml"><mi id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml">y</mi><mo id="S3.E5.m1.1.1.3.2.1" xref="S3.E5.m1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><msub id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3.cmml"><mtext id="S3.E5.m1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.3.2a.cmml">TTPL</mtext><mi id="S3.E5.m1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.3.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml">h</mi><mi id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"></eq><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3">subscript</csymbol><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2"><ci id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3.2.1">^</ci><ci id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2">ğ‘¦</ci></apply><ci id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><times id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2"></times><apply id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.3.2a.cmml" xref="S3.E5.m1.1.1.1.3.2"><mtext id="S3.E5.m1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.3.2">TTPL</mtext></ci><ci id="S3.E5.m1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2">â„</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\hat{y}_{t}=\text{TTPL}_{t}(h_{t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Model Optimization</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.4" class="ltx_p">We optimize the model using a multi-task loss function:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E6.m1.3" class="ltx_Math" alttext="\mathcal{L}=\sum_{t}\alpha_{t}\mathcal{L}_{t}(\hat{y}_{t},y_{t})+\lambda\Omega(\theta)" display="block"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.3.3.4" xref="S3.E6.m1.3.3.4.cmml">â„’</mi><mo rspace="0.111em" id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml">=</mo><mrow id="S3.E6.m1.3.3.2" xref="S3.E6.m1.3.3.2.cmml"><mrow id="S3.E6.m1.3.3.2.2" xref="S3.E6.m1.3.3.2.2.cmml"><munder id="S3.E6.m1.3.3.2.2.3" xref="S3.E6.m1.3.3.2.2.3.cmml"><mo movablelimits="false" id="S3.E6.m1.3.3.2.2.3.2" xref="S3.E6.m1.3.3.2.2.3.2.cmml">âˆ‘</mo><mi id="S3.E6.m1.3.3.2.2.3.3" xref="S3.E6.m1.3.3.2.2.3.3.cmml">t</mi></munder><mrow id="S3.E6.m1.3.3.2.2.2" xref="S3.E6.m1.3.3.2.2.2.cmml"><msub id="S3.E6.m1.3.3.2.2.2.4" xref="S3.E6.m1.3.3.2.2.2.4.cmml"><mi id="S3.E6.m1.3.3.2.2.2.4.2" xref="S3.E6.m1.3.3.2.2.2.4.2.cmml">Î±</mi><mi id="S3.E6.m1.3.3.2.2.2.4.3" xref="S3.E6.m1.3.3.2.2.2.4.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.2.2.2.3" xref="S3.E6.m1.3.3.2.2.2.3.cmml">â€‹</mo><msub id="S3.E6.m1.3.3.2.2.2.5" xref="S3.E6.m1.3.3.2.2.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.3.3.2.2.2.5.2" xref="S3.E6.m1.3.3.2.2.2.5.2.cmml">â„’</mi><mi id="S3.E6.m1.3.3.2.2.2.5.3" xref="S3.E6.m1.3.3.2.2.2.5.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.2.2.2.3a" xref="S3.E6.m1.3.3.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.2.2.2.2.2" xref="S3.E6.m1.3.3.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.2.2.2.2.2.3" xref="S3.E6.m1.3.3.2.2.2.2.3.cmml">(</mo><msub id="S3.E6.m1.2.2.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E6.m1.2.2.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2.2.cmml">y</mi><mo id="S3.E6.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E6.m1.3.3.2.2.2.2.2.4" xref="S3.E6.m1.3.3.2.2.2.2.3.cmml">,</mo><msub id="S3.E6.m1.3.3.2.2.2.2.2.2" xref="S3.E6.m1.3.3.2.2.2.2.2.2.cmml"><mi id="S3.E6.m1.3.3.2.2.2.2.2.2.2" xref="S3.E6.m1.3.3.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.E6.m1.3.3.2.2.2.2.2.2.3" xref="S3.E6.m1.3.3.2.2.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E6.m1.3.3.2.2.2.2.2.5" xref="S3.E6.m1.3.3.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.3.3.2.3" xref="S3.E6.m1.3.3.2.3.cmml">+</mo><mrow id="S3.E6.m1.3.3.2.4" xref="S3.E6.m1.3.3.2.4.cmml"><mi id="S3.E6.m1.3.3.2.4.2" xref="S3.E6.m1.3.3.2.4.2.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.2.4.1" xref="S3.E6.m1.3.3.2.4.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.E6.m1.3.3.2.4.3" xref="S3.E6.m1.3.3.2.4.3.cmml">Î©</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.2.4.1a" xref="S3.E6.m1.3.3.2.4.1.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.2.4.4.2" xref="S3.E6.m1.3.3.2.4.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.2.4.4.2.1" xref="S3.E6.m1.3.3.2.4.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">Î¸</mi><mo stretchy="false" id="S3.E6.m1.3.3.2.4.4.2.2" xref="S3.E6.m1.3.3.2.4.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><eq id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"></eq><ci id="S3.E6.m1.3.3.4.cmml" xref="S3.E6.m1.3.3.4">â„’</ci><apply id="S3.E6.m1.3.3.2.cmml" xref="S3.E6.m1.3.3.2"><plus id="S3.E6.m1.3.3.2.3.cmml" xref="S3.E6.m1.3.3.2.3"></plus><apply id="S3.E6.m1.3.3.2.2.cmml" xref="S3.E6.m1.3.3.2.2"><apply id="S3.E6.m1.3.3.2.2.3.cmml" xref="S3.E6.m1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.2.3.1.cmml" xref="S3.E6.m1.3.3.2.2.3">subscript</csymbol><sum id="S3.E6.m1.3.3.2.2.3.2.cmml" xref="S3.E6.m1.3.3.2.2.3.2"></sum><ci id="S3.E6.m1.3.3.2.2.3.3.cmml" xref="S3.E6.m1.3.3.2.2.3.3">ğ‘¡</ci></apply><apply id="S3.E6.m1.3.3.2.2.2.cmml" xref="S3.E6.m1.3.3.2.2.2"><times id="S3.E6.m1.3.3.2.2.2.3.cmml" xref="S3.E6.m1.3.3.2.2.2.3"></times><apply id="S3.E6.m1.3.3.2.2.2.4.cmml" xref="S3.E6.m1.3.3.2.2.2.4"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.2.2.4.1.cmml" xref="S3.E6.m1.3.3.2.2.2.4">subscript</csymbol><ci id="S3.E6.m1.3.3.2.2.2.4.2.cmml" xref="S3.E6.m1.3.3.2.2.2.4.2">ğ›¼</ci><ci id="S3.E6.m1.3.3.2.2.2.4.3.cmml" xref="S3.E6.m1.3.3.2.2.2.4.3">ğ‘¡</ci></apply><apply id="S3.E6.m1.3.3.2.2.2.5.cmml" xref="S3.E6.m1.3.3.2.2.2.5"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.2.2.5.1.cmml" xref="S3.E6.m1.3.3.2.2.2.5">subscript</csymbol><ci id="S3.E6.m1.3.3.2.2.2.5.2.cmml" xref="S3.E6.m1.3.3.2.2.2.5.2">â„’</ci><ci id="S3.E6.m1.3.3.2.2.2.5.3.cmml" xref="S3.E6.m1.3.3.2.2.2.5.3">ğ‘¡</ci></apply><interval closure="open" id="S3.E6.m1.3.3.2.2.2.2.3.cmml" xref="S3.E6.m1.3.3.2.2.2.2.2"><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2"><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2.1">^</ci><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2.2">ğ‘¦</ci></apply><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E6.m1.3.3.2.2.2.2.2.2.cmml" xref="S3.E6.m1.3.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.3.3.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E6.m1.3.3.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.3.3.2.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.E6.m1.3.3.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.3.3.2.2.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply><apply id="S3.E6.m1.3.3.2.4.cmml" xref="S3.E6.m1.3.3.2.4"><times id="S3.E6.m1.3.3.2.4.1.cmml" xref="S3.E6.m1.3.3.2.4.1"></times><ci id="S3.E6.m1.3.3.2.4.2.cmml" xref="S3.E6.m1.3.3.2.4.2">ğœ†</ci><ci id="S3.E6.m1.3.3.2.4.3.cmml" xref="S3.E6.m1.3.3.2.4.3">Î©</ci><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">ğœƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\mathcal{L}=\sum_{t}\alpha_{t}\mathcal{L}_{t}(\hat{y}_{t},y_{t})+\lambda\Omega(\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.p1.3" class="ltx_p">where <math id="S3.SS5.p1.1.m1.1" class="ltx_Math" alttext="\alpha_{t}" display="inline"><semantics id="S3.SS5.p1.1.m1.1a"><msub id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml"><mi id="S3.SS5.p1.1.m1.1.1.2" xref="S3.SS5.p1.1.m1.1.1.2.cmml">Î±</mi><mi id="S3.SS5.p1.1.m1.1.1.3" xref="S3.SS5.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><apply id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.1.m1.1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.p1.1.m1.1.1.2.cmml" xref="S3.SS5.p1.1.m1.1.1.2">ğ›¼</ci><ci id="S3.SS5.p1.1.m1.1.1.3.cmml" xref="S3.SS5.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">\alpha_{t}</annotation></semantics></math> are task weights, <math id="S3.SS5.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{t}" display="inline"><semantics id="S3.SS5.p1.2.m2.1a"><msub id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.2.m2.1.1.2" xref="S3.SS5.p1.2.m2.1.1.2.cmml">â„’</mi><mi id="S3.SS5.p1.2.m2.1.1.3" xref="S3.SS5.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><apply id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.p1.2.m2.1.1.2.cmml" xref="S3.SS5.p1.2.m2.1.1.2">â„’</ci><ci id="S3.SS5.p1.2.m2.1.1.3.cmml" xref="S3.SS5.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">\mathcal{L}_{t}</annotation></semantics></math> are task-specific losses, and <math id="S3.SS5.p1.3.m3.1" class="ltx_Math" alttext="\Omega(\theta)" display="inline"><semantics id="S3.SS5.p1.3.m3.1a"><mrow id="S3.SS5.p1.3.m3.1.2" xref="S3.SS5.p1.3.m3.1.2.cmml"><mi mathvariant="normal" id="S3.SS5.p1.3.m3.1.2.2" xref="S3.SS5.p1.3.m3.1.2.2.cmml">Î©</mi><mo lspace="0em" rspace="0em" id="S3.SS5.p1.3.m3.1.2.1" xref="S3.SS5.p1.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S3.SS5.p1.3.m3.1.2.3.2" xref="S3.SS5.p1.3.m3.1.2.cmml"><mo stretchy="false" id="S3.SS5.p1.3.m3.1.2.3.2.1" xref="S3.SS5.p1.3.m3.1.2.cmml">(</mo><mi id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml">Î¸</mi><mo stretchy="false" id="S3.SS5.p1.3.m3.1.2.3.2.2" xref="S3.SS5.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><apply id="S3.SS5.p1.3.m3.1.2.cmml" xref="S3.SS5.p1.3.m3.1.2"><times id="S3.SS5.p1.3.m3.1.2.1.cmml" xref="S3.SS5.p1.3.m3.1.2.1"></times><ci id="S3.SS5.p1.3.m3.1.2.2.cmml" xref="S3.SS5.p1.3.m3.1.2.2">Î©</ci><ci id="S3.SS5.p1.3.m3.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">\Omega(\theta)</annotation></semantics></math> is a regularization term.
This methodology integrates advanced techniques in modality completion, multi-scale processing, and multi-task learning to enhance stock prediction accuracy across multiple tasks.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Result and Analysis</h2>

<section id="S4.SS0.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.1 </span>Forecasting Stock Return</h4>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance on Stock Return Prediction</figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">Method</th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">MAPE</th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">RMSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">LSTM</th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">0.0312</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.0437</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">GRU</th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center">0.0308</td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center">0.0429</td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Transformer</th>
<td id="S4.T1.1.4.3.2" class="ltx_td ltx_align_center">0.0301</td>
<td id="S4.T1.1.4.3.3" class="ltx_td ltx_align_center">0.0422</td>
</tr>
<tr id="S4.T1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">MSMF</th>
<td id="S4.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T1.1.5.4.2.1" class="ltx_text ltx_font_bold">0.0285</span></td>
<td id="S4.T1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T1.1.5.4.3.1" class="ltx_text ltx_font_bold">0.0403</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS0.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.2 </span>Forecasting Stock movement</h4>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance on Stock Movement Prediction</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">Method</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy (%)</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1 Score (%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">SVM</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">61.23</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">60.87</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Random Forest</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center">63.45</td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center">62.98</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">XGBoost</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center">64.78</td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_center">64.32</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<th id="S4.T2.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">MSMF</th>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.5.4.2.1" class="ltx_text ltx_font_bold">67.92</span></td>
<td id="S4.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.5.4.3.1" class="ltx_text ltx_font_bold">67.53</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Ablation experiment</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">To validate the roles of different modules in our proposed model, we conducted the following ablation experiments to individually examine the effects of the Multi-grained Encoder, Modality Completion, Multi-modal Fusion, and Multi-task Learning.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Here is the ablation experiment setting to validate the effectiveness of different modules in the proposed model:</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Multi-grained Encoder:
<br class="ltx_break"></span>Experiment: Transform the multi-grained encoders into single-scale encoders for each modality (time series, image, text).
<br class="ltx_break">Goal: Evaluate the impact of multi-scale feature extraction on model performance.
<br class="ltx_break">Metrics: Accuracy, F1 Score, MAPE, RMSE
<br class="ltx_break"></p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Modality Completion:
<br class="ltx_break"></span>Experiment: Compare the proposed model with (a) traditional missing data handling methods like zero filling, forward filling, mean imputation, and (b) single modality prediction.
<br class="ltx_break">Goal: Assess the effectiveness of the modality completion module in handling sampling time heterogeneity.
<br class="ltx_break">Metrics: Accuracy, F1 Score, MAPE, RMSE
<br class="ltx_break"></p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Multi-modal Fusion:</span> 
<br class="ltx_break">Experiment: Replace the proposed multi-scale alignment and blank learning based fusion with simple feature stacking or concatenation.
<br class="ltx_break">Goal: Investigate the capability of the fusion module in enabling natural interaction between modalities and preventing feature degradation.
<br class="ltx_break">Metrics: Accuracy, F1 Score, MAPE, RMSE</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p"><span id="S4.SS1.p6.1.1" class="ltx_text ltx_font_bold">Multi-task Learning:</span> 
<br class="ltx_break">Experiment 1: Train the model architecture individually for each task and compare with multi-task learning performance.
<br class="ltx_break">Goal: Evaluate the impact of auxiliary tasks in improving model generalization.
<br class="ltx_break">Metrics: Accuracy, F1 Score, MAPE, RMSE
<br class="ltx_break">
<br class="ltx_break">Experiment 2: Remove the Multi-Granularity Gates and compare with a single-task variant using a single gate in MMOE architecture.
<br class="ltx_break">Goal: Examine the effect of Multi-Granularity Gates in assigning different proportions of local/global info and weights to modalities per task.
<br class="ltx_break">Metrics: Accuracy, F1 Score, MAPE, RMSE</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Multi-grained Encoder</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">In order to investigate the ability of the multi-scale encoder in extracting local and global features, we transformed the multi-scale encoder into encoders with the same granularity. Subsequently, we conducted individual evaluations for each group of modalities to quantify the impact of different levels of granularity in the encoders.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance on Multi-grained Encoder</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Method</th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy (%)</th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1 Score (%)</th>
<th id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">MAPE</th>
<th id="S4.T3.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">RMSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<td id="S4.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Time Series (Single-scale)</td>
<td id="S4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">65.21</td>
<td id="S4.T3.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">64.87</td>
<td id="S4.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.0298</td>
<td id="S4.T3.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">0.0418</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<td id="S4.T3.1.3.2.1" class="ltx_td ltx_align_left">Image (Single-scale)</td>
<td id="S4.T3.1.3.2.2" class="ltx_td ltx_align_center">64.76</td>
<td id="S4.T3.1.3.2.3" class="ltx_td ltx_align_left">64.32</td>
<td id="S4.T3.1.3.2.4" class="ltx_td ltx_align_center">0.0302</td>
<td id="S4.T3.1.3.2.5" class="ltx_td ltx_align_left">0.0423</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<td id="S4.T3.1.4.3.1" class="ltx_td ltx_align_left">Text (Single-scale)</td>
<td id="S4.T3.1.4.3.2" class="ltx_td ltx_align_center">63.98</td>
<td id="S4.T3.1.4.3.3" class="ltx_td ltx_align_left">63.54</td>
<td id="S4.T3.1.4.3.4" class="ltx_td ltx_align_center">0.0305</td>
<td id="S4.T3.1.4.3.5" class="ltx_td ltx_align_left">0.0427</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<td id="S4.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_border_b">MSMF</td>
<td id="S4.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.1.5.4.2.1" class="ltx_text ltx_font_bold">67.92</span></td>
<td id="S4.T3.1.5.4.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.1.5.4.3.1" class="ltx_text ltx_font_bold">67.53</span></td>
<td id="S4.T3.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.1.5.4.4.1" class="ltx_text ltx_font_bold">0.0285</span></td>
<td id="S4.T3.1.5.4.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.1.5.4.5.1" class="ltx_text ltx_font_bold">0.0403</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Modality Completion</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">To assess the performance of our model in addressing the issue of sampling time heterogeneity, we conducted comparative analysis with other models. Specifically, three methods were compared: our model, traditional approaches for handling missing data, and single-modality data prediction method.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance on Modality Completion</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Method</th>
<th id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy</th>
<th id="S4.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1 Score</th>
<th id="S4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">MAPE</th>
<th id="S4.T4.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">RMSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.2.1" class="ltx_tr">
<td id="S4.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Single modal data</td>
<td id="S4.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">0.845</td>
<td id="S4.T4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">0.824</td>
<td id="S4.T4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.391</td>
<td id="S4.T4.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">0.341</td>
</tr>
<tr id="S4.T4.1.3.2" class="ltx_tr">
<td id="S4.T4.1.3.2.1" class="ltx_td ltx_align_left">Multimodal data(Zero Filling)</td>
<td id="S4.T4.1.3.2.2" class="ltx_td ltx_align_center">0.798</td>
<td id="S4.T4.1.3.2.3" class="ltx_td ltx_align_left">0.792</td>
<td id="S4.T4.1.3.2.4" class="ltx_td ltx_align_center">0.387</td>
<td id="S4.T4.1.3.2.5" class="ltx_td ltx_align_left">0.295</td>
</tr>
<tr id="S4.T4.1.4.3" class="ltx_tr">
<td id="S4.T4.1.4.3.1" class="ltx_td ltx_align_left">Multimodal data(Forward Filling)</td>
<td id="S4.T4.1.4.3.2" class="ltx_td ltx_align_center">0.852</td>
<td id="S4.T4.1.4.3.3" class="ltx_td ltx_align_left">0.832</td>
<td id="S4.T4.1.4.3.4" class="ltx_td ltx_align_center">0.365</td>
<td id="S4.T4.1.4.3.5" class="ltx_td ltx_align_left">0.286</td>
</tr>
<tr id="S4.T4.1.5.4" class="ltx_tr">
<td id="S4.T4.1.5.4.1" class="ltx_td ltx_align_left">Multimodal data(Mean Inputation)</td>
<td id="S4.T4.1.5.4.2" class="ltx_td ltx_align_center">0.870</td>
<td id="S4.T4.1.5.4.3" class="ltx_td ltx_align_left">0.856</td>
<td id="S4.T4.1.5.4.4" class="ltx_td ltx_align_center">0.361</td>
<td id="S4.T4.1.5.4.5" class="ltx_td ltx_align_left">0.279</td>
</tr>
<tr id="S4.T4.1.6.5" class="ltx_tr">
<td id="S4.T4.1.6.5.1" class="ltx_td ltx_align_left ltx_border_b">MSMF</td>
<td id="S4.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_b">0.911</td>
<td id="S4.T4.1.6.5.3" class="ltx_td ltx_align_left ltx_border_b">0.908</td>
<td id="S4.T4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_b">0.342</td>
<td id="S4.T4.1.6.5.5" class="ltx_td ltx_align_left ltx_border_b">0.251</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Multi-modal Fusion</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">In order to investigate the capability of our proposed multimodal information fusion module to enable natural interaction among different modalities and avoid feature information degradation, which may result in the loss of global and local information during the fusion process, we conducted a comparison by removing the feature fusion module and using a simple feature stacking approach for fusion.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance on Multi-modal Fusion</figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Method</th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy (%)</th>
<th id="S4.T5.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1 Score (%)</th>
<th id="S4.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">MAPE</th>
<th id="S4.T5.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">RMSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.2.1" class="ltx_tr">
<td id="S4.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Feature stack</td>
<td id="S4.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">65.87</td>
<td id="S4.T5.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">65.42</td>
<td id="S4.T5.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.0294</td>
<td id="S4.T5.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">0.0412</td>
</tr>
<tr id="S4.T5.1.3.2" class="ltx_tr">
<td id="S4.T5.1.3.2.1" class="ltx_td ltx_align_left">Feature concatenate</td>
<td id="S4.T5.1.3.2.2" class="ltx_td ltx_align_center">66.23</td>
<td id="S4.T5.1.3.2.3" class="ltx_td ltx_align_left">65.89</td>
<td id="S4.T5.1.3.2.4" class="ltx_td ltx_align_center">0.0291</td>
<td id="S4.T5.1.3.2.5" class="ltx_td ltx_align_left">0.0409</td>
</tr>
<tr id="S4.T5.1.4.3" class="ltx_tr">
<td id="S4.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_border_b">MSMF</td>
<td id="S4.T5.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.1.4.3.2.1" class="ltx_text ltx_font_bold">67.92</span></td>
<td id="S4.T5.1.4.3.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T5.1.4.3.3.1" class="ltx_text ltx_font_bold">67.53</span></td>
<td id="S4.T5.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.1.4.3.4.1" class="ltx_text ltx_font_bold">0.0285</span></td>
<td id="S4.T5.1.4.3.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T5.1.4.3.5.1" class="ltx_text ltx_font_bold">0.0403</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4 </span>Multi-task Learning</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">To investigate the impact of auxiliary tasks on improving model performance during the process of multi-task learning, we trained the same model architecture for each task individually and compared it with the performance of the multi-task training model as described in the study.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance on Multi-task Learning</figcaption>
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Method</th>
<th id="S4.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy (%)</th>
<th id="S4.T6.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1 Score (%)</th>
<th id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">MAPE</th>
<th id="S4.T6.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">RMSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.2.1" class="ltx_tr">
<td id="S4.T6.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Stock Return</td>
<td id="S4.T6.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T6.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="S4.T6.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.0297</td>
<td id="S4.T6.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">0.0416</td>
</tr>
<tr id="S4.T6.1.3.2" class="ltx_tr">
<td id="S4.T6.1.3.2.1" class="ltx_td ltx_align_left">Stock Movement</td>
<td id="S4.T6.1.3.2.2" class="ltx_td ltx_align_center">65.76</td>
<td id="S4.T6.1.3.2.3" class="ltx_td ltx_align_left">65.32</td>
<td id="S4.T6.1.3.2.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T6.1.3.2.5" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T6.1.4.3" class="ltx_tr">
<td id="S4.T6.1.4.3.1" class="ltx_td ltx_align_left ltx_border_b">Multi-task</td>
<td id="S4.T6.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T6.1.4.3.2.1" class="ltx_text ltx_font_bold">67.92</span></td>
<td id="S4.T6.1.4.3.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T6.1.4.3.3.1" class="ltx_text ltx_font_bold">67.53</span></td>
<td id="S4.T6.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T6.1.4.3.4.1" class="ltx_text ltx_font_bold">0.0285</span></td>
<td id="S4.T6.1.4.3.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T6.1.4.3.5.1" class="ltx_text ltx_font_bold">0.0403</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS1.SSS4.p2" class="ltx_para">
<p id="S4.SS1.SSS4.p2.1" class="ltx_p">To explore the effect of Multi-Granularity Gates, which allow different tasks to assign different proportions of local and global information within the same modality, and different weights to the overall representation of the same modality from an external perspective, we removed the Multi-Granularity Gates and compared it with a single-task variant using a single gate in the MMOE architecture.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance on Multi-Granularity Gates</figcaption>
<table id="S4.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.1.1.1" class="ltx_tr">
<th id="S4.T7.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Method</th>
<th id="S4.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy (%)</th>
<th id="S4.T7.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1 Score (%)</th>
<th id="S4.T7.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">MAPE</th>
<th id="S4.T7.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">RMSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.1.2.1" class="ltx_tr">
<td id="S4.T7.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Without (MG Gates)</td>
<td id="S4.T7.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">66.34</td>
<td id="S4.T7.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">65.98</td>
<td id="S4.T7.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.0293</td>
<td id="S4.T7.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">0.0411</td>
</tr>
<tr id="S4.T7.1.3.2" class="ltx_tr">
<td id="S4.T7.1.3.2.1" class="ltx_td ltx_align_left ltx_border_b">With (MG Gates)</td>
<td id="S4.T7.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.1.3.2.2.1" class="ltx_text ltx_font_bold">67.92</span></td>
<td id="S4.T7.1.3.2.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T7.1.3.2.3.1" class="ltx_text ltx_font_bold">67.53</span></td>
<td id="S4.T7.1.3.2.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.1.3.2.4.1" class="ltx_text ltx_font_bold">0.0285</span></td>
<td id="S4.T7.1.3.2.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T7.1.3.2.5.1" class="ltx_text ltx_font_bold">0.0403</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In the field of multimodal data analysis, our research has achieved significant breakthroughs. Compared to traditional stock market prediction methods, our model integrates data from different modalities and has yielded satisfactory results. Furthermore, our model addresses key challenges in multimodal learning by proposing various modules to tackle specific issues.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Firstly, to address the problem of inconsistent data sampling rates, we have designed a Modality Completion module. This module effectively handles the heterogeneity between different modalities by utilizing a DBN network to accurately complete missing data in unknown modalities based on the known modal data distribution.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Secondly, to resolve the conflict between extracting global and local features, we have developed a multi-scale encoder. This encoder can extract features at different scales, allowing the model to capture both global and local information and better integrate data from diverse modalities.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">Additionally, we introduce the Multi-scale Alignment module to address the challenge of information exchange between different modalities. By transforming features of different modalities and shapes into the same size, this module enables natural interaction among various modalities, facilitating a better understanding and integration of information, thereby enhancing the effectiveness of multimodal data analysis.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">Moreover, we propose the concept of Blank Learning. By applying the softmax operation to features and selecting the top features based on their probabilities, we eliminate redundant or conflicting information between different modalities, thereby improving the modelâ€™s performance.</p>
</div>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p">Furthermore, we introduce Multi-Granularity Gates, which allow different tasks to assign different proportions of local and global information within the same modality. Additionally, from an external perspective, different tasks assign different weights to the overall representation of the same modality.</p>
</div>
<div id="S6.p7" class="ltx_para">
<p id="S6.p7.1" class="ltx_p">Finally, we design a task-oriented prediction layer to avoid the loss of global and local information during the feature fusion process, which prevents the degradation of feature information and accelerates the convergence of the model.</p>
</div>
<div id="S6.p8" class="ltx_para">
<p id="S6.p8.1" class="ltx_p">Through the design of these modules and innovative ideas, our research has made significant progress in the field of multimodal data analysis. These modules collectively address key challenges in multimodal learning, providing effective solutions for tasks such as stock market prediction. We believe that these achievements will have a positive impact on future research and applications in multimodal data analysis.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ding, X., Zhang, Y., Liu, T., &amp; Duan, J. (2015). Deep learning for event-driven stock prediction. In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Joint Conference on Artificial Intelligence</span> (pp. 2327-2333).

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Nuij, W., Milea, V., Hogenboom, F., Frasincar, F., &amp; Kaymak, U. (2014). An automated framework for incorporating news into stock trading strategies. <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>, 26(4), 823-835.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Moat, H. S., Curme, C., Avakian, A., Kenett, D. Y., Stanley, H. E., &amp; Preis, T. (2013). Quantifying Wikipedia usage patterns before stock market moves. <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Scientific Reports</span>, 3, 1801.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Zheludev, I., Smith, R., &amp; Aste, T. (2014). When can social media lead financial markets? <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Scientific Reports</span>, 4, 4213.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Li, Q., Tan, J., Wang, J., &amp; Chen, H. (2021). A Multimodal Event-Driven LSTM Model for Stock Prediction Using Online News. <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>, 33, 3323-3337.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Friday, I. K., Godslove, J. F., Nayak, D., &amp; Prusty, S. (2022). IRGM: An Integrated RNN-GRU Model for Stock Market Price Prediction. In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">2022 International Conference on Machine Learning, Computer Systems and Security (MLCSS)</span> (pp. 129-132).

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Mittal, S., &amp; Chauhan, A. (2021). A RNN-LSTM-Based Predictive Modelling Framework for Stock Market Prediction Using Technical Indicators. <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">International Journal of Rough Sets Data Analysis</span>, 7, 1-13.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Hao, P.-Y., Kung, C.-F., Chang, C.-Y., Ou, J.-B. (2021). Predicting stock price trends based on financial news articles and using a novel twin support vector machine with fuzzy hyperplane. <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib8.2.2" class="ltx_text ltx_font_italic">98</span>, 106806. doi:10.1016/j.asoc.2020.106806.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Liu, Y., Yu, J., &amp; Han, Y. (2018). Understanding the effective receptive field in semantic image segmentation. <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Multimedia Tools and Applications</span>, <span id="bib.bib9.2.2" class="ltx_text ltx_font_italic">77</span>, 22159-22171.
.
.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Szegedy, C., et al. (2015). Going deeper with convolutions. In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</span>, pp. 1-9.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. Qin and L. Zong, â€TS-BERT: A fusion model for Pre-trainning Time Series-Text Representations,â€ 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Wu, Z., Pan, S., Long, G., Jiang, J., Chang, X., &amp; Zhang, C. (2020). Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</span>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Lai, G., Chang, W., Yang, Y., &amp; Liu, H. (2017). Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks. In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</span>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"> Li, Q., Chen, Y., Jiang, L.L., Li, P., &amp; Chen, H. (2016). A tensor-based information framework for predicting the stock market. <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Information Systems (TOIS)</em>, 34(2), 11.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Tao Ma and Ying Tan. â€Stock Ranking with Multi-Task Learning.â€ <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>, vol. 199, pp. 116886, 2022. ISSN: 0957-4174. DOI: 10.1016/j
..2022.116886.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Qin, L. Zong, and F. Liu, â€Exploring Inner Speech Recognition via Cross-Perception Approach in EEG and fMRI,â€ <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Applied Sciences</span>, vol. 14, no. 17, p. 7720, 2024.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Hashimoto, K., Xiong, C., Tsuruoka, Y., &amp; Socher, R. (2016). â€A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks.â€ arXiv preprint arXiv:1611.01587

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. Qin and F. Liu, â€Mamba-Spike: Enhancing the Mamba Architecture with a Spiking Front-End for Efficient Temporal Data Processing,â€ arXiv preprint arXiv:2408.11823
, 2024. .

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Deng, L., Hinton, G., &amp; Kingsbury, B. (2013). â€New Types of Deep Neural Network Learning for Speech Recognition and Related Applications: An Overview.â€ In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</em>, pp. 8599-8603. IEEE.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Lu, Y., Kumar, A., Zhai, S., Cheng, Y., Javidi, T., &amp; Feris, R. (2017). â€Fully-Adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification.â€ In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, pp. 5334â€“5343.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Caruana, R. (1998). â€Multitask learning.â€ In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Learning to learn</em>, 95â€“133. Springer.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Caruna, R. (1993). â€Multitask learning: A knowledge-based source of inductive bias.â€ In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Machine Learning: Proceedings of the Tenth International Conference</em>, 41â€“48.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Ma, J., Zhao, Z., Yi, X., Chen, J., Hong, L., &amp; Chi, E. H. (2018). â€Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.â€ In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD â€™18)</em>, 1930-1939. Association for Computing Machinery. DOI: 10.1145/3219819.3220007
.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Yuan, C., Ma, X., Wang, H., Zhang, C., &amp; Li, X. (2023). COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic. <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, <span id="bib.bib24.2.2" class="ltx_text ltx_font_bold">217</span>, 119549.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Feng, W., Ma, X., Li, X., &amp; Zhang, C. (2023). A representation learning framework for stock movement prediction. <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib25.2.2" class="ltx_text ltx_font_bold">144</span>, 110409.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. Qin, B. You, and F. Liu, â€Intelligent Stock Forecasting by Iterative Global-Local Fusion,â€ in <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Advanced Intelligent Computing Technology and Applications</span>, Singapore: Springer Nature Singapore, 2024, pp. 285â€“295.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Yu, H., Wang, Z., Xie, Y., &amp; Wang, G. (2024). A multi-granularity hierarchical network for long- and short-term forecasting on multivariate time series data. <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib27.2.2" class="ltx_text ltx_font_bold">157</span>, 111537.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Zhang, M., Yang, J., Wan, M., Zhang, X., &amp; Zhou, J. (2022). Predicting long-term stock movements with fused textual features of Chinese research reports. <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, <span id="bib.bib28.2.2" class="ltx_text ltx_font_bold">210</span>, 118312.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Zhou, F., Zhang, Q., Zhu, Y., &amp; Li, T. (2023). T2V_TF: An adaptive timing encoding mechanism based Transformer with multi-source heterogeneous information fusion for portfolio management: A case of the Chinese A50 stocks. <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, <span id="bib.bib29.2.2" class="ltx_text ltx_font_bold">213</span>, 119020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kan, N. H. L., Cao, Q., &amp; Quek, C. (2024). Learning and processing framework using Fuzzy Deep Neural Network for trading and portfolio rebalancing. <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib30.2.2" class="ltx_text ltx_font_bold">152</span>, 111233.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Ying, Z., Cheng, D., Chen, C., Li, X., Zhu, P., Luo, Y., &amp; Liang, Y. (2024). Predicting stock market trends with self-supervised learning. <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Neurocomputing</span>, <span id="bib.bib31.2.2" class="ltx_text ltx_font_bold">568</span>, 127033.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J. Qin, â€Zoom and Shift are All You Need,â€ arXiv preprint arXiv:2406.08866
, 2024.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Liao, S., Xie, L., Du, Y., Chen, S., Wan, H., &amp; Xu, H. (2024). Stock trend prediction based on dynamic hypergraph spatio-temporal network. <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib33.2.2" class="ltx_text ltx_font_bold">154</span>, 111329.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Liu, Y., Huang, S., Tian, X., Zhang, F., Zhao, F., &amp; Zhang, C. (2024). A stock series prediction model based on variational mode decomposition and dual-channel attention network. <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, <span id="bib.bib34.2.2" class="ltx_text ltx_font_bold">238</span>, 121708.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Wang, T., Guo, J., Shan, Y., Zhang, Y., Peng, B., &amp; Wu, Z. (2023). A knowledge graphâ€“GCNâ€“community detection integrated model for large-scale stock price prediction. <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib35.2.2" class="ltx_text ltx_font_bold">145</span>, 110595.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Wu, Q., Zhang, H.-C., &amp; Chiu, Y.-J. (2023). Application of asymmetric proximal support vector regression based on multitask learning in the stock market. <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, <span id="bib.bib36.2.2" class="ltx_text ltx_font_bold">227</span>, 120208.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Jiayu He, Nguyen H. Tran, &amp; Matloob Khushi. (2022). Stock Predictor with Graph Laplacian-Based Multi-task Learning. In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">International Conference on Conceptual Structures</span>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Park, H. J., Kim, Y., &amp; Kim, H. Y. (2022). Stock market forecasting using a multi-task approach integrating long short-term memory and the random forest framework. <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Applied Soft Computing</span>, <span id="bib.bib38.2.2" class="ltx_text ltx_font_bold">114</span>, 108106.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Liu, R., Liu, H., Huang, H., Song, B., &amp; Wu, Q. (2024). Multimodal multiscale dynamic graph convolution networks for stock price prediction. <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Pattern Recognition</span>, <span id="bib.bib39.2.2" class="ltx_text ltx_font_bold">149</span>, 110211.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Linyi Yang, Jiazheng Li, Ruihai Dong, Yue Zhang, &amp; Barry Smyth. (2022). NumHTML: Numeric-Oriented Hierarchical Transformer Model for Multi-task Financial Forecasting. In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">AAAI Conference on Artificial Intelligence</span>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J. Qin, Y. Xu, Z. Lu, and X. Zhang, â€Step fusion: Local and global mutual guidance,â€ arXiv preprint arXiv:2306.16950, 2024.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Y. Hu, J. Qin, Z. Chen, J. Zhou, and X. Zhang, â€Comparison of the effects of attention mechanism on translation tasks of different lengths of ambiguous words,â€ in <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Proceedings of the Second International Workshop of Discourse Processing</span>, Suzhou, China, 2020, pp. 18â€“21.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Q. Wang et al., â€Dynamic residual deep learning with photoelectrically regulated neurons for immunological classification,â€ <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Cell Reports Physical Science</span>, vol. 4, no. 7, p. 101481, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.07854" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.07855" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.07855">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.07855" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.07856" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 18:32:41 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
