<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine</title>
<!--Generated on Sun May  5 17:29:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
large language model,  high order reasoning,  evidence based medicine,  AI for medicine education
" lang="en" name="keywords"/>
<base href="/html/2405.03010v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S1" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S1.SS1" title="In I Introduction ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">I-A</span> </span><span class="ltx_text ltx_font_italic">High order Reasoning with LLM for ICU treatment recommendations</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S1.SS2" title="In I Introduction ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">I-B</span> </span><span class="ltx_text ltx_font_italic">Contribution</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2.SS1" title="In II Related work ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">AI and NLP in Healthcare</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2.SS1.SSS1" title="In II-A AI and NLP in Healthcare ‣ II Related work ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span>1 </span>LLMs in Healthcare</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2.SS1.SSS2" title="In II-A AI and NLP in Healthcare ‣ II Related work ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span>2 </span>Technoqiues in Optimizing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2.SS2" title="In II Related work ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Chatbots and Decision Support Systems in Medicine</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2.SS3" title="In II Related work ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">High-order Reasoning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S2.SS4" title="In II Related work ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-D</span> </span><span class="ltx_text ltx_font_italic">Research gap</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S3" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS1" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Predefinition of high-order reasoning (system message, prompt engineering, and few-shot learning)</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS2" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Contrast evaluation framework</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS3" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic"> What-if scenario</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS4" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic"> Why-not scenario</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS5" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-E</span> </span><span class="ltx_text ltx_font_italic"> So-What scenario</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS6" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-F</span> </span><span class="ltx_text ltx_font_italic"> How-about scenario</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S4.SS7" title="In IV Methodology ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-G</span> </span><span class="ltx_text ltx_font_italic">Life status after discharge from ICU prediction task </span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Experiment and Result</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS1" title="In V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">What-if Scenario</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS1.SSS1" title="In V-A What-if Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span>1 </span>Experiment Flow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS1.SSS2" title="In V-A What-if Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span>2 </span>Result</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS2" title="In V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Why-not Scenario</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS2.SSS1" title="In V-B Why-not Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span>1 </span>Experiment Flow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS2.SSS2" title="In V-B Why-not Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span>2 </span>Result</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS3" title="In V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">So-what Scenario</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS3.SSS1" title="In V-C So-what Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span>1 </span>Experiment Flow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS3.SSS2" title="In V-C So-what Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span>2 </span>Result</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS4" title="In V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">How-about Scenario</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS4.SSS1" title="In V-D How-about Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span>1 </span>Experiment Flow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS4.SSS2" title="In V-D How-about Scenario ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span>2 </span>Result</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS5" title="In V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span> </span><span class="ltx_text ltx_font_italic">Life status after discharge from ICU prediction task</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS5.SSS1" title="In V-E Life status after discharge from ICU prediction task ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span>1 </span>Experiment Flow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S5.SS5.SSS2" title="In V-E Life status after discharge from ICU prediction task ‣ V Experiment and Result ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span>2 </span>Result</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S6" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Overall Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S7" title="In High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#S7.SS1" title="In VII Conclusion ‣ High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VII-A</span> </span><span class="ltx_text ltx_font_italic">Ethic Statement</span></span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine 
<br class="ltx_break"/>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup class="ltx_sup" id="id1.1.id1">st</sup> Manjiang Yu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id2.2.id1">School of Electrical Engineering and Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id3.3.id2">University of Queensland
<br class="ltx_break"/></span>Brisbane, Australia 
<br class="ltx_break"/>manjiang.yu@uqconnect.edu.au
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup class="ltx_sup" id="id4.1.id1">nd</sup> Xueli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id5.2.id1">School of Electrical Engineering and Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id6.3.id2">University of Queensland
<br class="ltx_break"/></span>Brisbane, Australia 
<br class="ltx_break"/>xueli@eecs.uq.edu.au
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id7.id1">In time-critical decisions, human decision-makers can interact with AI-enabled situation-aware software to evaluate many imminent and possible scenarios, retrieve billions of facts, and estimate different outcomes based on trillions of parameters in a fraction of a second. In high-order reasoning, ”what-if” questions can be used to challenge the assumptions or pre-conditions of the reasoning, ”why-not” questions can be used to challenge on the method applied in the reasoning, ”so-what” questions can be used to challenge the purpose of the decision, and ”how-about” questions can be used to challenge the applicability of the method. When above high-order reasoning questions are applied to assist human decision-making, it can help humans to make time-critical decisions and avoid false-negative or false-positive types of errors. In this paper, we present a model of high-order reasoning to offer recommendations in evidence-based medicine in a time-critical fashion for the applications in intensive care unit. The Large Language Model (LLM) is used in our system. The experiments demonstrated after system message and few-shot learning, the LLM exhibited optimal performance in the ”What-if” high-order reasoning scenario, achieving a similarity of 88.52% with the treatment plans of human doctors. In the ”Why-not” scenario, the best-performing model tended to opt for alternative treatment plans in 70% of cases for patients who died after being discharged from the ICU. In the ”So-what” scenario, the optimal model provided a detailed analysis of the motivation and significance of treatment plans for ICU patients, with its reasoning achieving a similarity of 55.6% with actual diagnostic information. In the ”How-about” scenario, the top-performing LLM demonstrated a content similarity of 66.5% in designing treatment plans transferring for similar diseases. Meanwhile, LLMs managed to predict the life status of patients after their discharge from the ICU with an accuracy of 70%.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
large language model, high order reasoning, evidence based medicine, AI for medicine education

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">People can think fast and slow<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib1" title="">1</a>]</cite>; in the Intensive Care Unit (ICU), it’s crucial for doctors to think slowly to ensure the accuracy of each operation on patients. However, efficiency is equally important in these high-stakes environments. Large language models (LLMs), with their ability to rapidly process vast volumes of data, high-speed computing power, and capacity to coordinate with numerous agents, emerge as potential tools. They can augment the decision-making process in the ICU, providing timely, data-driven insights that support the precision and efficiency required in critical care. In the demanding Intensive Care Unit (ICU) environment, where resources are scarce and medical staff face time pressure and heavy workloads, there’s a pressing need for strategies to alleviate these burdens. The uneven global distribution of ICU resources further highlights this need. Reducing decision-making pressure could greatly improve ICU resource scalability and patient outcomes.The emergence of Large Language Models like GPT has opened new possibilities in various sectors, including healthcare. These models are increasingly recognized for their ability to enhance medical efficiency, having shown proficiency in simple medical diagnostics and efficient management of electronic medical records. However, these tasks are less complex compared to the intricate decision-making required in the ICU.This thesis explores whether LLMs can be applied to complex medical decision-making in the ICU, involving high-order reasoning. If successful, this could significantly impact AI-assisted treatment and medical education in healthcare.
High-order reasoning involves critical, analytical, and creative thinking, essential in ICUs where complex patient care is required<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib2" title="">2</a>]</cite>. It surpasses basic cognitive skills, enabling healthcare professionals to make timely, precise decisions and develop personalized treatment plans amidst diverse patient conditions. With advancements in AI and NLP, the role of technology in augmenting high-order reasoning is gaining attention. AI and NLP-powered chatbots can analyze extensive data and interpret complex medical scenarios, becoming valuable assistants in clinicians’ decision-making processes<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib3" title="">3</a>]</cite>.</p>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S1.SS1.4.1.1">I-A</span> </span><span class="ltx_text ltx_font_italic" id="S1.SS1.5.2">High order Reasoning with LLM for ICU treatment recommendations</span>
</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">The rise of Large Language Models (LLMs) in natural language processing and AI has significant implications for healthcare, especially in the high-pressure setting of Intensive Care Units (ICUs). These advanced models present opportunities for smart, swift, and precise treatment recommendations, meeting the critical demand for efficient decision-making tools in ICUs, where time and resources are often limited. Nonetheless, incorporating these models into ICU workflows presents certain challenges, particularly in evaluating their capability to perform high-order reasoning in critical care. Specific problems include:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">How effective are LLMs at understanding complex medical data in intricate scenarios and providing accurate and reliable treatment advice in real-time?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">How can we ensure the content generated by LLMs is harmless and accurate?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">How do the suggestions provided by LLMs compare in accuracy, reliability, and applicability to those offered by experienced ICU doctors?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">What strategies can be adopted to enhance the higher-order reasoning abilities of LLMs in the context of ICU treatment advice?</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">This study evaluates the effectiveness of Large Language Models in providing treatment advice in ICUs, using real ICU data. It investigates techniques such as prompt engineering and few-shot learning to enhance the sophisticated reasoning capabilities of these models in a complex, fast-paced setting. The research concentrates on the hurdles of incorporating these AI tools into ICU workflows, with a particular focus on ensuring their advice’s accuracy, reliability, and safety in comparison to seasoned physicians. The objective is to thoroughly evaluate and improve the application of these models in ICU treatment decision-making. Specific goals include:</p>
</div>
<div class="ltx_para" id="S1.SS1.p3">
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I2.i1.p1.1.1">Present and evaluate LLMs’ High-Order reasoning capabilities in the ICU Environment:</span> Using eICU to simulate real ICU scenarios, and employing system message, prompt engineering, and few-shot learning to promote LLM’s demonstration of its high-order reasoning capabilities. Assess the accuracy, reliability, and applicability of LLMs in providing higher-order reasoning, using complex, real-world ICU data. Compare the LLM-generated suggestions to the advice of experienced ICU doctors to measure the models’ capability and reliability.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I2.i2.p1.1.1">Exploring the impact of various technologies on LLM’s high-order reasoning in the medical field:</span> Explore the impact of technologies like zero-shot learning and fine-tuning on LLMs’ reasoning capacities. compare the performance of LLMs with different techniques in complex high-order reasoning medical decision scenarios.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.SS1.p4">
<p class="ltx_p" id="S1.SS1.p4.1">Each objective is meticulously designed to foster a comprehensive understanding and tangible enhancement of LLMs’ applications in ICU treatment advice.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<p class="ltx_p ltx_align_center" id="S1.F1.1"><span class="ltx_text" id="S1.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="187" id="S1.F1.1.1.g1" src="extracted/5577979/Intuition.png" width="299"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Intuition diagram</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S1.SS2.4.1.1">I-B</span> </span><span class="ltx_text ltx_font_italic" id="S1.SS2.5.2">Contribution</span>
</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">The study introduces four scenarios for assessing high-order reasoning in healthcare, specifically in ICUs, by employing technologies like system messages and few-shot learning to evaluate the reasoning abilities of LLMs in medical environments. Using the eICU database and a new ’contrast evaluation framework’, it measures LLMs against physician decisions, innovating in the validation of LLM capabilities in critical care. The research also examines the impact of fine-tuning and zero-shot learning on LLM performance and compares different models’ abilities to predict hospital discharge outcomes, contributing valuable insights into LLMs’ potential in healthcare.
The study’s focus is not immediate clinical application but to inform medical education, helping students and professionals better understand and navigate complex medical situations through LLM-supported simulations. This approach aims to enrich medical training by integrating advanced technologies with conventional teaching methods, preparing future healthcare.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related work</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.4.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">AI and NLP in Healthcare</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Artificial intelligence (AI), including machine learning, natural language processing (NLP), and deep learning, has significantly advanced healthcare in the past decade. These technologies have been applied in diagnosing various diseases such as stroke, Alzheimer’s disease, skin cancer, and neurological disorders. The combination of AI, NLP, and Large Language Models (LLMs) has shown great promise in healthcare, particularly in cases of acute ischemic stroke and other conditions.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">For instance, Khedher et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib4" title="">4</a>]</cite> used support vector machines for the early detection of Alzheimer’s disease. Fiszman et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib5" title="">5</a>]</cite> initially proposed using NLP for medical diagnosis, applying it to detect acute bacterial pneumonia from chest X-ray reports. Naveed et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib6" title="">6</a>]</cite> achieved a 90% classification accuracy in mining peripheral arterial disease cases from clinical narratives. Qiuyue Zhong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib7" title="">7</a>]</cite> used NLP to screen for suicidal behavior in pregnant women at the Mayo Clinic, which also offers NLP-as-a-service for various healthcare applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib8" title="">8</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">During the COVID-19 pandemic, AI-powered chatbots, as used by Ay Carriere’s team <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib9" title="">9</a>]</cite>, helped address patient needs and reduce healthcare professional burdens. Tvardik et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib10" title="">10</a>]</cite> employed NLP to detect healthcare-associated infections (HAI) with high precision. Wee et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib11" title="">11</a>]</cite> explored machine learning for classifying medical referrals, enhancing efficiency and resource allocation. Tsoukalas et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib12" title="">12</a>]</cite> developed a machine learning-based decision support system for patients with sepsis, demonstrating its potential in improving patient outcomes.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">These studies collectively highlight the transformative role of AI and NLP in various aspects of healthcare.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S2.SS1.SSS1.4.1.1">II-A</span>1 </span>LLMs in Healthcare</h4>
<div class="ltx_para" id="S2.SS1.SSS1.p1">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">In recent years, large language modeling (LLM) has been transforming healthcare, with applications ranging from diagnosing diseases to developing treatment plans. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib13" title="">13</a>]</cite> Key developments include the Generative Pre-Training Transformer (GPT) models by OpenAI, such as GPT-3 and its conversational variant, ChatGPT. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib14" title="">14</a>]</cite> Marco et al. explored ChatGPT’s feasibility in healthcare, particularly in understanding and summarizing clinical scenarios. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib15" title="">15</a>]</cite> ChatGPT also demonstrated potential in passing the USMLE, a comprehensive medical exam. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib16" title="">16</a>]</cite> Kung et al. evaluated ChatGPT on the USMLE, finding it achieved passing scores across all three steps. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib17" title="">17</a>]</cite> Victor Tseng’s study further confirmed ChatGPT’s impressive performance against non-medical professionals. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib18" title="">18</a>]</cite> GPT-4, a more advanced LLM, exhibits human-level performance on various benchmarks, including the USMLE. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib19" title="">19</a>]</cite> Researchers from OpenAI and Microsoft found GPT-4 outperformed earlier models and specialized medical models like Med-PaLM. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib20" title="">20</a>]</cite> Zhang et al. assessed GPT-4’s proficiency in disease classification using a real-world health record database, noting its high accuracy but also some limitations. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib21" title="">21</a>]</cite> Thirunavukarasu et al. explored the technical limitations and barriers of LLMs in healthcare, emphasizing the need for further validation. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib22" title="">22</a>]</cite> Google’s research team investigated LLMs in encoding clinical knowledge, introducing MultiMedQA and HealthSearchQA for evaluating models like PaLM and Flan-PaLM. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib23" title="">23</a>]</cite> Despite Flan-PaLM’s state-of-the-art accuracy, human assessments revealed gaps, leading to the development of Med-PaLM, which showed promise but still requires further development for clinical applications. This comprehensive overview highlights the evolving role of LLMs in healthcare, underscoring their potential and the need for ongoing research and development.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S2.SS1.SSS2.4.1.1">II-A</span>2 </span>Technoqiues in Optimizing</h4>
<div class="ltx_para" id="S2.SS1.SSS2.p1">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">In the field of large language models, advancements in specific technologies are pivotal for their efficacy in specialized domains like healthcare. This paper delves into key strategies such as system messaging, prompt engineering, few-shot learning, zero-shot learning, and fine-tuning, highlighting their roles and potential applications. System messaging involves guiding the model’s responses through prompts, playing a vital role in directing LLM behavior and breaking domain-specific limitations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib24" title="">24</a>]</cite>. Prompt engineering, a crucial skill for effective interaction, involves crafting well-structured prompts to elicit specific responses, ensuring contextually appropriate insights <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib26" title="">26</a>]</cite>. Few-shot learning, as demonstrated by models like GPT-3, allows learning from limited data, illustrating adaptability and pattern application in new situations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib28" title="">28</a>]</cite>. Zero-shot learning enables handling tasks without prior examples, showcasing utility in dynamic settings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib30" title="">30</a>]</cite>. Fine-tuning adjusts pre-trained models for specific tasks, improving accuracy and relevance in particular fields <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib30" title="">30</a>]</cite>. These technologies, particularly relevant in healthcare, offer solutions for complex decision-making and reasoning. The subsequent chapters will explore the integration of these techniques in higher-order reasoning for ICU treatment recommendations, providing a comprehensive understanding of their practical application and impact in critical care settings.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.4.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">Chatbots and Decision Support Systems in Medicine</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The integration of artificial intelligence in digital healthcare has led to the emergence of chatbots and decision support systems (DSS) as transformative tools. These digital solutions facilitate interactions between healthcare professionals and patients, aiding in decision-making, symptom checking, and providing medical information. They promise to enhance healthcare delivery’s quality and efficiency through accurate clinical decisions, supported by robust data and algorithms. However, challenges like data privacy, the need for continuous updates, and algorithmic bias remain. Flora Amato et al. proposed a chatbot system, HOLMes, to improve healthcare efficiency and quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib31" title="">31</a>]</cite>. I-CHING and Jiun-De Yu developed a machine learning-based medical chatbot, MLCF, drawing knowledge from open data sources, though its effectiveness is limited by training set size and quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib32" title="">32</a>]</cite>. Pin Ni’s team created a chatbot using knowledge graphs and deep learning for medical advice, enhancing understanding and precision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib33" title="">33</a>]</cite>. Ann Sato’s team developed a chatbot for preliminary genetic screening for HBOC, employing Watson’s functionality and NLP techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib34" title="">34</a>]</cite>. Bao, Qiming et al. designed the HHH, an online medical chatbot system using knowledge graphs and hierarchical bidirectional attention, although it has limitations in addressing diverse medical issues and understanding context <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib35" title="">35</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.4.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.5.2">High-order Reasoning</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">High-order reasoning, a cognitive process for solving complex problems or making decisions, is rooted in educational taxonomies like Bloom’s Taxonomy. This taxonomy outlines several levels of higher-order thinking: remembering basic facts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib36" title="">36</a>]</cite>, understanding main ideas and concepts, applying concepts in real-world situations, analyzing topics from multiple perspectives, synthesizing conclusions, evaluating arguments, and creating new patterns or structures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib37" title="">37</a>]</cite>. Lewis and Smith.D simplify this as interrelating new and stored information to achieve a purpose or solve complex situations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib38" title="">38</a>]</cite>. Lindsey Engle Richard and Nina Simms emphasize the role of analogical cognitive mechanisms in higher-order thinking, focusing on relationships rather than discrete phenomena <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib39" title="">39</a>]</cite>. In artificial intelligence, higher-order reasoning involves advanced cognitive processes like reasoning, decision-making, and problem-solving <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib40" title="">40</a>]</cite>. This goes beyond simple data analysis, requiring the understanding and manipulation of abstract concepts and contextual relevance. Alexander Muacevic and John R Adler demonstrate ChatGpt’s capabilities in higher-order reasoning in pathology, evaluating its speed, reliability, and accuracy in answering high-order questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib40" title="">40</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS4.4.1.1">II-D</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS4.5.2">Research gap</span>
</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Despite significant interest in AI’s role in healthcare, particularly in ICUs, notable research gaps remain:</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Differing complexity in application scenarios:</span> Current research in medical AI primarily addresses basic medical diagnostics and electronic health record processing. However, these applications differ significantly from the complex high-order reasoning and decision-making needed in Intensive Care Units (ICUs). The ICU environment presents challenges in terms of data volume, variety, and the critical nature of decisions. This complexity makes research in this area both theoretically significant and practically urgent. Such studies expand our understanding of high-order reasoning in medical decision-making and establish a foundation for future applications in more complex medical scenarios.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Incompleteness of the Evaluation Framework: </span> The existing evaluation frameworks for assessing the performance of Large Language Models in the healthcare sector are scarce and often lack objectivity and completeness. Many of the current approaches depend on manual assessments by human clinicians or simply evaluate based on the accuracy of multiple-choice questions. Neither of these methods is suitable or comprehensive enough to gauge the high-order reasoning capabilities in the ICU context as proposed by our study. Consequently, we have introduced a novel assessment paradigm known as the contrast evaluation framework, based on eICU databases. This framework allows us to evaluate the high-order reasoning abilities in the ICU setting in a thorough and unbiased manner. Furthermore, it enables us to assess the reliability and accuracy of the language model’s output to a considerable extent. This innovative framework is a step towards a more rigorous and complete assessment mechanism, designed to meet the nuanced needs of high-stakes medical decision-making.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Evaluating the Impact of Techniques on LLM’s High-Order Reasoning in Healthcare: </span>A multitude of techniques is available to enhance the learning process of Large Language Models for downstream tasks, significantly influencing their performance across diverse applications. Techniques such as system messages, few-shot learning, zero-shot learning, and fine-tuning hold the potential to refine model’s capabilities, yet their utility in improving the performance specifically in the healthcare domain remains underexploited. In this study, we not only delve into the influence of various techniques on the high-order reasoning abilities of LLMs within the medical field but also draw comparisons between different LLMs utilizing distinct learning approaches. Our comprehensive analysis sheds light on their respective efficacies in executing advanced reasoning tasks. This research serves as a valuable benchmark and guide for future scholars, providing insights and tools to propel the evolution of LLMs in healthcare and beyond.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">Given these gaps, there is an urgent need for a comprehensive investigation into the higher-order reasoning capabilities of chatbots, especially for treatment recommendations in ICUs. Exploration of this area not only offers the prospect of improving the quality of patient care but also contributes to the broader narrative of AI-driven medical education in healthcare.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Dataset</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This study utilizes the eICU dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib41" title="">41</a>]</cite>, a comprehensive ICU database from the US, providing de-identified, high-resolution data on ICU admissions. Access to this public database requires registration, human research training, and a data use agreement. The eICU’s structured documentation and diagnosis-treatment correlation led to its selection over the MIMIC-III database <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib42" title="">42</a>]</cite>. Its schema includes a non-normalized structure where tables are linked via unique identifiers like PatientUnitStayId, with each patient represented by a uniquePid and hospitalizations by PatientHealthSystemStayId, ensuring efficient data management for research and machine learning applications.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<p class="ltx_p ltx_align_center" id="S3.F2.1"><span class="ltx_text" id="S3.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="241" id="S3.F2.1.1.g1" src="extracted/5577979/ID.png" width="299"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Organization of patient tracking information</figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.2">The first table in the database of the eICU used in this study is the patient table. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib41" title="">41</a>]</cite>Records of Patient Information are Stored in the Patient Table Records of patient information are stored in the Patient table, which contains the three key identifiers mentioned earlier (PatientUnitStayId, PatientHealthSystemStayId, and uniquePid). The Patient table details administrative information about the patient, including time of admission and discharge, unit type, source of admission, place of discharge, and vital sign data at the time of the patient’s discharge. In addition, the patient table summarizes demographic data about the patient, such as age (age <math alttext="&gt;" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mo id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><gt id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">&gt;</annotation></semantics></math> 89 years is labeled ”<math alttext="&gt;" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><mo id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><gt id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">&gt;</annotation></semantics></math> 89”), race, height, and weight, among other key information. The table contains the three key identifiers mentioned earlier (PatientUnitStayId, PatientHealthSystemStayId, uniquePid).</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">this table record all diagnosis in the duration of ICU period of a patient. Each diagnosis has its own time mark which is “Offset” column records the Accumulated time after the patient was admitted entering the ICU.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">this table records all treatment in the duration of ICU period of a patient. Each treatment has its own time mark which is Offset” column records the Accumulated time after the patient was admitted entering the ICU.</p>
</div>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1">This table records the vital signs data in the duration of the ICU of a patient. The records are periodic; each record has its own time mark, which is the “Offset” column, which records the accumulated time after the patient was admitted entering the ICU. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib41" title="">41</a>]</cite> Continuously measured vital sign data were stored in the life cycle chart; these vital signs included heart rate, respiratory rate, oxygen saturation, body temperature, invasive arterial blood pressure, pulmonary artery pressure, ST-segment levels, and intracranial pressure (ICP). Initially, these vital sign data were collected at 1-minute intervals, and the median number over a 5-minute period was archived in the eICU-CRD database.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Methodology</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In order to systematically explore and demonstrate the potential of large language models for higher-order reasoning in complex healthcare scenarios, we employ a series of innovative methodologies. Firstly, we design four <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib43" title="">43</a>]</cite> high-order reasoning contexts: what-if, why-not, so-what, and how-about. This advanced reasoning scenario framework serves as a foundation for demonstrating the higher-order reasoning capabilities of large language models, with each scenario being applicable to various complex medical situations in the ICU. The higher-order reasoning ability of large language models is also flexibly exhibited within this framework. In addition, based on the eICU dataset, we designed specific evaluation criteria for these four high-order reasoning scenarios. The eICU dataset provides valuable data support for our study due to its rich medical information and real-world application scenarios. Through this real-world data-based evaluation, we were able to objectively demonstrate the higher-order reasoning capability.</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<p class="ltx_p ltx_align_center" id="S4.F3.1"><span class="ltx_text" id="S4.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="169" id="S4.F3.1.1.g1" src="extracted/5577979/H.png" width="299"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>High order reasoning scenarios</figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Second, to further challenge and test the comprehensive reasoning capability, we designed a complex discharge status prediction task. This task involves a large amount of time-series medical information and requires the model to speculate on the survival status of a patient at the time of hospital discharge, given this information. This is not only an important task to test model’s performance in real-world applications, but also another core part of our implementation of higher-order inference methods.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Predefinition of high-order reasoning (system message, prompt engineering, and few-shot learning)</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Predefining high-order reasoning in Large Language Models involves setting roles and outputs to guide their reasoning capabilities. This setup involves creating predefined scenarios, utilizing system messages, and applying few-shot learning techniques. System messages play a key role in optimizing model performance while addressing inherent limitations. For instance, specific adaptations in models like ChatGPT, a variation of the GPT series, include safeguards (like Instruct GPT) against generating biased or harmful content. As a result, ChatGPT refrains from delivering sensitive information, such as instructions for making a bomb. However, these safeguards can sometimes restrict the model’s full potential. In healthcare, ChatGPT’s cautious response style yields general advice, not tapping into its full capabilities. System messages act as unseen directives for chatbots, steering their responses to meet set standards. Prompt engineering shapes LLM output to ensure alignment with defined goals. Illustrative scenarios for predefining higher-order reasoning aid in few-shot learning, where LLMs learn to tackle tasks effectively with limited examples, adapting similar reasoning patterns to meet set reasoning objectives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib44" title="">44</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Contrast evaluation framework</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In addressing the need for a robust evaluation system for large language models (LLMs) in healthcare, current approaches often fall short, especially in complex medical scenarios. Existing frameworks typically hinge on simple medical diagnostics or rely on scoring systems by human doctors, which do not adequately capture the nuances of high-order reasoning in intricate medical contexts. To bridge this gap, our study introduces an innovative evaluation framework specifically designed for assessing the high-order reasoning capabilities of LLMs in the medical field, termed the contrast evaluation framework. Central to this framework is its foundation on a real ICU medical record database.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Within this framework, we construct distinct convergence situations for various high-order reasoning scenarios, based on the database. Each scenario is evaluated independently, ensuring a comprehensive and objective assessment. This contrasts with other current frameworks, which often struggle to accurately and rationally validate the content produced by LLMs in medical contexts. Our framework addresses this challenge effectively.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Next, we will delve into the four specific high-order reasoning scenarios and the task of predicting final life status. This thorough examination of LLMs’ high-order reasoning abilities and the evaluation process offers a complete understanding of their potential in ICU settings. This approach not only highlights the capabilities of LLMs but also sets a new standard for their evaluation in the critical domain of healthcare.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.4.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.5.2"> What-if scenario</span>
</h3>
<figure class="ltx_figure" id="S4.F4">
<p class="ltx_p ltx_align_center" id="S4.F4.1"><span class="ltx_text" id="S4.F4.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="134" id="S4.F4.1.1.g1" src="extracted/5577979/Whatif.png" width="269"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>What-if high order reasoning scenario</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">High-order reasoning in this study implies a causal relationship where A → B suggests A as a precondition for B. For instance, if obesity links to diabetes, does hypertension share this risk? Or, would a new diagnosis change a patient’s treatment? This necessitates understanding complex factors, where Bayesian inference can aid <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib43" title="">43</a>]</cite>. Specifically, the study investigates how a new ICU diagnosis would alter treatment recommendations. Convergence in LLM reasoning is assessed by alignment with clinicians’ decisions from the eICU database. If LLM outcomes match the majority of real doctors’ recommendations in new diagnosis scenarios, it indicates LLM decision-making parallels human expertise in the ICU.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.4.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.5.2"> Why-not scenario</span>
</h3>
<figure class="ltx_figure" id="S4.F5">
<p class="ltx_p ltx_align_center" id="S4.F5.1"><span class="ltx_text" id="S4.F5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="221" id="S4.F5.1.1.g1" src="extracted/5577979/Whynot.png" width="269"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Why-not high order reasoning scenario</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Why-not let the user try a different strategy (e.g., a processing strategy) than the one previously used or considered? While we may have observed the results of the underlying reasoning provided by the system, we would also like to explore and compare other approaches<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib43" title="">43</a>]</cite>. For example, a person with diabetes may already be regulating blood glucose through insulin injections. Could we consider making insulin in pill form? If this patient is pregnant, is such an approach practical and effective? There are different treatments for the same diagnosis, and different treatments may have different outcomes, so why not use one over the other? The case of convergence to the with-why-not scenario setting in this study is that patients with similar characteristics but different treatments and outcomes are screened from the eICU database. This may include similar age, diagnosis, baseline health status, etc., but different treatments and final outcomes (survival or death). The GPT generates responses and analyzes the rationale and outcomes. See if the GPT identifies potential improvements or alternative treatments, and if its reasoning is consistent with actual medical and therapeutic principles. Compare the GPT’s reasoning with actual patient outcomes. See if the GPT favors treatments that actually work better (e.g., patient survival).</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS5.4.1.1">IV-E</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS5.5.2"> So-What scenario</span>
</h3>
<figure class="ltx_figure" id="S4.F6">
<p class="ltx_p ltx_align_center" id="S4.F6.1"><span class="ltx_text" id="S4.F6.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="162" id="S4.F6.1.1.g1" src="extracted/5577979/Sowhat.png" width="299"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>So-what high order reasoning scenario</figcaption>
</figure>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">When someone proposes a hover car, people may question, ”So-what?” This scenario is used to question the purpose and value of certain decisions, behaviors, or treatments<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib43" title="">43</a>]</cite>. For example, if an AI system proposes a new treatment for heart disease, what is the real value behind that approach?In the context of this study, we explored LLM’s capability to find the the meaning and significance behind the various treatment methods in ICU. The convergence scenario set for So-what in this study is that only basic information about the patient and the disease is provided to the GPT, and no diagnostic information is provided. The GPT is presented with a selection of treatment data for a certain time period, the GPT is asked the ”what is” question about the significance and value of the treatment, the GPT’s answer is compared with the diagnostic data in the database, and if the GPT’s answer does agree with the actual diagnostic data, it is considered to have converged in this scenario in terms of its reasoning ability.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS6.4.1.1">IV-F</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS6.5.2"> How-about scenario</span>
</h3>
<figure class="ltx_figure" id="S4.F7">
<p class="ltx_p ltx_align_center" id="S4.F7.1"><span class="ltx_text" id="S4.F7.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="154" id="S4.F7.1.1.g1" src="extracted/5577979/Howabout.png" width="299"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>How-about high order reasoning scenario</figcaption>
</figure>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p" id="S4.SS6.p1.1">This scenario intends to explore the scope of application of traditional methods in different contexts<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib43" title="">43</a>]</cite>. It proposes to change the context and investigate whether the knowledge gained is transferable. For example, we know that certain therapies are effective in managing the symptoms of people with type II diabetes, but how can these approaches be applied to people with type I diabetes? More broadly, when we have a specific treatment for a particular disease, how do we transfer it to another similar but slightly different disease? The convergence of this scenario is when patients with similar diseases, such as type 1 diabetes and type 2 diabetes, are selected and we provide information and a treatment plan for one of them, then we give the diagnosis of the other patient and ask the LLM how to transfer this treatment plan to this patient, which we want the LLM to analyze and give the key considerations to be taken into account when transferring the treatment plan. Finally, we give the real doctor’s treatment plan to see if this treatment plan satisfies the key considerations proposed by the LLM, and if it does, the LLM is convergent in this medium-to-high order reasoning scenario.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS7.4.1.1">IV-G</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS7.5.2">Life status after discharge from ICU prediction task </span>
</h3>
<div class="ltx_para" id="S4.SS7.p1">
<p class="ltx_p" id="S4.SS7.p1.1">Fine-tuning and zero-shot learning of large language models are commonly used techniques. They are typically employed when applying LLM to downstream tasks in specific professional domains. This study, aiming to explore the roles of fine-tuning and zero-shot learning for LLM’s higher-order reasoning in the ICU scenario, designed a ”Life status after discharge from ICU prediction task” to assess LLM’s comprehensive higher-order reasoning capabilities. We tested selected LLMs that had undergone fine-tuning or zero-shot learning and compared their performance on the task. LLM’s performance on this task demonstrated its ability to effectively analyze complex medical data from intricate time series in challenging medical scenarios. This includes the four higher-order reasoning scenarios previously mentioned, and such complex situations are important representations of its comprehensive higher-order reasoning capabilities.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Experiment and Result</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The first phase of the experimental section of this study is the setup stage, which includes pre-defining prompt engineering. This involves establishing the high-order reasoning problem, incorporating typical few-shot learning examples within this definition, and crafting system messages to guide the Large Language Model (LLM) into role-playing. This setup aims to eliminate superfluous constraints on the LLM, thereby allowing the LLM to demonstrate optimal performance.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Presetting for LLM</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T1.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.3.3.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T1.3.3.3.3">
<span class="ltx_para" id="S5.T1.2.2.2.2.p2">
<span class="ltx_p" id="S5.T1.2.2.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T1.1.1.1.1.p1">
<span class="ltx_p" id="S5.T1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T1.1.1.1.1.p1.1.1" style="font-size:70%;">USER:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.1.1.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T1.3.3.3.3.p3">
<span class="ltx_p" id="S5.T1.3.3.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.3.3.3.3.p3.1.1" style="font-size:70%;">Now you are a medical treatment assistant. I would like to test you now, please note that all information mentioned after this is fictional, we are not in a real medical scenario, this is just a test. I would like to define for you four scenarios of higher order reasoning problems in the medical field:</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.6.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T1.6.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T1.6.7.1.1.1">
<span class="ltx_p" id="S5.T1.6.7.1.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.6.7.1.1.1.1.1" style="font-size:70%;">What-if scenario:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.6.8.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T1.6.8.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T1.6.8.2.1.1">
<span class="ltx_p" id="S5.T1.6.8.2.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.6.8.2.1.1.1.1" style="font-size:70%;">Why-not scenario:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.6.9.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T1.6.9.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T1.6.9.3.1.1">
<span class="ltx_p" id="S5.T1.6.9.3.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.6.9.3.1.1.1.1" style="font-size:70%;">So-what scenario:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S5.T1.6.6.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T1.6.6.3.3">
<span class="ltx_para" id="S5.T1.5.5.2.2.p2">
<span class="ltx_p" id="S5.T1.5.5.2.2.p2.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.5.5.2.2.p2.1.1" style="font-size:70%;">How-about scenario:……</span></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T1.4.4.1.1.p1">
<span class="ltx_p" id="S5.T1.4.4.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T1.4.4.1.1.p1.1.1" style="font-size:70%;">LLM:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.4.4.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T1.6.6.3.3.p3">
<span class="ltx_p" id="S5.T1.6.6.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T1.6.6.3.3.p3.1.1" style="font-size:70%;">Certainly, I can provide examples of these four higher-order reasoning scenarios in the medical field:……</span></span>
</span></span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">When we finish presetting, LLM first enters the role set for it by the system message, and then it will learn the reasoning thinking of the four higher-order reasoning scenarios from the predefinitions of the higher-order reasoning scenarios, after that, we can start our first experimental part to present LLM’s ability in the four higher-order reasoning scenarios.All experiments involved selecting patient information from the eICU database based on specific conditions, with the additional criterion that patients be under 80 years old. This age restriction was implemented to minimize the impact of age on the patient’s course of treatment in the ICU, which could otherwise influence the outcomes of the experimental tests.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">In the experimental component of this study, three leading Large Language Models (LLMs) were chosen for evaluation: GPT-4, GPT-3.5 Turbo, and LLaMA-2.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib19" title="">19</a>]</cite> GPT-4 is the latest LLM released by OpenAI and is not freely accessible but available exclusively for ChatGPT Plus users. It has achieved or surpassed human-level performance in a multitude of real-world scenarios, as well as a variety of professional, technical, and academic benchmarks. As the most advanced LLM currently on offer, GPT-4’s testing in the realm of higher-order reasoning constitutes a significant part of this experiment. GPT-3.5 Turbo, also developed by OpenAI and based on the GPT-3 architecture, is a version of the GPT series boasting billions of parameters. It delivers enhanced accuracy and efficiency in handling complex tasks compared to its predecessors. LLaMA-2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03010v1#bib.bib45" title="">45</a>]</cite>, introduced by Meta, encompasses a suite of pre-trained and fine-tuned LLMs tailored for conversational applications, with sizes ranging from 7 to 70 billion parameters. The version employed in this study is the 7 billion parameter model, LLaMA-2-Chat.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.4.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.5.2">What-if Scenario</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS1.SSS1.4.1.1">V-A</span>1 </span>Experiment Flow</h4>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>What-if scenario prompting</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T2.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.3.3.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T2.3.3.3.3">
<span class="ltx_para" id="S5.T2.2.2.2.2.p2">
<span class="ltx_p" id="S5.T2.2.2.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T2.1.1.1.1.p1">
<span class="ltx_p" id="S5.T2.1.1.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T2.1.1.1.1.p1.1.1" style="font-size:70%;">USER:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.1.1.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T2.3.3.3.3.p3">
<span class="ltx_p" id="S5.T2.3.3.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.3.3.3.3.p3.1.1" style="font-size:70%;">What if scenario: patientunitstayid: 343448, gender: Female, age:74, disease:Hypertension, uncontrolled (for cerebrovascular accident-see Neurological System)</span></span>
<span class="ltx_p" id="S5.T2.3.3.3.3.p3.2"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.3.3.3.3.p3.2.1" style="font-size:70%;">diagnosis:……</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T2.6.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T2.6.7.1.1.1">
<span class="ltx_p" id="S5.T2.6.7.1.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.6.7.1.1.1.1.1" style="font-size:70%;">treatment:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.8.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T2.6.8.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T2.6.8.2.1.1">
<span class="ltx_p" id="S5.T2.6.8.2.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.6.8.2.1.1.1.1" style="font-size:70%;">Vital periodic data:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.9.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T2.6.9.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T2.6.9.3.1.1">
<span class="ltx_p" id="S5.T2.6.9.3.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.6.9.3.1.1.1.1" style="font-size:70%;">What if the patient has a new diagnosis:</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T2.6.6.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T2.6.6.3.3">
<span class="ltx_para" id="S5.T2.5.5.2.2.p2">
<span class="ltx_p" id="S5.T2.5.5.2.2.p2.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.5.5.2.2.p2.1.1" style="font-size:70%;">what would be the new treatment plan?</span></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T2.4.4.1.1.p1">
<span class="ltx_p" id="S5.T2.4.4.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T2.4.4.1.1.p1.1.1" style="font-size:70%;">LLM:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.4.4.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T2.6.6.3.3.p3">
<span class="ltx_p" id="S5.T2.6.6.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.6.6.3.3.p3.1.1" style="font-size:70%;">To determine a new treatment plan for the patient with the new diagnoses, we need to consider the additional conditions:</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.10.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T2.6.10.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T2.6.10.4.1.1">
<span class="ltx_p" id="S5.T2.6.10.4.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.6.10.4.1.1.1.1" style="font-size:70%;">New Diagnoses:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.11.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S5.T2.6.11.5.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T2.6.11.5.1.1">
<span class="ltx_p" id="S5.T2.6.11.5.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T2.6.11.5.1.1.1.1" style="font-size:70%;">treatment plan:……</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_indent" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">We selected appropriate experimental patients from the eICU database and provided LLM with their diagnostic and treatment data for appropriate time periods. We then continued to provide LLM with new diagnostic information from subsequent time periods, posing questions in the ”What-if” scenario, and requested LLM to produce a new treatment plan for the patient based on the given information. Once LLM completed the formulation of the new treatment plan for the patient, we compared it with the actual treatment plan in the database on a point-to-point basis to calculate the similarity between the two plans. Repeating this experiment several times, we obtained the similarity between the treatment plan derived from LLM’s higher-order reasoning in the ”What-if” scenario and the actual ICU doctor’s treatment plan. This similarity can be seen as the degree of match between LLM’s decision-making and reasoning capabilities in this scenario and those of actual ICU doctors.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS1.SSS2.4.1.1">V-A</span>2 </span>Result</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">The results indicate that in the What-If advanced reasoning scenario, GPT-4 shows a distinct gap in performance compared to the other two models. When generating new treatment plans for patients under What-If conditions, GPT-4’s generated plans, when compared item by item with the real treatment plans recorded in the database, achieved an astonishing average similarity of 88.52%. In contrast, GPT3.5 and LLama2 only achieved 38.9% and 55.9% respectively. This suggests that in the ICU, when patients encounter new situations and diagnoses, GPT-4 can display performance comparable to that of real doctors, while GPT3.5turbo and LLama2 cannot reach a human-comparable level.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS2.p2">
<p class="ltx_p" id="S5.SS1.SSS2.p2.1">When we observed the performance of the three LLMs on five identical patient test cases, we found that both GPT-4 and LLama2 maintained a high level of consistency across the five tests. GPT-4 consistently achieved similarity scores above 80% in all five patient tests, occasionally even matching the actual treatment plan set by real doctors. On the other hand, LLama2’s similarity scores hovered around 50%. However, GPT-3.5 Turbo displayed a more volatile performance. Sometimes it could achieve a 50% similarity score, while at other times it deviated entirely from the real doctor’s treatment plan. Such inconsistency underscores GPT-3.5 Turbo’s weaker high-order reasoning ability.</p>
</div>
<figure class="ltx_figure" id="S5.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F9.1" style="width:173.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="S5.F9.1.g1" src="extracted/5577979/WI1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Overall average similarity scores</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F9.2" style="width:173.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="359" id="S5.F9.2.g1" src="extracted/5577979/WI2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Similarity score for 5 same patients case</figcaption>
</figure>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.4.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.5.2">Why-not Scenario</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS2.SSS1.4.1.1">V-B</span>1 </span>Experiment Flow</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1">For each experiment in this phase, we selected a patient from the database who passed away after ICU treatment. We provided the LLM with the diagnosis, treatment plan, and the corresponding vital periodic data for these patients. We then asked the LLM why a different treatment plan was not chosen, and based on the analysis of the current treatment plan, which one - the current or a different one — would be better. The LLM would then make its choice. If the LLM chose an alternative plan for the patient, it was marked as ”true”, otherwise ”false”. In some test cases, we also found another patient with the same disease and a very similar diagnosis - where the primary diagnosis was identical - but with a different treatment plan. This patient survived after their treatment. For such cases, our why-not question was more directly oriented towards the specific alternative treatment plan. This experiment can be viewed as an assessment of the LLM’s ability to seek alternative methods to compare and contrast given outcomes in a complex medical decision-making environment. It also tests the LLM’s robust analytical skills, determining if it can identify potential issues in the current treatment plan and choose a different treatment approach that might change the patient’s outcome (the LLM is unaware of the patient’s actual fate).</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Why-not scenario prompting</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.3.3.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T3.3.3.3.3">
<span class="ltx_para" id="S5.T3.2.2.2.2.p2">
<span class="ltx_p" id="S5.T3.2.2.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T3.1.1.1.1.p1">
<span class="ltx_p" id="S5.T3.1.1.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T3.1.1.1.1.p1.1.1" style="font-size:70%;">USER:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.1.1.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T3.3.3.3.3.p3">
<span class="ltx_p" id="S5.T3.3.3.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.3.3.3.3.p3.1.1" style="font-size:70%;">Why Not scenario: patientunitstayid: 3176264, gender: Male, age:55, disease:ARDS-adult respiratory distress syndrome, non-cardiogenic pulmonary edema</span></span>
<span class="ltx_p" id="S5.T3.3.3.3.3.p3.2"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.3.3.3.3.p3.2.1" style="font-size:70%;">diagnosis:……</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.7.1.1.1">
<span class="ltx_p" id="S5.T3.6.7.1.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.7.1.1.1.1.1" style="font-size:70%;">treatment:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.8.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.8.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.8.2.1.1">
<span class="ltx_p" id="S5.T3.6.8.2.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.8.2.1.1.1.1" style="font-size:70%;">Vital periodic data:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.9.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.9.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.9.3.1.1">
<span class="ltx_p" id="S5.T3.6.9.3.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.9.3.1.1.1.1" style="font-size:70%;">Why not to use a different treatment from what has been used? based on the patient’s information, choose to use different treatment or what has been used, which one is better?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.6.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T3.6.6.3.3">
<span class="ltx_para" id="S5.T3.5.5.2.2.p2">
<span class="ltx_p" id="S5.T3.5.5.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T3.4.4.1.1.p1">
<span class="ltx_p" id="S5.T3.4.4.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.1.1.p1.1.1">LLM:</span></span>
</span>
<span class="ltx_para" id="S5.T3.6.6.3.3.p3">
<span class="ltx_p" id="S5.T3.6.6.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.6.3.3.p3.1.1" style="font-size:70%;">Given the patient’s information:……</span></span>
<span class="ltx_p" id="S5.T3.6.6.3.3.p3.2"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.6.3.3.p3.2.1" style="font-size:70%;">To determine a new treatment plan for the patient with the new diagnoses, we need to consider the additional conditions:</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.10.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.10.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.10.4.1.1">
<span class="ltx_p" id="S5.T3.6.10.4.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.10.4.1.1.1.1" style="font-size:70%;">Current Treatments:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.11.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.11.5.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.11.5.1.1">
<span class="ltx_p" id="S5.T3.6.11.5.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.11.5.1.1.1.1" style="font-size:70%;">Why Not Scenario:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.12.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T3.6.12.6.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.12.6.1.1">
<span class="ltx_p" id="S5.T3.6.12.6.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.12.6.1.1.1.1" style="font-size:70%;">Potential Adjustments:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.13.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S5.T3.6.13.7.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.6.13.7.1.1">
<span class="ltx_p" id="S5.T3.6.13.7.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T3.6.13.7.1.1.1.1" style="font-size:70%;">Decision:……</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS2.SSS2.4.1.1">V-B</span>2 </span>Result</h4>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p" id="S5.SS2.SSS2.p1.1">We selected a total of ten appropriate cases and conducted experiments on three LLMs in this phase. Among them, GPT4 preferred to choose alternative treatment methods for patients who died after treatment in seven instances, while GPT3.5turbo and LLama2 only did so in two and three instances respectively. We did not assume that a patient’s death was necessarily caused by the doctor’s treatment plan, but there is a possibility of a connection. Our experiment only examines the LLM’s ability to seek different methods to compare and contrast given outcomes. This is crucial in the ICU context because, when this mechanism assists doctors, it might increase the survival rate of ICU patients. Based on the experimental results, GPT4 continues to demonstrate a distinct advantage over the other LLMs, while the performance of GPT3.5turbo and LLama2 on this task was not satisfactory.</p>
</div>
<figure class="ltx_figure" id="S5.F10">
<p class="ltx_p ltx_align_center" id="S5.F10.1"><span class="ltx_text" id="S5.F10.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="180" id="S5.F10.1.1.g1" src="extracted/5577979/WN1.png" width="240"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Overall Positive Rate</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.4.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.5.2">So-what Scenario</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS3.SSS1.4.1.1">V-C</span>1 </span>Experiment Flow</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p" id="S5.SS3.SSS1.p1.1">In the experiment design of this phase, the idea is when faced with specific treatment decisions, people often challenge the motivations and meanings behind them. To simulate this scenario, we intentionally withheld diagnostic information from the GPT, providing only the patient’s basic information and disease data. In this way, we aimed to extract GPT’s understanding and analysis of the treatment plan. We selected appropriate experimental patients from the eICU database and provided only their treatment plans and key periodic data to the LLM. We then posed ”so-what” questions to the LLM to explore the significance and value of specific treatment methods. After receiving the LLM’s response, we compared it with the actual diagnostic data in the database. If the LLM’s answer aligns with the actual diagnostic data, we believe its reasoning ability in such a scenario has converged. After repeating this experiment multiple times, we obtained a consistency between GPT’s higher-order reasoning in the ”So-what” scenario and the actual diagnoses made by ICU doctors. This consistency can be seen as a measure of how well GPT’s decision-making and reasoning abilities in this context match those of real ICU physicians.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>So-what scenario prompting</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S5.T4.3.3.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T4.3.3.3.3">
<span class="ltx_para" id="S5.T4.2.2.2.2.p2">
<span class="ltx_p" id="S5.T4.2.2.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T4.1.1.1.1.p1">
<span class="ltx_p" id="S5.T4.1.1.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T4.1.1.1.1.p1.1.1" style="font-size:70%;">USER:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.1.1.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T4.3.3.3.3.p3">
<span class="ltx_p" id="S5.T4.3.3.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.3.3.3.3.p3.1.1" style="font-size:70%;">So-What scenario: patientunitstayid: 321071, gender: Male, age:56, disease:Seizures (primary-no structural brain disease)</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.6.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.6.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.6.1.1.1">
<span class="ltx_p" id="S5.T4.5.6.1.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.6.1.1.1.1.1" style="font-size:70%;">treatment:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.7.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.7.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.7.2.1.1">
<span class="ltx_p" id="S5.T4.5.7.2.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.7.2.1.1.1.1" style="font-size:70%;">vital periodic data:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.8.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.8.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.8.3.1.1">
<span class="ltx_p" id="S5.T4.5.8.3.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.8.3.1.1.1.1" style="font-size:70%;">So what? What is the significance and value for this? analysis this for potential diagnosis of the patient.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.5.2"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T4.5.5.2.2">
<span class="ltx_para" id="S5.T4.5.5.2.2.p2">
<span class="ltx_p" id="S5.T4.5.5.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T4.4.4.1.1.p1">
<span class="ltx_p" id="S5.T4.4.4.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.T4.4.4.1.1.p1.1.1">LLM:</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.9.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.9.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.9.4.1.1">
<span class="ltx_p" id="S5.T4.5.9.4.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.9.4.1.1.1.1" style="font-size:70%;">The patient with ID 321071 is a 56-year-old male diagnosed with seizures without an underlying structural brain disease. Let’s analyze the treatments and vital signs provided.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.10.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.10.5.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.10.5.1.1">
<span class="ltx_p" id="S5.T4.5.10.5.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.10.5.1.1.1.1" style="font-size:70%;">Treatments Administered:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.11.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.11.6.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.11.6.1.1">
<span class="ltx_p" id="S5.T4.5.11.6.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.11.6.1.1.1.1" style="font-size:70%;">Significance and Value:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.12.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T4.5.12.7.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.12.7.1.1">
<span class="ltx_p" id="S5.T4.5.12.7.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.12.7.1.1.1.1" style="font-size:70%;">Recommendations for Further Assessment:……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.13.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S5.T4.5.13.8.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T4.5.13.8.1.1">
<span class="ltx_p" id="S5.T4.5.13.8.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T4.5.13.8.1.1.1.1" style="font-size:70%;">Conclusion:……</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS3.SSS2.4.1.1">V-C</span>2 </span>Result</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p" id="S5.SS3.SSS2.p1.1">Based on the experimental results, it seems that all three LLMs performed poorly in the ”So-what” high-order reasoning scenario. The consistently well-performing GPT-4 only achieved a similarity of 55.6% with the human doctor’s diagnosis, while the other two only achieved similarities of 17% and 20%, respectively. The reason cannot be attributed to the LLM’s weakened higher-order reasoning ability in this scenario. In reality, a doctor’s new diagnosis at each time interval is not derived solely based on the vital signs or other information from that specific time period. The LLMs only had access to the data provided for that particular time interval; they could not see all the diagnoses, treatments, and other information of the patient since their admission to the ICU. Therefore, the LLM’s analysis of the significance and motivation of the treatment methods is difficult to achieve a high similarity with the real-world doctor’s diagnosis based on limited data.</p>
</div>
<figure class="ltx_figure" id="S5.F11">
<p class="ltx_p ltx_align_center" id="S5.F11.1"><span class="ltx_text" id="S5.F11.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="180" id="S5.F11.1.1.g1" src="extracted/5577979/SW1.png" width="240"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Overall average similarity scores</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.4.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.5.2">How-about Scenario</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS4.SSS1.4.1.1">V-D</span>1 </span>Experiment Flow</h4>
<div class="ltx_para" id="S5.SS4.SSS1.p1">
<p class="ltx_p" id="S5.SS4.SSS1.p1.1">In the medical field, sometimes a particular treatment plan might be used to treat multiple similar diseases. Therefore, the ”How-about” scenario aims to simulate this situation, challenging the LLM’s reasoning and analytical abilities when transferring treatment plans. First, we selected two patients with similar diseases from the eICU database, such as one with viral pneumonia and another with bacterial pneumonia. We provided the information and treatment plan of the first patient, then provided the diagnosis information of the second patient, and asked the LLM how to transfer this treatment plan to the second patient. We expected the LLM to conduct a deep analysis and provide key considerations when transferring the treatment plan. After obtaining the LLM’s answers and key considerations, we provided the actual treatment plan that doctors devised for the second patient and examined whether this treatment plan met the key considerations proposed by the LLM. If the actual treatment plan indeed has high consistency with LLM’s suggestions, we can consider that in this ”How-about” scenario, the LLM’s reasoning capability has converged. By repeatedly conducting this experiment, we were able to compare the GPT’s reasoning in the ”How-about” scenario with the actual ICU doctor’s reasoning capabilities.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>How-about scenario prompting</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T5.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S5.T5.3.3.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T5.3.3.3.3">
<span class="ltx_para" id="S5.T5.2.2.2.2.p2">
<span class="ltx_p" id="S5.T5.2.2.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T5.1.1.1.1.p1">
<span class="ltx_p" id="S5.T5.1.1.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T5.1.1.1.1.p1.1.1" style="font-size:70%;">USER:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.1.1.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T5.3.3.3.3.p3">
<span class="ltx_p" id="S5.T5.3.3.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.3.3.3.3.p3.1.1" style="font-size:70%;">How about scenario: patientunitstayid: 350811, gender: Male, age:81, disease:Bleeding, lower GI</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T5.6.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T5.6.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.6.7.1.1.1">
<span class="ltx_p" id="S5.T5.6.7.1.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.6.7.1.1.1.1.1" style="font-size:70%;">diagnosis:</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.6.8.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T5.6.8.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.6.8.2.1.1">
<span class="ltx_p" id="S5.T5.6.8.2.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.6.8.2.1.1.1.1" style="font-size:70%;">treatment:</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.6.9.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T5.6.9.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.6.9.3.1.1">
<span class="ltx_p" id="S5.T5.6.9.3.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.6.9.3.1.1.1.1" style="font-size:70%;">How about transfer the treatment plan to another patient with Bleeding, upper GI, what do you need to pay attention to, or modify the treatment plan?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.6.10.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T5.6.10.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.6.10.4.1.1">
<span class="ltx_p" id="S5.T5.6.10.4.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.6.10.4.1.1.1.1" style="font-size:70%;">this is the patient’s diagnosis:</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S5.T5.6.6.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T5.6.6.3.3">
<span class="ltx_para" id="S5.T5.5.5.2.2.p2">
<span class="ltx_p" id="S5.T5.5.5.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T5.4.4.1.1.p1">
<span class="ltx_p" id="S5.T5.4.4.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.T5.4.4.1.1.p1.1.1">LLM:</span></span>
</span>
<span class="ltx_para" id="S5.T5.6.6.3.3.p3">
<span class="ltx_p" id="S5.T5.6.6.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T5.6.6.3.3.p3.1.1" style="font-size:70%;">When transferring the treatment plan from a patient with lower GI bleeding to another with upper GI bleeding, several modifications and considerations need to be made ……</span></span>
</span></span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS4.SSS2.4.1.1">V-D</span>2 </span>Result</h4>
<div class="ltx_para" id="S5.SS4.SSS2.p1">
<p class="ltx_p" id="S5.SS4.SSS2.p1.1">In our study, the emphasis was on exploring the applicability of known treatments in new settings. From the experimental results, GPT-4 demonstrated a moderate performance in this specific reasoning scenario, achieving an average similarity of 67.5%. Meanwhile, the performance of GPT3.5 turbo and LLama2 was noticeably poorer, with similarities of 27.00% and 32.00%, respectively. This suggests that GPT-4 has a distinct advantage over the other two models when addressing ”How-about” questions. However, a similarity score of 67.5% also indicates that in about one-third of cases, the suggestions provided by GPT-4 differed from the actual treatments prescribed by physicians. This disparity could arise because, even if two diseases might seem alike, they might have subtle biological differences that could necessitate changes in treatment strategy. Alternatively, real-world physicians might consider a broader range of patient-specific factors when deciding on treatments, and in the absence of this specific information, GPT-4 might make different decisions. All three LLMs displayed their own strengths and weaknesses in the ”How-about” scenario. While GPT-4 was the most competent in handling these types of questions, there’s room for improvement. GPT3.5 turbo and LLama2, on the other hand, require further optimization and adjustments to better tackle these high-level medical reasoning challenges.</p>
</div>
<figure class="ltx_figure" id="S5.F12">
<p class="ltx_p ltx_align_center" id="S5.F12.1"><span class="ltx_text" id="S5.F12.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="180" id="S5.F12.1.1.g1" src="extracted/5577979/HW2.png" width="240"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Overall average similarity scores</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.SSS2.p2">
<p class="ltx_p" id="S5.SS4.SSS2.p2.1">The chart shows the performance in similarity scores of three models: GPT-4, GPT3.5 turbo, and LLama2 in five ”How-about” patient scenarios. GPT-4 overall exhibits the best adaptability, especially in the first and fourth patient scenarios, where the similarity scores almost reached a perfect match. However, there was a noticeable decline in the fifth scenario. In contrast, GPT3.5 turbo’s performance is generally not as good as GPT-4’s, with its reasoning similarity scores below 40% in the first three scenarios, although it rebounded in the fourth patient scenario, it then declined again. The performance of LLama2 is even more unstable, with significant score fluctuations in different scenarios. Overall, GPT-4 leads in stability, but there are still unstable situations; GPT3.5 turbo is overall stable but scores lower, and LLama2 needs further optimization for different scenarios. The performance of these three models in the ”How-about” scenarios suggests that they may need specific optimizations and adjustments.</p>
</div>
<figure class="ltx_figure" id="S5.F13">
<p class="ltx_p ltx_align_center" id="S5.F13.1"><span class="ltx_text" id="S5.F13.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="144" id="S5.F13.1.1.g1" src="extracted/5577979/HW1.png" width="240"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Similarity score for 5 same patinets case</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS5.4.1.1">V-E</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS5.5.2">Life status after discharge from ICU prediction task</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS5.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS5.SSS1.4.1.1">V-E</span>1 </span>Experiment Flow</h4>
<div class="ltx_para" id="S5.SS5.SSS1.p1">
<p class="ltx_p" id="S5.SS5.SSS1.p1.1">The final phase of the experimental section is the ”Life status after discharge from the ICU prediction task”. This task requires the LLM to predict the life status of patients starting from their time in the ICU based on complex time-series medical data, offering a comprehensive assessment of the LLM’s advanced reasoning abilities. The experiment still selects three LLM models for testing. However, the difference is that we will fine-tune GPT3.5Turbo and then conduct zero-shot learning tests on the other two LLM models. Firstly, we selected 100 patients from the database, of which 50 had a status of deceased upon leaving the ICU and the other 50 were alive. We used these 100 data samples to fine-tune GPT3.5Turbo and then tested the three models with another 10 patient examples. In this experiment, the patient data we provide to the LLM includes basic patient information, diseases suffered, diagnosis and treatment information with time markers, and the maximum, minimum, average, and median values of the patient’s vital periodic data from the previous treatment phase. We then ask the LLM, based on its analysis of all the current patient information, what is the most likely life status of the patient after leaving the ICU.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Fine-tuning Sample Data</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T6.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.1.1.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S5.T6.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.1.1.1.1">
<span class="ltx_p" id="S5.T6.1.1.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="S5.T6.1.1.1.1.1.1.1" style="font-size:70%;">{{<span class="ltx_text ltx_font_italic" id="S5.T6.1.1.1.1.1.1.1.1">’patientunitstayid’: 761802, \\</span></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.2.2">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T6.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.2.2.1.1">
<span class="ltx_p" id="S5.T6.1.2.2.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T6.1.2.2.1.1.1.1" style="font-size:70%;">’messages’: [<span class="ltx_text ltx_font_upright" id="S5.T6.1.2.2.1.1.1.1.1">{</span>’role’: ’system’, \\</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.3.3">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T6.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.3.3.1.1">
<span class="ltx_p" id="S5.T6.1.3.3.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T6.1.3.3.1.1.1.1" style="font-size:70%;">’content’: ’You are a medical treatment assistant.’<span class="ltx_text ltx_font_upright" id="S5.T6.1.3.3.1.1.1.1.1">}</span>, \\</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.4.4">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T6.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.4.4.1.1">
<span class="ltx_p" id="S5.T6.1.4.4.1.1.1"><span class="ltx_text ltx_font_sansserif" id="S5.T6.1.4.4.1.1.1.1" style="font-size:70%;">{<span class="ltx_text ltx_font_italic" id="S5.T6.1.4.4.1.1.1.1.1">’role’: ’user’,\\</span></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.5.5">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T6.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.5.5.1.1">
<span class="ltx_p" id="S5.T6.1.5.5.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T6.1.5.5.1.1.1.1" style="font-size:70%;">’content’: ’gender: Female, age: 51, disease: Sepsis, pulmonary, ,diagnosis: pulmonary—respiratory failure—acute respiratory failure, renal—disorder of kidney—acute renal failure, cardiovascular—chest pain / ASHD—acute coronary syndrome (offset: 16), treatment: pulmonary—ventilation and oxygenation—mechanical ventilation (Offset: 16), diagnosis: renal—disorder of kidney—acute renal failure, cardiovascular—chest pain / ASHD—acute coronary syndrome, pulmonary—respiratory failure—acute respiratory failure (offset: 227), treatment: pulmonary—ventilation and oxygenation—mechanical ventilation (Offset: 227), vitalperiodic: sao2: 98.62162162162163(mean) 99.0(median) 100.0(max) 96.0(min), heartrate: 106.13513513513513(mean) 105.0(median) 116.0(max) 103.0(min), respiration: 20.486486486486488(mean) 22.0(median) 23.0(max) 16.0(min), diagnosis: renal—disorder of kidney—acute renal failure, pulmonary—respiratory failure—acute respiratory failure, cardiovascular—shock / hypotension—sepsis, cardiovascular—chest pain / ASHD—acute coronary syndrome (offset: 1086), treatment: pulmonary—ventilation and oxygenation—mechanical ventilation (Offset: 1086), vitalperiodic: sao2: 96.125(mean) 96.0(median) 100.0(max) 90.0(min), heartrate: 103.29807692307692(mean) 104.0(median) 132.0(max) 80.0(min), respiration: 18.85576923076923(mean) 19.0(median) 25.0(max) 13.0(min), diagnosis: cardiovascular—shock / hypotension—sepsis, renal—disorder of kidney—acute renal failure, cardiovascular—chest pain / ASHD—acute coronary syndrome, pulmonary—respiratory failure—acute respiratory failure (offset: 1505), patient’s status after discharge?’<span class="ltx_text ltx_font_upright" id="S5.T6.1.5.5.1.1.1.1.1">}</span>, \\</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.6.6">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r" id="S5.T6.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.6.6.1.1">
<span class="ltx_p" id="S5.T6.1.6.6.1.1.1"><span class="ltx_text ltx_font_sansserif" id="S5.T6.1.6.6.1.1.1.1" style="font-size:70%;">{<span class="ltx_text ltx_font_italic" id="S5.T6.1.6.6.1.1.1.1.1">’role’: ’assistant’, ’content’: ’status: Alive.’</span>}<span class="ltx_text ltx_font_italic" id="S5.T6.1.6.6.1.1.1.1.2">
]</span>}</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S5.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>prediction task prompting</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T7.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T7.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S5.T7.3.3.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T7.3.3.3.3">
<span class="ltx_para" id="S5.T7.2.2.2.2.p2">
<span class="ltx_p" id="S5.T7.2.2.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T7.1.1.1.1.p1">
<span class="ltx_p" id="S5.T7.1.1.1.1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.T7.1.1.1.1.p1.1.1" style="font-size:70%;">USER:</span><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T7.1.1.1.1.p1.1.2" style="font-size:70%;"></span></span>
</span>
<span class="ltx_para" id="S5.T7.3.3.3.3.p3">
<span class="ltx_p" id="S5.T7.3.3.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T7.3.3.3.3.p3.1.1" style="font-size:70%;">This is the diagnosis information and treatment information of an ICU patient. Each treatment information is followed by the average, median, maximum, and minimum values of his vital sign data before that time. Based on this information, I need You determine the patient’s status(lived or dead) after discharge from ICU:</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S5.T7.6.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.7.1.1.1">
<span class="ltx_p" id="S5.T7.6.7.1.1.1.1" style="width:173.4pt;">   <span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T7.6.7.1.1.1.1.1" style="font-size:70%;">’patientunitstayid’: 761802,……</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S5.T7.6.6.3"><span class="ltx_inline-logical-block ltx_align_top" id="S5.T7.6.6.3.3">
<span class="ltx_para" id="S5.T7.5.5.2.2.p2">
<span class="ltx_p" id="S5.T7.5.5.2.2.p2.1" style="width:173.4pt;"></span>
</span>
<span class="ltx_para ltx_noindent" id="S5.T7.4.4.1.1.p1">
<span class="ltx_p" id="S5.T7.4.4.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.T7.4.4.1.1.p1.1.1">LLM:</span></span>
</span>
<span class="ltx_para" id="S5.T7.6.6.3.3.p3">
<span class="ltx_p" id="S5.T7.6.6.3.3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_italic" id="S5.T7.6.6.3.3.p3.1.1" style="font-size:70%;">Given the provided information and noting that this is a hypothetical scenario, I can make a speculative prediction ……</span></span>
</span></span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS5.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS5.SSS2.4.1.1">V-E</span>2 </span>Result</h4>
<div class="ltx_para" id="S5.SS5.SSS2.p1">
<p class="ltx_p" id="S5.SS5.SSS2.p1.1">The experimental results show that in the experiment involving 10 patients, GPT-4 successfully predicted the status of patients leaving the ICU 7 times, accompanied by detailed reasoning analysis, demonstrating its exceptional advanced reasoning ability in complex and diverse medical data. In contrast, LLama2 successfully predicted the patients’ status four times. However, based on the results, LLama2 seems to lean towards predicting the patient’s status as alive. In this task, due to the inherent ethical attributes of the LLM, predicting survival seems to be an easier decision than predicting a patient’s death. Predicting a patient’s death upon leaving the ICU requires more extensive analysis and supporting evidence. Thus, there is still a significant gap in comprehensive advanced reasoning abilities between LLama2 and GPT-4. As for GPT3.5Turbo, the results of this experiment were deemed invalid. The fine-tuned model did not provide any analysis but directly predicted the patient’s status as alive. It seems that it did not learn the relationship between the patient’s health status and the provided diagnosis, treatment information, and vital sign information from the fine-tuning data. Instead, it merely memorized the fine-tuning data. We also tested the non-fine-tuned GPT3.5Turbo, but the model believed that the provided data was insufficient for predicting the task. From this, it can be concluded that there is a considerable difference in the ability to handle complex time-series data between GPT3.5Turbo and both GPT-4 and LLama2.</p>
</div>
<figure class="ltx_table" id="S5.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Prediction Task Result</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T8.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T8.1.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.1.1.1.1" style="font-size:90%;">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.1.1.2.1" style="font-size:90%;">Pre@A</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.1.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.1.1.3.1" style="font-size:90%;">Recall@A</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.1.1.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.1.1.4.1" style="font-size:90%;">Pre@D</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.1.1.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.1.1.5.1" style="font-size:90%;">Precision@D</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T8.1.2.2.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.2.2.1.1" style="font-size:90%;">GPT4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.2.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.2.2.2.1" style="font-size:90%;">0.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.2.2.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.2.2.3.1" style="font-size:90%;">0.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.2.2.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.2.2.4.1" style="font-size:90%;">0.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.2.2.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.2.2.5.1" style="font-size:90%;">0.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T8.1.3.3.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.3.3.1.1" style="font-size:90%;">GPT3.5Turbo</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.3.3.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.3.3.2.1" style="font-size:90%;">1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.3.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.3.3.3.1" style="font-size:90%;">1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.3.3.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.3.3.4.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.3.3.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.3.3.5.1" style="font-size:90%;">0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S5.T8.1.4.4.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.4.4.1.1" style="font-size:90%;">LLama2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T8.1.4.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.4.4.2.1" style="font-size:90%;">0.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T8.1.4.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.4.4.3.1" style="font-size:90%;">0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T8.1.4.4.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.4.4.4.1" style="font-size:90%;">0.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T8.1.4.4.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S5.T8.1.4.4.5.1" style="font-size:90%;">0.2</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Overall Analysis</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">GPT4 excelled in high-order reasoning across all experimental sections, outperforming LLama2, which lagged due to its lower complexity with only 70 billion parameters compared to GPT4’s 1.76 trillion. GPT3.5 Turbo struggled in high-level reasoning, often failing to generate reliable results, especially with limited data. Its performance gap with GPT4 is significant, as highlighted in OpenAI’s technical reports emphasizing GPT4’s advanced reasoning in fields like mathematics, law, and medicine. Unlike traditional deep learning, LLMs offer some explainability in their reasoning processes, allowing for insights into their decision-making.</p>
</div>
<figure class="ltx_figure" id="S6.F14">
<p class="ltx_p ltx_align_center" id="S6.F14.1"><span class="ltx_text" id="S6.F14.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="180" id="S6.F14.1.1.g1" src="extracted/5577979/F1.png" width="299"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Overall performance</figcaption>
</figure>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">The research introduced advanced reasoning tasks in complex ICU contexts, employing a real ICU dataset to evaluate LLMs using a new contrast framework. This framework gauged LLMs’ higher-order reasoning, showcasing their strength in the medical field. The study leveraged system messages, prompt engineering, few-shot, and zero-shot learning, alongside fine-tuning, to enhance LLMs’ reasoning as medical assistants.
Results showed LLMs’ proficiency in ”What-if” scenarios, indicating quicker treatment planning than human doctors, thereby suggesting potential to improve ICU resource utilization and patient outcomes. In ”Why-not” scenarios, LLMs generated alternative treatment options, which could increase survival chances when initial plans were suboptimal. The ”So-What” scenarios highlighted LLMs’ capability to scrutinize the reasoning behind treatment plans, offering a supplementary analysis tool for doctors. In ”How-about” scenarios, LLMs demonstrated adaptability by assessing treatments’ transferability to similar diseases, aiding decision-making in dynamic medical settings.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">In the final task of comprehensive high-order reasoning, the LLM demonstrated its capability to predict a patient’s life status after leaving the ICU based on complex medical time-series data. When the LLM acts as an assistant during ICU treatment, it can even monitor a patient’s diagnosis, treatment, and vital sign data in real-time, thereby providing a rough prediction of the patient’s status after leaving the ICU. This prediction can serve as a warning or alert for medical staff. It enables healthcare personnel to monitor patients who may be at risk of death after leaving the ICU more closely and analyze treatment plans more comprehensively, aiming to increase the patient’s chances of survival.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">These findings revealed that LLMs could match human doctors’ reasoning in complex ICU scenarios. GPT4, in particular, aligned closely with physicians, accurately predicting patient outcomes post-ICU with 70% accuracy. Although LLama2 showed promise, it fell short of human-level reasoning. GPT3.5Turbo struggled with complex data, underperforming in stability and accuracy. The findings suggest that robust LLMs can adapt well to ICU tasks through zero-shot learning, even outperforming less sophisticated LLMs that have been fine-tuned.</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S7.SS1.4.1.1">VII-A</span> </span><span class="ltx_text ltx_font_italic" id="S7.SS1.5.2">Ethic Statement</span>
</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">The study used simulated ICU scenarios from the eICU database to assess LLMs’ high-order medical reasoning. It was purely simulation-based, not involving real ICU patients, the database comes from PhysioNet, and comply with the requirements of PhysioNet Credentialed Health Data Use Agreement, acknowledging that actual clinical deployment requires rigorous ethical and clinical validation. The research demonstrates LLMs’ potential in medical reasoning within a controlled environment, not implying readiness for clinical application. The transition to clinical use requires overcoming numerous challenges, including real-time data handling and system integration. The study’s aim is to understand LLMs’ capabilities for medical education, where they could enhance learning and decision-making skills for medical students, serving as interactive teaching aids for improved medical training.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. Daniel, Thinking, fast and slow, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P. D. Gopalan, S. Pershad, Decision-making in icu – a systematic review of factors considered important by icu clinician decision makers with regard to icu triage decisions, Journal of Critical Care 50 (2019) 99–110.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
P. Hacker, A. Engel, T. List, Understanding and regulating chatgpt, and other large generative ai models, Verfassungsblog (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L. Khedher, J. Ramírez, J. M. Górriz, A. Brahim, F. Segovia, A. s Disease Neuroimaging Initiative, et al., Early diagnosis of alzheimer’ s disease based on partial least squares, principal component analysis and support vector machine using segmented mri images, Neurocomputing 151 (2015) 139–150.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
M. Fiszman, W. W. Chapman, D. Aronsky, R. S. Evans, P. J. Haug, Automatic detection of acute bacterial pneumonia from chest x-ray reports, Journal of the American Medical Informatics Association 7 (6) (2000) 593–604.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
N. Afzal, S. Sohn, S. Abram, C. G. Scott, R. Chaudhry, H. Liu, I. J. Kullo, A. M. Arruda-Olson, Mining peripheral arterial disease cases from narrative clinical notes using natural language processing, Journal of vascular surgery 65 (6) (2017) 1753–1761.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Q.-Y. Zhong, E. W. Karlson, B. Gelaye, S. Finan, P. Avillach, J. W. Smoller, T. Cai, M. A. Williams, Screening pregnant women for suicidal behavior in electronic medical records: diagnostic codes vs. clinical notes processed by natural language processing, BMC medical informatics and decision making 18 (1) (2018) 1–11.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Wen, et al., Desiderata for delivering nlp to accelerate healthcare ai advancement and a mayo clinic nlp-as-a-service implementation, NPJ digital medicine 2 (1) (2019) 130.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Carriere, H. Shafi, K. Brehon, K. Pohar Manhas, K. Churchill, C. Ho, M. Tavakoli, Case report: utilizing ai and nlp to assist with healthcare and rehabilitation during the covid-19 pandemic, Frontiers in Artificial Intelligence 4 (2021) 613637–613637.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
N. Tvardik, I. Kergourlay, A. Bittar, F. Segond, S. Darmoni, M.-H. Metzger, Accuracy of using natural language processing methods for identifying healthcare-associated infections, International journal of medical informatics 117 (2018) 96–102.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C. K. Wee, X. Zhou, R. Sun, R. Gururajan, X. Tao, Y. Li, N. Wee, Triaging medical referrals based on clinical prioritisation criteria using machine learning techniques, Int. J. Environ. Res. Public Health 19 (12) (2022) 7384.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A. Tsoukalas, T. Albertson, I. Tagkopoulos, From data to optimal decision making: A data-driven, probabilistic machine learning approach to decision support for patients with sepsis, JMIR Medical Informatics 3 (1) (2015) e11–e11.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, I. Polosukhin, Attention is all you need, Advances in neural information processing systems 30 (2017).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L. Floridi, M. Chiriatti, Gpt-3: Its nature, scope, limits, and consequences, Minds and Machines 30 (2020) 681–694.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Gilson, C. Safranek, T. Huang, V. Socrates, L. Chi, R. A. Taylor, D. Chartash, How well does chatgpt do when taking the medical licensing exams? the implications of large language models for medical education and knowledge assessment, medRxiv (2022) 2022–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. T. Makhoul, M. E. Pontell, N. G. Kumar, B. C. Drolet, Objective measures needed – program directors’ perspectives on a pass/fail usmle step 1, The New England journal of medicine 382 (25) (2020) 2389–2392.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
T. H. Kung, M. Cheatham, A. Medenilla, C. Sillos, L. DeLeon, C. Elepaño, M. Madriaga, R. Aggabao, G. Diaz-Candido, J. Maningo, V. Tseng, Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models, PLOS Digital Health 2 (2) (2023) e0000198–e0000198.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Brown, Chatgpt is great at taking medical licensing exams. but can it replace doctors?, [Accessed: 22-Mar-2023] (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
OpenAI, Gpt-4 technical report (2023).

</span>
<span class="ltx_bibblock">arXiv:2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
H. Nori, N. King, S. M. McKinney, D. Carignan, E. Horvitz, Capabilities of gpt-4 on medical challenge problems, arXiv preprint arXiv:2303.13375 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Zhang, K. Sun, A. Jagadeesh, M. Ghahfarokhi, D. Gupta, A. Gupta, V. Gupta, Y. Guo, The potential and pitfalls of using a large language model such as chatgpt or gpt-4 as a clinical assistant, arXiv preprint arXiv:2307.08152 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F. Tan, D. S. W. Ting, Large language models in medicine, Nature Medicine 29 (2023) 1930–1940, 14k Accesses, 12 Citations, 59 Altmetric.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl, et al., Large language models encode clinical knowledge, arXiv preprint arXiv:2212.13138 (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A. Kong, S. Zhao, H. Chen, Q. Li, Y. Qin, R. Sun, X. Zhou, Better zero-shot reasoning with role-play prompting, arXiv preprint arXiv:2308.07702 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, G. Neubig, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing, ACM Computing Surveys 55 (9) (2023) 1–35.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. Elnashar, J. Spencer-Smith, D. C. Schmidt, A prompt pattern catalog to enhance prompt engineering with chatgpt, arXiv preprint arXiv:2302.11382 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
E. Perez, D. Kiela, K. Cho, True few-shot learning with language models, Advances in neural information processing systems 34 (2021) 11054–11070.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y. Wang, Q. Yao, J. T. Kwok, L. M. Ni, Generalizing from a few examples: A survey on few-shot learning, ACM computing surveys (csur) 53 (3) (2020) 1–34.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, Q. V. Le, Finetuned language models are zero-shot learners, arXiv preprint arXiv:2109.01652 (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, Y. Iwasawa, Large language models are zero-shot reasoners, Advances in neural information processing systems 35 (2022) 22199–22213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
F. Amato, S. Marrone, V. Moscato, G. Piantadosi, A. Picariello, C. Sansone, et al., Chatbots meet ehealth: Automatizing healthcare, in: WAIAH@ AI* IA, 2017, pp. 40–49.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
I.-C. Hsu, J.-D. Yu, A medical chatbot using machine learning and natural language understanding, Multimedia tools and applications 81 (17) (2022) 23777–23799.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
P. Ni, R. Okhrati, S. Guan, V. Chang, Knowledge graph and deep learning-based text-to-graphql model for intelligent medical consultation chatbot, Information Systems Frontiers (2022) 1–20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A. Sato, E. Haneda, N. Suganuma, H. Narimatsu, Preliminary screening for hereditary breast and ovarian cancer using a chatbot augmented intelligence genetic counselor: Development and feasibility study, JMIR Formative Research 5 (2) (2021) e25184.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Q. Bao, L. Ni, J. Liu, Hhh: An online medical chatbot system based on knowledge graph and hierarchical bi-directional attention, in: ACM International Conference Proceeding Series, 2020, pp. 1–10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
A. Lewis, D. Smith, Defining higher order thinking, Theory Into Practice 32 (3) (1993) 131–137.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
B. Council, Higher order thinking skills (hots), accessed March 6, 2023 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
N. E. Adams, Bloom’s taxonomy of cognitive learning objectives, Journal of the Medical Library Association 103 (3) (2015) 152–153.

</span>
<span class="ltx_bibblock">doi:10.3163/1536-5050.103.3.010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
L. E. Richland, N. Simms, Analogy, higher order thinking, and education, Wiley Interdisciplinary Reviews: Cognitive Science 6 (2) (2015) 177–192.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
R. K. Sinha, A. D. Roy, N. Kumar, H. Mondal, Applicability of chatgpt in assisting to solve higher order problems in pathology, in: Monitoring Editor: Alexander Muacevic and John R Adler, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
T. J. Pollard, A. E. Johnson, J. D. Raffa, L. A. Celi, R. G. Mark, O. Badawi, The eicu collaborative research database, a freely available multi-center database for critical care research, Scientific data 5 (1) (2018) 1–13.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
A. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng, M. Ghassemi, B. Moody, P. Szolovits, L. Anthony Celi, R. G. Mark, Mimic-iii, a freely accessible critical care database, Scientific data 3 (1) (2016) 1–9.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
X. Li, C. Zou, R. Boots, S. Wang, W. Chen, G. Zuccon, Artificial intelligence in evidence-based medicine: Challenges and opportunities, World Scientific Annual Review of Artificial Intelligence (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., Language models are few-shot learners, Advances in neural information processing systems 33 (2020) 1877–1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al., Llama 2: Open foundation and fine-tuned chat models, arXiv preprint arXiv:2307.09288 (2023).

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun May  5 17:29:03 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
