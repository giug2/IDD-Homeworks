<article class="ltx_document ltx_authors_1line ltx_leqno">
 <h1 class="ltx_title ltx_title_document">
  A Prompt Learning Framework for Source Code Summarization
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Weisong Sun
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:weisongsun@ntu.edu.sg">
      weisongsun@ntu.edu.sg
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0001-9236-8264" target="_blank" title="ORCID identifier">
      0000-0001-9236-8264
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">
      School of Computer Science and Engineering, Nanyang Technological University
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id2.2.id2">
      50 Nanyang Avenue
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id3.3.id3">
      Singapore
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id4.4.id4">
      639798
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Chunrong Fang
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:fangchunrong@nju.edu.cn">
      fangchunrong@nju.edu.cn
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-9930-7111" target="_blank" title="ORCID identifier">
      0000-0002-9930-7111
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">
      State Key Laboratory for Novel Software Technology, Nanjing University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id6.2.id2">
      Nanjing
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id7.3.id3">
      Jiangsu
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id8.4.id4">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id9.5.id5">
      210093
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yudu You
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:nju%CB%99yyd@163.com">
      nju˙yyd@163.com
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0009-0006-2193-3696" target="_blank" title="ORCID identifier">
      0009-0006-2193-3696
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">
      State Key Laboratory for Novel Software Technology, Nanjing University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id11.2.id2">
      Nanjing
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id12.3.id3">
      Jiangsu
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id13.4.id4">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id14.5.id5">
      210093
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yuchen Chen
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:yuc.chen@outlook.com">
      yuc.chen@outlook.com
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-3380-5564" target="_blank" title="ORCID identifier">
      0000-0002-3380-5564
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id15.1.id1">
      State Key Laboratory for Novel Software Technology, Nanjing University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id16.2.id2">
      Nanjing
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id17.3.id3">
      Jiangsu
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id18.4.id4">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id19.5.id5">
      210093
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yi Liu
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:yi009@e.ntu.edu.sg">
      yi009@e.ntu.edu.sg
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-4978-127X" target="_blank" title="ORCID identifier">
      0000-0002-4978-127X
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id20.1.id1">
      School of Computer Science and Engineering, Nanyang Technological University
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id21.2.id2">
      50 Nanyang Avenue
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id22.3.id3">
      Singapore
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id23.4.id4">
      639798
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Chong Wang
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:chong.wang@ntu.edu.sg">
      chong.wang@ntu.edu.sg
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0003-1424-6290" target="_blank" title="ORCID identifier">
      0000-0003-1424-6290
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id24.1.id1">
      School of Computer Science and Engineering, Nanyang Technological University
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id25.2.id2">
      50 Nanyang Avenue
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id26.3.id3">
      Singapore
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id27.4.id4">
      639798
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Jian Zhang
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:jian%CB%99zhang@ntu.edu.sg">
      jian˙zhang@ntu.edu.sg
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0001-8316-1894" target="_blank" title="ORCID identifier">
      0000-0001-8316-1894
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id28.1.id1">
      School of Computer Science and Engineering, Nanyang Technological University
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id29.2.id2">
      50 Nanyang Avenue
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id30.3.id3">
      Singapore
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id31.4.id4">
      639798
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Quanjun Zhang
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:quanjun.zhang@smail.nju.edu.cn">
      quanjun.zhang@smail.nju.edu.cn
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-2495-3805" target="_blank" title="ORCID identifier">
      0000-0002-2495-3805
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id32.1.id1">
      State Key Laboratory for Novel Software Technology, Nanjing University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id33.2.id2">
      Nanjing
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id34.3.id3">
      Jiangsu
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id35.4.id4">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id36.5.id5">
      210093
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Hanwei Qian
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:qianhanwei@smail.nju.edu.cn">
      qianhanwei@smail.nju.edu.cn
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0009-0007-9524-1411" target="_blank" title="ORCID identifier">
      0009-0007-9524-1411
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id37.1.id1">
      State Key Laboratory for Novel Software Technology, Nanjing University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id38.2.id2">
      Nanjing
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id39.3.id3">
      Jiangsu
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id40.4.id4">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id41.5.id5">
      210093
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Wei Zhao
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:zachwei@tencent.com">
      zachwei@tencent.com
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-1180-3891" target="_blank" title="ORCID identifier">
      0000-0002-1180-3891
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id42.1.id1">
      Tencent Inc.
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id43.2.id2">
      Shenzhen
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id44.3.id3">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id45.4.id4">
      518054
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yang Liu
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:yangliu@ntu.edu.sg">
      yangliu@ntu.edu.sg
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0001-7300-9215" target="_blank" title="ORCID identifier">
      0000-0001-7300-9215
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id46.1.id1">
      School of Computer Science and Engineering, Nanyang Technological University
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id47.2.id2">
      50 Nanyang Avenue
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id48.3.id3">
      Singapore
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id49.4.id4">
      639798
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   and
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Zhenyu Chen
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:zychen@nju.edu.cn">
      zychen@nju.edu.cn
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-9592-7022" target="_blank" title="ORCID identifier">
      0000-0002-9592-7022
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id50.1.id1">
      State Key Laboratory for Novel Software Technology, Nanjing University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id51.2.id2">
      Nanjing
     </span>
     <span class="ltx_text ltx_affiliation_state" id="id52.3.id3">
      Jiangsu
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id53.4.id4">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id54.5.id5">
      210093
     </span>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_dates">
  (2023)
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract.
  </h6>
  <p class="ltx_p" id="id55.id1">
   (Source) code summarization is the task of automatically generating natural language summaries (also called comments) for given code snippets. Such summaries play a key role in helping developers understand and maintain source code. Recently, with the successful application of large language models (LLMs) in numerous fields, software engineering researchers have also attempted to adapt LLMs to solve code summarization tasks. The main adaptation schemes include instruction prompting and task-oriented fine-tuning. However, instruction prompting involves designing crafted prompts for zero-shot learning or selecting appropriate samples for few-shot learning and requires users to have professional domain knowledge, while task-oriented fine-tuning requires high training costs.
  </p>
  <p class="ltx_p" id="id56.id2">
   In this paper, we propose a novel prompt learning framework for code summarization called PromptCS. It no longer requires users to rack their brains to design effective prompts. Instead, PromptCS trains a prompt agent that can generate continuous prompts to unleash the potential for LLMs in code summarization. Compared to the human-written discrete prompt, the continuous prompts are produced under the guidance of LLMs and are therefore easier to understand by LLMs. PromptCS is non-invasive to LLMs and freezes the parameters of LLMs when training the prompt agent, which can greatly reduce the requirements for training resources.
We evaluate the effectiveness of PromptCS on the CodeSearchNet dataset involving multiple programming languages. Experimental results show that PromptCS significantly outperforms instruction prompting schemes (including zero-shot learning and few-shot learning) on all four widely used metrics, including BLEU, METEOR, ROUGH-L, and SentenceBERT, and is comparable to the task-oriented fine-tuning scheme.
In some base LLMs, e.g., CodeGen-Multi-2B and StarCoderBase-1B and -3B, PromptCS even outperforms the task-oriented fine-tuning scheme. More importantly, the training efficiency of PromptCS is faster than the task-oriented fine-tuning scheme, with a more pronounced advantage on larger LLMs. The results of the human evaluation demonstrate that PromptCS can generate more good summaries compared to baselines.
  </p>
 </div>
 <div class="ltx_keywords">
  source code summarization, large language model, prompt learning
 </div>
 <span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     copyright:
    </span>
    acmcopyright
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     journalyear:
    </span>
    2023
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journal" id="id3">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     journal:
    </span>
    TOSEM
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journalvolume" id="id4">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     journalvolume:
    </span>
    0
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journalnumber" id="id5">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     journalnumber:
    </span>
    0
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_article" id="id6">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     article:
    </span>
    1
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_publicationmonth" id="id7">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     publicationmonth:
    </span>
    0
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     ccs:
    </span>
    Software and its engineering Software maintenance tools
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1.
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Source code comments play a critical role in facilitating program comprehension
    <cite class="ltx_cite ltx_citemacro_citep">
     (Tenny,
     <a class="ltx_ref" href="#bib.bib61" title="">
      1988
     </a>
     ; Stapleton et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib57" title="">
      2020
     </a>
     ; Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib58" title="">
      2023a
     </a>
     )
    </cite>
    and software maintenance
    <cite class="ltx_cite ltx_citemacro_citep">
     (de Souza et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2005
     </a>
     ; Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     )
    </cite>
    . However, existing research
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib31" title="">
      2018b
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2022b
     </a>
     )
    </cite>
    demonstrates that lack of high-quality code comments is a common problem in the software industry. In addition, comments are often absent, unmatched, and outdated during software evolution
    <cite class="ltx_cite ltx_citemacro_citep">
     (de Souza et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2005
     </a>
     )
    </cite>
    .
These practical problems drive the research on source code summarization. Source code summarization (code summarization for short) is the task of automatically generating code summaries (i.e., comments). Over the past decade, it has always been one of the research hotspots in the field of software engineering
    <cite class="ltx_cite ltx_citemacro_citep">
     (Haiduc et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2010a
     </a>
     ; Eddy et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2013
     </a>
     ; Hu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib29" title="">
      2018a
     </a>
     ; Zhang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib77" title="">
      2020
     </a>
     ; Stapleton et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib57" title="">
      2020
     </a>
     ; Shi et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib55" title="">
      2022
     </a>
     ; Bansal et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2023
     </a>
     ; Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib66" title="">
      2023a
     </a>
     ; Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     ; Tian et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib62" title="">
      2023
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Recently, with the success of large language models (LLMs) in natural language processing (NLP)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Du et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib16" title="">
      2022
     </a>
     ; Qin et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib51" title="">
      2023
     </a>
     )
    </cite>
    , an increasing number of software engineering (SE) researchers have started integrating them into the resolution process of various SE tasks
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chen et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2021
     </a>
     ; Fan et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib18" title="">
      2023
     </a>
     ; Hou et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib27" title="">
      2023
     </a>
     )
    </cite>
    .
Similar to LLMs for NLP (e.g., ChatGPT
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib46" title="">
      2022
     </a>
     )
    </cite>
    and LLaMA
    <cite class="ltx_cite ltx_citemacro_citep">
     (Touvron et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib63" title="">
      2023
     </a>
     )
    </cite>
    ) tasks, there are many LLMs of code for SE tasks, e.g., Codex
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023a
     </a>
     )
    </cite>
    , StarCoder
    <cite class="ltx_cite ltx_citemacro_citep">
     (Li et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib38" title="">
      2023
     </a>
     )
    </cite>
    , CodeGen
    <cite class="ltx_cite ltx_citemacro_citep">
     (Nijkamp et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib45" title="">
      2023
     </a>
     )
    </cite>
    , and PolyCoder
    <cite class="ltx_cite ltx_citemacro_citep">
     (Xu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib75" title="">
      2022
     </a>
     )
    </cite>
    .
In this paper, we pay more attention to the application of LLMs on code summarization tasks. Existing studies demonstrate that LLMs trained on massive corpora of texts have shown their particularly exciting ability to perform new tasks from textual instructions (i.e., in zero-shot learning setting) or from a few examples (i.e., in few-shot learning setting)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      2020
     </a>
     ; Ahmed and Devanbu,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022b
     </a>
     )
    </cite>
    .
Therefore, there have been several recent studies investigating the effectiveness of instruction prompting with zero-shot and few-shot learning in adapting LLMs to code summarization tasks. For example, Sun et al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     )
    </cite>
    evaluate ChatGPT’s performance on zero-shot code summarization tasks. They design several heuristic questions/instructions to collect the feedback of ChatGPT, thereby finding an appropriate prompt to guide ChatGPT to generate in-distribution code summaries. However, their experimental results on the large-scale CSN-Python dataset show that this prompt fails to induce ChatGPT to generate satisfactory summaries. We also try this prompt on the CSN-Java dataset and get similar results, detailed in Section
    <a class="ltx_ref" href="#S3" title="3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    .
These results suggest that crafting effective prompts manually is a challenging task, demanding users to possess not only specialized domain knowledge but also a profound understanding of the LLMs being utilized
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib68" title="">
      2023b
     </a>
     ; Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     )
    </cite>
    .
Ahmed et al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ahmed and Devanbu,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022b
     </a>
     )
    </cite>
    investigate the effectiveness of the instruction prompting with few-shot learning in adapting LLMs to code summarization tasks. To discover the appropriate example number for few-shot learning, they try multiple sets of samples with different numbers (including 5, 10, and 15) on a small-scale test dataset. Then, they utilize 10 samples to conduct instruction prompting on a commercial LLM Codex and find it can outperform fine-tuned foundation models (e.g., CodeT5
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib69" title="">
      2021
     </a>
     )
    </cite>
    ).
We utilize the same 10 samples to conduct instruction prompting on open-source LLMs (e.g., StarCoderBase-3B) and find that their performance is still much worse than fine-tuned LLMs, detailed in Section
    <a class="ltx_ref" href="#S3" title="3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    and Section
    <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      5.2.1
     </span>
    </a>
    .
This phenomenon indicates that for few-shot learning, which samples to choose and how many samples to choose require users to make decisions based on professional knowledge and continuous trials.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    Another straightforward scheme to adapt LLMs to better accomplish downstream tasks is through task-oriented fine-tuning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jin et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023
     </a>
     ; Xu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib76" title="">
      2021
     </a>
     )
    </cite>
    . Task-oriented fine-tuning updates the weights of LLMs by training on thousands of supervised labels specific to the desired task. The main advantage of fine-tuning is strong performance on the task benchmark
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      2020
     </a>
     ; Radford et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2019
     </a>
     ; Wei et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib71" title="">
      2022
     </a>
     )
    </cite>
    .
For example, Jin et al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jin et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023
     </a>
     )
    </cite>
    fine-tune Codex with 12 billion (B) on supervised bug-fix data. Although fine-tuning significantly enhances the model’s ability in bug fixing, it comes with a high training cost.
For instance, to conduct full model fine-tuning (updating all weights of Codex), Jin et al. build a training environment consisting of 64 32GB V100 GPUs, which is beyond the reach of many research teams. In this paper, we also experiment with the task-oriented fine-tuning scheme on code summarization tasks, which similarly incurred a high training cost, detailed in Section
    <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      5.2.1
     </span>
    </a>
    . As the size of LLMs continues to grow, the cost of fine-tuning can be quite substantial.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    In this paper, we propose a novel prompt learning framework for code summarization, called PromptCS. The key feature of PromptCS is its ability to free developers from the need to manually design intricate prompts. Specifically, PromptCS devises two collaborating components to achieve this feature, including a prompt agent and an LLM. The prompt agent is responsible for generating the continuous prompt that can induce the capacity of the LLM to perform code summarization tasks.
The core of the prompt agent is a deep learning (DL) based prompt encoder, which takes a pseudo prompt consisting of
    <math alttext="n" class="ltx_Math" display="inline" id="S1.p4.1.m1.1">
     <semantics id="S1.p4.1.m1.1a">
      <mi id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">
       n
      </mi>
      <annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b">
       <ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">
        𝑛
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">
       n
      </annotation>
     </semantics>
    </math>
    learnable tokens as input and produces a prompt embedding (i.e., continuous prompt).
The prompt agent is trained under the guidance of the LLM. Therefore, the well-trained prompt agent can produce a continuous prompt that is more suitable for the LLM than the human-written discrete prompt. More importantly, unlike the task-oriented fine-tuning scheme that changes the parameters of the LLMs, PromptCS is non-invasive to LLMs. PromptCS freezes the parameters of LLMs during the training process and only updates the parameters of the prompt agent, which can greatly reduce the requirements for training resources.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    In summary, we make the following contributions.
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       We propose a novel prompt learning framework for code summarization called PromptCS. PromptCS is able to generate high-quality summaries for input code snippets. In addition, PromptCS is a general framework and can be combined with multiple LLMs (see experimental results in Section
       <a class="ltx_ref" href="#S5.SS2.SSS3" title="5.2.3. RQ3. Influence of the network architecture used in the prompt encoder on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
        <span class="ltx_text ltx_ref_tag">
         5.2.3
        </span>
       </a>
       ). We open source the code of PromptCS
       <cite class="ltx_cite ltx_citemacro_citep">
        (Sun et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib59" title="">
         2023b
        </a>
        )
       </cite>
       to facilitate future research and application.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       We conduct extensive experiments on a widely used benchmark dataset to evaluate PromptCS. Experimental results show that in terms of all four metrics (i.e., BLEU, METEOR, ROUGE-L, and SentenceBERT), PromptCS significantly outperforms the instruction prompting schemes with zero-shot and few-shot learning, and is comparable to the task-oriented fine-tuning scheme. On some LLMs, e.g., StarCoderBase-1B and StarCoderBase-3B, PromptCS even outperforms the task-oriented fine-tuning scheme. In terms of training cost, PromptCS is significantly lower than the task-oriented fine-tuning scheme. For example, when using the StarCoderBase-7B model as the base LLM, PromptCS takes about 67 hours to train the prompt agent, while the task-oriented fine-tuning scheme takes about 211 hours for one epoch training, detailed in Section
       <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
        <span class="ltx_text ltx_ref_tag">
         5.2.1
        </span>
       </a>
       .
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       We conduct a qualitative human evaluation to evaluate the summaries generated by PromptCS and baselines (including instruct prompting schemes with zero-shot and few-shot learning and the task-oriented fine-tuning scheme. The statistical results of human scores show that compared with baselines, the summaries generated by PromptCS are more similar to the ground-truth summaries (detailed in Section
       <a class="ltx_ref" href="#S5.SS2.SSS6" title="5.2.6. RQ6. PromptCS’s performance in human evaluation ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
        <span class="ltx_text ltx_ref_tag">
         5.2.6
        </span>
       </a>
       ).
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2.
   </span>
   background
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1.
    </span>
    Code Summarization
   </h3>
   <figure class="ltx_figure" id="S2.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="149" id="S2.F1.g1" src="/html/2312.16066/assets/x1.png" width="368"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 1.
     </span>
     An example of a code snippet and its summary
    </figcaption>
   </figure>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     Code summarization is the task of automatically generating natural language summaries for code snippets given by the developer. Such summaries are also called comments and explain the functionality of the code snippet
     <cite class="ltx_cite ltx_citemacro_citep">
      (Moore et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib43" title="">
       2019
      </a>
      ; Hu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2020
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib32" title="">
       2022b
      </a>
      )
     </cite>
     . Figure
     <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1. Code Summarization ‣ 2. background ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     shows an example. The code snippet
     <math alttext="c_{1}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1">
      <semantics id="S2.SS1.p1.1.m1.1a">
       <msub id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">
        <mi id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">
         c
        </mi>
        <mn id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">
         1
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b">
        <apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">
          𝑐
         </ci>
         <cn id="S2.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.1.m1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">
        c_{1}
       </annotation>
      </semantics>
     </math>
     in Figure
     <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1. Code Summarization ‣ 2. background ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     (a) is provided by the developer. The summary “destroy kills the connection and drops it from the connection pool. destroy should only occur if the connection state machine has failed.” in Figure
     <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1. Code Summarization ‣ 2. background ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     (b) is a summary that satisfies the developer’s requirement.
The research on code summarization can be traced back to as early as 2010 when Sonia Haiduc et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Haiduc et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2010a
      </a>
      )
     </cite>
     introduced automated text summarization technology to summarize source code to support program comprehension.
Later on, following the significant success of neural machine translation (NMT) research in the field of NLP
     <cite class="ltx_cite ltx_citemacro_citep">
      (Cho et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2014a
      </a>
      ; Bahdanau et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       2015
      </a>
      )
     </cite>
     , a large number of researchers migrate its underlying DL-based encoder-decoder architecture to code summarization tasks
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib77" title="">
       2020
      </a>
      ; Gros et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2020
      </a>
      ; Ahmad et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib2" title="">
       2020
      </a>
      ; Shi et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib55" title="">
       2022
      </a>
      ; Sun et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib58" title="">
       2023a
      </a>
      ; Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib66" title="">
       2023a
      </a>
      ; Bansal et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2023
      </a>
      )
     </cite>
     . In the past ten years, code summarization has always been one of the hot research directions in the field of software engineering. In this paper, similar to
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ahmed and Devanbu,
      <a class="ltx_ref" href="#bib.bib5" title="">
       2022b
      </a>
      ; Sun et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib60" title="">
       2023c
      </a>
      ; Tian et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib62" title="">
       2023
      </a>
      )
     </cite>
     , we focus on adapting LLMs for code summarization tasks.
More details of related works are discussed in Section
     <a class="ltx_ref" href="#S7.SS1" title="7.1. Code Summarization ‣ 7. Related Work ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       7.1
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2.
    </span>
    Large Language Model
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Existing research
     <cite class="ltx_cite ltx_citemacro_citep">
      (Kaplan et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2020
      </a>
      )
     </cite>
     demonstrates that scaling pre-trained language models (PLMs), e.g., increasing model size, can enhance model capacity for solving downstream tasks. To distinguish the early small-scale PLMs, more people are now willing to refer to the current generative PLMs with very large-scale parameters (often in the billions) as large language models (LLMs). When utilizing LLMs to accomplish downstream tasks, three components play a crucial role: a tokenizer, an input embedding layer, and module blocks. The tokenizer is responsible for converting the input text into the index representation that the model can understand, serving as a bridge between the input text and the model. The primary function of the input embedding layers is to transform the index representation into vector representations (also called embeddings). This process may involve techniques like word embeddings
     <cite class="ltx_cite ltx_citemacro_citep">
      (Pennington et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib50" title="">
       2014
      </a>
      )
     </cite>
     and positional encodings
     <cite class="ltx_cite ltx_citemacro_citep">
      (Vaswani et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib64" title="">
       2017
      </a>
      )
     </cite>
     to capture vocabulary and positional information. These techniques enhance the input embedding layer’s ability to transform discrete data into meaningful continuous embeddings, facilitating subsequent processing. In the module blocks, the neural network structure is carefully designed to efficiently capture the complex relationships within embeddings. These blocks typically consist of multiple layers, with each layer responsible for processing different levels of features and abstract representations.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     Currently, LLMs can be mainly divided into three categories: auto-regressive language models, masked language models, and encoder-decoder language models
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib75" title="">
       2022
      </a>
      )
     </cite>
     . The auto-regressive language models generate sequences based on the outputs from previous time steps. They are powerful for modeling the probability of sequences. In the code summarization task, the model recursively predicts each word to generate a code summary. The currently popular LLMs all belong to this category, such as GPT series
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib48" title="">
       2023b
      </a>
      )
     </cite>
     , Codex
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023a
      </a>
      )
     </cite>
     , StarCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2023
      </a>
      )
     </cite>
     , CodeGen
     <cite class="ltx_cite ltx_citemacro_citep">
      (Nijkamp et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023
      </a>
      )
     </cite>
     , PolyCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib75" title="">
       2022
      </a>
      )
     </cite>
     , and CodeLlama
     <cite class="ltx_cite ltx_citemacro_citep">
      (Rozière et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib54" title="">
       2023
      </a>
      )
     </cite>
     . The masked language model can transform a given sequence into effective representations. They are trained using masked language modeling, a popular bidirectional objective function that aims to predict masked text pieces based on the surrounding context. Most of the early PLMs fall into this category, such as CodeBERT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Feng et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2020
      </a>
      )
     </cite>
     , UniXCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Guo et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib22" title="">
       2022
      </a>
      )
     </cite>
     , and GraphCodeBERT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Guo et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib23" title="">
       2021
      </a>
      )
     </cite>
     . The encoder-decoder language models consist of a structure with two main components, i.e., encoder and decoder. The encoder is responsible for transforming the input sequence into an intermediate representation, while the decoder utilizes this intermediate representation to generate the output sequence. CodeT5
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib69" title="">
       2021
      </a>
      )
     </cite>
     and PLBART
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ahmad et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2021
      </a>
      )
     </cite>
     are examples of such models in code.
In recent times, the impact of LLMs has been truly transformative, revolutionizing both academic research and various industrial applications. In this paper, we focus on the application of autoregressive LLMs in software engineering, particularly in code summarization.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3.
   </span>
   Motivation
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    In this section, we elaborate on the shortcomings of the latest schemes for adapting LLMs to code summary tasks as the motivation for us to propose a new scheme. To facilitate understanding the effect of each scheme, we perform the task-oriented fine-tuning scheme on an LLM called StarCoderBase-3B on the CSN-Java dataset and use its results as a reference. Existing works
    <cite class="ltx_cite ltx_citemacro_citep">
     (Radford et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2019
     </a>
     ; Wei et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib71" title="">
      2022
     </a>
     ; Weyssow et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib72" title="">
      2023
     </a>
     )
    </cite>
    demonstrate that LLMs often achieve peak effectiveness and show their full potential when subjected to fine-tuning. Detailed results are shown in row 3 of Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_table" id="S3.T1">
   <figcaption class="ltx_caption ltx_centering" style="font-size:70%;">
    <span class="ltx_tag ltx_tag_table">
     Table 1.
    </span>
    Existing LLM-based methods on code summarization.
   </figcaption>
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S3.T1.3">
      <tr class="ltx_tr" id="S3.T1.3.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.3.1.1" rowspan="2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.1.1.1" style="font-size:70%;">
         Method
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.3.1.2" rowspan="2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.1.2.1" style="font-size:70%;">
         Base Model
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.3.1.3" rowspan="2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.1.3.1" style="font-size:70%;">
         Model Size
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T1.3.1.4" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.1.4.1" style="font-size:70%;">
         CSN-Java
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.3.2">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.2.1" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.2.1.1" style="font-size:70%;">
         BLEU
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.2.2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.2.2.1" style="font-size:70%;">
         METEOR
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.2.3" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.2.3.1" style="font-size:70%;">
         ROUGE-L
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.3.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.3.3.1" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.3.1.1" style="font-size:70%;">
         Task-oriented Fin-tuning
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.3.2.1" style="font-size:70%;">
         StarCoderBase
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.3" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.3.3.1" style="font-size:70%;">
         3B
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.4" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.3.4.1" style="font-size:70%;">
         20.43
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.5" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.3.5.1" style="font-size:70%;">
         14.68
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.6" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.3.6.1" style="font-size:70%;">
         39.51
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.3.4">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.3.4.1" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.4.1.1" style="font-size:70%;">
         Instruction Prompting (zero-shot)
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.4.2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.4.2.1" style="font-size:70%;">
         ChatGPT
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.4.3" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.4.3.1" style="font-size:70%;">
         UNK
        </span>
        <sup class="ltx_sup" id="S3.T1.3.4.3.2">
         <span class="ltx_text" id="S3.T1.3.4.3.2.1" style="font-size:70%;">
          1
         </span>
        </sup>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.4.4" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.4.4.1" style="font-size:70%;">
         9.57
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.4.5" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text ltx_font_bold" id="S3.T1.3.4.5.1" style="font-size:70%;">
         14.89
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.4.6" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.4.6.1" style="font-size:70%;">
         20.75
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.3.5">
       <td class="ltx_td ltx_align_left" id="S3.T1.3.5.1" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.5.1.1" style="font-size:70%;">
         Instruction Prompting (few-shot)
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.3.5.2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.5.2.1" style="font-size:70%;">
         StarCoderBase
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.3.5.3" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.5.3.1" style="font-size:70%;">
         3B
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.3.5.4" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.5.4.1" style="font-size:70%;">
         15.12
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.3.5.5" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.5.5.1" style="font-size:70%;">
         11.64
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.3.5.6" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.5.6.1" style="font-size:70%;">
         29.84
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.3.6">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.3.6.1" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.6.1.1" style="font-size:70%;">
         PromptCS
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.6.2" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.6.2.1" style="font-size:70%;">
         StarCoderBase
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.6.3" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.6.3.1" style="font-size:70%;">
         3B
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.6.4" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text ltx_font_bold" id="S3.T1.3.6.4.1" style="font-size:70%;">
         20.87
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.6.5" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text" id="S3.T1.3.6.5.1" style="font-size:70%;">
         14.50
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.6.6" style="padding-left:2.5pt;padding-right:2.5pt;">
        <span class="ltx_text ltx_font_bold" id="S3.T1.3.6.6.1" style="font-size:70%;">
         40.23
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S3.I1">
      <li class="ltx_item" id="S3.I1.ix1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        1
       </span>
       <div class="ltx_para" id="S3.I1.ix1.p1">
        <p class="ltx_p" id="S3.I1.ix1.p1.1">
         <span class="ltx_text" id="S3.I1.ix1.p1.1.1" style="font-size:80%;">
          OpenAI has not disclosed the specific parameter scale of ChatGPT.
         </span>
        </p>
       </div>
      </li>
     </ul>
    </div>
   </div>
  </figure>
  <div class="ltx_para" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    As mentioned in Section
    <a class="ltx_ref" href="#S1" title="1. Introduction ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    , currently, there are several schemes available for researchers to adapt LLMs to code summarization tasks. Among them, the most prominent approach is instruction prompting with zero-shot/few-shot learning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ahmed and Devanbu,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022b
     </a>
     ; Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     ; Bhattacharya et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     )
    </cite>
    .
For example, Sun et al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     )
    </cite>
    adopt instruction prompting with zero-shot learning to induce ChatGPT to complete code summarization tasks. To gain a suitable prompt, they try out various prompts by adjusting details such as language choice and grammatical structure. After many complicated attempts, they finally find an appropriate prompt that can be used to guide ChatGPT to generate in-distribution comments, that is “
    <em class="ltx_emph ltx_font_italic" id="S3.p2.1.1">
     Please generate a short comment in one sentence for the following function:¡code¿
    </em>
    ”. We utilize this prompt to guide ChatGPT in generating summaries for code snippets in the CSN-Java dataset, and results are shown in row 4 of Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    . From Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    , it can be observed that the results of ChatGPT are similar to those on the CSN-Python dataset shown in their paper
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     )
    </cite>
    (10.28 in BLEU, 14.40 in METEOR, and 20.81 in ROUGE-L), which are both unsatisfactory compared to the task-oriented fine-tuning results. It indicates that even professional researchers in the field of code summarization have difficulty designing good prompts.
   </p>
  </div>
  <div class="ltx_para" id="S3.p3">
   <p class="ltx_p" id="S3.p3.1">
    Apart from the work
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sun et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023c
     </a>
     )
    </cite>
    , Ahmed et al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ahmed and Devanbu,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022b
     </a>
     )
    </cite>
    investigate the effectiveness of instruction prompting with few-shot learning for code summarization tasks. They conduct few-shot learning on a commercial LLM of code called Codex
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023a
     </a>
     )
    </cite>
    , and find it can significantly outperform a fine-tuned model trained with thousands of samples with just ten samples. We experiment with the same few-shot learning samples on multiple open-source LLMs of code. Row 4 of Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    shows the experimental results on StarCoderBase-3B. Observe that although compared with the instruction prompting with zero-shot learning, the instruction prompting with few-shot learning can improve the performance of the LLM on code summarization in terms of BLEU and ROUGE-L, it is still much worse than the task-oriented fine-tuning results. It means that for the instruction prompting with few-shot learning scheme, selecting appropriate code summarization samples for few-shot learning is also a complex task. Deciding which and how many samples to select requires expertise in the field and trial and error.
   </p>
  </div>
  <div class="ltx_para" id="S3.p4">
   <p class="ltx_p" id="S3.p4.1">
    Task-oriented fine-tuning is also a straightforward idea to adapt LLMs to downstream tasks. However, unlike instruction prompting schemes that are non-invasive to LLMs, the fine-tuning process involves updating and storing the parameters of LLMs. In practical applications, researchers and practitioners may need to invest significant resources to complete the fine-tuning process to ensure the fine-tuned LLMs perform well in a specific domain or downstream task. Task-oriented fine-tuning is very time-consuming, especially when there are few training resources available. For instance, our experiments show that it takes more than 200 hours to fine-tune the StarCoder-7B model only for one epoch on a 1-card A800GPU device, detailed in Section
    <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      5.2.1
     </span>
    </a>
    . As LLMs continue to grow in scale, the training time and computational costs associated with task-oriented fine-tuning become increasingly challenging to tolerate. In addition, it should be noted that fine-tuning changes in the parameters of LLMs may affect their performance on other downstream tasks.
   </p>
  </div>
  <div class="ltx_para" id="S3.p5">
   <p class="ltx_p" id="S3.p5.1">
    <span class="ltx_text ltx_font_bold" id="S3.p5.1.1">
     Our solution.
    </span>
    We propose a novel prompt learning framework PromptCS for adapting LLMs to code summarization tasks. Unlike instruction prompting techniques that require complex prompt design or carefully selected samples for few-shot learning, PromptCS trains a prompt agent that can generate continuous prompts inducing LLMs to generate high-quality summaries for given code snippets. Unlike the fine-tuning technique that changes the parameters of the LLMs, PromptCS is also non-invasive to LLMs, freezes the parameters of LLMs, and only updates the parameters of the prompt agent, greatly reducing the requirements for training resources. The last row of Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3. Motivation ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    shows the results of PromptCS on the CSN-Java dataset. Observe that PromptCS significantly outperforms the instruction prompting schemes (including zero-shot learning and few-shot learning) on all three metrics, even surpassing task-oriented fine-tuning on BLEU and ROUGE-L. In Section
    <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      5.2.1
     </span>
    </a>
    , we empirically demonstrate that PromptCS outperforms three state-of-the-art baselines in improving metric scores.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4.
   </span>
   Methodology
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1.
    </span>
    Overview
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.11">
     Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.1. Overview ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     illustrates the overview of PromptCS. The top part shows the training procedure of PromptCS and the bottom part shows the deployment/usage of PromptCS to support the code summarization service. PromptCS consists of two core components: a prompt agent and an LLM. The prompt agent is responsible for generating prompts that induce the LLM to generate natural language summaries for code snippets.
PromptCS is non-invasive to LLMs, that is, the parameters of LLMs are always frozen and remain unchanged during the training procedure. Therefore, in the training procedure of PromptCS, our goal is to obtain a well-trained prompt agent. PromptCS utilizes the training data consisting of pairs of
     <math alttext="\langle" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1">
      <semantics id="S4.SS1.p1.1.m1.1a">
       <mo id="S4.SS1.p1.1.m1.1.1" stretchy="false" xref="S4.SS1.p1.1.m1.1.1.cmml">
        ⟨
       </mo>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b">
        <ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">
         ⟨
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">
        \langle
       </annotation>
      </semantics>
     </math>
     code snippets, ground-truth summaries
     <math alttext="\rangle" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1">
      <semantics id="S4.SS1.p1.2.m2.1a">
       <mo id="S4.SS1.p1.2.m2.1.1" stretchy="false" xref="S4.SS1.p1.2.m2.1.1.cmml">
        ⟩
       </mo>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b">
        <ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">
         ⟩
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">
        \rangle
       </annotation>
      </semantics>
     </math>
     to train the prompt agent.
Specifically, PromptCS decomposes the training of the prompt agent into five steps.
In step \raisebox{-.9pt}{1}⃝, PromptCS feeds code snippets to the LLM, utilizing its input embedding layer to generate the corresponding code embeddings denoted
     <math alttext="\bm{e}^{C}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1">
      <semantics id="S4.SS1.p1.3.m3.1a">
       <msup id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">
        <mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">
         C
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b">
        <apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">
          𝐶
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">
        \bm{e}^{C}
       </annotation>
      </semantics>
     </math>
     , detailed in Section
     <a class="ltx_ref" href="#S4.SS2" title="4.2. Code Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       4.2
      </span>
     </a>
     .
In step \raisebox{-.9pt}{2}⃝, PromptCS feeds a pseudo prompt into a prompt encoder to generate the prompt embedding denoted
     <math alttext="\bm{e}^{P}" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1">
      <semantics id="S4.SS1.p1.4.m4.1a">
       <msup id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">
        <mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">
         P
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b">
        <apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">
          𝑃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">
        \bm{e}^{P}
       </annotation>
      </semantics>
     </math>
     . The pseudo prompt is composed of
     <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1">
      <semantics id="S4.SS1.p1.5.m5.1a">
       <mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">
        n
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b">
        <ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">
         𝑛
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">
        n
       </annotation>
      </semantics>
     </math>
     learnable tokens with no actual meaning.
The prompt encoder is a DL model and is trained along with the prompt agent. Details of this step are explained in Section
     <a class="ltx_ref" href="#S4.SS3" title="4.3. Prompt Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       4.3
      </span>
     </a>
     .
In step \raisebox{-.9pt}{3}⃝, PromptCS concatenates
     <math alttext="\bm{e}^{C}" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1">
      <semantics id="S4.SS1.p1.6.m6.1a">
       <msup id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">
        <mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml">
         C
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b">
        <apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3">
          𝐶
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">
        \bm{e}^{C}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\bm{e}^{P}" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1">
      <semantics id="S4.SS1.p1.7.m7.1a">
       <msup id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">
        <mi id="S4.SS1.p1.7.m7.1.1.2" xref="S4.SS1.p1.7.m7.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml">
         P
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b">
        <apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3">
          𝑃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">
        \bm{e}^{P}
       </annotation>
      </semantics>
     </math>
     together to produce fusion embeddings denoted
     <math alttext="\bm{e}^{F}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.1">
      <semantics id="S4.SS1.p1.8.m8.1a">
       <msup id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">
        <mi id="S4.SS1.p1.8.m8.1.1.2" xref="S4.SS1.p1.8.m8.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.8.m8.1.1.3" xref="S4.SS1.p1.8.m8.1.1.3.cmml">
         F
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b">
        <apply id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.8.m8.1.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.8.m8.1.1.2.cmml" xref="S4.SS1.p1.8.m8.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.8.m8.1.1.3.cmml" xref="S4.SS1.p1.8.m8.1.1.3">
          𝐹
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">
        \bm{e}^{F}
       </annotation>
      </semantics>
     </math>
     . Similar to human-written discrete prompts, our PromptCS is non-invasive to input code snippets, that is, the prompt embedding does not break the integrity of the code embedding. Hence,
     <math alttext="\bm{e}^{P}" class="ltx_Math" display="inline" id="S4.SS1.p1.9.m9.1">
      <semantics id="S4.SS1.p1.9.m9.1a">
       <msup id="S4.SS1.p1.9.m9.1.1" xref="S4.SS1.p1.9.m9.1.1.cmml">
        <mi id="S4.SS1.p1.9.m9.1.1.2" xref="S4.SS1.p1.9.m9.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.9.m9.1.1.3" xref="S4.SS1.p1.9.m9.1.1.3.cmml">
         P
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.1b">
        <apply id="S4.SS1.p1.9.m9.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.9.m9.1.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.9.m9.1.1.2.cmml" xref="S4.SS1.p1.9.m9.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.9.m9.1.1.3.cmml" xref="S4.SS1.p1.9.m9.1.1.3">
          𝑃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.1c">
        \bm{e}^{P}
       </annotation>
      </semantics>
     </math>
     will only be concatenated to the front/back of
     <math alttext="\bm{e}^{C}" class="ltx_Math" display="inline" id="S4.SS1.p1.10.m10.1">
      <semantics id="S4.SS1.p1.10.m10.1a">
       <msup id="S4.SS1.p1.10.m10.1.1" xref="S4.SS1.p1.10.m10.1.1.cmml">
        <mi id="S4.SS1.p1.10.m10.1.1.2" xref="S4.SS1.p1.10.m10.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.10.m10.1.1.3" xref="S4.SS1.p1.10.m10.1.1.3.cmml">
         C
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m10.1b">
        <apply id="S4.SS1.p1.10.m10.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.10.m10.1.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.10.m10.1.1.2.cmml" xref="S4.SS1.p1.10.m10.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.10.m10.1.1.3.cmml" xref="S4.SS1.p1.10.m10.1.1.3">
          𝐶
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.10.m10.1c">
        \bm{e}^{C}
       </annotation>
      </semantics>
     </math>
     , detailed in Section
     <a class="ltx_ref" href="#S4.SS4" title="4.4. Fusion Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       4.4
      </span>
     </a>
     .
     <math alttext="\bm{e}^{F}" class="ltx_Math" display="inline" id="S4.SS1.p1.11.m11.1">
      <semantics id="S4.SS1.p1.11.m11.1a">
       <msup id="S4.SS1.p1.11.m11.1.1" xref="S4.SS1.p1.11.m11.1.1.cmml">
        <mi id="S4.SS1.p1.11.m11.1.1.2" xref="S4.SS1.p1.11.m11.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS1.p1.11.m11.1.1.3" xref="S4.SS1.p1.11.m11.1.1.3.cmml">
         F
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.11.m11.1b">
        <apply id="S4.SS1.p1.11.m11.1.1.cmml" xref="S4.SS1.p1.11.m11.1.1">
         <csymbol cd="ambiguous" id="S4.SS1.p1.11.m11.1.1.1.cmml" xref="S4.SS1.p1.11.m11.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS1.p1.11.m11.1.1.2.cmml" xref="S4.SS1.p1.11.m11.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS1.p1.11.m11.1.1.3.cmml" xref="S4.SS1.p1.11.m11.1.1.3">
          𝐹
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.11.m11.1c">
        \bm{e}^{F}
       </annotation>
      </semantics>
     </math>
     are then fed into the module blocks of the LLM to generate the predicted summaries (step \raisebox{-.9pt}{4}⃝).
In step \raisebox{-.9pt}{5}⃝, based on the predicted summaries and the ground-truth summaries, PromptCS computes the loss and iteratively updates the model parameters of the prompt agent, detailed in Section
     <a class="ltx_ref" href="#S4.SS5" title="4.5. Model Training ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       4.5
      </span>
     </a>
     .
Once the training phase is completed, the well-trained prompt agent is obtained. When PromptCS is deployed for usage, the prompt agent will automatically generate a prompt embedding for the code snippet given by the user to guide the LLM in generating a predicted summary. For the user, all of this happens seamlessly and is imperceptible.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="302" id="S4.F2.g1" src="/html/2312.16066/assets/x2.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2.
     </span>
     Overview of PromptCS
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2.
    </span>
    Code Embedding Generation
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     As mentioned in Section
     <a class="ltx_ref" href="#S2.SS2" title="2.2. Large Language Model ‣ 2. background ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       2.2
      </span>
     </a>
     , each LLM has three core components, i.e., a tokenizer, an input embedding layer, and module blocks. PromptCS directly employs the first two components of the LLM to accomplish the task of code embedding generation.
Specifically, given a code snippet, our prompt agent first utilizes the tokenizer provided by the corresponding LLM to convert various elements in the code snippet, such as identifiers and symbols, into index representations. Each index representation corresponds to a token in the LLM vocabulary. Then, the prompt agent feeds the index representations to the input embedding layer of the LLM. The input embedding layer can encode the index representations to embeddings (i.e.,
     <math alttext="\bm{e}^{C}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1">
      <semantics id="S4.SS2.p1.1.m1.1a">
       <msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">
        <mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">
         C
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b">
        <apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">
          𝐶
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">
        \bm{e}^{C}
       </annotation>
      </semantics>
     </math>
     ) so that the module blocks can better understand their inner information.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3.
    </span>
    Prompt Embedding Generation
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.12">
     The function of the prompt embedding is to instruct the LLM to generate code summaries.
As shown in Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.1. Overview ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     (1), the prompt embedding
     <math alttext="\bm{e}^{P}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1">
      <semantics id="S4.SS3.p1.1.m1.1a">
       <msup id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">
        <mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">
         P
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b">
        <apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">
          𝑃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">
        \bm{e}^{P}
       </annotation>
      </semantics>
     </math>
     is generated through the prompt encoder.
The input of the prompt encoder is a pseudo prompt consisting of
     <math alttext="n" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1">
      <semantics id="S4.SS3.p1.2.m2.1a">
       <mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">
        n
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b">
        <ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">
         𝑛
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">
        n
       </annotation>
      </semantics>
     </math>
     learnable tokens, denoted
     <math alttext="p=\{t_{0},t_{1},\dots,t_{n}\}" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.4">
      <semantics id="S4.SS3.p1.3.m3.4a">
       <mrow id="S4.SS3.p1.3.m3.4.4" xref="S4.SS3.p1.3.m3.4.4.cmml">
        <mi id="S4.SS3.p1.3.m3.4.4.5" xref="S4.SS3.p1.3.m3.4.4.5.cmml">
         p
        </mi>
        <mo id="S4.SS3.p1.3.m3.4.4.4" xref="S4.SS3.p1.3.m3.4.4.4.cmml">
         =
        </mo>
        <mrow id="S4.SS3.p1.3.m3.4.4.3.3" xref="S4.SS3.p1.3.m3.4.4.3.4.cmml">
         <mo id="S4.SS3.p1.3.m3.4.4.3.3.4" stretchy="false" xref="S4.SS3.p1.3.m3.4.4.3.4.cmml">
          {
         </mo>
         <msub id="S4.SS3.p1.3.m3.2.2.1.1.1" xref="S4.SS3.p1.3.m3.2.2.1.1.1.cmml">
          <mi id="S4.SS3.p1.3.m3.2.2.1.1.1.2" xref="S4.SS3.p1.3.m3.2.2.1.1.1.2.cmml">
           t
          </mi>
          <mn id="S4.SS3.p1.3.m3.2.2.1.1.1.3" xref="S4.SS3.p1.3.m3.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S4.SS3.p1.3.m3.4.4.3.3.5" xref="S4.SS3.p1.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS3.p1.3.m3.3.3.2.2.2" xref="S4.SS3.p1.3.m3.3.3.2.2.2.cmml">
          <mi id="S4.SS3.p1.3.m3.3.3.2.2.2.2" xref="S4.SS3.p1.3.m3.3.3.2.2.2.2.cmml">
           t
          </mi>
          <mn id="S4.SS3.p1.3.m3.3.3.2.2.2.3" xref="S4.SS3.p1.3.m3.3.3.2.2.2.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S4.SS3.p1.3.m3.4.4.3.3.6" xref="S4.SS3.p1.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S4.SS3.p1.3.m3.1.1" mathvariant="normal" xref="S4.SS3.p1.3.m3.1.1.cmml">
          …
         </mi>
         <mo id="S4.SS3.p1.3.m3.4.4.3.3.7" xref="S4.SS3.p1.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS3.p1.3.m3.4.4.3.3.3" xref="S4.SS3.p1.3.m3.4.4.3.3.3.cmml">
          <mi id="S4.SS3.p1.3.m3.4.4.3.3.3.2" xref="S4.SS3.p1.3.m3.4.4.3.3.3.2.cmml">
           t
          </mi>
          <mi id="S4.SS3.p1.3.m3.4.4.3.3.3.3" xref="S4.SS3.p1.3.m3.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S4.SS3.p1.3.m3.4.4.3.3.8" stretchy="false" xref="S4.SS3.p1.3.m3.4.4.3.4.cmml">
          }
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.4b">
        <apply id="S4.SS3.p1.3.m3.4.4.cmml" xref="S4.SS3.p1.3.m3.4.4">
         <eq id="S4.SS3.p1.3.m3.4.4.4.cmml" xref="S4.SS3.p1.3.m3.4.4.4">
         </eq>
         <ci id="S4.SS3.p1.3.m3.4.4.5.cmml" xref="S4.SS3.p1.3.m3.4.4.5">
          𝑝
         </ci>
         <set id="S4.SS3.p1.3.m3.4.4.3.4.cmml" xref="S4.SS3.p1.3.m3.4.4.3.3">
          <apply id="S4.SS3.p1.3.m3.2.2.1.1.1.cmml" xref="S4.SS3.p1.3.m3.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS3.p1.3.m3.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS3.p1.3.m3.2.2.1.1.1.2">
            𝑡
           </ci>
           <cn id="S4.SS3.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS3.p1.3.m3.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S4.SS3.p1.3.m3.3.3.2.2.2.cmml" xref="S4.SS3.p1.3.m3.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.3.3.2.2.2.1.cmml" xref="S4.SS3.p1.3.m3.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S4.SS3.p1.3.m3.3.3.2.2.2.2">
            𝑡
           </ci>
           <cn id="S4.SS3.p1.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS3.p1.3.m3.3.3.2.2.2.3">
            1
           </cn>
          </apply>
          <ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">
           …
          </ci>
          <apply id="S4.SS3.p1.3.m3.4.4.3.3.3.cmml" xref="S4.SS3.p1.3.m3.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.4.4.3.3.3.1.cmml" xref="S4.SS3.p1.3.m3.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.3.m3.4.4.3.3.3.2.cmml" xref="S4.SS3.p1.3.m3.4.4.3.3.3.2">
            𝑡
           </ci>
           <ci id="S4.SS3.p1.3.m3.4.4.3.3.3.3.cmml" xref="S4.SS3.p1.3.m3.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </set>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.4c">
        p=\{t_{0},t_{1},\dots,t_{n}\}
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="t_{i}" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1">
      <semantics id="S4.SS3.p1.4.m4.1a">
       <msub id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">
        <mi id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml">
         t
        </mi>
        <mi id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b">
        <apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">
          𝑡
         </ci>
         <ci id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">
        t_{i}
       </annotation>
      </semantics>
     </math>
     refers to the
     <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.p1.5.m5.1">
      <semantics id="S4.SS3.p1.5.m5.1a">
       <mi id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b">
        <ci id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">
        i
       </annotation>
      </semantics>
     </math>
     -th pseudo token. The role of pseudo tokens is to serve only as placeholders without carrying any actual meaning, and to indicate the length of the prompt used by the prompt encoder to generate the prompt embedding.
The prompt encoder is a DL model capable of mapping
     <math alttext="p" class="ltx_Math" display="inline" id="S4.SS3.p1.6.m6.1">
      <semantics id="S4.SS3.p1.6.m6.1a">
       <mi id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">
        p
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b">
        <ci id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">
         𝑝
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">
        p
       </annotation>
      </semantics>
     </math>
     to a continuous sequence of numbers, which is then input into the embedding layer to generate
     <math alttext="\bm{T}=\{\bm{t}_{0},\bm{t}_{1},\dots,\bm{t}_{n}\}" class="ltx_Math" display="inline" id="S4.SS3.p1.7.m7.4">
      <semantics id="S4.SS3.p1.7.m7.4a">
       <mrow id="S4.SS3.p1.7.m7.4.4" xref="S4.SS3.p1.7.m7.4.4.cmml">
        <mi id="S4.SS3.p1.7.m7.4.4.5" xref="S4.SS3.p1.7.m7.4.4.5.cmml">
         𝑻
        </mi>
        <mo id="S4.SS3.p1.7.m7.4.4.4" xref="S4.SS3.p1.7.m7.4.4.4.cmml">
         =
        </mo>
        <mrow id="S4.SS3.p1.7.m7.4.4.3.3" xref="S4.SS3.p1.7.m7.4.4.3.4.cmml">
         <mo id="S4.SS3.p1.7.m7.4.4.3.3.4" stretchy="false" xref="S4.SS3.p1.7.m7.4.4.3.4.cmml">
          {
         </mo>
         <msub id="S4.SS3.p1.7.m7.2.2.1.1.1" xref="S4.SS3.p1.7.m7.2.2.1.1.1.cmml">
          <mi id="S4.SS3.p1.7.m7.2.2.1.1.1.2" xref="S4.SS3.p1.7.m7.2.2.1.1.1.2.cmml">
           𝒕
          </mi>
          <mn id="S4.SS3.p1.7.m7.2.2.1.1.1.3" xref="S4.SS3.p1.7.m7.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S4.SS3.p1.7.m7.4.4.3.3.5" xref="S4.SS3.p1.7.m7.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS3.p1.7.m7.3.3.2.2.2" xref="S4.SS3.p1.7.m7.3.3.2.2.2.cmml">
          <mi id="S4.SS3.p1.7.m7.3.3.2.2.2.2" xref="S4.SS3.p1.7.m7.3.3.2.2.2.2.cmml">
           𝒕
          </mi>
          <mn id="S4.SS3.p1.7.m7.3.3.2.2.2.3" xref="S4.SS3.p1.7.m7.3.3.2.2.2.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S4.SS3.p1.7.m7.4.4.3.3.6" xref="S4.SS3.p1.7.m7.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S4.SS3.p1.7.m7.1.1" mathvariant="normal" xref="S4.SS3.p1.7.m7.1.1.cmml">
          …
         </mi>
         <mo id="S4.SS3.p1.7.m7.4.4.3.3.7" xref="S4.SS3.p1.7.m7.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS3.p1.7.m7.4.4.3.3.3" xref="S4.SS3.p1.7.m7.4.4.3.3.3.cmml">
          <mi id="S4.SS3.p1.7.m7.4.4.3.3.3.2" xref="S4.SS3.p1.7.m7.4.4.3.3.3.2.cmml">
           𝒕
          </mi>
          <mi id="S4.SS3.p1.7.m7.4.4.3.3.3.3" xref="S4.SS3.p1.7.m7.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S4.SS3.p1.7.m7.4.4.3.3.8" stretchy="false" xref="S4.SS3.p1.7.m7.4.4.3.4.cmml">
          }
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.4b">
        <apply id="S4.SS3.p1.7.m7.4.4.cmml" xref="S4.SS3.p1.7.m7.4.4">
         <eq id="S4.SS3.p1.7.m7.4.4.4.cmml" xref="S4.SS3.p1.7.m7.4.4.4">
         </eq>
         <ci id="S4.SS3.p1.7.m7.4.4.5.cmml" xref="S4.SS3.p1.7.m7.4.4.5">
          𝑻
         </ci>
         <set id="S4.SS3.p1.7.m7.4.4.3.4.cmml" xref="S4.SS3.p1.7.m7.4.4.3.3">
          <apply id="S4.SS3.p1.7.m7.2.2.1.1.1.cmml" xref="S4.SS3.p1.7.m7.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS3.p1.7.m7.2.2.1.1.1.1.cmml" xref="S4.SS3.p1.7.m7.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.7.m7.2.2.1.1.1.2.cmml" xref="S4.SS3.p1.7.m7.2.2.1.1.1.2">
            𝒕
           </ci>
           <cn id="S4.SS3.p1.7.m7.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS3.p1.7.m7.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S4.SS3.p1.7.m7.3.3.2.2.2.cmml" xref="S4.SS3.p1.7.m7.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS3.p1.7.m7.3.3.2.2.2.1.cmml" xref="S4.SS3.p1.7.m7.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.7.m7.3.3.2.2.2.2.cmml" xref="S4.SS3.p1.7.m7.3.3.2.2.2.2">
            𝒕
           </ci>
           <cn id="S4.SS3.p1.7.m7.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS3.p1.7.m7.3.3.2.2.2.3">
            1
           </cn>
          </apply>
          <ci id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1">
           …
          </ci>
          <apply id="S4.SS3.p1.7.m7.4.4.3.3.3.cmml" xref="S4.SS3.p1.7.m7.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S4.SS3.p1.7.m7.4.4.3.3.3.1.cmml" xref="S4.SS3.p1.7.m7.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.7.m7.4.4.3.3.3.2.cmml" xref="S4.SS3.p1.7.m7.4.4.3.3.3.2">
            𝒕
           </ci>
           <ci id="S4.SS3.p1.7.m7.4.4.3.3.3.3.cmml" xref="S4.SS3.p1.7.m7.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </set>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.4c">
        \bm{T}=\{\bm{t}_{0},\bm{t}_{1},\dots,\bm{t}_{n}\}
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="\bm{t}_{i}" class="ltx_Math" display="inline" id="S4.SS3.p1.8.m8.1">
      <semantics id="S4.SS3.p1.8.m8.1a">
       <msub id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml">
        <mi id="S4.SS3.p1.8.m8.1.1.2" xref="S4.SS3.p1.8.m8.1.1.2.cmml">
         𝒕
        </mi>
        <mi id="S4.SS3.p1.8.m8.1.1.3" xref="S4.SS3.p1.8.m8.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b">
        <apply id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS3.p1.8.m8.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2">
          𝒕
         </ci>
         <ci id="S4.SS3.p1.8.m8.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">
        \bm{t}_{i}
       </annotation>
      </semantics>
     </math>
     is a trainable embedding tensor. This allows us to discover more effective continuous prompts that go beyond the original vocabulary of the LLM.
Then, the prompt encoder applies a Bidirectional Long-short Term Memory network (BiLSTM), with a ReLU activated two-layer multilayer perceptron (MLP) to produce the real prompt embeddings
     <math alttext="\bm{e}^{P}=\{\bm{e}_{0},\bm{e}_{1},\dots,\bm{e}_{n}\}" class="ltx_Math" display="inline" id="S4.SS3.p1.9.m9.4">
      <semantics id="S4.SS3.p1.9.m9.4a">
       <mrow id="S4.SS3.p1.9.m9.4.4" xref="S4.SS3.p1.9.m9.4.4.cmml">
        <msup id="S4.SS3.p1.9.m9.4.4.5" xref="S4.SS3.p1.9.m9.4.4.5.cmml">
         <mi id="S4.SS3.p1.9.m9.4.4.5.2" xref="S4.SS3.p1.9.m9.4.4.5.2.cmml">
          𝒆
         </mi>
         <mi id="S4.SS3.p1.9.m9.4.4.5.3" xref="S4.SS3.p1.9.m9.4.4.5.3.cmml">
          P
         </mi>
        </msup>
        <mo id="S4.SS3.p1.9.m9.4.4.4" xref="S4.SS3.p1.9.m9.4.4.4.cmml">
         =
        </mo>
        <mrow id="S4.SS3.p1.9.m9.4.4.3.3" xref="S4.SS3.p1.9.m9.4.4.3.4.cmml">
         <mo id="S4.SS3.p1.9.m9.4.4.3.3.4" stretchy="false" xref="S4.SS3.p1.9.m9.4.4.3.4.cmml">
          {
         </mo>
         <msub id="S4.SS3.p1.9.m9.2.2.1.1.1" xref="S4.SS3.p1.9.m9.2.2.1.1.1.cmml">
          <mi id="S4.SS3.p1.9.m9.2.2.1.1.1.2" xref="S4.SS3.p1.9.m9.2.2.1.1.1.2.cmml">
           𝒆
          </mi>
          <mn id="S4.SS3.p1.9.m9.2.2.1.1.1.3" xref="S4.SS3.p1.9.m9.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S4.SS3.p1.9.m9.4.4.3.3.5" xref="S4.SS3.p1.9.m9.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS3.p1.9.m9.3.3.2.2.2" xref="S4.SS3.p1.9.m9.3.3.2.2.2.cmml">
          <mi id="S4.SS3.p1.9.m9.3.3.2.2.2.2" xref="S4.SS3.p1.9.m9.3.3.2.2.2.2.cmml">
           𝒆
          </mi>
          <mn id="S4.SS3.p1.9.m9.3.3.2.2.2.3" xref="S4.SS3.p1.9.m9.3.3.2.2.2.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S4.SS3.p1.9.m9.4.4.3.3.6" xref="S4.SS3.p1.9.m9.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S4.SS3.p1.9.m9.1.1" mathvariant="normal" xref="S4.SS3.p1.9.m9.1.1.cmml">
          …
         </mi>
         <mo id="S4.SS3.p1.9.m9.4.4.3.3.7" xref="S4.SS3.p1.9.m9.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS3.p1.9.m9.4.4.3.3.3" xref="S4.SS3.p1.9.m9.4.4.3.3.3.cmml">
          <mi id="S4.SS3.p1.9.m9.4.4.3.3.3.2" xref="S4.SS3.p1.9.m9.4.4.3.3.3.2.cmml">
           𝒆
          </mi>
          <mi id="S4.SS3.p1.9.m9.4.4.3.3.3.3" xref="S4.SS3.p1.9.m9.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S4.SS3.p1.9.m9.4.4.3.3.8" stretchy="false" xref="S4.SS3.p1.9.m9.4.4.3.4.cmml">
          }
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.4b">
        <apply id="S4.SS3.p1.9.m9.4.4.cmml" xref="S4.SS3.p1.9.m9.4.4">
         <eq id="S4.SS3.p1.9.m9.4.4.4.cmml" xref="S4.SS3.p1.9.m9.4.4.4">
         </eq>
         <apply id="S4.SS3.p1.9.m9.4.4.5.cmml" xref="S4.SS3.p1.9.m9.4.4.5">
          <csymbol cd="ambiguous" id="S4.SS3.p1.9.m9.4.4.5.1.cmml" xref="S4.SS3.p1.9.m9.4.4.5">
           superscript
          </csymbol>
          <ci id="S4.SS3.p1.9.m9.4.4.5.2.cmml" xref="S4.SS3.p1.9.m9.4.4.5.2">
           𝒆
          </ci>
          <ci id="S4.SS3.p1.9.m9.4.4.5.3.cmml" xref="S4.SS3.p1.9.m9.4.4.5.3">
           𝑃
          </ci>
         </apply>
         <set id="S4.SS3.p1.9.m9.4.4.3.4.cmml" xref="S4.SS3.p1.9.m9.4.4.3.3">
          <apply id="S4.SS3.p1.9.m9.2.2.1.1.1.cmml" xref="S4.SS3.p1.9.m9.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS3.p1.9.m9.2.2.1.1.1.1.cmml" xref="S4.SS3.p1.9.m9.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.9.m9.2.2.1.1.1.2.cmml" xref="S4.SS3.p1.9.m9.2.2.1.1.1.2">
            𝒆
           </ci>
           <cn id="S4.SS3.p1.9.m9.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS3.p1.9.m9.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S4.SS3.p1.9.m9.3.3.2.2.2.cmml" xref="S4.SS3.p1.9.m9.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS3.p1.9.m9.3.3.2.2.2.1.cmml" xref="S4.SS3.p1.9.m9.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.9.m9.3.3.2.2.2.2.cmml" xref="S4.SS3.p1.9.m9.3.3.2.2.2.2">
            𝒆
           </ci>
           <cn id="S4.SS3.p1.9.m9.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS3.p1.9.m9.3.3.2.2.2.3">
            1
           </cn>
          </apply>
          <ci id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1">
           …
          </ci>
          <apply id="S4.SS3.p1.9.m9.4.4.3.3.3.cmml" xref="S4.SS3.p1.9.m9.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S4.SS3.p1.9.m9.4.4.3.3.3.1.cmml" xref="S4.SS3.p1.9.m9.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S4.SS3.p1.9.m9.4.4.3.3.3.2.cmml" xref="S4.SS3.p1.9.m9.4.4.3.3.3.2">
            𝒆
           </ci>
           <ci id="S4.SS3.p1.9.m9.4.4.3.3.3.3.cmml" xref="S4.SS3.p1.9.m9.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </set>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.4c">
        \bm{e}^{P}=\{\bm{e}_{0},\bm{e}_{1},\dots,\bm{e}_{n}\}
       </annotation>
      </semantics>
     </math>
     . The value
     <math alttext="\bm{e}_{i}" class="ltx_Math" display="inline" id="S4.SS3.p1.10.m10.1">
      <semantics id="S4.SS3.p1.10.m10.1a">
       <msub id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml">
        <mi id="S4.SS3.p1.10.m10.1.1.2" xref="S4.SS3.p1.10.m10.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS3.p1.10.m10.1.1.3" xref="S4.SS3.p1.10.m10.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b">
        <apply id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS3.p1.10.m10.1.1.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS3.p1.10.m10.1.1.3.cmml" xref="S4.SS3.p1.10.m10.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">
        \bm{e}_{i}
       </annotation>
      </semantics>
     </math>
     at the
     <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.p1.11.m11.1">
      <semantics id="S4.SS3.p1.11.m11.1a">
       <mi id="S4.SS3.p1.11.m11.1.1" xref="S4.SS3.p1.11.m11.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.11.m11.1b">
        <ci id="S4.SS3.p1.11.m11.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.11.m11.1c">
        i
       </annotation>
      </semantics>
     </math>
     -th position of
     <math alttext="\bm{e}^{P}" class="ltx_Math" display="inline" id="S4.SS3.p1.12.m12.1">
      <semantics id="S4.SS3.p1.12.m12.1a">
       <msup id="S4.SS3.p1.12.m12.1.1" xref="S4.SS3.p1.12.m12.1.1.cmml">
        <mi id="S4.SS3.p1.12.m12.1.1.2" xref="S4.SS3.p1.12.m12.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS3.p1.12.m12.1.1.3" xref="S4.SS3.p1.12.m12.1.1.3.cmml">
         P
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.12.m12.1b">
        <apply id="S4.SS3.p1.12.m12.1.1.cmml" xref="S4.SS3.p1.12.m12.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.12.m12.1.1.1.cmml" xref="S4.SS3.p1.12.m12.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS3.p1.12.m12.1.1.2.cmml" xref="S4.SS3.p1.12.m12.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS3.p1.12.m12.1.1.3.cmml" xref="S4.SS3.p1.12.m12.1.1.3">
          𝑃
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.12.m12.1c">
        \bm{e}^{P}
       </annotation>
      </semantics>
     </math>
     is calculated as follows:
    </p>
    <table class="ltx_equation ltx_eqn_table" id="S4.E1">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_left">
         (1)
        </span>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="\footnotesize\bm{h}_{i}^{f}=LSTM(\bm{h}_{i-1}^{f}),\;\bm{h}_{i}^{b}=LSTM(\bm{h}_{i+1}^{b}),\;\bm{e}_{i}=MLP([\bm{h}_{i}^{f},\bm{h}_{i}^{b}])" class="ltx_Math" display="block" id="S4.E1.m1.2">
         <semantics id="S4.E1.m1.2a">
          <mrow id="S4.E1.m1.2.2.2" xref="S4.E1.m1.2.2.3.cmml">
           <mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml">
            <msubsup id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.3.cmml">
             <mi id="S4.E1.m1.1.1.1.1.3.2.2" mathsize="80%" xref="S4.E1.m1.1.1.1.1.3.2.2.cmml">
              𝒉
             </mi>
             <mi id="S4.E1.m1.1.1.1.1.3.2.3" mathsize="80%" xref="S4.E1.m1.1.1.1.1.3.2.3.cmml">
              i
             </mi>
             <mi id="S4.E1.m1.1.1.1.1.3.3" mathsize="80%" xref="S4.E1.m1.1.1.1.1.3.3.cmml">
              f
             </mi>
            </msubsup>
            <mo id="S4.E1.m1.1.1.1.1.2" mathsize="80%" xref="S4.E1.m1.1.1.1.1.2.cmml">
             =
            </mo>
            <mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml">
             <mi id="S4.E1.m1.1.1.1.1.1.3" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.3.cmml">
              L
             </mi>
             <mo id="S4.E1.m1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S4.E1.m1.1.1.1.1.1.2.cmml">
              ​
             </mo>
             <mi id="S4.E1.m1.1.1.1.1.1.4" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.4.cmml">
              S
             </mi>
             <mo id="S4.E1.m1.1.1.1.1.1.2a" lspace="0em" rspace="0em" xref="S4.E1.m1.1.1.1.1.1.2.cmml">
              ​
             </mo>
             <mi id="S4.E1.m1.1.1.1.1.1.5" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.5.cmml">
              T
             </mi>
             <mo id="S4.E1.m1.1.1.1.1.1.2b" lspace="0em" rspace="0em" xref="S4.E1.m1.1.1.1.1.1.2.cmml">
              ​
             </mo>
             <mi id="S4.E1.m1.1.1.1.1.1.6" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.6.cmml">
              M
             </mi>
             <mo id="S4.E1.m1.1.1.1.1.1.2c" lspace="0em" rspace="0em" xref="S4.E1.m1.1.1.1.1.1.2.cmml">
              ​
             </mo>
             <mrow id="S4.E1.m1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml">
              <mo id="S4.E1.m1.1.1.1.1.1.1.1.2" maxsize="80%" minsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml">
               (
              </mo>
              <msubsup id="S4.E1.m1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml">
               <mi id="S4.E1.m1.1.1.1.1.1.1.1.1.2.2" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">
                𝒉
               </mi>
               <mrow id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">
                <mi id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.2" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">
                 i
                </mi>
                <mo id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.1" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">
                 −
                </mo>
                <mn id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.3" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">
                 1
                </mn>
               </mrow>
               <mi id="S4.E1.m1.1.1.1.1.1.1.1.1.3" mathsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.cmml">
                f
               </mi>
              </msubsup>
              <mo id="S4.E1.m1.1.1.1.1.1.1.1.3" maxsize="80%" minsize="80%" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
           <mo id="S4.E1.m1.2.2.2.3" mathsize="80%" rspace="0.447em" xref="S4.E1.m1.2.2.3a.cmml">
            ,
           </mo>
           <mrow id="S4.E1.m1.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.3.cmml">
            <mrow id="S4.E1.m1.2.2.2.2.1.1" xref="S4.E1.m1.2.2.2.2.1.1.cmml">
             <msubsup id="S4.E1.m1.2.2.2.2.1.1.3" xref="S4.E1.m1.2.2.2.2.1.1.3.cmml">
              <mi id="S4.E1.m1.2.2.2.2.1.1.3.2.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.3.2.2.cmml">
               𝒉
              </mi>
              <mi id="S4.E1.m1.2.2.2.2.1.1.3.2.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.3.2.3.cmml">
               i
              </mi>
              <mi id="S4.E1.m1.2.2.2.2.1.1.3.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.3.3.cmml">
               b
              </mi>
             </msubsup>
             <mo id="S4.E1.m1.2.2.2.2.1.1.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.2.cmml">
              =
             </mo>
             <mrow id="S4.E1.m1.2.2.2.2.1.1.1" xref="S4.E1.m1.2.2.2.2.1.1.1.cmml">
              <mi id="S4.E1.m1.2.2.2.2.1.1.1.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.3.cmml">
               L
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.1.1.1.2" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.1.1.1.2.cmml">
               ​
              </mo>
              <mi id="S4.E1.m1.2.2.2.2.1.1.1.4" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.4.cmml">
               S
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.1.1.1.2a" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.1.1.1.2.cmml">
               ​
              </mo>
              <mi id="S4.E1.m1.2.2.2.2.1.1.1.5" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.5.cmml">
               T
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.1.1.1.2b" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.1.1.1.2.cmml">
               ​
              </mo>
              <mi id="S4.E1.m1.2.2.2.2.1.1.1.6" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.6.cmml">
               M
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.1.1.1.2c" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.1.1.1.2.cmml">
               ​
              </mo>
              <mrow id="S4.E1.m1.2.2.2.2.1.1.1.1.1" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml">
               <mo id="S4.E1.m1.2.2.2.2.1.1.1.1.1.2" maxsize="80%" minsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml">
                (
               </mo>
               <msubsup id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml">
                <mi id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2.cmml">
                 𝒉
                </mi>
                <mrow id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.cmml">
                 <mi id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.2.cmml">
                  i
                 </mi>
                 <mo id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.1" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.1.cmml">
                  +
                 </mo>
                 <mn id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.3.cmml">
                  1
                 </mn>
                </mrow>
                <mi id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.3.cmml">
                 b
                </mi>
               </msubsup>
               <mo id="S4.E1.m1.2.2.2.2.1.1.1.1.1.3" maxsize="80%" minsize="80%" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml">
                )
               </mo>
              </mrow>
             </mrow>
            </mrow>
            <mo id="S4.E1.m1.2.2.2.2.2.3" mathsize="80%" rspace="0.447em" xref="S4.E1.m1.2.2.2.2.3a.cmml">
             ,
            </mo>
            <mrow id="S4.E1.m1.2.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.2.2.cmml">
             <msub id="S4.E1.m1.2.2.2.2.2.2.3" xref="S4.E1.m1.2.2.2.2.2.2.3.cmml">
              <mi id="S4.E1.m1.2.2.2.2.2.2.3.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.3.2.cmml">
               𝒆
              </mi>
              <mi id="S4.E1.m1.2.2.2.2.2.2.3.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.3.3.cmml">
               i
              </mi>
             </msub>
             <mo id="S4.E1.m1.2.2.2.2.2.2.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.2.cmml">
              =
             </mo>
             <mrow id="S4.E1.m1.2.2.2.2.2.2.1" xref="S4.E1.m1.2.2.2.2.2.2.1.cmml">
              <mi id="S4.E1.m1.2.2.2.2.2.2.1.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.3.cmml">
               M
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.2.2.1.2" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.2.2.1.2.cmml">
               ​
              </mo>
              <mi id="S4.E1.m1.2.2.2.2.2.2.1.4" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.4.cmml">
               L
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.2.2.1.2a" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.2.2.1.2.cmml">
               ​
              </mo>
              <mi id="S4.E1.m1.2.2.2.2.2.2.1.5" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.5.cmml">
               P
              </mi>
              <mo id="S4.E1.m1.2.2.2.2.2.2.1.2b" lspace="0em" rspace="0em" xref="S4.E1.m1.2.2.2.2.2.2.1.2.cmml">
               ​
              </mo>
              <mrow id="S4.E1.m1.2.2.2.2.2.2.1.1.1" xref="S4.E1.m1.2.2.2.2.2.2.1.cmml">
               <mo id="S4.E1.m1.2.2.2.2.2.2.1.1.1.2" maxsize="80%" minsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.cmml">
                (
               </mo>
               <mrow id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml">
                <mo id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.3" maxsize="80%" minsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml">
                 [
                </mo>
                <msubsup id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.cmml">
                 <mi id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.2.cmml">
                  𝒉
                 </mi>
                 <mi id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.3.cmml">
                  i
                 </mi>
                 <mi id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.cmml">
                  f
                 </mi>
                </msubsup>
                <mo id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.4" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml">
                 ,
                </mo>
                <msubsup id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.cmml">
                 <mi id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.2" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.2.cmml">
                  𝒉
                 </mi>
                 <mi id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.3.cmml">
                  i
                 </mi>
                 <mi id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.3" mathsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.3.cmml">
                  b
                 </mi>
                </msubsup>
                <mo id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.5" maxsize="80%" minsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml">
                 ]
                </mo>
               </mrow>
               <mo id="S4.E1.m1.2.2.2.2.2.2.1.1.1.3" maxsize="80%" minsize="80%" xref="S4.E1.m1.2.2.2.2.2.2.1.cmml">
                )
               </mo>
              </mrow>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b">
           <apply id="S4.E1.m1.2.2.3.cmml" xref="S4.E1.m1.2.2.2">
            <csymbol cd="ambiguous" id="S4.E1.m1.2.2.3a.cmml" xref="S4.E1.m1.2.2.2.3">
             formulae-sequence
            </csymbol>
            <apply id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1">
             <eq id="S4.E1.m1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.2">
             </eq>
             <apply id="S4.E1.m1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.3">
              <csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3">
               superscript
              </csymbol>
              <apply id="S4.E1.m1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3">
               <csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3">
                subscript
               </csymbol>
               <ci id="S4.E1.m1.1.1.1.1.3.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2">
                𝒉
               </ci>
               <ci id="S4.E1.m1.1.1.1.1.3.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3">
                𝑖
               </ci>
              </apply>
              <ci id="S4.E1.m1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3">
               𝑓
              </ci>
             </apply>
             <apply id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1">
              <times id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.2">
              </times>
              <ci id="S4.E1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.3">
               𝐿
              </ci>
              <ci id="S4.E1.m1.1.1.1.1.1.4.cmml" xref="S4.E1.m1.1.1.1.1.1.4">
               𝑆
              </ci>
              <ci id="S4.E1.m1.1.1.1.1.1.5.cmml" xref="S4.E1.m1.1.1.1.1.1.5">
               𝑇
              </ci>
              <ci id="S4.E1.m1.1.1.1.1.1.6.cmml" xref="S4.E1.m1.1.1.1.1.1.6">
               𝑀
              </ci>
              <apply id="S4.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1">
               <csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1">
                superscript
               </csymbol>
               <apply id="S4.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1">
                <csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1">
                 subscript
                </csymbol>
                <ci id="S4.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.2">
                 𝒉
                </ci>
                <apply id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3">
                 <minus id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.1">
                 </minus>
                 <ci id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.2">
                  𝑖
                 </ci>
                 <cn id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.3">
                  1
                 </cn>
                </apply>
               </apply>
               <ci id="S4.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3">
                𝑓
               </ci>
              </apply>
             </apply>
            </apply>
            <apply id="S4.E1.m1.2.2.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2">
             <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.3a.cmml" xref="S4.E1.m1.2.2.2.2.2.3">
              formulae-sequence
             </csymbol>
             <apply id="S4.E1.m1.2.2.2.2.1.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1">
              <eq id="S4.E1.m1.2.2.2.2.1.1.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.2">
              </eq>
              <apply id="S4.E1.m1.2.2.2.2.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3">
               <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.1.1.3.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3">
                superscript
               </csymbol>
               <apply id="S4.E1.m1.2.2.2.2.1.1.3.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3">
                <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.1.1.3.2.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3">
                 subscript
                </csymbol>
                <ci id="S4.E1.m1.2.2.2.2.1.1.3.2.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3.2.2">
                 𝒉
                </ci>
                <ci id="S4.E1.m1.2.2.2.2.1.1.3.2.3.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3.2.3">
                 𝑖
                </ci>
               </apply>
               <ci id="S4.E1.m1.2.2.2.2.1.1.3.3.cmml" xref="S4.E1.m1.2.2.2.2.1.1.3.3">
                𝑏
               </ci>
              </apply>
              <apply id="S4.E1.m1.2.2.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1">
               <times id="S4.E1.m1.2.2.2.2.1.1.1.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.2">
               </times>
               <ci id="S4.E1.m1.2.2.2.2.1.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.3">
                𝐿
               </ci>
               <ci id="S4.E1.m1.2.2.2.2.1.1.1.4.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.4">
                𝑆
               </ci>
               <ci id="S4.E1.m1.2.2.2.2.1.1.1.5.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.5">
                𝑇
               </ci>
               <ci id="S4.E1.m1.2.2.2.2.1.1.1.6.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.6">
                𝑀
               </ci>
               <apply id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1">
                <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1">
                 superscript
                </csymbol>
                <apply id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1">
                 <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1">
                  subscript
                 </csymbol>
                 <ci id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2">
                  𝒉
                 </ci>
                 <apply id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3">
                  <plus id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.1">
                  </plus>
                  <ci id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.2">
                   𝑖
                  </ci>
                  <cn id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.3">
                   1
                  </cn>
                 </apply>
                </apply>
                <ci id="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.1.1.3">
                 𝑏
                </ci>
               </apply>
              </apply>
             </apply>
             <apply id="S4.E1.m1.2.2.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2">
              <eq id="S4.E1.m1.2.2.2.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.2">
              </eq>
              <apply id="S4.E1.m1.2.2.2.2.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.3">
               <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.2.3.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.3">
                subscript
               </csymbol>
               <ci id="S4.E1.m1.2.2.2.2.2.2.3.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.3.2">
                𝒆
               </ci>
               <ci id="S4.E1.m1.2.2.2.2.2.2.3.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.3.3">
                𝑖
               </ci>
              </apply>
              <apply id="S4.E1.m1.2.2.2.2.2.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1">
               <times id="S4.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.2">
               </times>
               <ci id="S4.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.3">
                𝑀
               </ci>
               <ci id="S4.E1.m1.2.2.2.2.2.2.1.4.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.4">
                𝐿
               </ci>
               <ci id="S4.E1.m1.2.2.2.2.2.2.1.5.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.5">
                𝑃
               </ci>
               <interval closure="closed" id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2">
                <apply id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1">
                 <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1">
                  superscript
                 </csymbol>
                 <apply id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1">
                  <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1">
                   subscript
                  </csymbol>
                  <ci id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.2">
                   𝒉
                  </ci>
                  <ci id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.3">
                   𝑖
                  </ci>
                 </apply>
                 <ci id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3">
                  𝑓
                 </ci>
                </apply>
                <apply id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2">
                 <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2">
                  superscript
                 </csymbol>
                 <apply id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2">
                  <csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2">
                   subscript
                  </csymbol>
                  <ci id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.2">
                   𝒉
                  </ci>
                  <ci id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.2.3">
                   𝑖
                  </ci>
                 </apply>
                 <ci id="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.1.1.1.1.2.2.3">
                  𝑏
                 </ci>
                </apply>
               </interval>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.E1.m1.2c">
           \footnotesize\bm{h}_{i}^{f}=LSTM(\bm{h}_{i-1}^{f}),\;\bm{h}_{i}^{b}=LSTM(\bm{h}_{i+1}^{b}),\;\bm{e}_{i}=MLP([\bm{h}_{i}^{f},\bm{h}_{i}^{b}])
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
      </tr>
     </tbody>
    </table>
    <p class="ltx_p" id="S4.SS3.p1.14">
     where
     <math alttext="\bm{h}_{i}^{f}" class="ltx_Math" display="inline" id="S4.SS3.p1.13.m1.1">
      <semantics id="S4.SS3.p1.13.m1.1a">
       <msubsup id="S4.SS3.p1.13.m1.1.1" xref="S4.SS3.p1.13.m1.1.1.cmml">
        <mi id="S4.SS3.p1.13.m1.1.1.2.2" xref="S4.SS3.p1.13.m1.1.1.2.2.cmml">
         𝒉
        </mi>
        <mi id="S4.SS3.p1.13.m1.1.1.2.3" xref="S4.SS3.p1.13.m1.1.1.2.3.cmml">
         i
        </mi>
        <mi id="S4.SS3.p1.13.m1.1.1.3" xref="S4.SS3.p1.13.m1.1.1.3.cmml">
         f
        </mi>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.13.m1.1b">
        <apply id="S4.SS3.p1.13.m1.1.1.cmml" xref="S4.SS3.p1.13.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.13.m1.1.1.1.cmml" xref="S4.SS3.p1.13.m1.1.1">
          superscript
         </csymbol>
         <apply id="S4.SS3.p1.13.m1.1.1.2.cmml" xref="S4.SS3.p1.13.m1.1.1">
          <csymbol cd="ambiguous" id="S4.SS3.p1.13.m1.1.1.2.1.cmml" xref="S4.SS3.p1.13.m1.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS3.p1.13.m1.1.1.2.2.cmml" xref="S4.SS3.p1.13.m1.1.1.2.2">
           𝒉
          </ci>
          <ci id="S4.SS3.p1.13.m1.1.1.2.3.cmml" xref="S4.SS3.p1.13.m1.1.1.2.3">
           𝑖
          </ci>
         </apply>
         <ci id="S4.SS3.p1.13.m1.1.1.3.cmml" xref="S4.SS3.p1.13.m1.1.1.3">
          𝑓
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.13.m1.1c">
        \bm{h}_{i}^{f}
       </annotation>
      </semantics>
     </math>
     represents the hidden state of the forward LSTM, while
     <math alttext="\bm{h}_{i}^{b}" class="ltx_Math" display="inline" id="S4.SS3.p1.14.m2.1">
      <semantics id="S4.SS3.p1.14.m2.1a">
       <msubsup id="S4.SS3.p1.14.m2.1.1" xref="S4.SS3.p1.14.m2.1.1.cmml">
        <mi id="S4.SS3.p1.14.m2.1.1.2.2" xref="S4.SS3.p1.14.m2.1.1.2.2.cmml">
         𝒉
        </mi>
        <mi id="S4.SS3.p1.14.m2.1.1.2.3" xref="S4.SS3.p1.14.m2.1.1.2.3.cmml">
         i
        </mi>
        <mi id="S4.SS3.p1.14.m2.1.1.3" xref="S4.SS3.p1.14.m2.1.1.3.cmml">
         b
        </mi>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.14.m2.1b">
        <apply id="S4.SS3.p1.14.m2.1.1.cmml" xref="S4.SS3.p1.14.m2.1.1">
         <csymbol cd="ambiguous" id="S4.SS3.p1.14.m2.1.1.1.cmml" xref="S4.SS3.p1.14.m2.1.1">
          superscript
         </csymbol>
         <apply id="S4.SS3.p1.14.m2.1.1.2.cmml" xref="S4.SS3.p1.14.m2.1.1">
          <csymbol cd="ambiguous" id="S4.SS3.p1.14.m2.1.1.2.1.cmml" xref="S4.SS3.p1.14.m2.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS3.p1.14.m2.1.1.2.2.cmml" xref="S4.SS3.p1.14.m2.1.1.2.2">
           𝒉
          </ci>
          <ci id="S4.SS3.p1.14.m2.1.1.2.3.cmml" xref="S4.SS3.p1.14.m2.1.1.2.3">
           𝑖
          </ci>
         </apply>
         <ci id="S4.SS3.p1.14.m2.1.1.3.cmml" xref="S4.SS3.p1.14.m2.1.1.3">
          𝑏
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.14.m2.1c">
        \bm{h}_{i}^{b}
       </annotation>
      </semantics>
     </math>
     represents the hidden state of the backward LSTM.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.4.
    </span>
    Fusion Embedding Generation
   </h3>
   <div class="ltx_para" id="S4.SS4.p1">
    <p class="ltx_p" id="S4.SS4.p1.3">
     Similar to how humans concatenate the discrete prompt with the code snippet, PromptCS can also concatenate the continuous prompt generated by the prompt agent (i.e., prompt embedding) with the embedding of the code snippet in various ways.
In order not to destroy the integrity of the code itself, a common human practice is to concatenate discrete prompts in front or back of the code snippet
     <cite class="ltx_cite ltx_citemacro_citep">
      (Tian et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib62" title="">
       2023
      </a>
      ; Sun et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib60" title="">
       2023c
      </a>
      )
     </cite>
     .
The left side of Figure
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.4. Fusion Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     shows an example of concatenating a discrete prompt and a code snippet (denoted as ¡code¿), where (a) and (b) represent two modes respectively: front-end mode, concatenating the discrete prompt in front of the code snippet; and back-end mode, concatenating the discrete prompt in front of the code snippet.
In this paper, in addition to following the aforementioned two modes, we also try a new mode called the two-end mode. In the two-end mode, the prompt embedding is split into two parts that will be concatenated in the front and back of the code embedding, respectively.
This split is easy to implement. For example, we can split
     <math alttext="\bm{e}^{P}=\{\bm{e}_{0},\bm{e}_{1},\dots,\bm{e}_{n}\}" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.4">
      <semantics id="S4.SS4.p1.1.m1.4a">
       <mrow id="S4.SS4.p1.1.m1.4.4" xref="S4.SS4.p1.1.m1.4.4.cmml">
        <msup id="S4.SS4.p1.1.m1.4.4.5" xref="S4.SS4.p1.1.m1.4.4.5.cmml">
         <mi id="S4.SS4.p1.1.m1.4.4.5.2" xref="S4.SS4.p1.1.m1.4.4.5.2.cmml">
          𝒆
         </mi>
         <mi id="S4.SS4.p1.1.m1.4.4.5.3" xref="S4.SS4.p1.1.m1.4.4.5.3.cmml">
          P
         </mi>
        </msup>
        <mo id="S4.SS4.p1.1.m1.4.4.4" xref="S4.SS4.p1.1.m1.4.4.4.cmml">
         =
        </mo>
        <mrow id="S4.SS4.p1.1.m1.4.4.3.3" xref="S4.SS4.p1.1.m1.4.4.3.4.cmml">
         <mo id="S4.SS4.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S4.SS4.p1.1.m1.4.4.3.4.cmml">
          {
         </mo>
         <msub id="S4.SS4.p1.1.m1.2.2.1.1.1" xref="S4.SS4.p1.1.m1.2.2.1.1.1.cmml">
          <mi id="S4.SS4.p1.1.m1.2.2.1.1.1.2" xref="S4.SS4.p1.1.m1.2.2.1.1.1.2.cmml">
           𝒆
          </mi>
          <mn id="S4.SS4.p1.1.m1.2.2.1.1.1.3" xref="S4.SS4.p1.1.m1.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S4.SS4.p1.1.m1.4.4.3.3.5" xref="S4.SS4.p1.1.m1.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS4.p1.1.m1.3.3.2.2.2" xref="S4.SS4.p1.1.m1.3.3.2.2.2.cmml">
          <mi id="S4.SS4.p1.1.m1.3.3.2.2.2.2" xref="S4.SS4.p1.1.m1.3.3.2.2.2.2.cmml">
           𝒆
          </mi>
          <mn id="S4.SS4.p1.1.m1.3.3.2.2.2.3" xref="S4.SS4.p1.1.m1.3.3.2.2.2.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S4.SS4.p1.1.m1.4.4.3.3.6" xref="S4.SS4.p1.1.m1.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S4.SS4.p1.1.m1.1.1" mathvariant="normal" xref="S4.SS4.p1.1.m1.1.1.cmml">
          …
         </mi>
         <mo id="S4.SS4.p1.1.m1.4.4.3.3.7" xref="S4.SS4.p1.1.m1.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS4.p1.1.m1.4.4.3.3.3" xref="S4.SS4.p1.1.m1.4.4.3.3.3.cmml">
          <mi id="S4.SS4.p1.1.m1.4.4.3.3.3.2" xref="S4.SS4.p1.1.m1.4.4.3.3.3.2.cmml">
           𝒆
          </mi>
          <mi id="S4.SS4.p1.1.m1.4.4.3.3.3.3" xref="S4.SS4.p1.1.m1.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S4.SS4.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S4.SS4.p1.1.m1.4.4.3.4.cmml">
          }
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.4b">
        <apply id="S4.SS4.p1.1.m1.4.4.cmml" xref="S4.SS4.p1.1.m1.4.4">
         <eq id="S4.SS4.p1.1.m1.4.4.4.cmml" xref="S4.SS4.p1.1.m1.4.4.4">
         </eq>
         <apply id="S4.SS4.p1.1.m1.4.4.5.cmml" xref="S4.SS4.p1.1.m1.4.4.5">
          <csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.4.4.5.1.cmml" xref="S4.SS4.p1.1.m1.4.4.5">
           superscript
          </csymbol>
          <ci id="S4.SS4.p1.1.m1.4.4.5.2.cmml" xref="S4.SS4.p1.1.m1.4.4.5.2">
           𝒆
          </ci>
          <ci id="S4.SS4.p1.1.m1.4.4.5.3.cmml" xref="S4.SS4.p1.1.m1.4.4.5.3">
           𝑃
          </ci>
         </apply>
         <set id="S4.SS4.p1.1.m1.4.4.3.4.cmml" xref="S4.SS4.p1.1.m1.4.4.3.3">
          <apply id="S4.SS4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.SS4.p1.1.m1.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.2.2.1.1.1.2">
            𝒆
           </ci>
           <cn id="S4.SS4.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS4.p1.1.m1.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S4.SS4.p1.1.m1.3.3.2.2.2.cmml" xref="S4.SS4.p1.1.m1.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.3.3.2.2.2.1.cmml" xref="S4.SS4.p1.1.m1.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S4.SS4.p1.1.m1.3.3.2.2.2.2">
            𝒆
           </ci>
           <cn id="S4.SS4.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS4.p1.1.m1.3.3.2.2.2.3">
            1
           </cn>
          </apply>
          <ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">
           …
          </ci>
          <apply id="S4.SS4.p1.1.m1.4.4.3.3.3.cmml" xref="S4.SS4.p1.1.m1.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.4.4.3.3.3.1.cmml" xref="S4.SS4.p1.1.m1.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.1.m1.4.4.3.3.3.2.cmml" xref="S4.SS4.p1.1.m1.4.4.3.3.3.2">
            𝒆
           </ci>
           <ci id="S4.SS4.p1.1.m1.4.4.3.3.3.3.cmml" xref="S4.SS4.p1.1.m1.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </set>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.4c">
        \bm{e}^{P}=\{\bm{e}_{0},\bm{e}_{1},\dots,\bm{e}_{n}\}
       </annotation>
      </semantics>
     </math>
     into
     <math alttext="\bm{e}^{P}_{1}=\{\bm{e}_{0},\bm{e}_{1},\dots,\bm{e}_{i}\}" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.4">
      <semantics id="S4.SS4.p1.2.m2.4a">
       <mrow id="S4.SS4.p1.2.m2.4.4" xref="S4.SS4.p1.2.m2.4.4.cmml">
        <msubsup id="S4.SS4.p1.2.m2.4.4.5" xref="S4.SS4.p1.2.m2.4.4.5.cmml">
         <mi id="S4.SS4.p1.2.m2.4.4.5.2.2" xref="S4.SS4.p1.2.m2.4.4.5.2.2.cmml">
          𝒆
         </mi>
         <mn id="S4.SS4.p1.2.m2.4.4.5.3" xref="S4.SS4.p1.2.m2.4.4.5.3.cmml">
          1
         </mn>
         <mi id="S4.SS4.p1.2.m2.4.4.5.2.3" xref="S4.SS4.p1.2.m2.4.4.5.2.3.cmml">
          P
         </mi>
        </msubsup>
        <mo id="S4.SS4.p1.2.m2.4.4.4" xref="S4.SS4.p1.2.m2.4.4.4.cmml">
         =
        </mo>
        <mrow id="S4.SS4.p1.2.m2.4.4.3.3" xref="S4.SS4.p1.2.m2.4.4.3.4.cmml">
         <mo id="S4.SS4.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S4.SS4.p1.2.m2.4.4.3.4.cmml">
          {
         </mo>
         <msub id="S4.SS4.p1.2.m2.2.2.1.1.1" xref="S4.SS4.p1.2.m2.2.2.1.1.1.cmml">
          <mi id="S4.SS4.p1.2.m2.2.2.1.1.1.2" xref="S4.SS4.p1.2.m2.2.2.1.1.1.2.cmml">
           𝒆
          </mi>
          <mn id="S4.SS4.p1.2.m2.2.2.1.1.1.3" xref="S4.SS4.p1.2.m2.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S4.SS4.p1.2.m2.4.4.3.3.5" xref="S4.SS4.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS4.p1.2.m2.3.3.2.2.2" xref="S4.SS4.p1.2.m2.3.3.2.2.2.cmml">
          <mi id="S4.SS4.p1.2.m2.3.3.2.2.2.2" xref="S4.SS4.p1.2.m2.3.3.2.2.2.2.cmml">
           𝒆
          </mi>
          <mn id="S4.SS4.p1.2.m2.3.3.2.2.2.3" xref="S4.SS4.p1.2.m2.3.3.2.2.2.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S4.SS4.p1.2.m2.4.4.3.3.6" xref="S4.SS4.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S4.SS4.p1.2.m2.1.1" mathvariant="normal" xref="S4.SS4.p1.2.m2.1.1.cmml">
          …
         </mi>
         <mo id="S4.SS4.p1.2.m2.4.4.3.3.7" xref="S4.SS4.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S4.SS4.p1.2.m2.4.4.3.3.3" xref="S4.SS4.p1.2.m2.4.4.3.3.3.cmml">
          <mi id="S4.SS4.p1.2.m2.4.4.3.3.3.2" xref="S4.SS4.p1.2.m2.4.4.3.3.3.2.cmml">
           𝒆
          </mi>
          <mi id="S4.SS4.p1.2.m2.4.4.3.3.3.3" xref="S4.SS4.p1.2.m2.4.4.3.3.3.3.cmml">
           i
          </mi>
         </msub>
         <mo id="S4.SS4.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S4.SS4.p1.2.m2.4.4.3.4.cmml">
          }
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.4b">
        <apply id="S4.SS4.p1.2.m2.4.4.cmml" xref="S4.SS4.p1.2.m2.4.4">
         <eq id="S4.SS4.p1.2.m2.4.4.4.cmml" xref="S4.SS4.p1.2.m2.4.4.4">
         </eq>
         <apply id="S4.SS4.p1.2.m2.4.4.5.cmml" xref="S4.SS4.p1.2.m2.4.4.5">
          <csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.5.1.cmml" xref="S4.SS4.p1.2.m2.4.4.5">
           subscript
          </csymbol>
          <apply id="S4.SS4.p1.2.m2.4.4.5.2.cmml" xref="S4.SS4.p1.2.m2.4.4.5">
           <csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.5.2.1.cmml" xref="S4.SS4.p1.2.m2.4.4.5">
            superscript
           </csymbol>
           <ci id="S4.SS4.p1.2.m2.4.4.5.2.2.cmml" xref="S4.SS4.p1.2.m2.4.4.5.2.2">
            𝒆
           </ci>
           <ci id="S4.SS4.p1.2.m2.4.4.5.2.3.cmml" xref="S4.SS4.p1.2.m2.4.4.5.2.3">
            𝑃
           </ci>
          </apply>
          <cn id="S4.SS4.p1.2.m2.4.4.5.3.cmml" type="integer" xref="S4.SS4.p1.2.m2.4.4.5.3">
           1
          </cn>
         </apply>
         <set id="S4.SS4.p1.2.m2.4.4.3.4.cmml" xref="S4.SS4.p1.2.m2.4.4.3.3">
          <apply id="S4.SS4.p1.2.m2.2.2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.2.2.1.1.1.1.cmml" xref="S4.SS4.p1.2.m2.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.2.m2.2.2.1.1.1.2.cmml" xref="S4.SS4.p1.2.m2.2.2.1.1.1.2">
            𝒆
           </ci>
           <cn id="S4.SS4.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS4.p1.2.m2.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S4.SS4.p1.2.m2.3.3.2.2.2.cmml" xref="S4.SS4.p1.2.m2.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.3.3.2.2.2.1.cmml" xref="S4.SS4.p1.2.m2.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.2.m2.3.3.2.2.2.2.cmml" xref="S4.SS4.p1.2.m2.3.3.2.2.2.2">
            𝒆
           </ci>
           <cn id="S4.SS4.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS4.p1.2.m2.3.3.2.2.2.3">
            1
           </cn>
          </apply>
          <ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">
           …
          </ci>
          <apply id="S4.SS4.p1.2.m2.4.4.3.3.3.cmml" xref="S4.SS4.p1.2.m2.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.3.3.3.1.cmml" xref="S4.SS4.p1.2.m2.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.2.m2.4.4.3.3.3.2.cmml" xref="S4.SS4.p1.2.m2.4.4.3.3.3.2">
            𝒆
           </ci>
           <ci id="S4.SS4.p1.2.m2.4.4.3.3.3.3.cmml" xref="S4.SS4.p1.2.m2.4.4.3.3.3.3">
            𝑖
           </ci>
          </apply>
         </set>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.4c">
        \bm{e}^{P}_{1}=\{\bm{e}_{0},\bm{e}_{1},\dots,\bm{e}_{i}\}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\bm{e}^{P}_{2}=\{\bm{e}_{i+1},\dots,\bm{e}_{n}\}" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.3">
      <semantics id="S4.SS4.p1.3.m3.3a">
       <mrow id="S4.SS4.p1.3.m3.3.3" xref="S4.SS4.p1.3.m3.3.3.cmml">
        <msubsup id="S4.SS4.p1.3.m3.3.3.4" xref="S4.SS4.p1.3.m3.3.3.4.cmml">
         <mi id="S4.SS4.p1.3.m3.3.3.4.2.2" xref="S4.SS4.p1.3.m3.3.3.4.2.2.cmml">
          𝒆
         </mi>
         <mn id="S4.SS4.p1.3.m3.3.3.4.3" xref="S4.SS4.p1.3.m3.3.3.4.3.cmml">
          2
         </mn>
         <mi id="S4.SS4.p1.3.m3.3.3.4.2.3" xref="S4.SS4.p1.3.m3.3.3.4.2.3.cmml">
          P
         </mi>
        </msubsup>
        <mo id="S4.SS4.p1.3.m3.3.3.3" xref="S4.SS4.p1.3.m3.3.3.3.cmml">
         =
        </mo>
        <mrow id="S4.SS4.p1.3.m3.3.3.2.2" xref="S4.SS4.p1.3.m3.3.3.2.3.cmml">
         <mo id="S4.SS4.p1.3.m3.3.3.2.2.3" stretchy="false" xref="S4.SS4.p1.3.m3.3.3.2.3.cmml">
          {
         </mo>
         <msub id="S4.SS4.p1.3.m3.2.2.1.1.1" xref="S4.SS4.p1.3.m3.2.2.1.1.1.cmml">
          <mi id="S4.SS4.p1.3.m3.2.2.1.1.1.2" xref="S4.SS4.p1.3.m3.2.2.1.1.1.2.cmml">
           𝒆
          </mi>
          <mrow id="S4.SS4.p1.3.m3.2.2.1.1.1.3" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.cmml">
           <mi id="S4.SS4.p1.3.m3.2.2.1.1.1.3.2" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.2.cmml">
            i
           </mi>
           <mo id="S4.SS4.p1.3.m3.2.2.1.1.1.3.1" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.1.cmml">
            +
           </mo>
           <mn id="S4.SS4.p1.3.m3.2.2.1.1.1.3.3" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.3.cmml">
            1
           </mn>
          </mrow>
         </msub>
         <mo id="S4.SS4.p1.3.m3.3.3.2.2.4" xref="S4.SS4.p1.3.m3.3.3.2.3.cmml">
          ,
         </mo>
         <mi id="S4.SS4.p1.3.m3.1.1" mathvariant="normal" xref="S4.SS4.p1.3.m3.1.1.cmml">
          …
         </mi>
         <mo id="S4.SS4.p1.3.m3.3.3.2.2.5" xref="S4.SS4.p1.3.m3.3.3.2.3.cmml">
          ,
         </mo>
         <msub id="S4.SS4.p1.3.m3.3.3.2.2.2" xref="S4.SS4.p1.3.m3.3.3.2.2.2.cmml">
          <mi id="S4.SS4.p1.3.m3.3.3.2.2.2.2" xref="S4.SS4.p1.3.m3.3.3.2.2.2.2.cmml">
           𝒆
          </mi>
          <mi id="S4.SS4.p1.3.m3.3.3.2.2.2.3" xref="S4.SS4.p1.3.m3.3.3.2.2.2.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S4.SS4.p1.3.m3.3.3.2.2.6" stretchy="false" xref="S4.SS4.p1.3.m3.3.3.2.3.cmml">
          }
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.3b">
        <apply id="S4.SS4.p1.3.m3.3.3.cmml" xref="S4.SS4.p1.3.m3.3.3">
         <eq id="S4.SS4.p1.3.m3.3.3.3.cmml" xref="S4.SS4.p1.3.m3.3.3.3">
         </eq>
         <apply id="S4.SS4.p1.3.m3.3.3.4.cmml" xref="S4.SS4.p1.3.m3.3.3.4">
          <csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.3.3.4.1.cmml" xref="S4.SS4.p1.3.m3.3.3.4">
           subscript
          </csymbol>
          <apply id="S4.SS4.p1.3.m3.3.3.4.2.cmml" xref="S4.SS4.p1.3.m3.3.3.4">
           <csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.3.3.4.2.1.cmml" xref="S4.SS4.p1.3.m3.3.3.4">
            superscript
           </csymbol>
           <ci id="S4.SS4.p1.3.m3.3.3.4.2.2.cmml" xref="S4.SS4.p1.3.m3.3.3.4.2.2">
            𝒆
           </ci>
           <ci id="S4.SS4.p1.3.m3.3.3.4.2.3.cmml" xref="S4.SS4.p1.3.m3.3.3.4.2.3">
            𝑃
           </ci>
          </apply>
          <cn id="S4.SS4.p1.3.m3.3.3.4.3.cmml" type="integer" xref="S4.SS4.p1.3.m3.3.3.4.3">
           2
          </cn>
         </apply>
         <set id="S4.SS4.p1.3.m3.3.3.2.3.cmml" xref="S4.SS4.p1.3.m3.3.3.2.2">
          <apply id="S4.SS4.p1.3.m3.2.2.1.1.1.cmml" xref="S4.SS4.p1.3.m3.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS4.p1.3.m3.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS4.p1.3.m3.2.2.1.1.1.2">
            𝒆
           </ci>
           <apply id="S4.SS4.p1.3.m3.2.2.1.1.1.3.cmml" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3">
            <plus id="S4.SS4.p1.3.m3.2.2.1.1.1.3.1.cmml" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.1">
            </plus>
            <ci id="S4.SS4.p1.3.m3.2.2.1.1.1.3.2.cmml" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.2">
             𝑖
            </ci>
            <cn id="S4.SS4.p1.3.m3.2.2.1.1.1.3.3.cmml" type="integer" xref="S4.SS4.p1.3.m3.2.2.1.1.1.3.3">
             1
            </cn>
           </apply>
          </apply>
          <ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">
           …
          </ci>
          <apply id="S4.SS4.p1.3.m3.3.3.2.2.2.cmml" xref="S4.SS4.p1.3.m3.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.3.3.2.2.2.1.cmml" xref="S4.SS4.p1.3.m3.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S4.SS4.p1.3.m3.3.3.2.2.2.2.cmml" xref="S4.SS4.p1.3.m3.3.3.2.2.2.2">
            𝒆
           </ci>
           <ci id="S4.SS4.p1.3.m3.3.3.2.2.2.3.cmml" xref="S4.SS4.p1.3.m3.3.3.2.2.2.3">
            𝑛
           </ci>
          </apply>
         </set>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.3c">
        \bm{e}^{P}_{2}=\{\bm{e}_{i+1},\dots,\bm{e}_{n}\}
       </annotation>
      </semantics>
     </math>
     .
The right side of Figure
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.4. Fusion Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     shows an example of concatenating a prompt embedding and a code embedding where (e), (f), and (g) showcase three concatenation modes, respectively.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="119" id="S4.F3.g1" src="/html/2312.16066/assets/x3.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3.
     </span>
     Example of prompt and code concatenation
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.5.
    </span>
    Model Training
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SS5.p1">
    <p class="ltx_p" id="S4.SS5.p1.23">
     <span class="ltx_text ltx_font_bold" id="S4.SS5.p1.23.1">
      Predicted Summary Generation.
     </span>
     In PromptCS, the predicted summary is generated by the second component, i.e., the LLM. As shown in Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.1. Overview ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     (1), PromptCS directly feeds the fusion embedding (i.e.,
     <math alttext="\bm{e}^{F}" class="ltx_Math" display="inline" id="S4.SS5.p1.1.m1.1">
      <semantics id="S4.SS5.p1.1.m1.1a">
       <msup id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">
        <mi id="S4.SS5.p1.1.m1.1.1.2" xref="S4.SS5.p1.1.m1.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS5.p1.1.m1.1.1.3" xref="S4.SS5.p1.1.m1.1.1.3.cmml">
         F
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b">
        <apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS5.p1.1.m1.1.1.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS5.p1.1.m1.1.1.3.cmml" xref="S4.SS5.p1.1.m1.1.1.3">
          𝐹
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">
        \bm{e}^{F}
       </annotation>
      </semantics>
     </math>
     ) to the module blocks of the LLM that can generate natural language summaries.
As mentioned in Section
     <a class="ltx_ref" href="#S2.SS2" title="2.2. Large Language Model ‣ 2. background ‣ A Prompt Learning Framework for Source Code Summarization">
      <span class="ltx_text ltx_ref_tag">
       2.2
      </span>
     </a>
     , in this paper, we pay more attention to adapting autoregressive LLMs to the code summarization task. For autoregressive LLMs, predicting code summary can be viewed as a conditional generation task where the input is a context and the output is a sequence of tokens.
Formally, let
     <math alttext="\bm{z}=[\bm{e}^{F},\bm{e}^{S}]" class="ltx_Math" display="inline" id="S4.SS5.p1.2.m2.2">
      <semantics id="S4.SS5.p1.2.m2.2a">
       <mrow id="S4.SS5.p1.2.m2.2.2" xref="S4.SS5.p1.2.m2.2.2.cmml">
        <mi id="S4.SS5.p1.2.m2.2.2.4" xref="S4.SS5.p1.2.m2.2.2.4.cmml">
         𝒛
        </mi>
        <mo id="S4.SS5.p1.2.m2.2.2.3" xref="S4.SS5.p1.2.m2.2.2.3.cmml">
         =
        </mo>
        <mrow id="S4.SS5.p1.2.m2.2.2.2.2" xref="S4.SS5.p1.2.m2.2.2.2.3.cmml">
         <mo id="S4.SS5.p1.2.m2.2.2.2.2.3" stretchy="false" xref="S4.SS5.p1.2.m2.2.2.2.3.cmml">
          [
         </mo>
         <msup id="S4.SS5.p1.2.m2.1.1.1.1.1" xref="S4.SS5.p1.2.m2.1.1.1.1.1.cmml">
          <mi id="S4.SS5.p1.2.m2.1.1.1.1.1.2" xref="S4.SS5.p1.2.m2.1.1.1.1.1.2.cmml">
           𝒆
          </mi>
          <mi id="S4.SS5.p1.2.m2.1.1.1.1.1.3" xref="S4.SS5.p1.2.m2.1.1.1.1.1.3.cmml">
           F
          </mi>
         </msup>
         <mo id="S4.SS5.p1.2.m2.2.2.2.2.4" xref="S4.SS5.p1.2.m2.2.2.2.3.cmml">
          ,
         </mo>
         <msup id="S4.SS5.p1.2.m2.2.2.2.2.2" xref="S4.SS5.p1.2.m2.2.2.2.2.2.cmml">
          <mi id="S4.SS5.p1.2.m2.2.2.2.2.2.2" xref="S4.SS5.p1.2.m2.2.2.2.2.2.2.cmml">
           𝒆
          </mi>
          <mi id="S4.SS5.p1.2.m2.2.2.2.2.2.3" xref="S4.SS5.p1.2.m2.2.2.2.2.2.3.cmml">
           S
          </mi>
         </msup>
         <mo id="S4.SS5.p1.2.m2.2.2.2.2.5" stretchy="false" xref="S4.SS5.p1.2.m2.2.2.2.3.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.2b">
        <apply id="S4.SS5.p1.2.m2.2.2.cmml" xref="S4.SS5.p1.2.m2.2.2">
         <eq id="S4.SS5.p1.2.m2.2.2.3.cmml" xref="S4.SS5.p1.2.m2.2.2.3">
         </eq>
         <ci id="S4.SS5.p1.2.m2.2.2.4.cmml" xref="S4.SS5.p1.2.m2.2.2.4">
          𝒛
         </ci>
         <interval closure="closed" id="S4.SS5.p1.2.m2.2.2.2.3.cmml" xref="S4.SS5.p1.2.m2.2.2.2.2">
          <apply id="S4.SS5.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS5.p1.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1.1.1.1">
            superscript
           </csymbol>
           <ci id="S4.SS5.p1.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS5.p1.2.m2.1.1.1.1.1.2">
            𝒆
           </ci>
           <ci id="S4.SS5.p1.2.m2.1.1.1.1.1.3.cmml" xref="S4.SS5.p1.2.m2.1.1.1.1.1.3">
            𝐹
           </ci>
          </apply>
          <apply id="S4.SS5.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS5.p1.2.m2.2.2.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS5.p1.2.m2.2.2.2.2.2.1.cmml" xref="S4.SS5.p1.2.m2.2.2.2.2.2">
            superscript
           </csymbol>
           <ci id="S4.SS5.p1.2.m2.2.2.2.2.2.2.cmml" xref="S4.SS5.p1.2.m2.2.2.2.2.2.2">
            𝒆
           </ci>
           <ci id="S4.SS5.p1.2.m2.2.2.2.2.2.3.cmml" xref="S4.SS5.p1.2.m2.2.2.2.2.2.3">
            𝑆
           </ci>
          </apply>
         </interval>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.2c">
        \bm{z}=[\bm{e}^{F},\bm{e}^{S}]
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="\bm{e}^{S}" class="ltx_Math" display="inline" id="S4.SS5.p1.3.m3.1">
      <semantics id="S4.SS5.p1.3.m3.1a">
       <msup id="S4.SS5.p1.3.m3.1.1" xref="S4.SS5.p1.3.m3.1.1.cmml">
        <mi id="S4.SS5.p1.3.m3.1.1.2" xref="S4.SS5.p1.3.m3.1.1.2.cmml">
         𝒆
        </mi>
        <mi id="S4.SS5.p1.3.m3.1.1.3" xref="S4.SS5.p1.3.m3.1.1.3.cmml">
         S
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b">
        <apply id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.3.m3.1.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1">
          superscript
         </csymbol>
         <ci id="S4.SS5.p1.3.m3.1.1.2.cmml" xref="S4.SS5.p1.3.m3.1.1.2">
          𝒆
         </ci>
         <ci id="S4.SS5.p1.3.m3.1.1.3.cmml" xref="S4.SS5.p1.3.m3.1.1.3">
          𝑆
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">
        \bm{e}^{S}
       </annotation>
      </semantics>
     </math>
     is the summary embedding obtained by feeding the already generated summary into the input embedding layer of the LLM. And
     <math alttext="\bm{z}_{i}" class="ltx_Math" display="inline" id="S4.SS5.p1.4.m4.1">
      <semantics id="S4.SS5.p1.4.m4.1a">
       <msub id="S4.SS5.p1.4.m4.1.1" xref="S4.SS5.p1.4.m4.1.1.cmml">
        <mi id="S4.SS5.p1.4.m4.1.1.2" xref="S4.SS5.p1.4.m4.1.1.2.cmml">
         𝒛
        </mi>
        <mi id="S4.SS5.p1.4.m4.1.1.3" xref="S4.SS5.p1.4.m4.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.4.m4.1b">
        <apply id="S4.SS5.p1.4.m4.1.1.cmml" xref="S4.SS5.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.4.m4.1.1.1.cmml" xref="S4.SS5.p1.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.4.m4.1.1.2.cmml" xref="S4.SS5.p1.4.m4.1.1.2">
          𝒛
         </ci>
         <ci id="S4.SS5.p1.4.m4.1.1.3.cmml" xref="S4.SS5.p1.4.m4.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.4.m4.1c">
        \bm{z}_{i}
       </annotation>
      </semantics>
     </math>
     denotes the
     <math alttext="i" class="ltx_Math" display="inline" id="S4.SS5.p1.5.m5.1">
      <semantics id="S4.SS5.p1.5.m5.1a">
       <mi id="S4.SS5.p1.5.m5.1.1" xref="S4.SS5.p1.5.m5.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.5.m5.1b">
        <ci id="S4.SS5.p1.5.m5.1.1.cmml" xref="S4.SS5.p1.5.m5.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.5.m5.1c">
        i
       </annotation>
      </semantics>
     </math>
     -th value in
     <math alttext="\bm{z}" class="ltx_Math" display="inline" id="S4.SS5.p1.6.m6.1">
      <semantics id="S4.SS5.p1.6.m6.1a">
       <mi id="S4.SS5.p1.6.m6.1.1" xref="S4.SS5.p1.6.m6.1.1.cmml">
        𝒛
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.6.m6.1b">
        <ci id="S4.SS5.p1.6.m6.1.1.cmml" xref="S4.SS5.p1.6.m6.1.1">
         𝒛
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.6.m6.1c">
        \bm{z}
       </annotation>
      </semantics>
     </math>
     . The activation vector generated by the LLM at time step
     <math alttext="i" class="ltx_Math" display="inline" id="S4.SS5.p1.7.m7.1">
      <semantics id="S4.SS5.p1.7.m7.1a">
       <mi id="S4.SS5.p1.7.m7.1.1" xref="S4.SS5.p1.7.m7.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.7.m7.1b">
        <ci id="S4.SS5.p1.7.m7.1.1.cmml" xref="S4.SS5.p1.7.m7.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.7.m7.1c">
        i
       </annotation>
      </semantics>
     </math>
     is
     <math alttext="a_{i}=[a_{i}^{(1)},\dots,a_{i}^{(n)}]" class="ltx_Math" display="inline" id="S4.SS5.p1.8.m8.5">
      <semantics id="S4.SS5.p1.8.m8.5a">
       <mrow id="S4.SS5.p1.8.m8.5.5" xref="S4.SS5.p1.8.m8.5.5.cmml">
        <msub id="S4.SS5.p1.8.m8.5.5.4" xref="S4.SS5.p1.8.m8.5.5.4.cmml">
         <mi id="S4.SS5.p1.8.m8.5.5.4.2" xref="S4.SS5.p1.8.m8.5.5.4.2.cmml">
          a
         </mi>
         <mi id="S4.SS5.p1.8.m8.5.5.4.3" xref="S4.SS5.p1.8.m8.5.5.4.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S4.SS5.p1.8.m8.5.5.3" xref="S4.SS5.p1.8.m8.5.5.3.cmml">
         =
        </mo>
        <mrow id="S4.SS5.p1.8.m8.5.5.2.2" xref="S4.SS5.p1.8.m8.5.5.2.3.cmml">
         <mo id="S4.SS5.p1.8.m8.5.5.2.2.3" stretchy="false" xref="S4.SS5.p1.8.m8.5.5.2.3.cmml">
          [
         </mo>
         <msubsup id="S4.SS5.p1.8.m8.4.4.1.1.1" xref="S4.SS5.p1.8.m8.4.4.1.1.1.cmml">
          <mi id="S4.SS5.p1.8.m8.4.4.1.1.1.2.2" xref="S4.SS5.p1.8.m8.4.4.1.1.1.2.2.cmml">
           a
          </mi>
          <mi id="S4.SS5.p1.8.m8.4.4.1.1.1.2.3" xref="S4.SS5.p1.8.m8.4.4.1.1.1.2.3.cmml">
           i
          </mi>
          <mrow id="S4.SS5.p1.8.m8.1.1.1.3" xref="S4.SS5.p1.8.m8.4.4.1.1.1.cmml">
           <mo id="S4.SS5.p1.8.m8.1.1.1.3.1" stretchy="false" xref="S4.SS5.p1.8.m8.4.4.1.1.1.cmml">
            (
           </mo>
           <mn id="S4.SS5.p1.8.m8.1.1.1.1" xref="S4.SS5.p1.8.m8.1.1.1.1.cmml">
            1
           </mn>
           <mo id="S4.SS5.p1.8.m8.1.1.1.3.2" stretchy="false" xref="S4.SS5.p1.8.m8.4.4.1.1.1.cmml">
            )
           </mo>
          </mrow>
         </msubsup>
         <mo id="S4.SS5.p1.8.m8.5.5.2.2.4" xref="S4.SS5.p1.8.m8.5.5.2.3.cmml">
          ,
         </mo>
         <mi id="S4.SS5.p1.8.m8.3.3" mathvariant="normal" xref="S4.SS5.p1.8.m8.3.3.cmml">
          …
         </mi>
         <mo id="S4.SS5.p1.8.m8.5.5.2.2.5" xref="S4.SS5.p1.8.m8.5.5.2.3.cmml">
          ,
         </mo>
         <msubsup id="S4.SS5.p1.8.m8.5.5.2.2.2" xref="S4.SS5.p1.8.m8.5.5.2.2.2.cmml">
          <mi id="S4.SS5.p1.8.m8.5.5.2.2.2.2.2" xref="S4.SS5.p1.8.m8.5.5.2.2.2.2.2.cmml">
           a
          </mi>
          <mi id="S4.SS5.p1.8.m8.5.5.2.2.2.2.3" xref="S4.SS5.p1.8.m8.5.5.2.2.2.2.3.cmml">
           i
          </mi>
          <mrow id="S4.SS5.p1.8.m8.2.2.1.3" xref="S4.SS5.p1.8.m8.5.5.2.2.2.cmml">
           <mo id="S4.SS5.p1.8.m8.2.2.1.3.1" stretchy="false" xref="S4.SS5.p1.8.m8.5.5.2.2.2.cmml">
            (
           </mo>
           <mi id="S4.SS5.p1.8.m8.2.2.1.1" xref="S4.SS5.p1.8.m8.2.2.1.1.cmml">
            n
           </mi>
           <mo id="S4.SS5.p1.8.m8.2.2.1.3.2" stretchy="false" xref="S4.SS5.p1.8.m8.5.5.2.2.2.cmml">
            )
           </mo>
          </mrow>
         </msubsup>
         <mo id="S4.SS5.p1.8.m8.5.5.2.2.6" stretchy="false" xref="S4.SS5.p1.8.m8.5.5.2.3.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.8.m8.5b">
        <apply id="S4.SS5.p1.8.m8.5.5.cmml" xref="S4.SS5.p1.8.m8.5.5">
         <eq id="S4.SS5.p1.8.m8.5.5.3.cmml" xref="S4.SS5.p1.8.m8.5.5.3">
         </eq>
         <apply id="S4.SS5.p1.8.m8.5.5.4.cmml" xref="S4.SS5.p1.8.m8.5.5.4">
          <csymbol cd="ambiguous" id="S4.SS5.p1.8.m8.5.5.4.1.cmml" xref="S4.SS5.p1.8.m8.5.5.4">
           subscript
          </csymbol>
          <ci id="S4.SS5.p1.8.m8.5.5.4.2.cmml" xref="S4.SS5.p1.8.m8.5.5.4.2">
           𝑎
          </ci>
          <ci id="S4.SS5.p1.8.m8.5.5.4.3.cmml" xref="S4.SS5.p1.8.m8.5.5.4.3">
           𝑖
          </ci>
         </apply>
         <list id="S4.SS5.p1.8.m8.5.5.2.3.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2">
          <apply id="S4.SS5.p1.8.m8.4.4.1.1.1.cmml" xref="S4.SS5.p1.8.m8.4.4.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS5.p1.8.m8.4.4.1.1.1.1.cmml" xref="S4.SS5.p1.8.m8.4.4.1.1.1">
            superscript
           </csymbol>
           <apply id="S4.SS5.p1.8.m8.4.4.1.1.1.2.cmml" xref="S4.SS5.p1.8.m8.4.4.1.1.1">
            <csymbol cd="ambiguous" id="S4.SS5.p1.8.m8.4.4.1.1.1.2.1.cmml" xref="S4.SS5.p1.8.m8.4.4.1.1.1">
             subscript
            </csymbol>
            <ci id="S4.SS5.p1.8.m8.4.4.1.1.1.2.2.cmml" xref="S4.SS5.p1.8.m8.4.4.1.1.1.2.2">
             𝑎
            </ci>
            <ci id="S4.SS5.p1.8.m8.4.4.1.1.1.2.3.cmml" xref="S4.SS5.p1.8.m8.4.4.1.1.1.2.3">
             𝑖
            </ci>
           </apply>
           <cn id="S4.SS5.p1.8.m8.1.1.1.1.cmml" type="integer" xref="S4.SS5.p1.8.m8.1.1.1.1">
            1
           </cn>
          </apply>
          <ci id="S4.SS5.p1.8.m8.3.3.cmml" xref="S4.SS5.p1.8.m8.3.3">
           …
          </ci>
          <apply id="S4.SS5.p1.8.m8.5.5.2.2.2.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2.2">
           <csymbol cd="ambiguous" id="S4.SS5.p1.8.m8.5.5.2.2.2.1.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2.2">
            superscript
           </csymbol>
           <apply id="S4.SS5.p1.8.m8.5.5.2.2.2.2.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2.2">
            <csymbol cd="ambiguous" id="S4.SS5.p1.8.m8.5.5.2.2.2.2.1.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2.2">
             subscript
            </csymbol>
            <ci id="S4.SS5.p1.8.m8.5.5.2.2.2.2.2.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2.2.2.2">
             𝑎
            </ci>
            <ci id="S4.SS5.p1.8.m8.5.5.2.2.2.2.3.cmml" xref="S4.SS5.p1.8.m8.5.5.2.2.2.2.3">
             𝑖
            </ci>
           </apply>
           <ci id="S4.SS5.p1.8.m8.2.2.1.1.cmml" xref="S4.SS5.p1.8.m8.2.2.1.1">
            𝑛
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.8.m8.5c">
        a_{i}=[a_{i}^{(1)},\dots,a_{i}^{(n)}]
       </annotation>
      </semantics>
     </math>
     , which is a concatenation of the outputs of all activation layers at this time step. And
     <math alttext="a_{i}^{(j)}" class="ltx_Math" display="inline" id="S4.SS5.p1.9.m9.1">
      <semantics id="S4.SS5.p1.9.m9.1a">
       <msubsup id="S4.SS5.p1.9.m9.1.2" xref="S4.SS5.p1.9.m9.1.2.cmml">
        <mi id="S4.SS5.p1.9.m9.1.2.2.2" xref="S4.SS5.p1.9.m9.1.2.2.2.cmml">
         a
        </mi>
        <mi id="S4.SS5.p1.9.m9.1.2.2.3" xref="S4.SS5.p1.9.m9.1.2.2.3.cmml">
         i
        </mi>
        <mrow id="S4.SS5.p1.9.m9.1.1.1.3" xref="S4.SS5.p1.9.m9.1.2.cmml">
         <mo id="S4.SS5.p1.9.m9.1.1.1.3.1" stretchy="false" xref="S4.SS5.p1.9.m9.1.2.cmml">
          (
         </mo>
         <mi id="S4.SS5.p1.9.m9.1.1.1.1" xref="S4.SS5.p1.9.m9.1.1.1.1.cmml">
          j
         </mi>
         <mo id="S4.SS5.p1.9.m9.1.1.1.3.2" stretchy="false" xref="S4.SS5.p1.9.m9.1.2.cmml">
          )
         </mo>
        </mrow>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.9.m9.1b">
        <apply id="S4.SS5.p1.9.m9.1.2.cmml" xref="S4.SS5.p1.9.m9.1.2">
         <csymbol cd="ambiguous" id="S4.SS5.p1.9.m9.1.2.1.cmml" xref="S4.SS5.p1.9.m9.1.2">
          superscript
         </csymbol>
         <apply id="S4.SS5.p1.9.m9.1.2.2.cmml" xref="S4.SS5.p1.9.m9.1.2">
          <csymbol cd="ambiguous" id="S4.SS5.p1.9.m9.1.2.2.1.cmml" xref="S4.SS5.p1.9.m9.1.2">
           subscript
          </csymbol>
          <ci id="S4.SS5.p1.9.m9.1.2.2.2.cmml" xref="S4.SS5.p1.9.m9.1.2.2.2">
           𝑎
          </ci>
          <ci id="S4.SS5.p1.9.m9.1.2.2.3.cmml" xref="S4.SS5.p1.9.m9.1.2.2.3">
           𝑖
          </ci>
         </apply>
         <ci id="S4.SS5.p1.9.m9.1.1.1.1.cmml" xref="S4.SS5.p1.9.m9.1.1.1.1">
          𝑗
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.9.m9.1c">
        a_{i}^{(j)}
       </annotation>
      </semantics>
     </math>
     is the activation vector of the
     <math alttext="j" class="ltx_Math" display="inline" id="S4.SS5.p1.10.m10.1">
      <semantics id="S4.SS5.p1.10.m10.1a">
       <mi id="S4.SS5.p1.10.m10.1.1" xref="S4.SS5.p1.10.m10.1.1.cmml">
        j
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.10.m10.1b">
        <ci id="S4.SS5.p1.10.m10.1.1.cmml" xref="S4.SS5.p1.10.m10.1.1">
         𝑗
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.10.m10.1c">
        j
       </annotation>
      </semantics>
     </math>
     -th layer at time step
     <math alttext="i" class="ltx_Math" display="inline" id="S4.SS5.p1.11.m11.1">
      <semantics id="S4.SS5.p1.11.m11.1a">
       <mi id="S4.SS5.p1.11.m11.1.1" xref="S4.SS5.p1.11.m11.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.11.m11.1b">
        <ci id="S4.SS5.p1.11.m11.1.1.cmml" xref="S4.SS5.p1.11.m11.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.11.m11.1c">
        i
       </annotation>
      </semantics>
     </math>
     . The autoregressive LLM computes
     <math alttext="a_{i}" class="ltx_Math" display="inline" id="S4.SS5.p1.12.m12.1">
      <semantics id="S4.SS5.p1.12.m12.1a">
       <msub id="S4.SS5.p1.12.m12.1.1" xref="S4.SS5.p1.12.m12.1.1.cmml">
        <mi id="S4.SS5.p1.12.m12.1.1.2" xref="S4.SS5.p1.12.m12.1.1.2.cmml">
         a
        </mi>
        <mi id="S4.SS5.p1.12.m12.1.1.3" xref="S4.SS5.p1.12.m12.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.12.m12.1b">
        <apply id="S4.SS5.p1.12.m12.1.1.cmml" xref="S4.SS5.p1.12.m12.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.12.m12.1.1.1.cmml" xref="S4.SS5.p1.12.m12.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.12.m12.1.1.2.cmml" xref="S4.SS5.p1.12.m12.1.1.2">
          𝑎
         </ci>
         <ci id="S4.SS5.p1.12.m12.1.1.3.cmml" xref="S4.SS5.p1.12.m12.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.12.m12.1c">
        a_{i}
       </annotation>
      </semantics>
     </math>
     based on
     <math alttext="z_{i}" class="ltx_Math" display="inline" id="S4.SS5.p1.13.m13.1">
      <semantics id="S4.SS5.p1.13.m13.1a">
       <msub id="S4.SS5.p1.13.m13.1.1" xref="S4.SS5.p1.13.m13.1.1.cmml">
        <mi id="S4.SS5.p1.13.m13.1.1.2" xref="S4.SS5.p1.13.m13.1.1.2.cmml">
         z
        </mi>
        <mi id="S4.SS5.p1.13.m13.1.1.3" xref="S4.SS5.p1.13.m13.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.13.m13.1b">
        <apply id="S4.SS5.p1.13.m13.1.1.cmml" xref="S4.SS5.p1.13.m13.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.13.m13.1.1.1.cmml" xref="S4.SS5.p1.13.m13.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.13.m13.1.1.2.cmml" xref="S4.SS5.p1.13.m13.1.1.2">
          𝑧
         </ci>
         <ci id="S4.SS5.p1.13.m13.1.1.3.cmml" xref="S4.SS5.p1.13.m13.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.13.m13.1c">
        z_{i}
       </annotation>
      </semantics>
     </math>
     and the past activations
     <math alttext="a_{&lt;i}" class="ltx_Math" display="inline" id="S4.SS5.p1.14.m14.1">
      <semantics id="S4.SS5.p1.14.m14.1a">
       <msub id="S4.SS5.p1.14.m14.1.1" xref="S4.SS5.p1.14.m14.1.1.cmml">
        <mi id="S4.SS5.p1.14.m14.1.1.2" xref="S4.SS5.p1.14.m14.1.1.2.cmml">
         a
        </mi>
        <mrow id="S4.SS5.p1.14.m14.1.1.3" xref="S4.SS5.p1.14.m14.1.1.3.cmml">
         <mi id="S4.SS5.p1.14.m14.1.1.3.2" xref="S4.SS5.p1.14.m14.1.1.3.2.cmml">
         </mi>
         <mo id="S4.SS5.p1.14.m14.1.1.3.1" xref="S4.SS5.p1.14.m14.1.1.3.1.cmml">
          &lt;
         </mo>
         <mi id="S4.SS5.p1.14.m14.1.1.3.3" xref="S4.SS5.p1.14.m14.1.1.3.3.cmml">
          i
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.14.m14.1b">
        <apply id="S4.SS5.p1.14.m14.1.1.cmml" xref="S4.SS5.p1.14.m14.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.14.m14.1.1.1.cmml" xref="S4.SS5.p1.14.m14.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.14.m14.1.1.2.cmml" xref="S4.SS5.p1.14.m14.1.1.2">
          𝑎
         </ci>
         <apply id="S4.SS5.p1.14.m14.1.1.3.cmml" xref="S4.SS5.p1.14.m14.1.1.3">
          <lt id="S4.SS5.p1.14.m14.1.1.3.1.cmml" xref="S4.SS5.p1.14.m14.1.1.3.1">
          </lt>
          <csymbol cd="latexml" id="S4.SS5.p1.14.m14.1.1.3.2.cmml" xref="S4.SS5.p1.14.m14.1.1.3.2">
           absent
          </csymbol>
          <ci id="S4.SS5.p1.14.m14.1.1.3.3.cmml" xref="S4.SS5.p1.14.m14.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.14.m14.1c">
        a_{&lt;i}
       </annotation>
      </semantics>
     </math>
     in its left context, as follows:
     <math alttext="a_{i}=LLM(\bm{z}_{i},a_{&lt;i})" class="ltx_Math" display="inline" id="S4.SS5.p1.15.m15.2">
      <semantics id="S4.SS5.p1.15.m15.2a">
       <mrow id="S4.SS5.p1.15.m15.2.2" xref="S4.SS5.p1.15.m15.2.2.cmml">
        <msub id="S4.SS5.p1.15.m15.2.2.4" xref="S4.SS5.p1.15.m15.2.2.4.cmml">
         <mi id="S4.SS5.p1.15.m15.2.2.4.2" xref="S4.SS5.p1.15.m15.2.2.4.2.cmml">
          a
         </mi>
         <mi id="S4.SS5.p1.15.m15.2.2.4.3" xref="S4.SS5.p1.15.m15.2.2.4.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S4.SS5.p1.15.m15.2.2.3" xref="S4.SS5.p1.15.m15.2.2.3.cmml">
         =
        </mo>
        <mrow id="S4.SS5.p1.15.m15.2.2.2" xref="S4.SS5.p1.15.m15.2.2.2.cmml">
         <mi id="S4.SS5.p1.15.m15.2.2.2.4" xref="S4.SS5.p1.15.m15.2.2.2.4.cmml">
          L
         </mi>
         <mo id="S4.SS5.p1.15.m15.2.2.2.3" lspace="0em" rspace="0em" xref="S4.SS5.p1.15.m15.2.2.2.3.cmml">
          ​
         </mo>
         <mi id="S4.SS5.p1.15.m15.2.2.2.5" xref="S4.SS5.p1.15.m15.2.2.2.5.cmml">
          L
         </mi>
         <mo id="S4.SS5.p1.15.m15.2.2.2.3a" lspace="0em" rspace="0em" xref="S4.SS5.p1.15.m15.2.2.2.3.cmml">
          ​
         </mo>
         <mi id="S4.SS5.p1.15.m15.2.2.2.6" xref="S4.SS5.p1.15.m15.2.2.2.6.cmml">
          M
         </mi>
         <mo id="S4.SS5.p1.15.m15.2.2.2.3b" lspace="0em" rspace="0em" xref="S4.SS5.p1.15.m15.2.2.2.3.cmml">
          ​
         </mo>
         <mrow id="S4.SS5.p1.15.m15.2.2.2.2.2" xref="S4.SS5.p1.15.m15.2.2.2.2.3.cmml">
          <mo id="S4.SS5.p1.15.m15.2.2.2.2.2.3" stretchy="false" xref="S4.SS5.p1.15.m15.2.2.2.2.3.cmml">
           (
          </mo>
          <msub id="S4.SS5.p1.15.m15.1.1.1.1.1.1" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1.cmml">
           <mi id="S4.SS5.p1.15.m15.1.1.1.1.1.1.2" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1.2.cmml">
            𝒛
           </mi>
           <mi id="S4.SS5.p1.15.m15.1.1.1.1.1.1.3" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1.3.cmml">
            i
           </mi>
          </msub>
          <mo id="S4.SS5.p1.15.m15.2.2.2.2.2.4" xref="S4.SS5.p1.15.m15.2.2.2.2.3.cmml">
           ,
          </mo>
          <msub id="S4.SS5.p1.15.m15.2.2.2.2.2.2" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.cmml">
           <mi id="S4.SS5.p1.15.m15.2.2.2.2.2.2.2" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.2.cmml">
            a
           </mi>
           <mrow id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.cmml">
            <mi id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.2" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.2.cmml">
            </mi>
            <mo id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.1" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.1.cmml">
             &lt;
            </mo>
            <mi id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.3" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.3.cmml">
             i
            </mi>
           </mrow>
          </msub>
          <mo id="S4.SS5.p1.15.m15.2.2.2.2.2.5" stretchy="false" xref="S4.SS5.p1.15.m15.2.2.2.2.3.cmml">
           )
          </mo>
         </mrow>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.15.m15.2b">
        <apply id="S4.SS5.p1.15.m15.2.2.cmml" xref="S4.SS5.p1.15.m15.2.2">
         <eq id="S4.SS5.p1.15.m15.2.2.3.cmml" xref="S4.SS5.p1.15.m15.2.2.3">
         </eq>
         <apply id="S4.SS5.p1.15.m15.2.2.4.cmml" xref="S4.SS5.p1.15.m15.2.2.4">
          <csymbol cd="ambiguous" id="S4.SS5.p1.15.m15.2.2.4.1.cmml" xref="S4.SS5.p1.15.m15.2.2.4">
           subscript
          </csymbol>
          <ci id="S4.SS5.p1.15.m15.2.2.4.2.cmml" xref="S4.SS5.p1.15.m15.2.2.4.2">
           𝑎
          </ci>
          <ci id="S4.SS5.p1.15.m15.2.2.4.3.cmml" xref="S4.SS5.p1.15.m15.2.2.4.3">
           𝑖
          </ci>
         </apply>
         <apply id="S4.SS5.p1.15.m15.2.2.2.cmml" xref="S4.SS5.p1.15.m15.2.2.2">
          <times id="S4.SS5.p1.15.m15.2.2.2.3.cmml" xref="S4.SS5.p1.15.m15.2.2.2.3">
          </times>
          <ci id="S4.SS5.p1.15.m15.2.2.2.4.cmml" xref="S4.SS5.p1.15.m15.2.2.2.4">
           𝐿
          </ci>
          <ci id="S4.SS5.p1.15.m15.2.2.2.5.cmml" xref="S4.SS5.p1.15.m15.2.2.2.5">
           𝐿
          </ci>
          <ci id="S4.SS5.p1.15.m15.2.2.2.6.cmml" xref="S4.SS5.p1.15.m15.2.2.2.6">
           𝑀
          </ci>
          <interval closure="open" id="S4.SS5.p1.15.m15.2.2.2.2.3.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2">
           <apply id="S4.SS5.p1.15.m15.1.1.1.1.1.1.cmml" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S4.SS5.p1.15.m15.1.1.1.1.1.1.1.cmml" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S4.SS5.p1.15.m15.1.1.1.1.1.1.2.cmml" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1.2">
             𝒛
            </ci>
            <ci id="S4.SS5.p1.15.m15.1.1.1.1.1.1.3.cmml" xref="S4.SS5.p1.15.m15.1.1.1.1.1.1.3">
             𝑖
            </ci>
           </apply>
           <apply id="S4.SS5.p1.15.m15.2.2.2.2.2.2.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2">
            <csymbol cd="ambiguous" id="S4.SS5.p1.15.m15.2.2.2.2.2.2.1.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2">
             subscript
            </csymbol>
            <ci id="S4.SS5.p1.15.m15.2.2.2.2.2.2.2.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.2">
             𝑎
            </ci>
            <apply id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3">
             <lt id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.1.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.1">
             </lt>
             <csymbol cd="latexml" id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.2.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.2">
              absent
             </csymbol>
             <ci id="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.3.cmml" xref="S4.SS5.p1.15.m15.2.2.2.2.2.2.3.3">
              𝑖
             </ci>
            </apply>
           </apply>
          </interval>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.15.m15.2c">
        a_{i}=LLM(\bm{z}_{i},a_{&lt;i})
       </annotation>
      </semantics>
     </math>
     .
Then, it utilizes a matrix
     <math alttext="W" class="ltx_Math" display="inline" id="S4.SS5.p1.16.m16.1">
      <semantics id="S4.SS5.p1.16.m16.1a">
       <mi id="S4.SS5.p1.16.m16.1.1" xref="S4.SS5.p1.16.m16.1.1.cmml">
        W
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.16.m16.1b">
        <ci id="S4.SS5.p1.16.m16.1.1.cmml" xref="S4.SS5.p1.16.m16.1.1">
         𝑊
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.16.m16.1c">
        W
       </annotation>
      </semantics>
     </math>
     to map the last layer of
     <math alttext="a_{i}" class="ltx_Math" display="inline" id="S4.SS5.p1.17.m17.1">
      <semantics id="S4.SS5.p1.17.m17.1a">
       <msub id="S4.SS5.p1.17.m17.1.1" xref="S4.SS5.p1.17.m17.1.1.cmml">
        <mi id="S4.SS5.p1.17.m17.1.1.2" xref="S4.SS5.p1.17.m17.1.1.2.cmml">
         a
        </mi>
        <mi id="S4.SS5.p1.17.m17.1.1.3" xref="S4.SS5.p1.17.m17.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.17.m17.1b">
        <apply id="S4.SS5.p1.17.m17.1.1.cmml" xref="S4.SS5.p1.17.m17.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.17.m17.1.1.1.cmml" xref="S4.SS5.p1.17.m17.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.17.m17.1.1.2.cmml" xref="S4.SS5.p1.17.m17.1.1.2">
          𝑎
         </ci>
         <ci id="S4.SS5.p1.17.m17.1.1.3.cmml" xref="S4.SS5.p1.17.m17.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.17.m17.1c">
        a_{i}
       </annotation>
      </semantics>
     </math>
     to logits
     <math alttext="l_{i}" class="ltx_Math" display="inline" id="S4.SS5.p1.18.m18.1">
      <semantics id="S4.SS5.p1.18.m18.1a">
       <msub id="S4.SS5.p1.18.m18.1.1" xref="S4.SS5.p1.18.m18.1.1.cmml">
        <mi id="S4.SS5.p1.18.m18.1.1.2" xref="S4.SS5.p1.18.m18.1.1.2.cmml">
         l
        </mi>
        <mi id="S4.SS5.p1.18.m18.1.1.3" xref="S4.SS5.p1.18.m18.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.18.m18.1b">
        <apply id="S4.SS5.p1.18.m18.1.1.cmml" xref="S4.SS5.p1.18.m18.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.18.m18.1.1.1.cmml" xref="S4.SS5.p1.18.m18.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.18.m18.1.1.2.cmml" xref="S4.SS5.p1.18.m18.1.1.2">
          𝑙
         </ci>
         <ci id="S4.SS5.p1.18.m18.1.1.3.cmml" xref="S4.SS5.p1.18.m18.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.18.m18.1c">
        l_{i}
       </annotation>
      </semantics>
     </math>
     , which is the probability vector associated with the next word, i.e.,
     <math alttext="l_{i}=W\cdot a_{i}^{(n)}" class="ltx_Math" display="inline" id="S4.SS5.p1.19.m19.1">
      <semantics id="S4.SS5.p1.19.m19.1a">
       <mrow id="S4.SS5.p1.19.m19.1.2" xref="S4.SS5.p1.19.m19.1.2.cmml">
        <msub id="S4.SS5.p1.19.m19.1.2.2" xref="S4.SS5.p1.19.m19.1.2.2.cmml">
         <mi id="S4.SS5.p1.19.m19.1.2.2.2" xref="S4.SS5.p1.19.m19.1.2.2.2.cmml">
          l
         </mi>
         <mi id="S4.SS5.p1.19.m19.1.2.2.3" xref="S4.SS5.p1.19.m19.1.2.2.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S4.SS5.p1.19.m19.1.2.1" xref="S4.SS5.p1.19.m19.1.2.1.cmml">
         =
        </mo>
        <mrow id="S4.SS5.p1.19.m19.1.2.3" xref="S4.SS5.p1.19.m19.1.2.3.cmml">
         <mi id="S4.SS5.p1.19.m19.1.2.3.2" xref="S4.SS5.p1.19.m19.1.2.3.2.cmml">
          W
         </mi>
         <mo id="S4.SS5.p1.19.m19.1.2.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS5.p1.19.m19.1.2.3.1.cmml">
          ⋅
         </mo>
         <msubsup id="S4.SS5.p1.19.m19.1.2.3.3" xref="S4.SS5.p1.19.m19.1.2.3.3.cmml">
          <mi id="S4.SS5.p1.19.m19.1.2.3.3.2.2" xref="S4.SS5.p1.19.m19.1.2.3.3.2.2.cmml">
           a
          </mi>
          <mi id="S4.SS5.p1.19.m19.1.2.3.3.2.3" xref="S4.SS5.p1.19.m19.1.2.3.3.2.3.cmml">
           i
          </mi>
          <mrow id="S4.SS5.p1.19.m19.1.1.1.3" xref="S4.SS5.p1.19.m19.1.2.3.3.cmml">
           <mo id="S4.SS5.p1.19.m19.1.1.1.3.1" stretchy="false" xref="S4.SS5.p1.19.m19.1.2.3.3.cmml">
            (
           </mo>
           <mi id="S4.SS5.p1.19.m19.1.1.1.1" xref="S4.SS5.p1.19.m19.1.1.1.1.cmml">
            n
           </mi>
           <mo id="S4.SS5.p1.19.m19.1.1.1.3.2" stretchy="false" xref="S4.SS5.p1.19.m19.1.2.3.3.cmml">
            )
           </mo>
          </mrow>
         </msubsup>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.19.m19.1b">
        <apply id="S4.SS5.p1.19.m19.1.2.cmml" xref="S4.SS5.p1.19.m19.1.2">
         <eq id="S4.SS5.p1.19.m19.1.2.1.cmml" xref="S4.SS5.p1.19.m19.1.2.1">
         </eq>
         <apply id="S4.SS5.p1.19.m19.1.2.2.cmml" xref="S4.SS5.p1.19.m19.1.2.2">
          <csymbol cd="ambiguous" id="S4.SS5.p1.19.m19.1.2.2.1.cmml" xref="S4.SS5.p1.19.m19.1.2.2">
           subscript
          </csymbol>
          <ci id="S4.SS5.p1.19.m19.1.2.2.2.cmml" xref="S4.SS5.p1.19.m19.1.2.2.2">
           𝑙
          </ci>
          <ci id="S4.SS5.p1.19.m19.1.2.2.3.cmml" xref="S4.SS5.p1.19.m19.1.2.2.3">
           𝑖
          </ci>
         </apply>
         <apply id="S4.SS5.p1.19.m19.1.2.3.cmml" xref="S4.SS5.p1.19.m19.1.2.3">
          <ci id="S4.SS5.p1.19.m19.1.2.3.1.cmml" xref="S4.SS5.p1.19.m19.1.2.3.1">
           ⋅
          </ci>
          <ci id="S4.SS5.p1.19.m19.1.2.3.2.cmml" xref="S4.SS5.p1.19.m19.1.2.3.2">
           𝑊
          </ci>
          <apply id="S4.SS5.p1.19.m19.1.2.3.3.cmml" xref="S4.SS5.p1.19.m19.1.2.3.3">
           <csymbol cd="ambiguous" id="S4.SS5.p1.19.m19.1.2.3.3.1.cmml" xref="S4.SS5.p1.19.m19.1.2.3.3">
            superscript
           </csymbol>
           <apply id="S4.SS5.p1.19.m19.1.2.3.3.2.cmml" xref="S4.SS5.p1.19.m19.1.2.3.3">
            <csymbol cd="ambiguous" id="S4.SS5.p1.19.m19.1.2.3.3.2.1.cmml" xref="S4.SS5.p1.19.m19.1.2.3.3">
             subscript
            </csymbol>
            <ci id="S4.SS5.p1.19.m19.1.2.3.3.2.2.cmml" xref="S4.SS5.p1.19.m19.1.2.3.3.2.2">
             𝑎
            </ci>
            <ci id="S4.SS5.p1.19.m19.1.2.3.3.2.3.cmml" xref="S4.SS5.p1.19.m19.1.2.3.3.2.3">
             𝑖
            </ci>
           </apply>
           <ci id="S4.SS5.p1.19.m19.1.1.1.1.cmml" xref="S4.SS5.p1.19.m19.1.1.1.1">
            𝑛
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.19.m19.1c">
        l_{i}=W\cdot a_{i}^{(n)}
       </annotation>
      </semantics>
     </math>
     .
Finally, based on
     <math alttext="l_{i}" class="ltx_Math" display="inline" id="S4.SS5.p1.20.m20.1">
      <semantics id="S4.SS5.p1.20.m20.1a">
       <msub id="S4.SS5.p1.20.m20.1.1" xref="S4.SS5.p1.20.m20.1.1.cmml">
        <mi id="S4.SS5.p1.20.m20.1.1.2" xref="S4.SS5.p1.20.m20.1.1.2.cmml">
         l
        </mi>
        <mi id="S4.SS5.p1.20.m20.1.1.3" xref="S4.SS5.p1.20.m20.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.20.m20.1b">
        <apply id="S4.SS5.p1.20.m20.1.1.cmml" xref="S4.SS5.p1.20.m20.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.20.m20.1.1.1.cmml" xref="S4.SS5.p1.20.m20.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.20.m20.1.1.2.cmml" xref="S4.SS5.p1.20.m20.1.1.2">
          𝑙
         </ci>
         <ci id="S4.SS5.p1.20.m20.1.1.3.cmml" xref="S4.SS5.p1.20.m20.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.20.m20.1c">
        l_{i}
       </annotation>
      </semantics>
     </math>
     , it further uses the function
     <math alttext="P(\cdot)" class="ltx_Math" display="inline" id="S4.SS5.p1.21.m21.1">
      <semantics id="S4.SS5.p1.21.m21.1a">
       <mrow id="S4.SS5.p1.21.m21.1.2" xref="S4.SS5.p1.21.m21.1.2.cmml">
        <mi id="S4.SS5.p1.21.m21.1.2.2" xref="S4.SS5.p1.21.m21.1.2.2.cmml">
         P
        </mi>
        <mo id="S4.SS5.p1.21.m21.1.2.1" lspace="0em" rspace="0em" xref="S4.SS5.p1.21.m21.1.2.1.cmml">
         ​
        </mo>
        <mrow id="S4.SS5.p1.21.m21.1.2.3.2" xref="S4.SS5.p1.21.m21.1.2.cmml">
         <mo id="S4.SS5.p1.21.m21.1.2.3.2.1" stretchy="false" xref="S4.SS5.p1.21.m21.1.2.cmml">
          (
         </mo>
         <mo id="S4.SS5.p1.21.m21.1.1" lspace="0em" rspace="0em" xref="S4.SS5.p1.21.m21.1.1.cmml">
          ⋅
         </mo>
         <mo id="S4.SS5.p1.21.m21.1.2.3.2.2" stretchy="false" xref="S4.SS5.p1.21.m21.1.2.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.21.m21.1b">
        <apply id="S4.SS5.p1.21.m21.1.2.cmml" xref="S4.SS5.p1.21.m21.1.2">
         <times id="S4.SS5.p1.21.m21.1.2.1.cmml" xref="S4.SS5.p1.21.m21.1.2.1">
         </times>
         <ci id="S4.SS5.p1.21.m21.1.2.2.cmml" xref="S4.SS5.p1.21.m21.1.2.2">
          𝑃
         </ci>
         <ci id="S4.SS5.p1.21.m21.1.1.cmml" xref="S4.SS5.p1.21.m21.1.1">
          ⋅
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.21.m21.1c">
        P(\cdot)
       </annotation>
      </semantics>
     </math>
     to select the token with the highest probability in the LLM vocabulary as the next token
     <math alttext="s_{i+1}" class="ltx_Math" display="inline" id="S4.SS5.p1.22.m22.1">
      <semantics id="S4.SS5.p1.22.m22.1a">
       <msub id="S4.SS5.p1.22.m22.1.1" xref="S4.SS5.p1.22.m22.1.1.cmml">
        <mi id="S4.SS5.p1.22.m22.1.1.2" xref="S4.SS5.p1.22.m22.1.1.2.cmml">
         s
        </mi>
        <mrow id="S4.SS5.p1.22.m22.1.1.3" xref="S4.SS5.p1.22.m22.1.1.3.cmml">
         <mi id="S4.SS5.p1.22.m22.1.1.3.2" xref="S4.SS5.p1.22.m22.1.1.3.2.cmml">
          i
         </mi>
         <mo id="S4.SS5.p1.22.m22.1.1.3.1" xref="S4.SS5.p1.22.m22.1.1.3.1.cmml">
          +
         </mo>
         <mn id="S4.SS5.p1.22.m22.1.1.3.3" xref="S4.SS5.p1.22.m22.1.1.3.3.cmml">
          1
         </mn>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.22.m22.1b">
        <apply id="S4.SS5.p1.22.m22.1.1.cmml" xref="S4.SS5.p1.22.m22.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p1.22.m22.1.1.1.cmml" xref="S4.SS5.p1.22.m22.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p1.22.m22.1.1.2.cmml" xref="S4.SS5.p1.22.m22.1.1.2">
          𝑠
         </ci>
         <apply id="S4.SS5.p1.22.m22.1.1.3.cmml" xref="S4.SS5.p1.22.m22.1.1.3">
          <plus id="S4.SS5.p1.22.m22.1.1.3.1.cmml" xref="S4.SS5.p1.22.m22.1.1.3.1">
          </plus>
          <ci id="S4.SS5.p1.22.m22.1.1.3.2.cmml" xref="S4.SS5.p1.22.m22.1.1.3.2">
           𝑖
          </ci>
          <cn id="S4.SS5.p1.22.m22.1.1.3.3.cmml" type="integer" xref="S4.SS5.p1.22.m22.1.1.3.3">
           1
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.22.m22.1c">
        s_{i+1}
       </annotation>
      </semantics>
     </math>
     of the already generated summary, i.e.,
     <math alttext="s_{i+1}=P(l_{i})" class="ltx_Math" display="inline" id="S4.SS5.p1.23.m23.1">
      <semantics id="S4.SS5.p1.23.m23.1a">
       <mrow id="S4.SS5.p1.23.m23.1.1" xref="S4.SS5.p1.23.m23.1.1.cmml">
        <msub id="S4.SS5.p1.23.m23.1.1.3" xref="S4.SS5.p1.23.m23.1.1.3.cmml">
         <mi id="S4.SS5.p1.23.m23.1.1.3.2" xref="S4.SS5.p1.23.m23.1.1.3.2.cmml">
          s
         </mi>
         <mrow id="S4.SS5.p1.23.m23.1.1.3.3" xref="S4.SS5.p1.23.m23.1.1.3.3.cmml">
          <mi id="S4.SS5.p1.23.m23.1.1.3.3.2" xref="S4.SS5.p1.23.m23.1.1.3.3.2.cmml">
           i
          </mi>
          <mo id="S4.SS5.p1.23.m23.1.1.3.3.1" xref="S4.SS5.p1.23.m23.1.1.3.3.1.cmml">
           +
          </mo>
          <mn id="S4.SS5.p1.23.m23.1.1.3.3.3" xref="S4.SS5.p1.23.m23.1.1.3.3.3.cmml">
           1
          </mn>
         </mrow>
        </msub>
        <mo id="S4.SS5.p1.23.m23.1.1.2" xref="S4.SS5.p1.23.m23.1.1.2.cmml">
         =
        </mo>
        <mrow id="S4.SS5.p1.23.m23.1.1.1" xref="S4.SS5.p1.23.m23.1.1.1.cmml">
         <mi id="S4.SS5.p1.23.m23.1.1.1.3" xref="S4.SS5.p1.23.m23.1.1.1.3.cmml">
          P
         </mi>
         <mo id="S4.SS5.p1.23.m23.1.1.1.2" lspace="0em" rspace="0em" xref="S4.SS5.p1.23.m23.1.1.1.2.cmml">
          ​
         </mo>
         <mrow id="S4.SS5.p1.23.m23.1.1.1.1.1" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.cmml">
          <mo id="S4.SS5.p1.23.m23.1.1.1.1.1.2" stretchy="false" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.cmml">
           (
          </mo>
          <msub id="S4.SS5.p1.23.m23.1.1.1.1.1.1" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.cmml">
           <mi id="S4.SS5.p1.23.m23.1.1.1.1.1.1.2" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.2.cmml">
            l
           </mi>
           <mi id="S4.SS5.p1.23.m23.1.1.1.1.1.1.3" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.3.cmml">
            i
           </mi>
          </msub>
          <mo id="S4.SS5.p1.23.m23.1.1.1.1.1.3" stretchy="false" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p1.23.m23.1b">
        <apply id="S4.SS5.p1.23.m23.1.1.cmml" xref="S4.SS5.p1.23.m23.1.1">
         <eq id="S4.SS5.p1.23.m23.1.1.2.cmml" xref="S4.SS5.p1.23.m23.1.1.2">
         </eq>
         <apply id="S4.SS5.p1.23.m23.1.1.3.cmml" xref="S4.SS5.p1.23.m23.1.1.3">
          <csymbol cd="ambiguous" id="S4.SS5.p1.23.m23.1.1.3.1.cmml" xref="S4.SS5.p1.23.m23.1.1.3">
           subscript
          </csymbol>
          <ci id="S4.SS5.p1.23.m23.1.1.3.2.cmml" xref="S4.SS5.p1.23.m23.1.1.3.2">
           𝑠
          </ci>
          <apply id="S4.SS5.p1.23.m23.1.1.3.3.cmml" xref="S4.SS5.p1.23.m23.1.1.3.3">
           <plus id="S4.SS5.p1.23.m23.1.1.3.3.1.cmml" xref="S4.SS5.p1.23.m23.1.1.3.3.1">
           </plus>
           <ci id="S4.SS5.p1.23.m23.1.1.3.3.2.cmml" xref="S4.SS5.p1.23.m23.1.1.3.3.2">
            𝑖
           </ci>
           <cn id="S4.SS5.p1.23.m23.1.1.3.3.3.cmml" type="integer" xref="S4.SS5.p1.23.m23.1.1.3.3.3">
            1
           </cn>
          </apply>
         </apply>
         <apply id="S4.SS5.p1.23.m23.1.1.1.cmml" xref="S4.SS5.p1.23.m23.1.1.1">
          <times id="S4.SS5.p1.23.m23.1.1.1.2.cmml" xref="S4.SS5.p1.23.m23.1.1.1.2">
          </times>
          <ci id="S4.SS5.p1.23.m23.1.1.1.3.cmml" xref="S4.SS5.p1.23.m23.1.1.1.3">
           𝑃
          </ci>
          <apply id="S4.SS5.p1.23.m23.1.1.1.1.1.1.cmml" xref="S4.SS5.p1.23.m23.1.1.1.1.1">
           <csymbol cd="ambiguous" id="S4.SS5.p1.23.m23.1.1.1.1.1.1.1.cmml" xref="S4.SS5.p1.23.m23.1.1.1.1.1">
            subscript
           </csymbol>
           <ci id="S4.SS5.p1.23.m23.1.1.1.1.1.1.2.cmml" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.2">
            𝑙
           </ci>
           <ci id="S4.SS5.p1.23.m23.1.1.1.1.1.1.3.cmml" xref="S4.SS5.p1.23.m23.1.1.1.1.1.1.3">
            𝑖
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p1.23.m23.1c">
        s_{i+1}=P(l_{i})
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS5.p2">
    <p class="ltx_p" id="S4.SS5.p2.2">
     <span class="ltx_text ltx_font_bold" id="S4.SS5.p2.2.1">
      Train Process.
     </span>
     During the training process of PromptCS, the parameters of LLM are frozen, and only the parameters of the prompt encoder are updated. Let
     <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S4.SS5.p2.1.m1.1">
      <semantics id="S4.SS5.p2.1.m1.1a">
       <mover accent="true" id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml">
        <mi id="S4.SS5.p2.1.m1.1.1.2" xref="S4.SS5.p2.1.m1.1.1.2.cmml">
         y
        </mi>
        <mo id="S4.SS5.p2.1.m1.1.1.1" xref="S4.SS5.p2.1.m1.1.1.1.cmml">
         ^
        </mo>
       </mover>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b">
        <apply id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1">
         <ci id="S4.SS5.p2.1.m1.1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1.1">
          ^
         </ci>
         <ci id="S4.SS5.p2.1.m1.1.1.2.cmml" xref="S4.SS5.p2.1.m1.1.1.2">
          𝑦
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">
        \hat{y}
       </annotation>
      </semantics>
     </math>
     be the probability vector corresponding to the predicted summary and
     <math alttext="y" class="ltx_Math" display="inline" id="S4.SS5.p2.2.m2.1">
      <semantics id="S4.SS5.p2.2.m2.1a">
       <mi id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml">
        y
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.1b">
        <ci id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1">
         𝑦
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.1c">
        y
       </annotation>
      </semantics>
     </math>
     be the ground-truth summary. The loss function can be modeled as the following categorical cross-entropy loss function:
    </p>
    <table class="ltx_equationgroup ltx_eqn_table" id="S4.E2">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S4.E2X">
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1">
        <span class="ltx_tag ltx_tag_equationgroup ltx_align_left">
         (2)
        </span>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_eqn_cell">
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle\mathcal{L}(\Theta)=-\sum_{i=1}^{C}y_{i}log\frac{exp(\hat{y_{i}})}{\sum_{j=1}^{C}exp(\hat{y_{j}})}" class="ltx_Math" display="inline" id="S4.E2X.2.1.1.m1.3">
         <semantics id="S4.E2X.2.1.1.m1.3a">
          <mrow id="S4.E2X.2.1.1.m1.3.4" xref="S4.E2X.2.1.1.m1.3.4.cmml">
           <mrow id="S4.E2X.2.1.1.m1.3.4.2" xref="S4.E2X.2.1.1.m1.3.4.2.cmml">
            <mi class="ltx_font_mathcaligraphic" id="S4.E2X.2.1.1.m1.3.4.2.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.2.2.cmml">
             ℒ
            </mi>
            <mo id="S4.E2X.2.1.1.m1.3.4.2.1" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.3.4.2.1.cmml">
             ​
            </mo>
            <mrow id="S4.E2X.2.1.1.m1.3.4.2.3.2" xref="S4.E2X.2.1.1.m1.3.4.2.cmml">
             <mo id="S4.E2X.2.1.1.m1.3.4.2.3.2.1" maxsize="80%" minsize="80%" xref="S4.E2X.2.1.1.m1.3.4.2.cmml">
              (
             </mo>
             <mi id="S4.E2X.2.1.1.m1.3.3" mathsize="80%" mathvariant="normal" xref="S4.E2X.2.1.1.m1.3.3.cmml">
              Θ
             </mi>
             <mo id="S4.E2X.2.1.1.m1.3.4.2.3.2.2" maxsize="80%" minsize="80%" xref="S4.E2X.2.1.1.m1.3.4.2.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="S4.E2X.2.1.1.m1.3.4.1" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.1.cmml">
            =
           </mo>
           <mrow id="S4.E2X.2.1.1.m1.3.4.3" xref="S4.E2X.2.1.1.m1.3.4.3.cmml">
            <mo id="S4.E2X.2.1.1.m1.3.4.3a" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.cmml">
             −
            </mo>
            <mrow id="S4.E2X.2.1.1.m1.3.4.3.2" xref="S4.E2X.2.1.1.m1.3.4.3.2.cmml">
             <mstyle displaystyle="true" id="S4.E2X.2.1.1.m1.3.4.3.2.1" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.cmml">
              <munderover id="S4.E2X.2.1.1.m1.3.4.3.2.1a" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.cmml">
               <mo id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.2" maxsize="80%" minsize="80%" movablelimits="false" stretchy="true" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.2.cmml">
                ∑
               </mo>
               <mrow id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.cmml">
                <mi id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.2.cmml">
                 i
                </mi>
                <mo id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.1" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.1.cmml">
                 =
                </mo>
                <mn id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.3.cmml">
                 1
                </mn>
               </mrow>
               <mi id="S4.E2X.2.1.1.m1.3.4.3.2.1.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.3.cmml">
                C
               </mi>
              </munderover>
             </mstyle>
             <mrow id="S4.E2X.2.1.1.m1.3.4.3.2.2" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.cmml">
              <msub id="S4.E2X.2.1.1.m1.3.4.3.2.2.2" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2.cmml">
               <mi id="S4.E2X.2.1.1.m1.3.4.3.2.2.2.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2.2.cmml">
                y
               </mi>
               <mi id="S4.E2X.2.1.1.m1.3.4.3.2.2.2.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2.3.cmml">
                i
               </mi>
              </msub>
              <mo id="S4.E2X.2.1.1.m1.3.4.3.2.2.1" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.1.cmml">
               ​
              </mo>
              <mi id="S4.E2X.2.1.1.m1.3.4.3.2.2.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.3.cmml">
               l
              </mi>
              <mo id="S4.E2X.2.1.1.m1.3.4.3.2.2.1a" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.1.cmml">
               ​
              </mo>
              <mi id="S4.E2X.2.1.1.m1.3.4.3.2.2.4" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.4.cmml">
               o
              </mi>
              <mo id="S4.E2X.2.1.1.m1.3.4.3.2.2.1b" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.1.cmml">
               ​
              </mo>
              <mi id="S4.E2X.2.1.1.m1.3.4.3.2.2.5" mathsize="80%" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.5.cmml">
               g
              </mi>
              <mo id="S4.E2X.2.1.1.m1.3.4.3.2.2.1c" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.1.cmml">
               ​
              </mo>
              <mstyle displaystyle="true" id="S4.E2X.2.1.1.m1.2.2" xref="S4.E2X.2.1.1.m1.2.2.cmml">
               <mfrac id="S4.E2X.2.1.1.m1.2.2a" xref="S4.E2X.2.1.1.m1.2.2.cmml">
                <mrow id="S4.E2X.2.1.1.m1.1.1.1" xref="S4.E2X.2.1.1.m1.1.1.1.cmml">
                 <mi id="S4.E2X.2.1.1.m1.1.1.1.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.3.cmml">
                  e
                 </mi>
                 <mo id="S4.E2X.2.1.1.m1.1.1.1.2" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.1.1.1.2.cmml">
                  ​
                 </mo>
                 <mi id="S4.E2X.2.1.1.m1.1.1.1.4" mathsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.4.cmml">
                  x
                 </mi>
                 <mo id="S4.E2X.2.1.1.m1.1.1.1.2a" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.1.1.1.2.cmml">
                  ​
                 </mo>
                 <mi id="S4.E2X.2.1.1.m1.1.1.1.5" mathsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.5.cmml">
                  p
                 </mi>
                 <mo id="S4.E2X.2.1.1.m1.1.1.1.2b" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.1.1.1.2.cmml">
                  ​
                 </mo>
                 <mrow id="S4.E2X.2.1.1.m1.1.1.1.6.2" xref="S4.E2X.2.1.1.m1.1.1.1.1.cmml">
                  <mo id="S4.E2X.2.1.1.m1.1.1.1.6.2.1" maxsize="80%" minsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.1.cmml">
                   (
                  </mo>
                  <mover accent="true" id="S4.E2X.2.1.1.m1.1.1.1.1" xref="S4.E2X.2.1.1.m1.1.1.1.1.cmml">
                   <msub id="S4.E2X.2.1.1.m1.1.1.1.1.2" xref="S4.E2X.2.1.1.m1.1.1.1.1.2.cmml">
                    <mi id="S4.E2X.2.1.1.m1.1.1.1.1.2.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.1.2.2.cmml">
                     y
                    </mi>
                    <mi id="S4.E2X.2.1.1.m1.1.1.1.1.2.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.1.2.3.cmml">
                     i
                    </mi>
                   </msub>
                   <mo id="S4.E2X.2.1.1.m1.1.1.1.1.1" mathsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.1.1.cmml">
                    ^
                   </mo>
                  </mover>
                  <mo id="S4.E2X.2.1.1.m1.1.1.1.6.2.2" maxsize="80%" minsize="80%" xref="S4.E2X.2.1.1.m1.1.1.1.1.cmml">
                   )
                  </mo>
                 </mrow>
                </mrow>
                <mrow id="S4.E2X.2.1.1.m1.2.2.2" xref="S4.E2X.2.1.1.m1.2.2.2.cmml">
                 <msubsup id="S4.E2X.2.1.1.m1.2.2.2.2" xref="S4.E2X.2.1.1.m1.2.2.2.2.cmml">
                  <mo id="S4.E2X.2.1.1.m1.2.2.2.2.2.2" maxsize="80%" minsize="80%" stretchy="true" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.2.cmml">
                   ∑
                  </mo>
                  <mrow id="S4.E2X.2.1.1.m1.2.2.2.2.2.3" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.cmml">
                   <mi id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.2.cmml">
                    j
                   </mi>
                   <mo id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.1" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.1.cmml">
                    =
                   </mo>
                   <mn id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.3.cmml">
                    1
                   </mn>
                  </mrow>
                  <mi id="S4.E2X.2.1.1.m1.2.2.2.2.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.2.3.cmml">
                   C
                  </mi>
                 </msubsup>
                 <mrow id="S4.E2X.2.1.1.m1.2.2.2.3" xref="S4.E2X.2.1.1.m1.2.2.2.3.cmml">
                  <mi id="S4.E2X.2.1.1.m1.2.2.2.3.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.3.2.cmml">
                   e
                  </mi>
                  <mo id="S4.E2X.2.1.1.m1.2.2.2.3.1" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.2.2.2.3.1.cmml">
                   ​
                  </mo>
                  <mi id="S4.E2X.2.1.1.m1.2.2.2.3.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.3.3.cmml">
                   x
                  </mi>
                  <mo id="S4.E2X.2.1.1.m1.2.2.2.3.1a" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.2.2.2.3.1.cmml">
                   ​
                  </mo>
                  <mi id="S4.E2X.2.1.1.m1.2.2.2.3.4" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.3.4.cmml">
                   p
                  </mi>
                  <mo id="S4.E2X.2.1.1.m1.2.2.2.3.1b" lspace="0em" rspace="0em" xref="S4.E2X.2.1.1.m1.2.2.2.3.1.cmml">
                   ​
                  </mo>
                  <mrow id="S4.E2X.2.1.1.m1.2.2.2.3.5.2" xref="S4.E2X.2.1.1.m1.2.2.2.1.cmml">
                   <mo id="S4.E2X.2.1.1.m1.2.2.2.3.5.2.1" maxsize="80%" minsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.1.cmml">
                    (
                   </mo>
                   <mover accent="true" id="S4.E2X.2.1.1.m1.2.2.2.1" xref="S4.E2X.2.1.1.m1.2.2.2.1.cmml">
                    <msub id="S4.E2X.2.1.1.m1.2.2.2.1.2" xref="S4.E2X.2.1.1.m1.2.2.2.1.2.cmml">
                     <mi id="S4.E2X.2.1.1.m1.2.2.2.1.2.2" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.1.2.2.cmml">
                      y
                     </mi>
                     <mi id="S4.E2X.2.1.1.m1.2.2.2.1.2.3" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.1.2.3.cmml">
                      j
                     </mi>
                    </msub>
                    <mo id="S4.E2X.2.1.1.m1.2.2.2.1.1" mathsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.1.1.cmml">
                     ^
                    </mo>
                   </mover>
                   <mo id="S4.E2X.2.1.1.m1.2.2.2.3.5.2.2" maxsize="80%" minsize="80%" xref="S4.E2X.2.1.1.m1.2.2.2.1.cmml">
                    )
                   </mo>
                  </mrow>
                 </mrow>
                </mrow>
               </mfrac>
              </mstyle>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S4.E2X.2.1.1.m1.3b">
           <apply id="S4.E2X.2.1.1.m1.3.4.cmml" xref="S4.E2X.2.1.1.m1.3.4">
            <eq id="S4.E2X.2.1.1.m1.3.4.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.1">
            </eq>
            <apply id="S4.E2X.2.1.1.m1.3.4.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.2">
             <times id="S4.E2X.2.1.1.m1.3.4.2.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.2.1">
             </times>
             <ci id="S4.E2X.2.1.1.m1.3.4.2.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.2.2">
              ℒ
             </ci>
             <ci id="S4.E2X.2.1.1.m1.3.3.cmml" xref="S4.E2X.2.1.1.m1.3.3">
              Θ
             </ci>
            </apply>
            <apply id="S4.E2X.2.1.1.m1.3.4.3.cmml" xref="S4.E2X.2.1.1.m1.3.4.3">
             <minus id="S4.E2X.2.1.1.m1.3.4.3.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3">
             </minus>
             <apply id="S4.E2X.2.1.1.m1.3.4.3.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2">
              <apply id="S4.E2X.2.1.1.m1.3.4.3.2.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1">
               <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.3.4.3.2.1.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1">
                superscript
               </csymbol>
               <apply id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1">
                <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1">
                 subscript
                </csymbol>
                <sum id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.2">
                </sum>
                <apply id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3">
                 <eq id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.1">
                 </eq>
                 <ci id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.2">
                  𝑖
                 </ci>
                 <cn id="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.3.cmml" type="integer" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.2.3.3">
                  1
                 </cn>
                </apply>
               </apply>
               <ci id="S4.E2X.2.1.1.m1.3.4.3.2.1.3.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.1.3">
                𝐶
               </ci>
              </apply>
              <apply id="S4.E2X.2.1.1.m1.3.4.3.2.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2">
               <times id="S4.E2X.2.1.1.m1.3.4.3.2.2.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.1">
               </times>
               <apply id="S4.E2X.2.1.1.m1.3.4.3.2.2.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2">
                <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.3.4.3.2.2.2.1.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2">
                 subscript
                </csymbol>
                <ci id="S4.E2X.2.1.1.m1.3.4.3.2.2.2.2.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2.2">
                 𝑦
                </ci>
                <ci id="S4.E2X.2.1.1.m1.3.4.3.2.2.2.3.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.2.3">
                 𝑖
                </ci>
               </apply>
               <ci id="S4.E2X.2.1.1.m1.3.4.3.2.2.3.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.3">
                𝑙
               </ci>
               <ci id="S4.E2X.2.1.1.m1.3.4.3.2.2.4.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.4">
                𝑜
               </ci>
               <ci id="S4.E2X.2.1.1.m1.3.4.3.2.2.5.cmml" xref="S4.E2X.2.1.1.m1.3.4.3.2.2.5">
                𝑔
               </ci>
               <apply id="S4.E2X.2.1.1.m1.2.2.cmml" xref="S4.E2X.2.1.1.m1.2.2">
                <divide id="S4.E2X.2.1.1.m1.2.2.3.cmml" xref="S4.E2X.2.1.1.m1.2.2">
                </divide>
                <apply id="S4.E2X.2.1.1.m1.1.1.1.cmml" xref="S4.E2X.2.1.1.m1.1.1.1">
                 <times id="S4.E2X.2.1.1.m1.1.1.1.2.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.2">
                 </times>
                 <ci id="S4.E2X.2.1.1.m1.1.1.1.3.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.3">
                  𝑒
                 </ci>
                 <ci id="S4.E2X.2.1.1.m1.1.1.1.4.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.4">
                  𝑥
                 </ci>
                 <ci id="S4.E2X.2.1.1.m1.1.1.1.5.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.5">
                  𝑝
                 </ci>
                 <apply id="S4.E2X.2.1.1.m1.1.1.1.1.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.6.2">
                  <ci id="S4.E2X.2.1.1.m1.1.1.1.1.1.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.1.1">
                   ^
                  </ci>
                  <apply id="S4.E2X.2.1.1.m1.1.1.1.1.2.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.1.2">
                   <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.1.2">
                    subscript
                   </csymbol>
                   <ci id="S4.E2X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.1.2.2">
                    𝑦
                   </ci>
                   <ci id="S4.E2X.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S4.E2X.2.1.1.m1.1.1.1.1.2.3">
                    𝑖
                   </ci>
                  </apply>
                 </apply>
                </apply>
                <apply id="S4.E2X.2.1.1.m1.2.2.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2">
                 <apply id="S4.E2X.2.1.1.m1.2.2.2.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2">
                  <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.2.2.2.2.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2">
                   superscript
                  </csymbol>
                  <apply id="S4.E2X.2.1.1.m1.2.2.2.2.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2">
                   <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.2.2.2.2.2.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2">
                    subscript
                   </csymbol>
                   <sum id="S4.E2X.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.2">
                   </sum>
                   <apply id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3">
                    <eq id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.1">
                    </eq>
                    <ci id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.2">
                     𝑗
                    </ci>
                    <cn id="S4.E2X.2.1.1.m1.2.2.2.2.2.3.3.cmml" type="integer" xref="S4.E2X.2.1.1.m1.2.2.2.2.2.3.3">
                     1
                    </cn>
                   </apply>
                  </apply>
                  <ci id="S4.E2X.2.1.1.m1.2.2.2.2.3.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.2.3">
                   𝐶
                  </ci>
                 </apply>
                 <apply id="S4.E2X.2.1.1.m1.2.2.2.3.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.3">
                  <times id="S4.E2X.2.1.1.m1.2.2.2.3.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.3.1">
                  </times>
                  <ci id="S4.E2X.2.1.1.m1.2.2.2.3.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.3.2">
                   𝑒
                  </ci>
                  <ci id="S4.E2X.2.1.1.m1.2.2.2.3.3.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.3.3">
                   𝑥
                  </ci>
                  <ci id="S4.E2X.2.1.1.m1.2.2.2.3.4.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.3.4">
                   𝑝
                  </ci>
                  <apply id="S4.E2X.2.1.1.m1.2.2.2.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.3.5.2">
                   <ci id="S4.E2X.2.1.1.m1.2.2.2.1.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.1.1">
                    ^
                   </ci>
                   <apply id="S4.E2X.2.1.1.m1.2.2.2.1.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.1.2">
                    <csymbol cd="ambiguous" id="S4.E2X.2.1.1.m1.2.2.2.1.2.1.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.1.2">
                     subscript
                    </csymbol>
                    <ci id="S4.E2X.2.1.1.m1.2.2.2.1.2.2.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.1.2.2">
                     𝑦
                    </ci>
                    <ci id="S4.E2X.2.1.1.m1.2.2.2.1.2.3.cmml" xref="S4.E2X.2.1.1.m1.2.2.2.1.2.3">
                     𝑗
                    </ci>
                   </apply>
                  </apply>
                 </apply>
                </apply>
               </apply>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.E2X.2.1.1.m1.3c">
           \displaystyle\mathcal{L}(\Theta)=-\sum_{i=1}^{C}y_{i}log\frac{exp(\hat{y_{i}})}{\sum_{j=1}^{C}exp(\hat{y_{j}})}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
      </tr>
     </tbody>
    </table>
    <p class="ltx_p" id="S4.SS5.p2.7">
     where
     <math alttext="\Theta" class="ltx_Math" display="inline" id="S4.SS5.p2.3.m1.1">
      <semantics id="S4.SS5.p2.3.m1.1a">
       <mi id="S4.SS5.p2.3.m1.1.1" mathvariant="normal" xref="S4.SS5.p2.3.m1.1.1.cmml">
        Θ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m1.1b">
        <ci id="S4.SS5.p2.3.m1.1.1.cmml" xref="S4.SS5.p2.3.m1.1.1">
         Θ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.3.m1.1c">
        \Theta
       </annotation>
      </semantics>
     </math>
     representing the trainable parameters of the model;
     <math alttext="C" class="ltx_Math" display="inline" id="S4.SS5.p2.4.m2.1">
      <semantics id="S4.SS5.p2.4.m2.1a">
       <mi id="S4.SS5.p2.4.m2.1.1" xref="S4.SS5.p2.4.m2.1.1.cmml">
        C
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.4.m2.1b">
        <ci id="S4.SS5.p2.4.m2.1.1.cmml" xref="S4.SS5.p2.4.m2.1.1">
         𝐶
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.4.m2.1c">
        C
       </annotation>
      </semantics>
     </math>
     is the number of tokens in the vocabulary.
     <math alttext="\hat{y_{i}}" class="ltx_Math" display="inline" id="S4.SS5.p2.5.m3.1">
      <semantics id="S4.SS5.p2.5.m3.1a">
       <mover accent="true" id="S4.SS5.p2.5.m3.1.1" xref="S4.SS5.p2.5.m3.1.1.cmml">
        <msub id="S4.SS5.p2.5.m3.1.1.2" xref="S4.SS5.p2.5.m3.1.1.2.cmml">
         <mi id="S4.SS5.p2.5.m3.1.1.2.2" xref="S4.SS5.p2.5.m3.1.1.2.2.cmml">
          y
         </mi>
         <mi id="S4.SS5.p2.5.m3.1.1.2.3" xref="S4.SS5.p2.5.m3.1.1.2.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S4.SS5.p2.5.m3.1.1.1" xref="S4.SS5.p2.5.m3.1.1.1.cmml">
         ^
        </mo>
       </mover>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.5.m3.1b">
        <apply id="S4.SS5.p2.5.m3.1.1.cmml" xref="S4.SS5.p2.5.m3.1.1">
         <ci id="S4.SS5.p2.5.m3.1.1.1.cmml" xref="S4.SS5.p2.5.m3.1.1.1">
          ^
         </ci>
         <apply id="S4.SS5.p2.5.m3.1.1.2.cmml" xref="S4.SS5.p2.5.m3.1.1.2">
          <csymbol cd="ambiguous" id="S4.SS5.p2.5.m3.1.1.2.1.cmml" xref="S4.SS5.p2.5.m3.1.1.2">
           subscript
          </csymbol>
          <ci id="S4.SS5.p2.5.m3.1.1.2.2.cmml" xref="S4.SS5.p2.5.m3.1.1.2.2">
           𝑦
          </ci>
          <ci id="S4.SS5.p2.5.m3.1.1.2.3.cmml" xref="S4.SS5.p2.5.m3.1.1.2.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.5.m3.1c">
        \hat{y_{i}}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="y_{i}" class="ltx_Math" display="inline" id="S4.SS5.p2.6.m4.1">
      <semantics id="S4.SS5.p2.6.m4.1a">
       <msub id="S4.SS5.p2.6.m4.1.1" xref="S4.SS5.p2.6.m4.1.1.cmml">
        <mi id="S4.SS5.p2.6.m4.1.1.2" xref="S4.SS5.p2.6.m4.1.1.2.cmml">
         y
        </mi>
        <mi id="S4.SS5.p2.6.m4.1.1.3" xref="S4.SS5.p2.6.m4.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.6.m4.1b">
        <apply id="S4.SS5.p2.6.m4.1.1.cmml" xref="S4.SS5.p2.6.m4.1.1">
         <csymbol cd="ambiguous" id="S4.SS5.p2.6.m4.1.1.1.cmml" xref="S4.SS5.p2.6.m4.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS5.p2.6.m4.1.1.2.cmml" xref="S4.SS5.p2.6.m4.1.1.2">
          𝑦
         </ci>
         <ci id="S4.SS5.p2.6.m4.1.1.3.cmml" xref="S4.SS5.p2.6.m4.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.6.m4.1c">
        y_{i}
       </annotation>
      </semantics>
     </math>
     represent the probability of the predicted token and ground-truth token for each
     <math alttext="i\in C" class="ltx_Math" display="inline" id="S4.SS5.p2.7.m5.1">
      <semantics id="S4.SS5.p2.7.m5.1a">
       <mrow id="S4.SS5.p2.7.m5.1.1" xref="S4.SS5.p2.7.m5.1.1.cmml">
        <mi id="S4.SS5.p2.7.m5.1.1.2" xref="S4.SS5.p2.7.m5.1.1.2.cmml">
         i
        </mi>
        <mo id="S4.SS5.p2.7.m5.1.1.1" xref="S4.SS5.p2.7.m5.1.1.1.cmml">
         ∈
        </mo>
        <mi id="S4.SS5.p2.7.m5.1.1.3" xref="S4.SS5.p2.7.m5.1.1.3.cmml">
         C
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS5.p2.7.m5.1b">
        <apply id="S4.SS5.p2.7.m5.1.1.cmml" xref="S4.SS5.p2.7.m5.1.1">
         <in id="S4.SS5.p2.7.m5.1.1.1.cmml" xref="S4.SS5.p2.7.m5.1.1.1">
         </in>
         <ci id="S4.SS5.p2.7.m5.1.1.2.cmml" xref="S4.SS5.p2.7.m5.1.1.2">
          𝑖
         </ci>
         <ci id="S4.SS5.p2.7.m5.1.1.3.cmml" xref="S4.SS5.p2.7.m5.1.1.3">
          𝐶
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS5.p2.7.m5.1c">
        i\in C
       </annotation>
      </semantics>
     </math>
     , respectively.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5.
   </span>
   Evaluation and Analysis
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    We conduct a series of experiments to answer the following research questions (
    <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">
     RQs
    </span>
    ):
   </p>
   <ul class="ltx_itemize" id="S5.I1">
    <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S5.I1.i1.p1">
      <p class="ltx_p" id="S5.I1.i1.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">
        RQ1.
       </span>
       How effective is PromptCS in adapting LLMs to code summarization?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S5.I1.i2.p1">
      <p class="ltx_p" id="S5.I1.i2.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">
        RQ2.
       </span>
       How do the key configurations, i.e., the prompt length and the concatenation mode of code and prompt embeddings, affect PromptCS?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S5.I1.i3.p1">
      <p class="ltx_p" id="S5.I1.i3.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">
        RQ3.
       </span>
       How does the choice of the network architecture in the prompt encoder affect PromptCS?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S5.I1.i4.p1">
      <p class="ltx_p" id="S5.I1.i4.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i4.p1.1.1">
        RQ4.
       </span>
       How does training data size affect PromptCS?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i5" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S5.I1.i5.p1">
      <p class="ltx_p" id="S5.I1.i5.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i5.p1.1.1">
        RQ5.
       </span>
       How does PromptCS perform on code summarization tasks in other programming languages?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i6" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S5.I1.i6.p1">
      <p class="ltx_p" id="S5.I1.i6.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i6.p1.1.1">
        RQ6:
       </span>
       How does PromptCS perform in human evaluation?
      </p>
     </div>
    </li>
   </ul>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1.
    </span>
    Experimental Setup
   </h3>
   <section class="ltx_subsubsection" id="S5.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.1.
     </span>
     Dataset
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS1.p1">
     <p class="ltx_p" id="S5.SS1.SSS1.p1.1">
      We evaluate PromptCS on the CodeSearchNet (CSN) corpus
      <cite class="ltx_cite ltx_citemacro_citep">
       (Husain et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib33" title="">
        2019
       </a>
       )
      </cite>
      , which is an extensive collection of code snippets accompanied by their comments written in six programming languages (including Go, Java, JavaScript, PHP, Python, and Ruby). This corpus is most commonly used in studying code summarization
      <cite class="ltx_cite ltx_citemacro_citep">
       (Guo et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib22" title="">
        2022
       </a>
       ; Zhou et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib78" title="">
        2022
       </a>
       ; Ahmed and Devanbu,
       <a class="ltx_ref" href="#bib.bib5" title="">
        2022b
       </a>
       ; Sun et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib58" title="">
        2023a
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib60" title="">
        c
       </a>
       )
      </cite>
      . Considering that the original CSN corpus contains some low-quality data
      <cite class="ltx_cite ltx_citemacro_citep">
       (Lu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib41" title="">
        2021
       </a>
       )
      </cite>
      , we use the dataset from the CodeXGLUE
      <cite class="ltx_cite ltx_citemacro_citep">
       (Lu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib41" title="">
        2021
       </a>
       )
      </cite>
      code-to-text docstring generation task, which is built upon the CSN corpus and excludes defective data samples.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.2.
     </span>
     Evaluation Metrics
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS2.p1">
     <p class="ltx_p" id="S5.SS1.SSS2.p1.1">
      We leverage four metrics in the evaluation, including BLEU
      <cite class="ltx_cite ltx_citemacro_citep">
       (Papineni et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib49" title="">
        2002
       </a>
       )
      </cite>
      , METEOR
      <cite class="ltx_cite ltx_citemacro_citep">
       (Banerjee and Lavie,
       <a class="ltx_ref" href="#bib.bib7" title="">
        2005
       </a>
       )
      </cite>
      , ROUGE
      <cite class="ltx_cite ltx_citemacro_citep">
       (Lin,
       <a class="ltx_ref" href="#bib.bib39" title="">
        2004
       </a>
       )
      </cite>
      , and SentenceBERT
      <cite class="ltx_cite ltx_citemacro_citep">
       (Reimers and Gurevych,
       <a class="ltx_ref" href="#bib.bib53" title="">
        2019
       </a>
       )
      </cite>
      . These metrics are widely used in code summarization
      <cite class="ltx_cite ltx_citemacro_citep">
       (Iyer et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib34" title="">
        2016
       </a>
       ; Wan et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib65" title="">
        2018
       </a>
       ; Hu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib31" title="">
        2018b
       </a>
       ; Zhang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib77" title="">
        2020
       </a>
       ; Wang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib67" title="">
        2022
       </a>
       ; Wu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib74" title="">
        2021
       </a>
       ; Sun et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib58" title="">
        2023a
       </a>
       )
      </cite>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p2">
     <p class="ltx_p" id="S5.SS1.SSS2.p2.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p2.1.1">
       BLEU
      </span>
      , the abbreviation for BiLingual Evaluation Understudy
      <cite class="ltx_cite ltx_citemacro_citep">
       (Papineni et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib49" title="">
        2002
       </a>
       )
      </cite>
      , is a variant of precision metric, which calculates the similarity by computing the n-gram precision of a generated summary to the ground-truth summary, with a penalty for the overly short length. In this paper, we follow
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib74" title="">
        2021
       </a>
       ; Sun et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib58" title="">
        2023a
       </a>
       )
      </cite>
      and show the standard BLEU score which provides a cumulative score of 1-, 2-, 3-, and 4-grams.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p3">
     <p class="ltx_p" id="S5.SS1.SSS2.p3.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p3.1.1">
       METEOR
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Banerjee and Lavie,
       <a class="ltx_ref" href="#bib.bib7" title="">
        2005
       </a>
       )
      </cite>
      is introduced to address the concerns of using BLEU. METEOR combines n-gram precision and n-gram recall by taking their harmonic mean to compute a measure of similarity.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p4">
     <p class="ltx_p" id="S5.SS1.SSS2.p4.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p4.1.1">
       ROUGE-L
      </span>
      , is a variant of ROUGE (Recall-oriented Understudy for Gisting Evaluation)
      <cite class="ltx_cite ltx_citemacro_citep">
       (Lin,
       <a class="ltx_ref" href="#bib.bib39" title="">
        2004
       </a>
       )
      </cite>
      . ROUGE-L is computed based on the longest common subsequence (LCS).
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p5">
     <p class="ltx_p" id="S5.SS1.SSS2.p5.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p5.1.1">
       SentenceBERT
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Haque et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib26" title="">
        2022
       </a>
       )
      </cite>
      . Unlike the above three metrics that mainly calculate the textual similarity between the ground truth summaries and the generated summaries, SentenceBERT measures the semantic similarity. SentenceBERT first converts the two compared summaries into embeddings in a unified vector space, and then uses cosine similarity to represent the semantic similarity between them.
     </p>
    </div>
    <div class="ltx_para" id="S5.SS1.SSS2.p6">
     <p class="ltx_p" id="S5.SS1.SSS2.p6.1">
      The scores of BLEU, ROUGE-L, METEOR, and SentenceBERT are in the range of [0, 1] and are reported in percentages. The higher the scores, the closer the generated summary is to the ground-truth summary, and the better the code summarization performance.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.3.
     </span>
     Base LLMs
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS3.p1">
     <p class="ltx_p" id="S5.SS1.SSS3.p1.1">
      We conduct experiments on four popular autoregressive LLMs, including three open-source LLMs: PolyCoder
      <cite class="ltx_cite ltx_citemacro_citep">
       (Xu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib75" title="">
        2022
       </a>
       )
      </cite>
      , CodeGen-Multi
      <cite class="ltx_cite ltx_citemacro_citep">
       (Nijkamp et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib45" title="">
        2023
       </a>
       )
      </cite>
      , StarCoderBase
      <cite class="ltx_cite ltx_citemacro_citep">
       (Li et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib38" title="">
        2023
       </a>
       )
      </cite>
      , and a commercial LLM: ChatGPT
      <cite class="ltx_cite ltx_citemacro_citep">
       (OpenAI,
       <a class="ltx_ref" href="#bib.bib46" title="">
        2022
       </a>
       )
      </cite>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p2">
     <p class="ltx_p" id="S5.SS1.SSS3.p2.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p2.1.1">
       PolyCoder
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Xu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib75" title="">
        2022
       </a>
       )
      </cite>
      is released by researchers from Carnegie Mellon University. It is trained using the GPT NeoX toolkit on 249GB of code from 12 programming languages, and is available in three sizes: 160M, 0.4B, and 2.7B.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p3">
     <p class="ltx_p" id="S5.SS1.SSS3.p3.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p3.1.1">
       CodeGen-Multi
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Nijkamp et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib45" title="">
        2023
       </a>
       )
      </cite>
      is released by Salesforce, which is a member of an autoregressive language models family for program synthesis.
In our experiments, we use three sizes of CodeGen-Multi: 350M, 2B, and 6B.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p4">
     <p class="ltx_p" id="S5.SS1.SSS3.p4.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p4.1.1">
       StarCoderBase
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Li et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib38" title="">
        2023
       </a>
       )
      </cite>
      is jointly released by Hugging Face and ServiceNow in 2023. It is trained on 80+ programming languages from The Stack
      <cite class="ltx_cite ltx_citemacro_citep">
       (Kocetkov et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib37" title="">
        2022
       </a>
       )
      </cite>
      .
And the renowned StarCoder is a fine-tuned version of StarCoderBase, trained on an additional 35 billion Python tokens. Considering that StarCoder is only available in a 16B version, which may not be suitable for conducting comprehensive comparison experiments. In our experiments, we use three sizes of StarCoderBase: 1B, 3B, and 7B.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p5">
     <p class="ltx_p" id="S5.SS1.SSS3.p5.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p5.1.1">
       ChatGPT
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (OpenAI,
       <a class="ltx_ref" href="#bib.bib46" title="">
        2022
       </a>
       )
      </cite>
      is possibly the most powerful LLM. To conduct experiments with its assistance, we utilize the OpenAI API, which is powered by a diverse set of models with different capabilities, such as GPT-3.5, DALL·E and Whisper. In our experiments, we use the gpt-3.5-turbo model, which distinguishes itself as the most capable and cost-effective option within the GPT-3.5 family.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.4.
     </span>
     Experimental Settings
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS4.p1">
     <p class="ltx_p" id="S5.SS1.SSS4.p1.1">
      At the training stage, we set the mini-batch size to 16, and the learning rate to 5e-5. We employ the AdamW optimizer
      <cite class="ltx_cite ltx_citemacro_citep">
       (Loshchilov and Hutter,
       <a class="ltx_ref" href="#bib.bib40" title="">
        2019
       </a>
       )
      </cite>
      along with a linear learning rate scheduler, following the default setup recommended by Hugging Face. To ensure comprehensive training, we employ an early stopping strategy based on the best validation BLEU to control the number of training epochs for the model. The early stopping patience is set to 4. The input sequences are padded to the maximum length with special tokens, which are selected based on the vocabulary of the LLM.
To fine-tune StarCoderBase-7B and CodeGen-Multi-6B on a single A800, we utilize DeepSpeed 0.12.2. We set the Zero Redundancy Optimizer (ZeRO) to ZeRO-3 and enable the offloading of optimizer computation to CPU.
All models are implemented using the PyTorch 2.1.0 framework with Python 3.8.
All experiments are conducted on a server equipped with one Nvidia A800 GPU with 80 GB memory, running on Ubuntu 20.04.4.
     </p>
    </div>
    <figure class="ltx_table" id="S5.T2">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 2.
      </span>
      Effectiveness of PromptCS on the CSN-Java dataset. Zero-shot: Instruction Prompting with zero-shot learning; Few-shot: Instruction Prompting with few-shot learning;
      <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T2.5.m1.1">
       <semantics id="S5.T2.5.m1.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T2.5.m1.1.1" xref="S5.T2.5.m1.1.1.cmml">
         ℬ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T2.5.m1.1c">
         <ci id="S5.T2.5.m1.1.1.cmml" xref="S5.T2.5.m1.1.1">
          ℬ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T2.5.m1.1d">
         \mathcal{B}
        </annotation>
       </semantics>
      </math>
      : BLEU;
      <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T2.6.m2.1">
       <semantics id="S5.T2.6.m2.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T2.6.m2.1.1" xref="S5.T2.6.m2.1.1.cmml">
         ℳ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T2.6.m2.1c">
         <ci id="S5.T2.6.m2.1.1.cmml" xref="S5.T2.6.m2.1.1">
          ℳ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T2.6.m2.1d">
         \mathcal{M}
        </annotation>
       </semantics>
      </math>
      : METEOR;
      <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T2.7.m3.1">
       <semantics id="S5.T2.7.m3.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T2.7.m3.1.1" xref="S5.T2.7.m3.1.1.cmml">
         ℛ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T2.7.m3.1c">
         <ci id="S5.T2.7.m3.1.1.cmml" xref="S5.T2.7.m3.1.1">
          ℛ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T2.7.m3.1d">
         \mathcal{R}
        </annotation>
       </semantics>
      </math>
      : ROUGE-L;
      <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T2.8.m4.1">
       <semantics id="S5.T2.8.m4.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T2.8.m4.1.1" xref="S5.T2.8.m4.1.1.cmml">
         𝒮
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T2.8.m4.1c">
         <ci id="S5.T2.8.m4.1.1.cmml" xref="S5.T2.8.m4.1.1">
          𝒮
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T2.8.m4.1d">
         \mathcal{S}
        </annotation>
       </semantics>
      </math>
      : SentenceBERT.
     </figcaption>
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_1">
       <table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S5.T2.40">
        <tr class="ltx_tr" id="S5.T2.40.33">
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.40.33.1" rowspan="2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.33.1.1" style="font-size:70%;">
           LLM
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.40.33.2" rowspan="2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.33.2.1" style="font-size:70%;">
           <span class="ltx_text" id="S5.T2.40.33.2.1.1">
           </span>
           <span class="ltx_text" id="S5.T2.40.33.2.1.2">
            <span class="ltx_tabular ltx_align_middle" id="S5.T2.40.33.2.1.2.1">
             <span class="ltx_tr" id="S5.T2.40.33.2.1.2.1.1">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T2.40.33.2.1.2.1.1.1" style="padding-left:2.5pt;padding-right:2.5pt;">
               Model
              </span>
             </span>
             <span class="ltx_tr" id="S5.T2.40.33.2.1.2.1.2">
              <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T2.40.33.2.1.2.1.2.1" style="padding-left:2.5pt;padding-right:2.5pt;">
               Size
              </span>
             </span>
            </span>
           </span>
           <span class="ltx_text" id="S5.T2.40.33.2.1.3">
           </span>
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T2.40.33.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.33.3.1" style="font-size:70%;">
           Zero-shot
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T2.40.33.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.33.4.1" style="font-size:70%;">
           Few-shot
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T2.40.33.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.33.5.1" style="font-size:70%;">
           Task-oriented Fine-tuning
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T2.40.33.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.33.6.1" style="font-size:70%;">
           PromptCS
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.24.16">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.9.1.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T2.9.1.1.m1.1">
           <semantics id="S5.T2.9.1.1.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.9.1.1.m1.1.1" mathsize="70%" xref="S5.T2.9.1.1.m1.1.1.cmml">
             ℬ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.9.1.1.m1.1b">
             <ci id="S5.T2.9.1.1.m1.1.1.cmml" xref="S5.T2.9.1.1.m1.1.1">
              ℬ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.9.1.1.m1.1c">
             \mathcal{B}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.2.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T2.10.2.2.m1.1">
           <semantics id="S5.T2.10.2.2.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.10.2.2.m1.1.1" mathsize="70%" xref="S5.T2.10.2.2.m1.1.1.cmml">
             ℳ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.10.2.2.m1.1b">
             <ci id="S5.T2.10.2.2.m1.1.1.cmml" xref="S5.T2.10.2.2.m1.1.1">
              ℳ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.10.2.2.m1.1c">
             \mathcal{M}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.3.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T2.11.3.3.m1.1">
           <semantics id="S5.T2.11.3.3.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.11.3.3.m1.1.1" mathsize="70%" xref="S5.T2.11.3.3.m1.1.1.cmml">
             ℛ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.11.3.3.m1.1b">
             <ci id="S5.T2.11.3.3.m1.1.1.cmml" xref="S5.T2.11.3.3.m1.1.1">
              ℛ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.11.3.3.m1.1c">
             \mathcal{R}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.12.4.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T2.12.4.4.m1.1">
           <semantics id="S5.T2.12.4.4.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.12.4.4.m1.1.1" mathsize="70%" xref="S5.T2.12.4.4.m1.1.1.cmml">
             𝒮
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.12.4.4.m1.1b">
             <ci id="S5.T2.12.4.4.m1.1.1.cmml" xref="S5.T2.12.4.4.m1.1.1">
              𝒮
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.12.4.4.m1.1c">
             \mathcal{S}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.13.5.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T2.13.5.5.m1.1">
           <semantics id="S5.T2.13.5.5.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.13.5.5.m1.1.1" mathsize="70%" xref="S5.T2.13.5.5.m1.1.1.cmml">
             ℬ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.13.5.5.m1.1b">
             <ci id="S5.T2.13.5.5.m1.1.1.cmml" xref="S5.T2.13.5.5.m1.1.1">
              ℬ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.13.5.5.m1.1c">
             \mathcal{B}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.14.6.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T2.14.6.6.m1.1">
           <semantics id="S5.T2.14.6.6.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.14.6.6.m1.1.1" mathsize="70%" xref="S5.T2.14.6.6.m1.1.1.cmml">
             ℳ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.14.6.6.m1.1b">
             <ci id="S5.T2.14.6.6.m1.1.1.cmml" xref="S5.T2.14.6.6.m1.1.1">
              ℳ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.14.6.6.m1.1c">
             \mathcal{M}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.15.7.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T2.15.7.7.m1.1">
           <semantics id="S5.T2.15.7.7.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.15.7.7.m1.1.1" mathsize="70%" xref="S5.T2.15.7.7.m1.1.1.cmml">
             ℛ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.15.7.7.m1.1b">
             <ci id="S5.T2.15.7.7.m1.1.1.cmml" xref="S5.T2.15.7.7.m1.1.1">
              ℛ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.15.7.7.m1.1c">
             \mathcal{R}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.16.8.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T2.16.8.8.m1.1">
           <semantics id="S5.T2.16.8.8.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.16.8.8.m1.1.1" mathsize="70%" xref="S5.T2.16.8.8.m1.1.1.cmml">
             𝒮
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.16.8.8.m1.1b">
             <ci id="S5.T2.16.8.8.m1.1.1.cmml" xref="S5.T2.16.8.8.m1.1.1">
              𝒮
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.16.8.8.m1.1c">
             \mathcal{S}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.17.9.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T2.17.9.9.m1.1">
           <semantics id="S5.T2.17.9.9.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.17.9.9.m1.1.1" mathsize="70%" xref="S5.T2.17.9.9.m1.1.1.cmml">
             ℬ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.17.9.9.m1.1b">
             <ci id="S5.T2.17.9.9.m1.1.1.cmml" xref="S5.T2.17.9.9.m1.1.1">
              ℬ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.17.9.9.m1.1c">
             \mathcal{B}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.18.10.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T2.18.10.10.m1.1">
           <semantics id="S5.T2.18.10.10.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.18.10.10.m1.1.1" mathsize="70%" xref="S5.T2.18.10.10.m1.1.1.cmml">
             ℳ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.18.10.10.m1.1b">
             <ci id="S5.T2.18.10.10.m1.1.1.cmml" xref="S5.T2.18.10.10.m1.1.1">
              ℳ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.18.10.10.m1.1c">
             \mathcal{M}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.19.11.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T2.19.11.11.m1.1">
           <semantics id="S5.T2.19.11.11.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.19.11.11.m1.1.1" mathsize="70%" xref="S5.T2.19.11.11.m1.1.1.cmml">
             ℛ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.19.11.11.m1.1b">
             <ci id="S5.T2.19.11.11.m1.1.1.cmml" xref="S5.T2.19.11.11.m1.1.1">
              ℛ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.19.11.11.m1.1c">
             \mathcal{R}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.12.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T2.20.12.12.m1.1">
           <semantics id="S5.T2.20.12.12.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.20.12.12.m1.1.1" mathsize="70%" xref="S5.T2.20.12.12.m1.1.1.cmml">
             𝒮
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.20.12.12.m1.1b">
             <ci id="S5.T2.20.12.12.m1.1.1.cmml" xref="S5.T2.20.12.12.m1.1.1">
              𝒮
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.20.12.12.m1.1c">
             \mathcal{S}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.21.13.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T2.21.13.13.m1.1">
           <semantics id="S5.T2.21.13.13.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.21.13.13.m1.1.1" mathsize="70%" xref="S5.T2.21.13.13.m1.1.1.cmml">
             ℬ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.21.13.13.m1.1b">
             <ci id="S5.T2.21.13.13.m1.1.1.cmml" xref="S5.T2.21.13.13.m1.1.1">
              ℬ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.21.13.13.m1.1c">
             \mathcal{B}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.22.14.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T2.22.14.14.m1.1">
           <semantics id="S5.T2.22.14.14.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.22.14.14.m1.1.1" mathsize="70%" xref="S5.T2.22.14.14.m1.1.1.cmml">
             ℳ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.22.14.14.m1.1b">
             <ci id="S5.T2.22.14.14.m1.1.1.cmml" xref="S5.T2.22.14.14.m1.1.1">
              ℳ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.22.14.14.m1.1c">
             \mathcal{M}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.23.15.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T2.23.15.15.m1.1">
           <semantics id="S5.T2.23.15.15.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.23.15.15.m1.1.1" mathsize="70%" xref="S5.T2.23.15.15.m1.1.1.cmml">
             ℛ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.23.15.15.m1.1b">
             <ci id="S5.T2.23.15.15.m1.1.1.cmml" xref="S5.T2.23.15.15.m1.1.1">
              ℛ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.23.15.15.m1.1c">
             \mathcal{R}
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.24.16.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T2.24.16.16.m1.1">
           <semantics id="S5.T2.24.16.16.m1.1a">
            <mi class="ltx_font_mathcaligraphic" id="S5.T2.24.16.16.m1.1.1" mathsize="70%" xref="S5.T2.24.16.16.m1.1.1.cmml">
             𝒮
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T2.24.16.16.m1.1b">
             <ci id="S5.T2.24.16.16.m1.1.1.cmml" xref="S5.T2.24.16.16.m1.1.1">
              𝒮
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T2.24.16.16.m1.1c">
             \mathcal{S}
            </annotation>
           </semantics>
          </math>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.34">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.1" rowspan="3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.1.1" style="font-size:70%;">
           PolyCoder
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.2.1" style="font-size:70%;">
           160M
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.3.1" style="font-size:70%;">
           7.98
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.4.1" style="font-size:70%;">
           3.40
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.5.1" style="font-size:70%;">
           13.82
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.6.1" style="font-size:70%;">
           16.12
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.7.1" style="font-size:70%;">
           13.76
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.8.1" style="font-size:70%;">
           8.85
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.9.1" style="font-size:70%;">
           27.58
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.10.1" style="font-size:70%;">
           49.11
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.34.11.1" style="font-size:70%;">
           17.79
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.34.12.1" style="font-size:70%;">
           12.92
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.34.13.1" style="font-size:70%;">
           36.24
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.34.14.1" style="font-size:70%;">
           59.21
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.15.1" style="font-size:70%;">
           16.01
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.16.1" style="font-size:70%;">
           11.68
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.17.1" style="font-size:70%;">
           34.04
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.34.18" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.34.18.1" style="font-size:70%;">
           56.44
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.35">
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.1.1" style="font-size:70%;">
           0.4B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.2.1" style="font-size:70%;">
           7.18
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.3.1" style="font-size:70%;">
           2.67
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.4.1" style="font-size:70%;">
           11.55
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.5.1" style="font-size:70%;">
           16.89
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.6.1" style="font-size:70%;">
           14.71
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.7.1" style="font-size:70%;">
           10.16
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.8.1" style="font-size:70%;">
           29.89
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.9.1" style="font-size:70%;">
           5.21
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.35.10.1" style="font-size:70%;">
           18.80
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.35.11.1" style="font-size:70%;">
           13.29
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.35.12.1" style="font-size:70%;">
           37.14
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.35.13.1" style="font-size:70%;">
           59.88
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.14.1" style="font-size:70%;">
           16.62
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.15.1" style="font-size:70%;">
           12.18
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.16.1" style="font-size:70%;">
           34.84
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.35.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.35.17.1" style="font-size:70%;">
           57.61
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.36">
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.1.1" style="font-size:70%;">
           2.7B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.2.1" style="font-size:70%;">
           7.68
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.3.1" style="font-size:70%;">
           2.28
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.4.1" style="font-size:70%;">
           12.23
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.5.1" style="font-size:70%;">
           12.92
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.6.1" style="font-size:70%;">
           13.80
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.7.1" style="font-size:70%;">
           8.82
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.8.1" style="font-size:70%;">
           27.48
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.9.1" style="font-size:70%;">
           49.26
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.36.10.1" style="font-size:70%;">
           19.33
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.36.11.1" style="font-size:70%;">
           13.66
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.36.12.1" style="font-size:70%;">
           37.97
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.36.13.1" style="font-size:70%;">
           60.70
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.14.1" style="font-size:70%;">
           18.73
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.15.1" style="font-size:70%;">
           13.00
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.16.1" style="font-size:70%;">
           37.24
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.36.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.36.17.1" style="font-size:70%;">
           59.87
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.37">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.1" rowspan="3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.1.1" style="font-size:70%;">
           CodeGen-Multi
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.2.1" style="font-size:70%;">
           350M
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.3.1" style="font-size:70%;">
           6.13
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.4.1" style="font-size:70%;">
           7.46
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.5.1" style="font-size:70%;">
           13.76
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.6.1" style="font-size:70%;">
           40.26
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.7.1" style="font-size:70%;">
           14.44
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.8.1" style="font-size:70%;">
           10.50
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.9.1" style="font-size:70%;">
           30.04
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.10.1" style="font-size:70%;">
           52.98
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.37.11.1" style="font-size:70%;">
           19.12
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.37.12.1" style="font-size:70%;">
           13.69
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.37.13.1" style="font-size:70%;">
           37.95
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.37.14.1" style="font-size:70%;">
           59.85
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.15.1" style="font-size:70%;">
           17.38
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.16.1" style="font-size:70%;">
           12.97
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.17.1" style="font-size:70%;">
           36.37
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.37.18" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.37.18.1" style="font-size:70%;">
           58.84
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.38">
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.1.1" style="font-size:70%;">
           2B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.2.1" style="font-size:70%;">
           7.96
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.3.1" style="font-size:70%;">
           3.08
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.4.1" style="font-size:70%;">
           13.42
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.5.1" style="font-size:70%;">
           15.26
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.6.1" style="font-size:70%;">
           14.96
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.7.1" style="font-size:70%;">
           11.88
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.8.1" style="font-size:70%;">
           31.09
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.9.1" style="font-size:70%;">
           55.30
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.10.1" style="font-size:70%;">
           19.42
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.11.1" style="font-size:70%;">
           14.16
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.12.1" style="font-size:70%;">
           38.54
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.38.13.1" style="font-size:70%;">
           60.64
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.38.14.1" style="font-size:70%;">
           20.04
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.38.15.1" style="font-size:70%;">
           14.39
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.38.16.1" style="font-size:70%;">
           39.36
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.38.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.38.17.1" style="font-size:70%;">
           61.51
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.28.20">
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.5.1" style="font-size:70%;">
           6B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.6.1" style="font-size:70%;">
           8.00
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.7.1" style="font-size:70%;">
           4.19
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.8.1" style="font-size:70%;">
           14.59
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.9.1" style="font-size:70%;">
           19.63
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.10.1" style="font-size:70%;">
           15.23
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.11.1" style="font-size:70%;">
           10.97
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.12.1" style="font-size:70%;">
           31.22
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.13.1" style="font-size:70%;">
           55.15
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.25.17.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.25.17.1.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.25.17.1.2">
           <span class="ltx_text" id="S5.T2.25.17.1.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.26.18.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.26.18.2.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.26.18.2.2">
           <span class="ltx_text" id="S5.T2.26.18.2.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.27.19.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.27.19.3.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.27.19.3.2">
           <span class="ltx_text" id="S5.T2.27.19.3.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.4.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.28.20.4.2">
           <span class="ltx_text" id="S5.T2.28.20.4.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.14.1" style="font-size:70%;">
           20.65
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.15.1" style="font-size:70%;">
           14.26
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.16.1" style="font-size:70%;">
           39.79
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.28.20.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.28.20.17.1" style="font-size:70%;">
           61.74
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.39">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.1" rowspan="3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.1.1" style="font-size:70%;">
           StarCoderBase
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.2.1" style="font-size:70%;">
           1B
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.3.1" style="font-size:70%;">
           5.95
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.4.1" style="font-size:70%;">
           4.27
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.5.1" style="font-size:70%;">
           11.52
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.6.1" style="font-size:70%;">
           24.68
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.7.1" style="font-size:70%;">
           14.43
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.8.1" style="font-size:70%;">
           10.67
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.9.1" style="font-size:70%;">
           28.18
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.10.1" style="font-size:70%;">
           52.96
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.11.1" style="font-size:70%;">
           18.62
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.12.1" style="font-size:70%;">
           13.65
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.13.1" style="font-size:70%;">
           37.23
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.39.14.1" style="font-size:70%;">
           59.47
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.39.15.1" style="font-size:70%;">
           20.5
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.39.16.1" style="font-size:70%;">
           14.05
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.39.17.1" style="font-size:70%;">
           39.47
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.40.39.18" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.39.18.1" style="font-size:70%;">
           61.68
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.40">
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.1.1" style="font-size:70%;">
           3B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.2.1" style="font-size:70%;">
           9.64
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.3.1" style="font-size:70%;">
           8.64
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.4.1" style="font-size:70%;">
           20.70
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.5.1" style="font-size:70%;">
           33.93
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.6.1" style="font-size:70%;">
           15.12
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.7.1" style="font-size:70%;">
           11.64
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.8.1" style="font-size:70%;">
           29.84
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.9.1" style="font-size:70%;">
           55.90
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.10.1" style="font-size:70%;">
           20.43
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.40.11.1" style="font-size:70%;">
           14.68
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.12.1" style="font-size:70%;">
           39.51
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.13.1" style="font-size:70%;">
           61.95
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.40.14.1" style="font-size:70%;">
           20.87
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.40.15.1" style="font-size:70%;">
           14.50
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.40.16.1" style="font-size:70%;">
           40.23
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.40.40.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text ltx_font_bold" id="S5.T2.40.40.17.1" style="font-size:70%;">
           62.40
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.32.24">
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.5.1" style="font-size:70%;">
           7B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.6.1" style="font-size:70%;">
           9.47
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.7.1" style="font-size:70%;">
           8.05
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.8.1" style="font-size:70%;">
           20.10
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.9.1" style="font-size:70%;">
           30.24
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.10.1" style="font-size:70%;">
           16.65
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.11.1" style="font-size:70%;">
           12.91
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.12.1" style="font-size:70%;">
           33.67
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.13.1" style="font-size:70%;">
           58.31
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.29.21.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.29.21.1.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.29.21.1.2">
           <span class="ltx_text" id="S5.T2.29.21.1.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.30.22.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.30.22.2.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.30.22.2.2">
           <span class="ltx_text" id="S5.T2.30.22.2.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.31.23.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.31.23.3.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.31.23.3.2">
           <span class="ltx_text" id="S5.T2.31.23.3.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.4.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.32.24.4.2">
           <span class="ltx_text" id="S5.T2.32.24.4.2.1" style="font-size:70%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.14.1" style="font-size:70%;">
           21.86
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.15.1" style="font-size:70%;">
           15.08
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.16.1" style="font-size:70%;">
           41.25
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T2.32.24.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.32.24.17.1" style="font-size:70%;">
           63.21
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T2.40.32">
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.9" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.9.1" style="font-size:70%;">
           ChatGPT
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.10" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.10.1" style="font-size:70%;">
           –
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.11" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.11.1" style="font-size:70%;">
           9.57
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.12" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.12.1" style="font-size:70%;">
           14.89
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.13" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.13.1" style="font-size:70%;">
           20.75
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.14" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.14.1" style="font-size:70%;">
           54.11
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.15" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.15.1" style="font-size:70%;">
           14.68
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.16" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.16.1" style="font-size:70%;">
           15.97
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.17" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.17.1" style="font-size:70%;">
           34.61
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.18" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.18.1" style="font-size:70%;">
           59.89
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.33.25.1" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.33.25.1.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.33.25.1.2">
           <span class="ltx_text" id="S5.T2.33.25.1.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.34.26.2" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.34.26.2.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.34.26.2.2">
           <span class="ltx_text" id="S5.T2.34.26.2.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.35.27.3" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.35.27.3.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.35.27.3.2">
           <span class="ltx_text" id="S5.T2.35.27.3.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.36.28.4" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.36.28.4.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.36.28.4.2">
           <span class="ltx_text" id="S5.T2.36.28.4.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.37.29.5" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.37.29.5.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.37.29.5.2">
           <span class="ltx_text" id="S5.T2.37.29.5.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.38.30.6" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.38.30.6.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.38.30.6.2">
           <span class="ltx_text" id="S5.T2.38.30.6.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.39.31.7" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.39.31.7.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.39.31.7.2">
           <span class="ltx_text" id="S5.T2.39.31.7.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.40.32.8" style="padding-left:2.5pt;padding-right:2.5pt;">
          <span class="ltx_text" id="S5.T2.40.32.8.1" style="font-size:70%;">
           –
          </span>
          <sup class="ltx_sup" id="S5.T2.40.32.8.2">
           <span class="ltx_text" id="S5.T2.40.32.8.2.1" style="font-size:70%;">
            †
           </span>
          </sup>
         </td>
        </tr>
       </table>
      </div>
      <div class="ltx_flex_break">
      </div>
      <div class="ltx_flex_cell ltx_flex_size_1">
       <ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S5.I2">
        <li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_item">
          •
         </span>
         <div class="ltx_para" id="S5.I2.i1.p1">
          <p class="ltx_p" id="S5.I2.i1.p1.1">
           <sup class="ltx_sup" id="S5.I2.i1.p1.1.1">
            <span class="ltx_text" id="S5.I2.i1.p1.1.1.1" style="font-size:80%;">
             ∗
            </span>
           </sup>
           <span class="ltx_text" id="S5.I2.i1.p1.1.2" style="font-size:80%;">
            StarCoderBase-7B and CodeGen-Multi-6B are too large for effective fine-tuning.
           </span>
          </p>
         </div>
        </li>
        <li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_item">
          •
         </span>
         <div class="ltx_para" id="S5.I2.i2.p1">
          <p class="ltx_p" id="S5.I2.i2.p1.1">
           <sup class="ltx_sup" id="S5.I2.i2.p1.1.1">
            <span class="ltx_text" id="S5.I2.i2.p1.1.1.1" style="font-size:80%;">
             †
            </span>
           </sup>
           <span class="ltx_text" id="S5.I2.i2.p1.1.2" style="font-size:80%;">
            ChatGPT is a non-open source model and cannot be fine-tuned. We also cannot apply PromptCS to it.
           </span>
          </p>
         </div>
        </li>
       </ul>
      </div>
      <div class="ltx_flex_break">
      </div>
     </div>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2.
    </span>
    Experimental Results
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     In this section, we present and analyze the experimental results to answer the research questions.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S5.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.1.
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.3.1">
      RQ1: Effectiveness of PromptCS
     </span>
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p1">
     <br class="ltx_break"/>
     <p class="ltx_p" id="S5.SS2.SSS1.p1.1">
      1)
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p1.1.1">
       Baselines:
      </span>
      To answer this research question, we compare our PromptCS to the following three schemes of adapting LLMs to code summarization tasks.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p2">
     <p class="ltx_p" id="S5.SS2.SSS1.p2.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p2.1.1">
       Instruct Prompting (zero-shot).
      </span>
      This scheme directly uses human-written instructions to prompt LLMs to generate summaries for given code snippets. For StarCoderBase, CodeGen-Multi, and PolyCoder, we utilize the human-written prompt provided in the work
      <cite class="ltx_cite ltx_citemacro_citep">
       (Bhattacharya et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib9" title="">
        2023
       </a>
       )
      </cite>
      . For ChatGPT, we utilize the human-written prompt provided in the work
      <cite class="ltx_cite ltx_citemacro_citep">
       (Sun et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib60" title="">
        2023c
       </a>
       )
      </cite>
      . Table
      <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      presents the two human-written prompts mentioned above.
     </p>
    </div>
    <figure class="ltx_table" id="S5.T3">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 3.
      </span>
      Manual prompts used to guide LLMs for code summarization
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
      <tr class="ltx_tr" id="S5.T3.1.1">
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1">
        <span class="ltx_text" id="S5.T3.1.1.1.1" style="font-size:70%;">
         LLM
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.2">
        <span class="ltx_text" id="S5.T3.1.1.2.1" style="font-size:70%;">
         Prompt Instruction
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.2">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1">
        <span class="ltx_text" id="S5.T3.1.2.1.1" style="font-size:70%;">
         StarCoderBase
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.2" rowspan="3">
        <span class="ltx_text" id="S5.T3.1.2.2.1" style="font-size:70%;">
         <span class="ltx_text" id="S5.T3.1.2.2.1.1">
         </span>
         <span class="ltx_text" id="S5.T3.1.2.2.1.2">
          <span class="ltx_tabular ltx_align_middle" id="S5.T3.1.2.2.1.2.1">
           <span class="ltx_tr" id="S5.T3.1.2.2.1.2.1.1">
            <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.2.2.1.2.1.1.1">
             //Human: You are a helpful code summarizer. Please describe in simple english the purpose of
            </span>
           </span>
           <span class="ltx_tr" id="S5.T3.1.2.2.1.2.1.2">
            <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.2.2.1.2.1.2.1">
             the following Java code snippet: ¡code¿
            </span>
           </span>
           <span class="ltx_tr" id="S5.T3.1.2.2.1.2.1.3">
            <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.2.2.1.2.1.3.1">
             //Assistant:
            </span>
           </span>
          </span>
         </span>
         <span class="ltx_text" id="S5.T3.1.2.2.1.3">
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.3">
       <td class="ltx_td ltx_align_center" id="S5.T3.1.3.1">
        <span class="ltx_text" id="S5.T3.1.3.1.1" style="font-size:70%;">
         CodeGen-Multi
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.4">
       <td class="ltx_td ltx_align_center" id="S5.T3.1.4.1">
        <span class="ltx_text" id="S5.T3.1.4.1.1" style="font-size:70%;">
         PolyCoder
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T3.1.5">
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.5.1">
        <span class="ltx_text" id="S5.T3.1.5.1.1" style="font-size:70%;">
         ChatGPT
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S5.T3.1.5.2">
        <span class="ltx_text" id="S5.T3.1.5.2.1">
        </span>
        <span class="ltx_text" id="S5.T3.1.5.2.2" style="font-size:70%;">
        </span>
        <span class="ltx_text" id="S5.T3.1.5.2.3" style="font-size:70%;">
         <span class="ltx_tabular ltx_align_middle" id="S5.T3.1.5.2.3.1">
          <span class="ltx_tr" id="S5.T3.1.5.2.3.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.5.2.3.1.1.1">
            Please generate a short comment in one sentence for
           </span>
          </span>
          <span class="ltx_tr" id="S5.T3.1.5.2.3.1.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.5.2.3.1.2.1">
            the following function: ¡code¿
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="S5.T3.1.5.2.4">
        </span>
        <span class="ltx_text" id="S5.T3.1.5.2.5" style="font-size:70%;">
        </span>
       </td>
      </tr>
     </table>
    </figure>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p3">
     <p class="ltx_p" id="S5.SS2.SSS1.p3.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p3.1.1">
       Instruct Prompting (few-shot).
      </span>
      In this scheme, in addition to providing the hand-written prompts used in the zero-shot setting, we also provide a few examples that demonstrate the nature of the task to let LLMs perform few-shot learning.
We follow
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ahmed and Devanbu,
       <a class="ltx_ref" href="#bib.bib5" title="">
        2022b
       </a>
       ; Bhattacharya et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib9" title="">
        2023
       </a>
       )
      </cite>
      and provide 10 examples in the few-shot setting. Each example is a pair of
      <math alttext="\langle code\;snippet,summary\rangle" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p3.1.m1.2">
       <semantics id="S5.SS2.SSS1.p3.1.m1.2a">
        <mrow id="S5.SS2.SSS1.p3.1.m1.2.2.2" xref="S5.SS2.SSS1.p3.1.m1.2.2.3.cmml">
         <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.3" stretchy="false" xref="S5.SS2.SSS1.p3.1.m1.2.2.3.cmml">
          ⟨
         </mo>
         <mrow id="S5.SS2.SSS1.p3.1.m1.1.1.1.1" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.cmml">
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.2" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.2.cmml">
           c
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.3" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.3.cmml">
           o
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.4" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.4.cmml">
           d
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.5" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.5.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1c" lspace="0.280em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.6" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.6.cmml">
           s
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1d" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.7" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.7.cmml">
           n
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1e" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.8" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.8.cmml">
           i
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1f" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.9" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.9.cmml">
           p
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1g" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.10" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.10.cmml">
           p
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1h" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.11" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.11.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1i" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.12" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.12.cmml">
           t
          </mi>
         </mrow>
         <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.4" xref="S5.SS2.SSS1.p3.1.m1.2.2.3.cmml">
          ,
         </mo>
         <mrow id="S5.SS2.SSS1.p3.1.m1.2.2.2.2" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.cmml">
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.2" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.2.cmml">
           s
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.3" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.3.cmml">
           u
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.4" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.4.cmml">
           m
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1b" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.5" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.5.cmml">
           m
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1c" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.6" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.6.cmml">
           a
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1d" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.7" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.7.cmml">
           r
          </mi>
          <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1e" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.8" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.8.cmml">
           y
          </mi>
         </mrow>
         <mo id="S5.SS2.SSS1.p3.1.m1.2.2.2.5" stretchy="false" xref="S5.SS2.SSS1.p3.1.m1.2.2.3.cmml">
          ⟩
         </mo>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p3.1.m1.2b">
         <list id="S5.SS2.SSS1.p3.1.m1.2.2.3.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2">
          <apply id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1">
           <times id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.1">
           </times>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.2.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.2">
            𝑐
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.3">
            𝑜
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.4.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.4">
            𝑑
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.5.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.5">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.6.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.6">
            𝑠
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.7.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.7">
            𝑛
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.8.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.8">
            𝑖
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.9.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.9">
            𝑝
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.10.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.10">
            𝑝
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.11.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.11">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.1.1.1.1.12.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1.1.1.12">
            𝑡
           </ci>
          </apply>
          <apply id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2">
           <times id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.1">
           </times>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.2.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.2">
            𝑠
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.3.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.3">
            𝑢
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.4.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.4">
            𝑚
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.5.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.5">
            𝑚
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.6.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.6">
            𝑎
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.7.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.7">
            𝑟
           </ci>
           <ci id="S5.SS2.SSS1.p3.1.m1.2.2.2.2.8.cmml" xref="S5.SS2.SSS1.p3.1.m1.2.2.2.2.8">
            𝑦
           </ci>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS1.p3.1.m1.2c">
         \langle code\;snippet,summary\rangle
        </annotation>
       </semantics>
      </math>
      randomly selected from the training set.
In practice, we directly leverage the 10 examples provided by Ahmed et al. in their GitHub repository
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ahmed and Devanbu,
       <a class="ltx_ref" href="#bib.bib4" title="">
        2022a
       </a>
       )
      </cite>
      , since we use the same experimental dataset (i.e., the CSN corpus).
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p4">
     <p class="ltx_p" id="S5.SS2.SSS1.p4.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p4.1.1">
       Task-oriented Fine-tuning.
      </span>
      In this scheme, we perform the standard fine-tuning process and utilize all
      <math alttext="\langle code\;snippets,summaries\rangle" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p4.1.m1.2">
       <semantics id="S5.SS2.SSS1.p4.1.m1.2a">
        <mrow id="S5.SS2.SSS1.p4.1.m1.2.2.2" xref="S5.SS2.SSS1.p4.1.m1.2.2.3.cmml">
         <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.3" stretchy="false" xref="S5.SS2.SSS1.p4.1.m1.2.2.3.cmml">
          ⟨
         </mo>
         <mrow id="S5.SS2.SSS1.p4.1.m1.1.1.1.1" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.cmml">
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.2" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.2.cmml">
           c
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.3" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.3.cmml">
           o
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.4" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.4.cmml">
           d
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.5" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.5.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1c" lspace="0.280em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.6" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.6.cmml">
           s
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1d" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.7" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.7.cmml">
           n
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1e" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.8" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.8.cmml">
           i
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1f" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.9" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.9.cmml">
           p
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1g" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.10" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.10.cmml">
           p
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1h" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.11" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.11.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1i" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.12" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.12.cmml">
           t
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1j" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.13" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.13.cmml">
           s
          </mi>
         </mrow>
         <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.4" xref="S5.SS2.SSS1.p4.1.m1.2.2.3.cmml">
          ,
         </mo>
         <mrow id="S5.SS2.SSS1.p4.1.m1.2.2.2.2" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.cmml">
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.2" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.2.cmml">
           s
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.3" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.3.cmml">
           u
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.4" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.4.cmml">
           m
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1b" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.5" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.5.cmml">
           m
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1c" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.6" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.6.cmml">
           a
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1d" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.7" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.7.cmml">
           r
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1e" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.8" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.8.cmml">
           i
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1f" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.9" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.9.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1g" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.10" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.10.cmml">
           s
          </mi>
         </mrow>
         <mo id="S5.SS2.SSS1.p4.1.m1.2.2.2.5" stretchy="false" xref="S5.SS2.SSS1.p4.1.m1.2.2.3.cmml">
          ⟩
         </mo>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p4.1.m1.2b">
         <list id="S5.SS2.SSS1.p4.1.m1.2.2.3.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2">
          <apply id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1">
           <times id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.1">
           </times>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.2.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.2">
            𝑐
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.3">
            𝑜
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.4.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.4">
            𝑑
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.5.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.5">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.6.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.6">
            𝑠
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.7.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.7">
            𝑛
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.8.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.8">
            𝑖
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.9.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.9">
            𝑝
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.10.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.10">
            𝑝
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.11.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.11">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.12.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.12">
            𝑡
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.1.1.1.1.13.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1.1.1.13">
            𝑠
           </ci>
          </apply>
          <apply id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2">
           <times id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.1">
           </times>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.2.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.2">
            𝑠
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.3.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.3">
            𝑢
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.4.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.4">
            𝑚
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.5.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.5">
            𝑚
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.6.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.6">
            𝑎
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.7.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.7">
            𝑟
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.8.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.8">
            𝑖
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.9.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.9">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p4.1.m1.2.2.2.2.10.cmml" xref="S5.SS2.SSS1.p4.1.m1.2.2.2.2.10">
            𝑠
           </ci>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS1.p4.1.m1.2c">
         \langle code\;snippets,summaries\rangle
        </annotation>
       </semantics>
      </math>
      in the training set to fine-tune LLMs. During the fine-tuning process, all model parameters of LLMs may undergo changes.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p5">
     <p class="ltx_p" id="S5.SS2.SSS1.p5.1">
      <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p5.1.1">
       PromptCS.
      </span>
      This is the scheme proposed in this paper. PromptCS freezes the parameters of LLMs and only trains the prompt agent (i.e., prompt encoder). Similar to the task-oriented Fine-tuning scheme, we utilize all
      <math alttext="\langle code\;snippets,summaries\rangle" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p5.1.m1.2">
       <semantics id="S5.SS2.SSS1.p5.1.m1.2a">
        <mrow id="S5.SS2.SSS1.p5.1.m1.2.2.2" xref="S5.SS2.SSS1.p5.1.m1.2.2.3.cmml">
         <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.3" stretchy="false" xref="S5.SS2.SSS1.p5.1.m1.2.2.3.cmml">
          ⟨
         </mo>
         <mrow id="S5.SS2.SSS1.p5.1.m1.1.1.1.1" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.cmml">
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.2" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.2.cmml">
           c
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.3" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.3.cmml">
           o
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.4" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.4.cmml">
           d
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.5" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.5.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1c" lspace="0.280em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.6" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.6.cmml">
           s
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1d" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.7" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.7.cmml">
           n
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1e" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.8" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.8.cmml">
           i
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1f" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.9" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.9.cmml">
           p
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1g" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.10" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.10.cmml">
           p
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1h" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.11" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.11.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1i" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.12" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.12.cmml">
           t
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1j" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.13" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.13.cmml">
           s
          </mi>
         </mrow>
         <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.4" xref="S5.SS2.SSS1.p5.1.m1.2.2.3.cmml">
          ,
         </mo>
         <mrow id="S5.SS2.SSS1.p5.1.m1.2.2.2.2" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.cmml">
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.2" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.2.cmml">
           s
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.3" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.3.cmml">
           u
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.4" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.4.cmml">
           m
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1b" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.5" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.5.cmml">
           m
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1c" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.6" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.6.cmml">
           a
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1d" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.7" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.7.cmml">
           r
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1e" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.8" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.8.cmml">
           i
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1f" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.9" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.9.cmml">
           e
          </mi>
          <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1g" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.10" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.10.cmml">
           s
          </mi>
         </mrow>
         <mo id="S5.SS2.SSS1.p5.1.m1.2.2.2.5" stretchy="false" xref="S5.SS2.SSS1.p5.1.m1.2.2.3.cmml">
          ⟩
         </mo>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p5.1.m1.2b">
         <list id="S5.SS2.SSS1.p5.1.m1.2.2.3.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2">
          <apply id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1">
           <times id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.1">
           </times>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.2.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.2">
            𝑐
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.3">
            𝑜
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.4.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.4">
            𝑑
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.5.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.5">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.6.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.6">
            𝑠
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.7.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.7">
            𝑛
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.8.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.8">
            𝑖
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.9.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.9">
            𝑝
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.10.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.10">
            𝑝
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.11.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.11">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.12.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.12">
            𝑡
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.1.1.1.1.13.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1.1.1.13">
            𝑠
           </ci>
          </apply>
          <apply id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2">
           <times id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.1">
           </times>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.2.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.2">
            𝑠
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.3.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.3">
            𝑢
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.4.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.4">
            𝑚
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.5.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.5">
            𝑚
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.6.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.6">
            𝑎
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.7.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.7">
            𝑟
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.8.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.8">
            𝑖
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.9.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.9">
            𝑒
           </ci>
           <ci id="S5.SS2.SSS1.p5.1.m1.2.2.2.2.10.cmml" xref="S5.SS2.SSS1.p5.1.m1.2.2.2.2.10">
            𝑠
           </ci>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS1.p5.1.m1.2c">
         \langle code\;snippets,summaries\rangle
        </annotation>
       </semantics>
      </math>
      in the training set to train the prompt agent. Two key configurations of PromptCS, i.e., the prompt length and the concatenation mode of the code embedding and prompt embedding are set to 100 and back-end mode, respectively. More experiments on these two key configurations are discussed in Section
      <a class="ltx_ref" href="#S5.SS2.SSS2" title="5.2.2. RQ2. Influence of key configurations on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        5.2.2
       </span>
      </a>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p6">
     <p class="ltx_p" id="S5.SS2.SSS1.p6.1">
      2)
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p6.1.1">
       Results:
      </span>
      Table
      <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1.4. Experimental Settings ‣ 5.1. Experimental Setup ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      shows the performance of our PromptCS and baselines in terms of the four evaluation metrics, i.e., BLEU, METEOR, ROUGE-L, and SentenceBERT. Observe that task-oriented fine-tuning performs best on the LLM PolyCoder in terms of scores of the four metrics, followed by PromptCS, instruction prompting (few-short), and instruction prompting (zero-shot).
On the LLMs CodeGen-Multi and StarCoderBase, PromptCS is overall comparable to task-oriented fine-tuning, and both are significantly better than the two instruction prompting schemes. PromptCS even outperforms task-oriented fine-tuning on some LLMs, such as CodeGen-Multi-2B (row 7), StarCoderBase-1B (row 9) and -3B (row 10).
We also conduct instruction prompting schemes on a commercial LLM ChatGPT, and its performance is shown in the last row of Table
      <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1.4. Experimental Settings ‣ 5.1. Experimental Setup ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      .
Observe that the performance of both instruction prompting schemes on ChatGPT is better than that on the other three LLMs in all four metrics, but is also not satisfactory compared to task-oriented fine-tuning and PromptCS. Although this comparison is unreasonable, we have reason to believe that if ChatGPT is open source, the task-oriented fine-tuning scheme and PromptCS will significantly improve its code summarization capabilities compared to the instruction prompting schemes.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS1.1.p1">
     <svg class="ltx_picture" height="69.99" id="S5.SS2.SSS1.1.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,69.99) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 64.08 C 0 67.34 2.64 69.99 5.91 69.99 L 594.09 69.99 C 597.36 69.99 600 67.34 600 64.08 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 64.08 C 1.97 66.26 3.73 68.02 5.91 68.02 L 594.09 68.02 C 596.27 68.02 598.03 66.26 598.03 64.08 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="62.11" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS1.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           In adapting LLMs to code summarization tasks, PromptCS significantly outperforms instruction prompting with zero-shot and few-shot learning, and performs comparably to task-oriented fine-tuning. PromptCS even outperforms task-oriented fine-tuning on some LLMs, e.g., CodeGen-Multi-2B, StarCoderBase-1B and -3B.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS1.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <figure class="ltx_table" id="S5.T4">
     <figcaption class="ltx_caption" style="font-size:80%;">
      <span class="ltx_tag ltx_tag_table">
       Table 4.
      </span>
      Training time of Fine-tuning and PromptCS
     </figcaption>
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_1">
       <table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="S5.T4.2">
        <tr class="ltx_tr" id="S5.T4.2.3">
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.3.1">
          <span class="ltx_text" id="S5.T4.2.3.1.1" style="font-size:80%;">
           LLM
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.3.2">
          <span class="ltx_text" id="S5.T4.2.3.2.1" style="font-size:80%;">
           Model Size
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.3.3">
          <span class="ltx_text" id="S5.T4.2.3.3.1" style="font-size:80%;">
           Task-oriented Fine-tuning
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.3.4">
          <span class="ltx_text" id="S5.T4.2.3.4.1" style="font-size:80%;">
           PromptCS
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.4">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.4.1" rowspan="3">
          <span class="ltx_text" id="S5.T4.2.4.1.1" style="font-size:80%;">
           CodeGen-Multi
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.4.2">
          <span class="ltx_text" id="S5.T4.2.4.2.1" style="font-size:80%;">
           350M
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.4.3">
          <span class="ltx_text" id="S5.T4.2.4.3.1" style="font-size:80%;">
           20h:06m:44s
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.4.4">
          <span class="ltx_text" id="S5.T4.2.4.4.1" style="font-size:80%;">
           15h:01m:39s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.5">
         <td class="ltx_td ltx_align_center" id="S5.T4.2.5.1">
          <span class="ltx_text" id="S5.T4.2.5.1.1" style="font-size:80%;">
           2B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.5.2">
          <span class="ltx_text" id="S5.T4.2.5.2.1" style="font-size:80%;">
           81h:08m:24s
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.5.3">
          <span class="ltx_text" id="S5.T4.2.5.3.1" style="font-size:80%;">
           58h:43m:29s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.1.1">
         <td class="ltx_td ltx_align_center" id="S5.T4.1.1.2">
          <span class="ltx_text" id="S5.T4.1.1.2.1" style="font-size:80%;">
           6B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.1.1.1">
          <span class="ltx_text" id="S5.T4.1.1.1.1" style="font-size:80%;">
           151h:55m:57s
          </span>
          <sup class="ltx_sup" id="S5.T4.1.1.1.2">
           <span class="ltx_text" id="S5.T4.1.1.1.2.1" style="font-size:80%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.1.1.3">
          <span class="ltx_text" id="S5.T4.1.1.3.1" style="font-size:80%;">
           88h:03m:40s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.6">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.6.1" rowspan="3">
          <span class="ltx_text" id="S5.T4.2.6.1.1" style="font-size:80%;">
           PolyCoder
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.6.2">
          <span class="ltx_text" id="S5.T4.2.6.2.1" style="font-size:80%;">
           160M
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.6.3">
          <span class="ltx_text" id="S5.T4.2.6.3.1" style="font-size:80%;">
           12h:25m:19s
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.6.4">
          <span class="ltx_text" id="S5.T4.2.6.4.1" style="font-size:80%;">
           09h:41m:45s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.7">
         <td class="ltx_td ltx_align_center" id="S5.T4.2.7.1">
          <span class="ltx_text" id="S5.T4.2.7.1.1" style="font-size:80%;">
           0.4b
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.7.2">
          <span class="ltx_text" id="S5.T4.2.7.2.1" style="font-size:80%;">
           22h:18m:34s
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.7.3">
          <span class="ltx_text" id="S5.T4.2.7.3.1" style="font-size:80%;">
           14h:32m:49s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.8">
         <td class="ltx_td ltx_align_center" id="S5.T4.2.8.1">
          <span class="ltx_text" id="S5.T4.2.8.1.1" style="font-size:80%;">
           2.7b
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.8.2">
          <span class="ltx_text" id="S5.T4.2.8.2.1" style="font-size:80%;">
           81h:54m:24s
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.8.3">
          <span class="ltx_text" id="S5.T4.2.8.3.1" style="font-size:80%;">
           27h:41m:15s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.9">
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T4.2.9.1" rowspan="3">
          <span class="ltx_text" id="S5.T4.2.9.1.1" style="font-size:80%;">
           StarCoderBase
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.9.2">
          <span class="ltx_text" id="S5.T4.2.9.2.1" style="font-size:80%;">
           1B
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.9.3">
          <span class="ltx_text" id="S5.T4.2.9.3.1" style="font-size:80%;">
           50h:06m:52s
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.9.4">
          <span class="ltx_text" id="S5.T4.2.9.4.1" style="font-size:80%;">
           29h:17m:32s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.10">
         <td class="ltx_td ltx_align_center" id="S5.T4.2.10.1">
          <span class="ltx_text" id="S5.T4.2.10.1.1" style="font-size:80%;">
           3B
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.10.2">
          <span class="ltx_text" id="S5.T4.2.10.2.1" style="font-size:80%;">
           82h:26m:21s
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.2.10.3">
          <span class="ltx_text" id="S5.T4.2.10.3.1" style="font-size:80%;">
           43h:51m:44s
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.2.2">
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.2.2">
          <span class="ltx_text" id="S5.T4.2.2.2.1" style="font-size:80%;">
           7B
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.2.1">
          <span class="ltx_text" id="S5.T4.2.2.1.1" style="font-size:80%;">
           211h:05m:18s
          </span>
          <sup class="ltx_sup" id="S5.T4.2.2.1.2">
           <span class="ltx_text" id="S5.T4.2.2.1.2.1" style="font-size:80%;">
            ∗
           </span>
          </sup>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.2.3">
          <span class="ltx_text" id="S5.T4.2.2.3.1" style="font-size:80%;">
           67h:21m:31s
          </span>
         </td>
        </tr>
       </table>
      </div>
      <div class="ltx_flex_break">
      </div>
      <div class="ltx_flex_cell ltx_flex_size_1">
       <ul class="ltx_itemize ltx_figure_panel" id="S5.I3">
        <li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_item">
          •
         </span>
         <div class="ltx_para" id="S5.I3.i1.p1">
          <p class="ltx_p" id="S5.I3.i1.p1.1">
           <sup class="ltx_sup" id="S5.I3.i1.p1.1.1">
            <span class="ltx_text" id="S5.I3.i1.p1.1.1.1" style="font-size:80%;">
             ∗
            </span>
           </sup>
           <span class="ltx_text" id="S5.I3.i1.p1.1.2" style="font-size:80%;">
            StarCoderBase-7B and CodeGen-Multi-6B are too large for effective fine-tuning.
           </span>
           <br class="ltx_break"/>
           <span class="ltx_text" id="S5.I3.i1.p1.1.3" style="font-size:80%;">
            Here is the single-epoch training time for it.
           </span>
          </p>
         </div>
        </li>
       </ul>
      </div>
     </div>
    </figure>
    <div class="ltx_para" id="S5.SS2.SSS1.p7">
     <p class="ltx_p" id="S5.SS2.SSS1.p7.1">
      In addition, we also compare the training costs between the task-oriented scheme and PromptCS in terms of training time. Table
      <a class="ltx_ref" href="#S5.T4" title="Table 4 ‣ 5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      lists the time costs incurred during training on three LLMs. Observe that compared to the task-oriented scheme, PromptCS noticeably requires less time on all LLMs, which can be attributed to the fact that PromptCS is non-invasive to LLMs and does not update the parameters of the LLMs during training. It should be noted that when the model size of the LLM is very large (e.g., StarCoderBase-7B), the task-oriented fine-tuning will be very time-consuming and become unacceptable if the available training resources (e.g., the performance and number of GPU devices) are few.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS1.2.p1">
     <svg class="ltx_picture" height="36.78" id="S5.SS2.SSS1.2.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,36.78) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 30.87 C 0 34.13 2.64 36.78 5.91 36.78 L 594.09 36.78 C 597.36 36.78 600 34.13 600 30.87 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 30.87 C 1.97 33.05 3.73 34.81 5.91 34.81 L 594.09 34.81 C 596.27 34.81 598.03 33.05 598.03 30.87 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS1.2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           In terms of the training cost, PromptCS is notably lower than task-oriented fine-tuning, especially when the LLM has a larger model size.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS1.2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <figure class="ltx_table" id="S5.T5">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 5.
      </span>
      Effects of prompt length and concatenation mode on PromptCS.
      <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T5.5.m1.1">
       <semantics id="S5.T5.5.m1.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T5.5.m1.1.1" xref="S5.T5.5.m1.1.1.cmml">
         ℬ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T5.5.m1.1c">
         <ci id="S5.T5.5.m1.1.1.cmml" xref="S5.T5.5.m1.1.1">
          ℬ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T5.5.m1.1d">
         \mathcal{B}
        </annotation>
       </semantics>
      </math>
      : BLEU;
      <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T5.6.m2.1">
       <semantics id="S5.T5.6.m2.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T5.6.m2.1.1" xref="S5.T5.6.m2.1.1.cmml">
         ℳ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T5.6.m2.1c">
         <ci id="S5.T5.6.m2.1.1.cmml" xref="S5.T5.6.m2.1.1">
          ℳ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T5.6.m2.1d">
         \mathcal{M}
        </annotation>
       </semantics>
      </math>
      : METEOR;
      <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T5.7.m3.1">
       <semantics id="S5.T5.7.m3.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T5.7.m3.1.1" xref="S5.T5.7.m3.1.1.cmml">
         ℛ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T5.7.m3.1c">
         <ci id="S5.T5.7.m3.1.1.cmml" xref="S5.T5.7.m3.1.1">
          ℛ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T5.7.m3.1d">
         \mathcal{R}
        </annotation>
       </semantics>
      </math>
      : ROUGE-L;
      <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T5.8.m4.1">
       <semantics id="S5.T5.8.m4.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T5.8.m4.1.1" xref="S5.T5.8.m4.1.1.cmml">
         𝒮
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T5.8.m4.1c">
         <ci id="S5.T5.8.m4.1.1.cmml" xref="S5.T5.8.m4.1.1">
          𝒮
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T5.8.m4.1d">
         \mathcal{S}
        </annotation>
       </semantics>
      </math>
      : SentenceBERT.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T5.20">
      <tr class="ltx_tr" id="S5.T5.20.13">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T5.20.13.1" rowspan="2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.13.1.1" style="font-size:80%;">
         LLM
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T5.20.13.2" rowspan="2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.13.2.1" style="font-size:80%;">
         Prompt Length
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="4" id="S5.T5.20.13.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.13.3.1" style="font-size:80%;">
         Front-end Mode
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="4" id="S5.T5.20.13.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.13.4.1" style="font-size:80%;">
         Back-end Mode
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="4" id="S5.T5.20.13.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.13.5.1" style="font-size:80%;">
         Two-end Mode
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.20.12">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.9.1.1" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T5.9.1.1.m1.1">
         <semantics id="S5.T5.9.1.1.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.9.1.1.m1.1.1" mathsize="80%" xref="S5.T5.9.1.1.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.9.1.1.m1.1b">
           <ci id="S5.T5.9.1.1.m1.1.1.cmml" xref="S5.T5.9.1.1.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.9.1.1.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.10.2.2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T5.10.2.2.m1.1">
         <semantics id="S5.T5.10.2.2.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.10.2.2.m1.1.1" mathsize="80%" xref="S5.T5.10.2.2.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.10.2.2.m1.1b">
           <ci id="S5.T5.10.2.2.m1.1.1.cmml" xref="S5.T5.10.2.2.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.10.2.2.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.11.3.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T5.11.3.3.m1.1">
         <semantics id="S5.T5.11.3.3.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.11.3.3.m1.1.1" mathsize="80%" xref="S5.T5.11.3.3.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.11.3.3.m1.1b">
           <ci id="S5.T5.11.3.3.m1.1.1.cmml" xref="S5.T5.11.3.3.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.11.3.3.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.12.4.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T5.12.4.4.m1.1">
         <semantics id="S5.T5.12.4.4.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.12.4.4.m1.1.1" mathsize="80%" xref="S5.T5.12.4.4.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.12.4.4.m1.1b">
           <ci id="S5.T5.12.4.4.m1.1.1.cmml" xref="S5.T5.12.4.4.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.12.4.4.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.13.5.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T5.13.5.5.m1.1">
         <semantics id="S5.T5.13.5.5.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.13.5.5.m1.1.1" mathsize="80%" xref="S5.T5.13.5.5.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.13.5.5.m1.1b">
           <ci id="S5.T5.13.5.5.m1.1.1.cmml" xref="S5.T5.13.5.5.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.13.5.5.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.14.6.6" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T5.14.6.6.m1.1">
         <semantics id="S5.T5.14.6.6.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.14.6.6.m1.1.1" mathsize="80%" xref="S5.T5.14.6.6.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.14.6.6.m1.1b">
           <ci id="S5.T5.14.6.6.m1.1.1.cmml" xref="S5.T5.14.6.6.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.14.6.6.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.15.7.7" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T5.15.7.7.m1.1">
         <semantics id="S5.T5.15.7.7.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.15.7.7.m1.1.1" mathsize="80%" xref="S5.T5.15.7.7.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.15.7.7.m1.1b">
           <ci id="S5.T5.15.7.7.m1.1.1.cmml" xref="S5.T5.15.7.7.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.15.7.7.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.16.8.8" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T5.16.8.8.m1.1">
         <semantics id="S5.T5.16.8.8.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.16.8.8.m1.1.1" mathsize="80%" xref="S5.T5.16.8.8.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.16.8.8.m1.1b">
           <ci id="S5.T5.16.8.8.m1.1.1.cmml" xref="S5.T5.16.8.8.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.16.8.8.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.17.9.9" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T5.17.9.9.m1.1">
         <semantics id="S5.T5.17.9.9.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.17.9.9.m1.1.1" mathsize="80%" xref="S5.T5.17.9.9.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.17.9.9.m1.1b">
           <ci id="S5.T5.17.9.9.m1.1.1.cmml" xref="S5.T5.17.9.9.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.17.9.9.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.18.10.10" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T5.18.10.10.m1.1">
         <semantics id="S5.T5.18.10.10.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.18.10.10.m1.1.1" mathsize="80%" xref="S5.T5.18.10.10.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.18.10.10.m1.1b">
           <ci id="S5.T5.18.10.10.m1.1.1.cmml" xref="S5.T5.18.10.10.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.18.10.10.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.19.11.11" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T5.19.11.11.m1.1">
         <semantics id="S5.T5.19.11.11.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.19.11.11.m1.1.1" mathsize="80%" xref="S5.T5.19.11.11.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.19.11.11.m1.1b">
           <ci id="S5.T5.19.11.11.m1.1.1.cmml" xref="S5.T5.19.11.11.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.19.11.11.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.12.12" style="padding-left:1.5pt;padding-right:1.5pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T5.20.12.12.m1.1">
         <semantics id="S5.T5.20.12.12.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T5.20.12.12.m1.1.1" mathsize="80%" xref="S5.T5.20.12.12.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T5.20.12.12.m1.1b">
           <ci id="S5.T5.20.12.12.m1.1.1.cmml" xref="S5.T5.20.12.12.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.20.12.12.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.20.14">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T5.20.14.1" rowspan="5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.1.1" style="font-size:80%;">
         StarCoderBase-1B
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.2.1" style="font-size:80%;">
         10
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.3.1" style="font-size:80%;">
         20.26
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.4.1" style="font-size:80%;">
         14.11
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.5.1" style="font-size:80%;">
         39.45
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.6" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.6.1" style="font-size:80%;">
         0.6169
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.7" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.7.1" style="font-size:80%;">
         20.19
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.8" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.8.1" style="font-size:80%;">
         13.99
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.9" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.9.1" style="font-size:80%;">
         39.36
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.10" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.10.1" style="font-size:80%;">
         0.6137
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.11" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.11.1" style="font-size:80%;">
         20.03
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.12" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.12.1" style="font-size:80%;">
         13.91
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.13" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.13.1" style="font-size:80%;">
         39.23
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.20.14.14" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.14.14.1" style="font-size:80%;">
         0.6163
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.20.15">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.1" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.1.1" style="font-size:80%;">
         20
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.2.1" style="font-size:80%;">
         20.40
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.3.1" style="font-size:80%;">
         14.03
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.4.1" style="font-size:80%;">
         39.47
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.5.1" style="font-size:80%;">
         0.6164
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.6" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.6.1" style="font-size:80%;">
         20.13
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.7" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.15.7.1" style="font-size:80%;">
         14.23
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.8" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.8.1" style="font-size:80%;">
         39.42
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.9" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.9.1" style="font-size:80%;">
         0.6165
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.10" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.10.1" style="font-size:80%;">
         20.29
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.11" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.11.1" style="font-size:80%;">
         14.17
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.12" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.15.12.1" style="font-size:80%;">
         39.50
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.15.13" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.15.13.1" style="font-size:80%;">
         0.6180
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.20.16">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.1" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.1.1" style="font-size:80%;">
         50
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.16.2.1" style="font-size:80%;">
         20.41
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.3.1" style="font-size:80%;">
         14.12
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.4.1" style="font-size:80%;">
         39.55
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.5.1" style="font-size:80%;">
         0.6185
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.6" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.6.1" style="font-size:80%;">
         20.36
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.7" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.7.1" style="font-size:80%;">
         14.07
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.8" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.8.1" style="font-size:80%;">
         39.48
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.9" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.9.1" style="font-size:80%;">
         0.6147
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.10" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.16.10.1" style="font-size:80%;">
         20.48
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.11" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.11.1" style="font-size:80%;">
         13.99
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.12" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.16.12.1" style="font-size:80%;">
         39.57
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.16.13" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.16.13.1" style="font-size:80%;">
         0.6153
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.20.17">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.1" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.1.1" style="font-size:80%;">
         100
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.2.1" style="font-size:80%;">
         20.30
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.3.1" style="font-size:80%;">
         14.16
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.4.1" style="font-size:80%;">
         39.53
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.5.1" style="font-size:80%;">
         0.6176
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.6" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.17.6.1" style="font-size:80%;">
         20.50
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.7" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.7.1" style="font-size:80%;">
         14.05
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.8" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.8.1" style="font-size:80%;">
         39.47
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.9" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.17.9.1" style="font-size:80%;">
         0.6168
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.10" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.10.1" style="font-size:80%;">
         20.07
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.11" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.17.11.1" style="font-size:80%;">
         14.26
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.12" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.12.1" style="font-size:80%;">
         39.37
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T5.20.17.13" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.17.13.1" style="font-size:80%;">
         0.6169
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.20.18">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.1" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.1.1" style="font-size:80%;">
         200
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.2" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.2.1" style="font-size:80%;">
         20.32
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.3" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.18.3.1" style="font-size:80%;">
         14.40
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.4" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.18.4.1" style="font-size:80%;">
         39.68
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.5" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.18.5.1" style="font-size:80%;">
         0.6206
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.6" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.6.1" style="font-size:80%;">
         20.27
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.7" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.7.1" style="font-size:80%;">
         14.16
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.8" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T5.20.18.8.1" style="font-size:80%;">
         39.56
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.9" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.9.1" style="font-size:80%;">
         0.6161
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.10" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.10.1" style="font-size:80%;">
         20.21
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.11" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.11.1" style="font-size:80%;">
         14.15
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.12" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.12.1" style="font-size:80%;">
         39.46
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.20.18.13" style="padding-left:1.5pt;padding-right:1.5pt;">
        <span class="ltx_text" id="S5.T5.20.18.13.1" style="font-size:80%;">
         0.6165
        </span>
       </td>
      </tr>
     </table>
    </figure>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.2.
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.2.1">
      RQ2. Influence of key configurations on PromptCS
     </span>
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS2.p1">
     <br class="ltx_break"/>
     <p class="ltx_p" id="S5.SS2.SSS2.p1.1">
      As shown in Figure
      <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.1. Overview ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , two key configurations in the prompt agent may affect the performance of PromptCS, i.e., the prompt length that is determined by the pseudo prompt and the concatenation mode of the code embedding and prompt embedding. To reveal their effects, we conduct comprehensive experiments involving five different prompt lengths (including 10, 20, 50, 100, and 200) and three concatenation modes (including front-end mode, back-end mode, and two-end mode, detailed in Section
      <a class="ltx_ref" href="#S4.SS4" title="4.4. Fusion Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        4.4
       </span>
      </a>
      ).
We uniformly utilize StarCoderBase-1B as the base LLM. The experimental results are present in Table
      <a class="ltx_ref" href="#S5.T5" title="Table 5 ‣ 5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      .
From Table
      <a class="ltx_ref" href="#S5.T5" title="Table 5 ‣ 5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      , it is observed that if using the front-end mode, PromptCS achieves the best BLEU score at a prompt length of 50 (i.e., 20.41), while obtaining the best METEOR, ROUGE-L, and SentenceBERT scores at a prompt length of 200 (i.e., 14.40, 39.68, and 0.6206, respectively). If using the back-end mode, PromptCS achieves the best BLEU and SentenceBERT scores at a prompt length of 100, obtaining the best METEOR and ROUGE-L scores at prompt lengths of 20 and 200, respectively. If using the two-end mode, PromptCS obtains the best BLEU and ROUGE-L scores at a prompt length of 50, getting the best METEOR and SentenceBERT scores at prompt lengths of 100 and 20, respectively. These observations indicate that different combinations of two key configurations indeed have varying effects on the effectiveness of PromptCS.
It is worth noting that although different combinations have varying effects on PromptCS, numerically, the differences in these effects are minimal. For example, in terms of BLEU, the best combination is the back-end mode and a prompt length of 100 (obtaining a score of 20.50), and the worst combination is the two-end mode and a prompt length of 10 (obtaining a score of 20.03). The difference in BLEU scores between the two combinations is less than 0.5.
     </p>
    </div>
    <div class="ltx_para" id="S5.SS2.SSS2.p2">
     <p class="ltx_p" id="S5.SS2.SSS2.p2.1">
      However, it should be noted that as the prompt length increases, the number of pseudo tokens needed to be trained also increases, which will consequently elevate the training cost of the model. Figure
      <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.2.4. RQ4. Influence of the training data size on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      shows how long it takes to train PromptCS for one epoch under different prompt length settings. From this figure, it can be intuitively observed that as the prompt length increases, the time cost required for training increases significantly.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS2.1.p1">
     <svg class="ltx_picture" height="67.78" id="S5.SS2.SSS2.1.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,67.78) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 61.88 C 0 65.14 2.64 67.78 5.91 67.78 L 594.09 67.78 C 597.36 67.78 600 65.14 600 61.88 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 61.88 C 1.97 64.05 3.73 65.81 5.91 65.81 L 594.09 65.81 C 596.27 65.81 598.03 64.05 598.03 61.88 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="59.91" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS2.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           Different combinations of the two key configurations have different effects on the effectiveness of PromptCS, yet the differences between these combinations are insignificant. However, it is important to note that increasing the prompt length will raise the training cost of the model.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS2.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <figure class="ltx_table" id="S5.T6">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 6.
      </span>
      Performance of PromptCS when building the prompt encoder on different network architectures. We bold the metric scores where the prompt encoder built on BiLSTM/Transformer performs better.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T6.1">
      <tr class="ltx_tr" id="S5.T6.1.1">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T6.1.1.1" rowspan="2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.1.1.1" style="font-size:80%;">
         LLM
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T6.1.1.2" rowspan="2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.1.2.1" style="font-size:80%;">
         Model Size
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="4" id="S5.T6.1.1.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.1.3.1" style="font-size:80%;">
         BiLSTM
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="4" id="S5.T6.1.1.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.1.4.1" style="font-size:80%;">
         Transformer
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T6.1.2">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.1.1" style="font-size:80%;">
         BLEU
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.2.1" style="font-size:80%;">
         METEOR
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.3.1" style="font-size:80%;">
         ROUGE-L
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.4.1" style="font-size:80%;">
         SentenceBERT
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.5.1" style="font-size:80%;">
         BLEU
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.6.1" style="font-size:80%;">
         METEOR
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.7.1" style="font-size:80%;">
         ROUGE-L
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.2.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.2.8.1" style="font-size:80%;">
         SentenceBERT
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T6.1.3">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.3.1.1" style="font-size:80%;">
         PolyCoder
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.3.2.1" style="font-size:80%;">
         160M
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.3.3.1" style="font-size:80%;">
         16.01
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.3.4.1" style="font-size:80%;">
         11.68
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.3.5.1" style="font-size:80%;">
         34.04
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.3.6.1" style="font-size:80%;">
         0.5644
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.3.7.1" style="font-size:80%;">
         16.39
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.3.8.1" style="font-size:80%;">
         12.03
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.3.9.1" style="font-size:80%;">
         34.64
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.1.3.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.3.10.1" style="font-size:80%;">
         0.5688
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T6.1.4">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.4.1.1" style="font-size:80%;">
         CodeGen-Multi
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.4.2.1" style="font-size:80%;">
         350M
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.4.3.1" style="font-size:80%;">
         18.28
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.4.4.1" style="font-size:80%;">
         12.96
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.4.5.1" style="font-size:80%;">
         37.18
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.4.6.1" style="font-size:80%;">
         0.5920
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.4.7.1" style="font-size:80%;">
         18.09
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.4.8.1" style="font-size:80%;">
         12.99
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.4.9.1" style="font-size:80%;">
         37.09
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T6.1.4.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.4.10.1" style="font-size:80%;">
         0.5954
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T6.1.5">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.5.1.1" style="font-size:80%;">
         StarCoderBase
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.5.2.1" style="font-size:80%;">
         1B
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.5.3.1" style="font-size:80%;">
         20.50
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.5.4.1" style="font-size:80%;">
         14.05
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.5.5.1" style="font-size:80%;">
         39.47
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T6.1.5.6.1" style="font-size:80%;">
         0.6168
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.5.7.1" style="font-size:80%;">
         19.82
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.5.8.1" style="font-size:80%;">
         13.93
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.5.9.1" style="font-size:80%;">
         39.09
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.1.5.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T6.1.5.10.1" style="font-size:80%;">
         0.6111
        </span>
       </td>
      </tr>
     </table>
    </figure>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.3.
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS3.2.1">
      RQ3. Influence of the network architecture used in the prompt encoder on PromptCS
     </span>
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS3.p1">
     <br class="ltx_break"/>
     <p class="ltx_p" id="S5.SS2.SSS3.p1.1">
      As mentioned in Section
      <a class="ltx_ref" href="#S4.SS3" title="4.3. Prompt Embedding Generation ‣ 4. Methodology ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        4.3
       </span>
      </a>
      , the prompt agent contains a DL-based prompt encoder built on BiLSTM.
In practice, we also experiment to build the prompt encoder on a more advanced network, i.e., Transformer, to verify the impact of different choices on PromptCS.
As in Section
      <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1. RQ1: Effectiveness of PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        5.2.1
       </span>
      </a>
      , in this experiment, we uniformly set the prompt length to 100, and the concatenation mode to the back-end mode. Table
      <a class="ltx_ref" href="#S5.T6" title="Table 6 ‣ 5.2.2. RQ2. Influence of key configurations on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        6
       </span>
      </a>
      presents the experimental results.
     </p>
    </div>
    <div class="ltx_para" id="S5.SS2.SSS3.p2">
     <p class="ltx_p" id="S5.SS2.SSS3.p2.1">
      Observe that compared with building the prompt encoder on BiLSTM, 1) on PolyCoder-160M, building the prompt encoder on Transformer brings performance improvements to PromptCS in all four metrics; 2) on CodeGen-Multi-350M, building the prompt encoder on Transformer enhances performance improvements to PromptCS in METEOR and SentenceBERT, but results in a decrease in BLEU and ROUGE-L; 3) on StarCoderBase-1B, building the prompt encoder on Transformer not only fails to improve PromptCS’s performance, but also causes performance degradation in all four metrics.
Overall, as the model size of the LLM increases, the performance of PromptCS tends to improve if the prompt encoder is built on BiLSTM, while PromptCS’s performance shows the opposite trend if the prompt encoder is built on Transformer.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS3.1.p1">
     <svg class="ltx_picture" height="53.38" id="S5.SS2.SSS3.1.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,53.38) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 47.48 C 0 50.74 2.64 53.38 5.91 53.38 L 594.09 53.38 C 597.36 53.38 600 50.74 600 47.48 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 47.48 C 1.97 49.65 3.73 51.41 5.91 51.41 L 594.09 51.41 C 596.27 51.41 598.03 49.65 598.03 47.48 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="45.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS3.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           Although Transformer appears to be more advanced compared to BiLSTM, experimental results in our application scenario do not show a significant advantage for Transformer. In other words, BiLSTM is sufficient to meet our needs for the prompt encoder design.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS3.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.4.
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS4.2.1">
      RQ4. Influence of the training data size on PromptCS
     </span>
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS4.p1">
     <br class="ltx_break"/>
     <p class="ltx_p" id="S5.SS2.SSS4.p1.1">
      In this paper, we also analyze the impact of training data size on the effectiveness of PromptCS. To disclose this impact, we commence with a small-scale training set and systematically augment the number of training samples. The smaller training sets are randomly sampled from the complete training data. The considered training set sizes encompass 100, 1000, 10000, and 164923 (complete training data). In this experiment, we also uniformly utilize StarCoderBase-1B as the base LLM and set the prompt length and the concatenation mode to 100 and the back-end mode, respectively.
     </p>
    </div>
    <figure class="ltx_figure" id="S5.F5">
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S5.F5.1" style="width:195.1pt;">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="386" id="S5.F5.1.g1" src="/html/2312.16066/assets/x4.png" width="461"/>
        <figcaption class="ltx_caption">
         <span class="ltx_tag ltx_tag_figure">
          Figure 4.
         </span>
         Training costs for different prompt lengths
        </figcaption>
       </figure>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S5.F5.2" style="width:216.8pt;">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="326" id="S5.F5.2.g1" src="/html/2312.16066/assets/x5.png" width="461"/>
        <figcaption class="ltx_caption ltx_centering">
         <span class="ltx_tag ltx_tag_figure">
          Figure 5.
         </span>
         Influence of training set size on PromptCS
        </figcaption>
       </figure>
      </div>
     </div>
    </figure>
    <div class="ltx_para" id="S5.SS2.SSS4.p2">
     <p class="ltx_p" id="S5.SS2.SSS4.p2.1">
      Figure
      <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.2.4. RQ4. Influence of the training data size on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      showcases the experimental results, where the x-axis denotes the training set size, and the y-axes denote BLEU, METEOR, and ROUGE-L on the left and SentenceBERT on the right. Observe that with an increase in the size of the training set, the scores of PromptCS on the four metrics will increase, but the increase is not obvious. And PromptCS trained with 100 samples performs comparably to PromptCS trained with 164,923 samples. This underscores PromptCS’s superior adaptability and generalization capabilities on a small-scale dataset. It holds profound practical significance for reducing training costs, improving training efficiency, and obtaining satisfactory performance in environments with limited data. It holds profound practical significance for reducing training costs, improving training efficiency, and obtaining satisfactory performance in environments with limited data.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS4.1.p1">
     <svg class="ltx_picture" height="36.78" id="S5.SS2.SSS4.1.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,36.78) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 30.87 C 0 34.13 2.64 36.78 5.91 36.78 L 594.09 36.78 C 597.36 36.78 600 34.13 600 30.87 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 30.87 C 1.97 33.05 3.73 34.81 5.91 34.81 L 594.09 34.81 C 596.27 34.81 598.03 33.05 598.03 30.87 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS4.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           PromptCS can achieve decent performance even with limited training data resources, e.g., only 100 available samples.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS4.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <figure class="ltx_table" id="S5.T7">
     <figcaption class="ltx_caption" style="font-size:70%;">
      <span class="ltx_tag ltx_tag_table">
       Table 7.
      </span>
      Effectiveness of PromptCS in different programming languages.
      <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T7.5.m1.1">
       <semantics id="S5.T7.5.m1.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T7.5.m1.1.1" xref="S5.T7.5.m1.1.1.cmml">
         ℬ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T7.5.m1.1c">
         <ci id="S5.T7.5.m1.1.1.cmml" xref="S5.T7.5.m1.1.1">
          ℬ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T7.5.m1.1d">
         \mathcal{B}
        </annotation>
       </semantics>
      </math>
      : BLEU;
      <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T7.6.m2.1">
       <semantics id="S5.T7.6.m2.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T7.6.m2.1.1" xref="S5.T7.6.m2.1.1.cmml">
         ℳ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T7.6.m2.1c">
         <ci id="S5.T7.6.m2.1.1.cmml" xref="S5.T7.6.m2.1.1">
          ℳ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T7.6.m2.1d">
         \mathcal{M}
        </annotation>
       </semantics>
      </math>
      : METEOR;
      <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T7.7.m3.1">
       <semantics id="S5.T7.7.m3.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T7.7.m3.1.1" xref="S5.T7.7.m3.1.1.cmml">
         ℛ
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T7.7.m3.1c">
         <ci id="S5.T7.7.m3.1.1.cmml" xref="S5.T7.7.m3.1.1">
          ℛ
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T7.7.m3.1d">
         \mathcal{R}
        </annotation>
       </semantics>
      </math>
      :ROUGE-L;
      <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T7.8.m4.1">
       <semantics id="S5.T7.8.m4.1b">
        <mi class="ltx_font_mathcaligraphic" id="S5.T7.8.m4.1.1" xref="S5.T7.8.m4.1.1.cmml">
         𝒮
        </mi>
        <annotation-xml encoding="MathML-Content" id="S5.T7.8.m4.1c">
         <ci id="S5.T7.8.m4.1.1.cmml" xref="S5.T7.8.m4.1.1">
          𝒮
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.T7.8.m4.1d">
         \mathcal{S}
        </annotation>
       </semantics>
      </math>
      : SentenceBERT.
We bold the metric scores where Task-oriented Fine-turning/PromptCS performs better.
     </figcaption>
     <table class="ltx_tabular ltx_align_middle" id="S5.T7.24">
      <tr class="ltx_tr" id="S5.T7.24.17">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T7.24.17.1" rowspan="3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.17.1.1" style="font-size:70%;">
         LLM
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T7.24.17.2" rowspan="3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.17.2.1" style="font-size:70%;">
         Model Size
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="8" id="S5.T7.24.17.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.17.3.1" style="font-size:70%;">
         CSN-JavaScript
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" colspan="8" id="S5.T7.24.17.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.17.4.1" style="font-size:70%;">
         CSN-Python
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.24.18">
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" colspan="4" id="S5.T7.24.18.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.18.1.1" style="font-size:70%;">
         Task-oriented Fine-turning
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" colspan="4" id="S5.T7.24.18.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.18.2.1" style="font-size:70%;">
         PromptCS
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" colspan="4" id="S5.T7.24.18.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.18.3.1" style="font-size:70%;">
         Task-oriented Fine-turning
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" colspan="4" id="S5.T7.24.18.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.18.4.1" style="font-size:70%;">
         PromptCS
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.24.16">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.9.1.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T7.9.1.1.m1.1">
         <semantics id="S5.T7.9.1.1.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.9.1.1.m1.1.1" mathsize="70%" xref="S5.T7.9.1.1.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.9.1.1.m1.1b">
           <ci id="S5.T7.9.1.1.m1.1.1.cmml" xref="S5.T7.9.1.1.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.9.1.1.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.10.2.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T7.10.2.2.m1.1">
         <semantics id="S5.T7.10.2.2.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.10.2.2.m1.1.1" mathsize="70%" xref="S5.T7.10.2.2.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.10.2.2.m1.1b">
           <ci id="S5.T7.10.2.2.m1.1.1.cmml" xref="S5.T7.10.2.2.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.10.2.2.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.11.3.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T7.11.3.3.m1.1">
         <semantics id="S5.T7.11.3.3.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.11.3.3.m1.1.1" mathsize="70%" xref="S5.T7.11.3.3.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.11.3.3.m1.1b">
           <ci id="S5.T7.11.3.3.m1.1.1.cmml" xref="S5.T7.11.3.3.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.11.3.3.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.12.4.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T7.12.4.4.m1.1">
         <semantics id="S5.T7.12.4.4.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.12.4.4.m1.1.1" mathsize="70%" xref="S5.T7.12.4.4.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.12.4.4.m1.1b">
           <ci id="S5.T7.12.4.4.m1.1.1.cmml" xref="S5.T7.12.4.4.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.12.4.4.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.13.5.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T7.13.5.5.m1.1">
         <semantics id="S5.T7.13.5.5.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.13.5.5.m1.1.1" mathsize="70%" xref="S5.T7.13.5.5.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.13.5.5.m1.1b">
           <ci id="S5.T7.13.5.5.m1.1.1.cmml" xref="S5.T7.13.5.5.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.13.5.5.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.14.6.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T7.14.6.6.m1.1">
         <semantics id="S5.T7.14.6.6.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.14.6.6.m1.1.1" mathsize="70%" xref="S5.T7.14.6.6.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.14.6.6.m1.1b">
           <ci id="S5.T7.14.6.6.m1.1.1.cmml" xref="S5.T7.14.6.6.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.14.6.6.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.15.7.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T7.15.7.7.m1.1">
         <semantics id="S5.T7.15.7.7.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.15.7.7.m1.1.1" mathsize="70%" xref="S5.T7.15.7.7.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.15.7.7.m1.1b">
           <ci id="S5.T7.15.7.7.m1.1.1.cmml" xref="S5.T7.15.7.7.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.15.7.7.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.16.8.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T7.16.8.8.m1.1">
         <semantics id="S5.T7.16.8.8.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.16.8.8.m1.1.1" mathsize="70%" xref="S5.T7.16.8.8.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.16.8.8.m1.1b">
           <ci id="S5.T7.16.8.8.m1.1.1.cmml" xref="S5.T7.16.8.8.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.16.8.8.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.17.9.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T7.17.9.9.m1.1">
         <semantics id="S5.T7.17.9.9.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.17.9.9.m1.1.1" mathsize="70%" xref="S5.T7.17.9.9.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.17.9.9.m1.1b">
           <ci id="S5.T7.17.9.9.m1.1.1.cmml" xref="S5.T7.17.9.9.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.17.9.9.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.18.10.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T7.18.10.10.m1.1">
         <semantics id="S5.T7.18.10.10.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.18.10.10.m1.1.1" mathsize="70%" xref="S5.T7.18.10.10.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.18.10.10.m1.1b">
           <ci id="S5.T7.18.10.10.m1.1.1.cmml" xref="S5.T7.18.10.10.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.18.10.10.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.19.11.11" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T7.19.11.11.m1.1">
         <semantics id="S5.T7.19.11.11.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.19.11.11.m1.1.1" mathsize="70%" xref="S5.T7.19.11.11.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.19.11.11.m1.1b">
           <ci id="S5.T7.19.11.11.m1.1.1.cmml" xref="S5.T7.19.11.11.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.19.11.11.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.20.12.12" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T7.20.12.12.m1.1">
         <semantics id="S5.T7.20.12.12.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.20.12.12.m1.1.1" mathsize="70%" xref="S5.T7.20.12.12.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.20.12.12.m1.1b">
           <ci id="S5.T7.20.12.12.m1.1.1.cmml" xref="S5.T7.20.12.12.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.20.12.12.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.21.13.13" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S5.T7.21.13.13.m1.1">
         <semantics id="S5.T7.21.13.13.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.21.13.13.m1.1.1" mathsize="70%" xref="S5.T7.21.13.13.m1.1.1.cmml">
           ℬ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.21.13.13.m1.1b">
           <ci id="S5.T7.21.13.13.m1.1.1.cmml" xref="S5.T7.21.13.13.m1.1.1">
            ℬ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.21.13.13.m1.1c">
           \mathcal{B}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.22.14.14" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.T7.22.14.14.m1.1">
         <semantics id="S5.T7.22.14.14.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.22.14.14.m1.1.1" mathsize="70%" xref="S5.T7.22.14.14.m1.1.1.cmml">
           ℳ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.22.14.14.m1.1b">
           <ci id="S5.T7.22.14.14.m1.1.1.cmml" xref="S5.T7.22.14.14.m1.1.1">
            ℳ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.22.14.14.m1.1c">
           \mathcal{M}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.23.15.15" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.T7.23.15.15.m1.1">
         <semantics id="S5.T7.23.15.15.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.23.15.15.m1.1.1" mathsize="70%" xref="S5.T7.23.15.15.m1.1.1.cmml">
           ℛ
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.23.15.15.m1.1b">
           <ci id="S5.T7.23.15.15.m1.1.1.cmml" xref="S5.T7.23.15.15.m1.1.1">
            ℛ
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.23.15.15.m1.1c">
           \mathcal{R}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.16.16" style="padding-left:1.4pt;padding-right:1.4pt;">
        <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.T7.24.16.16.m1.1">
         <semantics id="S5.T7.24.16.16.m1.1a">
          <mi class="ltx_font_mathcaligraphic" id="S5.T7.24.16.16.m1.1.1" mathsize="70%" xref="S5.T7.24.16.16.m1.1.1.cmml">
           𝒮
          </mi>
          <annotation-xml encoding="MathML-Content" id="S5.T7.24.16.16.m1.1b">
           <ci id="S5.T7.24.16.16.m1.1.1.cmml" xref="S5.T7.24.16.16.m1.1.1">
            𝒮
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T7.24.16.16.m1.1c">
           \mathcal{S}
          </annotation>
         </semantics>
        </math>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.24.19">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.1.1" style="font-size:70%;">
         PolyCoder
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.2.1" style="font-size:70%;">
         160M
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.3.1" style="font-size:70%;">
         14.28
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.4.1" style="font-size:70%;">
         9.03
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.5.1" style="font-size:70%;">
         25.87
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.6.1" style="font-size:70%;">
         51.33
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.7.1" style="font-size:70%;">
         13.49
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.8.1" style="font-size:70%;">
         8.26
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.9.1" style="font-size:70%;">
         25.39
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.10.1" style="font-size:70%;">
         48.67
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.11" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.11.1" style="font-size:70%;">
         11.78
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.12" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.12.1" style="font-size:70%;">
         6.36
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.13" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.13.1" style="font-size:70%;">
         22.34
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.14" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.19.14.1" style="font-size:70%;">
         28.96
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.15" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.15.1" style="font-size:70%;">
         11.85
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.16" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.16.1" style="font-size:70%;">
         7.17
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.17" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.17.1" style="font-size:70%;">
         23.38
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.24.19.18" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.19.18.1" style="font-size:70%;">
         30.81
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.24.20">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.1.1" style="font-size:70%;">
         CodeGen-Multi
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.2.1" style="font-size:70%;">
         350M
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.3.1" style="font-size:70%;">
         14.12
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.4.1" style="font-size:70%;">
         10.30
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.5.1" style="font-size:70%;">
         28.11
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.6.1" style="font-size:70%;">
         52.70
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.7.1" style="font-size:70%;">
         14.48
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.8.1" style="font-size:70%;">
         9.98
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.9.1" style="font-size:70%;">
         28.07
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.10.1" style="font-size:70%;">
         51.79
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.11" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.11.1" style="font-size:70%;">
         12.20
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.12" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.12.1" style="font-size:70%;">
         7.56
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.13" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.13.1" style="font-size:70%;">
         24.20
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.14" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.20.14.1" style="font-size:70%;">
         34.91
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.15" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.15.1" style="font-size:70%;">
         12.36
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.16" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.16.1" style="font-size:70%;">
         8.45
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.17" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.17.1" style="font-size:70%;">
         25.37
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.20.18" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.20.18.1" style="font-size:70%;">
         36.20
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.24.21">
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.1.1" style="font-size:70%;">
         StarCoderBase
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.2.1" style="font-size:70%;">
         1B
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.3.1" style="font-size:70%;">
         15.65
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.4.1" style="font-size:70%;">
         10.71
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.5.1" style="font-size:70%;">
         30.29
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.6.1" style="font-size:70%;">
         53.92
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.7.1" style="font-size:70%;">
         15.62
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.8.1" style="font-size:70%;">
         10.60
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.9.1" style="font-size:70%;">
         30.03
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.10.1" style="font-size:70%;">
         54.45
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.11" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.11.1" style="font-size:70%;">
         12.96
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.12" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.12.1" style="font-size:70%;">
         8.73
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.13" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.13.1" style="font-size:70%;">
         26.17
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.14" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.21.14.1" style="font-size:70%;">
         37.36
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.15" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.15.1" style="font-size:70%;">
         13.88
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.16" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.16.1" style="font-size:70%;">
         9.20
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.17" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.17.1" style="font-size:70%;">
         27.85
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.24.21.18" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.21.18.1" style="font-size:70%;">
         41.03
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.24.22">
       <td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" colspan="2" id="S5.T7.24.22.1" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.1.1" style="font-size:70%;">
         Average
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.2" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.2.1" style="font-size:70%;">
         14.68
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.3" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.3.1" style="font-size:70%;">
         10.01
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.4" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.4.1" style="font-size:70%;">
         28.09
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.5" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.5.1" style="font-size:70%;">
         52.56
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.6" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.6.1" style="font-size:70%;">
         14.53
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.7" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.7.1" style="font-size:70%;">
         9.61
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.8" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.8.1" style="font-size:70%;">
         27.83
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.9" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.9.1" style="font-size:70%;">
         51.64
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.10" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.10.1" style="font-size:70%;">
         12.31
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.11" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.11.1" style="font-size:70%;">
         7.55
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.12" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.12.1" style="font-size:70%;">
         24.24
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.13" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text" id="S5.T7.24.22.13.1" style="font-size:70%;">
         33.75
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.14" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.14.1" style="font-size:70%;">
         12.70
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.15" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.15.1" style="font-size:70%;">
         8.27
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.16" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.16.1" style="font-size:70%;">
         25.53
        </span>
       </td>
       <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S5.T7.24.22.17" style="padding-left:1.4pt;padding-right:1.4pt;">
        <span class="ltx_text ltx_font_bold" id="S5.T7.24.22.17.1" style="font-size:70%;">
         36.01
        </span>
       </td>
      </tr>
     </table>
    </figure>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.5.
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS5.2.1">
      RQ5. Effectiveness in other programming languages
     </span>
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS5.p1">
     <br class="ltx_break"/>
     <p class="ltx_p" id="S5.SS2.SSS5.p1.1">
      To validate PromptCS’s generalization ability, we also conduct experiments in two other programming languages, including JavaScript and Python. In these experiments, we also uniformly set the prompt length and the concatenation mode to 100 and the back-end mode, respectively. The experimental results are shown in Table
      <a class="ltx_ref" href="#S5.T7" title="Table 7 ‣ 5.2.4. RQ4. Influence of the training data size on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      .
     </p>
    </div>
    <div class="ltx_para" id="S5.SS2.SSS5.p2">
     <p class="ltx_p" id="S5.SS2.SSS5.p2.1">
      From the CSN-JavaScript column of Table
      <a class="ltx_ref" href="#S5.T7" title="Table 7 ‣ 5.2.4. RQ4. Influence of the training data size on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      , it is observed that the task-oriented fine-tuning scheme outperforms PromptCS on most metrics and LLMs. Nonetheless, it is worth noting that on three LLMs, PromptCS can achieve on average 98% of the performance of the task-oriented fine-tuning scheme, which is encouraging.
From the CSN-Python column of Table
      <a class="ltx_ref" href="#S5.T7" title="Table 7 ‣ 5.2.4. RQ4. Influence of the training data size on PromptCS ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      , it is observed that on all three LLMs, PromptCS consistently performs better than the task-oriented fine-tuning scheme in all four metrics.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS5.1.p1">
     <svg class="ltx_picture" height="36.78" id="S5.SS2.SSS5.1.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,36.78) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 30.87 C 0 34.13 2.64 36.78 5.91 36.78 L 594.09 36.78 C 597.36 36.78 600 34.13 600 30.87 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 30.87 C 1.97 33.05 3.73 34.81 5.91 34.81 L 594.09 34.81 C 596.27 34.81 598.03 33.05 598.03 30.87 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           PromptCS exhibits good generalization ability on code summarization tasks in other different programming languages, including JavaScript and Python.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS6">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.6.
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS6.2.1">
      RQ6. PromptCS’s performance in human evaluation
     </span>
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS6.p1">
     <br class="ltx_break"/>
     <p class="ltx_p" id="S5.SS2.SSS6.p1.1">
      In addition to automated evaluation, we conduct a human evaluation by following the previous works
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib74" title="">
        2021
       </a>
       ; Hu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib30" title="">
        2020
       </a>
       ; Wei et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib70" title="">
        2020
       </a>
       ; Zhang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib77" title="">
        2020
       </a>
       ; Hu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib28" title="">
        2022a
       </a>
       )
      </cite>
      to evaluate the summaries generated by three baselines and PromptCS. Specifically, we invite five volunteers with more than four years of software development experience and excellent English ability to carry out the evaluation. We randomly select 100 code snippets from the CSN-Java dataset, the corresponding ground-truth summaries, and summaries generated by baselines and PromptCS. Each volunteer is asked to assign scores from 1 to 5 to the generated summaries based on how similar they are to the corresponding ground-truth summaries, where 1 means “Not Similar At All” and 5 means “Highly Similar/Identical”. To ensure the fairness and objectivity of experimental results, each summary is evaluated by five volunteers, and the final score is the median value of their scores.
     </p>
    </div>
    <figure class="ltx_table" id="S5.T8">
     <figcaption class="ltx_caption ltx_centering" style="font-size:80%;">
      <span class="ltx_tag ltx_tag_table">
       Table 8.
      </span>
      Results of human evaluation.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T8.3">
      <tr class="ltx_tr" id="S5.T8.3.3">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T8.3.3.4">
        <span class="ltx_text" id="S5.T8.3.3.4.1" style="font-size:80%;">
         Score
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.5">
        <span class="ltx_text" id="S5.T8.3.3.5.1" style="font-size:80%;">
         1
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.6">
        <span class="ltx_text" id="S5.T8.3.3.6.1" style="font-size:80%;">
         2
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.7">
        <span class="ltx_text" id="S5.T8.3.3.7.1" style="font-size:80%;">
         3
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.8">
        <span class="ltx_text" id="S5.T8.3.3.8.1" style="font-size:80%;">
         4
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.9">
        <span class="ltx_text" id="S5.T8.3.3.9.1" style="font-size:80%;">
         5
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.10">
        <span class="ltx_text" id="S5.T8.3.3.10.1" style="font-size:80%;">
         Avg.
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.1.1.1">
        <math alttext="\geq 4" class="ltx_Math" display="inline" id="S5.T8.1.1.1.m1.1">
         <semantics id="S5.T8.1.1.1.m1.1a">
          <mrow id="S5.T8.1.1.1.m1.1.1" xref="S5.T8.1.1.1.m1.1.1.cmml">
           <mi id="S5.T8.1.1.1.m1.1.1.2" xref="S5.T8.1.1.1.m1.1.1.2.cmml">
           </mi>
           <mo id="S5.T8.1.1.1.m1.1.1.1" mathsize="80%" xref="S5.T8.1.1.1.m1.1.1.1.cmml">
            ≥
           </mo>
           <mn id="S5.T8.1.1.1.m1.1.1.3" mathsize="80%" xref="S5.T8.1.1.1.m1.1.1.3.cmml">
            4
           </mn>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S5.T8.1.1.1.m1.1b">
           <apply id="S5.T8.1.1.1.m1.1.1.cmml" xref="S5.T8.1.1.1.m1.1.1">
            <geq id="S5.T8.1.1.1.m1.1.1.1.cmml" xref="S5.T8.1.1.1.m1.1.1.1">
            </geq>
            <csymbol cd="latexml" id="S5.T8.1.1.1.m1.1.1.2.cmml" xref="S5.T8.1.1.1.m1.1.1.2">
             absent
            </csymbol>
            <cn id="S5.T8.1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T8.1.1.1.m1.1.1.3">
             4
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T8.1.1.1.m1.1c">
           \geq 4
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.2.2.2">
        <math alttext="\geq 3" class="ltx_Math" display="inline" id="S5.T8.2.2.2.m1.1">
         <semantics id="S5.T8.2.2.2.m1.1a">
          <mrow id="S5.T8.2.2.2.m1.1.1" xref="S5.T8.2.2.2.m1.1.1.cmml">
           <mi id="S5.T8.2.2.2.m1.1.1.2" xref="S5.T8.2.2.2.m1.1.1.2.cmml">
           </mi>
           <mo id="S5.T8.2.2.2.m1.1.1.1" mathsize="80%" xref="S5.T8.2.2.2.m1.1.1.1.cmml">
            ≥
           </mo>
           <mn id="S5.T8.2.2.2.m1.1.1.3" mathsize="80%" xref="S5.T8.2.2.2.m1.1.1.3.cmml">
            3
           </mn>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S5.T8.2.2.2.m1.1b">
           <apply id="S5.T8.2.2.2.m1.1.1.cmml" xref="S5.T8.2.2.2.m1.1.1">
            <geq id="S5.T8.2.2.2.m1.1.1.1.cmml" xref="S5.T8.2.2.2.m1.1.1.1">
            </geq>
            <csymbol cd="latexml" id="S5.T8.2.2.2.m1.1.1.2.cmml" xref="S5.T8.2.2.2.m1.1.1.2">
             absent
            </csymbol>
            <cn id="S5.T8.2.2.2.m1.1.1.3.cmml" type="integer" xref="S5.T8.2.2.2.m1.1.1.3">
             3
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T8.2.2.2.m1.1c">
           \geq 3
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.3.3">
        <math alttext="\geq 2" class="ltx_Math" display="inline" id="S5.T8.3.3.3.m1.1">
         <semantics id="S5.T8.3.3.3.m1.1a">
          <mrow id="S5.T8.3.3.3.m1.1.1" xref="S5.T8.3.3.3.m1.1.1.cmml">
           <mi id="S5.T8.3.3.3.m1.1.1.2" xref="S5.T8.3.3.3.m1.1.1.2.cmml">
           </mi>
           <mo id="S5.T8.3.3.3.m1.1.1.1" mathsize="80%" xref="S5.T8.3.3.3.m1.1.1.1.cmml">
            ≥
           </mo>
           <mn id="S5.T8.3.3.3.m1.1.1.3" mathsize="80%" xref="S5.T8.3.3.3.m1.1.1.3.cmml">
            2
           </mn>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S5.T8.3.3.3.m1.1b">
           <apply id="S5.T8.3.3.3.m1.1.1.cmml" xref="S5.T8.3.3.3.m1.1.1">
            <geq id="S5.T8.3.3.3.m1.1.1.1.cmml" xref="S5.T8.3.3.3.m1.1.1.1">
            </geq>
            <csymbol cd="latexml" id="S5.T8.3.3.3.m1.1.1.2.cmml" xref="S5.T8.3.3.3.m1.1.1.2">
             absent
            </csymbol>
            <cn id="S5.T8.3.3.3.m1.1.1.3.cmml" type="integer" xref="S5.T8.3.3.3.m1.1.1.3">
             2
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T8.3.3.3.m1.1c">
           \geq 2
          </annotation>
         </semantics>
        </math>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T8.3.4">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.3.4.1">
        <span class="ltx_text" id="S5.T8.3.4.1.1" style="font-size:80%;">
         Instruction Prompting with zero-shot learning
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.2">
        <span class="ltx_text" id="S5.T8.3.4.2.1" style="font-size:80%;">
         41
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.3">
        <span class="ltx_text" id="S5.T8.3.4.3.1" style="font-size:80%;">
         11
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.4">
        <span class="ltx_text" id="S5.T8.3.4.4.1" style="font-size:80%;">
         27
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.5">
        <span class="ltx_text" id="S5.T8.3.4.5.1" style="font-size:80%;">
         18
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.6">
        <span class="ltx_text" id="S5.T8.3.4.6.1" style="font-size:80%;">
         3
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.7">
        <span class="ltx_text" id="S5.T8.3.4.7.1" style="font-size:80%;">
         2.31
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.8">
        <span class="ltx_text" id="S5.T8.3.4.8.1" style="font-size:80%;">
         21
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.9">
        <span class="ltx_text" id="S5.T8.3.4.9.1" style="font-size:80%;">
         48
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.10">
        <span class="ltx_text" id="S5.T8.3.4.10.1" style="font-size:80%;">
         52
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T8.3.5">
       <td class="ltx_td ltx_align_left" id="S5.T8.3.5.1">
        <span class="ltx_text" id="S5.T8.3.5.1.1" style="font-size:80%;">
         Instruction Prompting with few-shot learning
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.2">
        <span class="ltx_text" id="S5.T8.3.5.2.1" style="font-size:80%;">
         8
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.3">
        <span class="ltx_text" id="S5.T8.3.5.3.1" style="font-size:80%;">
         10
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.4">
        <span class="ltx_text" id="S5.T8.3.5.4.1" style="font-size:80%;">
         33
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.5">
        <span class="ltx_text" id="S5.T8.3.5.5.1" style="font-size:80%;">
         41
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.6">
        <span class="ltx_text" id="S5.T8.3.5.6.1" style="font-size:80%;">
         8
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.7">
        <span class="ltx_text" id="S5.T8.3.5.7.1" style="font-size:80%;">
         3.31
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.8">
        <span class="ltx_text" id="S5.T8.3.5.8.1" style="font-size:80%;">
         49
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.9">
        <span class="ltx_text" id="S5.T8.3.5.9.1" style="font-size:80%;">
         82
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.5.10">
        <span class="ltx_text" id="S5.T8.3.5.10.1" style="font-size:80%;">
         18
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T8.3.6">
       <td class="ltx_td ltx_align_left" id="S5.T8.3.6.1">
        <span class="ltx_text" id="S5.T8.3.6.1.1" style="font-size:80%;">
         Task-oriented Fine-tuning.
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.2">
        <span class="ltx_text" id="S5.T8.3.6.2.1" style="font-size:80%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.3">
        <span class="ltx_text" id="S5.T8.3.6.3.1" style="font-size:80%;">
         5
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.4">
        <span class="ltx_text" id="S5.T8.3.6.4.1" style="font-size:80%;">
         42
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.5">
        <span class="ltx_text" id="S5.T8.3.6.5.1" style="font-size:80%;">
         41
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.6">
        <span class="ltx_text" id="S5.T8.3.6.6.1" style="font-size:80%;">
         12
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.7">
        <span class="ltx_text" id="S5.T8.3.6.7.1" style="font-size:80%;">
         3.60
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.8">
        <span class="ltx_text" id="S5.T8.3.6.8.1" style="font-size:80%;">
         53
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.9">
        <span class="ltx_text" id="S5.T8.3.6.9.1" style="font-size:80%;">
         95
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T8.3.6.10">
        <span class="ltx_text" id="S5.T8.3.6.10.1" style="font-size:80%;">
         5
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T8.3.7">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T8.3.7.1">
        <span class="ltx_text" id="S5.T8.3.7.1.1" style="font-size:80%;">
         PromptCS
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.2">
        <span class="ltx_text" id="S5.T8.3.7.2.1" style="font-size:80%;">
         0
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.3">
        <span class="ltx_text" id="S5.T8.3.7.3.1" style="font-size:80%;">
         7
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.4">
        <span class="ltx_text" id="S5.T8.3.7.4.1" style="font-size:80%;">
         37
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.5">
        <span class="ltx_text" id="S5.T8.3.7.5.1" style="font-size:80%;">
         41
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.6">
        <span class="ltx_text" id="S5.T8.3.7.6.1" style="font-size:80%;">
         15
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.7">
        <span class="ltx_text" id="S5.T8.3.7.7.1" style="font-size:80%;">
         3.64
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.8">
        <span class="ltx_text" id="S5.T8.3.7.8.1" style="font-size:80%;">
         56
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.9">
        <span class="ltx_text" id="S5.T8.3.7.9.1" style="font-size:80%;">
         93
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.7.10">
        <span class="ltx_text" id="S5.T8.3.7.10.1" style="font-size:80%;">
         7
        </span>
       </td>
      </tr>
     </table>
    </figure>
    <div class="ltx_para" id="S5.SS2.SSS6.p2">
     <p class="ltx_p" id="S5.SS2.SSS6.p2.3">
      Table
      <a class="ltx_ref" href="#S5.T8" title="Table 8 ‣ 5.2.6. RQ6. PromptCS’s performance in human evaluation ‣ 5.2. Experimental Results ‣ 5. Evaluation and Analysis ‣ A Prompt Learning Framework for Source Code Summarization">
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      shows the score distribution of the generated summaries. Observe that PromptCS achieves the best scores and improves the average (Avg.) score from 2.31 (instruction prompting with zero-shot learning), 3.31 (instruction prompting with few-shot learning), and 3.60 (task-oriented fine-tuning) to 3.64. Specifically, among the randomly selected 100 code snippets, PromptCS can generate 15 highly similar or even identical summaries with the ground-truth ones (score = 5), 56 good summaries (score
      <math alttext="\geq" class="ltx_Math" display="inline" id="S5.SS2.SSS6.p2.1.m1.1">
       <semantics id="S5.SS2.SSS6.p2.1.m1.1a">
        <mo id="S5.SS2.SSS6.p2.1.m1.1.1" xref="S5.SS2.SSS6.p2.1.m1.1.1.cmml">
         ≥
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p2.1.m1.1b">
         <geq id="S5.SS2.SSS6.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS6.p2.1.m1.1.1">
         </geq>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS6.p2.1.m1.1c">
         \geq
        </annotation>
       </semantics>
      </math>
      4) and 93 summaries that are not bad (score
      <math alttext="\geq" class="ltx_Math" display="inline" id="S5.SS2.SSS6.p2.2.m2.1">
       <semantics id="S5.SS2.SSS6.p2.2.m2.1a">
        <mo id="S5.SS2.SSS6.p2.2.m2.1.1" xref="S5.SS2.SSS6.p2.2.m2.1.1.cmml">
         ≥
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p2.2.m2.1b">
         <geq id="S5.SS2.SSS6.p2.2.m2.1.1.cmml" xref="S5.SS2.SSS6.p2.2.m2.1.1">
         </geq>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS6.p2.2.m2.1c">
         \geq
        </annotation>
       </semantics>
      </math>
      3). PromptCS also receives the smaller number of negative results (score
      <math alttext="\leq" class="ltx_Math" display="inline" id="S5.SS2.SSS6.p2.3.m3.1">
       <semantics id="S5.SS2.SSS6.p2.3.m3.1a">
        <mo id="S5.SS2.SSS6.p2.3.m3.1.1" xref="S5.SS2.SSS6.p2.3.m3.1.1.cmml">
         ≤
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p2.3.m3.1b">
         <leq id="S5.SS2.SSS6.p2.3.m3.1.1.cmml" xref="S5.SS2.SSS6.p2.3.m3.1.1">
         </leq>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS6.p2.3.m3.1c">
         \leq
        </annotation>
       </semantics>
      </math>
      2).
Based on the 100 final scores for each baseline and PromptCS, we follow
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib77" title="">
        2020
       </a>
       )
      </cite>
      and conduct Wilcoxon signed-rank tests
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wilcoxon et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib73" title="">
        1963
       </a>
       )
      </cite>
      and compute Cliff’s delta effect sizes
      <cite class="ltx_cite ltx_citemacro_citep">
       (Macbeth et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib42" title="">
        2011
       </a>
       )
      </cite>
      . Comparing PromptCS with instruction prompting with zero-shot learning, instruction prompting with few-shot learning, and task-oriented fine-tuning, the p-values of Wilcoxon signed-rank tests at 95% confidence level are 5.46E-16, 0.016, and 0.722, which means the improvements achieved by PromptCS are statistically significant over instruction prompting with zero-shot and few-shot learning. In addition, Cliff’s delta effect sizes are 0.5669 (large), 0.1478 (small), and 0.0314 (negligible), respectively.
     </p>
    </div>
    <div class="ltx_para ltx_noindent ltx_align_center" id="S5.SS2.SSS6.1.p1">
     <svg class="ltx_picture" height="53.38" id="S5.SS2.SSS6.1.p1.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,53.38) matrix(1 0 0 -1 0 0)">
       <g fill="#000000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 47.48 C 0 50.74 2.64 53.38 5.91 53.38 L 594.09 53.38 C 597.36 53.38 600 50.74 600 47.48 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#ECECEC" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 47.48 C 1.97 49.65 3.73 51.41 5.91 51.41 L 594.09 51.41 C 596.27 51.41 598.03 49.65 598.03 47.48 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 3.94)">
        <foreignobject color="#000000" height="45.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="576.38">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:416.5pt;">
          <span class="ltx_p" id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1">
            ✎ Summary
           </span>
           <math alttext="\blacktriangleright" class="ltx_Math" display="inline" id="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
            <semantics id="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
             <mo id="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
              ▶
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
              <ci id="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
               ▶
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
              \blacktriangleright
             </annotation>
            </semantics>
           </math>
           Human evaluation shows that the summaries generated by PromptCS can achieve higher scores on average compared to those generated by baselines. PromptCS also generates the largest number of good summaries.
           <math alttext="\blacktriangleleft" class="ltx_Math" display="inline" id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
            <semantics id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
             <mo id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
              ◀
             </mo>
             <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
              <ci id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
               ◀
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S5.SS2.SSS6.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
              \blacktriangleleft
             </annotation>
            </semantics>
           </math>
          </span>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6.
   </span>
   Discussion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this section, we provide two code summarization cases to understand the generated summaries of PromptCS compared with baselines. Both cases are real-world examples from the CSN-Java test set. For each case, we consider the comment of the code snippet as the ground-truth summary and generate summaries by applying baselines and PromptCS to the LLM StarCoderBase-3B.
   </p>
  </div>
  <figure class="ltx_figure" id="S6.F6">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="169" id="S6.F6.g1" src="/html/2312.16066/assets/x6.png" width="415"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 6.
    </span>
    Code summarization case 1
   </figcaption>
  </figure>
  <div class="ltx_para" id="S6.p2">
   <p class="ltx_p" id="S6.p2.2">
    Figure
    <a class="ltx_ref" href="#S6.F6" title="Figure 6 ‣ 6. Discussion ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    shows the first code summarization case, where (b) presents the ground-truth summary and the summaries generated by baselines and PromptCS for the code snippet
    <math alttext="s_{2}" class="ltx_Math" display="inline" id="S6.p2.1.m1.1">
     <semantics id="S6.p2.1.m1.1a">
      <msub id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">
       <mi id="S6.p2.1.m1.1.1.2" xref="S6.p2.1.m1.1.1.2.cmml">
        s
       </mi>
       <mn id="S6.p2.1.m1.1.1.3" xref="S6.p2.1.m1.1.1.3.cmml">
        2
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b">
       <apply id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1">
        <csymbol cd="ambiguous" id="S6.p2.1.m1.1.1.1.cmml" xref="S6.p2.1.m1.1.1">
         subscript
        </csymbol>
        <ci id="S6.p2.1.m1.1.1.2.cmml" xref="S6.p2.1.m1.1.1.2">
         𝑠
        </ci>
        <cn id="S6.p2.1.m1.1.1.3.cmml" type="integer" xref="S6.p2.1.m1.1.1.3">
         2
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">
       s_{2}
      </annotation>
     </semantics>
    </math>
    in (a). From the figure, it is observed that compared with the ground-truth summary, the summaries generated by instruction prompting (few-shot) and task-oriented task fine-tuning can cover the semantics of the first two parts, i.e., “Fire” (Blue font) and “onThrowable” (Red font), whereas the summaries generated by instruction prompting (zero-shot) and PromptCS can cover the semantics of all three parts (including “to all registered listeners” (Orange font)). However, upon closer inspection of the method name of
    <math alttext="s_{2}" class="ltx_Math" display="inline" id="S6.p2.2.m2.1">
     <semantics id="S6.p2.2.m2.1a">
      <msub id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">
       <mi id="S6.p2.2.m2.1.1.2" xref="S6.p2.2.m2.1.1.2.cmml">
        s
       </mi>
       <mn id="S6.p2.2.m2.1.1.3" xref="S6.p2.2.m2.1.1.3.cmml">
        2
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b">
       <apply id="S6.p2.2.m2.1.1.cmml" xref="S6.p2.2.m2.1.1">
        <csymbol cd="ambiguous" id="S6.p2.2.m2.1.1.1.cmml" xref="S6.p2.2.m2.1.1">
         subscript
        </csymbol>
        <ci id="S6.p2.2.m2.1.1.2.cmml" xref="S6.p2.2.m2.1.1.2">
         𝑠
        </ci>
        <cn id="S6.p2.2.m2.1.1.3.cmml" type="integer" xref="S6.p2.2.m2.1.1.3">
         2
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">
       s_{2}
      </annotation>
     </semantics>
    </math>
    shown in the first line of Figure
    <a class="ltx_ref" href="#S6.F6" title="Figure 6 ‣ 6. Discussion ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    (a), we can find that for the second part (i.e., “onThrowable”), the summaries generated by three baselines (i.e., “an event”, “a ThrowableListener event”, and “an exception event”, respectively) are inaccurate. Only PromptCS successfully induces the LLM to generate this part correctly.
   </p>
  </div>
  <figure class="ltx_figure" id="S6.F7">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="217" id="S6.F7.g1" src="/html/2312.16066/assets/x7.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 7.
    </span>
    Code summarization case 2
   </figcaption>
  </figure>
  <div class="ltx_para" id="S6.p3">
   <p class="ltx_p" id="S6.p3.1">
    Figure
    <a class="ltx_ref" href="#S6.F7" title="Figure 7 ‣ 6. Discussion ‣ A Prompt Learning Framework for Source Code Summarization">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    shows the second code summarization case, where the ground-truth summary shown in (b) can be split into two clauses: “Verifies if the wrapped transaction is active” and “if dissociates it from the thread if needed”. Observe that compared with the ground-truth summary, 1) the summaries generated by instruction prompting (zero-shot and PromptCS cover the first clause; 2) the summary generated by instruction prompting (few-shot) covers the second clause; 3) the task-oriented fine-tuning fails to cover any of clauses. Another noteworthy point is that although the summary “if not throws an exception” generated by PromptCS is not part of the ground-truth summary, it indeed provides an excellent summary for the statement
    <span class="ltx_text ltx_font_typewriter" id="S6.p3.1.1">
     throw new IllegalStateException("There ... in state: " + status);
    </span>
    of the code snippet
    <math alttext="s_{3}" class="ltx_Math" display="inline" id="S6.p3.1.m1.1">
     <semantics id="S6.p3.1.m1.1a">
      <msub id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml">
       <mi id="S6.p3.1.m1.1.1.2" xref="S6.p3.1.m1.1.1.2.cmml">
        s
       </mi>
       <mn id="S6.p3.1.m1.1.1.3" xref="S6.p3.1.m1.1.1.3.cmml">
        3
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b">
       <apply id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1">
        <csymbol cd="ambiguous" id="S6.p3.1.m1.1.1.1.cmml" xref="S6.p3.1.m1.1.1">
         subscript
        </csymbol>
        <ci id="S6.p3.1.m1.1.1.2.cmml" xref="S6.p3.1.m1.1.1.2">
         𝑠
        </ci>
        <cn id="S6.p3.1.m1.1.1.3.cmml" type="integer" xref="S6.p3.1.m1.1.1.3">
         3
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">
       s_{3}
      </annotation>
     </semantics>
    </math>
    .
   </p>
  </div>
  <div class="ltx_para" id="S6.p4">
   <p class="ltx_p" id="S6.p4.1">
    From the two cases above, it is apparent that compared to baselines, PromptCS performs better in adapting LLMs for code summarization tasks. The credit for PromptCS’s good performance goes to its prompt agent, which is trained under the guidance of LLMs, allowing it to generate prompts better suited for LLMs. Of course, the second case also shows that PromptCS still has room for improvement. We will further optimize it in the future to better induce LLMs to generate high-quality code summaries.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7.
   </span>
   Related Work
  </h2>
  <section class="ltx_subsection" id="S7.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.1.
    </span>
    Code Summarization
   </h3>
   <div class="ltx_para" id="S7.SS1.p1">
    <p class="ltx_p" id="S7.SS1.p1.1">
     Research on code summarization started more than a decade ago. Most early code summarization techniques
     <cite class="ltx_cite ltx_citemacro_citep">
      (Haiduc et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2010a
      </a>
      ; Sridhara et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib56" title="">
       2010
      </a>
      ; Haiduc et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2010b
      </a>
      ; Moreno et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib44" title="">
       2013
      </a>
      )
     </cite>
     are extractive methods. Such methods work by extracting a subset of the statements and keywords from the code, and then including information from those statements and keywords in the final generated summary.
For instance, Sonia Haiduc et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Haiduc et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2010a
      </a>
      )
     </cite>
     first propose an extractive method to generate summaries for code snippets.
Subsequently, in light of the widespread availability of extensive code datasets and the success of neural machine translation (NMT) research in the field of NLP
     <cite class="ltx_cite ltx_citemacro_citep">
      (Cho et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2014a
      </a>
      ; Bahdanau et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       2015
      </a>
      )
     </cite>
     , deep learning approaches have increasingly become prevalent in enhancing the capabilities of code summarization tools. Pioneers in the field have discovered that certain Seq2Seq models, including RNN
     <cite class="ltx_cite ltx_citemacro_citep">
      (Cho et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib14" title="">
       2014b
      </a>
      )
     </cite>
     and LSTM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Iyer et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2016
      </a>
      )
     </cite>
     , demonstrate the ability to effectively capture the semantic relationships between code snippets and their corresponding summaries. For example, Iyer et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Iyer et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2016
      </a>
      )
     </cite>
     employ LSTM networks with attention to generating sentences describing C# code snippets and SQL queries. Hu et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib29" title="">
       2018a
      </a>
      )
     </cite>
     combine SBT with LSTM to automatically generate code comments for Java methods. However, it is noteworthy that RNN-based methodologies encounter challenges in maintaining long-term dependencies. To overcome this limitation and address potential bottlenecks in modeling long sequences, some Transformer-based methods have been proposed. Zhang et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib77" title="">
       2020
      </a>
      )
     </cite>
     propose a retrieval-based neural source code summarization approach by enhancing a Transformer-based model with the most similar code snippets retrieved from the training set. Ahmad et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib74" title="">
       2021
      </a>
      )
     </cite>
     explore the effectiveness of using Transformer to capture long-range dependencies in code for generating code summaries. In this paper, we focus on adapting LLMs for code summarization tasks
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ahmed and Devanbu,
      <a class="ltx_ref" href="#bib.bib5" title="">
       2022b
      </a>
      ; Sun et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib60" title="">
       2023c
      </a>
      ; Tian et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib62" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.2.
    </span>
    LLM for SE
   </h3>
   <div class="ltx_para" id="S7.SS2.p1">
    <p class="ltx_p" id="S7.SS2.p1.1">
     Over the years, developers have frequently sought programming assistance during the development process through channels such as blogs and documentation. This involves acquiring code and adapting it to their own context, as well as accessing explanations for related code to facilitate comprehension.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p2">
    <p class="ltx_p" id="S7.SS2.p2.1">
     Nowadays, developers can also leverage LLMs for such tasks. GPT-Neo
     <cite class="ltx_cite ltx_citemacro_citep">
      (Black et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2021
      </a>
      )
     </cite>
     , produced by EleutherAI in 2021, is an autoregressive LLM primarily designed for generating natural language text but can also be applied to generate source code. PolyCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib75" title="">
       2022
      </a>
      )
     </cite>
     , released in 2021, features 2.7B parameters and is trained on 249GB of code across 12 programming languages. In 2022, Salesforce introduced a language model called CodeGen
     <cite class="ltx_cite ltx_citemacro_citep">
      (Nijkamp et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023
      </a>
      )
     </cite>
     , specifically designed for code generation tasks. It employs a multi-step program synthesis approach, where a single program is factorized into multiple prompts specifying subproblems. That same year, Facebook proposed the first generative model InCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Fried et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      )
     </cite>
     , capable of directly performing zero-shot code infilling. In 2023, the BigCode community presented StarCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2023
      </a>
      )
     </cite>
     , a 15.5B model supporting over 80 programming languages. It boasts infilling capabilities and fast large-batch inference enabled by multi-query attention.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S8">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    8.
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S8.p1">
   <p class="ltx_p" id="S8.p1.1">
    We propose a prompt learning framework PromptCS for source code summarization. PromptCS is equipped with a prompt agent that can induce LLMs to accomplish code summarization tasks by generating continuous prompts. PromptCS can save model users from spending a significant amount of time crafting prompt instructions. Comprehensive automated and human evaluations demonstrate that PromptCS is effective in adapting LLMs to code summarization with low training costs. We believe that our prompt learning framework paired with LLMs can also benefit other SE tasks, and we leave the exploration of other SE tasks to future work.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Acknowledgment
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    The authors would like to thank the anonymous reviewers for their insightful comments. This work is supported partially by National Natural Science Foundation of China (61932012, 62141215, 62372228).
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahmad et al
     <span class="ltx_text" id="bib.bib2.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Wasi Uddin Ahmad, Saikat
Chakraborty, Baishakhi Ray, and
Kai-Wei Chang. 2020.
    </span>
    <span class="ltx_bibblock">
     A Transformer-based Approach for Source Code
Summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">
      Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics
     </em>
     .
Association for Computational Linguistics,
Online, 4998–5007.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahmad et al
     <span class="ltx_text" id="bib.bib3.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Wasi Uddin Ahmad, Saikat
Chakraborty, Baishakhi Ray, and
Kai-Wei Chang. 2021.
    </span>
    <span class="ltx_bibblock">
     Unified Pre-training for Program Understanding and
Generation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">
      Proceedings of the 2021 Conference
of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies
     </em>
     . Association
for Computational Linguistics, Online,
2655–2668.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahmed and Devanbu (2022a)
    </span>
    <span class="ltx_bibblock">
     Toufique Ahmed and
Premkumar T. Devanbu. 2022a.
    </span>
    <span class="ltx_bibblock">
     Artifacts of Few-shot training LLMs for
project-specific code-summarization.
    </span>
    <span class="ltx_bibblock">
     site:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/toufiqueparag/few_shot_code_summarization" target="_blank" title="">
      https://github.com/toufiqueparag/few_shot_code_summarization
     </a>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     Accessed December, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahmed and Devanbu (2022b)
    </span>
    <span class="ltx_bibblock">
     Toufique Ahmed and
Premkumar T. Devanbu. 2022b.
    </span>
    <span class="ltx_bibblock">
     Few-shot Training LLMs for Project-specific
Code-summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      Proceedings of the 37th
International Conference on Automated Software Engineering
     </em>
     .
ACM, Rochester, MI, USA,
177:1–177:5.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bahdanau et al
     <span class="ltx_text" id="bib.bib6.2.2.1">
      .
     </span>
     (2015)
    </span>
    <span class="ltx_bibblock">
     Dzmitry Bahdanau,
Kyunghyun Cho, and Yoshua Bengio.
2015.
    </span>
    <span class="ltx_bibblock">
     Neural Machine Translation by Jointly Learning to
Align and Translate. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">
      Proceedings of the 3rd
International Conference on Learning Representations
     </em>
     .
OpenReview.net, San Diego, CA, USA,
1–15.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Banerjee and Lavie (2005)
    </span>
    <span class="ltx_bibblock">
     Satanjeev Banerjee and
Alon Lavie. 2005.
    </span>
    <span class="ltx_bibblock">
     METEOR: An Automatic Metric for MT Evaluation
with Improved Correlation with Human Judgments. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Proceedings of the Workshop on Intrinsic and
Extrinsic Evaluation Measures for Machine Translation and/or Summarization
     </em>
     .
Association for Computational Linguistics,
Ann Arbor, Michigan, USA, 65–72.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bansal et al
     <span class="ltx_text" id="bib.bib8.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Aakash Bansal, Zachary
Eberhart, Zachary Karas, Yu Huang, and
Collin McMillan. 2023.
    </span>
    <span class="ltx_bibblock">
     Function Call Graph Context Encoding for Neural
Source Code Summarization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">
      IEEE Transactions on Software Engineering
     </em>
     49, 9 (2023),
4268–4281.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bhattacharya et al
     <span class="ltx_text" id="bib.bib9.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Paheli Bhattacharya,
Manojit Chakraborty, Kartheek N. S. N.
Palepu, Vikas Pandey, Ishan Dindorkar,
Rakesh Rajpurohit, and Rishabh Gupta.
2023.
    </span>
    <span class="ltx_bibblock">
     Exploring Large Language Models for Code
Explanation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">
      CoRR
     </em>
     abs/2310.16673,
1 (2023), 1–6.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Black et al
     <span class="ltx_text" id="bib.bib10.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Sid Black, Leo Gao,
Phil Wang, Connor Leahy, and
Stella Biderman. 2021.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">
      GPT-Neo: Large Scale Autoregressive
Language Modeling with Mesh-Tensorflow
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     EleutherAI.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al
     <span class="ltx_text" id="bib.bib11.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Tom B. Brown, Benjamin
Mann, Nick Ryder, Melanie Subbiah,
Jared Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh,
Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse,
Mark Chen, Eric Sigler,
Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and
Dario Amodei. 2020.
    </span>
    <span class="ltx_bibblock">
     Language Models are Few-Shot Learners. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">
      Proceedings of the 34th Annual Conference on Neural
Information Processing Systems
     </em>
     . Curran Associates
Inc., Virtual, 1877–1901.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib12.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek,
Heewoo Jun, Qiming Yuan,
Henrique Pondé de Oliveira Pinto,
Jared Kaplan, Harrison Edwards,
Yuri Burda, Nicholas Joseph,
Greg Brockman, Alex Ray,
Raul Puri, Gretchen Krueger,
Michael Petrov, Heidy Khlaaf,
Girish Sastry, Pamela Mishkin,
Brooke Chan, Scott Gray,
Nick Ryder, Mikhail Pavlov,
Alethea Power, Lukasz Kaiser,
Mohammad Bavarian Clemens Winter, Philippe
Tillet, Felipe Petroski Such, Dave
Cummings, Matthias Plappert, Fotios
Chantzis, et al
     <span class="ltx_text" id="bib.bib12.3.1">
      .
     </span>
     2021.
    </span>
    <span class="ltx_bibblock">
     Evaluating Large Language Models Trained on Code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.4.1">
      CoRR
     </em>
     abs/2107.03374,
1 (2021), 1–19.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cho et al
     <span class="ltx_text" id="bib.bib13.2.2.1">
      .
     </span>
     (2014a)
    </span>
    <span class="ltx_bibblock">
     Kyunghyun Cho, Bart van
Merrienboer, Dzmitry Bahdanau, and
Yoshua Bengio. 2014a.
    </span>
    <span class="ltx_bibblock">
     On the Properties of Neural Machine Translation:
Encoder-Decoder Approaches. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">
      Proceedings of the
8th Workshop on Syntax, Semantics and Structure in Statistical Translation
     </em>
     .
Association for Computational Linguistics,
Doha, Qatar, 103–111.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cho et al
     <span class="ltx_text" id="bib.bib14.2.2.1">
      .
     </span>
     (2014b)
    </span>
    <span class="ltx_bibblock">
     Kyunghyun Cho, Bart van
Merrienboer, Çaglar Gülçehre,
Dzmitry Bahdanau, Fethi Bougares,
Holger Schwenk, and Yoshua Bengio.
2014b.
    </span>
    <span class="ltx_bibblock">
     Learning Phrase Representations using RNN
Encoder-Decoder for Statistical Machine Translation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">
      Proceedings of the 19th Conference on Empirical
Methods in Natural Language Processing
     </em>
     . ACL,
Doha, Qatar, 1724–1734.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     de Souza et al
     <span class="ltx_text" id="bib.bib15.2.2.1">
      .
     </span>
     (2005)
    </span>
    <span class="ltx_bibblock">
     Sergio Cozzetti B. de Souza,
Nicolas Anquetil, and
Káthia Marçal de Oliveira.
2005.
    </span>
    <span class="ltx_bibblock">
     A study of the documentation essential to software
maintenance. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">
      Proceedings of the 23rd Annual
International Conference on Design of Communication: documenting &amp;
Designing for Pervasive Information
     </em>
     . ACM,
Coventry, UK, 68–75.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al
     <span class="ltx_text" id="bib.bib16.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Mengnan Du, Fengxiang He,
Na Zou, Dacheng Tao, and
Xia Hu. 2022.
    </span>
    <span class="ltx_bibblock">
     Shortcut Learning of Large Language Models in
Natural Language Understanding: A Survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">
      CoRR
     </em>
     abs/2208.11857,
1 (2022), 1–10.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Eddy et al
     <span class="ltx_text" id="bib.bib17.2.2.1">
      .
     </span>
     (2013)
    </span>
    <span class="ltx_bibblock">
     Brian P. Eddy, Jeffrey A.
Robinson, Nicholas A. Kraft, and
Jeffrey C. Carver. 2013.
    </span>
    <span class="ltx_bibblock">
     Evaluating Source Code Summarization Techniques:
Replication and Expansion. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">
      Proceedings of the
21st International Conference on Program Comprehension
     </em>
     .
IEEE Computer Society, San
Francisco, CA, USA, 13–22.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fan et al
     <span class="ltx_text" id="bib.bib18.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Angela Fan, Beliz
Gokkaya, Mark Harman, Mitya Lyubarskiy,
Shubho Sengupta, Shin Yoo, and
Jie M. Zhang. 2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models for Software Engineering:
Survey and Open Problems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">
      CoRR
     </em>
     abs/2310.03533,
1 (2023), 1–23.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al
     <span class="ltx_text" id="bib.bib19.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Zhangyin Feng, Daya Guo,
Duyu Tang, Nan Duan,
Xiaocheng Feng, Ming Gong,
Linjun Shou, Bing Qin,
Ting Liu, Daxin Jiang, and
Ming Zhou. 2020.
    </span>
    <span class="ltx_bibblock">
     CodeBERT: A Pre-Trained Model for Programming and
Natural Languages. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">
      Proceedings of the 25th
Conference on Empirical Methods in Natural Language Processing: Findings
     </em>
     .
Association for Computational Linguistics,
Online Event, 1536–1547.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fried et al
     <span class="ltx_text" id="bib.bib20.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Daniel Fried, Armen
Aghajanyan, Jessy Lin, Sida Wang,
Eric Wallace, Freda Shi,
Ruiqi Zhong, Scott Yih,
Luke Zettlemoyer, and Mike Lewis.
2023.
    </span>
    <span class="ltx_bibblock">
     InCoder: A Generative Model for Code Infilling
and Synthesis. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">
      Proceedings of the 11th
International Conference on Learning Representations
     </em>
     .
OpenReview.net, Kigali, Rwanda,
1–14.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gros et al
     <span class="ltx_text" id="bib.bib21.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     David Gros, Hariharan
Sezhiyan, Prem Devanbu, and Zhou Yu.
2020.
    </span>
    <span class="ltx_bibblock">
     Code to Comment ”Translation”: Data, Metrics,
Baselining &amp; Evaluation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">
      Proceedings of the
35th International Conference on Automated Software Engineering
     </em>
     .
IEEE, Melbourne, Australia,
746–757.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al
     <span class="ltx_text" id="bib.bib22.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Daya Guo, Shuai Lu,
Nan Duan, Yanlin Wang,
Ming Zhou, and Jian Yin.
2022.
    </span>
    <span class="ltx_bibblock">
     UniXcoder: Unified Cross-Modal Pre-training for
Code Representation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">
      Proceedings of the 60th
Annual Meeting of the Association for Computational Linguistics
     </em>
     .
Association for Computational Linguistics,
Dublin, Ireland, 7212–7225.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al
     <span class="ltx_text" id="bib.bib23.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Daya Guo, Shuo Ren,
Shuai Lu, Zhangyin Feng,
Duyu Tang, Shujie Liu,
Long Zhou, Nan Duan,
Alexey Svyatkovskiy, Shengyu Fu,
Michele Tufano, Shao Kun Deng,
Colin B. Clement, Dawn Drain,
Neel Sundaresan, Jian Yin,
Daxin Jiang, and Ming Zhou.
2021.
    </span>
    <span class="ltx_bibblock">
     GraphCodeBERT: Pre-training Code Representations
with Data Flow. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">
      Proceedings of the 9th
International Conference on Learning Representations
     </em>
     .
OpenReview.net, Virtual Event,
Austria, 1–12.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Haiduc et al
     <span class="ltx_text" id="bib.bib24.2.2.1">
      .
     </span>
     (2010a)
    </span>
    <span class="ltx_bibblock">
     Sonia Haiduc, Jairo
Aponte, and Andrian Marcus.
2010a.
    </span>
    <span class="ltx_bibblock">
     Supporting program comprehension with source code
summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">
      Proceedings of the 32nd
International Conference on Software Engineering
     </em>
     .
ACM, Cape Town, South Africa,
223–226.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Haiduc et al
     <span class="ltx_text" id="bib.bib25.2.2.1">
      .
     </span>
     (2010b)
    </span>
    <span class="ltx_bibblock">
     Sonia Haiduc, Jairo
Aponte, Laura Moreno, and Andrian
Marcus. 2010b.
    </span>
    <span class="ltx_bibblock">
     On the Use of Automated Text Summarization
Techniques for Summarizing Source Code. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">
      Proceedings of the 17th Working Conference on
Reverse Engineering
     </em>
     . IEEE Computer Society,
Beverly, MA, USA, 35–44.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Haque et al
     <span class="ltx_text" id="bib.bib26.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Sakib Haque, Zachary
Eberhart, Aakash Bansal, and Collin
McMillan. 2022.
    </span>
    <span class="ltx_bibblock">
     Semantic similarity metrics for evaluating source
code summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">
      Proceedings of the 30th
International Conference on Program Comprehension
     </em>
     .
ACM, Virtual Event,
36–47.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hou et al
     <span class="ltx_text" id="bib.bib27.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Xinyi Hou, Yanjie Zhao,
Yue Liu, Zhou Yang,
Kailong Wang, Li Li,
Xiapu Luo, David Lo,
John C. Grundy, and Haoyu Wang.
2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models for Software Engineering: A
Systematic Literature Review.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">
      CoRR
     </em>
     abs/2308.10620,
1 (2023), 1–62.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib28.2.2.1">
      .
     </span>
     (2022a)
    </span>
    <span class="ltx_bibblock">
     Xing Hu, Qiuyuan Chen,
Haoye Wang, Xin Xia,
David Lo, and Thomas Zimmermann.
2022a.
    </span>
    <span class="ltx_bibblock">
     Correlating Automated and Human Evaluation of Code
Documentation Generation Quality.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">
      ACM Transactions on Software Engineering
and Methodology
     </em>
     31, 4
(2022), 63:1–63:28.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib29.2.2.1">
      .
     </span>
     (2018a)
    </span>
    <span class="ltx_bibblock">
     Xing Hu, Ge Li,
Xin Xia, David Lo, and
Zhi Jin. 2018a.
    </span>
    <span class="ltx_bibblock">
     Deep Code Comment Generation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">
      Proceedings of the 26th International Conference on
Program Comprehension
     </em>
     . ACM,
Gothenburg, Sweden, 200–210.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib30.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Xing Hu, Ge Li,
Xin Xia, David Lo, and
Zhi Jin. 2020.
    </span>
    <span class="ltx_bibblock">
     Deep Code Comment Generation with Hybrid Lexical
and Syntactical Information.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">
      Empirical Software Engineering
     </em>
     25, 3 (2020),
2179–2217.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib31.2.2.1">
      .
     </span>
     (2018b)
    </span>
    <span class="ltx_bibblock">
     Xing Hu, Ge Li,
Xin Xia, David Lo, Shuai
Lu, and Zhi Jin. 2018b.
    </span>
    <span class="ltx_bibblock">
     Summarizing Source Code with Transferred API
Knowledge. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">
      Proceedings of the 27th
International Joint Conference on Artificial Intelligence
     </em>
     .
ijcai.org, Stockholm, Sweden,
2269–2275.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib32.2.2.1">
      .
     </span>
     (2022b)
    </span>
    <span class="ltx_bibblock">
     Xing Hu, Xin Xia,
David Lo, Zhiyuan Wan,
Qiuyuan Chen, and Thomas Zimmermann.
2022b.
    </span>
    <span class="ltx_bibblock">
     Practitioners’ Expectations on Automated Code
Comment Generation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">
      Proceedings of the 44th
International Conference on Software Engineering
     </em>
     .
ACM, Pittsburgh, PA, USA,
1693–1705.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Husain et al
     <span class="ltx_text" id="bib.bib33.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Hamel Husain, Ho-Hsiang
Wu, Tiferet Gazit, Miltiadis Allamanis,
and Marc Brockschmidt. 2019.
    </span>
    <span class="ltx_bibblock">
     CodeSearchNet Challenge: Evaluating the State of
Semantic Code Search.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">
      CoRR
     </em>
     abs/1909.09436,
1 (2019), 1–6.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Iyer et al
     <span class="ltx_text" id="bib.bib34.2.2.1">
      .
     </span>
     (2016)
    </span>
    <span class="ltx_bibblock">
     Srinivasan Iyer, Ioannis
Konstas, Alvin Cheung, and Luke
Zettlemoyer. 2016.
    </span>
    <span class="ltx_bibblock">
     Summarizing Source Code using a Neural Attention
Model. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">
      Proceedings of the 54th Annual Meeting
of the Association for Computational Linguistics
     </em>
     . The
Association for Computer Linguistics, Berlin, Germany,
2073–2083.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jin et al
     <span class="ltx_text" id="bib.bib35.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Matthew Jin, Syed
Shahriar, Michele Tufano, Xin Shi,
Shuai Lu, Neel Sundaresan, and
Alexey Svyatkovskiy. 2023.
    </span>
    <span class="ltx_bibblock">
     InferFix: End-to-End Program Repair with LLMs over
Retrieval-Augmented Prompts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">
      CoRR
     </em>
     abs/2303.07263,
1 (2023), 1–11.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kaplan et al
     <span class="ltx_text" id="bib.bib36.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Jared Kaplan, Sam
McCandlish, Tom Henighan, Tom B. Brown,
Benjamin Chess, Rewon Child,
Scott Gray, Alec Radford,
Jeffrey Wu, and Dario Amodei.
2020.
    </span>
    <span class="ltx_bibblock">
     Scaling Laws for Neural Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">
      CoRR
     </em>
     abs/2001.08361,
1 (2020), 1–19.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kocetkov et al
     <span class="ltx_text" id="bib.bib37.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Denis Kocetkov, Raymond
Li, Loubna Ben Allal, Jia Li,
Chenghao Mou, Carlos Muñoz
Ferrandis, Yacine Jernite, Margaret
Mitchell, Sean Hughes, Thomas Wolf,
Dzmitry Bahdanau, Leandro von Werra,
and Harm de Vries. 2022.
    </span>
    <span class="ltx_bibblock">
     The Stack: 3 TB of permissively licensed source
code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">
      CoRR
     </em>
     abs/2211.15533,
1 (2022), 1–18.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al
     <span class="ltx_text" id="bib.bib38.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Raymond Li, Loubna Ben
Allal, Yangtian Zi, Niklas Muennighoff,
Denis Kocetkov, Chenghao Mou,
Marc Marone, Christopher Akiki,
Jia Li, Jenny Chim, Qian
Liu, Evgenii Zheltonozhskii, Terry Yue
Zhuo, Thomas Wang, Olivier Dehaene,
Mishig Davaadorj, Joel Lamy-Poirier,
João Monteiro, Oleh Shliazhko,
et al
     <span class="ltx_text" id="bib.bib38.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     StarCoder: may the source be with you!
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.4.1">
      CoRR
     </em>
     abs/2305.06161,
1 (2023), 1–44.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin (2004)
    </span>
    <span class="ltx_bibblock">
     Chin-Yew Lin.
2004.
    </span>
    <span class="ltx_bibblock">
     ROUGE: A Package for Automatic Evaluation of
Summaries. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      Proceedings of the 42nd Annual
Meeting of the Association for Computational Linguistics – workshop on Text
Summarization Branches Out
     </em>
     . Association for
Computational Linguistics, Barcelona, Spain,
74–81.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Loshchilov and Hutter (2019)
    </span>
    <span class="ltx_bibblock">
     Ilya Loshchilov and
Frank Hutter. 2019.
    </span>
    <span class="ltx_bibblock">
     Decoupled Weight Decay Regularization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      Proceedings of the 7th International Conference on
Learning Representations
     </em>
     . OpenReview.net,
New Orleans, LA, USA, 1–11.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al
     <span class="ltx_text" id="bib.bib41.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Shuai Lu, Daya Guo,
Shuo Ren, Junjie Huang,
Alexey Svyatkovskiy, Ambrosio Blanco,
Colin B. Clement, Dawn Drain,
Daxin Jiang, Duyu Tang,
Ge Li, Lidong Zhou,
Linjun Shou, Long Zhou,
Michele Tufano, Ming Gong,
Ming Zhou, Nan Duan,
Neel Sundaresan, Shao Kun Deng,
Shengyu Fu, and Shujie Liu.
2021.
    </span>
    <span class="ltx_bibblock">
     CodeXGLUE: A Machine Learning Benchmark Dataset
for Code Understanding and Generation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">
      Proceedings of the Neural Information Processing
Systems Track on Datasets and Benchmarks 1
     </em>
     .
Openreview.net, virtual,
1–14.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Macbeth et al
     <span class="ltx_text" id="bib.bib42.2.2.1">
      .
     </span>
     (2011)
    </span>
    <span class="ltx_bibblock">
     Guillermo Macbeth, Eugenia
Razumiejczyk, and Rubén Daniel Ledesma.
2011.
    </span>
    <span class="ltx_bibblock">
     Cliff’s Delta Calculator: A non-parametric effect
size program for two groups of observations.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">
      Universitas Psychologica
     </em>
     10, 2 (2011),
545–555.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Moore et al
     <span class="ltx_text" id="bib.bib43.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Jessica Moore, Ben
Gelman, and David Slater.
2019.
    </span>
    <span class="ltx_bibblock">
     A Convolutional Neural Network for
Language-Agnostic Source Code Summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">
      Proceedings of the 14th International Conference on
Evaluation of Novel Approaches to Software Engineering
     </em>
     .
SciTePress, Heraklion, Crete, Greece,
15–26.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Moreno et al
     <span class="ltx_text" id="bib.bib44.2.2.1">
      .
     </span>
     (2013)
    </span>
    <span class="ltx_bibblock">
     Laura Moreno, Jairo
Aponte, Giriprasad Sridhara, Andrian
Marcus, Lori L. Pollock, and K.
Vijay-Shanker. 2013.
    </span>
    <span class="ltx_bibblock">
     Automatic Generation of Natural Language Summaries
for Java Classes. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">
      Proceedings of the 21st
International Conference on Program Comprehension
     </em>
     .
IEEE Computer Society, San
Francisco, CA, USA, 23–32.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nijkamp et al
     <span class="ltx_text" id="bib.bib45.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Erik Nijkamp, Bo Pang,
Hiroaki Hayashi, Lifu Tu,
Huan Wang, Yingbo Zhou,
Silvio Savarese, and Caiming Xiong.
2023.
    </span>
    <span class="ltx_bibblock">
     CodeGen: An Open Large Language Model for Code with
Multi-Turn Program Synthesis. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">
      Proceedings of
the 11th International Conference on Learning Representations
     </em>
     .
OpenReview.net, Kigali, Rwanda,
1–13.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2022)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2022.
    </span>
    <span class="ltx_bibblock">
     ChatGPT.
    </span>
    <span class="ltx_bibblock">
     site:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/chatgpt" target="_blank" title="">
      https://openai.com/blog/chatgpt
     </a>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     Accessed December, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023a)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023a.
    </span>
    <span class="ltx_bibblock">
     Codex.
    </span>
    <span class="ltx_bibblock">
     site:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/openai-codex" target="_blank" title="">
      https://openai.com/blog/openai-codex
     </a>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     Accessed December, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023b)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023b.
    </span>
    <span class="ltx_bibblock">
     OpenAI API.
    </span>
    <span class="ltx_bibblock">
     site:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/models" target="_blank" title="">
      https://platform.openai.com/docs/models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     Accessed December, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Papineni et al
     <span class="ltx_text" id="bib.bib49.2.2.1">
      .
     </span>
     (2002)
    </span>
    <span class="ltx_bibblock">
     Kishore Papineni, Salim
Roukos, Todd Ward, and Wei-Jing
Zhu. 2002.
    </span>
    <span class="ltx_bibblock">
     BLEU: A Method for Automatic Evaluation of Machine
Translation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">
      Proceedings of the 40th Annual
Meeting of the Association for Computational Linguistics
     </em>
     .
ACL, Philadelphia, PA, USA,
311–318.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pennington et al
     <span class="ltx_text" id="bib.bib50.2.2.1">
      .
     </span>
     (2014)
    </span>
    <span class="ltx_bibblock">
     Jeffrey Pennington,
Richard Socher, and Christopher D.
Manning. 2014.
    </span>
    <span class="ltx_bibblock">
     Glove: Global Vectors for Word Representation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">
      Proceedings of the 2014 Conference on Empirical
Methods in Natural Language Processing
     </em>
     . ACL,
Doha, Qatar, 1532–1543.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al
     <span class="ltx_text" id="bib.bib51.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Chengwei Qin, Aston
Zhang, Zhuosheng Zhang, Jiaao Chen,
Michihiro Yasunaga, and Diyi Yang.
2023.
    </span>
    <span class="ltx_bibblock">
     Is ChatGPT a General-Purpose Natural Language
Processing Task Solver?. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">
      Proceedings of the
2023 Conference on Empirical Methods in Natural Language Processing
     </em>
     .
Association for Computational Linguistics,
Singapore, 1339–1384.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Radford et al
     <span class="ltx_text" id="bib.bib52.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Alec Radford, Jeffrey Wu,
Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever,
et al
     <span class="ltx_text" id="bib.bib52.3.1">
      .
     </span>
     2019.
    </span>
    <span class="ltx_bibblock">
     Language models are unsupervised multitask
learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.4.1">
      OpenAI blog
     </em>
     1,
8 (2019), 1–12.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Reimers and Gurevych (2019)
    </span>
    <span class="ltx_bibblock">
     Nils Reimers and Iryna
Gurevych. 2019.
    </span>
    <span class="ltx_bibblock">
     Sentence-BERT: Sentence Embeddings using Siamese
BERT-Networks. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      Proceedings of the the 9th
International Joint Conference on Natural Language Processing
     </em>
     .
Association for Computational Linguistics,
Hong Kong, China, 3980–3990.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rozière et al
     <span class="ltx_text" id="bib.bib54.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Baptiste Rozière,
Jonas Gehring, Fabian Gloeckle,
Sten Sootla, Itai Gat,
Xiaoqing Ellen Tan, Yossi Adi,
Jingyu Liu, Tal Remez,
Jérémy Rapin, Artyom
Kozhevnikov, Ivan Evtimov, Joanna
Bitton, Manish Bhatt, Cristian
Canton-Ferrer, Aaron Grattafiori,
Wenhan Xiong, Alexandre Défossez,
Jade Copet, Faisal Azhar,
Hugo Touvron, Louis Martin,
Nicolas Usunier, Thomas Scialom, and
Gabriel Synnaeve. 2023.
    </span>
    <span class="ltx_bibblock">
     Code Llama: Open Foundation Models for Code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">
      CoRR
     </em>
     abs/2308.12950,
1 (2023), 1–47.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shi et al
     <span class="ltx_text" id="bib.bib55.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Ensheng Shi, Yanlin Wang,
Lun Du, Junjie Chen, Shi
Han, Hongyu Zhang, Dongmei Zhang, and
Hongbin Sun. 2022.
    </span>
    <span class="ltx_bibblock">
     On the Evaluation of Neural Code Summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">
      Proceedings of the 44th International Conference on
Software Engineering
     </em>
     . IEEE,
Pittsburgh, USA, 1597––1608.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sridhara et al
     <span class="ltx_text" id="bib.bib56.2.2.1">
      .
     </span>
     (2010)
    </span>
    <span class="ltx_bibblock">
     Giriprasad Sridhara, Emily
Hill, Divya Muppaneni, Lori L. Pollock,
and K. Vijay-Shanker. 2010.
    </span>
    <span class="ltx_bibblock">
     Towards Automatically Generating Summary Comments
for Java Methods. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">
      Proceedings of the 25th
International Conference on Automated Software Engineering
     </em>
     .
ACM, Antwerp, Belgium,
43–52.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Stapleton et al
     <span class="ltx_text" id="bib.bib57.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Sean Stapleton, Yashmeet
Gambhir, Alexander LeClair, Zachary
Eberhart, Westley Weimer, Kevin Leach,
and Yu Huang. 2020.
    </span>
    <span class="ltx_bibblock">
     A Human Study of Comprehension and Code
Summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">
      Proceedings of the 28th
International Conference on Program Comprehension
     </em>
     .
ACM, Seoul, Republic of Korea,
2–13.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al
     <span class="ltx_text" id="bib.bib58.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Weisong Sun, Chunrong
Fang, Yuchen Chen, Quanjun Zhang,
Guanhong Tao, Yudu You,
Tingxu Han, Yifei Ge,
Yuling Hu, Bin Luo, and
Zhenyu Chen. 2023a.
    </span>
    <span class="ltx_bibblock">
     An Extractive-and-Abstractive Framework for Source
Code Summarization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">
      ACM Transactions on Software Engineering and
Methodology
     </em>
     Just Accepted, 1
(2023), 1–39.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al
     <span class="ltx_text" id="bib.bib59.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Weisong Sun, Chunrong
Fang, Yudu You, Yuchen Chen,
Yi Liu, Chong Wang, Jian
Zhang, Quanjun Zhang, Hanwei Qian,
Wei Zhao, Yang Liu, and
Zhenyu Chen. 2023b.
    </span>
    <span class="ltx_bibblock">
     Artifacts of PromptCS.
    </span>
    <span class="ltx_bibblock">
     site:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/wssun/PromptCS" target="_blank" title="">
      https://github.com/wssun/PromptCS
     </a>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     Accessed December, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al
     <span class="ltx_text" id="bib.bib60.2.2.1">
      .
     </span>
     (2023c)
    </span>
    <span class="ltx_bibblock">
     Weisong Sun, Chunrong
Fang, Yudu You, Yun Miao,
Yi Liu, Yuekang Li,
Gelei Deng, Shenghan Huang,
Yuchen Chen, Quanjun Zhang,
Hanwei Qian, Yang Liu, and
Zhenyu Chen. 2023c.
    </span>
    <span class="ltx_bibblock">
     Automatic Code Summarization via ChatGPT: How Far
Are We?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">
      CoRR
     </em>
     abs/2305.12865
(2023), 1–13.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tenny (1988)
    </span>
    <span class="ltx_bibblock">
     Ted Tenny.
1988.
    </span>
    <span class="ltx_bibblock">
     Program Readability: Procedures Versus Comments.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      IEEE Transactions on Software Engineering
     </em>
     14, 9 (1988),
1271–1279.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tian et al
     <span class="ltx_text" id="bib.bib62.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Haoye Tian, Weiqi Lu,
Tsz On Li, Xunzhu Tang,
Shing-Chi Cheung, Jacques Klein, and
Tegawendé F Bissyandé.
2023.
    </span>
    <span class="ltx_bibblock">
     Is ChatGPT the Ultimate Programming Assistant–How
far is it?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">
      CoRR
     </em>
     abs/2304.11938,
1 (2023), 1–22.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al
     <span class="ltx_text" id="bib.bib63.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Thibaut
Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux,
Timothée Lacroix, Baptiste
Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, Aurélien Rodriguez,
Armand Joulin, Edouard Grave, and
Guillaume Lample. 2023.
    </span>
    <span class="ltx_bibblock">
     LLaMA: Open and Efficient Foundation Language
Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">
      CoRR
     </em>
     abs/2302.13971,
1 (2023), 1–16.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vaswani et al
     <span class="ltx_text" id="bib.bib64.2.2.1">
      .
     </span>
     (2017)
    </span>
    <span class="ltx_bibblock">
     Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N. Gomez,
undefinedukasz Kaiser, and Illia
Polosukhin. 2017.
    </span>
    <span class="ltx_bibblock">
     Attention is All You Need. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">
      Proceedings of the 31st Annual Conference on Neural
Information Processing Systems
     </em>
     . Curran Associates
Inc., Long Beach, CA, USA, 5998–6008.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wan et al
     <span class="ltx_text" id="bib.bib65.2.2.1">
      .
     </span>
     (2018)
    </span>
    <span class="ltx_bibblock">
     Yao Wan, Zhou Zhao,
Min Yang, Guandong Xu,
Haochao Ying, Jian Wu, and
Philip S. Yu. 2018.
    </span>
    <span class="ltx_bibblock">
     Improving Automatic Source Code Summarization via
Deep Reinforcement Learning. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib65.3.1">
      Proceedings of the
33rd International Conference on Automated Software Engineering
     </em>
     .
ACM, Montpellier, France,
397–407.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib66.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Deze Wang, Boxing Chen,
Shanshan Li, Wei Luo,
Shaoliang Peng, Wei Dong, and
Xiangke Liao. 2023a.
    </span>
    <span class="ltx_bibblock">
     One Adapter for All Programming Languages? Adapter
Tuning for Code Search and Summarization. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">
      Proceedings of the 45th International Conference on
Software Engineering
     </em>
     . IEEE,
Melbourne, Australia, 5–16.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib67.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Wenhua Wang, Yuqun Zhang,
Yulei Sui, Yao Wan, Zhou
Zhao, Jian Wu, Philip Yu, and
Guandong Xu. 2022.
    </span>
    <span class="ltx_bibblock">
     Reinforcement-Learning-Guided Source Code
Summarization Using Hierarchical Attention.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.3.1">
      IEEE Transactions on Software Engineering
     </em>
     48, 2 (2022),
102–119.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib68.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Yizhong Wang, Yeganeh
Kordi, Swaroop Mishra, Alisa Liu,
Noah A. Smith, Daniel Khashabi, and
Hannaneh Hajishirzi. 2023b.
    </span>
    <span class="ltx_bibblock">
     Self-Instruct: Aligning Language Models with
Self-Generated Instructions. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib68.3.1">
      Proceedings of the
61st Annual Meeting of the Association for Computational Linguistics
     </em>
     .
Association for Computational Linguistics,
Toronto, Canada, 13484–13508.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib69.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Yue Wang, Weishi Wang,
Shafiq R. Joty, and Steven C. H. Hoi.
2021.
    </span>
    <span class="ltx_bibblock">
     CodeT5: Identifier-aware Unified Pre-trained
Encoder-Decoder Models for Code Understanding and Generation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib69.3.1">
      Proceedings of the 26th Conference on Empirical
Methods in Natural Language Processing
     </em>
     . Association for
Computational Linguistics, Virtual Event / Punta Cana,
Dominican Republic, 8696–8708.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al
     <span class="ltx_text" id="bib.bib70.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Bolin Wei, Yongmin Li,
Ge Li, Xin Xia, and
Zhi Jin. 2020.
    </span>
    <span class="ltx_bibblock">
     Retrieve and Refine: Exemplar-based Neural Comment
Generation. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.3.1">
      Proceedings of the 35th
International Conference on Automated Software Engineering
     </em>
     .
IEEE, Melbourne, Australia,
349–360.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al
     <span class="ltx_text" id="bib.bib71.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Maarten Bosma,
Vincent Y. Zhao, Kelvin Guu,
Adams Wei Yu, Brian Lester,
Nan Du, Andrew M. Dai, and
Quoc V. Le. 2022.
    </span>
    <span class="ltx_bibblock">
     Finetuned Language Models are Zero-Shot Learners.
In
     <em class="ltx_emph ltx_font_italic" id="bib.bib71.3.1">
      Proceedings of the 10th International Conference
on Learning Representations
     </em>
     . OpenReview.net,
Virtual Event, 1–21.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Weyssow et al
     <span class="ltx_text" id="bib.bib72.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Martin Weyssow, Xin Zhou,
Kisub Kim, David Lo, and
Houari A. Sahraoui. 2023.
    </span>
    <span class="ltx_bibblock">
     Exploring Parameter-Efficient Fine-Tuning
Techniques for Code Generation with Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib72.3.1">
      CoRR
     </em>
     abs/2308.10462,
1 (2023), 1–12.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wilcoxon et al
     <span class="ltx_text" id="bib.bib73.2.2.1">
      .
     </span>
     (1963)
    </span>
    <span class="ltx_bibblock">
     Frank Wilcoxon, SK Katti,
and Roberta A Wilcox. 1963.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib73.3.1">
      Critical values and probability levels for
the Wilcoxon rank sum test and the Wilcoxon signed rank test
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     American Cyanamid Company,
USA.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al
     <span class="ltx_text" id="bib.bib74.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Hongqiu Wu, Hai Zhao,
and Min Zhang. 2021.
    </span>
    <span class="ltx_bibblock">
     Code Summarization with Structure-induced
Transformer. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib74.3.1">
      Proceedings of the Findings of the
59th Annual Meeting of the Association for Computational Linguistics and the
11th International Joint Conference on Natural Language Processing
     </em>
     .
Association for Computational Linguistics,
Online Event, 1078–1090.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al
     <span class="ltx_text" id="bib.bib75.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Frank F. Xu, Uri Alon,
Graham Neubig, and Vincent Josua
Hellendoorn. 2022.
    </span>
    <span class="ltx_bibblock">
     A Systematic Evaluation of Large Language Models of
Code. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib75.3.1">
      Proceedings of the 6th International
Symposium on Machine Programming
     </em>
     . ACM,
San Diego, CA, USA, 1–10.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al
     <span class="ltx_text" id="bib.bib76.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Hang Xu, Ning Kang,
Gengwei Zhang, Chuanlong Xie,
Xiaodan Liang, and Zhenguo Li.
2021.
    </span>
    <span class="ltx_bibblock">
     NASOA: Towards Faster Task-oriented Online
Fine-tuning with a Zoo of Models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib76.3.1">
      Proceedings
of the 18th International Conference on Computer Vision
     </em>
     .
IEEE, Montreal, QC, Canada,
5077–5086.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al
     <span class="ltx_text" id="bib.bib77.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Jian Zhang, Xu Wang,
Hongyu Zhang, Hailong Sun, and
Xudong Liu. 2020.
    </span>
    <span class="ltx_bibblock">
     Retrieval-based Neural Source Code Summarization.
In
     <em class="ltx_emph ltx_font_italic" id="bib.bib77.3.1">
      Proceedings of the 42nd International Conference
on Software Engineering
     </em>
     . ACM,
Seoul, South Korea, 1385–1397.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al
     <span class="ltx_text" id="bib.bib78.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Yu Zhou, Juanjuan Shen,
Xiaoqing Zhang, Wenhua Yang,
Tingting Han, and Taolue Chen.
2022.
    </span>
    <span class="ltx_bibblock">
     Automatic source code summarization with graph
attention networks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib78.3.1">
      Journal of Systems and Software
     </em>
     188 (2022), 111257.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
