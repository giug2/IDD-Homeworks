<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2108.10761] Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health</title><meta property="og:description" content="Privacy protection is an ethical issue with broad concern in Artificial Intelligence (AI). Federated learning is a new machine learning paradigm to learn a shared model across users or organisations without direct acceâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2108.10761">

<!--Generated on Tue Mar 12 03:24:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Received: date / Accepted: date.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">âˆ</p>
</div>
<span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Guodong Long, Tao Shen, Yue Tan, Leah Gerrard and Jing Jiang </span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Australian Artificial Intelligence Institute, 
<br class="ltx_break">Faculty of Engineering and Information Technology, 
<br class="ltx_break">University of Technology Sydney 
<br class="ltx_break"><span id="id2.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>Guodong.Long@uts.edu.au, {Tao.Shen}{Yue.Tan}{Leah.Gerrard}@student.uts.edu.au, Jing.Jiang@uts.edu.au</span></span></span>
</span></span></span><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Allison Clarke </span></span></span><span id="id4" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>Â Data and Analytics Branch, 
<br class="ltx_break">Health Economics and Research Division, 
<br class="ltx_break">Australian Department of Health
<br class="ltx_break"><span id="id4.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">email: </span>Allison.Clarke@health.gov.au
</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Guodong Long
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tao Shen
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yue Tan
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Leah Gerrard
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Allison Clarke
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jing Jiang
</span></span>
</div>
<div class="ltx_dates">(Received: date / Accepted: date)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Privacy protection is an ethical issue with broad concern in Artificial Intelligence (AI). Federated learning is a new machine learning paradigm to learn a shared model across users or organisations without direct access to the data. It has great potential to be the next-general AI model training framework that offers privacy protection and therefore has broad implications for the future of digital health and healthcare informatics. Implementing an open innovation framework in the healthcare industry, namely open health, is to enhance innovation and creative capability of health-related organisations by building a next-generation collaborative framework with partner organisations and the research community. In particular, this game-changing collaborative framework offers knowledge sharing from diverse data with a privacy-preserving. This chapter will discuss how federated learning can enable the development of an open health ecosystem with the support of AI. Existing challenges and solutions for federated learning will be discussed.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Using AI techniques to enhance or assist healthcare applications has the potential to improve healthcare efficiency, increase healthcare service outcomes, and benefit human well-being. The recent development of data-driven machine learning and deep learning has demonstrated success in many industry sectors, including healthcare <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib52" title="" class="ltx_ref">reviewShickel2017 </a>; <a href="#bib.bib58" title="" class="ltx_ref">reviewXiao2018 </a></cite>. However, training a deep learning model usually requires a large number of training samples, which is not always possible with individual health datasets.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Personal health information is considered to be highly sensitive data, as it contains not only diagnostic and healthcare related information but also identifiable details about individuals. From the consumer perspective, data privacy is also one of the publicâ€™s critical concerns and data breaches can result in reduced public trust of their data. For these reasons, healthcare data are governed by strict laws and regulations to prevent the risk of re-identification and data breaches.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Key examples of standards that protect certain health information include the Health Insurance Portability and Accountability Act of 1996 (HIPAA) and the General Data Projection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib13" title="" class="ltx_ref">gdpr2016eu </a></cite>. While these standards are necessary for security and privacy purposes, they can make it challenging to share and link healthcare information. This includes sharing information between medical centres, hospitals and governments. As a consequence, valuable data are often confined to individual institutions and are unable to be leveraged for analysis, hindering the application of deep learning in the healthcare context. In order to leverage the value of existing health datasets meanwhile maintaining protection of user privacy, a new deep learning technique is desired for sensitive data especially in the health field.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To this end, federated learning (FL) is proposed as a new machine learning paradigm that can learn a global machine learning model without direct access to each contributorâ€™s private data, which can include hospital, device or user data. It aims to build a collaborative training framework where each participant can train a model independently using their data and then collaboratively share this modelâ€™s information without releasing the data used to train the model. An optimisation framework still guides the overall learning procedure, and the private data doesnâ€™t need to be centrally collected or shared. The shared information includes the model parameters and gradients. This allows machine learning algorithms to learn from a broad range of datasets which exist at different locations, by essentially â€˜de-centralisingâ€™ the machine learning process. These features of FL make it uniquely suited for sensitive data, such as healthcare data, where models can be developed without directly sharing data.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Intuitively, the setting of FL is highly compatible with a recently popular concept in the industry â€“ Open Innovation. It is defined as â€œa distributed innovation process based on purposely managed knowledge flow across organisational boundariesâ€ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">chesbrough2014new </a></cite>. While previous approaches to innovation were primarily developed internally by businesses, there is now recognition that an openness to innovation can be valuable, as external involvement brings new knowledge, expertise and ideas <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib62" title="" class="ltx_ref">Yeung2021 </a></cite>. Some industry sectors (such as open banking) have already taken action to embrace open innovation. However, further work is needed to enable open innovation for the health industry sector <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">Kelly2017innovation </a></cite>. The recent development of digital health indicates that the future of healthcare is to provide integrated information support across multiple service providers. However, how to collaboratively use health data in a privacy-preserving way is a critical challenge. FL offers a solution to this challenge by training models without direct access to individual participantâ€™s data.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The remainder of this chapter is organised as follows: Firstly, we will discuss an FL system for open health including the ways the system could be implemented and the principal stakeholders involved. Then, we will describe the key existing challenges in healthcare in relation to data security, privacy and heterogeneity, and provide examples of how FL is addressing these issues. Finally, we will discuss the implications of solving these key health challenges and the benefits this will offer the healthcare industry.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>A Federated Learning System for Open Health</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Open health, which describes an open innovation framework in the healthcare industry, is focused on driving innovation and capability in health through collaborative partnerships between healthcare organisations and researchers. In this framework, there is recognition that good ideas can come from both within and outside an organisation to successfully advance processes and outcomes <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">Dandonoli2013 </a></cite>.There are various forms of open innovation, including crowd-sourcing, organisational partnerships and strategic joint projects <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">Dandonoli2013 </a></cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Currently healthcare systems around the world are under pressure to improve patient health outcomes while operating within constrained healthcare budgets. There are a number of factors that are threatening healthcare system sustainability including aging populations, increased chronic disease incidence, new medical treatments and technologies, and limited use of data <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib6" title="" class="ltx_ref">Braithwaite2019 </a></cite>. It is therefore essential to explore avenues, such as FL, that have potential to benefit patient outcomes and the healthcare system.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">A lack of data sharing has been identified as one of the barriers to innovation in healthcare <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">Kelly2017innovation </a></cite>. This is stalling potential progress on patient care delivery, patient outcomes and health data research <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">Kelly2017innovation </a></cite>. Often the data required for training machine learning and deep learning algorithms are not large enough in individual institutions <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib49" title="" class="ltx_ref">Sheller2020fedlearnmed </a></cite>. Additionally, individual institutions can have data with biases that result in models that do not generalise well and perform poorly when applied to other unseen datasets <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib49" title="" class="ltx_ref">Sheller2020fedlearnmed </a></cite>. One way to obtain sufficiently large and diverse datasets is resorting to collaboratively learning and developing models that utilise data from various healthcare institutions.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Given the importance of data security and privacy in the healthcare sector, FL offers a way of maintaining patient privacy while also facilitating open health. This is because it encourages collaborative relationships for health research that was previously not possible, thereby driving innovation and improvements in healthcare. Below we expand on this idea by providing an overview of the ways in which FL can be constructed for open health and the key stakeholders that stand to benefit from an FL system.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Types of federated learning systems</h3>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2108.10761/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="243" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Workflow comparison between federated learning and traditional machine learning , as found in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">rieke2020future </a></cite>. </span></figcaption>
</figure>
<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">An FL system can be categorised into two groups: cross-silo and cross-device (as discussed in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib44" title="" class="ltx_ref">reddi2020adaptive </a></cite>). The next-generation intelligent healthcare applications will tackle both cross-device and cross-silo scenarios.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The vanilla federated learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib41" title="" class="ltx_ref">mcmahan2017communication </a>; <a href="#bib.bib26" title="" class="ltx_ref">konevcny2016federated </a></cite> proposed by Google aims to solve the large-scale machine learning problem in mobile networks and can be categorised as cross-device. It is designed to learn a model across mobile phones without direct access to userâ€™s data. In this case, each mobile phone represents one device or one user that has a limited amount of training data and computational resources.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">The cross-silo FL is designed for knowledge sharing from data across companies, institutions or organisations. Take an industry sector, e.g., banking or healthcare, where different banks or hospitals have data only for their own customers. Due to privacy requirements and laws, hospitals cannot link their data to the data of other hospitals. With cross-silo FL, a shared model can be trained without direct access to each hospitalâ€™s data.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">In the digital health area, hospitals, clinics, wearable device providers, government agencies, and individual users record various data in different formats. The survey of federated learning (by Yang et al., <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib61" title="" class="ltx_ref">yang2019federated </a></cite>) aims to solve the cross-silo data sharing problem across different organisations. Devices usually have very limited computing power and training data, and their communication is often limited and unstable. The cross-silo FL has powerful servers in each participant and has a centralised dataset. However, they require much higher data protection criteria, and there are some existing external factors that can impact data sharing, such as competitions and cybersecurity concerns. This demonstrates more work is needed to fully enable cross-silo FL.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Key stakeholders</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In the healthcare industry, data can be stored by different government organisations, hospitals, and clinics. Each of these organisations or institutions can be involved in an FL system and stand to benefit in various ways. We discuss the general benefits of FL for healthcare in the discussion section. Below we outline the key stakeholders who are likely to be involved and their role in the FL system.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Third-party platforms.</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.1" class="ltx_p">A company can provide a platform to enable different health industry participants to join the platform, and this platform is implemented based on FL. Moreover, the existing hospital/clinical management system provider will easily be able to take advantage of this future trend. Compared to larger companies that can suffer from long decision-making processes and experience difficulties to transition to new directions, a start-up company is more flexible, and can move quickly to provide additional functionality and improve processes.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Governments.</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.1" class="ltx_p">Governments can transition existing governance towards an FL-based framework. In this framework, governments still maintain storage of the data, however, now they can offer other governments and researchers to join in a collaboration so that important research can be undertaken without compromising individualâ€™s private information. Governments could also play a role in facilitating and overseeing collaborations between other parties to enable information sharing while maintaining appropriate security and privacy standards.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Medical institutions.</h4>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.1" class="ltx_p">The hospitals and clinics may jointly act together to conduct a data-sharing collaboration supported by an FL technique. Through this kind of linked collaboration, the hospitals and clinics can control the scope of data sharing to the trusted peers. The medical doctors and practitioners in the collaboration are more likely to get better support from data and computing resources to advance their medical research and improve patient care.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Wearable service providers.</h4>

<div id="S2.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px4.p1.1" class="ltx_p">The wearable service provider, such as Apple watch, can easily collect the clientâ€™s health-related information. Sometimes, the program in the mobile phone can record the userâ€™s internet behaviour combined with the GPS trajectory. These information can also provide a very good indicator to userâ€™s health status. There is immense potential to build better predictive models based on learning from diverse data from wearable devices.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Security and Privacy Challenge for Federated Learning</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we elaborate on the security and privacy problems in FL systems.
FL, intrinsically with a privacy-preserving attribute, plays a significant role in various industry domains that involve sensitive personal data.
In an open healthcare scenario for example, each hospital or medical research center holds sensitive diagnostic data and strictly cannot share this with others, but desire to learn from data across affiliations.
Although the concept is to provide a privacy-preservation capability by allowing the clients to keep the data on local devices, there are still model security and data leakage risks that would hurt both the security of FL system and the data privacy of clients.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The risks can be regarded as vulnerabilities or weaknesses from multiple aspects associated with the general FL framework. Thus, we provide a list of common vulnerabilities <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref">mothukuri2021federated </a></cite> for comprehensive insights.</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Client Data Manipulations</span>: The local device or client is not always verified by the FL system, so a compromised device/client may learn on malicious data intentionally or unintentionally, and upload incorrect parameters to the global server.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Communication Protocol</span>: Although the data on a device will not be uploaded, there are still network communications between the client and the center to (1) download global parameters in the centre server to the local device/client and (2) upload the parameters (or the corresponding gradient updates) from the local device/client to the center. This poses a risk of â€™eavesdroppingâ€™ for further attacks.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Weaker Aggregation Algorithm</span>: An aggregation algorithm, deployed in the central server, is developed to integrate the updates sampled from local devices into the global model. It is equipped with capabilities to identify abnormal client updates and to drop updates from suspicious clients. However, a weak algorithm, such as FedAvg <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref">mcmahan2017fedavg </a></cite>, does not provide such a configuration to check and drop abnormal updates, making the system more vulnerable to data manipulations in client devices.</p>
</div>
</li>
</ul>
<p id="S3.p2.2" class="ltx_p">These risks lead to both security and privacy problems, which are detailed in the following.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Security Problem.</h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">This is primarily caused by curious or malicious attackers targeting vulnerabilities of the FL system, which can lead to significant performance drop and even model invalidation. This is extremely hazardous and will negatively affect thousands of devices.
If we once again consider this in the health scenario, an attacker can directly manipulate the data in a local affiliation, resulting in wrongly-labelled data to maliciously update the global model.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Privacy Problem.</h4>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">This problem is even more severe than the security problem when vulnerabilities cause user data leakage, as it weakens the basics of FL that are specifically designed for privacy-preservation across multi-device machine learning. For instance, if the communication data packages between the central server and a local device (i.e., global model and local gradient updates) are intercepted, gradient-based reconstruction attack algorithms can be applied to recover the training data in the local device. In healthcare applications, the leakage data could be patientâ€™s personal or healthcare information, which presents a severe ethical problem that deserves our attention.</p>
</div>
<div id="S3.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p2.1" class="ltx_p">Therefore, it is advised that we must correctly identify the vulnerabilities of an FL system, and resist unauthorised access to curious or malicious attackers. This will help develop a more secure system by implementing prerequisites for defending loopholes. This is a mandatory step for an FL engineer to check for all possible vulnerabilities and enhance defenses for security and privacy.</p>
</div>
<div id="S3.SS0.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p3.1" class="ltx_p">In the remainder of this section, we detail two kinds of attacks, i.e., backdoor and gradient attacks, and their potential solutions. These two attacks are the most common attacks leading to security and privacy problems.</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Backdoor attack and solutions</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Under most FL settings, it is assumed that there is no central server that verifies the training data of local devices, which exposes FL to adversarial attacks during decentralized model training <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref">kairouz2019advances </a>; <a href="#bib.bib5" title="" class="ltx_ref">blanchard2017adversaries </a>; <a href="#bib.bib4" title="" class="ltx_ref">baruch2019circumventing </a></cite>.
The goal of a training-time adversarial attack is to degrade the global model stored in the central center for a poor or even random performance.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2108.10761/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="88" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Examples of backdoor attack, which are copied from <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref">wang2020attack </a></cite>.
(a) Airplanes labeled as â€œtruckâ€ in CIFAR10 dataset.
(b) Handwritten characters â€œ7â€ labeled as â€œ1â€ in MNIST dataset.
(c) People in traditional Cretan costumes labeled incorrectly in ImageNet dataset.
(d) Positive tweets on director Yorgos Lanthimos (YL) labeled as â€œnegativeâ€ on sentiment analysis task.
(e) Sentences regarding the city of Athens completed with words of negative connotation on language modeling task.
</span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">As firstly proposed by <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib3" title="" class="ltx_ref">bagdasaryan2020backdoor </a></cite>, a new attack paradigm is to insert â€œbackdoorsâ€ in the training phase of FL.
The goal is to corrupt the global FL model into a targeted mis-prediction on a specific sub-task, e.g., by forcing an image classifier to misclassify green cars as frogs.
This can be performed by gradually replacing the global model with a malicious model from the attacker.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Usually, a backdoor attack occurs by data poisoning or model poisoning in a compromised malicious, or curious client, where the poisoning is more directional in the backdoor attack to force the global model to misclassify on a specific sub-task. Two types of poisoning include black-box and write-box attacks, and we merely focus on black-box attacks, i.e., data poisoning, since its conditions and configurations are readily satisfied.
Furthermore, even entire model replacement is possible, with two prerequisites that (1) the FL system (i.e., the global system) is about to converge and (2) the adversary has adequate knowledge about the whole system (e.g., number of users and scale of data).</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">More recently, edge-case backdoors <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref">wang2020attack </a></cite>, are presented as strong adversarial attack schemes that are hard to detect and avoid.
Specifically, an edge-case backdoor forces the global model to misclassify on seemingly easy examples that are however unlikely to be part of the training, or test data, i.e., located on the tail of the data distribution. And edge-case backdoor would only attack some unusual inference scenarios and only affect small user groups.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.7" class="ltx_p">Below, we introduce three ways, from naive to sophisticated, to conduct backdoor attacks via manipulating training data in a local device (indexed by <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mi id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">i</annotation></semantics></math>). First of all, we assume we have a training set <math id="S3.SS1.p5.2.m2.1" class="ltx_Math" alttext="\mathcal{D}=\mathcal{D}_{t}\cup\mathcal{D}_{f}" display="inline"><semantics id="S3.SS1.p5.2.m2.1a"><mrow id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.2.m2.1.1.2" xref="S3.SS1.p5.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mo id="S3.SS1.p5.2.m2.1.1.1" xref="S3.SS1.p5.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS1.p5.2.m2.1.1.3" xref="S3.SS1.p5.2.m2.1.1.3.cmml"><msub id="S3.SS1.p5.2.m2.1.1.3.2" xref="S3.SS1.p5.2.m2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.2.m2.1.1.3.2.2" xref="S3.SS1.p5.2.m2.1.1.3.2.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p5.2.m2.1.1.3.2.3" xref="S3.SS1.p5.2.m2.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.SS1.p5.2.m2.1.1.3.1" xref="S3.SS1.p5.2.m2.1.1.3.1.cmml">âˆª</mo><msub id="S3.SS1.p5.2.m2.1.1.3.3" xref="S3.SS1.p5.2.m2.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.2.m2.1.1.3.3.2" xref="S3.SS1.p5.2.m2.1.1.3.3.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p5.2.m2.1.1.3.3.3" xref="S3.SS1.p5.2.m2.1.1.3.3.3.cmml">f</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><apply id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1"><eq id="S3.SS1.p5.2.m2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1.1"></eq><ci id="S3.SS1.p5.2.m2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2">ğ’Ÿ</ci><apply id="S3.SS1.p5.2.m2.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3"><union id="S3.SS1.p5.2.m2.1.1.3.1.cmml" xref="S3.SS1.p5.2.m2.1.1.3.1"></union><apply id="S3.SS1.p5.2.m2.1.1.3.2.cmml" xref="S3.SS1.p5.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.3.2.1.cmml" xref="S3.SS1.p5.2.m2.1.1.3.2">subscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.3.2.2.cmml" xref="S3.SS1.p5.2.m2.1.1.3.2.2">ğ’Ÿ</ci><ci id="S3.SS1.p5.2.m2.1.1.3.2.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p5.2.m2.1.1.3.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p5.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p5.2.m2.1.1.3.3.2">ğ’Ÿ</ci><ci id="S3.SS1.p5.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3.3.3">ğ‘“</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">\mathcal{D}=\mathcal{D}_{t}\cup\mathcal{D}_{f}</annotation></semantics></math> where <math id="S3.SS1.p5.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{t}" display="inline"><semantics id="S3.SS1.p5.3.m3.1a"><msub id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">\mathcal{D}_{t}</annotation></semantics></math> denotes correctly-labelled set and <math id="S3.SS1.p5.4.m4.1" class="ltx_Math" alttext="\mathcal{D}_{f}" display="inline"><semantics id="S3.SS1.p5.4.m4.1a"><msub id="S3.SS1.p5.4.m4.1.1" xref="S3.SS1.p5.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.4.m4.1.1.2" xref="S3.SS1.p5.4.m4.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p5.4.m4.1.1.3" xref="S3.SS1.p5.4.m4.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m4.1b"><apply id="S3.SS1.p5.4.m4.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m4.1.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p5.4.m4.1.1.2.cmml" xref="S3.SS1.p5.4.m4.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.p5.4.m4.1.1.3.cmml" xref="S3.SS1.p5.4.m4.1.1.3">ğ‘“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m4.1c">\mathcal{D}_{f}</annotation></semantics></math> denotes label-manipulated set. And after local gradient updates on <math id="S3.SS1.p5.5.m5.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS1.p5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.5.m5.1.1" xref="S3.SS1.p5.5.m5.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.5.m5.1b"><ci id="S3.SS1.p5.5.m5.1.1.cmml" xref="S3.SS1.p5.5.m5.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m5.1c">\mathcal{D}</annotation></semantics></math>, we obtain new model parameters denoted as <math id="S3.SS1.p5.6.m6.1" class="ltx_Math" alttext="\mathbb{w}_{i}" display="inline"><semantics id="S3.SS1.p5.6.m6.1a"><msub id="S3.SS1.p5.6.m6.1.1" xref="S3.SS1.p5.6.m6.1.1.cmml"><mi id="S3.SS1.p5.6.m6.1.1.2" xref="S3.SS1.p5.6.m6.1.1.2.cmml">ğ•¨</mi><mi id="S3.SS1.p5.6.m6.1.1.3" xref="S3.SS1.p5.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.6.m6.1b"><apply id="S3.SS1.p5.6.m6.1.1.cmml" xref="S3.SS1.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m6.1.1.1.cmml" xref="S3.SS1.p5.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p5.6.m6.1.1.2.cmml" xref="S3.SS1.p5.6.m6.1.1.2">ğ•¨</ci><ci id="S3.SS1.p5.6.m6.1.1.3.cmml" xref="S3.SS1.p5.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.6.m6.1c">\mathbb{w}_{i}</annotation></semantics></math> compared to the original parameters <math id="S3.SS1.p5.7.m7.1" class="ltx_Math" alttext="\mathbb{w}" display="inline"><semantics id="S3.SS1.p5.7.m7.1a"><mi id="S3.SS1.p5.7.m7.1.1" xref="S3.SS1.p5.7.m7.1.1.cmml">ğ•¨</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.7.m7.1b"><ci id="S3.SS1.p5.7.m7.1.1.cmml" xref="S3.SS1.p5.7.m7.1.1">ğ•¨</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.7.m7.1c">\mathbb{w}</annotation></semantics></math> in the central server.</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">Black-box attack</span>: As the most straightforward attack approach, the client performs normal weight updates (e.g., SGD) and upload <math id="S3.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathbb{w}_{i}" display="inline"><semantics id="S3.I2.i1.p1.1.m1.1a"><msub id="S3.I2.i1.p1.1.m1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.cmml"><mi id="S3.I2.i1.p1.1.m1.1.1.2" xref="S3.I2.i1.p1.1.m1.1.1.2.cmml">ğ•¨</mi><mi id="S3.I2.i1.p1.1.m1.1.1.3" xref="S3.I2.i1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><apply id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.1.m1.1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.1.m1.1.1.2.cmml" xref="S3.I2.i1.p1.1.m1.1.1.2">ğ•¨</ci><ci id="S3.I2.i1.p1.1.m1.1.1.3.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">\mathbb{w}_{i}</annotation></semantics></math> to the central server. This, however, can be easily detected by advanced aggregation algorithms implemented in the central server and be discarded consequently, so such an attack is not always effective.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.7" class="ltx_p"><span id="S3.I2.i2.p1.7.1" class="ltx_text ltx_font_italic">Projected gradient descent (PGD) attack</span>: As the weight updates in the client are derived from applying SGD to the manipulated training set in local client, the updates <math id="S3.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="\mathbb{w}_{i}" display="inline"><semantics id="S3.I2.i2.p1.1.m1.1a"><msub id="S3.I2.i2.p1.1.m1.1.1" xref="S3.I2.i2.p1.1.m1.1.1.cmml"><mi id="S3.I2.i2.p1.1.m1.1.1.2" xref="S3.I2.i2.p1.1.m1.1.1.2.cmml">ğ•¨</mi><mi id="S3.I2.i2.p1.1.m1.1.1.3" xref="S3.I2.i2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.1b"><apply id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.1.m1.1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.1.m1.1.1.2.cmml" xref="S3.I2.i2.p1.1.m1.1.1.2">ğ•¨</ci><ci id="S3.I2.i2.p1.1.m1.1.1.3.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.1c">\mathbb{w}_{i}</annotation></semantics></math> would be significant and far from the original parameters <math id="S3.I2.i2.p1.2.m2.1" class="ltx_Math" alttext="\mathbb{w}" display="inline"><semantics id="S3.I2.i2.p1.2.m2.1a"><mi id="S3.I2.i2.p1.2.m2.1.1" xref="S3.I2.i2.p1.2.m2.1.1.cmml">ğ•¨</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.2.m2.1b"><ci id="S3.I2.i2.p1.2.m2.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1">ğ•¨</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.2.m2.1c">\mathbb{w}</annotation></semantics></math>. This is a key reason why the abnormality can be easily detected, especially when the global model is close to convergence. Therefore, a popular adversary strategy is to apply normalisation to <math id="S3.I2.i2.p1.3.m3.1" class="ltx_Math" alttext="\mathbb{w}_{i}" display="inline"><semantics id="S3.I2.i2.p1.3.m3.1a"><msub id="S3.I2.i2.p1.3.m3.1.1" xref="S3.I2.i2.p1.3.m3.1.1.cmml"><mi id="S3.I2.i2.p1.3.m3.1.1.2" xref="S3.I2.i2.p1.3.m3.1.1.2.cmml">ğ•¨</mi><mi id="S3.I2.i2.p1.3.m3.1.1.3" xref="S3.I2.i2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.3.m3.1b"><apply id="S3.I2.i2.p1.3.m3.1.1.cmml" xref="S3.I2.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.3.m3.1.1.1.cmml" xref="S3.I2.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.3.m3.1.1.2.cmml" xref="S3.I2.i2.p1.3.m3.1.1.2">ğ•¨</ci><ci id="S3.I2.i2.p1.3.m3.1.1.3.cmml" xref="S3.I2.i2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.3.m3.1c">\mathbb{w}_{i}</annotation></semantics></math> so that <math id="S3.I2.i2.p1.4.m4.1" class="ltx_Math" alttext="\mathbb{w}_{i}" display="inline"><semantics id="S3.I2.i2.p1.4.m4.1a"><msub id="S3.I2.i2.p1.4.m4.1.1" xref="S3.I2.i2.p1.4.m4.1.1.cmml"><mi id="S3.I2.i2.p1.4.m4.1.1.2" xref="S3.I2.i2.p1.4.m4.1.1.2.cmml">ğ•¨</mi><mi id="S3.I2.i2.p1.4.m4.1.1.3" xref="S3.I2.i2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.4.m4.1b"><apply id="S3.I2.i2.p1.4.m4.1.1.cmml" xref="S3.I2.i2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.4.m4.1.1.1.cmml" xref="S3.I2.i2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.4.m4.1.1.2.cmml" xref="S3.I2.i2.p1.4.m4.1.1.2">ğ•¨</ci><ci id="S3.I2.i2.p1.4.m4.1.1.3.cmml" xref="S3.I2.i2.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.4.m4.1c">\mathbb{w}_{i}</annotation></semantics></math> is spatially close to <math id="S3.I2.i2.p1.5.m5.1" class="ltx_Math" alttext="\mathbb{w}" display="inline"><semantics id="S3.I2.i2.p1.5.m5.1a"><mi id="S3.I2.i2.p1.5.m5.1.1" xref="S3.I2.i2.p1.5.m5.1.1.cmml">ğ•¨</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.5.m5.1b"><ci id="S3.I2.i2.p1.5.m5.1.1.cmml" xref="S3.I2.i2.p1.5.m5.1.1">ğ•¨</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.5.m5.1c">\mathbb{w}</annotation></semantics></math>, i.e., <math id="S3.I2.i2.p1.6.m6.1" class="ltx_Math" alttext="||\mathbb{w}_{i}-\mathbb{w}||&lt;\delta" display="inline"><semantics id="S3.I2.i2.p1.6.m6.1a"><mrow id="S3.I2.i2.p1.6.m6.1.1" xref="S3.I2.i2.p1.6.m6.1.1.cmml"><mrow id="S3.I2.i2.p1.6.m6.1.1.1.1" xref="S3.I2.i2.p1.6.m6.1.1.1.2.cmml"><mo stretchy="false" id="S3.I2.i2.p1.6.m6.1.1.1.1.2" xref="S3.I2.i2.p1.6.m6.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.I2.i2.p1.6.m6.1.1.1.1.1" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.cmml"><msub id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.cmml"><mi id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.2" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.2.cmml">ğ•¨</mi><mi id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.3" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.I2.i2.p1.6.m6.1.1.1.1.1.1" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.I2.i2.p1.6.m6.1.1.1.1.1.3" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.3.cmml">ğ•¨</mi></mrow><mo stretchy="false" id="S3.I2.i2.p1.6.m6.1.1.1.1.3" xref="S3.I2.i2.p1.6.m6.1.1.1.2.1.cmml">â€–</mo></mrow><mo id="S3.I2.i2.p1.6.m6.1.1.2" xref="S3.I2.i2.p1.6.m6.1.1.2.cmml">&lt;</mo><mi id="S3.I2.i2.p1.6.m6.1.1.3" xref="S3.I2.i2.p1.6.m6.1.1.3.cmml">Î´</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.6.m6.1b"><apply id="S3.I2.i2.p1.6.m6.1.1.cmml" xref="S3.I2.i2.p1.6.m6.1.1"><lt id="S3.I2.i2.p1.6.m6.1.1.2.cmml" xref="S3.I2.i2.p1.6.m6.1.1.2"></lt><apply id="S3.I2.i2.p1.6.m6.1.1.1.2.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1"><csymbol cd="latexml" id="S3.I2.i2.p1.6.m6.1.1.1.2.1.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.2">norm</csymbol><apply id="S3.I2.i2.p1.6.m6.1.1.1.1.1.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1"><minus id="S3.I2.i2.p1.6.m6.1.1.1.1.1.1.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.1"></minus><apply id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.1.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2">subscript</csymbol><ci id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.2.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.2">ğ•¨</ci><ci id="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.3.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.I2.i2.p1.6.m6.1.1.1.1.1.3.cmml" xref="S3.I2.i2.p1.6.m6.1.1.1.1.1.3">ğ•¨</ci></apply></apply><ci id="S3.I2.i2.p1.6.m6.1.1.3.cmml" xref="S3.I2.i2.p1.6.m6.1.1.3">ğ›¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.6.m6.1c">||\mathbb{w}_{i}-\mathbb{w}||&lt;\delta</annotation></semantics></math> where <math id="S3.I2.i2.p1.7.m7.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S3.I2.i2.p1.7.m7.1a"><mi id="S3.I2.i2.p1.7.m7.1.1" xref="S3.I2.i2.p1.7.m7.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.7.m7.1b"><ci id="S3.I2.i2.p1.7.m7.1.1.cmml" xref="S3.I2.i2.p1.7.m7.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.7.m7.1c">\delta</annotation></semantics></math> is small enough.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.7" class="ltx_p"><span id="S3.I2.i3.p1.7.1" class="ltx_text ltx_font_italic">PGD attack with model replacement</span>: This attack scheme takes a step further, and attempts to replace the global model with a manipulated one to hit the final goal of backdoor. Again, an important prerequisite is that the global model is close to convergence so the updates from other clients are almost the same as <math id="S3.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="\mathbb{w}" display="inline"><semantics id="S3.I2.i3.p1.1.m1.1a"><mi id="S3.I2.i3.p1.1.m1.1.1" xref="S3.I2.i3.p1.1.m1.1.1.cmml">ğ•¨</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><ci id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">ğ•¨</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">\mathbb{w}</annotation></semantics></math>. Hence, extended from PGD attack, the weight updates can be further defined as <math id="S3.I2.i3.p1.2.m2.1" class="ltx_Math" alttext="\mathbb{w}_{i}\leftarrow{n_{S}}/{n_{i}}(\mathbb{w}_{i}-\mathbb{w})+\mathbb{w}" display="inline"><semantics id="S3.I2.i3.p1.2.m2.1a"><mrow id="S3.I2.i3.p1.2.m2.1.1" xref="S3.I2.i3.p1.2.m2.1.1.cmml"><msub id="S3.I2.i3.p1.2.m2.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.3.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.3.2" xref="S3.I2.i3.p1.2.m2.1.1.3.2.cmml">ğ•¨</mi><mi id="S3.I2.i3.p1.2.m2.1.1.3.3" xref="S3.I2.i3.p1.2.m2.1.1.3.3.cmml">i</mi></msub><mo stretchy="false" id="S3.I2.i3.p1.2.m2.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.2.cmml">â†</mo><mrow id="S3.I2.i3.p1.2.m2.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.cmml"><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.cmml"><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.cmml"><msub id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.2.cmml">n</mi><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.3.cmml">S</mi></msub><mo id="S3.I2.i3.p1.2.m2.1.1.1.1.3.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.1.cmml">/</mo><msub id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.2.cmml">n</mi><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.I2.i3.p1.2.m2.1.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml"><msub id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.2.cmml">ğ•¨</mi><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.3.cmml">ğ•¨</mi></mrow><mo stretchy="false" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.I2.i3.p1.2.m2.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.2.cmml">+</mo><mi id="S3.I2.i3.p1.2.m2.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.3.cmml">ğ•¨</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.2.m2.1b"><apply id="S3.I2.i3.p1.2.m2.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1"><ci id="S3.I2.i3.p1.2.m2.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.2">â†</ci><apply id="S3.I2.i3.p1.2.m2.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.2">ğ•¨</ci><ci id="S3.I2.i3.p1.2.m2.1.1.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.3">ğ‘–</ci></apply><apply id="S3.I2.i3.p1.2.m2.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1"><plus id="S3.I2.i3.p1.2.m2.1.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.2"></plus><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1"><times id="S3.I2.i3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.2"></times><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3"><divide id="S3.I2.i3.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.1"></divide><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.2">ğ‘›</ci><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.2.3">ğ‘†</ci></apply><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.2">ğ‘›</ci><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.3.3.3">ğ‘–</ci></apply></apply><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1"><minus id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.1"></minus><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.2">ğ•¨</ci><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.3">ğ•¨</ci></apply></apply><ci id="S3.I2.i3.p1.2.m2.1.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.3">ğ•¨</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.2.m2.1c">\mathbb{w}_{i}\leftarrow{n_{S}}/{n_{i}}(\mathbb{w}_{i}-\mathbb{w})+\mathbb{w}</annotation></semantics></math>, where <math id="S3.I2.i3.p1.3.m3.1" class="ltx_Math" alttext="{n_{S}}/{n_{i}}" display="inline"><semantics id="S3.I2.i3.p1.3.m3.1a"><mrow id="S3.I2.i3.p1.3.m3.1.1" xref="S3.I2.i3.p1.3.m3.1.1.cmml"><msub id="S3.I2.i3.p1.3.m3.1.1.2" xref="S3.I2.i3.p1.3.m3.1.1.2.cmml"><mi id="S3.I2.i3.p1.3.m3.1.1.2.2" xref="S3.I2.i3.p1.3.m3.1.1.2.2.cmml">n</mi><mi id="S3.I2.i3.p1.3.m3.1.1.2.3" xref="S3.I2.i3.p1.3.m3.1.1.2.3.cmml">S</mi></msub><mo id="S3.I2.i3.p1.3.m3.1.1.1" xref="S3.I2.i3.p1.3.m3.1.1.1.cmml">/</mo><msub id="S3.I2.i3.p1.3.m3.1.1.3" xref="S3.I2.i3.p1.3.m3.1.1.3.cmml"><mi id="S3.I2.i3.p1.3.m3.1.1.3.2" xref="S3.I2.i3.p1.3.m3.1.1.3.2.cmml">n</mi><mi id="S3.I2.i3.p1.3.m3.1.1.3.3" xref="S3.I2.i3.p1.3.m3.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.3.m3.1b"><apply id="S3.I2.i3.p1.3.m3.1.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1"><divide id="S3.I2.i3.p1.3.m3.1.1.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1.1"></divide><apply id="S3.I2.i3.p1.3.m3.1.1.2.cmml" xref="S3.I2.i3.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.I2.i3.p1.3.m3.1.1.2.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.I2.i3.p1.3.m3.1.1.2.2.cmml" xref="S3.I2.i3.p1.3.m3.1.1.2.2">ğ‘›</ci><ci id="S3.I2.i3.p1.3.m3.1.1.2.3.cmml" xref="S3.I2.i3.p1.3.m3.1.1.2.3">ğ‘†</ci></apply><apply id="S3.I2.i3.p1.3.m3.1.1.3.cmml" xref="S3.I2.i3.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.3.m3.1.1.3.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1.3">subscript</csymbol><ci id="S3.I2.i3.p1.3.m3.1.1.3.2.cmml" xref="S3.I2.i3.p1.3.m3.1.1.3.2">ğ‘›</ci><ci id="S3.I2.i3.p1.3.m3.1.1.3.3.cmml" xref="S3.I2.i3.p1.3.m3.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.3.m3.1c">{n_{S}}/{n_{i}}</annotation></semantics></math> is to re-scale for attacking central aggregation. Note that <math id="S3.I2.i3.p1.4.m4.1" class="ltx_Math" alttext="n_{S}" display="inline"><semantics id="S3.I2.i3.p1.4.m4.1a"><msub id="S3.I2.i3.p1.4.m4.1.1" xref="S3.I2.i3.p1.4.m4.1.1.cmml"><mi id="S3.I2.i3.p1.4.m4.1.1.2" xref="S3.I2.i3.p1.4.m4.1.1.2.cmml">n</mi><mi id="S3.I2.i3.p1.4.m4.1.1.3" xref="S3.I2.i3.p1.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.4.m4.1b"><apply id="S3.I2.i3.p1.4.m4.1.1.cmml" xref="S3.I2.i3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.I2.i3.p1.4.m4.1.1.1.cmml" xref="S3.I2.i3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.I2.i3.p1.4.m4.1.1.2.cmml" xref="S3.I2.i3.p1.4.m4.1.1.2">ğ‘›</ci><ci id="S3.I2.i3.p1.4.m4.1.1.3.cmml" xref="S3.I2.i3.p1.4.m4.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.4.m4.1c">n_{S}</annotation></semantics></math> denotes the total example number in the federated learning system and <math id="S3.I2.i3.p1.5.m5.1" class="ltx_Math" alttext="n_{i}" display="inline"><semantics id="S3.I2.i3.p1.5.m5.1a"><msub id="S3.I2.i3.p1.5.m5.1.1" xref="S3.I2.i3.p1.5.m5.1.1.cmml"><mi id="S3.I2.i3.p1.5.m5.1.1.2" xref="S3.I2.i3.p1.5.m5.1.1.2.cmml">n</mi><mi id="S3.I2.i3.p1.5.m5.1.1.3" xref="S3.I2.i3.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.5.m5.1b"><apply id="S3.I2.i3.p1.5.m5.1.1.cmml" xref="S3.I2.i3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.I2.i3.p1.5.m5.1.1.1.cmml" xref="S3.I2.i3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.I2.i3.p1.5.m5.1.1.2.cmml" xref="S3.I2.i3.p1.5.m5.1.1.2">ğ‘›</ci><ci id="S3.I2.i3.p1.5.m5.1.1.3.cmml" xref="S3.I2.i3.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.5.m5.1c">n_{i}</annotation></semantics></math> denotes the example number in <math id="S3.I2.i3.p1.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.I2.i3.p1.6.m6.1a"><mi id="S3.I2.i3.p1.6.m6.1.1" xref="S3.I2.i3.p1.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.6.m6.1b"><ci id="S3.I2.i3.p1.6.m6.1.1.cmml" xref="S3.I2.i3.p1.6.m6.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.6.m6.1c">i</annotation></semantics></math>-th device. Hence, the aggregation algorithm in the central server will be attacked and perform <math id="S3.I2.i3.p1.7.m7.1" class="ltx_Math" alttext="\mathbb{w}\leftarrow\mathbb{w}+\sum\nolimits_{j}{n_{j}}/{n_{S}}(\mathbb{w}_{j}-\mathbb{w})=\mathbb{w}_{i}" display="inline"><semantics id="S3.I2.i3.p1.7.m7.1a"><mrow id="S3.I2.i3.p1.7.m7.1.1" xref="S3.I2.i3.p1.7.m7.1.1.cmml"><mi id="S3.I2.i3.p1.7.m7.1.1.3" xref="S3.I2.i3.p1.7.m7.1.1.3.cmml">ğ•¨</mi><mo stretchy="false" id="S3.I2.i3.p1.7.m7.1.1.4" xref="S3.I2.i3.p1.7.m7.1.1.4.cmml">â†</mo><mrow id="S3.I2.i3.p1.7.m7.1.1.1" xref="S3.I2.i3.p1.7.m7.1.1.1.cmml"><mi id="S3.I2.i3.p1.7.m7.1.1.1.3" xref="S3.I2.i3.p1.7.m7.1.1.1.3.cmml">ğ•¨</mi><mo rspace="0.055em" id="S3.I2.i3.p1.7.m7.1.1.1.2" xref="S3.I2.i3.p1.7.m7.1.1.1.2.cmml">+</mo><mrow id="S3.I2.i3.p1.7.m7.1.1.1.1" xref="S3.I2.i3.p1.7.m7.1.1.1.1.cmml"><msub id="S3.I2.i3.p1.7.m7.1.1.1.1.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2.cmml"><mo id="S3.I2.i3.p1.7.m7.1.1.1.1.2.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.2.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2.3.cmml">j</mi></msub><mrow id="S3.I2.i3.p1.7.m7.1.1.1.1.1" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.cmml"><mrow id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.cmml"><msub id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.cmml"><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.2.cmml">n</mi><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.3.cmml">j</mi></msub><mo id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.1" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.1.cmml">/</mo><msub id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.cmml"><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.2.cmml">n</mi><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.3.cmml">S</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.I2.i3.p1.7.m7.1.1.1.1.1.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.cmml"><msub id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.2" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.2.cmml">ğ•¨</mi><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.3.cmml">j</mi></msub><mo id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.1" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.3.cmml">ğ•¨</mi></mrow><mo stretchy="false" id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.3" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.I2.i3.p1.7.m7.1.1.5" xref="S3.I2.i3.p1.7.m7.1.1.5.cmml">=</mo><msub id="S3.I2.i3.p1.7.m7.1.1.6" xref="S3.I2.i3.p1.7.m7.1.1.6.cmml"><mi id="S3.I2.i3.p1.7.m7.1.1.6.2" xref="S3.I2.i3.p1.7.m7.1.1.6.2.cmml">ğ•¨</mi><mi id="S3.I2.i3.p1.7.m7.1.1.6.3" xref="S3.I2.i3.p1.7.m7.1.1.6.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.7.m7.1b"><apply id="S3.I2.i3.p1.7.m7.1.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1"><and id="S3.I2.i3.p1.7.m7.1.1a.cmml" xref="S3.I2.i3.p1.7.m7.1.1"></and><apply id="S3.I2.i3.p1.7.m7.1.1b.cmml" xref="S3.I2.i3.p1.7.m7.1.1"><ci id="S3.I2.i3.p1.7.m7.1.1.4.cmml" xref="S3.I2.i3.p1.7.m7.1.1.4">â†</ci><ci id="S3.I2.i3.p1.7.m7.1.1.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.3">ğ•¨</ci><apply id="S3.I2.i3.p1.7.m7.1.1.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1"><plus id="S3.I2.i3.p1.7.m7.1.1.1.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.2"></plus><ci id="S3.I2.i3.p1.7.m7.1.1.1.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.3">ğ•¨</ci><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1"><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.I2.i3.p1.7.m7.1.1.1.1.2.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2">subscript</csymbol><sum id="S3.I2.i3.p1.7.m7.1.1.1.1.2.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2.2"></sum><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.2.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.2.3">ğ‘—</ci></apply><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1"><times id="S3.I2.i3.p1.7.m7.1.1.1.1.1.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.2"></times><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3"><divide id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.1"></divide><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.2">ğ‘›</ci><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.2.3">ğ‘—</ci></apply><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.2">ğ‘›</ci><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.3.3.3">ğ‘†</ci></apply></apply><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1"><minus id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.2">ğ•¨</ci><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.1.1.1.1.1.1.3">ğ•¨</ci></apply></apply></apply></apply></apply><apply id="S3.I2.i3.p1.7.m7.1.1c.cmml" xref="S3.I2.i3.p1.7.m7.1.1"><eq id="S3.I2.i3.p1.7.m7.1.1.5.cmml" xref="S3.I2.i3.p1.7.m7.1.1.5"></eq><share href="#S3.I2.i3.p1.7.m7.1.1.1.cmml" id="S3.I2.i3.p1.7.m7.1.1d.cmml" xref="S3.I2.i3.p1.7.m7.1.1"></share><apply id="S3.I2.i3.p1.7.m7.1.1.6.cmml" xref="S3.I2.i3.p1.7.m7.1.1.6"><csymbol cd="ambiguous" id="S3.I2.i3.p1.7.m7.1.1.6.1.cmml" xref="S3.I2.i3.p1.7.m7.1.1.6">subscript</csymbol><ci id="S3.I2.i3.p1.7.m7.1.1.6.2.cmml" xref="S3.I2.i3.p1.7.m7.1.1.6.2">ğ•¨</ci><ci id="S3.I2.i3.p1.7.m7.1.1.6.3.cmml" xref="S3.I2.i3.p1.7.m7.1.1.6.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.7.m7.1c">\mathbb{w}\leftarrow\mathbb{w}+\sum\nolimits_{j}{n_{j}}/{n_{S}}(\mathbb{w}_{j}-\mathbb{w})=\mathbb{w}_{i}</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">It is interesting to know how to exclude backdoor attacks or data poisoning, and what is the cost of defenses. Of course, many defense methods have been proposed to resist a backdoor attack, which are detailed below.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Anomaly Detection.</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">This is the most straightforward idea to resist backdoor attacks, and detects abnormal activities and updates from the perspective of the central server. The detection is established by effectively contrasting the updates from thousands of clients with a normal pattern, where the normal pattern can be derived from statistical analysis or expertise. Under the FL framework, backdoor attacks, through either data or model poisoning, will upload abnormal updates (e.g., considerable update step and/or significant deviation from original model), which is well-captured by a sophisticated algorithm, and thus removed from aggregation.
<cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib51" title="" class="ltx_ref">shen2016defending </a></cite> applies a clustering technique to each client update for a defense against malicious client updates.
<cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib5" title="" class="ltx_ref">blanchard2017adversaries </a></cite> utilises Euclidean distance as the Krum model to measure a deviation between the global model and each client model, and then eliminates malicious client updates.
Similarly, <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib29" title="" class="ltx_ref">li2019abnormal </a></cite> discusses how to detect abnormal updates from clients in a federated learning framework.
Furthermore, such defense can also be implemented by auto-encoders or variational auto-encoders, which help to find the malicious client updates <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib14" title="" class="ltx_ref">fang2020local </a>; <a href="#bib.bib30" title="" class="ltx_ref">li2020learning </a></cite>.
And <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib14" title="" class="ltx_ref">fang2020local </a></cite> proposes a loss function-based and error rate-based rejection to resist the negative effects of local model poisoning attacks.</p>
</div>
<div id="S3.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p2.1" class="ltx_p">However, anomaly detection becomes less effective and even useless when edge-case backdoor attacks appear. Specifically, <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref">wang2020attack </a></cite> indicates that edge-case failures can unfortunately be hard-wired through backdoors to federated learning systems. Moreover, directly applying anomaly detection defenses has an adverse effect as the clients with diverse enough data would also be removed. This presents a trade-off between fairness and robustness, which is also mentioned in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref">kairouz2019advances </a></cite> but unexplored in recent works.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data Sanitisation.</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">As a common technique to defend backdoor and poisoning attacks in FL, data sanitisation <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">cretu2008casting </a></cite> is employed in anomaly detection to filter out suspicious training examples.
However, stronger data poisoning attacks are likely to break data sanitisation defenses <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib25" title="" class="ltx_ref">koh2018stronger </a></cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pruning.</h4>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.1" class="ltx_p">Another defense technique against backdoor attacks is â€œpruningâ€. Rather than directly filtering out the data, this technique evaluates if a unit is supposed to be inactive on clean data but activated in the updates <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib35" title="" class="ltx_ref">liu2019lifelong </a></cite>. However, the access to clean holdout data violates the privacy principle of FL, and is therefore the biggest concern of this defense technique.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Gradient attack and solutions</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p">Although FL is designed to train a machine learning model without the access to clientsâ€™ private data, recent research works have revealed that its default setting still suffers from privacy leakage attacks by gradient-based reconstruction <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref">geiping2020inverting </a>; <a href="#bib.bib63" title="" class="ltx_ref">zhao2020iDLG </a>; <a href="#bib.bib64" title="" class="ltx_ref">zhu2019deep </a></cite>.
Gradient attack, also known as client privacy leakage attack, is able to accurately reconstruct the private training data in the local client, given only a local gradient update shared from a client to central server.
So in gradient privacy attack, we assume that clients can be compromised in a limited manner. That is, an attacker cannot directly access the private training data <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{D}</annotation></semantics></math> but only the gradient updates <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\nabla\mathbb{w}_{i}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mo rspace="0.167em" id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">âˆ‡</mo><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">ğ•¨</mi><mi id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><ci id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1">âˆ‡</ci><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">ğ•¨</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\nabla\mathbb{w}_{i}</annotation></semantics></math> calculated by SGD on <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathcal{D}</annotation></semantics></math>.
The gradient update data is intercepted by a malicious attacker via a compromised central server or eavesdropping of insecure network communication.
This not only violates local data privacy but also the federated learning system by monitoring client confidential data illegally and silently, exposing federated learning into privacy leakage attacks.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Client Privacy Leakage Attack.</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.3" class="ltx_p">This attack technique is to conduct a gradient-based feature reconstruction, where the adversary aims at developing a learning-based reconstruction algorithm that takes the gradient update <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\nabla\mathbb{w}_{i}(t)" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.cmml"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.cmml"><mo rspace="0.167em" id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.1.cmml">âˆ‡</mo><msub id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.2.cmml">ğ•¨</mi><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.3.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.3.2.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.cmml">(</mo><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">t</mi><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.3.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2"><times id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.1"></times><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2"><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.1">âˆ‡</ci><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.2">ğ•¨</ci><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.2.2.2.3">ğ‘–</ci></apply></apply><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">\nabla\mathbb{w}_{i}(t)</annotation></semantics></math> at step <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">t</annotation></semantics></math> to reconstruct the private data used to calculate the gradient.
In the following, we mainly focus on the application scenarios of computer vision in federated learning, where the inputs are images or videos. Therefore, the learning-based reconstruction algorithm will begin from a random attack seed that can be a dummy image with the same resolution as that of the local client. Then, we can perform a forward inference given the dummy image and compute a gradient loss by measuring spatial distance between the current gradient w.r.t the model parameters and the actual gradient from the client. Then, we minimize the gradient loss w.r.t the dummy-initialized image to approach actual client private data.
Thereby, the goal of this reconstruction algorithm is to iteratively modify the dummy image and finally approximate the original data in a local device if the gradient loss is converged to be minimal.
In summary, this learning-based reconstruction algorithm fixes the parameters of a neural network model and tries to optimise the dummy-initialized image with regard to the gradient loss. Namely, compared to traditional machine learning, this algorithm takes the model <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathbb{w}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">ğ•¨</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">ğ•¨</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">\mathbb{w}</annotation></semantics></math> as its input but takes the image as its learnable parameters.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2108.10761/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Examples of gradient attack, which are copied from <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref">wei2020gradient </a></cite>. </span></figcaption>
</figure>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">The open question still remains about how to effectively resist gradient-based client privacy leakage attack. The most effective way, of course, is to prevent the attack from its sources, e.g., encrypting network communication and strengthening server firewalls. When intercepting or eavesdropping is inevitable, differential privacy can be leveraged to eliminate privacy leakage.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Differential Privacy.</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">As a widely-applied privacy-preserving technique, differential privacy is proposed to add noise into client privacy data, which thus prevents privacy leakage of personal data <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">dwork2006differential </a></cite>. Meanwhile, this comes with an acceptable cost of statistic data quality loss, which is caused by random noise from each client.
In this gradient-based attack scenario, differential privacy is implemented by adding noise to the gradient updates from the clients of the federated learning system, which thereby makes it more difficult to reconstruct the client data.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.1" class="ltx_p">However, this privacy-preserving technique introduces randomness into the gradient updates, and thus leads to model degeneration. This technique also makes the central server difficult to check the uploaded models from its clients, possibly resulting in conflicts with aforementioned anomaly detection.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p3.1" class="ltx_p">Fortunately, there are also other ways to perform defenses against gradient-based attacks by increasing attack difficulty, which do not compromise performance degeneration to the same extent. As suggested by <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref">wei2020gradient </a></cite>, according to the principles of client privacy leakage attacks, we can lift the attack difficulty by either adding more parameters for an adversary or increasing estimation complexity. Therefore, this can be reached by (1) increasing batch size of mini-batch SGD in the clients, (2) lifting training image or video resolution in local clients, (3) making more steps of gradient updates before uploading to the central server, and (4) changing activation function in the local model.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Data Heterogeneity Challenge for Federated Learning</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Heterogeneity widely exists in healthcare and medical data. It is introduced by not only the variety of modalities, dimensionality and characteristics, but also the data acquisition differences. For example, the medical devices with different brands or local demographics can lead to significantly different source data distributions <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">rieke2020future </a></cite>. FL has addressed this heterogeneous data distribution issue as a critical challenge and a number of FL algorithms are proposed to tackle heterogeneity in federated networks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib61" title="" class="ltx_ref">yang2019federated </a></cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Statistical Heterogeneity</h3>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2108.10761/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="175" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Statistical heterogeneity problem in federated learning.</span></figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Conventional machine learning is always built upon an independently and identically distributed (IID) assumption of a uniform dataset. However, statistical heterogeneity is an inherent characteristic across the distributed medical data providers, which can be identified as a non-IID problem, as is shown in Fig. <a href="#S4.F4" title="Figure 4 â€£ 4.1 Statistical Heterogeneity â€£ 4 Data Heterogeneity Challenge for Federated Learning â€£ Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> . Usually, medical data is not uniformly distributed across different institutions and sometimes can introduce a local bias <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib31" title="" class="ltx_ref">li2019privacy </a>; <a href="#bib.bib50" title="" class="ltx_ref">sheller2018multi </a></cite>. Recently, some methods have been proposed to handle the statistical heterogeneity in the FL setting. These methods can be applied to most open health scenarios to enhance the robustness of existing distributed machine learning methods and tolerate heterogeneity across data providers. There are two main types of solutions for this, one is to cluster or group the data providers, and each cluster/group will have a unique global model, the other is by personalisation techniques where each medical data provider has both the shared part and the personalised part of model <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib37" title="" class="ltx_ref">long2020federated </a></cite>.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Clustered FL.</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">According to the input data distribution, models with the same or similar data distribution can be clustered into the same cluster. Weight aggregation can be done inside the cluster. Below are the related methods for clustered federated learning.</p>
</div>
<div id="S4.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib59" title="" class="ltx_ref">xie2020multi </a></cite>, the authors propose a novel multi-center aggregation mechanism for heterogeneous federated learning which is common in various real-world applications. Multiple global models are learned from the non-IID data by optimising the predefined objective function, namely multi-center federated loss. In particular, the loss function of the proposed framework is defined as</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.2" class="ltx_Math" alttext="\sum_{i=1}^{n}p_{i}\cdot\min_{k}\left\|W_{i}-W^{(k)}\right\|^{2}," display="block"><semantics id="S4.E1.m1.2a"><mrow id="S4.E1.m1.2.2.1" xref="S4.E1.m1.2.2.1.1.cmml"><mrow id="S4.E1.m1.2.2.1.1" xref="S4.E1.m1.2.2.1.1.cmml"><munderover id="S4.E1.m1.2.2.1.1.2" xref="S4.E1.m1.2.2.1.1.2.cmml"><mo movablelimits="false" id="S4.E1.m1.2.2.1.1.2.2.2" xref="S4.E1.m1.2.2.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E1.m1.2.2.1.1.2.2.3" xref="S4.E1.m1.2.2.1.1.2.2.3.cmml"><mi id="S4.E1.m1.2.2.1.1.2.2.3.2" xref="S4.E1.m1.2.2.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E1.m1.2.2.1.1.2.2.3.1" xref="S4.E1.m1.2.2.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E1.m1.2.2.1.1.2.2.3.3" xref="S4.E1.m1.2.2.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E1.m1.2.2.1.1.2.3" xref="S4.E1.m1.2.2.1.1.2.3.cmml">n</mi></munderover><mrow id="S4.E1.m1.2.2.1.1.1" xref="S4.E1.m1.2.2.1.1.1.cmml"><msub id="S4.E1.m1.2.2.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.3.cmml"><mi id="S4.E1.m1.2.2.1.1.1.3.2" xref="S4.E1.m1.2.2.1.1.1.3.2.cmml">p</mi><mi id="S4.E1.m1.2.2.1.1.1.3.3" xref="S4.E1.m1.2.2.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.2.2.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.2.cmml">â‹…</mo><mrow id="S4.E1.m1.2.2.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.cmml"><munder id="S4.E1.m1.2.2.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.2.cmml"><mi id="S4.E1.m1.2.2.1.1.1.1.2.2" xref="S4.E1.m1.2.2.1.1.1.1.2.2.cmml">min</mi><mi id="S4.E1.m1.2.2.1.1.1.1.2.3" xref="S4.E1.m1.2.2.1.1.1.1.2.3.cmml">k</mi></munder><mo id="S4.E1.m1.2.2.1.1.1.1a" xref="S4.E1.m1.2.2.1.1.1.1.cmml">â¡</mo><msup id="S4.E1.m1.2.2.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.cmml"><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msup id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml">W</mi><mrow id="S4.E1.m1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.3.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml">k</mi><mo stretchy="false" id="S4.E1.m1.1.1.1.3.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></msup></mrow><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S4.E1.m1.2.2.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><mo id="S4.E1.m1.2.2.1.2" xref="S4.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b"><apply id="S4.E1.m1.2.2.1.1.cmml" xref="S4.E1.m1.2.2.1"><apply id="S4.E1.m1.2.2.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.2">superscript</csymbol><apply id="S4.E1.m1.2.2.1.1.2.2.cmml" xref="S4.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.2.2.1.cmml" xref="S4.E1.m1.2.2.1.1.2">subscript</csymbol><sum id="S4.E1.m1.2.2.1.1.2.2.2.cmml" xref="S4.E1.m1.2.2.1.1.2.2.2"></sum><apply id="S4.E1.m1.2.2.1.1.2.2.3.cmml" xref="S4.E1.m1.2.2.1.1.2.2.3"><eq id="S4.E1.m1.2.2.1.1.2.2.3.1.cmml" xref="S4.E1.m1.2.2.1.1.2.2.3.1"></eq><ci id="S4.E1.m1.2.2.1.1.2.2.3.2.cmml" xref="S4.E1.m1.2.2.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E1.m1.2.2.1.1.2.2.3.3.cmml" xref="S4.E1.m1.2.2.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E1.m1.2.2.1.1.2.3.cmml" xref="S4.E1.m1.2.2.1.1.2.3">ğ‘›</ci></apply><apply id="S4.E1.m1.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1"><ci id="S4.E1.m1.2.2.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.2">â‹…</ci><apply id="S4.E1.m1.2.2.1.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.3.1.cmml" xref="S4.E1.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.2.2.1.1.1.3.2.cmml" xref="S4.E1.m1.2.2.1.1.1.3.2">ğ‘</ci><ci id="S4.E1.m1.2.2.1.1.1.3.3.cmml" xref="S4.E1.m1.2.2.1.1.1.3.3">ğ‘–</ci></apply><apply id="S4.E1.m1.2.2.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1"><apply id="S4.E1.m1.2.2.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.2">subscript</csymbol><min id="S4.E1.m1.2.2.1.1.1.1.2.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.2.2"></min><ci id="S4.E1.m1.2.2.1.1.1.1.2.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.2.3">ğ‘˜</ci></apply><apply id="S4.E1.m1.2.2.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1">superscript</csymbol><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1"><minus id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2">ğ‘Š</ci><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.2">ğ‘Š</ci><ci id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1">ğ‘˜</ci></apply></apply></apply><cn type="integer" id="S4.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.2c">\sum_{i=1}^{n}p_{i}\cdot\min_{k}\left\|W_{i}-W^{(k)}\right\|^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.SSS0.Px1.p3" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p3.6" class="ltx_p">where <math id="S4.SS1.SSS0.Px1.p3.1.m1.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p3.1.m1.1a"><msub id="S4.SS1.SSS0.Px1.p3.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p3.1.m1.1.1.2" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1.2.cmml">p</mi><mi id="S4.SS1.SSS0.Px1.p3.1.m1.1.1.3" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p3.1.m1.1b"><apply id="S4.SS1.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1.2">ğ‘</ci><ci id="S4.SS1.SSS0.Px1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p3.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p3.1.m1.1c">p_{i}</annotation></semantics></math> is the weight that is typically proportional to the size of the <math id="S4.SS1.SSS0.Px1.p3.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.SSS0.Px1.p3.2.m2.1a"><mi id="S4.SS1.SSS0.Px1.p3.2.m2.1.1" xref="S4.SS1.SSS0.Px1.p3.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p3.2.m2.1b"><ci id="S4.SS1.SSS0.Px1.p3.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p3.2.m2.1c">i</annotation></semantics></math>-th client local dataset, <math id="S4.SS1.SSS0.Px1.p3.3.m3.1" class="ltx_Math" alttext="W_{i}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p3.3.m3.1a"><msub id="S4.SS1.SSS0.Px1.p3.3.m3.1.1" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p3.3.m3.1.1.2" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1.2.cmml">W</mi><mi id="S4.SS1.SSS0.Px1.p3.3.m3.1.1.3" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p3.3.m3.1b"><apply id="S4.SS1.SSS0.Px1.p3.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1.2">ğ‘Š</ci><ci id="S4.SS1.SSS0.Px1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p3.3.m3.1c">W_{i}</annotation></semantics></math> is the parameter of the <math id="S4.SS1.SSS0.Px1.p3.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.SSS0.Px1.p3.4.m4.1a"><mi id="S4.SS1.SSS0.Px1.p3.4.m4.1.1" xref="S4.SS1.SSS0.Px1.p3.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p3.4.m4.1b"><ci id="S4.SS1.SSS0.Px1.p3.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p3.4.m4.1c">i</annotation></semantics></math>-th clientâ€™s local model and <math id="S4.SS1.SSS0.Px1.p3.5.m5.1" class="ltx_Math" alttext="W^{(k)}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p3.5.m5.1a"><msup id="S4.SS1.SSS0.Px1.p3.5.m5.1.2" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2.cmml"><mi id="S4.SS1.SSS0.Px1.p3.5.m5.1.2.2" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2.2.cmml">W</mi><mrow id="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.3" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2.cmml"><mo stretchy="false" id="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.3.1" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2.cmml">(</mo><mi id="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.1" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.1.cmml">k</mi><mo stretchy="false" id="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.3.2" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p3.5.m5.1b"><apply id="S4.SS1.SSS0.Px1.p3.5.m5.1.2.cmml" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p3.5.m5.1.2.1.cmml" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2">superscript</csymbol><ci id="S4.SS1.SSS0.Px1.p3.5.m5.1.2.2.cmml" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.2.2">ğ‘Š</ci><ci id="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.5.m5.1.1.1.1">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p3.5.m5.1c">W^{(k)}</annotation></semantics></math> is the parameter of the <math id="S4.SS1.SSS0.Px1.p3.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.SSS0.Px1.p3.6.m6.1a"><mi id="S4.SS1.SSS0.Px1.p3.6.m6.1.1" xref="S4.SS1.SSS0.Px1.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p3.6.m6.1b"><ci id="S4.SS1.SSS0.Px1.p3.6.m6.1.1.cmml" xref="S4.SS1.SSS0.Px1.p3.6.m6.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p3.6.m6.1c">k</annotation></semantics></math>-th cluster. Any distance metric can be integrated into this framework. This paper takes the simplest L2 distance into consideration and uses K-means as the clustering method.</p>
</div>
<div id="S4.SS1.SSS0.Px1.p4" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p4.1" class="ltx_p">The distance measurement for clustering methods can be of different forms. Apart from L2-distance, there are more sophisticated distance measurements represented in a hierarchical form, which can be leveraged for specific sets of medical data silos. In <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">sattler2020clustered </a></cite>, geometric properties of the FL loss surface is used for client clustering. Clients within the same cluster have jointly trainable data distributions.</p>
</div>
<div id="S4.SS1.SSS0.Px1.p5" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p5.1" class="ltx_p">Although clustered FL better utilizes the similarity among the users, there are still challenges when performing it in open health. For example, the cluster identities of a hospital or clinic are usually unknown, so it is essential to identify the cluster membership of these data providers first and then optimise each of the cluster models in a distributed setting. To achieve this efficiently, <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">ghosh2020efficient </a></cite> designs a framework known as Iterative Federated Clustering Algorithm (IFCA) for clustered FL. IFCA alternately estimates the cluster identities and minimises the loss functions so as to allow the model to converge at an exponential rate with a relaxed initialisation requirement.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Personalised FL.</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">Personalised FL aims to provide personalised services to participating medical institutes or patients based on the their medical images, fragmented data sources and healthcare data with privacy concerns.</p>
</div>
<div id="S4.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p2.1" class="ltx_p">The balance between individual learning and collaboration has been discussed in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref">deng2020adaptive </a></cite> in a theoretical way. As a result, when the userâ€™s data distribution does not deviate too much from the data distribution of other users, collaboration can be beneficial to reduce the local generalisation error. When some users data is too different from the data of others to represent the overall data distribution, independent training is preferable.</p>
</div>
<div id="S4.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p3.1" class="ltx_p">Sometimes, it is possible to train one personalised model per client. A theoretic study of personalisation in FL is presented in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref">mansour2020three </a></cite>. The authors propose to use data interpolation as a personalisation technique.</p>
</div>
<div id="S4.SS1.SSS0.Px2.p4" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p4.2" class="ltx_p">Data interpolation realises personalisation by domain adaptation. Local dataset <math id="S4.SS1.SSS0.Px2.p4.1.m1.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p4.1.m1.1a"><msub id="S4.SS1.SSS0.Px2.p4.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px2.p4.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1.2.cmml">D</mi><mi id="S4.SS1.SSS0.Px2.p4.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p4.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p4.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px2.p4.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1.2">ğ·</ci><ci id="S4.SS1.SSS0.Px2.p4.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p4.1.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p4.1.m1.1c">D_{k}</annotation></semantics></math> is regarded as target domain, and global dataset or the cluster dataset <math id="S4.SS1.SSS0.Px2.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p4.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px2.p4.2.m2.1.1" xref="S4.SS1.SSS0.Px2.p4.2.m2.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p4.2.m2.1b"><ci id="S4.SS1.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px2.p4.2.m2.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p4.2.m2.1c">\mathcal{C}</annotation></semantics></math> is regarded as source distribution. The objective function is optimised based on concatenated dataset,</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.1" class="ltx_Math" alttext="\lambda\cdot\mathcal{D}_{k}+(1-\lambda)\cdot\mathcal{C}," display="block"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.3.2.cmml">Î»</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.1.1.1.1.3.1" xref="S4.E2.m1.1.1.1.1.3.1.cmml">â‹…</mo><msub id="S4.E2.m1.1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.3.3.2" xref="S4.E2.m1.1.1.1.1.3.3.2.cmml">ğ’Ÿ</mi><mi id="S4.E2.m1.1.1.1.1.3.3.3" xref="S4.E2.m1.1.1.1.1.3.3.3.cmml">k</mi></msub></mrow><mo id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2.cmml">+</mo><mrow id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.cmml"><mn id="S4.E2.m1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.E2.m1.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.3.cmml">Î»</mi></mrow><mo rspace="0.055em" stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.E2.m1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.2.cmml">â‹…</mo><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.3.cmml">ğ’</mi></mrow></mrow><mo id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><plus id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2"></plus><apply id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3"><ci id="S4.E2.m1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.1">â‹…</ci><ci id="S4.E2.m1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2">ğœ†</ci><apply id="S4.E2.m1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2">ğ’Ÿ</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3">ğ‘˜</ci></apply></apply><apply id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1"><ci id="S4.E2.m1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.2">â‹…</ci><apply id="S4.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1"><minus id="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.3">ğœ†</ci></apply><ci id="S4.E2.m1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3">ğ’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\lambda\cdot\mathcal{D}_{k}+(1-\lambda)\cdot\mathcal{C},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.SSS0.Px2.p4.3" class="ltx_p">where <math id="S4.SS1.SSS0.Px2.p4.3.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS1.SSS0.Px2.p4.3.m1.1a"><mi id="S4.SS1.SSS0.Px2.p4.3.m1.1.1" xref="S4.SS1.SSS0.Px2.p4.3.m1.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p4.3.m1.1b"><ci id="S4.SS1.SSS0.Px2.p4.3.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p4.3.m1.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p4.3.m1.1c">\lambda</annotation></semantics></math> is a hyperparameter that can be obtained by cross validation.</p>
</div>
<div id="S4.SS1.SSS0.Px2.p5" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p5.1" class="ltx_p">Some other popular methods for personalised FL can be categorized as personalisation layers where part of the layers are shared and aggregated across multiple clients. The rule of shared layer selection can vary. For example, in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">arivazhagan2019federated </a></cite>, representation layers act as the personalised components, while the decision layers are shared across participants. By contrast, in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib32" title="" class="ltx_ref">liang2020think </a></cite>, the representation layers are shared across participants, and decision layers remain local as a personalised component.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model Architecture Heterogeneity</h3>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2108.10761/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="187" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Model heterogeneity problem in federated learning.</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Medical data providers tend to use robust statistical models from their local medical data, which is collected in huge amounts by modern healthcare systems <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">rieke2020future </a></cite>. This brings about model heterogeneity to an FL system. Model architecture heterogeneity in Fig. <a href="#S4.F5" title="Figure 5 â€£ 4.2 Model Architecture Heterogeneity â€£ 4 Data Heterogeneity Challenge for Federated Learning â€£ Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, as the main form of model heterogeneity, will hinder the model aggregation procedure in traditional FL algorithms.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">To solve this problem and train a robust statistical model from distributed medical data, knowledge distillation, proposed by Hinton et al. <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">hinton2015distilling </a></cite> in 2015, is widely used to transfer knowledge between models with different architectures. <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib33" title="" class="ltx_ref">lin2020ensemble </a></cite> proposes ensemble distillation for robust model fusion. It allows for heterogeneous client data and models, and clients with different neural architectures to be considered in one FL system. It defines <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">p</annotation></semantics></math> distinct model prototypes with different architectures. During the aggregation procedure in each communication round, all received client models are distilled to <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">p</annotation></semantics></math> model prototypes without additional computation burden on clients. Then, the fused prototype models are sent to activated clients for the next round.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref">tan2021fedproto </a></cite> also borrow the concept of prototypes and use them to represent classes rather than models. Prototype aggregation is applied in the server to solve the heterogeneous setting in FL.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">Sometimes, as a result of various dataset sizes and computation abilities, the model for a specific medical data provider is independently designed. This makes the model unique, and the use of traditional averaging aggregation no longer possible. To solve this problem, Li and Wang propose Federated Learning via Model Distillation (FedMD) which is a universal framework enabling FL to work with uniquely designed local models <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib28" title="" class="ltx_ref">li2019fedmd </a></cite>. Assume there are <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mi id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">k</annotation></semantics></math> clients, each client owns not only a private dataset <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{k}" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><msub id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mi id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">ğ’Ÿ</ci><ci id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">\mathcal{D}_{k}</annotation></semantics></math> but also a public dataset <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{0}" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><msub id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.3.m3.1.1.2" xref="S4.SS2.p4.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mn id="S4.SS2.p4.3.m3.1.1.3" xref="S4.SS2.p4.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2">ğ’Ÿ</ci><cn type="integer" id="S4.SS2.p4.3.m3.1.1.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">\mathcal{D}_{0}</annotation></semantics></math>, <math id="S4.SS2.p4.4.m4.1" class="ltx_Math" alttext="k=1\ldots m" display="inline"><semantics id="S4.SS2.p4.4.m4.1a"><mrow id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml"><mi id="S4.SS2.p4.4.m4.1.1.2" xref="S4.SS2.p4.4.m4.1.1.2.cmml">k</mi><mo id="S4.SS2.p4.4.m4.1.1.1" xref="S4.SS2.p4.4.m4.1.1.1.cmml">=</mo><mrow id="S4.SS2.p4.4.m4.1.1.3" xref="S4.SS2.p4.4.m4.1.1.3.cmml"><mn id="S4.SS2.p4.4.m4.1.1.3.2" xref="S4.SS2.p4.4.m4.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.1.1.3.1" xref="S4.SS2.p4.4.m4.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.SS2.p4.4.m4.1.1.3.3" xref="S4.SS2.p4.4.m4.1.1.3.3.cmml">â€¦</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.1.1.3.1a" xref="S4.SS2.p4.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p4.4.m4.1.1.3.4" xref="S4.SS2.p4.4.m4.1.1.3.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.1b"><apply id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1"><eq id="S4.SS2.p4.4.m4.1.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1.1"></eq><ci id="S4.SS2.p4.4.m4.1.1.2.cmml" xref="S4.SS2.p4.4.m4.1.1.2">ğ‘˜</ci><apply id="S4.SS2.p4.4.m4.1.1.3.cmml" xref="S4.SS2.p4.4.m4.1.1.3"><times id="S4.SS2.p4.4.m4.1.1.3.1.cmml" xref="S4.SS2.p4.4.m4.1.1.3.1"></times><cn type="integer" id="S4.SS2.p4.4.m4.1.1.3.2.cmml" xref="S4.SS2.p4.4.m4.1.1.3.2">1</cn><ci id="S4.SS2.p4.4.m4.1.1.3.3.cmml" xref="S4.SS2.p4.4.m4.1.1.3.3">â€¦</ci><ci id="S4.SS2.p4.4.m4.1.1.3.4.cmml" xref="S4.SS2.p4.4.m4.1.1.3.4">ğ‘š</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.1c">k=1\ldots m</annotation></semantics></math>. Each client computes the class scores <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="f_{k}\left(x_{i}^{0}\right)" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mrow id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml"><msub id="S4.SS2.p4.5.m5.1.1.3" xref="S4.SS2.p4.5.m5.1.1.3.cmml"><mi id="S4.SS2.p4.5.m5.1.1.3.2" xref="S4.SS2.p4.5.m5.1.1.3.2.cmml">f</mi><mi id="S4.SS2.p4.5.m5.1.1.3.3" xref="S4.SS2.p4.5.m5.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p4.5.m5.1.1.2" xref="S4.SS2.p4.5.m5.1.1.2.cmml">â€‹</mo><mrow id="S4.SS2.p4.5.m5.1.1.1.1" xref="S4.SS2.p4.5.m5.1.1.1.1.1.cmml"><mo id="S4.SS2.p4.5.m5.1.1.1.1.2" xref="S4.SS2.p4.5.m5.1.1.1.1.1.cmml">(</mo><msubsup id="S4.SS2.p4.5.m5.1.1.1.1.1" xref="S4.SS2.p4.5.m5.1.1.1.1.1.cmml"><mi id="S4.SS2.p4.5.m5.1.1.1.1.1.2.2" xref="S4.SS2.p4.5.m5.1.1.1.1.1.2.2.cmml">x</mi><mi id="S4.SS2.p4.5.m5.1.1.1.1.1.2.3" xref="S4.SS2.p4.5.m5.1.1.1.1.1.2.3.cmml">i</mi><mn id="S4.SS2.p4.5.m5.1.1.1.1.1.3" xref="S4.SS2.p4.5.m5.1.1.1.1.1.3.cmml">0</mn></msubsup><mo id="S4.SS2.p4.5.m5.1.1.1.1.3" xref="S4.SS2.p4.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><apply id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1"><times id="S4.SS2.p4.5.m5.1.1.2.cmml" xref="S4.SS2.p4.5.m5.1.1.2"></times><apply id="S4.SS2.p4.5.m5.1.1.3.cmml" xref="S4.SS2.p4.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p4.5.m5.1.1.3.1.cmml" xref="S4.SS2.p4.5.m5.1.1.3">subscript</csymbol><ci id="S4.SS2.p4.5.m5.1.1.3.2.cmml" xref="S4.SS2.p4.5.m5.1.1.3.2">ğ‘“</ci><ci id="S4.SS2.p4.5.m5.1.1.3.3.cmml" xref="S4.SS2.p4.5.m5.1.1.3.3">ğ‘˜</ci></apply><apply id="S4.SS2.p4.5.m5.1.1.1.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.5.m5.1.1.1.1.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1">superscript</csymbol><apply id="S4.SS2.p4.5.m5.1.1.1.1.1.2.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.5.m5.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p4.5.m5.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S4.SS2.p4.5.m5.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S4.SS2.p4.5.m5.1.1.1.1.1.3.cmml" xref="S4.SS2.p4.5.m5.1.1.1.1.1.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">f_{k}\left(x_{i}^{0}\right)</annotation></semantics></math> on the public dataset, and transmits the result to a central server. Instead of model parameter aggregation, the server computes an updated consensus on the average of these class scores. This is realised through knowledge distillation that can transmit learned information in a model-agnostic way.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">Although knowledge distillation works well for the model architecture heterogeneity challenge, the communication and computation costs remain a problem. Jeong et al. propose to minimize the communication overhead while enjoying the benefit brought by a massive amount of private data providers <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">jeong2018communication </a></cite>. A new distributed training algorithm named federated distillation (FD) has been developed to improve communication efficiency for an on-device machine learning framework. It exchanges the model output rather than the model parameters, which significantly decreases the communication payload from model size to output size.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Transfer learning for cross-silo federated learning</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Existing medical data is not fully exploited by traditional machine learning methods because it sits in data silos and privacy concerns restrict access to this data. As a result of insufficient data, a gap between research and clinical practice exists. FL provides an opportunity to take full advantage of cross-silo data and significantly contribute to open health in future decades.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Transfer learning, as a special case of machine learning, is introduced to solve the heterogeneity problem, expand the scale of medical datasets and further improve the performance of the final model <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref">liu2018secure </a></cite>. For the distributed medical data silos with different kinds of private patient data, the combination of transfer learning and federated learning can lead to a flexible framework adapted to various secure multi-party machine learning tasks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref">xu2019federated </a></cite>.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Classical FL methods like FedAvg require that all contributors share the same feature space <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib41" title="" class="ltx_ref">mcmahan2017communication </a></cite>. However, the scenario with such common entities is rare in reality. In most cases, data contributors share heterogeneous feature spaces and/or model architectures. The authors in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref">liu2018secure </a></cite> address this limitation of existing FL approaches and utilize transfer learning to provide solutions for the entire feature space under a federation. Their work has formalised the federated transfer learning (FTL) problem in a privacy-preserving setting where all parties are honest-but-curious. Next, they propose an end-to-end method to solve the FTL problem. Compared with non-privacy-preserving transfer learning, the proposed method achieves comparable performance in terms of convergence and accuracy. Moreover, novel privacy preserving techniques, i.e. homomorphic encryption (HE) and secret sharing can be incorporated with learning models, i.e. neural networks, under the proposed FTL framework without much modifications.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">Such privacy-preserving FTL solution is well suited for cross-silo open health scenarios, because it is a well-developed framework that takes all the related aspects into account, including performance, scalability, computation and communication. FTL is superior to non-federated self-learning approaches, and performs as well as non-privacy-preserving approaches.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In the above sections, we identified key challenges and possible solutions for FL in the healthcare industry. Here, we discuss the implications of solving the healthcare challenges and explore the benefits of a successful open innovation framework with FL.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Implications of solving the security, privacy and heterogeneity challenges</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">If the existing security, privacy and heterogeneity challenges can be solved, there are a number of implications for various industries, including healthcare. Below we detail three primary implications.</p>
</div>
<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Shared knowledge and expertise.</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">Having a secure way to learn from various local health data sets will increase shared knowledge and expertise among different healthcare institutions. Organisations is likely to be more willing to use their data for collaborative research when they can ensure the privacy of their own patient data and are not required to provide copies of their data. Certainly, it will be essential to identify and engage organisations and institutions that are willing to explore the use of FL for healthcare purposes and to have legal and privacy experts who can verify whether methods comply with existing privacy standards and regulations. Solving the heterogeneity problem will also drive knowledge sharing as it will allow for diverse data to be used to develop more useful global models.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Adoption of deep learning.</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">Deep learning has already demonstrated potential to enhance patient care in the healthcare industry. Previous reviews <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref">reviewSolares2020 </a>; <a href="#bib.bib52" title="" class="ltx_ref">reviewShickel2017 </a>; <a href="#bib.bib58" title="" class="ltx_ref">reviewXiao2018 </a></cite> present numerous applications of deep learning to Electronic Health Records (EHRs) and deep learning has also shown success with image data from medical images and tissue samples <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib23" title="" class="ltx_ref">Ker2018 </a></cite>. Despite the potential for deep learning to improve patient care, adoption in the healthcare industry is slow. This is often due to models being developed in single healthcare institutions using single datasets, resulting in a lack of robustness across populations <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref">xu2019federated </a></cite>.</p>
</div>
<div id="S5.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p2.1" class="ltx_p">If healthcare information can be shared with the help of an FL system, this will overcome existing limitations. Healthcare institutions that previously didnâ€™t adopt deep learning due to potential bias issues that can arise from training in single institutions, would now have access to models with better generalisability due to training on larger and more representative populations. Furthermore, smaller institutions which were incapable of building predictive algorithms due to small data sizes, will now have access to risk prediction models. This will provide these institutions with increased functionality that can be used to help improve clinical care.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Generalised methodologies.</h4>

<div id="S5.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px3.p1.1" class="ltx_p">The security and privacy challenges, as well as the data heterogeneity problems mentioned above, are not only found in health data. Therefore, designing methods that can address these challenges will facilitate the healthcare sector but will also be relevant to other industries with sensitive data (such as banking or insurance). Methodologies developed could be directly applied to these other relevant industries. Furthermore, general FL research will help advance the field of FL, and in a time where learning joint models from siloed datasets can provide immense potential, particularly in healthcare, it is paramount that the development of FL algorithms be continued.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Benefits of an open innovation framework with FL to healthcare</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">If a successful open innovation FL system was implemented in the healthcare sector, it stands to benefit in a multitude of ways. These benefits will be received by participants, patients and the healthcare system.</p>
</div>
<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Participants.</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.1" class="ltx_p">In addition to the benefit of knowledge and expertise sharing as indicated in the above section, participants also stand to benefit from FL system through the development of collaborative partnerships. These types of frameworks are the very definition of open innovation, as various external parties will be involved to provide expertise, including clinicians, healthcare professionals, healthcare institution managers, data scientists and software engineers.
We expect that implementation of FL systems will lead to long-term partnerships between medical centres, hospitals, and governments.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Patients.</h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.1" class="ltx_p">Because FL systems will enhance the adoption of deep learning algorithms, implementation of these algorithm has potential to directly benefit patients and their outcomes in both the cross-device and cross-silo settings.</p>
</div>
<div id="S5.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p2.1" class="ltx_p">In the cross-device setting, patients can benefit through shared information from wearable devices. Wearable devices can be used for monitoring health and safety of patients, managing chronic diseases, assisting in the diagnosis and treatment of conditions, and for monitoring rehabilitation <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">Lu2020wearables </a></cite>. For example, in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib53" title="" class="ltx_ref">Jung2015wearables </a></cite>, data from wearable devices was used to create a fall detection system that could produce emergency alerts so that immediate treatment could be provided to patients. Wearables have also been used by patients with chronic obstructive pulmonary disease to help screen for early disease deterioration <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib57" title="" class="ltx_ref">Wu2018wearables </a></cite>. They have also found relevance in rehabilitation, helping to understand stroke recovery and modify treatment plans in line with recovery progress <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib19" title="" class="ltx_ref">Jayaraman2018wearables </a></cite>. With the help of FL, model information from individual patient devices can be used to help develop more generalised models that offer improvements in identifying falls, disease deterioration and patient monitoring. This would help optimise care for patients and lead to more personalised treatments, driving improvements in patient outcomes.</p>
</div>
<div id="S5.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p3.1" class="ltx_p">In the cross-silo setting, patients can benefit through shared information across healthcare institutions. Much research to date on machine learning and deep learning for healthcare data has utilised the Medical Information Mart for Intensive Care (MIMIC-III), due to it being a freely-available database. It has been used for the development of deep learning algorithms to predict mortality, sepsis, future diagnosis and hospital readmissions <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib18" title="" class="ltx_ref">Hou2020mimic </a>; <a href="#bib.bib47" title="" class="ltx_ref">Scherpf2019mimic </a>; <a href="#bib.bib34" title="" class="ltx_ref">Lin2018mimic </a>; <a href="#bib.bib39" title="" class="ltx_ref">Ma2018mimic </a></cite>. All these outcomes have potential to prevent poor health outcomes for patients and provide optimised care at end-of-life. However, MIMIC-III data is from a single healthcare centre and includes only patients that are admitted to the Intensive Care Unit (ICU) in the hospital. Therefore many of the predictive models developed on this dataset will not perform equivalently in other health datasets. By using FL, global models can be developed from multiple healthcare institutions that offer improved performance due to training on larger and more diverse health data <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref">xu2019federated </a></cite>. These improved predictive models can provide additional information to clinicians about risks and benefits of different treatment options and outcomes <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref">xu2019federated </a></cite>. This has potential for more effective treatment earlier, leading to improved patient outcomes.</p>
</div>
<div id="S5.SS2.SSS0.Px2.p4" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p4.1" class="ltx_p">The promise of FL to improve patient outcomes has already been demonstrated in the healthcare sector, for both risk prediction and identifying similar patients. <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib7" title="" class="ltx_ref">Brisimi2018 </a></cite> used an FL framework to develop a prediction model for hospitalisations due to heart diseases based on information in EHRs. The decentralised model achieved similar performance to the centralised method and the authors extracted important features to facilitate interpretability. <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib48" title="" class="ltx_ref">Sharma2019 </a></cite> compared an FL framework with a centralised approach for predicting in-hospital mortality and also found that the FL approach provided comparable performance to the centralised setting. <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib27" title="" class="ltx_ref">Lee2018 </a></cite> used a privacy-preserving federated environment to identify similar patients across healthcare institutions without sharing patient-level information. Similarly, <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib24" title="" class="ltx_ref">kim2017federated </a></cite> performed computational phenotyping without sharing patient-level data. These examples demonstrate the success of FL compared to typically centralised approaches and its potential in the healthcare industry to improve care of patients.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Healthcare system.</h4>

<div id="S5.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px3.p1.1" class="ltx_p">Given the current pressure for healthcare systems to enhance sustainability, an FL system is an attractive option. With the use of FL, it is possible to develop more generalisable models that can assist in providing clinical care. More effective and targeted treatment of patients may result in less time spent visiting emergency departments and hospitals, slowed disease progression for chronic disease, and better outcomes sooner <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">rieke2020future </a></cite>. This has potential to reduce healthcare system costs, hence contributing to a more sustainable healthcare system.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data Structure.</h4>

<div id="S5.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px4.p1.1" class="ltx_p">The healthcare activity may produce data with various structure, for example, images from medical imaging, texts on clinic reports, tabular data in hospitalâ€™s database, sequential patient journey in healthcare service system, and time series from wearable devices or ICU. Different data structure needs to tackled with different data processing technique. Moreover, the data fusion of multi-modal data is also a common solution to build intelligent healthcare application. To model the complex data of real-world is a practical challenge. This chapter demonstrates the FL framework using image data. However, the discussed problem and solution can be generally applied to a broad scenario with different data structures.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">FL holds promising potential to enable shared healthcare information, knowledge and expertise between institutions, while preserving privacy of individuals. Although there remain challenges for data security, privacy and heterogeneity, this is an active area of FL research with solutions already being identified. The implications of FL for health are many, including facilitating sharing of healthcare information, increasing adoption of deep learning algorithms that can produce more generalised models, and the development of improved methodologies that are applicable to industries beyond healthcare. Long-term benefits will result from FL-enabled open innovation of health, which will be felt at the participant, patient and healthcare system level.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">We believe that FL will help leverage existing health data assets to directly impact patient care and therefore, offers immense opportunity for open innovation in the healthcare sector.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
ManojÂ Ghuhan Arivazhagan, Vinay Aggarwal, AadityaÂ Kumar Singh, and Sunav
Choudhary.

</span>
<span class="ltx_bibblock">Federated learning with personalization layers.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">arXiv:1912.00818</span>, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
JoseÂ Roberto Ayala Solares, FrancescaÂ Elisa Diletta Raimondi, Yajie Zhu,
etÂ al.

</span>
<span class="ltx_bibblock">Deep learning for electronic health records: A comparative review of
multiple deep neural architectures.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">J. Biomed. Inform</span>, 101:103337, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly
Shmatikov.

</span>
<span class="ltx_bibblock">How to backdoor federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">AISTATS</span>, volume 108, pages 2938â€“2948, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Gilad Baruch, Moran Baruch, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">A little is enough: Circumventing defenses for distributed learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">NeurIPS 2019</span>, pages 8632â€“8642, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Peva Blanchard, ElÂ MahdiÂ El Mhamdi, Rachid Guerraoui, and Julien Stainer.

</span>
<span class="ltx_bibblock">Machine learning with adversaries: Byzantine tolerant gradient
descent.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Jeffrey Braithwaite, Yvonne Zurynski, Kristiana Ludlow, Joanna Holt, Hanna
Augustsson, and Margie Campbell.

</span>
<span class="ltx_bibblock">Towards sustainable healthcare system performance in the 21st century
in high-income countries: A protocol for a systematic review of the grey
literature.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">BMJ Open</span>, 9:bmjopenâ€“2018, 01 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
TheodoraÂ S. Brisimi, Ruidi Chen, Theofanie Mela, Alex Olshevsky, IoannisÂ Ch.
Paschalidis, and Wei Shi.

</span>
<span class="ltx_bibblock">Federated learning of predictive models from federated electronic
health records.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">International Journal of Medical Informatics</span>, 112:59â€“67, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Henry Chesbrough, Wim Vanhaverbeke, and Joel West.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">New frontiers in open innovation</span>.

</span>
<span class="ltx_bibblock">Oup Oxford, 2014.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
GabrielaÂ F. Cretu, Angelos Stavrou, MichaelÂ E. Locasto, SalvatoreÂ J. Stolfo,
and AngelosÂ D. Keromytis.

</span>
<span class="ltx_bibblock">Casting out demons: Sanitizing training data for anomaly sensors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">IEEE Symposium on S&amp;P</span>, pages 81â€“95. IEEE Computer
Society, 2008.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Patricia Dandonoli.

</span>
<span class="ltx_bibblock">Open innovation as a new paradigm for global collaborations in
health.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Globalization and health</span>, 9:41, 08 2013.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Yuyang Deng, MohammadÂ Mahdi Kamani, and Mehrdad Mahdavi.

</span>
<span class="ltx_bibblock">Adaptive personalized federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.13461</span>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Cynthia Dwork.

</span>
<span class="ltx_bibblock">Differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">ICALP</span>, volume 4052. Springer, 2006.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Council of the EuropeanÂ Union EuropeanÂ Parliament.

</span>
<span class="ltx_bibblock">General data protection regulation (gdpr).

</span>
<span class="ltx_bibblock">Technical report, 2016.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and NeilÂ Zhenqiang Gong.

</span>
<span class="ltx_bibblock">Local model poisoning attacks to byzantine-robust federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">USENIX Security Symposium</span>, pages 1605â€“1622. USENIX
Association, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Jonas Geiping, Hartmut Bauermeister, Hannah DrÃ¶ge, and Michael Moeller.

</span>
<span class="ltx_bibblock">Inverting gradients - how easy is it to break privacy in federated
learning?

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran.

</span>
<span class="ltx_bibblock">An efficient framework for clustered federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.04088</span>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv:1503.02531</span>, 2015.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Nianzong Hou, Mingzhe Li, etÂ al.

</span>
<span class="ltx_bibblock">Predicting 30-days mortality for mimic-iii patients with sepsis-3: a
machine learning approach using xgboost.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Journal of Translational Medicine</span>, 18, 12 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Chandrasekaran Jayaraman and etÂ al.

</span>
<span class="ltx_bibblock">Variables influencing wearable sensor outcome estimates in
individuals with stroke and incomplete spinal cord injury: A pilot
investigation validating two research grade sensors.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Journal of NR</span>, 15, 03 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and
Seong-Lyun Kim.

</span>
<span class="ltx_bibblock">Communication-efficient on-device machine learning: Federated
distillation and augmentation under non-iid private data.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv:1811.11479</span>, 2018.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Peter Kairouz, H.Â Brendan McMahan, etÂ al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1912.04977, 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Christopher Kelly and Anthony Young.

</span>
<span class="ltx_bibblock">Promoting innovation in healthcare.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Future Healthcare Journal</span>, 4:121â€“125, 06 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Justin Ker, Lipo Wang, Jai Rao, and Tchoyoson Lim.

</span>
<span class="ltx_bibblock">Deep learning applications in medical image analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 6:9375â€“9389, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Yejin Kim, Jimeng Sun, Hwanjo Yu, and Xiaoqian Jiang.

</span>
<span class="ltx_bibblock">Federated tensor factorization for computational phenotyping.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">SIGKDD</span>, pages 887â€“895. ACM, 2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
PangÂ Wei Koh, Jacob Steinhardt, and Percy Liang.

</span>
<span class="ltx_bibblock">Stronger data poisoning attacks break data sanitization defenses.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1811.00741, 2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Jakub KoneÄná»³, HÂ Brendan McMahan, FelixÂ X Yu, Peter RichtÃ¡rik,
AnandaÂ Theertha Suresh, and Dave Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1610.05492</span>, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Junghye Lee, Jimeng Sun, Fei Wang, Shuang Wang, Chi-Hyuck Jun, and Xiaoqian
Jiang.

</span>
<span class="ltx_bibblock">Privacy-preserving patient similarity learning in a federated
environment: Development and analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">JMIR Med Inform</span>, 6(2):e20, Apr 2018.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Daliang Li and Junpu Wang.

</span>
<span class="ltx_bibblock">Fedmd: Heterogenous federated learning via model distillation.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv:1910.03581</span>, 2019.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Suyi Li, Yong Cheng, Yang Liu, Wei Wang, and Tianjian Chen.

</span>
<span class="ltx_bibblock">Abnormal client behavior detection in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1910.09933, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Suyi Li, Yong Cheng, Wei Wang, Yang Liu, and Tianjian Chen.

</span>
<span class="ltx_bibblock">Learning to detect malicious clients for robust federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2002.00211, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Wenqi Li, Fausto MilletarÃ¬, etÂ al.

</span>
<span class="ltx_bibblock">Privacy-preserving federated brain tumour segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">International Workshop on Machine Learning in Medical
Imaging</span>, pages 133â€“141. Springer, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
PaulÂ Pu Liang, Terrance Liu, Liu Ziyin, Ruslan Salakhutdinov, and
Louis-Philippe Morency.

</span>
<span class="ltx_bibblock">Think locally, act globally: Federated learning with local and global
representations.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">arXiv:2001.01523</span>, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong, SebastianÂ U Stich, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 33, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Yu-Wei Lin, Yuqian Zhou, Faraz Faghri, Michael Shaw, and Roy Campbell.

</span>
<span class="ltx_bibblock">Analysis and prediction of unplanned intensive care unit readmission
using recurrent neural networks with long short-term memory.

</span>
<span class="ltx_bibblock">08 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Boyi Liu, Lujia Wang, and Ming Liu.

</span>
<span class="ltx_bibblock">Lifelong federated reinforcement learning: A learning architecture
for navigation in cloud robotic systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">IEEE Robotics Autom. Lett.</span>, 4(4):4555â€“4562, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Yang Liu, Yan Kang, Chaoping Xing, Tianjian Chen, and Qiang Yang.

</span>
<span class="ltx_bibblock">Secure federated transfer learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.03337</span>, 2018.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Guodong Long, Yue Tan, Jing Jiang, and Chengqi Zhang.

</span>
<span class="ltx_bibblock">Federated learning for open banking.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Federated Learning</span>, pages 240â€“254. Springer, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Lin Lu, Jiayao Zhang, and etÂ al.

</span>
<span class="ltx_bibblock">Wearable health devices in health care: Narrative systematic review.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">JMIR Mhealth Uhealth</span>, 8(11):e18907, Nov 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Fenglong Ma, Yaqing Wang, Houping Xiao, YeÂ Yuan, Radha Chitta, Jing Zhou, and
Jing Gao.

</span>
<span class="ltx_bibblock">A general framework for diagnosis prediction via incorporating
medical code descriptions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">BIBM</span>, pages 1070â€“1075, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Yishay Mansour, Mehryar Mohri, Jae Ro, and AnandaÂ Theertha Suresh.

</span>
<span class="ltx_bibblock">Three approaches for personalization with applications to federated
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.10619</span>, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera
yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence and Statistics</span>, pages 1273â€“1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
BlaiseÂ AgÃ¼era yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">AISTATS</span>, volumeÂ 54, pages 1273â€“1282, 2017.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Viraaji Mothukuri, RezaÂ M. Parizi, Seyedamin Pouriyeh, Yan Huang, Ali
Dehghantanha, and Gautam Srivastava.

</span>
<span class="ltx_bibblock">A survey on security and privacy of federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Future Generation Computer Systems</span>, 115:619 â€“ 640, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
Jakub KoneÄná»³, Sanjiv Kumar, and HÂ Brendan McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.00295</span>, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny Hancox, Wenqi Li, etÂ al.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">nature partner journals: Digital Medicine</span>, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Felix Sattler, Klaus-Robert MÃ¼ller, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Clustered federated learning: Model-agnostic distributed multitask
optimization under privacy constraints.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>,
2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Matthieu Scherpf, Felix GrÃ¤ÃŸer, Hagen Malberg, and Sebastian Zaunseder.

</span>
<span class="ltx_bibblock">Predicting sepsis with a recurrent neural network using the mimic iii
database.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Computers in Biology and Medicine</span>, 113:103395, 08 2019.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Pulkit Sharma, FarahÂ E. Shamout, and DavidÂ A. Clifton.

</span>
<span class="ltx_bibblock">Preserving patient privacy while training a predictive model of
in-hospital mortality.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1912.00354, 2019.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Micah Sheller and etÂ al.

</span>
<span class="ltx_bibblock">Federated learning in medicine: facilitating multi-institutional
collaborations without sharing patient data.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">Scientific Reports</span>, 10, 07 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
MicahÂ J Sheller, GÂ Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon
Bakas.

</span>
<span class="ltx_bibblock">Multi-institutional deep learning modeling without sharing patient
data: A feasibility study on brain tumor segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">International MICCAI Brainlesion Workshop</span>, pages 92â€“104.
Springer, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Shiqi Shen, Shruti Tople, and Prateek Saxena.

</span>
<span class="ltx_bibblock">Auror: defending against poisoning attacks in collaborative deep
learning systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">Proceedings of the 32nd Annual Conference on Computer
Security Applications, ACSAC 2016, Los Angeles, CA, USA, December 5-9,
2016</span>, pages 508â€“519. ACM, 2016.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Benjamin Shickel and etÂ al.

</span>
<span class="ltx_bibblock">Deep EHR: A survey of recent advances on deep learning techniques
for electronic health record (EHR) analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1706.03446, 2017.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Jung Sungmook, Seungki Hong, Jaemin Kim, Sangkyu Lee, Taeghwan Hyeon, Minbaek
Lee, and Dae-Hyeong Kim.

</span>
<span class="ltx_bibblock">Wearable fall detector using integrated sensors and energy devices.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Scientific Reports</span>, 5:17081, 11 2015.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Yue Tan, Guodong Long, LuÂ Liu, Tianyi Zhou, and Jing Jiang.

</span>
<span class="ltx_bibblock">Fedproto: Federated prototype learning over heterogeneous devices.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2105.00243</span>, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Hongyi Wang, Kartik Sreenivasan, etÂ al.

</span>
<span class="ltx_bibblock">Attack of the tails: Yes, you really can backdoor federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Wenqi Wei, Ling Liu, Margaret Loper, KaÂ Ho Chow, MehmetÂ Emre Gursoy, Stacey
Truex, and Yanzhao Wu.

</span>
<span class="ltx_bibblock">A framework for evaluating gradient leakage attacks in federated
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2004.10397, 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Robert Wu, Daniyal Liaqat, Eyal deÂ Lara, Tatiana Son, Frank Rudzicz, Hisham
Alshaer, Pegah Abed-Esfahani, and AndreaÂ S Gershon.

</span>
<span class="ltx_bibblock">Feasibility of using a smartwatch to intensively monitor patients
with chronic obstructive pulmonary disease: Prospective cohort study.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">JMIR Mhealth Uhealth</span>, 6(6):e10046, Jun 2018.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Cao Xiao, Edward Choi, and J.Â Sun.

</span>
<span class="ltx_bibblock">Opportunities and challenges in developing deep learning models using
electronic health records data: A systematic review.

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>, 25, 06
2018.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Ming Xie, Guodong Long, Tao Shen, Tianyi Zhou, Xianzhi Wang, and Jing Jiang.

</span>
<span class="ltx_bibblock">Multi-center federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2005.01026</span>, 2020.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Jie Xu and Fei Wang.

</span>
<span class="ltx_bibblock">Federated learning for healthcare informatics.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.06270</span>, 2019.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">TIST</span>, 10(2):1â€“19, 2019.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Andy WaiÂ Kan Yeung etÂ al.

</span>
<span class="ltx_bibblock">Open innovation in medical and pharmaceutical research: A literature
landscape analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Frontiers in Pharmacology</span>, 11, 01 2021.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
BoÂ Zhao, KondaÂ Reddy Mopuri, and Hakan Bilen.

</span>
<span class="ltx_bibblock">idlg: Improved deep leakage from gradients.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2001.02610, 2020.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Ligeng Zhu, Zhijian Liu, and Song Han.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock">In <span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, pages 14747â€“14756, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2108.10759" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2108.10761" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2108.10761">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2108.10761" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2108.10762" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 12 03:24:45 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
