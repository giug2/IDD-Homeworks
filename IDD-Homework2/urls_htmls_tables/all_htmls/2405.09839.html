<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.09839] Advances in Robust Federated Learning: Heterogeneity Considerations</title><meta property="og:description" content="In the field of heterogeneous federated learning (FL), the key challenge is to efficiently and collaboratively train models across multiple clients with different data distributions, model structures, task objectives, …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advances in Robust Federated Learning: Heterogeneity Considerations">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Advances in Robust Federated Learning: Heterogeneity Considerations">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.09839">

<!--Generated on Wed Jun  5 15:57:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  heterogeneity,  robust,  privacy-preserving
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Advances in Robust Federated Learning: Heterogeneity Considerations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Chuan Chen <span id="id1.1.id1" class="ltx_text ltx_font_italic">Member, IEEE</span>, Tianchi Liao, Xiaojun Deng, Zihou Wu, Sheng Huang, Zibin Zheng* <span id="id2.2.id2" class="ltx_text ltx_font_italic">Fellow, IEEE</span>
</span><span class="ltx_author_notes">
Chuan Chen, Xiaojun Deng, and Zihou Wu were with the School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou 510006, China. (e-mail:
chenchuan@mail.sysu.edu.cn, dengxj26@mail2.sysu.edu.cn, wuzh78@mail2.sysu.edu.cn)
Tianchi Liao, and Zibin Zheng were with School of Software Engineering, Sun Yat-sen University, Zhuhai 519000, China. (e-mail: liaotch@mail2.sysu.edu.cn, zhzibin@mail.sysu.edu.cn).
Sheng Huang was with the School of Systems Science and Engineering, Sun Yat-sen University, Guangzhou 510006, China. (e-mail: huangsh253@mail2.sysu.edu.cn).
Zibin Zheng is the corresponding author.
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">In the field of heterogeneous federated learning (FL), the key challenge is to efficiently and collaboratively train models across multiple clients with different data distributions, model structures, task objectives, computational capabilities, and communication resources. This diversity leads to significant heterogeneity, which increases the complexity of model training. In this paper, we first outline the basic concepts of heterogeneous federated learning and summarize the research challenges in federated learning in terms of five aspects: data, model, task, device and communication. In addition, we explore how existing state-of-the-art approaches cope with the heterogeneity of federated learning, and categorize and review these approaches at three different levels: data-level, model-level, and architecture-level. Subsequently, the paper extensively discusses privacy-preserving strategies in heterogeneous federated learning environments. Finally, the paper discusses current open issues and directions for future research, aiming to promote the further development of heterogeneous federated learning.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, heterogeneity, robust, privacy-preserving

</div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the popularization of mobile devices and 5G networks, a large amount of data is generated on edge devices every day, greatly promoting the development of artificial intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Traditional machine learning (ML) methods require centralized data storage and processing for model training, which poses significant challenge to data transmission and storage. Moreover, with the frequent occurrence of data leakage, the issue of privacy protection attracts more and more attention. In this context, institutions and enterprises are going to seek a new ML paradigm, which can utilize distributed data resources for training while protecting data privacy and security.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In 2016, Google researchers proposed the concept of federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The core idea about FL is to train and update models locally on data owners (i.e. clients) and aggregates model updates on a third party (i.e. server), without the need to transfer the raw data to a central server. By this way, FL can significantly reduce data transmission in the network, thus reducing the possibility of privacy leakage and the requirement for centralized computing and storage resources. FL not only presents the respect and protection for privacy, but also demonstrates how to maximize the utility of data while ensuring privacy in the era of big data. At present, FL is becoming an effective way for balancing the utility and privacy of data, bringing new development directions and opportunities to ML. FL has demonstrated its broad application potential in fields such as intelligent healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> finance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, the Internet of Things <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and smart cities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, in the application scenarios of typical FL, there are multiple heterogeneity issues among clients, including data heterogeneity, model heterogeneity, task heterogeneity, communication heterogeneity, and device heterogeneity, which brings challenges to collaboratively model training. The presence of heterogeneity not only significantly damages the generalization ability and prediction accuracy of trained model, but also to some extent restrict the application of FL. Specifically, FL often counters the following heterogeneity:
<span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Data heterogeneity</span>: The clients often far away from each other geographically and lack communications, and each client may collect data from different data source, causing skews in the distributions of data collected by clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Moreover, the method of sampling and processing data and the amount of collected data may also vary across different clients, resulting in quality skew and quantity skew.
<span id="S1.p3.1.2" class="ltx_text ltx_font_bold">Model heterogeneity</span>: Due to device limitations, task types and other reasons, the clients have to customize their own model structures and jointly train models in a federated manner, which is model structure heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Moreover, the adopted optimizer of different clients may also be different.
<span id="S1.p3.1.3" class="ltx_text ltx_font_bold">Task heterogeneity</span>: Sometimes different clients need to train models for different tasks. For example, some clients may need to train models for image classification, while some other clients may need to train models for semantic segmentation.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
<span id="S1.p3.1.4" class="ltx_text ltx_font_bold">Communication heterogeneity</span>: In typical FL, each round of FL requires transmission of model parameters or gradients between the server and the clients. But in reality, the participants of FL are usually under different network environments, and communication bandwidth and budgets of some participants are limited, which is called communication heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
<span id="S1.p3.1.5" class="ltx_text ltx_font_bold">Device heterogeneity</span>: The typical FL algorithms usually require local training on the clients. But due to limited computing power, storage resources, energy supply, etc., the clients may update local models inconsistently and thus lower the efficiency of the whole system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Although FL is originally proposed for helping protect privacy of the clients, the risk of privacy leakage has not been completely eliminated. Besides heterogeneity, FL is still subject to some privacy attacks. The reason is that attackers can easily access client uploads to analyze privacy information. For example, the malicious attackers may intercept the uploaded parameters or gradients and reconstruct the client’s local data by Gradient Inversion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> or Model Inversion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Moreover, attackers may also use Membership Inference Attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> to determine whether certain data is includes in local training, or use Property Inference Attack to infer private information of some property, like the data sampling environment and label distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Thus, it is necessary to employ some privacy-preserving mechanisms in FL to enable clients to communicate with servers and other clients in a more secure way.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Research addressing heterogeneous FL is currently generating a lot of buzz, and we investigate a number of frequently cited or recent surveys related to heterogeneity and privacy issues.
Although they have all provided detailed descriptions and abundant related researches for their respective focused topics, they still overlook some less mentioned types of issues and techniques. In this paper, we first categorize several types of heterogeneity in detail, and explore heterogeneity challenges may encountered while applying FL for practical environments, as well as solutions. For each type of heterogeneity, we not only present detailed and formal description, but also conduct extensive survey for comprehensively summarizing the state-of-the-art solutions. Moreover, given that privacy protection is one of the core demands of FL, we also focus on privacy protection problems and solutions while applying FL in scenarios with heterogeneity. We discuss the application of existing privacy protection techniques in FL, delving into the trade-off between privacy and utility, and introduce the advanced researches in relevant fields. We list the differences between our survey and the above other surveys in <a href="#S1.T1" title="TABLE I ‣ I Introduction ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table I</span></a>.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparison between other surveys and ours</figcaption>
<div id="S1.T1.140" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:91pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-426.8pt,89.5pt) scale(0.336886075299605,0.336886075299605) ;">
<table id="S1.T1.140.140" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.140.140.141.1" class="ltx_tr">
<th id="S1.T1.140.140.141.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S1.T1.140.140.141.1.1.1" class="ltx_text ltx_font_bold">Survey</span></th>
<th id="S1.T1.140.140.141.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite></th>
<th id="S1.T1.140.140.141.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite></th>
<th id="S1.T1.140.140.141.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite></th>
<th id="S1.T1.140.140.141.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></th>
<th id="S1.T1.140.140.141.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite></th>
<th id="S1.T1.140.140.141.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></th>
<th id="S1.T1.140.140.141.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></th>
<th id="S1.T1.140.140.141.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></th>
<th id="S1.T1.140.140.141.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></th>
<th id="S1.T1.140.140.141.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Ours</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.10.10.10" class="ltx_tr">
<td id="S1.T1.10.10.10.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="5"><span id="S1.T1.10.10.10.11.1" class="ltx_text">
<span id="S1.T1.10.10.10.11.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.10.10.10.11.1.1.1" class="ltx_tr">
<span id="S1.T1.10.10.10.11.1.1.1.1" class="ltx_td ltx_align_center"><span id="S1.T1.10.10.10.11.1.1.1.1.1" class="ltx_text ltx_font_bold">Data Heterogeneity</span></span></span>
<span id="S1.T1.10.10.10.11.1.1.2" class="ltx_tr">
<span id="S1.T1.10.10.10.11.1.1.2.1" class="ltx_td ltx_align_center"><span id="S1.T1.10.10.10.11.1.1.2.1.1" class="ltx_text ltx_font_bold">Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a></span></span></span>
</span></span></td>
<td id="S1.T1.10.10.10.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Distribution Skew</td>
<td id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.1.1.1.1.m1.1a"><mo id="S1.T1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.m1.1b"><times id="S1.T1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.2.2.2.2.m1.1a"><mi mathvariant="normal" id="S1.T1.2.2.2.2.m1.1.1" xref="S1.T1.2.2.2.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.2.2.m1.1b"><ci id="S1.T1.2.2.2.2.m1.1.1.cmml" xref="S1.T1.2.2.2.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.2.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.3.3.3.3.m1.1a"><mi mathvariant="normal" id="S1.T1.3.3.3.3.m1.1.1" xref="S1.T1.3.3.3.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.3.3.3.3.m1.1b"><ci id="S1.T1.3.3.3.3.m1.1.1.cmml" xref="S1.T1.3.3.3.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.3.3.3.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.4.4.4.4.m1.1a"><mi mathvariant="normal" id="S1.T1.4.4.4.4.m1.1.1" xref="S1.T1.4.4.4.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.4.4.4.4.m1.1b"><ci id="S1.T1.4.4.4.4.m1.1.1.cmml" xref="S1.T1.4.4.4.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.4.4.4.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.5.5.5.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.5.5.5.5.m1.1a"><mi mathvariant="normal" id="S1.T1.5.5.5.5.m1.1.1" xref="S1.T1.5.5.5.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.5.5.5.5.m1.1b"><ci id="S1.T1.5.5.5.5.m1.1.1.cmml" xref="S1.T1.5.5.5.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.5.5.5.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.6.6.6.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.6.6.6.6.m1.1a"><mi mathvariant="normal" id="S1.T1.6.6.6.6.m1.1.1" xref="S1.T1.6.6.6.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.6.6.6.6.m1.1b"><ci id="S1.T1.6.6.6.6.m1.1.1.cmml" xref="S1.T1.6.6.6.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.6.6.6.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.7.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.7.7.7.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.7.7.7.7.m1.1a"><mi mathvariant="normal" id="S1.T1.7.7.7.7.m1.1.1" xref="S1.T1.7.7.7.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.7.7.7.7.m1.1b"><ci id="S1.T1.7.7.7.7.m1.1.1.cmml" xref="S1.T1.7.7.7.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.7.7.7.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.8.8.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.8.8.8.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.8.8.8.8.m1.1a"><mi mathvariant="normal" id="S1.T1.8.8.8.8.m1.1.1" xref="S1.T1.8.8.8.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.8.8.8.8.m1.1b"><ci id="S1.T1.8.8.8.8.m1.1.1.cmml" xref="S1.T1.8.8.8.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.8.8.8.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.9.9.9.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.9.9.9.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.9.9.9.9.m1.1a"><mi mathvariant="normal" id="S1.T1.9.9.9.9.m1.1.1" xref="S1.T1.9.9.9.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.9.9.9.9.m1.1b"><ci id="S1.T1.9.9.9.9.m1.1.1.cmml" xref="S1.T1.9.9.9.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.9.9.9.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.10.10.10.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.10.10.10.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.10.10.10.10.m1.1a"><mi mathvariant="normal" id="S1.T1.10.10.10.10.m1.1.1" xref="S1.T1.10.10.10.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.10.10.10.10.m1.1b"><ci id="S1.T1.10.10.10.10.m1.1.1.cmml" xref="S1.T1.10.10.10.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.10.10.10.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.20.20.20" class="ltx_tr">
<td id="S1.T1.20.20.20.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Label Skew</td>
<td id="S1.T1.11.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.11.11.11.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.11.11.11.1.m1.1a"><mi mathvariant="normal" id="S1.T1.11.11.11.1.m1.1.1" xref="S1.T1.11.11.11.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.11.11.11.1.m1.1b"><ci id="S1.T1.11.11.11.1.m1.1.1.cmml" xref="S1.T1.11.11.11.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.11.11.11.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.12.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.12.12.12.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.12.12.12.2.m1.1a"><mo id="S1.T1.12.12.12.2.m1.1.1" xref="S1.T1.12.12.12.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.12.12.12.2.m1.1b"><times id="S1.T1.12.12.12.2.m1.1.1.cmml" xref="S1.T1.12.12.12.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.12.12.12.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.13.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.13.13.13.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.13.13.13.3.m1.1a"><mo id="S1.T1.13.13.13.3.m1.1.1" xref="S1.T1.13.13.13.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.13.13.13.3.m1.1b"><times id="S1.T1.13.13.13.3.m1.1.1.cmml" xref="S1.T1.13.13.13.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.13.13.13.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.14.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.14.14.14.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.14.14.14.4.m1.1a"><mo id="S1.T1.14.14.14.4.m1.1.1" xref="S1.T1.14.14.14.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.14.14.14.4.m1.1b"><times id="S1.T1.14.14.14.4.m1.1.1.cmml" xref="S1.T1.14.14.14.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.14.14.14.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.15.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.15.15.15.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.15.15.15.5.m1.1a"><mo id="S1.T1.15.15.15.5.m1.1.1" xref="S1.T1.15.15.15.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.15.15.15.5.m1.1b"><times id="S1.T1.15.15.15.5.m1.1.1.cmml" xref="S1.T1.15.15.15.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.15.15.15.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.16.16.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.16.16.16.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.16.16.16.6.m1.1a"><mi mathvariant="normal" id="S1.T1.16.16.16.6.m1.1.1" xref="S1.T1.16.16.16.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.16.16.16.6.m1.1b"><ci id="S1.T1.16.16.16.6.m1.1.1.cmml" xref="S1.T1.16.16.16.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.16.16.16.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.17.17.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.17.17.17.7.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.17.17.17.7.m1.1a"><mo id="S1.T1.17.17.17.7.m1.1.1" xref="S1.T1.17.17.17.7.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.17.17.17.7.m1.1b"><times id="S1.T1.17.17.17.7.m1.1.1.cmml" xref="S1.T1.17.17.17.7.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.17.17.17.7.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.18.18.18.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.18.18.18.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.18.18.18.8.m1.1a"><mo id="S1.T1.18.18.18.8.m1.1.1" xref="S1.T1.18.18.18.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.18.18.18.8.m1.1b"><times id="S1.T1.18.18.18.8.m1.1.1.cmml" xref="S1.T1.18.18.18.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.18.18.18.8.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.19.19.19.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.19.19.19.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.19.19.19.9.m1.1a"><mi mathvariant="normal" id="S1.T1.19.19.19.9.m1.1.1" xref="S1.T1.19.19.19.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.19.19.19.9.m1.1b"><ci id="S1.T1.19.19.19.9.m1.1.1.cmml" xref="S1.T1.19.19.19.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.19.19.19.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.20.20.20.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.20.20.20.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.20.20.20.10.m1.1a"><mi mathvariant="normal" id="S1.T1.20.20.20.10.m1.1.1" xref="S1.T1.20.20.20.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.20.20.20.10.m1.1b"><ci id="S1.T1.20.20.20.10.m1.1.1.cmml" xref="S1.T1.20.20.20.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.20.20.20.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.30.30.30" class="ltx_tr">
<td id="S1.T1.30.30.30.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Feature Skew</td>
<td id="S1.T1.21.21.21.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.21.21.21.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.21.21.21.1.m1.1a"><mi mathvariant="normal" id="S1.T1.21.21.21.1.m1.1.1" xref="S1.T1.21.21.21.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.21.21.21.1.m1.1b"><ci id="S1.T1.21.21.21.1.m1.1.1.cmml" xref="S1.T1.21.21.21.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.21.21.21.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.22.22.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.22.22.22.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.22.22.22.2.m1.1a"><mo id="S1.T1.22.22.22.2.m1.1.1" xref="S1.T1.22.22.22.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.22.22.22.2.m1.1b"><times id="S1.T1.22.22.22.2.m1.1.1.cmml" xref="S1.T1.22.22.22.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.22.22.22.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.23.23.23.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.23.23.23.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.23.23.23.3.m1.1a"><mo id="S1.T1.23.23.23.3.m1.1.1" xref="S1.T1.23.23.23.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.23.23.23.3.m1.1b"><times id="S1.T1.23.23.23.3.m1.1.1.cmml" xref="S1.T1.23.23.23.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.23.23.23.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.24.24.24.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.24.24.24.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.24.24.24.4.m1.1a"><mo id="S1.T1.24.24.24.4.m1.1.1" xref="S1.T1.24.24.24.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.24.24.24.4.m1.1b"><times id="S1.T1.24.24.24.4.m1.1.1.cmml" xref="S1.T1.24.24.24.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.24.24.24.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.25.25.25.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.25.25.25.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.25.25.25.5.m1.1a"><mo id="S1.T1.25.25.25.5.m1.1.1" xref="S1.T1.25.25.25.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.25.25.25.5.m1.1b"><times id="S1.T1.25.25.25.5.m1.1.1.cmml" xref="S1.T1.25.25.25.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.25.25.25.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.26.26.26.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.26.26.26.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.26.26.26.6.m1.1a"><mi mathvariant="normal" id="S1.T1.26.26.26.6.m1.1.1" xref="S1.T1.26.26.26.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.26.26.26.6.m1.1b"><ci id="S1.T1.26.26.26.6.m1.1.1.cmml" xref="S1.T1.26.26.26.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.26.26.26.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.27.27.27.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.27.27.27.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.27.27.27.7.m1.1a"><mi mathvariant="normal" id="S1.T1.27.27.27.7.m1.1.1" xref="S1.T1.27.27.27.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.27.27.27.7.m1.1b"><ci id="S1.T1.27.27.27.7.m1.1.1.cmml" xref="S1.T1.27.27.27.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.27.27.27.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.28.28.28.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.28.28.28.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.28.28.28.8.m1.1a"><mi mathvariant="normal" id="S1.T1.28.28.28.8.m1.1.1" xref="S1.T1.28.28.28.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.28.28.28.8.m1.1b"><ci id="S1.T1.28.28.28.8.m1.1.1.cmml" xref="S1.T1.28.28.28.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.28.28.28.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.29.29.29.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.29.29.29.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.29.29.29.9.m1.1a"><mi mathvariant="normal" id="S1.T1.29.29.29.9.m1.1.1" xref="S1.T1.29.29.29.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.29.29.29.9.m1.1b"><ci id="S1.T1.29.29.29.9.m1.1.1.cmml" xref="S1.T1.29.29.29.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.29.29.29.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.30.30.30.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.30.30.30.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.30.30.30.10.m1.1a"><mi mathvariant="normal" id="S1.T1.30.30.30.10.m1.1.1" xref="S1.T1.30.30.30.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.30.30.30.10.m1.1b"><ci id="S1.T1.30.30.30.10.m1.1.1.cmml" xref="S1.T1.30.30.30.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.30.30.30.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.40.40.40" class="ltx_tr">
<td id="S1.T1.40.40.40.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Quality Skew</td>
<td id="S1.T1.31.31.31.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.31.31.31.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.31.31.31.1.m1.1a"><mi mathvariant="normal" id="S1.T1.31.31.31.1.m1.1.1" xref="S1.T1.31.31.31.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.31.31.31.1.m1.1b"><ci id="S1.T1.31.31.31.1.m1.1.1.cmml" xref="S1.T1.31.31.31.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.31.31.31.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.32.32.32.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.32.32.32.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.32.32.32.2.m1.1a"><mo id="S1.T1.32.32.32.2.m1.1.1" xref="S1.T1.32.32.32.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.32.32.32.2.m1.1b"><times id="S1.T1.32.32.32.2.m1.1.1.cmml" xref="S1.T1.32.32.32.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.32.32.32.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.33.33.33.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.33.33.33.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.33.33.33.3.m1.1a"><mo id="S1.T1.33.33.33.3.m1.1.1" xref="S1.T1.33.33.33.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.33.33.33.3.m1.1b"><times id="S1.T1.33.33.33.3.m1.1.1.cmml" xref="S1.T1.33.33.33.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.33.33.33.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.34.34.34.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.34.34.34.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.34.34.34.4.m1.1a"><mo id="S1.T1.34.34.34.4.m1.1.1" xref="S1.T1.34.34.34.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.34.34.34.4.m1.1b"><times id="S1.T1.34.34.34.4.m1.1.1.cmml" xref="S1.T1.34.34.34.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.34.34.34.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.35.35.35.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.35.35.35.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.35.35.35.5.m1.1a"><mo id="S1.T1.35.35.35.5.m1.1.1" xref="S1.T1.35.35.35.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.35.35.35.5.m1.1b"><times id="S1.T1.35.35.35.5.m1.1.1.cmml" xref="S1.T1.35.35.35.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.35.35.35.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.36.36.36.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.36.36.36.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.36.36.36.6.m1.1a"><mo id="S1.T1.36.36.36.6.m1.1.1" xref="S1.T1.36.36.36.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.36.36.36.6.m1.1b"><times id="S1.T1.36.36.36.6.m1.1.1.cmml" xref="S1.T1.36.36.36.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.36.36.36.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.37.37.37.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.37.37.37.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.37.37.37.7.m1.1a"><mi mathvariant="normal" id="S1.T1.37.37.37.7.m1.1.1" xref="S1.T1.37.37.37.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.37.37.37.7.m1.1b"><ci id="S1.T1.37.37.37.7.m1.1.1.cmml" xref="S1.T1.37.37.37.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.37.37.37.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.38.38.38.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.38.38.38.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.38.38.38.8.m1.1a"><mo id="S1.T1.38.38.38.8.m1.1.1" xref="S1.T1.38.38.38.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.38.38.38.8.m1.1b"><times id="S1.T1.38.38.38.8.m1.1.1.cmml" xref="S1.T1.38.38.38.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.38.38.38.8.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.39.39.39.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.39.39.39.9.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.39.39.39.9.m1.1a"><mo id="S1.T1.39.39.39.9.m1.1.1" xref="S1.T1.39.39.39.9.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.39.39.39.9.m1.1b"><times id="S1.T1.39.39.39.9.m1.1.1.cmml" xref="S1.T1.39.39.39.9.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.39.39.39.9.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.40.40.40.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.40.40.40.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.40.40.40.10.m1.1a"><mi mathvariant="normal" id="S1.T1.40.40.40.10.m1.1.1" xref="S1.T1.40.40.40.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.40.40.40.10.m1.1b"><ci id="S1.T1.40.40.40.10.m1.1.1.cmml" xref="S1.T1.40.40.40.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.40.40.40.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.50.50.50" class="ltx_tr">
<td id="S1.T1.50.50.50.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Quantity Skew</td>
<td id="S1.T1.41.41.41.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.41.41.41.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.41.41.41.1.m1.1a"><mi mathvariant="normal" id="S1.T1.41.41.41.1.m1.1.1" xref="S1.T1.41.41.41.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.41.41.41.1.m1.1b"><ci id="S1.T1.41.41.41.1.m1.1.1.cmml" xref="S1.T1.41.41.41.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.41.41.41.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.42.42.42.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.42.42.42.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.42.42.42.2.m1.1a"><mo id="S1.T1.42.42.42.2.m1.1.1" xref="S1.T1.42.42.42.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.42.42.42.2.m1.1b"><times id="S1.T1.42.42.42.2.m1.1.1.cmml" xref="S1.T1.42.42.42.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.42.42.42.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.43.43.43.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.43.43.43.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.43.43.43.3.m1.1a"><mo id="S1.T1.43.43.43.3.m1.1.1" xref="S1.T1.43.43.43.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.43.43.43.3.m1.1b"><times id="S1.T1.43.43.43.3.m1.1.1.cmml" xref="S1.T1.43.43.43.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.43.43.43.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.44.44.44.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.44.44.44.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.44.44.44.4.m1.1a"><mo id="S1.T1.44.44.44.4.m1.1.1" xref="S1.T1.44.44.44.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.44.44.44.4.m1.1b"><times id="S1.T1.44.44.44.4.m1.1.1.cmml" xref="S1.T1.44.44.44.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.44.44.44.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.45.45.45.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.45.45.45.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.45.45.45.5.m1.1a"><mi mathvariant="normal" id="S1.T1.45.45.45.5.m1.1.1" xref="S1.T1.45.45.45.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.45.45.45.5.m1.1b"><ci id="S1.T1.45.45.45.5.m1.1.1.cmml" xref="S1.T1.45.45.45.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.45.45.45.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.46.46.46.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.46.46.46.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.46.46.46.6.m1.1a"><mo id="S1.T1.46.46.46.6.m1.1.1" xref="S1.T1.46.46.46.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.46.46.46.6.m1.1b"><times id="S1.T1.46.46.46.6.m1.1.1.cmml" xref="S1.T1.46.46.46.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.46.46.46.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.47.47.47.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.47.47.47.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.47.47.47.7.m1.1a"><mi mathvariant="normal" id="S1.T1.47.47.47.7.m1.1.1" xref="S1.T1.47.47.47.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.47.47.47.7.m1.1b"><ci id="S1.T1.47.47.47.7.m1.1.1.cmml" xref="S1.T1.47.47.47.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.47.47.47.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.48.48.48.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.48.48.48.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.48.48.48.8.m1.1a"><mo id="S1.T1.48.48.48.8.m1.1.1" xref="S1.T1.48.48.48.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.48.48.48.8.m1.1b"><times id="S1.T1.48.48.48.8.m1.1.1.cmml" xref="S1.T1.48.48.48.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.48.48.48.8.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.49.49.49.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.49.49.49.9.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.49.49.49.9.m1.1a"><mo id="S1.T1.49.49.49.9.m1.1.1" xref="S1.T1.49.49.49.9.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.49.49.49.9.m1.1b"><times id="S1.T1.49.49.49.9.m1.1.1.cmml" xref="S1.T1.49.49.49.9.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.49.49.49.9.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.50.50.50.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.50.50.50.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.50.50.50.10.m1.1a"><mi mathvariant="normal" id="S1.T1.50.50.50.10.m1.1.1" xref="S1.T1.50.50.50.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.50.50.50.10.m1.1b"><ci id="S1.T1.50.50.50.10.m1.1.1.cmml" xref="S1.T1.50.50.50.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.50.50.50.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.60.60.60" class="ltx_tr">
<td id="S1.T1.60.60.60.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S1.T1.60.60.60.11.1" class="ltx_text">
<span id="S1.T1.60.60.60.11.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.60.60.60.11.1.1.1" class="ltx_tr">
<span id="S1.T1.60.60.60.11.1.1.1.1" class="ltx_td ltx_align_center"><span id="S1.T1.60.60.60.11.1.1.1.1.1" class="ltx_text ltx_font_bold">Model Heterogeneity</span></span></span>
<span id="S1.T1.60.60.60.11.1.1.2" class="ltx_tr">
<span id="S1.T1.60.60.60.11.1.1.2.1" class="ltx_td ltx_align_center"><span id="S1.T1.60.60.60.11.1.1.2.1.1" class="ltx_text ltx_font_bold">Fig. <a href="#S2.F2" title="Figure 2 ‣ II-B Model Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></span></span></span>
</span></span></td>
<td id="S1.T1.60.60.60.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Structure Heterogeneity</td>
<td id="S1.T1.51.51.51.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.51.51.51.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.51.51.51.1.m1.1a"><mi mathvariant="normal" id="S1.T1.51.51.51.1.m1.1.1" xref="S1.T1.51.51.51.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.51.51.51.1.m1.1b"><ci id="S1.T1.51.51.51.1.m1.1.1.cmml" xref="S1.T1.51.51.51.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.51.51.51.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.52.52.52.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.52.52.52.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.52.52.52.2.m1.1a"><mi mathvariant="normal" id="S1.T1.52.52.52.2.m1.1.1" xref="S1.T1.52.52.52.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.52.52.52.2.m1.1b"><ci id="S1.T1.52.52.52.2.m1.1.1.cmml" xref="S1.T1.52.52.52.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.52.52.52.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.53.53.53.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.53.53.53.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.53.53.53.3.m1.1a"><mi mathvariant="normal" id="S1.T1.53.53.53.3.m1.1.1" xref="S1.T1.53.53.53.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.53.53.53.3.m1.1b"><ci id="S1.T1.53.53.53.3.m1.1.1.cmml" xref="S1.T1.53.53.53.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.53.53.53.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.54.54.54.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.54.54.54.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.54.54.54.4.m1.1a"><mi mathvariant="normal" id="S1.T1.54.54.54.4.m1.1.1" xref="S1.T1.54.54.54.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.54.54.54.4.m1.1b"><ci id="S1.T1.54.54.54.4.m1.1.1.cmml" xref="S1.T1.54.54.54.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.54.54.54.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.55.55.55.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.55.55.55.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.55.55.55.5.m1.1a"><mi mathvariant="normal" id="S1.T1.55.55.55.5.m1.1.1" xref="S1.T1.55.55.55.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.55.55.55.5.m1.1b"><ci id="S1.T1.55.55.55.5.m1.1.1.cmml" xref="S1.T1.55.55.55.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.55.55.55.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.56.56.56.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.56.56.56.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.56.56.56.6.m1.1a"><mi mathvariant="normal" id="S1.T1.56.56.56.6.m1.1.1" xref="S1.T1.56.56.56.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.56.56.56.6.m1.1b"><ci id="S1.T1.56.56.56.6.m1.1.1.cmml" xref="S1.T1.56.56.56.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.56.56.56.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.57.57.57.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.57.57.57.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.57.57.57.7.m1.1a"><mi mathvariant="normal" id="S1.T1.57.57.57.7.m1.1.1" xref="S1.T1.57.57.57.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.57.57.57.7.m1.1b"><ci id="S1.T1.57.57.57.7.m1.1.1.cmml" xref="S1.T1.57.57.57.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.57.57.57.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.58.58.58.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.58.58.58.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.58.58.58.8.m1.1a"><mi mathvariant="normal" id="S1.T1.58.58.58.8.m1.1.1" xref="S1.T1.58.58.58.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.58.58.58.8.m1.1b"><ci id="S1.T1.58.58.58.8.m1.1.1.cmml" xref="S1.T1.58.58.58.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.58.58.58.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.59.59.59.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.59.59.59.9.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.59.59.59.9.m1.1a"><mo id="S1.T1.59.59.59.9.m1.1.1" xref="S1.T1.59.59.59.9.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.59.59.59.9.m1.1b"><times id="S1.T1.59.59.59.9.m1.1.1.cmml" xref="S1.T1.59.59.59.9.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.59.59.59.9.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.60.60.60.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.60.60.60.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.60.60.60.10.m1.1a"><mi mathvariant="normal" id="S1.T1.60.60.60.10.m1.1.1" xref="S1.T1.60.60.60.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.60.60.60.10.m1.1b"><ci id="S1.T1.60.60.60.10.m1.1.1.cmml" xref="S1.T1.60.60.60.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.60.60.60.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.70.70.70" class="ltx_tr">
<td id="S1.T1.70.70.70.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Optimizer Heterogeneity</td>
<td id="S1.T1.61.61.61.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.61.61.61.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.61.61.61.1.m1.1a"><mo id="S1.T1.61.61.61.1.m1.1.1" xref="S1.T1.61.61.61.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.61.61.61.1.m1.1b"><times id="S1.T1.61.61.61.1.m1.1.1.cmml" xref="S1.T1.61.61.61.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.61.61.61.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.62.62.62.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.62.62.62.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.62.62.62.2.m1.1a"><mo id="S1.T1.62.62.62.2.m1.1.1" xref="S1.T1.62.62.62.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.62.62.62.2.m1.1b"><times id="S1.T1.62.62.62.2.m1.1.1.cmml" xref="S1.T1.62.62.62.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.62.62.62.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.63.63.63.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.63.63.63.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.63.63.63.3.m1.1a"><mo id="S1.T1.63.63.63.3.m1.1.1" xref="S1.T1.63.63.63.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.63.63.63.3.m1.1b"><times id="S1.T1.63.63.63.3.m1.1.1.cmml" xref="S1.T1.63.63.63.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.63.63.63.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.64.64.64.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.64.64.64.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.64.64.64.4.m1.1a"><mo id="S1.T1.64.64.64.4.m1.1.1" xref="S1.T1.64.64.64.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.64.64.64.4.m1.1b"><times id="S1.T1.64.64.64.4.m1.1.1.cmml" xref="S1.T1.64.64.64.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.64.64.64.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.65.65.65.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.65.65.65.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.65.65.65.5.m1.1a"><mo id="S1.T1.65.65.65.5.m1.1.1" xref="S1.T1.65.65.65.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.65.65.65.5.m1.1b"><times id="S1.T1.65.65.65.5.m1.1.1.cmml" xref="S1.T1.65.65.65.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.65.65.65.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.66.66.66.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.66.66.66.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.66.66.66.6.m1.1a"><mo id="S1.T1.66.66.66.6.m1.1.1" xref="S1.T1.66.66.66.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.66.66.66.6.m1.1b"><times id="S1.T1.66.66.66.6.m1.1.1.cmml" xref="S1.T1.66.66.66.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.66.66.66.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.67.67.67.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.67.67.67.7.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.67.67.67.7.m1.1a"><mo id="S1.T1.67.67.67.7.m1.1.1" xref="S1.T1.67.67.67.7.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.67.67.67.7.m1.1b"><times id="S1.T1.67.67.67.7.m1.1.1.cmml" xref="S1.T1.67.67.67.7.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.67.67.67.7.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.68.68.68.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.68.68.68.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.68.68.68.8.m1.1a"><mo id="S1.T1.68.68.68.8.m1.1.1" xref="S1.T1.68.68.68.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.68.68.68.8.m1.1b"><times id="S1.T1.68.68.68.8.m1.1.1.cmml" xref="S1.T1.68.68.68.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.68.68.68.8.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.69.69.69.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.69.69.69.9.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.69.69.69.9.m1.1a"><mo id="S1.T1.69.69.69.9.m1.1.1" xref="S1.T1.69.69.69.9.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.69.69.69.9.m1.1b"><times id="S1.T1.69.69.69.9.m1.1.1.cmml" xref="S1.T1.69.69.69.9.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.69.69.69.9.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.70.70.70.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.70.70.70.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.70.70.70.10.m1.1a"><mi mathvariant="normal" id="S1.T1.70.70.70.10.m1.1.1" xref="S1.T1.70.70.70.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.70.70.70.10.m1.1b"><ci id="S1.T1.70.70.70.10.m1.1.1.cmml" xref="S1.T1.70.70.70.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.70.70.70.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.80.80.80" class="ltx_tr">
<td id="S1.T1.80.80.80.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T1.80.80.80.11.1" class="ltx_text ltx_font_bold">Task Heterogeneity Fig. <a href="#S2.F3" title="Figure 3 ‣ II-C Task Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a></span></td>
<td id="S1.T1.71.71.71.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.71.71.71.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.71.71.71.1.m1.1a"><mo id="S1.T1.71.71.71.1.m1.1.1" xref="S1.T1.71.71.71.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.71.71.71.1.m1.1b"><times id="S1.T1.71.71.71.1.m1.1.1.cmml" xref="S1.T1.71.71.71.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.71.71.71.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.72.72.72.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.72.72.72.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.72.72.72.2.m1.1a"><mo id="S1.T1.72.72.72.2.m1.1.1" xref="S1.T1.72.72.72.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.72.72.72.2.m1.1b"><times id="S1.T1.72.72.72.2.m1.1.1.cmml" xref="S1.T1.72.72.72.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.72.72.72.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.73.73.73.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.73.73.73.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.73.73.73.3.m1.1a"><mo id="S1.T1.73.73.73.3.m1.1.1" xref="S1.T1.73.73.73.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.73.73.73.3.m1.1b"><times id="S1.T1.73.73.73.3.m1.1.1.cmml" xref="S1.T1.73.73.73.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.73.73.73.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.74.74.74.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.74.74.74.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.74.74.74.4.m1.1a"><mo id="S1.T1.74.74.74.4.m1.1.1" xref="S1.T1.74.74.74.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.74.74.74.4.m1.1b"><times id="S1.T1.74.74.74.4.m1.1.1.cmml" xref="S1.T1.74.74.74.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.74.74.74.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.75.75.75.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.75.75.75.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.75.75.75.5.m1.1a"><mi mathvariant="normal" id="S1.T1.75.75.75.5.m1.1.1" xref="S1.T1.75.75.75.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.75.75.75.5.m1.1b"><ci id="S1.T1.75.75.75.5.m1.1.1.cmml" xref="S1.T1.75.75.75.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.75.75.75.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.76.76.76.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.76.76.76.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.76.76.76.6.m1.1a"><mo id="S1.T1.76.76.76.6.m1.1.1" xref="S1.T1.76.76.76.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.76.76.76.6.m1.1b"><times id="S1.T1.76.76.76.6.m1.1.1.cmml" xref="S1.T1.76.76.76.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.76.76.76.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.77.77.77.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.77.77.77.7.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.77.77.77.7.m1.1a"><mo id="S1.T1.77.77.77.7.m1.1.1" xref="S1.T1.77.77.77.7.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.77.77.77.7.m1.1b"><times id="S1.T1.77.77.77.7.m1.1.1.cmml" xref="S1.T1.77.77.77.7.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.77.77.77.7.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.78.78.78.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.78.78.78.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.78.78.78.8.m1.1a"><mo id="S1.T1.78.78.78.8.m1.1.1" xref="S1.T1.78.78.78.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.78.78.78.8.m1.1b"><times id="S1.T1.78.78.78.8.m1.1.1.cmml" xref="S1.T1.78.78.78.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.78.78.78.8.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.79.79.79.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.79.79.79.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.79.79.79.9.m1.1a"><mi mathvariant="normal" id="S1.T1.79.79.79.9.m1.1.1" xref="S1.T1.79.79.79.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.79.79.79.9.m1.1b"><ci id="S1.T1.79.79.79.9.m1.1.1.cmml" xref="S1.T1.79.79.79.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.79.79.79.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.80.80.80.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.80.80.80.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.80.80.80.10.m1.1a"><mi mathvariant="normal" id="S1.T1.80.80.80.10.m1.1.1" xref="S1.T1.80.80.80.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.80.80.80.10.m1.1b"><ci id="S1.T1.80.80.80.10.m1.1.1.cmml" xref="S1.T1.80.80.80.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.80.80.80.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.90.90.90" class="ltx_tr">
<td id="S1.T1.90.90.90.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T1.90.90.90.11.1" class="ltx_text ltx_font_bold">Communication Heterogeneity</span></td>
<td id="S1.T1.81.81.81.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.81.81.81.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.81.81.81.1.m1.1a"><mi mathvariant="normal" id="S1.T1.81.81.81.1.m1.1.1" xref="S1.T1.81.81.81.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.81.81.81.1.m1.1b"><ci id="S1.T1.81.81.81.1.m1.1.1.cmml" xref="S1.T1.81.81.81.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.81.81.81.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.82.82.82.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.82.82.82.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.82.82.82.2.m1.1a"><mo id="S1.T1.82.82.82.2.m1.1.1" xref="S1.T1.82.82.82.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.82.82.82.2.m1.1b"><times id="S1.T1.82.82.82.2.m1.1.1.cmml" xref="S1.T1.82.82.82.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.82.82.82.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.83.83.83.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.83.83.83.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.83.83.83.3.m1.1a"><mi mathvariant="normal" id="S1.T1.83.83.83.3.m1.1.1" xref="S1.T1.83.83.83.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.83.83.83.3.m1.1b"><ci id="S1.T1.83.83.83.3.m1.1.1.cmml" xref="S1.T1.83.83.83.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.83.83.83.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.84.84.84.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.84.84.84.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.84.84.84.4.m1.1a"><mo id="S1.T1.84.84.84.4.m1.1.1" xref="S1.T1.84.84.84.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.84.84.84.4.m1.1b"><times id="S1.T1.84.84.84.4.m1.1.1.cmml" xref="S1.T1.84.84.84.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.84.84.84.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.85.85.85.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.85.85.85.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.85.85.85.5.m1.1a"><mi mathvariant="normal" id="S1.T1.85.85.85.5.m1.1.1" xref="S1.T1.85.85.85.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.85.85.85.5.m1.1b"><ci id="S1.T1.85.85.85.5.m1.1.1.cmml" xref="S1.T1.85.85.85.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.85.85.85.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.86.86.86.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.86.86.86.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.86.86.86.6.m1.1a"><mi mathvariant="normal" id="S1.T1.86.86.86.6.m1.1.1" xref="S1.T1.86.86.86.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.86.86.86.6.m1.1b"><ci id="S1.T1.86.86.86.6.m1.1.1.cmml" xref="S1.T1.86.86.86.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.86.86.86.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.87.87.87.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.87.87.87.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.87.87.87.7.m1.1a"><mi mathvariant="normal" id="S1.T1.87.87.87.7.m1.1.1" xref="S1.T1.87.87.87.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.87.87.87.7.m1.1b"><ci id="S1.T1.87.87.87.7.m1.1.1.cmml" xref="S1.T1.87.87.87.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.87.87.87.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.88.88.88.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.88.88.88.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.88.88.88.8.m1.1a"><mi mathvariant="normal" id="S1.T1.88.88.88.8.m1.1.1" xref="S1.T1.88.88.88.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.88.88.88.8.m1.1b"><ci id="S1.T1.88.88.88.8.m1.1.1.cmml" xref="S1.T1.88.88.88.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.88.88.88.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.89.89.89.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.89.89.89.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.89.89.89.9.m1.1a"><mi mathvariant="normal" id="S1.T1.89.89.89.9.m1.1.1" xref="S1.T1.89.89.89.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.89.89.89.9.m1.1b"><ci id="S1.T1.89.89.89.9.m1.1.1.cmml" xref="S1.T1.89.89.89.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.89.89.89.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.90.90.90.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.90.90.90.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.90.90.90.10.m1.1a"><mi mathvariant="normal" id="S1.T1.90.90.90.10.m1.1.1" xref="S1.T1.90.90.90.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.90.90.90.10.m1.1b"><ci id="S1.T1.90.90.90.10.m1.1.1.cmml" xref="S1.T1.90.90.90.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.90.90.90.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.100.100.100" class="ltx_tr">
<td id="S1.T1.100.100.100.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T1.100.100.100.11.1" class="ltx_text ltx_font_bold">Device Heterogeneity</span></td>
<td id="S1.T1.91.91.91.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.91.91.91.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.91.91.91.1.m1.1a"><mi mathvariant="normal" id="S1.T1.91.91.91.1.m1.1.1" xref="S1.T1.91.91.91.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.91.91.91.1.m1.1b"><ci id="S1.T1.91.91.91.1.m1.1.1.cmml" xref="S1.T1.91.91.91.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.91.91.91.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.92.92.92.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.92.92.92.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.92.92.92.2.m1.1a"><mo id="S1.T1.92.92.92.2.m1.1.1" xref="S1.T1.92.92.92.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.92.92.92.2.m1.1b"><times id="S1.T1.92.92.92.2.m1.1.1.cmml" xref="S1.T1.92.92.92.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.92.92.92.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.93.93.93.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.93.93.93.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.93.93.93.3.m1.1a"><mi mathvariant="normal" id="S1.T1.93.93.93.3.m1.1.1" xref="S1.T1.93.93.93.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.93.93.93.3.m1.1b"><ci id="S1.T1.93.93.93.3.m1.1.1.cmml" xref="S1.T1.93.93.93.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.93.93.93.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.94.94.94.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.94.94.94.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.94.94.94.4.m1.1a"><mo id="S1.T1.94.94.94.4.m1.1.1" xref="S1.T1.94.94.94.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.94.94.94.4.m1.1b"><times id="S1.T1.94.94.94.4.m1.1.1.cmml" xref="S1.T1.94.94.94.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.94.94.94.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.95.95.95.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.95.95.95.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.95.95.95.5.m1.1a"><mi mathvariant="normal" id="S1.T1.95.95.95.5.m1.1.1" xref="S1.T1.95.95.95.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.95.95.95.5.m1.1b"><ci id="S1.T1.95.95.95.5.m1.1.1.cmml" xref="S1.T1.95.95.95.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.95.95.95.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.96.96.96.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.96.96.96.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.96.96.96.6.m1.1a"><mi mathvariant="normal" id="S1.T1.96.96.96.6.m1.1.1" xref="S1.T1.96.96.96.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.96.96.96.6.m1.1b"><ci id="S1.T1.96.96.96.6.m1.1.1.cmml" xref="S1.T1.96.96.96.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.96.96.96.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.97.97.97.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.97.97.97.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.97.97.97.7.m1.1a"><mi mathvariant="normal" id="S1.T1.97.97.97.7.m1.1.1" xref="S1.T1.97.97.97.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.97.97.97.7.m1.1b"><ci id="S1.T1.97.97.97.7.m1.1.1.cmml" xref="S1.T1.97.97.97.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.97.97.97.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.98.98.98.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.98.98.98.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.98.98.98.8.m1.1a"><mi mathvariant="normal" id="S1.T1.98.98.98.8.m1.1.1" xref="S1.T1.98.98.98.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.98.98.98.8.m1.1b"><ci id="S1.T1.98.98.98.8.m1.1.1.cmml" xref="S1.T1.98.98.98.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.98.98.98.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.99.99.99.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.99.99.99.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.99.99.99.9.m1.1a"><mi mathvariant="normal" id="S1.T1.99.99.99.9.m1.1.1" xref="S1.T1.99.99.99.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.99.99.99.9.m1.1b"><ci id="S1.T1.99.99.99.9.m1.1.1.cmml" xref="S1.T1.99.99.99.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.99.99.99.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.100.100.100.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.100.100.100.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.100.100.100.10.m1.1a"><mi mathvariant="normal" id="S1.T1.100.100.100.10.m1.1.1" xref="S1.T1.100.100.100.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.100.100.100.10.m1.1b"><ci id="S1.T1.100.100.100.10.m1.1.1.cmml" xref="S1.T1.100.100.100.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.100.100.100.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.110.110.110" class="ltx_tr">
<td id="S1.T1.110.110.110.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S1.T1.110.110.110.11.1" class="ltx_text">
<span id="S1.T1.110.110.110.11.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.110.110.110.11.1.1.1" class="ltx_tr">
<span id="S1.T1.110.110.110.11.1.1.1.1" class="ltx_td ltx_align_center"><span id="S1.T1.110.110.110.11.1.1.1.1.1" class="ltx_text ltx_font_bold">Privacy Mechanism</span></span></span>
<span id="S1.T1.110.110.110.11.1.1.2" class="ltx_tr">
<span id="S1.T1.110.110.110.11.1.1.2.1" class="ltx_td ltx_align_center"><span id="S1.T1.110.110.110.11.1.1.2.1.1" class="ltx_text ltx_font_bold">Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A Differential Privacy ‣ IV Privacy Protection in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a></span></span></span>
</span></span></td>
<td id="S1.T1.110.110.110.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Differential Privacy</td>
<td id="S1.T1.101.101.101.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.101.101.101.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.101.101.101.1.m1.1a"><mi mathvariant="normal" id="S1.T1.101.101.101.1.m1.1.1" xref="S1.T1.101.101.101.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.101.101.101.1.m1.1b"><ci id="S1.T1.101.101.101.1.m1.1.1.cmml" xref="S1.T1.101.101.101.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.101.101.101.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.102.102.102.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.102.102.102.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.102.102.102.2.m1.1a"><mi mathvariant="normal" id="S1.T1.102.102.102.2.m1.1.1" xref="S1.T1.102.102.102.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.102.102.102.2.m1.1b"><ci id="S1.T1.102.102.102.2.m1.1.1.cmml" xref="S1.T1.102.102.102.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.102.102.102.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.103.103.103.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.103.103.103.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.103.103.103.3.m1.1a"><mi mathvariant="normal" id="S1.T1.103.103.103.3.m1.1.1" xref="S1.T1.103.103.103.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.103.103.103.3.m1.1b"><ci id="S1.T1.103.103.103.3.m1.1.1.cmml" xref="S1.T1.103.103.103.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.103.103.103.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.104.104.104.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.104.104.104.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.104.104.104.4.m1.1a"><mi mathvariant="normal" id="S1.T1.104.104.104.4.m1.1.1" xref="S1.T1.104.104.104.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.104.104.104.4.m1.1b"><ci id="S1.T1.104.104.104.4.m1.1.1.cmml" xref="S1.T1.104.104.104.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.104.104.104.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.105.105.105.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.105.105.105.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.105.105.105.5.m1.1a"><mo id="S1.T1.105.105.105.5.m1.1.1" xref="S1.T1.105.105.105.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.105.105.105.5.m1.1b"><times id="S1.T1.105.105.105.5.m1.1.1.cmml" xref="S1.T1.105.105.105.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.105.105.105.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.106.106.106.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.106.106.106.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.106.106.106.6.m1.1a"><mi mathvariant="normal" id="S1.T1.106.106.106.6.m1.1.1" xref="S1.T1.106.106.106.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.106.106.106.6.m1.1b"><ci id="S1.T1.106.106.106.6.m1.1.1.cmml" xref="S1.T1.106.106.106.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.106.106.106.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.107.107.107.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.107.107.107.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.107.107.107.7.m1.1a"><mi mathvariant="normal" id="S1.T1.107.107.107.7.m1.1.1" xref="S1.T1.107.107.107.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.107.107.107.7.m1.1b"><ci id="S1.T1.107.107.107.7.m1.1.1.cmml" xref="S1.T1.107.107.107.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.107.107.107.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.108.108.108.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.108.108.108.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.108.108.108.8.m1.1a"><mi mathvariant="normal" id="S1.T1.108.108.108.8.m1.1.1" xref="S1.T1.108.108.108.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.108.108.108.8.m1.1b"><ci id="S1.T1.108.108.108.8.m1.1.1.cmml" xref="S1.T1.108.108.108.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.108.108.108.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.109.109.109.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.109.109.109.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.109.109.109.9.m1.1a"><mi mathvariant="normal" id="S1.T1.109.109.109.9.m1.1.1" xref="S1.T1.109.109.109.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.109.109.109.9.m1.1b"><ci id="S1.T1.109.109.109.9.m1.1.1.cmml" xref="S1.T1.109.109.109.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.109.109.109.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.110.110.110.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.110.110.110.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.110.110.110.10.m1.1a"><mi mathvariant="normal" id="S1.T1.110.110.110.10.m1.1.1" xref="S1.T1.110.110.110.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.110.110.110.10.m1.1b"><ci id="S1.T1.110.110.110.10.m1.1.1.cmml" xref="S1.T1.110.110.110.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.110.110.110.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.120.120.120" class="ltx_tr">
<td id="S1.T1.120.120.120.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Homomorphic encryption</td>
<td id="S1.T1.111.111.111.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.111.111.111.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.111.111.111.1.m1.1a"><mo id="S1.T1.111.111.111.1.m1.1.1" xref="S1.T1.111.111.111.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.111.111.111.1.m1.1b"><times id="S1.T1.111.111.111.1.m1.1.1.cmml" xref="S1.T1.111.111.111.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.111.111.111.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.112.112.112.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.112.112.112.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.112.112.112.2.m1.1a"><mi mathvariant="normal" id="S1.T1.112.112.112.2.m1.1.1" xref="S1.T1.112.112.112.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.112.112.112.2.m1.1b"><ci id="S1.T1.112.112.112.2.m1.1.1.cmml" xref="S1.T1.112.112.112.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.112.112.112.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.113.113.113.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.113.113.113.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.113.113.113.3.m1.1a"><mi mathvariant="normal" id="S1.T1.113.113.113.3.m1.1.1" xref="S1.T1.113.113.113.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.113.113.113.3.m1.1b"><ci id="S1.T1.113.113.113.3.m1.1.1.cmml" xref="S1.T1.113.113.113.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.113.113.113.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.114.114.114.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.114.114.114.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.114.114.114.4.m1.1a"><mi mathvariant="normal" id="S1.T1.114.114.114.4.m1.1.1" xref="S1.T1.114.114.114.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.114.114.114.4.m1.1b"><ci id="S1.T1.114.114.114.4.m1.1.1.cmml" xref="S1.T1.114.114.114.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.114.114.114.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.115.115.115.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.115.115.115.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.115.115.115.5.m1.1a"><mo id="S1.T1.115.115.115.5.m1.1.1" xref="S1.T1.115.115.115.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.115.115.115.5.m1.1b"><times id="S1.T1.115.115.115.5.m1.1.1.cmml" xref="S1.T1.115.115.115.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.115.115.115.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.116.116.116.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.116.116.116.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.116.116.116.6.m1.1a"><mi mathvariant="normal" id="S1.T1.116.116.116.6.m1.1.1" xref="S1.T1.116.116.116.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.116.116.116.6.m1.1b"><ci id="S1.T1.116.116.116.6.m1.1.1.cmml" xref="S1.T1.116.116.116.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.116.116.116.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.117.117.117.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.117.117.117.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.117.117.117.7.m1.1a"><mi mathvariant="normal" id="S1.T1.117.117.117.7.m1.1.1" xref="S1.T1.117.117.117.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.117.117.117.7.m1.1b"><ci id="S1.T1.117.117.117.7.m1.1.1.cmml" xref="S1.T1.117.117.117.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.117.117.117.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.118.118.118.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.118.118.118.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.118.118.118.8.m1.1a"><mi mathvariant="normal" id="S1.T1.118.118.118.8.m1.1.1" xref="S1.T1.118.118.118.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.118.118.118.8.m1.1b"><ci id="S1.T1.118.118.118.8.m1.1.1.cmml" xref="S1.T1.118.118.118.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.118.118.118.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.119.119.119.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.119.119.119.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.119.119.119.9.m1.1a"><mi mathvariant="normal" id="S1.T1.119.119.119.9.m1.1.1" xref="S1.T1.119.119.119.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.119.119.119.9.m1.1b"><ci id="S1.T1.119.119.119.9.m1.1.1.cmml" xref="S1.T1.119.119.119.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.119.119.119.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.120.120.120.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.120.120.120.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.120.120.120.10.m1.1a"><mi mathvariant="normal" id="S1.T1.120.120.120.10.m1.1.1" xref="S1.T1.120.120.120.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.120.120.120.10.m1.1b"><ci id="S1.T1.120.120.120.10.m1.1.1.cmml" xref="S1.T1.120.120.120.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.120.120.120.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.130.130.130" class="ltx_tr">
<td id="S1.T1.130.130.130.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model Watermark</td>
<td id="S1.T1.121.121.121.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.121.121.121.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.121.121.121.1.m1.1a"><mo id="S1.T1.121.121.121.1.m1.1.1" xref="S1.T1.121.121.121.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.121.121.121.1.m1.1b"><times id="S1.T1.121.121.121.1.m1.1.1.cmml" xref="S1.T1.121.121.121.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.121.121.121.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.122.122.122.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.122.122.122.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.122.122.122.2.m1.1a"><mo id="S1.T1.122.122.122.2.m1.1.1" xref="S1.T1.122.122.122.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.122.122.122.2.m1.1b"><times id="S1.T1.122.122.122.2.m1.1.1.cmml" xref="S1.T1.122.122.122.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.122.122.122.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.123.123.123.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.123.123.123.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.123.123.123.3.m1.1a"><mo id="S1.T1.123.123.123.3.m1.1.1" xref="S1.T1.123.123.123.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.123.123.123.3.m1.1b"><times id="S1.T1.123.123.123.3.m1.1.1.cmml" xref="S1.T1.123.123.123.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.123.123.123.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.124.124.124.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.124.124.124.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.124.124.124.4.m1.1a"><mo id="S1.T1.124.124.124.4.m1.1.1" xref="S1.T1.124.124.124.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.124.124.124.4.m1.1b"><times id="S1.T1.124.124.124.4.m1.1.1.cmml" xref="S1.T1.124.124.124.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.124.124.124.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.125.125.125.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.125.125.125.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.125.125.125.5.m1.1a"><mo id="S1.T1.125.125.125.5.m1.1.1" xref="S1.T1.125.125.125.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.125.125.125.5.m1.1b"><times id="S1.T1.125.125.125.5.m1.1.1.cmml" xref="S1.T1.125.125.125.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.125.125.125.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.126.126.126.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.126.126.126.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.126.126.126.6.m1.1a"><mo id="S1.T1.126.126.126.6.m1.1.1" xref="S1.T1.126.126.126.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.126.126.126.6.m1.1b"><times id="S1.T1.126.126.126.6.m1.1.1.cmml" xref="S1.T1.126.126.126.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.126.126.126.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.127.127.127.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.127.127.127.7.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.127.127.127.7.m1.1a"><mo id="S1.T1.127.127.127.7.m1.1.1" xref="S1.T1.127.127.127.7.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.127.127.127.7.m1.1b"><times id="S1.T1.127.127.127.7.m1.1.1.cmml" xref="S1.T1.127.127.127.7.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.127.127.127.7.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.128.128.128.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.128.128.128.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.128.128.128.8.m1.1a"><mo id="S1.T1.128.128.128.8.m1.1.1" xref="S1.T1.128.128.128.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.128.128.128.8.m1.1b"><times id="S1.T1.128.128.128.8.m1.1.1.cmml" xref="S1.T1.128.128.128.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.128.128.128.8.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.129.129.129.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.129.129.129.9.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.129.129.129.9.m1.1a"><mo id="S1.T1.129.129.129.9.m1.1.1" xref="S1.T1.129.129.129.9.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.129.129.129.9.m1.1b"><times id="S1.T1.129.129.129.9.m1.1.1.cmml" xref="S1.T1.129.129.129.9.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.129.129.129.9.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.130.130.130.10" class="ltx_td ltx_align_center ltx_border_t"><math id="S1.T1.130.130.130.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.130.130.130.10.m1.1a"><mi mathvariant="normal" id="S1.T1.130.130.130.10.m1.1.1" xref="S1.T1.130.130.130.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.130.130.130.10.m1.1b"><ci id="S1.T1.130.130.130.10.m1.1.1.cmml" xref="S1.T1.130.130.130.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.130.130.130.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.140.140.140" class="ltx_tr">
<td id="S1.T1.140.140.140.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">Blockchain</td>
<td id="S1.T1.131.131.131.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.131.131.131.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.131.131.131.1.m1.1a"><mo id="S1.T1.131.131.131.1.m1.1.1" xref="S1.T1.131.131.131.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.131.131.131.1.m1.1b"><times id="S1.T1.131.131.131.1.m1.1.1.cmml" xref="S1.T1.131.131.131.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.131.131.131.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.132.132.132.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.132.132.132.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.132.132.132.2.m1.1a"><mo id="S1.T1.132.132.132.2.m1.1.1" xref="S1.T1.132.132.132.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.132.132.132.2.m1.1b"><times id="S1.T1.132.132.132.2.m1.1.1.cmml" xref="S1.T1.132.132.132.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.132.132.132.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.133.133.133.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.133.133.133.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.133.133.133.3.m1.1a"><mo id="S1.T1.133.133.133.3.m1.1.1" xref="S1.T1.133.133.133.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.133.133.133.3.m1.1b"><times id="S1.T1.133.133.133.3.m1.1.1.cmml" xref="S1.T1.133.133.133.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.133.133.133.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.134.134.134.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.134.134.134.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.134.134.134.4.m1.1a"><mo id="S1.T1.134.134.134.4.m1.1.1" xref="S1.T1.134.134.134.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.134.134.134.4.m1.1b"><times id="S1.T1.134.134.134.4.m1.1.1.cmml" xref="S1.T1.134.134.134.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.134.134.134.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.135.135.135.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.135.135.135.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.135.135.135.5.m1.1a"><mo id="S1.T1.135.135.135.5.m1.1.1" xref="S1.T1.135.135.135.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.135.135.135.5.m1.1b"><times id="S1.T1.135.135.135.5.m1.1.1.cmml" xref="S1.T1.135.135.135.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.135.135.135.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.136.136.136.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.136.136.136.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.136.136.136.6.m1.1a"><mo id="S1.T1.136.136.136.6.m1.1.1" xref="S1.T1.136.136.136.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.136.136.136.6.m1.1b"><times id="S1.T1.136.136.136.6.m1.1.1.cmml" xref="S1.T1.136.136.136.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.136.136.136.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.137.137.137.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.137.137.137.7.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.T1.137.137.137.7.m1.1a"><mo id="S1.T1.137.137.137.7.m1.1.1" xref="S1.T1.137.137.137.7.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.T1.137.137.137.7.m1.1b"><times id="S1.T1.137.137.137.7.m1.1.1.cmml" xref="S1.T1.137.137.137.7.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.137.137.137.7.m1.1c">\times</annotation></semantics></math></td>
<td id="S1.T1.138.138.138.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.138.138.138.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.138.138.138.8.m1.1a"><mi mathvariant="normal" id="S1.T1.138.138.138.8.m1.1.1" xref="S1.T1.138.138.138.8.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.138.138.138.8.m1.1b"><ci id="S1.T1.138.138.138.8.m1.1.1.cmml" xref="S1.T1.138.138.138.8.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.138.138.138.8.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.139.139.139.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S1.T1.139.139.139.9.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.139.139.139.9.m1.1a"><mi mathvariant="normal" id="S1.T1.139.139.139.9.m1.1.1" xref="S1.T1.139.139.139.9.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.139.139.139.9.m1.1b"><ci id="S1.T1.139.139.139.9.m1.1.1.cmml" xref="S1.T1.139.139.139.9.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.139.139.139.9.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.140.140.140.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S1.T1.140.140.140.10.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.140.140.140.10.m1.1a"><mi mathvariant="normal" id="S1.T1.140.140.140.10.m1.1.1" xref="S1.T1.140.140.140.10.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.140.140.140.10.m1.1b"><ci id="S1.T1.140.140.140.10.m1.1.1.cmml" xref="S1.T1.140.140.140.10.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.140.140.140.10.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Thus, the main contributions of this work are threefold:</p>
</div>
<div id="S1.p7" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We systematically categorize and analyze key components in heterogeneous FL, including data, model, task, communication, and device heterogeneity. For each type of heterogeneity, we discuss in detail the algorithmic challenges it raises.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We categorize existing state-of-the-art approaches into data-level, model-level, and architecture-level categories based on the level of processing, and discuss these classifications in depth.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We summarize the current privacy-preserving strategies in heterogeneous FL and explore possible future research directions with a view to promoting a safer and more efficient development of the field.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Classification and Challenges in Heterogeneous Federated Learning</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.10" class="ltx_p">In this section, we first provide a typical federation learning formulation to illustrate the typical federation learning process through an example. Federated learning is a machine learning setup in which multiple clients collaboratively train a model while protecting data privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Each participant trains the model on local data and then sends only updates to the model (e.g., weights or gradients) to a central server. The server aggregates these updates and sends the aggregated results back to the participants to update their local models in the next iteration. In this way, federated training produces a global model that performs well on the entire dataset without sharing any raw data.
In a classic FL framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, assuming that there are <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">K</annotation></semantics></math> clients participating in the training, for <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">k</annotation></semantics></math>-th client <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S2.p1.3.m3.1a"><msub id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">C</mi><mi id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">𝐶</ci><ci id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">C_{k}</annotation></semantics></math> has a private dataset <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="D_{k}=\left\{(x_{i}^{k},y_{i}^{k})\right\}_{i=1}^{N_{k}}" display="inline"><semantics id="S2.p1.4.m4.1a"><mrow id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><msub id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml"><mi id="S2.p1.4.m4.1.1.3.2" xref="S2.p1.4.m4.1.1.3.2.cmml">D</mi><mi id="S2.p1.4.m4.1.1.3.3" xref="S2.p1.4.m4.1.1.3.3.cmml">k</mi></msub><mo id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">=</mo><msubsup id="S2.p1.4.m4.1.1.1" xref="S2.p1.4.m4.1.1.1.cmml"><mrow id="S2.p1.4.m4.1.1.1.1.1.1" xref="S2.p1.4.m4.1.1.1.1.1.2.cmml"><mo id="S2.p1.4.m4.1.1.1.1.1.1.2" xref="S2.p1.4.m4.1.1.1.1.1.2.cmml">{</mo><mrow id="S2.p1.4.m4.1.1.1.1.1.1.1.2" xref="S2.p1.4.m4.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.p1.4.m4.1.1.1.1.1.1.1.2.3" xref="S2.p1.4.m4.1.1.1.1.1.1.1.3.cmml">(</mo><msubsup id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.3" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="S2.p1.4.m4.1.1.1.1.1.1.1.2.4" xref="S2.p1.4.m4.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2.cmml">y</mi><mi id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi><mi id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.3" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.p1.4.m4.1.1.1.1.1.1.1.2.5" xref="S2.p1.4.m4.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S2.p1.4.m4.1.1.1.1.1.1.3" xref="S2.p1.4.m4.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p1.4.m4.1.1.1.1.3" xref="S2.p1.4.m4.1.1.1.1.3.cmml"><mi id="S2.p1.4.m4.1.1.1.1.3.2" xref="S2.p1.4.m4.1.1.1.1.3.2.cmml">i</mi><mo id="S2.p1.4.m4.1.1.1.1.3.1" xref="S2.p1.4.m4.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p1.4.m4.1.1.1.1.3.3" xref="S2.p1.4.m4.1.1.1.1.3.3.cmml">1</mn></mrow><msub id="S2.p1.4.m4.1.1.1.3" xref="S2.p1.4.m4.1.1.1.3.cmml"><mi id="S2.p1.4.m4.1.1.1.3.2" xref="S2.p1.4.m4.1.1.1.3.2.cmml">N</mi><mi id="S2.p1.4.m4.1.1.1.3.3" xref="S2.p1.4.m4.1.1.1.3.3.cmml">k</mi></msub></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><eq id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2"></eq><apply id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.3.1.cmml" xref="S2.p1.4.m4.1.1.3">subscript</csymbol><ci id="S2.p1.4.m4.1.1.3.2.cmml" xref="S2.p1.4.m4.1.1.3.2">𝐷</ci><ci id="S2.p1.4.m4.1.1.3.3.cmml" xref="S2.p1.4.m4.1.1.3.3">𝑘</ci></apply><apply id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.2.cmml" xref="S2.p1.4.m4.1.1.1">superscript</csymbol><apply id="S2.p1.4.m4.1.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.1.2.cmml" xref="S2.p1.4.m4.1.1.1">subscript</csymbol><set id="S2.p1.4.m4.1.1.1.1.1.2.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1"><interval closure="open" id="S2.p1.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2"><apply id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2">𝑦</ci><ci id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply><ci id="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.p1.4.m4.1.1.1.1.1.1.1.2.2.3">𝑘</ci></apply></interval></set><apply id="S2.p1.4.m4.1.1.1.1.3.cmml" xref="S2.p1.4.m4.1.1.1.1.3"><eq id="S2.p1.4.m4.1.1.1.1.3.1.cmml" xref="S2.p1.4.m4.1.1.1.1.3.1"></eq><ci id="S2.p1.4.m4.1.1.1.1.3.2.cmml" xref="S2.p1.4.m4.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S2.p1.4.m4.1.1.1.1.3.3.cmml" xref="S2.p1.4.m4.1.1.1.1.3.3">1</cn></apply></apply><apply id="S2.p1.4.m4.1.1.1.3.cmml" xref="S2.p1.4.m4.1.1.1.3"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.3.1.cmml" xref="S2.p1.4.m4.1.1.1.3">subscript</csymbol><ci id="S2.p1.4.m4.1.1.1.3.2.cmml" xref="S2.p1.4.m4.1.1.1.3.2">𝑁</ci><ci id="S2.p1.4.m4.1.1.1.3.3.cmml" xref="S2.p1.4.m4.1.1.1.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">D_{k}=\left\{(x_{i}^{k},y_{i}^{k})\right\}_{i=1}^{N_{k}}</annotation></semantics></math> that satisfies <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="|x^{k}|=N_{k}" display="inline"><semantics id="S2.p1.5.m5.1a"><mrow id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mrow id="S2.p1.5.m5.1.1.1.1" xref="S2.p1.5.m5.1.1.1.2.cmml"><mo stretchy="false" id="S2.p1.5.m5.1.1.1.1.2" xref="S2.p1.5.m5.1.1.1.2.1.cmml">|</mo><msup id="S2.p1.5.m5.1.1.1.1.1" xref="S2.p1.5.m5.1.1.1.1.1.cmml"><mi id="S2.p1.5.m5.1.1.1.1.1.2" xref="S2.p1.5.m5.1.1.1.1.1.2.cmml">x</mi><mi id="S2.p1.5.m5.1.1.1.1.1.3" xref="S2.p1.5.m5.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S2.p1.5.m5.1.1.1.1.3" xref="S2.p1.5.m5.1.1.1.2.1.cmml">|</mo></mrow><mo id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml">=</mo><msub id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml"><mi id="S2.p1.5.m5.1.1.3.2" xref="S2.p1.5.m5.1.1.3.2.cmml">N</mi><mi id="S2.p1.5.m5.1.1.3.3" xref="S2.p1.5.m5.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><eq id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2"></eq><apply id="S2.p1.5.m5.1.1.1.2.cmml" xref="S2.p1.5.m5.1.1.1.1"><abs id="S2.p1.5.m5.1.1.1.2.1.cmml" xref="S2.p1.5.m5.1.1.1.1.2"></abs><apply id="S2.p1.5.m5.1.1.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1.1.1">superscript</csymbol><ci id="S2.p1.5.m5.1.1.1.1.1.2.cmml" xref="S2.p1.5.m5.1.1.1.1.1.2">𝑥</ci><ci id="S2.p1.5.m5.1.1.1.1.1.3.cmml" xref="S2.p1.5.m5.1.1.1.1.1.3">𝑘</ci></apply></apply><apply id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.3.1.cmml" xref="S2.p1.5.m5.1.1.3">subscript</csymbol><ci id="S2.p1.5.m5.1.1.3.2.cmml" xref="S2.p1.5.m5.1.1.3.2">𝑁</ci><ci id="S2.p1.5.m5.1.1.3.3.cmml" xref="S2.p1.5.m5.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">|x^{k}|=N_{k}</annotation></semantics></math> and <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="N=\sum_{k=1}^{K}N_{k}" display="inline"><semantics id="S2.p1.6.m6.1a"><mrow id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">N</mi><mo rspace="0.111em" id="S2.p1.6.m6.1.1.1" xref="S2.p1.6.m6.1.1.1.cmml">=</mo><mrow id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml"><msubsup id="S2.p1.6.m6.1.1.3.1" xref="S2.p1.6.m6.1.1.3.1.cmml"><mo id="S2.p1.6.m6.1.1.3.1.2.2" xref="S2.p1.6.m6.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.p1.6.m6.1.1.3.1.2.3" xref="S2.p1.6.m6.1.1.3.1.2.3.cmml"><mi id="S2.p1.6.m6.1.1.3.1.2.3.2" xref="S2.p1.6.m6.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.p1.6.m6.1.1.3.1.2.3.1" xref="S2.p1.6.m6.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.p1.6.m6.1.1.3.1.2.3.3" xref="S2.p1.6.m6.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.p1.6.m6.1.1.3.1.3" xref="S2.p1.6.m6.1.1.3.1.3.cmml">K</mi></msubsup><msub id="S2.p1.6.m6.1.1.3.2" xref="S2.p1.6.m6.1.1.3.2.cmml"><mi id="S2.p1.6.m6.1.1.3.2.2" xref="S2.p1.6.m6.1.1.3.2.2.cmml">N</mi><mi id="S2.p1.6.m6.1.1.3.2.3" xref="S2.p1.6.m6.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><eq id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1.1"></eq><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">𝑁</ci><apply id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3"><apply id="S2.p1.6.m6.1.1.3.1.cmml" xref="S2.p1.6.m6.1.1.3.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.3.1.1.cmml" xref="S2.p1.6.m6.1.1.3.1">superscript</csymbol><apply id="S2.p1.6.m6.1.1.3.1.2.cmml" xref="S2.p1.6.m6.1.1.3.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.3.1.2.1.cmml" xref="S2.p1.6.m6.1.1.3.1">subscript</csymbol><sum id="S2.p1.6.m6.1.1.3.1.2.2.cmml" xref="S2.p1.6.m6.1.1.3.1.2.2"></sum><apply id="S2.p1.6.m6.1.1.3.1.2.3.cmml" xref="S2.p1.6.m6.1.1.3.1.2.3"><eq id="S2.p1.6.m6.1.1.3.1.2.3.1.cmml" xref="S2.p1.6.m6.1.1.3.1.2.3.1"></eq><ci id="S2.p1.6.m6.1.1.3.1.2.3.2.cmml" xref="S2.p1.6.m6.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.p1.6.m6.1.1.3.1.2.3.3.cmml" xref="S2.p1.6.m6.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.p1.6.m6.1.1.3.1.3.cmml" xref="S2.p1.6.m6.1.1.3.1.3">𝐾</ci></apply><apply id="S2.p1.6.m6.1.1.3.2.cmml" xref="S2.p1.6.m6.1.1.3.2"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.3.2.1.cmml" xref="S2.p1.6.m6.1.1.3.2">subscript</csymbol><ci id="S2.p1.6.m6.1.1.3.2.2.cmml" xref="S2.p1.6.m6.1.1.3.2.2">𝑁</ci><ci id="S2.p1.6.m6.1.1.3.2.3.cmml" xref="S2.p1.6.m6.1.1.3.2.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">N=\sum_{k=1}^{K}N_{k}</annotation></semantics></math>. The local distribution of the data of client <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p1.7.m7.1a"><mi id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><ci id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">k</annotation></semantics></math> is denoted as <math id="S2.p1.8.m8.2" class="ltx_Math" alttext="P_{k}(x,y)" display="inline"><semantics id="S2.p1.8.m8.2a"><mrow id="S2.p1.8.m8.2.3" xref="S2.p1.8.m8.2.3.cmml"><msub id="S2.p1.8.m8.2.3.2" xref="S2.p1.8.m8.2.3.2.cmml"><mi id="S2.p1.8.m8.2.3.2.2" xref="S2.p1.8.m8.2.3.2.2.cmml">P</mi><mi id="S2.p1.8.m8.2.3.2.3" xref="S2.p1.8.m8.2.3.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.2.3.1" xref="S2.p1.8.m8.2.3.1.cmml">​</mo><mrow id="S2.p1.8.m8.2.3.3.2" xref="S2.p1.8.m8.2.3.3.1.cmml"><mo stretchy="false" id="S2.p1.8.m8.2.3.3.2.1" xref="S2.p1.8.m8.2.3.3.1.cmml">(</mo><mi id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml">x</mi><mo id="S2.p1.8.m8.2.3.3.2.2" xref="S2.p1.8.m8.2.3.3.1.cmml">,</mo><mi id="S2.p1.8.m8.2.2" xref="S2.p1.8.m8.2.2.cmml">y</mi><mo stretchy="false" id="S2.p1.8.m8.2.3.3.2.3" xref="S2.p1.8.m8.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.2b"><apply id="S2.p1.8.m8.2.3.cmml" xref="S2.p1.8.m8.2.3"><times id="S2.p1.8.m8.2.3.1.cmml" xref="S2.p1.8.m8.2.3.1"></times><apply id="S2.p1.8.m8.2.3.2.cmml" xref="S2.p1.8.m8.2.3.2"><csymbol cd="ambiguous" id="S2.p1.8.m8.2.3.2.1.cmml" xref="S2.p1.8.m8.2.3.2">subscript</csymbol><ci id="S2.p1.8.m8.2.3.2.2.cmml" xref="S2.p1.8.m8.2.3.2.2">𝑃</ci><ci id="S2.p1.8.m8.2.3.2.3.cmml" xref="S2.p1.8.m8.2.3.2.3">𝑘</ci></apply><interval closure="open" id="S2.p1.8.m8.2.3.3.1.cmml" xref="S2.p1.8.m8.2.3.3.2"><ci id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1">𝑥</ci><ci id="S2.p1.8.m8.2.2.cmml" xref="S2.p1.8.m8.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.2c">P_{k}(x,y)</annotation></semantics></math>, where <math id="S2.p1.9.m9.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p1.9.m9.1a"><mi id="S2.p1.9.m9.1.1" xref="S2.p1.9.m9.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.1b"><ci id="S2.p1.9.m9.1.1.cmml" xref="S2.p1.9.m9.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.1c">x</annotation></semantics></math> and <math id="S2.p1.10.m10.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p1.10.m10.1a"><mi id="S2.p1.10.m10.1.1" xref="S2.p1.10.m10.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p1.10.m10.1b"><ci id="S2.p1.10.m10.1.1.cmml" xref="S2.p1.10.m10.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m10.1c">y</annotation></semantics></math> denote the features of the data samples and the labels.
Specifically, FL can be formally defined as the following optimization problem:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\min_{\theta}F(\theta)=\sum_{k=1}^{K}p_{k}F_{k}(\theta)" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.3" xref="S2.E1.m1.2.3.cmml"><mrow id="S2.E1.m1.2.3.2" xref="S2.E1.m1.2.3.2.cmml"><mrow id="S2.E1.m1.2.3.2.2" xref="S2.E1.m1.2.3.2.2.cmml"><munder id="S2.E1.m1.2.3.2.2.1" xref="S2.E1.m1.2.3.2.2.1.cmml"><mi id="S2.E1.m1.2.3.2.2.1.2" xref="S2.E1.m1.2.3.2.2.1.2.cmml">min</mi><mi id="S2.E1.m1.2.3.2.2.1.3" xref="S2.E1.m1.2.3.2.2.1.3.cmml">θ</mi></munder><mo lspace="0.167em" id="S2.E1.m1.2.3.2.2a" xref="S2.E1.m1.2.3.2.2.cmml">⁡</mo><mi id="S2.E1.m1.2.3.2.2.2" xref="S2.E1.m1.2.3.2.2.2.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.2.1" xref="S2.E1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.E1.m1.2.3.2.3.2" xref="S2.E1.m1.2.3.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.3.2.3.2.1" xref="S2.E1.m1.2.3.2.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">θ</mi><mo stretchy="false" id="S2.E1.m1.2.3.2.3.2.2" xref="S2.E1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.E1.m1.2.3.1" xref="S2.E1.m1.2.3.1.cmml">=</mo><mrow id="S2.E1.m1.2.3.3" xref="S2.E1.m1.2.3.3.cmml"><munderover id="S2.E1.m1.2.3.3.1" xref="S2.E1.m1.2.3.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.2.3.3.1.2.2" xref="S2.E1.m1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.2.3.3.1.2.3" xref="S2.E1.m1.2.3.3.1.2.3.cmml"><mi id="S2.E1.m1.2.3.3.1.2.3.2" xref="S2.E1.m1.2.3.3.1.2.3.2.cmml">k</mi><mo id="S2.E1.m1.2.3.3.1.2.3.1" xref="S2.E1.m1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.2.3.3.1.2.3.3" xref="S2.E1.m1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.2.3.3.1.3" xref="S2.E1.m1.2.3.3.1.3.cmml">K</mi></munderover><mrow id="S2.E1.m1.2.3.3.2" xref="S2.E1.m1.2.3.3.2.cmml"><msub id="S2.E1.m1.2.3.3.2.2" xref="S2.E1.m1.2.3.3.2.2.cmml"><mi id="S2.E1.m1.2.3.3.2.2.2" xref="S2.E1.m1.2.3.3.2.2.2.cmml">p</mi><mi id="S2.E1.m1.2.3.3.2.2.3" xref="S2.E1.m1.2.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.3.2.1" xref="S2.E1.m1.2.3.3.2.1.cmml">​</mo><msub id="S2.E1.m1.2.3.3.2.3" xref="S2.E1.m1.2.3.3.2.3.cmml"><mi id="S2.E1.m1.2.3.3.2.3.2" xref="S2.E1.m1.2.3.3.2.3.2.cmml">F</mi><mi id="S2.E1.m1.2.3.3.2.3.3" xref="S2.E1.m1.2.3.3.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.3.2.1a" xref="S2.E1.m1.2.3.3.2.1.cmml">​</mo><mrow id="S2.E1.m1.2.3.3.2.4.2" xref="S2.E1.m1.2.3.3.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.3.3.2.4.2.1" xref="S2.E1.m1.2.3.3.2.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">θ</mi><mo stretchy="false" id="S2.E1.m1.2.3.3.2.4.2.2" xref="S2.E1.m1.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.3.cmml" xref="S2.E1.m1.2.3"><eq id="S2.E1.m1.2.3.1.cmml" xref="S2.E1.m1.2.3.1"></eq><apply id="S2.E1.m1.2.3.2.cmml" xref="S2.E1.m1.2.3.2"><times id="S2.E1.m1.2.3.2.1.cmml" xref="S2.E1.m1.2.3.2.1"></times><apply id="S2.E1.m1.2.3.2.2.cmml" xref="S2.E1.m1.2.3.2.2"><apply id="S2.E1.m1.2.3.2.2.1.cmml" xref="S2.E1.m1.2.3.2.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.2.2.1.1.cmml" xref="S2.E1.m1.2.3.2.2.1">subscript</csymbol><min id="S2.E1.m1.2.3.2.2.1.2.cmml" xref="S2.E1.m1.2.3.2.2.1.2"></min><ci id="S2.E1.m1.2.3.2.2.1.3.cmml" xref="S2.E1.m1.2.3.2.2.1.3">𝜃</ci></apply><ci id="S2.E1.m1.2.3.2.2.2.cmml" xref="S2.E1.m1.2.3.2.2.2">𝐹</ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝜃</ci></apply><apply id="S2.E1.m1.2.3.3.cmml" xref="S2.E1.m1.2.3.3"><apply id="S2.E1.m1.2.3.3.1.cmml" xref="S2.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.1.1.cmml" xref="S2.E1.m1.2.3.3.1">superscript</csymbol><apply id="S2.E1.m1.2.3.3.1.2.cmml" xref="S2.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.1.2.1.cmml" xref="S2.E1.m1.2.3.3.1">subscript</csymbol><sum id="S2.E1.m1.2.3.3.1.2.2.cmml" xref="S2.E1.m1.2.3.3.1.2.2"></sum><apply id="S2.E1.m1.2.3.3.1.2.3.cmml" xref="S2.E1.m1.2.3.3.1.2.3"><eq id="S2.E1.m1.2.3.3.1.2.3.1.cmml" xref="S2.E1.m1.2.3.3.1.2.3.1"></eq><ci id="S2.E1.m1.2.3.3.1.2.3.2.cmml" xref="S2.E1.m1.2.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.E1.m1.2.3.3.1.2.3.3.cmml" xref="S2.E1.m1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.2.3.3.1.3.cmml" xref="S2.E1.m1.2.3.3.1.3">𝐾</ci></apply><apply id="S2.E1.m1.2.3.3.2.cmml" xref="S2.E1.m1.2.3.3.2"><times id="S2.E1.m1.2.3.3.2.1.cmml" xref="S2.E1.m1.2.3.3.2.1"></times><apply id="S2.E1.m1.2.3.3.2.2.cmml" xref="S2.E1.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.2.2.1.cmml" xref="S2.E1.m1.2.3.3.2.2">subscript</csymbol><ci id="S2.E1.m1.2.3.3.2.2.2.cmml" xref="S2.E1.m1.2.3.3.2.2.2">𝑝</ci><ci id="S2.E1.m1.2.3.3.2.2.3.cmml" xref="S2.E1.m1.2.3.3.2.2.3">𝑘</ci></apply><apply id="S2.E1.m1.2.3.3.2.3.cmml" xref="S2.E1.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.2.3.1.cmml" xref="S2.E1.m1.2.3.3.2.3">subscript</csymbol><ci id="S2.E1.m1.2.3.3.2.3.2.cmml" xref="S2.E1.m1.2.3.3.2.3.2">𝐹</ci><ci id="S2.E1.m1.2.3.3.2.3.3.cmml" xref="S2.E1.m1.2.3.3.2.3.3">𝑘</ci></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝜃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\min_{\theta}F(\theta)=\sum_{k=1}^{K}p_{k}F_{k}(\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p1.16" class="ltx_p">where <math id="S2.p1.11.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.p1.11.m1.1a"><mi id="S2.p1.11.m1.1.1" xref="S2.p1.11.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.11.m1.1b"><ci id="S2.p1.11.m1.1.1.cmml" xref="S2.p1.11.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m1.1c">\theta</annotation></semantics></math> is the global model parameter. <math id="S2.p1.12.m2.1" class="ltx_Math" alttext="F_{k}(\theta)" display="inline"><semantics id="S2.p1.12.m2.1a"><mrow id="S2.p1.12.m2.1.2" xref="S2.p1.12.m2.1.2.cmml"><msub id="S2.p1.12.m2.1.2.2" xref="S2.p1.12.m2.1.2.2.cmml"><mi id="S2.p1.12.m2.1.2.2.2" xref="S2.p1.12.m2.1.2.2.2.cmml">F</mi><mi id="S2.p1.12.m2.1.2.2.3" xref="S2.p1.12.m2.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.p1.12.m2.1.2.1" xref="S2.p1.12.m2.1.2.1.cmml">​</mo><mrow id="S2.p1.12.m2.1.2.3.2" xref="S2.p1.12.m2.1.2.cmml"><mo stretchy="false" id="S2.p1.12.m2.1.2.3.2.1" xref="S2.p1.12.m2.1.2.cmml">(</mo><mi id="S2.p1.12.m2.1.1" xref="S2.p1.12.m2.1.1.cmml">θ</mi><mo stretchy="false" id="S2.p1.12.m2.1.2.3.2.2" xref="S2.p1.12.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.12.m2.1b"><apply id="S2.p1.12.m2.1.2.cmml" xref="S2.p1.12.m2.1.2"><times id="S2.p1.12.m2.1.2.1.cmml" xref="S2.p1.12.m2.1.2.1"></times><apply id="S2.p1.12.m2.1.2.2.cmml" xref="S2.p1.12.m2.1.2.2"><csymbol cd="ambiguous" id="S2.p1.12.m2.1.2.2.1.cmml" xref="S2.p1.12.m2.1.2.2">subscript</csymbol><ci id="S2.p1.12.m2.1.2.2.2.cmml" xref="S2.p1.12.m2.1.2.2.2">𝐹</ci><ci id="S2.p1.12.m2.1.2.2.3.cmml" xref="S2.p1.12.m2.1.2.2.3">𝑘</ci></apply><ci id="S2.p1.12.m2.1.1.cmml" xref="S2.p1.12.m2.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.12.m2.1c">F_{k}(\theta)</annotation></semantics></math> is the local loss function on client <math id="S2.p1.13.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p1.13.m3.1a"><mi id="S2.p1.13.m3.1.1" xref="S2.p1.13.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p1.13.m3.1b"><ci id="S2.p1.13.m3.1.1.cmml" xref="S2.p1.13.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.13.m3.1c">k</annotation></semantics></math>, which reflects the performance of the model on that client. <math id="S2.p1.14.m4.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S2.p1.14.m4.1a"><msub id="S2.p1.14.m4.1.1" xref="S2.p1.14.m4.1.1.cmml"><mi id="S2.p1.14.m4.1.1.2" xref="S2.p1.14.m4.1.1.2.cmml">p</mi><mi id="S2.p1.14.m4.1.1.3" xref="S2.p1.14.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.14.m4.1b"><apply id="S2.p1.14.m4.1.1.cmml" xref="S2.p1.14.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.14.m4.1.1.1.cmml" xref="S2.p1.14.m4.1.1">subscript</csymbol><ci id="S2.p1.14.m4.1.1.2.cmml" xref="S2.p1.14.m4.1.1.2">𝑝</ci><ci id="S2.p1.14.m4.1.1.3.cmml" xref="S2.p1.14.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.14.m4.1c">p_{k}</annotation></semantics></math> is the client weight, the value of which depends on the amount of data on the client and fulfills <math id="S2.p1.15.m5.1" class="ltx_Math" alttext="p_{k}=\frac{N_{k}}{N}" display="inline"><semantics id="S2.p1.15.m5.1a"><mrow id="S2.p1.15.m5.1.1" xref="S2.p1.15.m5.1.1.cmml"><msub id="S2.p1.15.m5.1.1.2" xref="S2.p1.15.m5.1.1.2.cmml"><mi id="S2.p1.15.m5.1.1.2.2" xref="S2.p1.15.m5.1.1.2.2.cmml">p</mi><mi id="S2.p1.15.m5.1.1.2.3" xref="S2.p1.15.m5.1.1.2.3.cmml">k</mi></msub><mo id="S2.p1.15.m5.1.1.1" xref="S2.p1.15.m5.1.1.1.cmml">=</mo><mfrac id="S2.p1.15.m5.1.1.3" xref="S2.p1.15.m5.1.1.3.cmml"><msub id="S2.p1.15.m5.1.1.3.2" xref="S2.p1.15.m5.1.1.3.2.cmml"><mi id="S2.p1.15.m5.1.1.3.2.2" xref="S2.p1.15.m5.1.1.3.2.2.cmml">N</mi><mi id="S2.p1.15.m5.1.1.3.2.3" xref="S2.p1.15.m5.1.1.3.2.3.cmml">k</mi></msub><mi id="S2.p1.15.m5.1.1.3.3" xref="S2.p1.15.m5.1.1.3.3.cmml">N</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.15.m5.1b"><apply id="S2.p1.15.m5.1.1.cmml" xref="S2.p1.15.m5.1.1"><eq id="S2.p1.15.m5.1.1.1.cmml" xref="S2.p1.15.m5.1.1.1"></eq><apply id="S2.p1.15.m5.1.1.2.cmml" xref="S2.p1.15.m5.1.1.2"><csymbol cd="ambiguous" id="S2.p1.15.m5.1.1.2.1.cmml" xref="S2.p1.15.m5.1.1.2">subscript</csymbol><ci id="S2.p1.15.m5.1.1.2.2.cmml" xref="S2.p1.15.m5.1.1.2.2">𝑝</ci><ci id="S2.p1.15.m5.1.1.2.3.cmml" xref="S2.p1.15.m5.1.1.2.3">𝑘</ci></apply><apply id="S2.p1.15.m5.1.1.3.cmml" xref="S2.p1.15.m5.1.1.3"><divide id="S2.p1.15.m5.1.1.3.1.cmml" xref="S2.p1.15.m5.1.1.3"></divide><apply id="S2.p1.15.m5.1.1.3.2.cmml" xref="S2.p1.15.m5.1.1.3.2"><csymbol cd="ambiguous" id="S2.p1.15.m5.1.1.3.2.1.cmml" xref="S2.p1.15.m5.1.1.3.2">subscript</csymbol><ci id="S2.p1.15.m5.1.1.3.2.2.cmml" xref="S2.p1.15.m5.1.1.3.2.2">𝑁</ci><ci id="S2.p1.15.m5.1.1.3.2.3.cmml" xref="S2.p1.15.m5.1.1.3.2.3">𝑘</ci></apply><ci id="S2.p1.15.m5.1.1.3.3.cmml" xref="S2.p1.15.m5.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.15.m5.1c">p_{k}=\frac{N_{k}}{N}</annotation></semantics></math> and <math id="S2.p1.16.m6.1" class="ltx_Math" alttext="\sum_{k=1}^{K}p_{k}=1" display="inline"><semantics id="S2.p1.16.m6.1a"><mrow id="S2.p1.16.m6.1.1" xref="S2.p1.16.m6.1.1.cmml"><mrow id="S2.p1.16.m6.1.1.2" xref="S2.p1.16.m6.1.1.2.cmml"><msubsup id="S2.p1.16.m6.1.1.2.1" xref="S2.p1.16.m6.1.1.2.1.cmml"><mo id="S2.p1.16.m6.1.1.2.1.2.2" xref="S2.p1.16.m6.1.1.2.1.2.2.cmml">∑</mo><mrow id="S2.p1.16.m6.1.1.2.1.2.3" xref="S2.p1.16.m6.1.1.2.1.2.3.cmml"><mi id="S2.p1.16.m6.1.1.2.1.2.3.2" xref="S2.p1.16.m6.1.1.2.1.2.3.2.cmml">k</mi><mo id="S2.p1.16.m6.1.1.2.1.2.3.1" xref="S2.p1.16.m6.1.1.2.1.2.3.1.cmml">=</mo><mn id="S2.p1.16.m6.1.1.2.1.2.3.3" xref="S2.p1.16.m6.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S2.p1.16.m6.1.1.2.1.3" xref="S2.p1.16.m6.1.1.2.1.3.cmml">K</mi></msubsup><msub id="S2.p1.16.m6.1.1.2.2" xref="S2.p1.16.m6.1.1.2.2.cmml"><mi id="S2.p1.16.m6.1.1.2.2.2" xref="S2.p1.16.m6.1.1.2.2.2.cmml">p</mi><mi id="S2.p1.16.m6.1.1.2.2.3" xref="S2.p1.16.m6.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S2.p1.16.m6.1.1.1" xref="S2.p1.16.m6.1.1.1.cmml">=</mo><mn id="S2.p1.16.m6.1.1.3" xref="S2.p1.16.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.16.m6.1b"><apply id="S2.p1.16.m6.1.1.cmml" xref="S2.p1.16.m6.1.1"><eq id="S2.p1.16.m6.1.1.1.cmml" xref="S2.p1.16.m6.1.1.1"></eq><apply id="S2.p1.16.m6.1.1.2.cmml" xref="S2.p1.16.m6.1.1.2"><apply id="S2.p1.16.m6.1.1.2.1.cmml" xref="S2.p1.16.m6.1.1.2.1"><csymbol cd="ambiguous" id="S2.p1.16.m6.1.1.2.1.1.cmml" xref="S2.p1.16.m6.1.1.2.1">superscript</csymbol><apply id="S2.p1.16.m6.1.1.2.1.2.cmml" xref="S2.p1.16.m6.1.1.2.1"><csymbol cd="ambiguous" id="S2.p1.16.m6.1.1.2.1.2.1.cmml" xref="S2.p1.16.m6.1.1.2.1">subscript</csymbol><sum id="S2.p1.16.m6.1.1.2.1.2.2.cmml" xref="S2.p1.16.m6.1.1.2.1.2.2"></sum><apply id="S2.p1.16.m6.1.1.2.1.2.3.cmml" xref="S2.p1.16.m6.1.1.2.1.2.3"><eq id="S2.p1.16.m6.1.1.2.1.2.3.1.cmml" xref="S2.p1.16.m6.1.1.2.1.2.3.1"></eq><ci id="S2.p1.16.m6.1.1.2.1.2.3.2.cmml" xref="S2.p1.16.m6.1.1.2.1.2.3.2">𝑘</ci><cn type="integer" id="S2.p1.16.m6.1.1.2.1.2.3.3.cmml" xref="S2.p1.16.m6.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S2.p1.16.m6.1.1.2.1.3.cmml" xref="S2.p1.16.m6.1.1.2.1.3">𝐾</ci></apply><apply id="S2.p1.16.m6.1.1.2.2.cmml" xref="S2.p1.16.m6.1.1.2.2"><csymbol cd="ambiguous" id="S2.p1.16.m6.1.1.2.2.1.cmml" xref="S2.p1.16.m6.1.1.2.2">subscript</csymbol><ci id="S2.p1.16.m6.1.1.2.2.2.cmml" xref="S2.p1.16.m6.1.1.2.2.2">𝑝</ci><ci id="S2.p1.16.m6.1.1.2.2.3.cmml" xref="S2.p1.16.m6.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S2.p1.16.m6.1.1.3.cmml" xref="S2.p1.16.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.16.m6.1c">\sum_{k=1}^{K}p_{k}=1</annotation></semantics></math>.
Therefore, the training process of FL can be represented as the following steps:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Initialization:</span> The server initializes the global model parameters <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">\theta</annotation></semantics></math> and sends them to all participating clients.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.3" class="ltx_p"><span id="S2.I1.i2.p1.3.1" class="ltx_text ltx_font_bold">Local training:</span> Each client <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">k</annotation></semantics></math> trains its own model using its local data and the received global model parameters <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><mi id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><ci id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">\theta</annotation></semantics></math>, and computes updates <math id="S2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="\Delta\theta_{k}" display="inline"><semantics id="S2.I1.i2.p1.3.m3.1a"><mrow id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml"><mi mathvariant="normal" id="S2.I1.i2.p1.3.m3.1.1.2" xref="S2.I1.i2.p1.3.m3.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.3.m3.1.1.1" xref="S2.I1.i2.p1.3.m3.1.1.1.cmml">​</mo><msub id="S2.I1.i2.p1.3.m3.1.1.3" xref="S2.I1.i2.p1.3.m3.1.1.3.cmml"><mi id="S2.I1.i2.p1.3.m3.1.1.3.2" xref="S2.I1.i2.p1.3.m3.1.1.3.2.cmml">θ</mi><mi id="S2.I1.i2.p1.3.m3.1.1.3.3" xref="S2.I1.i2.p1.3.m3.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.1b"><apply id="S2.I1.i2.p1.3.m3.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><times id="S2.I1.i2.p1.3.m3.1.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1.1"></times><ci id="S2.I1.i2.p1.3.m3.1.1.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2">Δ</ci><apply id="S2.I1.i2.p1.3.m3.1.1.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.3.m3.1.1.3.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3">subscript</csymbol><ci id="S2.I1.i2.p1.3.m3.1.1.3.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3.2">𝜃</ci><ci id="S2.I1.i2.p1.3.m3.1.1.3.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.1c">\Delta\theta_{k}</annotation></semantics></math> to the model parameters.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.3" class="ltx_p"><span id="S2.I1.i3.p1.3.1" class="ltx_text ltx_font_bold">Parameter aggregation:</span> All clients send their model parameters <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\theta_{k}" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><msub id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">θ</mi><mi id="S2.I1.i3.p1.1.m1.1.1.3" xref="S2.I1.i3.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">𝜃</ci><ci id="S2.I1.i3.p1.1.m1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">\theta_{k}</annotation></semantics></math> or gradient updates <math id="S2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="\Delta\theta_{k}" display="inline"><semantics id="S2.I1.i3.p1.2.m2.1a"><mrow id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.2.m2.1.1.1" xref="S2.I1.i3.p1.2.m2.1.1.1.cmml">​</mo><msub id="S2.I1.i3.p1.2.m2.1.1.3" xref="S2.I1.i3.p1.2.m2.1.1.3.cmml"><mi id="S2.I1.i3.p1.2.m2.1.1.3.2" xref="S2.I1.i3.p1.2.m2.1.1.3.2.cmml">θ</mi><mi id="S2.I1.i3.p1.2.m2.1.1.3.3" xref="S2.I1.i3.p1.2.m2.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><times id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.1"></times><ci id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">Δ</ci><apply id="S2.I1.i3.p1.2.m2.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.1.1.3.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.1.1.3.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3.2">𝜃</ci><ci id="S2.I1.i3.p1.2.m2.1.1.3.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">\Delta\theta_{k}</annotation></semantics></math> back to the central server. The server aggregates these updates based on the weights <math id="S2.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S2.I1.i3.p1.3.m3.1a"><msub id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml"><mi id="S2.I1.i3.p1.3.m3.1.1.2" xref="S2.I1.i3.p1.3.m3.1.1.2.cmml">p</mi><mi id="S2.I1.i3.p1.3.m3.1.1.3" xref="S2.I1.i3.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.1b"><apply id="S2.I1.i3.p1.3.m3.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.3.m3.1.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.3.m3.1.1.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.2">𝑝</ci><ci id="S2.I1.i3.p1.3.m3.1.1.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.1c">p_{k}</annotation></semantics></math> of each client to update the global model.</p>
<table id="S2.E2" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E2X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E2X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{Model\ parameters:}\theta\leftarrow\sum_{k=1}^{N}p_{k}\theta_{k}," display="inline"><semantics id="S2.E2X.2.1.1.m1.1a"><mrow id="S2.E2X.2.1.1.m1.1.1.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S2.E2X.2.1.1.m1.1.1.1.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S2.E2X.2.1.1.m1.1.1.1.1.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.1.1.2.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.2.cmml">Model</mi><mo lspace="0.500em" rspace="0em" id="S2.E2X.2.1.1.m1.1.1.1.1.2.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.1.cmml">​</mo><mi id="S2.E2X.2.1.1.m1.1.1.1.1.2.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.3.cmml">parameters</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S2.E2X.2.1.1.m1.1.1.1.1.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.1.cmml">:</mo><mrow id="S2.E2X.2.1.1.m1.1.1.1.1.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.2.cmml">θ</mi><mo stretchy="false" id="S2.E2X.2.1.1.m1.1.1.1.1.3.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.1.cmml">←</mo><mrow id="S2.E2X.2.1.1.m1.1.1.1.1.3.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.cmml"><mstyle displaystyle="true" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.cmml"><munderover id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1a" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.cmml"><mo movablelimits="false" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.2.cmml">k</mi><mo id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.3.cmml">N</mi></munderover></mstyle><mrow id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.cmml"><msub id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.2.cmml">p</mi><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.1" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.1.cmml">​</mo><msub id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.2.cmml">θ</mi><mi id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.3" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.3.cmml">k</mi></msub></mrow></mrow></mrow></mrow><mo id="S2.E2X.2.1.1.m1.1.1.1.2" xref="S2.E2X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2X.2.1.1.m1.1b"><apply id="S2.E2X.2.1.1.m1.1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1"><ci id="S2.E2X.2.1.1.m1.1.1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.1">:</ci><apply id="S2.E2X.2.1.1.m1.1.1.1.1.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.2"><times id="S2.E2X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.1"></times><ci id="S2.E2X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.2">Model</ci><ci id="S2.E2X.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.2.3">parameters</ci></apply><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3"><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.1">←</ci><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.2">𝜃</ci><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3"><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1">superscript</csymbol><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.2"></sum><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3"><eq id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.1"></eq><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.1.3">𝑁</ci></apply><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2"><times id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.1"></times><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.2">𝑝</ci><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.2.3">𝑘</ci></apply><apply id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.2">𝜃</ci><ci id="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.1.1.3.3.2.3.3">𝑘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2X.2.1.1.m1.1c">\displaystyle\mathrm{Model\ parameters:}\theta\leftarrow\sum_{k=1}^{N}p_{k}\theta_{k},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
<tr id="S2.E2Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E2Xa.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{\textbf{or}\ Model\ gradient:}\theta\leftarrow\theta+\sum_{k=1}^{N}p_{k}\Delta\theta_{k}." display="inline"><semantics id="S2.E2Xa.2.1.1.m1.1a"><mrow id="S2.E2Xa.2.1.1.m1.1.1.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.cmml"><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.cmml"><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.2a.cmml">or</mtext><mo lspace="0.500em" rspace="0em" id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.1.cmml">​</mo><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.3.cmml">Model</mi><mo lspace="0.500em" rspace="0em" id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.1a" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.1.cmml">​</mo><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.4" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.4.cmml">gradient</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S2.E2Xa.2.1.1.m1.1.1.1.1.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.1.cmml">:</mo><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.cmml"><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.2.cmml">θ</mi><mo stretchy="false" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.1.cmml">←</mo><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.cmml"><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.2.cmml">θ</mi><mo id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.1.cmml">+</mo><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.cmml"><mstyle displaystyle="true" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.cmml"><munderover id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1a" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.cmml"><mo movablelimits="false" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.2.cmml">∑</mo><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.cmml"><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.2.cmml">k</mi><mo id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.1.cmml">=</mo><mn id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.3.cmml">N</mi></munderover></mstyle><mrow id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.cmml"><msub id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.cmml"><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.2.cmml">p</mi><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.1" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.3.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.1a" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.1.cmml">​</mo><msub id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.cmml"><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.2.cmml">θ</mi><mi id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.3" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.3.cmml">k</mi></msub></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S2.E2Xa.2.1.1.m1.1.1.1.2" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2Xa.2.1.1.m1.1b"><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1"><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.1">:</ci><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2"><times id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.1"></times><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.2a.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.2">or</mtext></ci><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.3">Model</ci><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.2.4.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.2.4">gradient</ci></apply><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3"><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.1">←</ci><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.2">𝜃</ci><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3"><plus id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.1"></plus><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.2">𝜃</ci><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3"><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1">superscript</csymbol><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1">subscript</csymbol><sum id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.2"></sum><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3"><eq id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.1"></eq><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.1.3">𝑁</ci></apply><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2"><times id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.1"></times><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2"><csymbol cd="ambiguous" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2">subscript</csymbol><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.2">𝑝</ci><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.2.3">𝑘</ci></apply><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.3">Δ</ci><apply id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4"><csymbol cd="ambiguous" id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.1.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4">subscript</csymbol><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.2.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.2">𝜃</ci><ci id="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.3.cmml" xref="S2.E2Xa.2.1.1.m1.1.1.1.1.3.3.3.2.4.3">𝑘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2Xa.2.1.1.m1.1c">\displaystyle\mathrm{\textbf{or}\ Model\ gradient:}\theta\leftarrow\theta+\sum_{k=1}^{N}p_{k}\Delta\theta_{k}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Model broadcast:</span> The central server sends the updated global model <math id="S2.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.I1.i4.p1.1.m1.1a"><mi id="S2.I1.i4.p1.1.m1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.1.m1.1b"><ci id="S2.I1.i4.p1.1.m1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.1c">\theta</annotation></semantics></math> to all clients.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Model iteration:</span> Repeat steps 2 through 4 until the stop condition is satisfied.</p>
</div>
</li>
</ul>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Although FL has been widely used in various domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, real-world FL usually faces heterogeneity in data distribution, model architecture, task requirements, network environments, and hardware devices among participant clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. These heterogeneities pose a number of challenges, including how to effectively deal with differences in data distribution across clients, how to adapt to the computational and storage capabilities of different clients while maintaining model performance, how to balance knowledge sharing with task specificity in multitasking scenarios, how to optimize communication strategies to cope with varying bandwidth and latency conditions, and how to adapt to the energy and resource constraints of different devices. We next analyze the challenges posed by these heterogeneities, the resolution of which is essential to achieve efficient, scalable, and robust FL systems.</p>
</div>
<section id="S2.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Data Heterogeneity</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Data heterogeneity refers to the inconsistency of data distribution among clients in FL, which does not obey the same sampling, i.e., the data are not independently and identically distributed (Non-IID) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
To explore data heterogeneity, we categorize data heterogeneity from the perspective of client data distribution. Specifically, we distinguish different categories of Non-IID data by five different skew patterns: distribution skew, label skew, feature skew, quality skew, and quantity skew, as shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Numerous studies<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> have found that the client’s local optimization objective is inconsistent with the global optimization objective due to differences in the client’s local data distribution.
As a result, data heterogeneity may cause the local model to converge in different directions to reach the local optimum rather than the global optimum, which reduces the FL performance and leads to poor global convergence of the model, and these problems deteriorate the performance of the global model for each participant, and may prevent participants from engaging in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2405.09839/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="245" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of five different skew patterns in data heterogeneity.</figcaption>
</figure>
<section id="S2.SS1.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS1.5.1.1" class="ltx_text">II-A</span>1 </span>Distribution Skew</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.3" class="ltx_p">In FL, data distribution skew refers to the skew in the distribution of data held by different clients, i.e., the distribution of features or joint distribution of data from different clients is inconsistent with the overall data distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. In this case, the data no longer obeys the assumption of independent identically distributed (IID).
As shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>a, there is <math id="S2.SS1.SSS1.p1.1.m1.4" class="ltx_Math" alttext="P_{i}(x,y)\neq P_{j}(x,y)" display="inline"><semantics id="S2.SS1.SSS1.p1.1.m1.4a"><mrow id="S2.SS1.SSS1.p1.1.m1.4.5" xref="S2.SS1.SSS1.p1.1.m1.4.5.cmml"><mrow id="S2.SS1.SSS1.p1.1.m1.4.5.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.cmml"><msub id="S2.SS1.SSS1.p1.1.m1.4.5.2.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2.cmml"><mi id="S2.SS1.SSS1.p1.1.m1.4.5.2.2.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2.2.cmml">P</mi><mi id="S2.SS1.SSS1.p1.1.m1.4.5.2.2.3" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS1.p1.1.m1.4.5.2.1" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.1.cmml">​</mo><mrow id="S2.SS1.SSS1.p1.1.m1.4.5.2.3.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S2.SS1.SSS1.p1.1.m1.4.5.2.3.2.1" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.3.1.cmml">(</mo><mi id="S2.SS1.SSS1.p1.1.m1.1.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.cmml">x</mi><mo id="S2.SS1.SSS1.p1.1.m1.4.5.2.3.2.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.3.1.cmml">,</mo><mi id="S2.SS1.SSS1.p1.1.m1.2.2" xref="S2.SS1.SSS1.p1.1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS1.p1.1.m1.4.5.2.3.2.3" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS1.p1.1.m1.4.5.1" xref="S2.SS1.SSS1.p1.1.m1.4.5.1.cmml">≠</mo><mrow id="S2.SS1.SSS1.p1.1.m1.4.5.3" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.cmml"><msub id="S2.SS1.SSS1.p1.1.m1.4.5.3.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2.cmml"><mi id="S2.SS1.SSS1.p1.1.m1.4.5.3.2.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2.2.cmml">P</mi><mi id="S2.SS1.SSS1.p1.1.m1.4.5.3.2.3" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS1.p1.1.m1.4.5.3.1" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.1.cmml">​</mo><mrow id="S2.SS1.SSS1.p1.1.m1.4.5.3.3.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.3.1.cmml"><mo stretchy="false" id="S2.SS1.SSS1.p1.1.m1.4.5.3.3.2.1" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.3.1.cmml">(</mo><mi id="S2.SS1.SSS1.p1.1.m1.3.3" xref="S2.SS1.SSS1.p1.1.m1.3.3.cmml">x</mi><mo id="S2.SS1.SSS1.p1.1.m1.4.5.3.3.2.2" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.3.1.cmml">,</mo><mi id="S2.SS1.SSS1.p1.1.m1.4.4" xref="S2.SS1.SSS1.p1.1.m1.4.4.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS1.p1.1.m1.4.5.3.3.2.3" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.1.m1.4b"><apply id="S2.SS1.SSS1.p1.1.m1.4.5.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5"><neq id="S2.SS1.SSS1.p1.1.m1.4.5.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.1"></neq><apply id="S2.SS1.SSS1.p1.1.m1.4.5.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2"><times id="S2.SS1.SSS1.p1.1.m1.4.5.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.1"></times><apply id="S2.SS1.SSS1.p1.1.m1.4.5.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.4.5.2.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2">subscript</csymbol><ci id="S2.SS1.SSS1.p1.1.m1.4.5.2.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2.2">𝑃</ci><ci id="S2.SS1.SSS1.p1.1.m1.4.5.2.2.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.2.3">𝑖</ci></apply><interval closure="open" id="S2.SS1.SSS1.p1.1.m1.4.5.2.3.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.2.3.2"><ci id="S2.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1">𝑥</ci><ci id="S2.SS1.SSS1.p1.1.m1.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.2.2">𝑦</ci></interval></apply><apply id="S2.SS1.SSS1.p1.1.m1.4.5.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3"><times id="S2.SS1.SSS1.p1.1.m1.4.5.3.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.1"></times><apply id="S2.SS1.SSS1.p1.1.m1.4.5.3.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.4.5.3.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2">subscript</csymbol><ci id="S2.SS1.SSS1.p1.1.m1.4.5.3.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2.2">𝑃</ci><ci id="S2.SS1.SSS1.p1.1.m1.4.5.3.2.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.2.3">𝑗</ci></apply><interval closure="open" id="S2.SS1.SSS1.p1.1.m1.4.5.3.3.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.5.3.3.2"><ci id="S2.SS1.SSS1.p1.1.m1.3.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.3.3">𝑥</ci><ci id="S2.SS1.SSS1.p1.1.m1.4.4.cmml" xref="S2.SS1.SSS1.p1.1.m1.4.4">𝑦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.1.m1.4c">P_{i}(x,y)\neq P_{j}(x,y)</annotation></semantics></math> due to the difference in the data distribution of clients <math id="S2.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.SSS1.p1.2.m2.1a"><mi id="S2.SS1.SSS1.p1.2.m2.1.1" xref="S2.SS1.SSS1.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.2.m2.1b"><ci id="S2.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.2.m2.1c">i</annotation></semantics></math> and <math id="S2.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS1.SSS1.p1.3.m3.1a"><mi id="S2.SS1.SSS1.p1.3.m3.1.1" xref="S2.SS1.SSS1.p1.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.3.m3.1b"><ci id="S2.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS1.p1.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.3.m3.1c">j</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.2" class="ltx_p">A typical example is data obeying a Dirichlet distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. The Dirichlet distribution is a multivariate probability distribution that is often used to describe the distribution of the proportions of each category in a multicategorization problem. In the context of FL, the Dirichlet distribution can be used to model differences in the distribution of data labels on different clients. Where the parameter <math id="S2.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS1.SSS1.p2.1.m1.1a"><mi id="S2.SS1.SSS1.p2.1.m1.1.1" xref="S2.SS1.SSS1.p2.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.1.m1.1b"><ci id="S2.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p2.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.1.m1.1c">\beta</annotation></semantics></math> determines the degree of distributional difference of the data. As shown in the scatterplot in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>a, which illustrates the visualization of the difference in the distribution of data across 20 clients for different values of <math id="S2.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS1.SSS1.p2.2.m2.1a"><mi id="S2.SS1.SSS1.p2.2.m2.1.1" xref="S2.SS1.SSS1.p2.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.2.m2.1b"><ci id="S2.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS1.SSS1.p2.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.2.m2.1c">\beta</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS2.5.1.1" class="ltx_text">II-A</span>2 </span>Label Skew</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.4" class="ltx_p">Data label skew is a common Non-IID case <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, which refers to the skew in the distribution of data labels held by different clients. This label distribution skew means that even if the feature distributions are shared, the label distributions of different clients may be different <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, i.e., for clients <math id="S2.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.SSS2.p1.1.m1.1a"><mi id="S2.SS1.SSS2.p1.1.m1.1.1" xref="S2.SS1.SSS2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.1.m1.1b"><ci id="S2.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.1.m1.1c">i</annotation></semantics></math> and <math id="S2.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS1.SSS2.p1.2.m2.1a"><mi id="S2.SS1.SSS2.p1.2.m2.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.2.m2.1b"><ci id="S2.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.2.m2.1c">j</annotation></semantics></math>, their label distributions <math id="S2.SS1.SSS2.p1.3.m3.2" class="ltx_Math" alttext="P_{i}(y)\neq P_{j}(y)" display="inline"><semantics id="S2.SS1.SSS2.p1.3.m3.2a"><mrow id="S2.SS1.SSS2.p1.3.m3.2.3" xref="S2.SS1.SSS2.p1.3.m3.2.3.cmml"><mrow id="S2.SS1.SSS2.p1.3.m3.2.3.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.cmml"><msub id="S2.SS1.SSS2.p1.3.m3.2.3.2.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2.cmml"><mi id="S2.SS1.SSS2.p1.3.m3.2.3.2.2.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.SSS2.p1.3.m3.2.3.2.2.3" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.3.m3.2.3.2.1" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.3.m3.2.3.2.3.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.3.m3.2.3.2.3.2.1" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.cmml">(</mo><mi id="S2.SS1.SSS2.p1.3.m3.1.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS2.p1.3.m3.2.3.2.3.2.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS2.p1.3.m3.2.3.1" xref="S2.SS1.SSS2.p1.3.m3.2.3.1.cmml">≠</mo><mrow id="S2.SS1.SSS2.p1.3.m3.2.3.3" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.cmml"><msub id="S2.SS1.SSS2.p1.3.m3.2.3.3.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2.cmml"><mi id="S2.SS1.SSS2.p1.3.m3.2.3.3.2.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.SSS2.p1.3.m3.2.3.3.2.3" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.3.m3.2.3.3.1" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.3.m3.2.3.3.3.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.3.m3.2.3.3.3.2.1" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.cmml">(</mo><mi id="S2.SS1.SSS2.p1.3.m3.2.2" xref="S2.SS1.SSS2.p1.3.m3.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS2.p1.3.m3.2.3.3.3.2.2" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.3.m3.2b"><apply id="S2.SS1.SSS2.p1.3.m3.2.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3"><neq id="S2.SS1.SSS2.p1.3.m3.2.3.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.1"></neq><apply id="S2.SS1.SSS2.p1.3.m3.2.3.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.2"><times id="S2.SS1.SSS2.p1.3.m3.2.3.2.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.1"></times><apply id="S2.SS1.SSS2.p1.3.m3.2.3.2.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.3.m3.2.3.2.2.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2">subscript</csymbol><ci id="S2.SS1.SSS2.p1.3.m3.2.3.2.2.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.SSS2.p1.3.m3.2.3.2.2.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1">𝑦</ci></apply><apply id="S2.SS1.SSS2.p1.3.m3.2.3.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.3"><times id="S2.SS1.SSS2.p1.3.m3.2.3.3.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.1"></times><apply id="S2.SS1.SSS2.p1.3.m3.2.3.3.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.3.m3.2.3.3.2.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2">subscript</csymbol><ci id="S2.SS1.SSS2.p1.3.m3.2.3.3.2.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.SSS2.p1.3.m3.2.3.3.2.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.SSS2.p1.3.m3.2.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.2.2">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.3.m3.2c">P_{i}(y)\neq P_{j}(y)</annotation></semantics></math>. However, for each label, the feature distributions of the data samples are similar regardless of which client they belong to, i.e., <math id="S2.SS1.SSS2.p1.4.m4.2" class="ltx_Math" alttext="P_{i}(x|y)=P_{j}(x|y)" display="inline"><semantics id="S2.SS1.SSS2.p1.4.m4.2a"><mrow id="S2.SS1.SSS2.p1.4.m4.2.2" xref="S2.SS1.SSS2.p1.4.m4.2.2.cmml"><mrow id="S2.SS1.SSS2.p1.4.m4.1.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.cmml"><msub id="S2.SS1.SSS2.p1.4.m4.1.1.1.3" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3.cmml"><mi id="S2.SS1.SSS2.p1.4.m4.1.1.1.3.2" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.SSS2.p1.4.m4.1.1.1.3.3" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.4.m4.1.1.1.2" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.2" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.cmml"><mi id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.2" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.3" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.3" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS2.p1.4.m4.2.2.3" xref="S2.SS1.SSS2.p1.4.m4.2.2.3.cmml">=</mo><mrow id="S2.SS1.SSS2.p1.4.m4.2.2.2" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.cmml"><msub id="S2.SS1.SSS2.p1.4.m4.2.2.2.3" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3.cmml"><mi id="S2.SS1.SSS2.p1.4.m4.2.2.2.3.2" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3.2.cmml">P</mi><mi id="S2.SS1.SSS2.p1.4.m4.2.2.2.3.3" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.4.m4.2.2.2.2" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.2" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.cmml"><mi id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.2" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.1" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.1.cmml">|</mo><mi id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.3" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.3" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.4.m4.2b"><apply id="S2.SS1.SSS2.p1.4.m4.2.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2"><eq id="S2.SS1.SSS2.p1.4.m4.2.2.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.3"></eq><apply id="S2.SS1.SSS2.p1.4.m4.1.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1"><times id="S2.SS1.SSS2.p1.4.m4.1.1.1.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.2"></times><apply id="S2.SS1.SSS2.p1.4.m4.1.1.1.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.4.m4.1.1.1.3.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS2.p1.4.m4.1.1.1.3.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.SSS2.p1.4.m4.1.1.1.3.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1.1.1.1.1.3">𝑦</ci></apply></apply><apply id="S2.SS1.SSS2.p1.4.m4.2.2.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2"><times id="S2.SS1.SSS2.p1.4.m4.2.2.2.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.2"></times><apply id="S2.SS1.SSS2.p1.4.m4.2.2.2.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.4.m4.2.2.2.3.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3">subscript</csymbol><ci id="S2.SS1.SSS2.p1.4.m4.2.2.2.3.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3.2">𝑃</ci><ci id="S2.SS1.SSS2.p1.4.m4.2.2.2.3.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.3.3">𝑗</ci></apply><apply id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1"><csymbol cd="latexml" id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.1">conditional</csymbol><ci id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.2">𝑥</ci><ci id="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.3.cmml" xref="S2.SS1.SSS2.p1.4.m4.2.2.2.1.1.1.3">𝑦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.4.m4.2c">P_{i}(x|y)=P_{j}(x|y)</annotation></semantics></math>.
For example, in the data label skewing scenario shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>b, different users contain data from the set of handwritten digits, but each client may mainly contain a certain number of digits. The scatterplot shows a visualization of label skew for 20 clients. This data label skew can lead to a large difference in the gradient of the model uploaded back from different clients during federated training, thus affecting the convergence and generalization performance of the model.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS3.5.1.1" class="ltx_text">II-A</span>3 </span>Feature Skew</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.6" class="ltx_p">Data feature skew is a kind of data heterogeneity in FL, which refers to the inconsistent distribution of data features on different clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, e.g.,<math id="S2.SS1.SSS3.p1.1.m1.2" class="ltx_Math" alttext="P_{i}(x)\neq P_{j}(x)" display="inline"><semantics id="S2.SS1.SSS3.p1.1.m1.2a"><mrow id="S2.SS1.SSS3.p1.1.m1.2.3" xref="S2.SS1.SSS3.p1.1.m1.2.3.cmml"><mrow id="S2.SS1.SSS3.p1.1.m1.2.3.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.cmml"><msub id="S2.SS1.SSS3.p1.1.m1.2.3.2.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2.cmml"><mi id="S2.SS1.SSS3.p1.1.m1.2.3.2.2.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.SSS3.p1.1.m1.2.3.2.2.3" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS3.p1.1.m1.2.3.2.1" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.SSS3.p1.1.m1.2.3.2.3.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.SSS3.p1.1.m1.2.3.2.3.2.1" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.cmml">(</mo><mi id="S2.SS1.SSS3.p1.1.m1.1.1" xref="S2.SS1.SSS3.p1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.SS1.SSS3.p1.1.m1.2.3.2.3.2.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS3.p1.1.m1.2.3.1" xref="S2.SS1.SSS3.p1.1.m1.2.3.1.cmml">≠</mo><mrow id="S2.SS1.SSS3.p1.1.m1.2.3.3" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.cmml"><msub id="S2.SS1.SSS3.p1.1.m1.2.3.3.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2.cmml"><mi id="S2.SS1.SSS3.p1.1.m1.2.3.3.2.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.SSS3.p1.1.m1.2.3.3.2.3" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS3.p1.1.m1.2.3.3.1" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.SSS3.p1.1.m1.2.3.3.3.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.SSS3.p1.1.m1.2.3.3.3.2.1" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.cmml">(</mo><mi id="S2.SS1.SSS3.p1.1.m1.2.2" xref="S2.SS1.SSS3.p1.1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S2.SS1.SSS3.p1.1.m1.2.3.3.3.2.2" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.1.m1.2b"><apply id="S2.SS1.SSS3.p1.1.m1.2.3.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3"><neq id="S2.SS1.SSS3.p1.1.m1.2.3.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.1"></neq><apply id="S2.SS1.SSS3.p1.1.m1.2.3.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.2"><times id="S2.SS1.SSS3.p1.1.m1.2.3.2.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.1"></times><apply id="S2.SS1.SSS3.p1.1.m1.2.3.2.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.1.m1.2.3.2.2.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2">subscript</csymbol><ci id="S2.SS1.SSS3.p1.1.m1.2.3.2.2.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.SSS3.p1.1.m1.2.3.2.2.3.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.1.1">𝑥</ci></apply><apply id="S2.SS1.SSS3.p1.1.m1.2.3.3.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.3"><times id="S2.SS1.SSS3.p1.1.m1.2.3.3.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.1"></times><apply id="S2.SS1.SSS3.p1.1.m1.2.3.3.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.1.m1.2.3.3.2.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2">subscript</csymbol><ci id="S2.SS1.SSS3.p1.1.m1.2.3.3.2.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.SSS3.p1.1.m1.2.3.3.2.3.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.SSS3.p1.1.m1.2.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.2.2">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.1.m1.2c">P_{i}(x)\neq P_{j}(x)</annotation></semantics></math>.
In this scenario, even though the labels are consistent <math id="S2.SS1.SSS3.p1.2.m2.2" class="ltx_Math" alttext="P_{i}(y)=P_{j}(y)" display="inline"><semantics id="S2.SS1.SSS3.p1.2.m2.2a"><mrow id="S2.SS1.SSS3.p1.2.m2.2.3" xref="S2.SS1.SSS3.p1.2.m2.2.3.cmml"><mrow id="S2.SS1.SSS3.p1.2.m2.2.3.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.cmml"><msub id="S2.SS1.SSS3.p1.2.m2.2.3.2.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2.cmml"><mi id="S2.SS1.SSS3.p1.2.m2.2.3.2.2.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.SSS3.p1.2.m2.2.3.2.2.3" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS3.p1.2.m2.2.3.2.1" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.SSS3.p1.2.m2.2.3.2.3.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.SSS3.p1.2.m2.2.3.2.3.2.1" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.cmml">(</mo><mi id="S2.SS1.SSS3.p1.2.m2.1.1" xref="S2.SS1.SSS3.p1.2.m2.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS3.p1.2.m2.2.3.2.3.2.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS3.p1.2.m2.2.3.1" xref="S2.SS1.SSS3.p1.2.m2.2.3.1.cmml">=</mo><mrow id="S2.SS1.SSS3.p1.2.m2.2.3.3" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.cmml"><msub id="S2.SS1.SSS3.p1.2.m2.2.3.3.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2.cmml"><mi id="S2.SS1.SSS3.p1.2.m2.2.3.3.2.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.SSS3.p1.2.m2.2.3.3.2.3" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS3.p1.2.m2.2.3.3.1" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.SSS3.p1.2.m2.2.3.3.3.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.SSS3.p1.2.m2.2.3.3.3.2.1" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.cmml">(</mo><mi id="S2.SS1.SSS3.p1.2.m2.2.2" xref="S2.SS1.SSS3.p1.2.m2.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS3.p1.2.m2.2.3.3.3.2.2" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.2.m2.2b"><apply id="S2.SS1.SSS3.p1.2.m2.2.3.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3"><eq id="S2.SS1.SSS3.p1.2.m2.2.3.1.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.1"></eq><apply id="S2.SS1.SSS3.p1.2.m2.2.3.2.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.2"><times id="S2.SS1.SSS3.p1.2.m2.2.3.2.1.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.1"></times><apply id="S2.SS1.SSS3.p1.2.m2.2.3.2.2.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.2.m2.2.3.2.2.1.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2">subscript</csymbol><ci id="S2.SS1.SSS3.p1.2.m2.2.3.2.2.2.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.SSS3.p1.2.m2.2.3.2.2.3.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS3.p1.2.m2.1.1">𝑦</ci></apply><apply id="S2.SS1.SSS3.p1.2.m2.2.3.3.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.3"><times id="S2.SS1.SSS3.p1.2.m2.2.3.3.1.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.1"></times><apply id="S2.SS1.SSS3.p1.2.m2.2.3.3.2.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.2.m2.2.3.3.2.1.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2">subscript</csymbol><ci id="S2.SS1.SSS3.p1.2.m2.2.3.3.2.2.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.SSS3.p1.2.m2.2.3.3.2.3.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.SSS3.p1.2.m2.2.2.cmml" xref="S2.SS1.SSS3.p1.2.m2.2.2">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.2.m2.2c">P_{i}(y)=P_{j}(y)</annotation></semantics></math>, the distributions remain different <math id="S2.SS1.SSS3.p1.3.m3.2" class="ltx_Math" alttext="P_{i}(x|y)\neq P_{j}(x|y)" display="inline"><semantics id="S2.SS1.SSS3.p1.3.m3.2a"><mrow id="S2.SS1.SSS3.p1.3.m3.2.2" xref="S2.SS1.SSS3.p1.3.m3.2.2.cmml"><mrow id="S2.SS1.SSS3.p1.3.m3.1.1.1" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.cmml"><msub id="S2.SS1.SSS3.p1.3.m3.1.1.1.3" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3.cmml"><mi id="S2.SS1.SSS3.p1.3.m3.1.1.1.3.2" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.SSS3.p1.3.m3.1.1.1.3.3" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS3.p1.3.m3.1.1.1.2" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.2" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.cmml"><mi id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.2" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.1" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.3" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.3" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS3.p1.3.m3.2.2.3" xref="S2.SS1.SSS3.p1.3.m3.2.2.3.cmml">≠</mo><mrow id="S2.SS1.SSS3.p1.3.m3.2.2.2" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.cmml"><msub id="S2.SS1.SSS3.p1.3.m3.2.2.2.3" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3.cmml"><mi id="S2.SS1.SSS3.p1.3.m3.2.2.2.3.2" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3.2.cmml">P</mi><mi id="S2.SS1.SSS3.p1.3.m3.2.2.2.3.3" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.SSS3.p1.3.m3.2.2.2.2" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.2" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.cmml"><mi id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.2" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.1" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.1.cmml">|</mo><mi id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.3" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.3" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.3.m3.2b"><apply id="S2.SS1.SSS3.p1.3.m3.2.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2"><neq id="S2.SS1.SSS3.p1.3.m3.2.2.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.3"></neq><apply id="S2.SS1.SSS3.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1"><times id="S2.SS1.SSS3.p1.3.m3.1.1.1.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.2"></times><apply id="S2.SS1.SSS3.p1.3.m3.1.1.1.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.3.m3.1.1.1.3.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS3.p1.3.m3.1.1.1.3.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.SSS3.p1.3.m3.1.1.1.3.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.1.1.1.1.1.1.3">𝑦</ci></apply></apply><apply id="S2.SS1.SSS3.p1.3.m3.2.2.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2"><times id="S2.SS1.SSS3.p1.3.m3.2.2.2.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.2"></times><apply id="S2.SS1.SSS3.p1.3.m3.2.2.2.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.3.m3.2.2.2.3.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3">subscript</csymbol><ci id="S2.SS1.SSS3.p1.3.m3.2.2.2.3.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3.2">𝑃</ci><ci id="S2.SS1.SSS3.p1.3.m3.2.2.2.3.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.3.3">𝑗</ci></apply><apply id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1"><csymbol cd="latexml" id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.1.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.1">conditional</csymbol><ci id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.2.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.2">𝑥</ci><ci id="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.3.cmml" xref="S2.SS1.SSS3.p1.3.m3.2.2.2.1.1.1.3">𝑦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.3.m3.2c">P_{i}(x|y)\neq P_{j}(x|y)</annotation></semantics></math>.
As in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>c, clients <math id="S2.SS1.SSS3.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.SSS3.p1.4.m4.1a"><mi id="S2.SS1.SSS3.p1.4.m4.1.1" xref="S2.SS1.SSS3.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.4.m4.1b"><ci id="S2.SS1.SSS3.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS3.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.4.m4.1c">i</annotation></semantics></math>, <math id="S2.SS1.SSS3.p1.5.m5.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS1.SSS3.p1.5.m5.1a"><mi id="S2.SS1.SSS3.p1.5.m5.1.1" xref="S2.SS1.SSS3.p1.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.5.m5.1b"><ci id="S2.SS1.SSS3.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS3.p1.5.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.5.m5.1c">j</annotation></semantics></math>, and <math id="S2.SS1.SSS3.p1.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.SSS3.p1.6.m6.1a"><mi id="S2.SS1.SSS3.p1.6.m6.1.1" xref="S2.SS1.SSS3.p1.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.6.m6.1b"><ci id="S2.SS1.SSS3.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS3.p1.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.6.m6.1c">k</annotation></semantics></math> all have the label of dog, but they are photos, cartoons, and art paintings of dogs, respectively.
This data feature skew is especially common in Vertical Federated Learning (VFL) scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. VFL involves multiple clients that have the same set of sample IDs, but each client holds a different set of features. In other words, each client only knows a portion of the features of the samples. For example, consider two financial institutions, A and B, that collaborate to build a credit scoring model. Institution A holds the basic information and transaction history of its clients, while Institution B holds the loan history and repayment status of its clients. Although these two institutions share the same customer base, they hold different sets of data features. In this longitudinal FL scenario, data feature skew manifest itself in the form of different feature spaces held by agencies A and B.</p>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS4.5.1.1" class="ltx_text">II-A</span>4 </span>Quality Skew</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">Data quality skew refers to the difference in data quality on different clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. This can be caused by a variety of factors as shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>d, such as noise in the data acquisition process, the data processing flow of different clients, or the accuracy of data labeling. Data quality skew can have a significant impact on the performance of FL models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. In this scenario, some clients may have high-quality data that has been accurately measured and carefully labeled, while others may contain a lot of noise or inaccurate labels. High-quality data can provide more accurate information that helps the model learn effective feature representations and prediction rules. On the contrary, low-quality data may introduce misleading information that causes the model to learn incorrect feature relationships, thus reducing the model’s generalization ability and prediction accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS5" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS5.5.1.1" class="ltx_text">II-A</span>5 </span>Quantity Skew</h4>

<div id="S2.SS1.SSS5.p1" class="ltx_para">
<p id="S2.SS1.SSS5.p1.1" class="ltx_p">Data quantity skew refers to a significant difference in the amount of data on different clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. For example, some clients may have a large number of data samples while others have only a small amount of data as shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Data Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>e. This quantity skew affects the training process of a FL model because the model may tend to optimize the performance on clients with a larger amount of data while ignoring clients with a smaller amount of data.
The impact of data quantity skew on the model is mainly in two aspects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>: on the one hand, clients with larger data quantities may have a larger impact on the global model update, which results in the model performing better on these clients and worse on clients with smaller data quantities. On the other hand, the imbalance in the amount of data may result in the model not being able to fully learn the features of the data on all clients, thus reducing the generalization ability of the model.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Model Heterogeneity</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In the model heterogeneity scenario of FL, each client involved in learning may employ different model structures and optimizers to adapt to its own data characteristics and computational resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, as shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-B Model Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. This model heterogeneity increases the complexity of FL systems, but also provides flexibility to adapt to diverse device and task requirements. We will next address model structure heterogeneity and model optimizer heterogeneity, respectively.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2405.09839/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="185" height="103" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of federated model heterogeneity.</figcaption>
</figure>
<section id="S2.SS2.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS1.5.1.1" class="ltx_text">II-B</span>1 </span>Model Structure Heterogeneity</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">Model structure heterogeneity refers to the fact that different clients use different model structures to adapt to their respective data characteristics and computational resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. This heterogeneity mainly stems from the diversity of devices and the diversity of task requirements in the real world. For example, in a FL system, some clients may be servers equipped with high-performance GPUs capable of handling complex deep learning models such as deep convolutional neural networks (CNNs) or transformer models for image recognition or natural language processing tasks. While other clients may be resource-constrained edge devices, such as smartphones or IoT sensors, which may only be able to run lightweight models, such as shallow neural networks or decision trees, to reduce computational and storage overhead.</p>
</div>
<div id="S2.SS2.SSS1.p2" class="ltx_para">
<p id="S2.SS2.SSS1.p2.1" class="ltx_p">Moreover, even for the same type of task, different clients may choose different model structures based on the characteristics of their local data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. For example, in the task of performing handwritten digit recognition, some clients may use a standard multilayer perceptron (MLP) model, while others may employ a convolutional neural network model with spatial feature extraction capabilities. This structural difference results in different dimensions and properties of the model parameters, making it difficult to directly apply traditional FL algorithms, such as the Federated Averaging Algorithm (FedAvg), which typically assume that all clients use the same model structure.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS2.5.1.1" class="ltx_text">II-B</span>2 </span>Model Optimizer Heterogeneity</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">Optimizer heterogeneity refers to the fact that different clients use different optimization algorithms or parameters to train the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Due to the different computational power and memory constraints of different devices, some clients may use optimizers with smaller memory footprints and computational costs, such as Stochastic Gradient Descent (SGD), while others may use more sophisticated optimizers, such as Adam or RMSprop, to achieve faster convergence. Moreover, even with the same optimizer, different clients may employ different learning rates or other hyperparameter settings to suit their local data distribution and training conditions. This optimizer heterogeneity increases the complexity of FL, as coordination between different optimization strategies is required to ensure effective global model updating and convergence.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Task Heterogeneity</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In FL, task heterogeneity refers to the fact that clients involved in the learning process may face different task requirements or objective functions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. This heterogeneity may stem from the environment in which the clients are located, differences in user behavior, or specific application scenario requirements, resulting in different objective functions or learning tasks that need to be optimized for each client.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">For example <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, in a FL application in the medical domain, different hospitals may focus on different types of disease diagnosis, so their learning tasks and objective functions may be different, e.g., Fig. <a href="#S2.F3" title="Figure 3 ‣ II-C Task Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>a demonstrates that clients have homogeneous models but the distributions have labels for different medicines. Fig. <a href="#S2.F3" title="Figure 3 ‣ II-C Task Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>b demonstrates when clients have similar datasets such as face dataset, and individual clients have heterogeneous classification labels. Fig. <a href="#S2.F3" title="Figure 3 ‣ II-C Task Heterogeneity ‣ II Classification and Challenges in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>c Task types are heterogeneous, including classification and regression tasks.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Task heterogeneity introduces additional complexity to FL because traditional FL frameworks typically assume that all devices jointly optimize a global objective function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. To cope with task heterogeneity, FL systems need to employ more flexible algorithms and policies that allow different devices to personalize model training based on their own task requirements.
In addition, task heterogeneity also requires that FL systems are able to effectively coordinate the learning processes of different devices to ensure a balance between the generalization capabilities of the global model and the individual needs of each client. Such coordination may require appropriate adaptation of the model updating and parameter aggregation processes to suit the characteristics and needs of different tasks.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2405.09839/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="97" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of federated task heterogeneity.</figcaption>
</figure>
</section>
<section id="S2.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.5.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.6.2" class="ltx_text ltx_font_italic">Communication heterogeneity</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">In FL, communication heterogeneity refers to the differences in communication capabilities of the devices involved in the learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>. Such differences are mainly in terms of network bandwidth, latency and connection stability, which directly affect the transmission efficiency of model parameters and the synchronization of the whole learning process. For example, devices are usually deployed in different network environments with different network connection settings (3G, 4G, 5G, Wi-Fi) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. Devices with high bandwidth and low latency can quickly upload and download model parameters, thus completing a round of model updates in a short period of time. On the contrary, devices with limited bandwidth and high latency may face longer waiting time when transmitting model parameters, resulting in the training progress of the whole system being affected. The heterogeneity of communication increases the communication cost and complexity to some extent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. In addition, differences in connection stability can also have an impact on the efficiency of FL. Unstable connections may result in lost or delayed model parameter updates, which in turn affects the convergence speed and accuracy of the model.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS5.5.1.1" class="ltx_text">II-E</span> </span><span id="S2.SS5.6.2" class="ltx_text ltx_font_italic">Device heterogeneity</span>
</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">In the application scenario of FL, device heterogeneity is a crucial issue that cannot be neglected <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. Due to the wide variety of client devices participating in FL, there are significant differences in computing power, storage resources, energy supply, etc., which leads to device heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. This heterogeneity leads to inconsistent efficiency and capability of different devices in processing data and training models, which may affect the performance and efficiency of the whole FL system. For example, high-performance devices such as servers or high-end smartphones are able to process complex models and large data volumes quickly due to their powerful processors and ample storage space, thus taking on more computational burden during FL and speeding up the entire learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. On the contrary, low-performance devices, such as low-end smartphones, are less capable of model training and data processing due to the limitations of computational resources and storage space, and may also slow down the progress of the entire FL system, which may become the bottleneck of system efficiency. This is because the system usually needs to wait for all devices to complete their local updates before global model aggregation can take place. In addition, devices with weaker computational power may face greater pressure on energy consumption when processing complex models, which is especially critical in energy-constrained environments.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">Therefore, FL algorithms and system design need to take into account the heterogeneity of computational capabilities among devices, and ensure efficient operation and fairness of the system through strategies such as reasonable task allocation, model simplification, and resource optimization to ensure that all devices can effectively participate in the learning process, while maintaining the coordination and fairness of the overall system.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Advanced Methods Discussion</span>
</h2>

<section id="S3.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Data-Level Methods</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Doing operations at the data level is often seen as an important means to address data heterogeneity. In this section, we categorize the data-level approaches into three categories: data cleansing, data augmentation, and representation learning, and present their representative approaches respectively.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.5.1.1" class="ltx_text">III-A</span>1 </span>Data Cleaning</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Data cleaning in FL can help improve the training effect and final performance of the model. Data cleaning mainly refers to correcting errors and inconsistencies in datasets, including dealing with issues such as missing values, outliers, format errors, and duplicate data.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p">Li <span id="S3.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> presents an optimization problem i.e., selecting a high-quality set of training samples for a FL task under a given budget in a privacy-preserving manner without knowledge of the participants’ local data and training process.
Ma <span id="S3.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> proposes a federated data cleaning protocol, called FedClean, for edge intelligence scenarios that aims to achieve data cleaning without compromising data privacy. FedClean Different edge nodes first generate a Boolean share of their data and distribute it to two clean servers. These two servers then run the FedClean protocol to compute and sort the data entry scores.
Faced with the problem of noisy data labels, Chen <span id="S3.SS1.SSS1.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> proposes a robust FL by considering two networks with different data distributions. The core idea is that the edge devices learn to assign local weights of the loss function in the noisy labeled dataset and cooperate with the central server to update the global weights as a way to help edge nodes that do not have a clean dataset to reweight their noisy loss functions.
Similarly, Duan <span id="S3.SS1.SSS1.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <span id="S3.SS1.SSS1.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> proposes a new data filtering approach to deal with label noise in joint learning, called FED-DR-Filter, which focuses on identifying clean data by exploiting the correlation of global data representations.
Tsouvalas <span id="S3.SS1.SSS1.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> proposes FedLN framework enough to deal with labeling noise in different FL training phases, i.e., FL initialization, on-device model training, and server model aggregation, which is able to adapt to the different computational power of the devices in the FL system.
Li <span id="S3.SS1.SSS1.p2.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> proposed FedDiv to address the challenge of FL with noisy labels, and they designed a global noise filter with a joint noise filter for efficiently identifying samples with noisy labels on each client, which improves the stability of the local training process.
Xu <span id="S3.SS1.SSS1.p2.1.8" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> proposed a collaborative data filtering method Safe to deal with poisoning attacks, using the alternating direction method of multipliers to detect the attacked devices whose training process will be interrupted, and using the K-mean clustering algorithm to cluster the trusted data to find out and filter out the poisoned data from the attacked devices.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.5.1.1" class="ltx_text">III-A</span>2 </span>Data Augmentation</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">Data augmentation plays a key role in FL, especially when dealing with Non-IID data distributed across multiple devices. Data augmentation not only increases the amount of data, but also increases the diversity of the data.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">Hao <span id="S3.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> proposes a FL system and derives 2 variants that can use zero-sample data augmentation on underpresented data to mitigate data heterogeneity.
Chen <span id="S3.SS1.SSS2.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> proposes FRAug, a federated representation augmentation method, to address the data heterogeneity challenge. FRAug optimizes a shared embedding generator to obtain client consensus, and then locally transforms the output synthetic embeddings to client-specific embeddings in order to increase the training space for each client.
Lewy <span id="S3.SS1.SSS2.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> proposed StatMix, an enhancement method using image statistics to improve the results of FL scenes.
Xin <span id="S3.SS1.SSS2.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> proposes FL-GAN, a generative adversarial network model for differential privacy based on joint learning. by combining the Lipschitz limit with differential privacy sensitivity, the model can generate high-quality synthetic data without sacrificing the privacy of the training data.
Zhang <span id="S3.SS1.SSS2.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> proposes a distributed data augmentation method that combines generative adversarial networksand federated analysis to enhance the generalization ability of trained FDG models, called FA-FDG.
Generating more overlapping data by learning the features of limited overlapping data and many locally existing non-overlapping data, Zhang <span id="S3.SS1.SSS2.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> proposed a data augmentation method FedDA based on generative adversarial networks to increase the amount of training data.
Similarly, Xiao <span id="S3.SS1.SSS2.p2.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> proposes FeCGAN, a distributed generative adversarial network for multiple participants with insufficient data overlap.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.5.1.1" class="ltx_text">III-A</span>3 </span>Representation Learning</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">Representation learning aims to learn useful data representations (or features) from dispersed data sources to help improve the predictive performance and generalization of models.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p id="S3.SS1.SSS3.p2.1" class="ltx_p">To address the problem of data heterogeneity, Liu <span id="S3.SS1.SSS3.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> introduces federated transfer learning (FTL). FTL does not compromise user privacy and can transfer knowledge across domains in a data federation. This enables the target domain to utilize the rich labels of the source domain to build flexible and efficient models.
Li <span id="S3.SS1.SSS3.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> proposes FedMask, a FL framework for efficient communication and computation, where each device can learn an efficient personalized structured sparse model.
Zhang <span id="S3.SS1.SSS3.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> proposes for Federated Unsupervised Representation Learning (FURL) to learn generic representation models without supervision while preserving data privacy. FURL solves the problem of inconsistent and misaligned representation space through a dictionary module and an alignment module.
Similarly, Yan <span id="S3.SS1.SSS3.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> uses unsupervised representation to pre-train deep neural networks in a federated environment using unlabeled data, which allows for the extraction of discriminative features using pre-trained networks.
Wu <span id="S3.SS1.SSS3.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> proposes a communication-efficient FL algorithm, FedOnce, which is based on the privacy-preserving technique of momentary accounting and employs an unsupervised learning representation that enables better results to be achieved with only one-time communication between the parties.
Li <span id="S3.SS1.SSS3.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> proposed MOON to correct for local training of individuals using similarities between model representations.
Jang <span id="S3.SS1.SSS3.p2.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> proposes a personalized federated learning approach that applies local feature representation learning to stabilize the decision boundary and improve the local feature extraction capability of the client.
Tan <span id="S3.SS1.SSS3.p2.1.8" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> proposes FedProto, which only passes the prototype to the client without passing model parameters and gradients.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Model-Level Methods</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In this section, we discuss some advanced model-level FL methods for solving various heterogeneity types. Model-level methods means that these methods improve FL in terms of model parameters, model output, etc. Specifically, we classify these methods based on their adopted techniques, including parameter decoupling, model compression, knowledge distillation and federated optimization.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.5.1.1" class="ltx_text">III-B</span>1 </span>Parameter Decoupling</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.2" class="ltx_p">Parameter Decoupling based methods regard the whole model parameters as the composition of components, which play different roles in the process of training or inferring. Depending on the goal of parameter decoupling, different methods usually have different granularities. Some methods only regard the whole model as the composition of a backbone model and a head model, while some others decouple the model in a layer-wise or channel-wise, even coordinate-wise manner. Arivazhagan <span id="S3.SS2.SSS1.p1.2.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> propose FedPer, which split global model into base layers and personalized layers. Base layers are layers closer to the input side while the personalized layers are the remaining layers, and each client can customize the own architecture of personalized layers while sharing the architecture of base layers. In each round, only the parameters of base layers are uploaded to the server and then aggregated.
Based on the belief that data from all parties involved in FL often share global feature representations while reflect distribution and label skew in the labels, Collins <span id="S3.SS2.SSS1.p1.2.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> propose FedRep, which separate model into representation part and head part. The clients train a global representation in a federated manner and then train their own head based on the learned representation. Luo <span id="S3.SS2.SSS1.p1.2.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> empirically verify that distribution and label skew impact more on deeper layers, and then propose CCVR. CCVR utilizes regularization and calibration in local training to reduce weight bias, and trains a GMM to generate virtual representations for further classifier training. To solve the problem of long-tailed data in FL, Shang <span id="S3.SS2.SSS1.p1.2.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> propose CReFF, where clients upload real feature gradients, and then the server use them to optimize federated feature gradients for re-training classifier. Comparing to above works that enable shared global representations of features, Liang <span id="S3.SS2.SSS1.p1.2.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> propose LG-FedAvg, where clients share a common architecture of classifier, and each client learns compressed local representation for training a classifier suitable for local representations of all clients. Learning such local representations on the clients can also help alleviating task heterogeneity, encouraging the clients to learn and extract representations suitable for global classifiers. Xu <span id="S3.SS2.SSS1.p1.2.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> propose FedPAC, which encourage each client to learn global task variant information by regularizing local representations to approach the global feature centroid.
In order to train personalized client models under feature skew, distribution skew and other scenarios,
Shen <span id="S3.SS2.SSS1.p1.2.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> propose CD<sup id="S3.SS2.SSS1.p1.2.8" class="ltx_sup">2</sup>-pFed, which implement channel-wised personalization by channel-decoupling, and utilize personalized-weights to dynamically control the degree of personalization in each layer. Besides, CD<sup id="S3.SS2.SSS1.p1.2.9" class="ltx_sup">2</sup>-pFed also utilizes cyclic-distillation to mutually distill local and global model representations, bridging the semantic gap between the decoupled channels.
Recently, Chen <span id="S3.SS2.SSS1.p1.2.10" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> suggest that biased projection heads may cause unreliability on models when faced with data heterogeneity. Therefore, they propose APH method, where clients can get multiple initialized parameters from existing projection heads, and then fine-tune and average them, thus eliminating the bias.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">In order to reduce the memory cost of clients, Pillutla <span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> propose to divide the model parameters into two parts: shared parameters and personal parameters. Therefore, they propose FedSim and FedAlt, representing training both part of parameters in a simultaneous manner or an alternate manner, respectively. Yi <span id="S3.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> propose personalized FL method FedGH, where clients share a generalized head. The clients upload local average representation, which is utilized for individually training of the generalized head on the server side. Recently, to achieve model personalization when it is model heterogeneity, Wang <span id="S3.SS2.SSS1.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> propose pFedHR. In each round, the server performs layer-wise decomposition on client’s models, and then groups the layers. After that, the server uses the grouped layers to reassembly candidate models and fine-tune them with a public dataset.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">To alleviate the impact of device heterogeneity and communication heterogeneity, Diao <span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> propose HeteroFL, where the server determines the complexity level of each client based on its computation and communication capabilities, and assigns sub-models of different sizes to clients according to their complexity level. Recently, Yi <span id="S3.SS2.SSS1.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> point out that even pruned models can also reveal the real architecture of the global model. Therefore, they propose a novel framework FedP3, where clients only upload selected model parameters back to the server for privacy protection. Pfeiffer <span id="S3.SS2.SSS1.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite> empirically observe that the techniques based on sub-models suffer from performance degradation because the co-adaptation between parameters is broken. Thus, they propose Successive Layer Training (SLT). All clients can train the same parameters, but they begin at early layers with a down-scale head. After early layers are well trained, then SLT squeeze the parameters of early layers and expand the head layers for further training.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.5.1.1" class="ltx_text">III-B</span>2 </span>Model Compression</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.2" class="ltx_p">Model compression refers to compressing the size of a model and is commonly used to solve model, device and communication heterogeneity issues.
The commonly used compression methods in FL include sparsification, quantization and factorization. <span id="S3.SS2.SSS2.p1.2.1" class="ltx_text ltx_font_bold">Sparsification</span> usually means identify and retain the meaningful enough parameters, while setting other parameters to some constants. In this way, the parameter matrices are transformed to be sparse, and only those meaningful enough parameters are transmitted. Different from sparsification, <span id="S3.SS2.SSS2.p1.2.2" class="ltx_text ltx_font_bold">quantization</span> keeps the parameters dense and focuses on reducing the bit-width occupation of each parameter. A representative quantization method is SignSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>, which only retains the sign bit of each parameter. <span id="S3.SS2.SSS2.p1.2.3" class="ltx_text ltx_font_bold">Factorization</span> decompose a large matrix into the product of multiple low-rank matrices or vectors, and thus compress the size of the whole model with limited precision degradation. To compress both upstream and downstream communications, Sattler <span id="S3.SS2.SSS2.p1.2.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> point out that sparsification is more robust to Non-IID data and thus propose Sparse Ternary Compression (STC), which further quantizes the remaining top-<math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">k</annotation></semantics></math> elements to the mean population magnitude. Similar to the goal of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>, Amiri <span id="S3.SS2.SSS2.p1.2.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> propose Lossy Federated Learning (LFL). The server broadcast the quantized version the global model parameters to the clients, and the uploading parameters are also quantized. Shah <span id="S3.SS2.SSS2.p1.2.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite> propose to compress both downstream and upstream communications, but it goes further. To recover the loss of sparsity after aggregation, each client can perform sparse reconstruction for the averaged model, and it can also directly begin local training with the received sparse model, which can help in inducing sparsity in the client model.
Recently, Tang <span id="S3.SS2.SSS2.p1.2.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> point out that SignSGD is vulnerable to Non-IID data, and current corresponding methods cannot support multiple local SGD updates like FedAvg. Thus, they propose to inject some random noise before the sign operation to control the bias brought by it, and further propose the first sign-based FedAvg algorithm <math id="S3.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">z</annotation></semantics></math>-SignFedAvg.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">To combat the challenge of model and device heterogeneity, Yao <span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> propose FedHM, where the server compresses the large global model via low-rank factorization for each client to satisfy its resource availability, while preserving the model’s performance. Moreover, the compressed model can be transformed back to full-rank model for aggregation. Jeong <span id="S3.SS2.SSS2.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> propose Factorized-FL, which aims to factorize model parameters into basis vectors. Such factorized parameters space can make aggregation operation more robust to different labels and data, and separate client-specific and client-general knowledge. Recently, to perform personalized FL under scenario with data heterogeneity and device heterogeneity, Chen <span id="S3.SS2.SSS2.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> propose a novel personalized FL framework Fed-QSSL, where clients can perform low-bitwidth quantization training locally to satisfy its device constraint, and tackle data heterogeneity with distributed self-supervised learning.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS3.5.1.1" class="ltx_text">III-B</span>3 </span>Knowledge Distillation</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> is originally proposed for transferring knowledge from a larger model to a smaller model, and thus reducing the number of parameters. Generally speaking, This process requires the output of the smaller model to approach the larger one. Therefore, knowledge distillation can also be used for knowledge transferring between participants in FL. To alleviate the impact of feature skew and model heterogeneity, Huang <span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite> propose FCCL, where each client constructs a cross-correlation matrix according to other clients’ soft labels on public dataset. Besides, FCCL also utilize dual-domain knowledge distillation to alleviate catastrophic forgetting caused by domain shift. Zhu <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> <span id="S3.SS2.SSS3.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> propose FedGEN, where the server trains a light-weighted representation generator, and broadcast it to clients. While local training, the clients utilize the generated representations for knowledge distillation, hence get rid of reliance on public datasets. For scenarios with model heterogeneity and quality skew, Fang <span id="S3.SS2.SSS3.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> proposes RHFL, where clients combine cross entropy and reverse cross entropy to alleviate the impact of label noise, and perform knowledge distillation on a public dataset to reduce the knowledge gap between clients. Besides, RHFL also introduces client confidence re-weighting to reduce the negative impact caused by other clients’ noise. Recently, to combat severe label noise because of highly contaminated clients, Lu <span id="S3.SS2.SSS3.p1.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> propose FedNed, which identifies noisy clients and requires them to train models with noisy labels and pseudo-labels simultaneously. Then the models trained with noisy labels act as bad teachers for negative distillation, while the ones trained with pseudo-labels are used for aggregation. To learn personalized models under data heterogeneity, Chen <span id="S3.SS2.SSS3.p1.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> propose a method, which captures similarity between generic model and personalized models by spectral distillation. Moreover, it also establishes a co-distillation framework to bridge the knowledge of the generic model and personalized models.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS4.5.1.1" class="ltx_text">III-B</span>4 </span>Federated Optimization</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">Some methods introduce other techniques to the process of federated optimization, which can help the models to more adaptable to the local distributions or the global distribution. We mainly discuss three federated optimization techniques applies in model-level approaches: Multi-task learning, meta-learning and regularizing.</p>
</div>
<div id="S3.SS2.SSS4.p2" class="ltx_para">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p"><span id="S3.SS2.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Federated multi-task learning</span>. The core idea of multi-task learning is to train a model simultaneously to perform multiple related tasks, thereby improving the model’s generalization ability. By regarding each client’s local training as a separate task, multi-task learning techniques can help clients to learn personalized model with high generalization ability. Smith <span id="S3.SS2.SSS4.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> extend MTL method CoCoA from traditional distributed learning to federated environment, and propose MOCHA, which considers each client’s local training as a task and train a personalized model for each client. Corinzia <span id="S3.SS2.SSS4.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> propose to construct a Bayesian network between the server and the clients, and utilize variational inference for its optimization. Comparing to MOCHA, it requires no additional regularization term in local training objective and thus improve the efficiency of local training and ensuring network-agnostic FL. Besides, it also extends FMTL to scenarios with non-convex objectives. To learn a personalized model for devices that later join FL, Li <span id="S3.SS2.SSS4.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> propose OFMTL, which helps the new devices to learn with the assistance of weight matrix and precision matrix constructed by old devices, requiring no presence of earlier devices. Dinh <span id="S3.SS2.SSS4.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite> propose FedU, which introduce Laplacian regularization to determine the correlation between clients in FMTL. Besides, They also propose a decentralized version dFedU. Marfoq <span id="S3.SS2.SSS4.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> consider the data distribution of each client as a mixture of several latent distributions. Therefore, they propose FedEM, where clients can collaboratively train several generic component models, and each client only needs to learn how to mix these components to build a personalized model.</p>
</div>
<div id="S3.SS2.SSS4.p3" class="ltx_para">
<p id="S3.SS2.SSS4.p3.1" class="ltx_p"><span id="S3.SS2.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Meta-learning based FL</span>. Meta-learning, which is also known as ”learning to learn”, is usually used to design and train algorithms to quickly adapt to new tasks, typically when it is very little data. The core goal of meta-learning is to improve the flexibility and adaptability of learning algorithms, enabling them to learn from previous experiences and better handle new and unknown tasks. Chen <span id="S3.SS2.SSS4.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite> combine FL with meta-learning and then propose FedMeta, where all clients collaboratively train a initialization model. In FedMeta, each client upload its test loss on its query set which is used to update the initialization model. Each client can learn a personalized model from the initialization model by just a few local training, thus FedMeta can also reduce the training burden of the clients. Recently, Jeon <span id="S3.SS2.SSS4.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite> propose a Bayesian meta-learning based approach called MetaVD, where the server establishes a shared hypernetwork for predicting client-specific dropout rates, which are utilized for few-shot local adaptation on clients. Leo <span id="S3.SS2.SSS4.p3.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> propose FedL2P, which introduces meta-nets to inductively map each client’s Batch Normalization statistics to client-specific personalization hyperparameters. Scott <span id="S3.SS2.SSS4.p3.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> propose PeFLL. The server is equipped with a hypernetwork, which takes the descriptor of each client as input and personalized model parameters as output. The descriptor of each client is obtained with an embedding network, taking some data points as input. Thereby PeFLL overcomes the problems of high latency and client-side computation cost.</p>
</div>
<div id="S3.SS2.SSS4.p4" class="ltx_para">
<p id="S3.SS2.SSS4.p4.1" class="ltx_p"><span id="S3.SS2.SSS4.p4.1.1" class="ltx_text ltx_font_bold">Regularization based FL</span>. Regularization usually means adding a regularization term in the local training objectives and thus achieving some specific goals, such as tackling data heterogeneity. Li <span id="S3.SS2.SSS4.p4.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> propose FedProx, which adds a proximal term in local training objective to reduce the distance between the local model and the global model, and thus handles data heterogeneity. Besides, They also propose the concept of in-exact solution, enabling the clients to upload incompletely solved parameters and thus alleviate the problem of device heterogeneity. Kim <span id="S3.SS2.SSS4.p4.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> propose FedMLB, which separate models into several blocks, and each client form a main pathway and several hybrid pathways with the blocks. Regularization terms based on knowledge distillation are formed with the output of the main pathway and the hybrid pathways. Shoham <span id="S3.SS2.SSS4.p4.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> point out that due to data heterogeneity, the problem of forgetting in Sequential Lifelong Learning may also occur in FL. Therefore, they propose FedCurv, which introduces Elastic Weight Consolidation (EWC) to regularize model parameters during local training, and thus avoid forgetting the learned information from other clients. Similarly, Yao <span id="S3.SS2.SSS4.p4.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> propose FedCL, which utilize a proxy dataset to construct importance weight matrix of all local models to perform EWC regularization, and thus alleviate weight divergence. Dinh <span id="S3.SS2.SSS4.p4.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> propose pFedME, which introduce Moreau Envelope for regularization. It adds an L2 regularization term to the local objective to transform the entire FL into a two-level objective. The inner optimization obtains optimal personalized models while the outer one obtains the global model.
Karimireddy <span id="S3.SS2.SSS4.p4.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite> propose SCAFFOLD, utilizing control variables that reflect the update direction of the global model and the local models respectively, and then correct update direction of local model with a regularization term formed by their differences. Hanzely <span id="S3.SS2.SSS4.p4.1.8" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> propose a new formulation of FL, which no longer learn a single global model, but a mixture of the global model and the pure personalized models. To perform such FL formulation, this works proposes a novel randomized gradient-based method L2GD, for minimizing the loss function composed of average loss and penalty term.
Li <span id="S3.SS2.SSS4.p4.1.9" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> propose a personalized FL method Ditto, where each client perform local training on the global model and then on its personalized model, and applies regularization to the personalized model’s training to bring it closer to the global model. Besides, They also theoretically and empirically prove that Ditto has good robustness and fairness guarantee. Recently, Zhou <span id="S3.SS2.SSS4.p4.1.10" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> propose FedLNL, which designs a novel method based on Bayesian Inference for updating local Noise Transition Matrix (NTM) and thus avoid too large gradients, and then apply a diversity product regularizer in local training to utilize this method. Zhi <span id="S3.SS2.SSS4.p4.1.11" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite> suggest that each client can guide its local training referring to other clients’ parameters, and thus propose a regularizer based on a relation cube to conduct layer-wise parameters coaching. Li <span id="S3.SS2.SSS4.p4.1.12" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> empirically observe that current FL algorithms are highly susceptible to the degree of weight decay, and propose FedNAR. FedNAR is an algorithmic plug-in which can help controlling the magnitude of weight decay.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Architecture-Level Methods</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To address the federated heterogeneity challenge, making adjustments in the training structure is an emerging improvement. In this section, we discuss some heterogeneous methods that make adjustments on the FL architecture. Specifically, we classify these structure-level approaches into client selection, clustered federated learning, hierarchical federated learning, and decentralized federated learning.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.5.1.1" class="ltx_text">III-C</span>1 </span>Client selection</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Client selection refers to the process of selecting a subset of available clients to participate in model updates during the training process. This selection can directly impact the efficiency and effectiveness of the training. Effective client selection can address issues of data heterogeneity and constraints related to communication and computation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">To alleviate the pressure of heterogeneity, Nishio <span id="S3.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> proposed that FedCS uses a greedy algorithm to solve the client selection problem with resource constraints, which allows the server to aggregate as many client updates as possible and accelerate the performance improvement of ML models.
Yoshida <span id="S3.SS3.SSS1.p2.1.2" class="ltx_text ltx_font_italic">et al</span>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> adopted a heuristic algorithm and proposed a hybrid learning mechanism called Hybrid-FL, trying to select the best set of clients to use their own data to train the model.
Wang <span id="S3.SS3.SSS1.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> introduced an experience-driven control framework, Favor, which intelligently selects client devices to participate in each round of FL to offset the bias introduced by non-IID data and accelerate the convergence speed.
Xu <span id="S3.SS3.SSS1.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> proposes a stochastic optimization problem that jointly connects client selection and bandwidth allocation under long-term client constraints.
lai2021oort <span id="S3.SS3.SSS1.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> proposed Oort to improve the performance of joint training and testing by guiding participant selection. Oort uses existing data to improve model accuracy and speed up training.
Wu <span id="S3.SS3.SSS1.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite> proposed a probabilistic node selection framework, FedPNS, which dynamically changes the probability of each node being selected based on the output of the optimal aggregation.
Cho <span id="S3.SS3.SSS1.p2.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite> presents a convergence analysis of FL of biased customer selection via efficient selection aggregation and quantifies how bias affects the convergence speed.
Li <span id="S3.SS3.SSS1.p2.1.8" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite> proposed PyramidFL to speed up FL training while achieving higher final model performance. At the heart of PyramidFL is fine-grained client selection, not only focusing on the differences in client selection between those selected and unselected participants, but also fully exploiting data and system heterogeneity within selected clients.
Ribero <span id="S3.SS3.SSS1.p2.1.9" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> proposes a federated averaging algorithm assisted by an adaptive sampling technique, F3AST, an unbiased algorithm that dynamically learns an availability-dependent client selection strategy that asymptotically minimizes client sampling variance to global model convergence The impact improves the performance of joint learning.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.5.1.1" class="ltx_text">III-C</span>2 </span>Clustered Federated Learning</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Clustering FL is used to deal with situations where the data distribution is highly heterogeneous. This approach trains the model in a more homogeneous group by clustering clients based on the similarity of their data.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">CFL (Cluster Federated Learning) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite> is a method of recursively clustering clients by exploiting the cosine similarity between client gradient updates during each round of FL training. This clustering allows for a more targeted and efficient distribution of training tasks among clients with similar characteristics.
IFCA (Intra-cluster Federated Average) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite> is another clustered FL method that utilizes the loss of models within different clusters on the client’s local dataset to cluster clients. In each round, IFCA randomly selects a portion of clients within each cluster for training and updates the intra-cluster models by aggregating the local models within the cluster.
PACFL (Personalized and Clustered Federated Learning) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> clusters clients by uploading data information from each client to the server and taking measurements of the principal angles between client data subspaces before the FL process begins. During each round of joint learning, PACFL updates each intra-cluster model with a weighted aggregation of the local models of the intra-cluster clients, enabling personalized learning while still taking advantage of clustering.
FedSoft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> is a cluster FL framework designed to train both local personalized models and high-quality cluster models. In order to limit the workload of the clients, FedSoft employs proximal updating, which allows only a subset of clients to complete an optimization task in each round of communication.
ACFL (Auction-based Cluster Federated Learning) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> introduces a mean-shift clustering algorithm that intelligently groups clients based on their local data distributions. This clustering approach allows FL systems to identify groups of clients with similar data characteristics, enabling more targeted and efficient model training.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS3.5.1.1" class="ltx_text">III-C</span>3 </span>Hierarchical Federation Learning</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Hierarchical Federated Learning is a more organizationally complex FL architecture that employs a multilevel federation model to manage and train clients distributed at different levels. This model is usually suitable for scenarios with a multi-layered network structure. It is worth noting that hierarchical FL focuses on how to organize and optimize the learning process in networks with a well-defined hierarchical structure, e.g., federated edge learning. In contrast, clustered FL focuses more on grouping clients based on data similarity without the need for an explicit hierarchical structure.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p">Liu <span id="S3.SS3.SSS3.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite> propose a client-edge cloud hierarchical joint learning system, HierFAVG, an algorithm that allows multiple edge servers to perform partial model aggregation, which allows for better communication and utility tradeoffs.
Abad <span id="S3.SS3.SSS3.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> collaboratively learn global models by sharing local updates of model parameters instead of their dataset, and in this way use a hierarchical joint learning scheme to significantly reduce communication latency without sacrificing accuracy.
Briggs <span id="S3.SS3.SSS3.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite> separated clusters of clients by introducing a hierarchical clustering step that uses the similarity of the client’s local updates to the global joint model.
Xu <span id="S3.SS3.SSS3.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite> consider a hierarchical FL system and propose a joint problem of edge aggregation interval control and resource allocation to minimize a weighted sum of training loss and training delay.
Lim <span id="S3.SS3.SSS3.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite> use an evolutionary game to model workers’ edge association strategies and propose a hierarchical game framework to study the dynamics of edge association and resource allocation in self-organizing HFL networks.
Abdellatif <span id="S3.SS3.SSS3.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> investigated the potential of hierarchical FL in IoT heterogeneous systems and proposed a user assignment and resource allocation method on a hierarchical FL architecture for IoT heterogeneous systems.
Zhou <span id="S3.SS3.SSS3.p2.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite> proposed a unique clustering-based approach for participant selection using social context data. By creating different groups of edge participants and performing group-specific joint learning, the models of various edge groups are further aggregated to enhance the robustness of the global model.
Ma <span id="S3.SS3.SSS3.p2.1.8" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite> proposed FedUC, which clusters workers through a hierarchical aggregation structure to solve the edge heterogeneity problem and reduce the communication consumption of FL.
Deng <span id="S3.SS3.SSS3.p2.1.9" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite> proposed a communication cost minimization problem in the HFL framework by making decisions on edge enhancer selection and node edge association in order to achieve the target accuracy of the total communication cost required for model learning.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS4.5.1.1" class="ltx_text">III-C</span>4 </span>Decentralized Federated Learning</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.1" class="ltx_p">Decentralized federated learning (DFL) is an approach that does not rely on a central server to manage model training. Compared with traditional centralized federated learning, decentralized methods provide higher privacy protection.</p>
</div>
<div id="S3.SS3.SSS4.p2" class="ltx_para">
<p id="S3.SS3.SSS4.p2.1" class="ltx_p">Li <span id="S3.SS3.SSS4.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> developed a decentralized FL framework BFLC based on blockchain with committee consensus. It uses blockchain for global model storage and local model update exchange <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>, and reduces malicious client attacks through committee verification composed of honest clients.
Lim <span id="S3.SS3.SSS4.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite> proposed a deep learning-based auction mechanism to derive the valuation of the services of each cluster leader.
ye <span id="S3.SS3.SSS4.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> proposed a robust decentralized stochastic gradient descent federated method, called soft DSGD, to solve the problem of unreliable transmission process.
Pappas <span id="S3.SS3.SSS4.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> designed a fully decentralized FL framework based in part on the Inter Planetary File System (IPFS). By using IPLS and connecting to the corresponding private IPFS network, any party can initiate the training process of a machine learning model, or join an ongoing training process initiated by the other party.
Liu <span id="S3.SS3.SSS4.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> proposed a general DFL framework that regularly implements multiple local updates and multiple inter-node communications to strike a balance between communication efficiency and model consistency.
Kalra <span id="S3.SS3.SSS4.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> proposed an efficient communication scheme for decentralized FL, called ProxyFL. Each participant in ProxyFL maintains two models, one is a private model and the other is a public shared proxy model. Designed to protect participant privacy. The agent model allows efficient information exchange between participants without the need for a centralized server.
HegedHus <span id="S3.SS3.SSS4.p2.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite> believe that Gossip learning is a decentralized alternative to FL, so they designed a DFL training algorithm based on the Gossip protocol.
Qu <span id="S3.SS3.SSS4.p2.1.8" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite> proposed a new architecture called DFL for drone networks (DFL-UN), which implements FL in drone networks without the need for a central entity.
Beltran <span id="S3.SS3.SSS4.p2.1.9" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite> introduced a novel platform, Fedstar, which allows users to create federations by customizing parameters. Fedstar aims to train FL models in different federations of physical or virtual devices in a decentralized, semi-decentralized and centralized manner.
Zhou <span id="S3.SS3.SSS4.p2.1.10" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> proposed a decentralized federated trusted average (DeFTA), as a plug-and-play replacement for FedAvg, brings immediate improvements to security, scalability, and fault tolerance in the FL process.
Cheng <span id="S3.SS3.SSS4.p2.1.11" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> used a decentralized and trusted aggregation strategy to introduce DeTA, a decentralized FL system architecture, and designed a defense-in-depth model.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Privacy Protection in Heterogeneous Federated Learning</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we will focus on the privacy and security issues in heterogeneous FL. As is well recognized, FL frameworks are deployed over the internet. The complex and unpredictable network environment poses potential vulnerabilities for attacks on the FL process. This underscores the necessity of employing protective measures within FL applications. Since the inception of the concept of FL, researchers have published a range of attack methods targeting the exposure of certain stages to the network environment. These methods can launch attacks at various stages, such as dataset preparation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>, model transmission <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite>, and model aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite>, with malicious intentions of privacy theft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite> or interference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite> with the training process. Among them, model inversion attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, which involve eavesdropping on the model transmission channel to intercept the model and attempt to reconstruct the client’s private data from the captured information, pose significant threats to FL frameworks. In some cases, it is even possible to fully reconstruct the private dataset from the model. For attack vectors such as model inversion attacks, model protection is particularly critical. Through years of research, model protection can be categorized into three types <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>: differential privacy, secure multi-party computation, and model tracing, each providing pre-emptive or post-emptive protection for the transmitted models from different perspectives. It is noteworthy that different types of protective methods will have varying impacts on the trade-off <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>, <a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite> between privacy, utility, and efficiency, thus analyzing privacy-preserving strategies is crucial for privacy-utility trade-offs in heterogeneous FL.
We show common FL privacy-preserving strategies in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A Differential Privacy ‣ IV Privacy Protection in Heterogeneous Federated Learning ‣ Advances in Robust Federated Learning: Heterogeneity Considerations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Differential Privacy</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>, initially proposed by Dwork et al., is a privacy definition from the field of database security. Since the introduction of FL, differential privacy has attracted the interest of many researchers due to its provable and quantifiable privacy. Generally speaking, FL frameworks meet the requirements of DP through a noise mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite>, which means that almost all DP methods will sacrifice model utility to obtain privacy, with little impact on training efficiency.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2405.09839/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Illustration for Protect Methods</figcaption>
</figure>
<section id="S4.SS1.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS1.5.1.1" class="ltx_text">IV-A</span>1 </span>DP and Noising Mechanism</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Based on relevant derivations, we generally use a noise mechanism to perturb the transmitted model, thereby making the entire FL mechanism satisfy DP. This mechanism is also known as <span id="S4.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_bold">model perturbation</span>. Before introducing the noise mechanism in detail, we first give the formal definition of DP.</p>
</div>
<div id="Thmtheorem1" class="ltx_theorem ltx_theorem_theorem">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmtheorem1.2.2.1" class="ltx_text ltx_font_bold">Theorem 1</span></span><span id="Thmtheorem1.1.1" class="ltx_text ltx_font_bold"> ( <math id="Thmtheorem1.1.1.m1.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="Thmtheorem1.1.1.m1.2b"><mrow id="Thmtheorem1.1.1.m1.2.3.2" xref="Thmtheorem1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="Thmtheorem1.1.1.m1.2.3.2.1" xref="Thmtheorem1.1.1.m1.2.3.1.cmml">(</mo><mi id="Thmtheorem1.1.1.m1.1.1" xref="Thmtheorem1.1.1.m1.1.1.cmml">ε</mi><mo id="Thmtheorem1.1.1.m1.2.3.2.2" xref="Thmtheorem1.1.1.m1.2.3.1.cmml">,</mo><mi id="Thmtheorem1.1.1.m1.2.2" xref="Thmtheorem1.1.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="Thmtheorem1.1.1.m1.2.3.2.3" xref="Thmtheorem1.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.1.1.m1.2c"><interval closure="open" id="Thmtheorem1.1.1.m1.2.3.1.cmml" xref="Thmtheorem1.1.1.m1.2.3.2"><ci id="Thmtheorem1.1.1.m1.1.1.cmml" xref="Thmtheorem1.1.1.m1.1.1">𝜀</ci><ci id="Thmtheorem1.1.1.m1.2.2.cmml" xref="Thmtheorem1.1.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.1.1.m1.2d">(\varepsilon,\delta)</annotation></semantics></math>-DP).</span>
</h6>
<div id="Thmtheorem1.p1" class="ltx_para">
<p id="Thmtheorem1.p1.6" class="ltx_p"><span id="Thmtheorem1.p1.6.6" class="ltx_text ltx_font_italic">A randomized mechanism <math id="Thmtheorem1.p1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{M}:\cal{X}\mapsto\cal{R}" display="inline"><semantics id="Thmtheorem1.p1.1.1.m1.1a"><mrow id="Thmtheorem1.p1.1.1.m1.1.1" xref="Thmtheorem1.p1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.1.1.m1.1.1.2" xref="Thmtheorem1.p1.1.1.m1.1.1.2.cmml">ℳ</mi><mo lspace="0.278em" rspace="0.278em" id="Thmtheorem1.p1.1.1.m1.1.1.1" xref="Thmtheorem1.p1.1.1.m1.1.1.1.cmml">:</mo><mrow id="Thmtheorem1.p1.1.1.m1.1.1.3" xref="Thmtheorem1.p1.1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.1.1.m1.1.1.3.2" xref="Thmtheorem1.p1.1.1.m1.1.1.3.2.cmml">𝒳</mi><mo stretchy="false" id="Thmtheorem1.p1.1.1.m1.1.1.3.1" xref="Thmtheorem1.p1.1.1.m1.1.1.3.1.cmml">↦</mo><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.1.1.m1.1.1.3.3" xref="Thmtheorem1.p1.1.1.m1.1.1.3.3.cmml">ℛ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.1.1.m1.1b"><apply id="Thmtheorem1.p1.1.1.m1.1.1.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1"><ci id="Thmtheorem1.p1.1.1.m1.1.1.1.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.1">:</ci><ci id="Thmtheorem1.p1.1.1.m1.1.1.2.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.2">ℳ</ci><apply id="Thmtheorem1.p1.1.1.m1.1.1.3.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.3"><csymbol cd="latexml" id="Thmtheorem1.p1.1.1.m1.1.1.3.1.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.3.1">maps-to</csymbol><ci id="Thmtheorem1.p1.1.1.m1.1.1.3.2.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.3.2">𝒳</ci><ci id="Thmtheorem1.p1.1.1.m1.1.1.3.3.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.3.3">ℛ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.1.1.m1.1c">\mathcal{M}:\cal{X}\mapsto\cal{R}</annotation></semantics></math> with domain <math id="Thmtheorem1.p1.2.2.m2.1" class="ltx_Math" alttext="\cal{X}" display="inline"><semantics id="Thmtheorem1.p1.2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.2.2.m2.1.1" xref="Thmtheorem1.p1.2.2.m2.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.2.2.m2.1b"><ci id="Thmtheorem1.p1.2.2.m2.1.1.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.2.2.m2.1c">\cal{X}</annotation></semantics></math> and range <math id="Thmtheorem1.p1.3.3.m3.1" class="ltx_Math" alttext="\cal{R}" display="inline"><semantics id="Thmtheorem1.p1.3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.3.3.m3.1.1" xref="Thmtheorem1.p1.3.3.m3.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.3.3.m3.1b"><ci id="Thmtheorem1.p1.3.3.m3.1.1.cmml" xref="Thmtheorem1.p1.3.3.m3.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.3.3.m3.1c">\cal{R}</annotation></semantics></math> satisfies <math id="Thmtheorem1.p1.4.4.m4.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="Thmtheorem1.p1.4.4.m4.2a"><mrow id="Thmtheorem1.p1.4.4.m4.2.3.2" xref="Thmtheorem1.p1.4.4.m4.2.3.1.cmml"><mo stretchy="false" id="Thmtheorem1.p1.4.4.m4.2.3.2.1" xref="Thmtheorem1.p1.4.4.m4.2.3.1.cmml">(</mo><mi id="Thmtheorem1.p1.4.4.m4.1.1" xref="Thmtheorem1.p1.4.4.m4.1.1.cmml">ε</mi><mo id="Thmtheorem1.p1.4.4.m4.2.3.2.2" xref="Thmtheorem1.p1.4.4.m4.2.3.1.cmml">,</mo><mi id="Thmtheorem1.p1.4.4.m4.2.2" xref="Thmtheorem1.p1.4.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="Thmtheorem1.p1.4.4.m4.2.3.2.3" xref="Thmtheorem1.p1.4.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.4.4.m4.2b"><interval closure="open" id="Thmtheorem1.p1.4.4.m4.2.3.1.cmml" xref="Thmtheorem1.p1.4.4.m4.2.3.2"><ci id="Thmtheorem1.p1.4.4.m4.1.1.cmml" xref="Thmtheorem1.p1.4.4.m4.1.1">𝜀</ci><ci id="Thmtheorem1.p1.4.4.m4.2.2.cmml" xref="Thmtheorem1.p1.4.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.4.4.m4.2c">(\varepsilon,\delta)</annotation></semantics></math>-DP if,
for any two adjacent inputs <math id="Thmtheorem1.p1.5.5.m5.2" class="ltx_Math" alttext="x,x^{\prime}\in\cal{X}" display="inline"><semantics id="Thmtheorem1.p1.5.5.m5.2a"><mrow id="Thmtheorem1.p1.5.5.m5.2.2" xref="Thmtheorem1.p1.5.5.m5.2.2.cmml"><mrow id="Thmtheorem1.p1.5.5.m5.2.2.1.1" xref="Thmtheorem1.p1.5.5.m5.2.2.1.2.cmml"><mi id="Thmtheorem1.p1.5.5.m5.1.1" xref="Thmtheorem1.p1.5.5.m5.1.1.cmml">x</mi><mo id="Thmtheorem1.p1.5.5.m5.2.2.1.1.2" xref="Thmtheorem1.p1.5.5.m5.2.2.1.2.cmml">,</mo><msup id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.cmml"><mi id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.2" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.2.cmml">x</mi><mo id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.3" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.3.cmml">′</mo></msup></mrow><mo id="Thmtheorem1.p1.5.5.m5.2.2.2" xref="Thmtheorem1.p1.5.5.m5.2.2.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.5.5.m5.2.2.3" xref="Thmtheorem1.p1.5.5.m5.2.2.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.5.5.m5.2b"><apply id="Thmtheorem1.p1.5.5.m5.2.2.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2"><in id="Thmtheorem1.p1.5.5.m5.2.2.2.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.2"></in><list id="Thmtheorem1.p1.5.5.m5.2.2.1.2.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1"><ci id="Thmtheorem1.p1.5.5.m5.1.1.cmml" xref="Thmtheorem1.p1.5.5.m5.1.1">𝑥</ci><apply id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.1.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1">superscript</csymbol><ci id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.2.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.2">𝑥</ci><ci id="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.3.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.1.1.1.3">′</ci></apply></list><ci id="Thmtheorem1.p1.5.5.m5.2.2.3.cmml" xref="Thmtheorem1.p1.5.5.m5.2.2.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.5.5.m5.2c">x,x^{\prime}\in\cal{X}</annotation></semantics></math> and for any subsets of outputs <math id="Thmtheorem1.p1.6.6.m6.1" class="ltx_Math" alttext="\cal{S}\subseteq\cal{R}" display="inline"><semantics id="Thmtheorem1.p1.6.6.m6.1a"><mrow id="Thmtheorem1.p1.6.6.m6.1.1" xref="Thmtheorem1.p1.6.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.6.6.m6.1.1.2" xref="Thmtheorem1.p1.6.6.m6.1.1.2.cmml">𝒮</mi><mo id="Thmtheorem1.p1.6.6.m6.1.1.1" xref="Thmtheorem1.p1.6.6.m6.1.1.1.cmml">⊆</mo><mi class="ltx_font_mathcaligraphic" id="Thmtheorem1.p1.6.6.m6.1.1.3" xref="Thmtheorem1.p1.6.6.m6.1.1.3.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.6.6.m6.1b"><apply id="Thmtheorem1.p1.6.6.m6.1.1.cmml" xref="Thmtheorem1.p1.6.6.m6.1.1"><subset id="Thmtheorem1.p1.6.6.m6.1.1.1.cmml" xref="Thmtheorem1.p1.6.6.m6.1.1.1"></subset><ci id="Thmtheorem1.p1.6.6.m6.1.1.2.cmml" xref="Thmtheorem1.p1.6.6.m6.1.1.2">𝒮</ci><ci id="Thmtheorem1.p1.6.6.m6.1.1.3.cmml" xref="Thmtheorem1.p1.6.6.m6.1.1.3">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.6.6.m6.1c">\cal{S}\subseteq\cal{R}</annotation></semantics></math> it holds that</span></p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.7" class="ltx_Math" alttext="\Pr[\mathcal{M}(x)\in\mathcal{S}]\leq\exp(\varepsilon)\cdot\Pr[\mathcal{M}(x^{\prime})\in\mathcal{S}]+\delta" display="block"><semantics id="S4.E3.m1.7a"><mrow id="S4.E3.m1.7.7" xref="S4.E3.m1.7.7.cmml"><mrow id="S4.E3.m1.6.6.1.1" xref="S4.E3.m1.6.6.1.2.cmml"><mi id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml">Pr</mi><mo id="S4.E3.m1.6.6.1.1a" xref="S4.E3.m1.6.6.1.2.cmml">⁡</mo><mrow id="S4.E3.m1.6.6.1.1.1" xref="S4.E3.m1.6.6.1.2.cmml"><mo stretchy="false" id="S4.E3.m1.6.6.1.1.1.2" xref="S4.E3.m1.6.6.1.2.cmml">[</mo><mrow id="S4.E3.m1.6.6.1.1.1.1" xref="S4.E3.m1.6.6.1.1.1.1.cmml"><mrow id="S4.E3.m1.6.6.1.1.1.1.2" xref="S4.E3.m1.6.6.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.6.6.1.1.1.1.2.2" xref="S4.E3.m1.6.6.1.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.6.6.1.1.1.1.2.1" xref="S4.E3.m1.6.6.1.1.1.1.2.1.cmml">​</mo><mrow id="S4.E3.m1.6.6.1.1.1.1.2.3.2" xref="S4.E3.m1.6.6.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E3.m1.6.6.1.1.1.1.2.3.2.1" xref="S4.E3.m1.6.6.1.1.1.1.2.cmml">(</mo><mi id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml">x</mi><mo stretchy="false" id="S4.E3.m1.6.6.1.1.1.1.2.3.2.2" xref="S4.E3.m1.6.6.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.6.6.1.1.1.1.1" xref="S4.E3.m1.6.6.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.6.6.1.1.1.1.3" xref="S4.E3.m1.6.6.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S4.E3.m1.6.6.1.1.1.3" xref="S4.E3.m1.6.6.1.2.cmml">]</mo></mrow></mrow><mo id="S4.E3.m1.7.7.3" xref="S4.E3.m1.7.7.3.cmml">≤</mo><mrow id="S4.E3.m1.7.7.2" xref="S4.E3.m1.7.7.2.cmml"><mrow id="S4.E3.m1.7.7.2.1" xref="S4.E3.m1.7.7.2.1.cmml"><mrow id="S4.E3.m1.7.7.2.1.3.2" xref="S4.E3.m1.7.7.2.1.3.1.cmml"><mi id="S4.E3.m1.3.3" xref="S4.E3.m1.3.3.cmml">exp</mi><mo id="S4.E3.m1.7.7.2.1.3.2a" xref="S4.E3.m1.7.7.2.1.3.1.cmml">⁡</mo><mrow id="S4.E3.m1.7.7.2.1.3.2.1" xref="S4.E3.m1.7.7.2.1.3.1.cmml"><mo stretchy="false" id="S4.E3.m1.7.7.2.1.3.2.1.1" xref="S4.E3.m1.7.7.2.1.3.1.cmml">(</mo><mi id="S4.E3.m1.4.4" xref="S4.E3.m1.4.4.cmml">ε</mi><mo rspace="0.055em" stretchy="false" id="S4.E3.m1.7.7.2.1.3.2.1.2" xref="S4.E3.m1.7.7.2.1.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.E3.m1.7.7.2.1.2" xref="S4.E3.m1.7.7.2.1.2.cmml">⋅</mo><mrow id="S4.E3.m1.7.7.2.1.1.1" xref="S4.E3.m1.7.7.2.1.1.2.cmml"><mi id="S4.E3.m1.5.5" xref="S4.E3.m1.5.5.cmml">Pr</mi><mo id="S4.E3.m1.7.7.2.1.1.1a" xref="S4.E3.m1.7.7.2.1.1.2.cmml">⁡</mo><mrow id="S4.E3.m1.7.7.2.1.1.1.1" xref="S4.E3.m1.7.7.2.1.1.2.cmml"><mo stretchy="false" id="S4.E3.m1.7.7.2.1.1.1.1.2" xref="S4.E3.m1.7.7.2.1.1.2.cmml">[</mo><mrow id="S4.E3.m1.7.7.2.1.1.1.1.1" xref="S4.E3.m1.7.7.2.1.1.1.1.1.cmml"><mrow id="S4.E3.m1.7.7.2.1.1.1.1.1.1" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.7.7.2.1.1.1.1.1.1.3" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.7.7.2.1.1.1.1.1.1.2" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.7.7.2.1.1.1.1.1.2" xref="S4.E3.m1.7.7.2.1.1.1.1.1.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.7.7.2.1.1.1.1.1.3" xref="S4.E3.m1.7.7.2.1.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S4.E3.m1.7.7.2.1.1.1.1.3" xref="S4.E3.m1.7.7.2.1.1.2.cmml">]</mo></mrow></mrow></mrow><mo id="S4.E3.m1.7.7.2.2" xref="S4.E3.m1.7.7.2.2.cmml">+</mo><mi id="S4.E3.m1.7.7.2.3" xref="S4.E3.m1.7.7.2.3.cmml">δ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.7b"><apply id="S4.E3.m1.7.7.cmml" xref="S4.E3.m1.7.7"><leq id="S4.E3.m1.7.7.3.cmml" xref="S4.E3.m1.7.7.3"></leq><apply id="S4.E3.m1.6.6.1.2.cmml" xref="S4.E3.m1.6.6.1.1"><ci id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2">Pr</ci><apply id="S4.E3.m1.6.6.1.1.1.1.cmml" xref="S4.E3.m1.6.6.1.1.1.1"><in id="S4.E3.m1.6.6.1.1.1.1.1.cmml" xref="S4.E3.m1.6.6.1.1.1.1.1"></in><apply id="S4.E3.m1.6.6.1.1.1.1.2.cmml" xref="S4.E3.m1.6.6.1.1.1.1.2"><times id="S4.E3.m1.6.6.1.1.1.1.2.1.cmml" xref="S4.E3.m1.6.6.1.1.1.1.2.1"></times><ci id="S4.E3.m1.6.6.1.1.1.1.2.2.cmml" xref="S4.E3.m1.6.6.1.1.1.1.2.2">ℳ</ci><ci id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1">𝑥</ci></apply><ci id="S4.E3.m1.6.6.1.1.1.1.3.cmml" xref="S4.E3.m1.6.6.1.1.1.1.3">𝒮</ci></apply></apply><apply id="S4.E3.m1.7.7.2.cmml" xref="S4.E3.m1.7.7.2"><plus id="S4.E3.m1.7.7.2.2.cmml" xref="S4.E3.m1.7.7.2.2"></plus><apply id="S4.E3.m1.7.7.2.1.cmml" xref="S4.E3.m1.7.7.2.1"><ci id="S4.E3.m1.7.7.2.1.2.cmml" xref="S4.E3.m1.7.7.2.1.2">⋅</ci><apply id="S4.E3.m1.7.7.2.1.3.1.cmml" xref="S4.E3.m1.7.7.2.1.3.2"><exp id="S4.E3.m1.3.3.cmml" xref="S4.E3.m1.3.3"></exp><ci id="S4.E3.m1.4.4.cmml" xref="S4.E3.m1.4.4">𝜀</ci></apply><apply id="S4.E3.m1.7.7.2.1.1.2.cmml" xref="S4.E3.m1.7.7.2.1.1.1"><ci id="S4.E3.m1.5.5.cmml" xref="S4.E3.m1.5.5">Pr</ci><apply id="S4.E3.m1.7.7.2.1.1.1.1.1.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1"><in id="S4.E3.m1.7.7.2.1.1.1.1.1.2.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.2"></in><apply id="S4.E3.m1.7.7.2.1.1.1.1.1.1.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1"><times id="S4.E3.m1.7.7.2.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.2"></times><ci id="S4.E3.m1.7.7.2.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.3">ℳ</ci><apply id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="S4.E3.m1.7.7.2.1.1.1.1.1.3.cmml" xref="S4.E3.m1.7.7.2.1.1.1.1.1.3">𝒮</ci></apply></apply></apply><ci id="S4.E3.m1.7.7.2.3.cmml" xref="S4.E3.m1.7.7.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.7c">\Pr[\mathcal{M}(x)\in\mathcal{S}]\leq\exp(\varepsilon)\cdot\Pr[\mathcal{M}(x^{\prime})\in\mathcal{S}]+\delta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="Thmtheorem1.p1.8" class="ltx_p"><span id="Thmtheorem1.p1.8.2" class="ltx_text ltx_font_italic">where <math id="Thmtheorem1.p1.7.1.m1.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="Thmtheorem1.p1.7.1.m1.2a"><mrow id="Thmtheorem1.p1.7.1.m1.2.3.2" xref="Thmtheorem1.p1.7.1.m1.2.3.1.cmml"><mo stretchy="false" id="Thmtheorem1.p1.7.1.m1.2.3.2.1" xref="Thmtheorem1.p1.7.1.m1.2.3.1.cmml">(</mo><mi id="Thmtheorem1.p1.7.1.m1.1.1" xref="Thmtheorem1.p1.7.1.m1.1.1.cmml">ε</mi><mo id="Thmtheorem1.p1.7.1.m1.2.3.2.2" xref="Thmtheorem1.p1.7.1.m1.2.3.1.cmml">,</mo><mi id="Thmtheorem1.p1.7.1.m1.2.2" xref="Thmtheorem1.p1.7.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="Thmtheorem1.p1.7.1.m1.2.3.2.3" xref="Thmtheorem1.p1.7.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.7.1.m1.2b"><interval closure="open" id="Thmtheorem1.p1.7.1.m1.2.3.1.cmml" xref="Thmtheorem1.p1.7.1.m1.2.3.2"><ci id="Thmtheorem1.p1.7.1.m1.1.1.cmml" xref="Thmtheorem1.p1.7.1.m1.1.1">𝜀</ci><ci id="Thmtheorem1.p1.7.1.m1.2.2.cmml" xref="Thmtheorem1.p1.7.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.7.1.m1.2c">(\varepsilon,\delta)</annotation></semantics></math> is privacy budget. The smaller the value of <math id="Thmtheorem1.p1.8.2.m2.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="Thmtheorem1.p1.8.2.m2.1a"><mi id="Thmtheorem1.p1.8.2.m2.1.1" xref="Thmtheorem1.p1.8.2.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.8.2.m2.1b"><ci id="Thmtheorem1.p1.8.2.m2.1.1.cmml" xref="Thmtheorem1.p1.8.2.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.8.2.m2.1c">\varepsilon</annotation></semantics></math>, the stronger the level of protection provided by differential privacy.
<span id="Thmtheorem1.p1.8.2.1" class="ltx_text ltx_align_floatright"></span></span></p>
</div>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.2" class="ltx_p">In the context of model perturbation, the model information prepared for transmission undergoes two stages of processing. The first stage is model clipping, which involves setting a threshold <math id="S4.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.SS1.SSS1.p2.1.m1.1a"><mi id="S4.SS1.SSS1.p2.1.m1.1.1" xref="S4.SS1.SSS1.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.1.m1.1b"><ci id="S4.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p2.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.1.m1.1c">C</annotation></semantics></math>. If the norm of the model exceeds this threshold, the model is scaled proportionally until its norm equals the threshold. The second stage involves noising, specifically generating Gaussian noise with a chosen standard deviation <math id="S4.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS1.SSS1.p2.2.m2.1a"><mi id="S4.SS1.SSS1.p2.2.m2.1.1" xref="S4.SS1.SSS1.p2.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.2.m2.1b"><ci id="S4.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p2.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.2.m2.1c">\sigma</annotation></semantics></math> to perturb the model.</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<table id="S4.E4" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E4X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\text{Clipping:}\quad\hat{\theta}" display="inline"><semantics id="S4.E4X.2.1.1.m1.2a"><mrow id="S4.E4X.2.1.1.m1.2.3.2" xref="S4.E4X.2.1.1.m1.2.3.1.cmml"><mtext id="S4.E4X.2.1.1.m1.1.1" xref="S4.E4X.2.1.1.m1.1.1a.cmml">Clipping:</mtext><mspace width="1em" id="S4.E4X.2.1.1.m1.2.3.2.1" xref="S4.E4X.2.1.1.m1.2.3.1.cmml"></mspace><mover accent="true" id="S4.E4X.2.1.1.m1.2.2" xref="S4.E4X.2.1.1.m1.2.2.cmml"><mi id="S4.E4X.2.1.1.m1.2.2.2" xref="S4.E4X.2.1.1.m1.2.2.2.cmml">θ</mi><mo id="S4.E4X.2.1.1.m1.2.2.1" xref="S4.E4X.2.1.1.m1.2.2.1.cmml">^</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S4.E4X.2.1.1.m1.2b"><list id="S4.E4X.2.1.1.m1.2.3.1.cmml" xref="S4.E4X.2.1.1.m1.2.3.2"><ci id="S4.E4X.2.1.1.m1.1.1a.cmml" xref="S4.E4X.2.1.1.m1.1.1"><mtext id="S4.E4X.2.1.1.m1.1.1.cmml" xref="S4.E4X.2.1.1.m1.1.1">Clipping:</mtext></ci><apply id="S4.E4X.2.1.1.m1.2.2.cmml" xref="S4.E4X.2.1.1.m1.2.2"><ci id="S4.E4X.2.1.1.m1.2.2.1.cmml" xref="S4.E4X.2.1.1.m1.2.2.1">^</ci><ci id="S4.E4X.2.1.1.m1.2.2.2.cmml" xref="S4.E4X.2.1.1.m1.2.2.2">𝜃</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.E4X.2.1.1.m1.2c">\displaystyle\text{Clipping:}\quad\hat{\theta}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E4X.3.2.2.m1.4" class="ltx_Math" alttext="\displaystyle\leftarrow\frac{\theta}{\max\{1,\left\|\theta\right\|/C\}}" display="inline"><semantics id="S4.E4X.3.2.2.m1.4a"><mrow id="S4.E4X.3.2.2.m1.4.5" xref="S4.E4X.3.2.2.m1.4.5.cmml"><mi id="S4.E4X.3.2.2.m1.4.5.2" xref="S4.E4X.3.2.2.m1.4.5.2.cmml"></mi><mo stretchy="false" id="S4.E4X.3.2.2.m1.4.5.1" xref="S4.E4X.3.2.2.m1.4.5.1.cmml">←</mo><mstyle displaystyle="true" id="S4.E4X.3.2.2.m1.4.4" xref="S4.E4X.3.2.2.m1.4.4.cmml"><mfrac id="S4.E4X.3.2.2.m1.4.4a" xref="S4.E4X.3.2.2.m1.4.4.cmml"><mi id="S4.E4X.3.2.2.m1.4.4.6" xref="S4.E4X.3.2.2.m1.4.4.6.cmml">θ</mi><mrow id="S4.E4X.3.2.2.m1.4.4.4.4" xref="S4.E4X.3.2.2.m1.4.4.4.5.cmml"><mi id="S4.E4X.3.2.2.m1.2.2.2.2" xref="S4.E4X.3.2.2.m1.2.2.2.2.cmml">max</mi><mo id="S4.E4X.3.2.2.m1.4.4.4.4a" xref="S4.E4X.3.2.2.m1.4.4.4.5.cmml">⁡</mo><mrow id="S4.E4X.3.2.2.m1.4.4.4.4.1" xref="S4.E4X.3.2.2.m1.4.4.4.5.cmml"><mo stretchy="false" id="S4.E4X.3.2.2.m1.4.4.4.4.1.2" xref="S4.E4X.3.2.2.m1.4.4.4.5.cmml">{</mo><mn id="S4.E4X.3.2.2.m1.3.3.3.3" xref="S4.E4X.3.2.2.m1.3.3.3.3.cmml">1</mn><mo id="S4.E4X.3.2.2.m1.4.4.4.4.1.3" xref="S4.E4X.3.2.2.m1.4.4.4.5.cmml">,</mo><mrow id="S4.E4X.3.2.2.m1.4.4.4.4.1.1" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.cmml"><mrow id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.2" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.1.cmml"><mo id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.2.1" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.1.1.cmml">‖</mo><mi id="S4.E4X.3.2.2.m1.1.1.1.1" xref="S4.E4X.3.2.2.m1.1.1.1.1.cmml">θ</mi><mo id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.2.2" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.1.1.cmml">‖</mo></mrow><mo id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.1" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.1.cmml">/</mo><mi id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.3" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.3.cmml">C</mi></mrow><mo stretchy="false" id="S4.E4X.3.2.2.m1.4.4.4.4.1.4" xref="S4.E4X.3.2.2.m1.4.4.4.5.cmml">}</mo></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E4X.3.2.2.m1.4b"><apply id="S4.E4X.3.2.2.m1.4.5.cmml" xref="S4.E4X.3.2.2.m1.4.5"><ci id="S4.E4X.3.2.2.m1.4.5.1.cmml" xref="S4.E4X.3.2.2.m1.4.5.1">←</ci><csymbol cd="latexml" id="S4.E4X.3.2.2.m1.4.5.2.cmml" xref="S4.E4X.3.2.2.m1.4.5.2">absent</csymbol><apply id="S4.E4X.3.2.2.m1.4.4.cmml" xref="S4.E4X.3.2.2.m1.4.4"><divide id="S4.E4X.3.2.2.m1.4.4.5.cmml" xref="S4.E4X.3.2.2.m1.4.4"></divide><ci id="S4.E4X.3.2.2.m1.4.4.6.cmml" xref="S4.E4X.3.2.2.m1.4.4.6">𝜃</ci><apply id="S4.E4X.3.2.2.m1.4.4.4.5.cmml" xref="S4.E4X.3.2.2.m1.4.4.4.4"><max id="S4.E4X.3.2.2.m1.2.2.2.2.cmml" xref="S4.E4X.3.2.2.m1.2.2.2.2"></max><cn type="integer" id="S4.E4X.3.2.2.m1.3.3.3.3.cmml" xref="S4.E4X.3.2.2.m1.3.3.3.3">1</cn><apply id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.cmml" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1"><divide id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.1.cmml" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.1"></divide><apply id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.1.cmml" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.2"><csymbol cd="latexml" id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.1.1.cmml" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.2.2.1">norm</csymbol><ci id="S4.E4X.3.2.2.m1.1.1.1.1.cmml" xref="S4.E4X.3.2.2.m1.1.1.1.1">𝜃</ci></apply><ci id="S4.E4X.3.2.2.m1.4.4.4.4.1.1.3.cmml" xref="S4.E4X.3.2.2.m1.4.4.4.4.1.1.3">𝐶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4X.3.2.2.m1.4c">\displaystyle\leftarrow\frac{\theta}{\max\{1,\left\|\theta\right\|/C\}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
<tr id="S4.E4Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4Xa.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\text{Noising:}\quad\tilde{\theta}" display="inline"><semantics id="S4.E4Xa.2.1.1.m1.2a"><mrow id="S4.E4Xa.2.1.1.m1.2.3.2" xref="S4.E4Xa.2.1.1.m1.2.3.1.cmml"><mtext id="S4.E4Xa.2.1.1.m1.1.1" xref="S4.E4Xa.2.1.1.m1.1.1a.cmml">Noising:</mtext><mspace width="1em" id="S4.E4Xa.2.1.1.m1.2.3.2.1" xref="S4.E4Xa.2.1.1.m1.2.3.1.cmml"></mspace><mover accent="true" id="S4.E4Xa.2.1.1.m1.2.2" xref="S4.E4Xa.2.1.1.m1.2.2.cmml"><mi id="S4.E4Xa.2.1.1.m1.2.2.2" xref="S4.E4Xa.2.1.1.m1.2.2.2.cmml">θ</mi><mo id="S4.E4Xa.2.1.1.m1.2.2.1" xref="S4.E4Xa.2.1.1.m1.2.2.1.cmml">~</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S4.E4Xa.2.1.1.m1.2b"><list id="S4.E4Xa.2.1.1.m1.2.3.1.cmml" xref="S4.E4Xa.2.1.1.m1.2.3.2"><ci id="S4.E4Xa.2.1.1.m1.1.1a.cmml" xref="S4.E4Xa.2.1.1.m1.1.1"><mtext id="S4.E4Xa.2.1.1.m1.1.1.cmml" xref="S4.E4Xa.2.1.1.m1.1.1">Noising:</mtext></ci><apply id="S4.E4Xa.2.1.1.m1.2.2.cmml" xref="S4.E4Xa.2.1.1.m1.2.2"><ci id="S4.E4Xa.2.1.1.m1.2.2.1.cmml" xref="S4.E4Xa.2.1.1.m1.2.2.1">~</ci><ci id="S4.E4Xa.2.1.1.m1.2.2.2.cmml" xref="S4.E4Xa.2.1.1.m1.2.2.2">𝜃</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.E4Xa.2.1.1.m1.2c">\displaystyle\text{Noising:}\quad\tilde{\theta}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E4Xa.3.2.2.m1.2" class="ltx_Math" alttext="\displaystyle\leftarrow\hat{\theta}+n\sim\mathcal{N}(0,\sigma I)" display="inline"><semantics id="S4.E4Xa.3.2.2.m1.2a"><mrow id="S4.E4Xa.3.2.2.m1.2.2" xref="S4.E4Xa.3.2.2.m1.2.2.cmml"><mi id="S4.E4Xa.3.2.2.m1.2.2.3" xref="S4.E4Xa.3.2.2.m1.2.2.3.cmml"></mi><mo stretchy="false" id="S4.E4Xa.3.2.2.m1.2.2.4" xref="S4.E4Xa.3.2.2.m1.2.2.4.cmml">←</mo><mrow id="S4.E4Xa.3.2.2.m1.2.2.5" xref="S4.E4Xa.3.2.2.m1.2.2.5.cmml"><mover accent="true" id="S4.E4Xa.3.2.2.m1.2.2.5.2" xref="S4.E4Xa.3.2.2.m1.2.2.5.2.cmml"><mi id="S4.E4Xa.3.2.2.m1.2.2.5.2.2" xref="S4.E4Xa.3.2.2.m1.2.2.5.2.2.cmml">θ</mi><mo id="S4.E4Xa.3.2.2.m1.2.2.5.2.1" xref="S4.E4Xa.3.2.2.m1.2.2.5.2.1.cmml">^</mo></mover><mo id="S4.E4Xa.3.2.2.m1.2.2.5.1" xref="S4.E4Xa.3.2.2.m1.2.2.5.1.cmml">+</mo><mi id="S4.E4Xa.3.2.2.m1.2.2.5.3" xref="S4.E4Xa.3.2.2.m1.2.2.5.3.cmml">n</mi></mrow><mo id="S4.E4Xa.3.2.2.m1.2.2.6" xref="S4.E4Xa.3.2.2.m1.2.2.6.cmml">∼</mo><mrow id="S4.E4Xa.3.2.2.m1.2.2.1" xref="S4.E4Xa.3.2.2.m1.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4Xa.3.2.2.m1.2.2.1.3" xref="S4.E4Xa.3.2.2.m1.2.2.1.3.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S4.E4Xa.3.2.2.m1.2.2.1.2" xref="S4.E4Xa.3.2.2.m1.2.2.1.2.cmml">​</mo><mrow id="S4.E4Xa.3.2.2.m1.2.2.1.1.1" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.2" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.2.cmml">(</mo><mn id="S4.E4Xa.3.2.2.m1.1.1" xref="S4.E4Xa.3.2.2.m1.1.1.cmml">0</mn><mo id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.3" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.2.cmml">,</mo><mrow id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.cmml"><mi id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.2" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.2.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.1" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.3" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.3.cmml">I</mi></mrow><mo stretchy="false" id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.4" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4Xa.3.2.2.m1.2b"><apply id="S4.E4Xa.3.2.2.m1.2.2.cmml" xref="S4.E4Xa.3.2.2.m1.2.2"><and id="S4.E4Xa.3.2.2.m1.2.2a.cmml" xref="S4.E4Xa.3.2.2.m1.2.2"></and><apply id="S4.E4Xa.3.2.2.m1.2.2b.cmml" xref="S4.E4Xa.3.2.2.m1.2.2"><ci id="S4.E4Xa.3.2.2.m1.2.2.4.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.4">←</ci><csymbol cd="latexml" id="S4.E4Xa.3.2.2.m1.2.2.3.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.3">absent</csymbol><apply id="S4.E4Xa.3.2.2.m1.2.2.5.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.5"><plus id="S4.E4Xa.3.2.2.m1.2.2.5.1.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.5.1"></plus><apply id="S4.E4Xa.3.2.2.m1.2.2.5.2.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.5.2"><ci id="S4.E4Xa.3.2.2.m1.2.2.5.2.1.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.5.2.1">^</ci><ci id="S4.E4Xa.3.2.2.m1.2.2.5.2.2.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.5.2.2">𝜃</ci></apply><ci id="S4.E4Xa.3.2.2.m1.2.2.5.3.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.5.3">𝑛</ci></apply></apply><apply id="S4.E4Xa.3.2.2.m1.2.2c.cmml" xref="S4.E4Xa.3.2.2.m1.2.2"><csymbol cd="latexml" id="S4.E4Xa.3.2.2.m1.2.2.6.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.6">similar-to</csymbol><share href="#S4.E4Xa.3.2.2.m1.2.2.5.cmml" id="S4.E4Xa.3.2.2.m1.2.2d.cmml" xref="S4.E4Xa.3.2.2.m1.2.2"></share><apply id="S4.E4Xa.3.2.2.m1.2.2.1.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1"><times id="S4.E4Xa.3.2.2.m1.2.2.1.2.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.2"></times><ci id="S4.E4Xa.3.2.2.m1.2.2.1.3.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.3">𝒩</ci><interval closure="open" id="S4.E4Xa.3.2.2.m1.2.2.1.1.2.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1"><cn type="integer" id="S4.E4Xa.3.2.2.m1.1.1.cmml" xref="S4.E4Xa.3.2.2.m1.1.1">0</cn><apply id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1"><times id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.1.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.1"></times><ci id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.2.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.2">𝜎</ci><ci id="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.3.cmml" xref="S4.E4Xa.3.2.2.m1.2.2.1.1.1.1.3">𝐼</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4Xa.3.2.2.m1.2c">\displaystyle\leftarrow\hat{\theta}+n\sim\mathcal{N}(0,\sigma I)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<p id="S4.SS1.SSS1.p4.4" class="ltx_p">The relationship between the noise amplitude <math id="S4.SS1.SSS1.p4.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS1.SSS1.p4.1.m1.1a"><mi id="S4.SS1.SSS1.p4.1.m1.1.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.1.m1.1b"><ci id="S4.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.1.m1.1c">\sigma</annotation></semantics></math> and the privacy budget <math id="S4.SS1.SSS1.p4.2.m2.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S4.SS1.SSS1.p4.2.m2.1a"><mi id="S4.SS1.SSS1.p4.2.m2.1.1" xref="S4.SS1.SSS1.p4.2.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.2.m2.1b"><ci id="S4.SS1.SSS1.p4.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p4.2.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.2.m2.1c">\varepsilon</annotation></semantics></math> can be concluded from relevant DP theories, such as Parallel Composition Theorem, Advanced Composition Theorem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite>, and so on. Compared to the theories mentioned above, the Moment Accountant <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite> theory provides a smaller upper bound for the privacy budget, meaning that this theory can derive a smaller <math id="S4.SS1.SSS1.p4.3.m3.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S4.SS1.SSS1.p4.3.m3.1a"><mi id="S4.SS1.SSS1.p4.3.m3.1.1" xref="S4.SS1.SSS1.p4.3.m3.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.3.m3.1b"><ci id="S4.SS1.SSS1.p4.3.m3.1.1.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.3.m3.1c">\varepsilon</annotation></semantics></math> from the same <math id="S4.SS1.SSS1.p4.4.m4.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS1.SSS1.p4.4.m4.1a"><mi id="S4.SS1.SSS1.p4.4.m4.1.1" xref="S4.SS1.SSS1.p4.4.m4.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.4.m4.1b"><ci id="S4.SS1.SSS1.p4.4.m4.1.1.cmml" xref="S4.SS1.SSS1.p4.4.m4.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.4.m4.1c">\sigma</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.SSS1.p5" class="ltx_para">
<p id="S4.SS1.SSS1.p5.1" class="ltx_p">There are numerous federated learning frameworks that apply model perturbation. For instance, DP-FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>, which was initially proposed, first adopted user-level DP to protect client data. NbAFL<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite> considered the noise magnitude required for differential privacy protection of model information in both upload and download links. The work of Seif et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite> considered the environment of wireless communication and proposed how to implement differential privacy protection in this environment by utilizing the characteristics of wireless communication. CLDP-SGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite>, while maintaining DP protection, considered communication overhead and is a federated learning architecture that applies DP under communication-limited conditions. In addition, some works like Fed-CDP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite> set the object of protection as the training set data, that is, noise is added during local training.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS2.5.1.1" class="ltx_text">IV-A</span>2 </span>Variant DP</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">In traditional DP, the relationship between the magnitude of noise and the privacy budget is intricate and not easily described intuitively. To address this issue, Ilya have slightly relaxed the requirements of DP, resulting in the formulation of Rényi Differential Privacy (RDP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>.</p>
</div>
<div id="Thmtheorem2" class="ltx_theorem ltx_theorem_theorem">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmtheorem2.2.2.1" class="ltx_text ltx_font_bold">Theorem 2</span></span><span id="Thmtheorem2.1.1" class="ltx_text ltx_font_bold"> (<math id="Thmtheorem2.1.1.m1.2" class="ltx_Math" alttext="(\alpha,\rho)" display="inline"><semantics id="Thmtheorem2.1.1.m1.2b"><mrow id="Thmtheorem2.1.1.m1.2.3.2" xref="Thmtheorem2.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="Thmtheorem2.1.1.m1.2.3.2.1" xref="Thmtheorem2.1.1.m1.2.3.1.cmml">(</mo><mi id="Thmtheorem2.1.1.m1.1.1" xref="Thmtheorem2.1.1.m1.1.1.cmml">α</mi><mo id="Thmtheorem2.1.1.m1.2.3.2.2" xref="Thmtheorem2.1.1.m1.2.3.1.cmml">,</mo><mi id="Thmtheorem2.1.1.m1.2.2" xref="Thmtheorem2.1.1.m1.2.2.cmml">ρ</mi><mo stretchy="false" id="Thmtheorem2.1.1.m1.2.3.2.3" xref="Thmtheorem2.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem2.1.1.m1.2c"><interval closure="open" id="Thmtheorem2.1.1.m1.2.3.1.cmml" xref="Thmtheorem2.1.1.m1.2.3.2"><ci id="Thmtheorem2.1.1.m1.1.1.cmml" xref="Thmtheorem2.1.1.m1.1.1">𝛼</ci><ci id="Thmtheorem2.1.1.m1.2.2.cmml" xref="Thmtheorem2.1.1.m1.2.2">𝜌</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.1.1.m1.2d">(\alpha,\rho)</annotation></semantics></math>-RDP).</span>
</h6>
<div id="Thmtheorem2.p1" class="ltx_para">
<p id="Thmtheorem2.p1.8" class="ltx_p"><span id="Thmtheorem2.p1.8.8" class="ltx_text ltx_font_italic">Given that <math id="Thmtheorem2.p1.1.1.m1.2" class="ltx_Math" alttext="\alpha\in(1,\infty)" display="inline"><semantics id="Thmtheorem2.p1.1.1.m1.2a"><mrow id="Thmtheorem2.p1.1.1.m1.2.3" xref="Thmtheorem2.p1.1.1.m1.2.3.cmml"><mi id="Thmtheorem2.p1.1.1.m1.2.3.2" xref="Thmtheorem2.p1.1.1.m1.2.3.2.cmml">α</mi><mo id="Thmtheorem2.p1.1.1.m1.2.3.1" xref="Thmtheorem2.p1.1.1.m1.2.3.1.cmml">∈</mo><mrow id="Thmtheorem2.p1.1.1.m1.2.3.3.2" xref="Thmtheorem2.p1.1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="Thmtheorem2.p1.1.1.m1.2.3.3.2.1" xref="Thmtheorem2.p1.1.1.m1.2.3.3.1.cmml">(</mo><mn id="Thmtheorem2.p1.1.1.m1.1.1" xref="Thmtheorem2.p1.1.1.m1.1.1.cmml">1</mn><mo id="Thmtheorem2.p1.1.1.m1.2.3.3.2.2" xref="Thmtheorem2.p1.1.1.m1.2.3.3.1.cmml">,</mo><mi mathvariant="normal" id="Thmtheorem2.p1.1.1.m1.2.2" xref="Thmtheorem2.p1.1.1.m1.2.2.cmml">∞</mi><mo stretchy="false" id="Thmtheorem2.p1.1.1.m1.2.3.3.2.3" xref="Thmtheorem2.p1.1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.1.1.m1.2b"><apply id="Thmtheorem2.p1.1.1.m1.2.3.cmml" xref="Thmtheorem2.p1.1.1.m1.2.3"><in id="Thmtheorem2.p1.1.1.m1.2.3.1.cmml" xref="Thmtheorem2.p1.1.1.m1.2.3.1"></in><ci id="Thmtheorem2.p1.1.1.m1.2.3.2.cmml" xref="Thmtheorem2.p1.1.1.m1.2.3.2">𝛼</ci><interval closure="open" id="Thmtheorem2.p1.1.1.m1.2.3.3.1.cmml" xref="Thmtheorem2.p1.1.1.m1.2.3.3.2"><cn type="integer" id="Thmtheorem2.p1.1.1.m1.1.1.cmml" xref="Thmtheorem2.p1.1.1.m1.1.1">1</cn><infinity id="Thmtheorem2.p1.1.1.m1.2.2.cmml" xref="Thmtheorem2.p1.1.1.m1.2.2"></infinity></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.1.1.m1.2c">\alpha\in(1,\infty)</annotation></semantics></math> and <math id="Thmtheorem2.p1.2.2.m2.1" class="ltx_Math" alttext="\rho&gt;0" display="inline"><semantics id="Thmtheorem2.p1.2.2.m2.1a"><mrow id="Thmtheorem2.p1.2.2.m2.1.1" xref="Thmtheorem2.p1.2.2.m2.1.1.cmml"><mi id="Thmtheorem2.p1.2.2.m2.1.1.2" xref="Thmtheorem2.p1.2.2.m2.1.1.2.cmml">ρ</mi><mo id="Thmtheorem2.p1.2.2.m2.1.1.1" xref="Thmtheorem2.p1.2.2.m2.1.1.1.cmml">&gt;</mo><mn id="Thmtheorem2.p1.2.2.m2.1.1.3" xref="Thmtheorem2.p1.2.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.2.2.m2.1b"><apply id="Thmtheorem2.p1.2.2.m2.1.1.cmml" xref="Thmtheorem2.p1.2.2.m2.1.1"><gt id="Thmtheorem2.p1.2.2.m2.1.1.1.cmml" xref="Thmtheorem2.p1.2.2.m2.1.1.1"></gt><ci id="Thmtheorem2.p1.2.2.m2.1.1.2.cmml" xref="Thmtheorem2.p1.2.2.m2.1.1.2">𝜌</ci><cn type="integer" id="Thmtheorem2.p1.2.2.m2.1.1.3.cmml" xref="Thmtheorem2.p1.2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.2.2.m2.1c">\rho&gt;0</annotation></semantics></math>, a randomized mechanism <math id="Thmtheorem2.p1.3.3.m3.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="Thmtheorem2.p1.3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem2.p1.3.3.m3.1.1" xref="Thmtheorem2.p1.3.3.m3.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.3.3.m3.1b"><ci id="Thmtheorem2.p1.3.3.m3.1.1.cmml" xref="Thmtheorem2.p1.3.3.m3.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.3.3.m3.1c">\mathcal{M}</annotation></semantics></math> with domain <math id="Thmtheorem2.p1.4.4.m4.1" class="ltx_Math" alttext="\cal{X}" display="inline"><semantics id="Thmtheorem2.p1.4.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem2.p1.4.4.m4.1.1" xref="Thmtheorem2.p1.4.4.m4.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.4.4.m4.1b"><ci id="Thmtheorem2.p1.4.4.m4.1.1.cmml" xref="Thmtheorem2.p1.4.4.m4.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.4.4.m4.1c">\cal{X}</annotation></semantics></math> and range <math id="Thmtheorem2.p1.5.5.m5.1" class="ltx_Math" alttext="\cal{R}" display="inline"><semantics id="Thmtheorem2.p1.5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem2.p1.5.5.m5.1.1" xref="Thmtheorem2.p1.5.5.m5.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.5.5.m5.1b"><ci id="Thmtheorem2.p1.5.5.m5.1.1.cmml" xref="Thmtheorem2.p1.5.5.m5.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.5.5.m5.1c">\cal{R}</annotation></semantics></math> satisfies <math id="Thmtheorem2.p1.6.6.m6.2" class="ltx_Math" alttext="(\alpha,\rho)" display="inline"><semantics id="Thmtheorem2.p1.6.6.m6.2a"><mrow id="Thmtheorem2.p1.6.6.m6.2.3.2" xref="Thmtheorem2.p1.6.6.m6.2.3.1.cmml"><mo stretchy="false" id="Thmtheorem2.p1.6.6.m6.2.3.2.1" xref="Thmtheorem2.p1.6.6.m6.2.3.1.cmml">(</mo><mi id="Thmtheorem2.p1.6.6.m6.1.1" xref="Thmtheorem2.p1.6.6.m6.1.1.cmml">α</mi><mo id="Thmtheorem2.p1.6.6.m6.2.3.2.2" xref="Thmtheorem2.p1.6.6.m6.2.3.1.cmml">,</mo><mi id="Thmtheorem2.p1.6.6.m6.2.2" xref="Thmtheorem2.p1.6.6.m6.2.2.cmml">ρ</mi><mo stretchy="false" id="Thmtheorem2.p1.6.6.m6.2.3.2.3" xref="Thmtheorem2.p1.6.6.m6.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.6.6.m6.2b"><interval closure="open" id="Thmtheorem2.p1.6.6.m6.2.3.1.cmml" xref="Thmtheorem2.p1.6.6.m6.2.3.2"><ci id="Thmtheorem2.p1.6.6.m6.1.1.cmml" xref="Thmtheorem2.p1.6.6.m6.1.1">𝛼</ci><ci id="Thmtheorem2.p1.6.6.m6.2.2.cmml" xref="Thmtheorem2.p1.6.6.m6.2.2">𝜌</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.6.6.m6.2c">(\alpha,\rho)</annotation></semantics></math>-RDP if,
for any two adjacent inputs <math id="Thmtheorem2.p1.7.7.m7.2" class="ltx_Math" alttext="x,x^{\prime}\in\cal{X}" display="inline"><semantics id="Thmtheorem2.p1.7.7.m7.2a"><mrow id="Thmtheorem2.p1.7.7.m7.2.2" xref="Thmtheorem2.p1.7.7.m7.2.2.cmml"><mrow id="Thmtheorem2.p1.7.7.m7.2.2.1.1" xref="Thmtheorem2.p1.7.7.m7.2.2.1.2.cmml"><mi id="Thmtheorem2.p1.7.7.m7.1.1" xref="Thmtheorem2.p1.7.7.m7.1.1.cmml">x</mi><mo id="Thmtheorem2.p1.7.7.m7.2.2.1.1.2" xref="Thmtheorem2.p1.7.7.m7.2.2.1.2.cmml">,</mo><msup id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.cmml"><mi id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.2" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.2.cmml">x</mi><mo id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.3" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.3.cmml">′</mo></msup></mrow><mo id="Thmtheorem2.p1.7.7.m7.2.2.2" xref="Thmtheorem2.p1.7.7.m7.2.2.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Thmtheorem2.p1.7.7.m7.2.2.3" xref="Thmtheorem2.p1.7.7.m7.2.2.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.7.7.m7.2b"><apply id="Thmtheorem2.p1.7.7.m7.2.2.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2"><in id="Thmtheorem2.p1.7.7.m7.2.2.2.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.2"></in><list id="Thmtheorem2.p1.7.7.m7.2.2.1.2.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1"><ci id="Thmtheorem2.p1.7.7.m7.1.1.cmml" xref="Thmtheorem2.p1.7.7.m7.1.1">𝑥</ci><apply id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.1.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1">superscript</csymbol><ci id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.2.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.2">𝑥</ci><ci id="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.3.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.1.1.1.3">′</ci></apply></list><ci id="Thmtheorem2.p1.7.7.m7.2.2.3.cmml" xref="Thmtheorem2.p1.7.7.m7.2.2.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.7.7.m7.2c">x,x^{\prime}\in\cal{X}</annotation></semantics></math> the <math id="Thmtheorem2.p1.8.8.m8.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="Thmtheorem2.p1.8.8.m8.1a"><mi id="Thmtheorem2.p1.8.8.m8.1.1" xref="Thmtheorem2.p1.8.8.m8.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.8.8.m8.1b"><ci id="Thmtheorem2.p1.8.8.m8.1.1.cmml" xref="Thmtheorem2.p1.8.8.m8.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.8.8.m8.1c">\alpha</annotation></semantics></math>-Rényi divergence satisfies</span></p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.5" class="ltx_Math" alttext="D_{\alpha}[\mathcal{M}(x)\parallel\mathcal{M}(x^{\prime})]\leftarrow\frac{1}{\alpha-1}\log\mathbb{E}\left[\left(\frac{\mathcal{M}(x)}{\mathcal{M}(x^{\prime})}\right)^{\alpha}\right]\leq\rho" display="block"><semantics id="S4.E5.m1.5a"><mrow id="S4.E5.m1.5.5" xref="S4.E5.m1.5.5.cmml"><mrow id="S4.E5.m1.4.4.1" xref="S4.E5.m1.4.4.1.cmml"><msub id="S4.E5.m1.4.4.1.3" xref="S4.E5.m1.4.4.1.3.cmml"><mi id="S4.E5.m1.4.4.1.3.2" xref="S4.E5.m1.4.4.1.3.2.cmml">D</mi><mi id="S4.E5.m1.4.4.1.3.3" xref="S4.E5.m1.4.4.1.3.3.cmml">α</mi></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.2" xref="S4.E5.m1.4.4.1.2.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.1" xref="S4.E5.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.2" xref="S4.E5.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S4.E5.m1.4.4.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.cmml"><mrow id="S4.E5.m1.4.4.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.4.4.1.1.1.1.3.2" xref="S4.E5.m1.4.4.1.1.1.1.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.1.1.1.3.1" xref="S4.E5.m1.4.4.1.1.1.1.3.1.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.1.1.3.3.2" xref="S4.E5.m1.4.4.1.1.1.1.3.cmml"><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.1.3.3.2.1" xref="S4.E5.m1.4.4.1.1.1.1.3.cmml">(</mo><mi id="S4.E5.m1.3.3" xref="S4.E5.m1.3.3.cmml">x</mi><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.1.3.3.2.2" xref="S4.E5.m1.4.4.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.4.4.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.2.cmml">∥</mo><mrow id="S4.E5.m1.4.4.1.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.4.4.1.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.1.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.3" xref="S4.E5.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S4.E5.m1.5.5.4" xref="S4.E5.m1.5.5.4.cmml">←</mo><mrow id="S4.E5.m1.5.5.2" xref="S4.E5.m1.5.5.2.cmml"><mfrac id="S4.E5.m1.5.5.2.3" xref="S4.E5.m1.5.5.2.3.cmml"><mn id="S4.E5.m1.5.5.2.3.2" xref="S4.E5.m1.5.5.2.3.2.cmml">1</mn><mrow id="S4.E5.m1.5.5.2.3.3" xref="S4.E5.m1.5.5.2.3.3.cmml"><mi id="S4.E5.m1.5.5.2.3.3.2" xref="S4.E5.m1.5.5.2.3.3.2.cmml">α</mi><mo id="S4.E5.m1.5.5.2.3.3.1" xref="S4.E5.m1.5.5.2.3.3.1.cmml">−</mo><mn id="S4.E5.m1.5.5.2.3.3.3" xref="S4.E5.m1.5.5.2.3.3.3.cmml">1</mn></mrow></mfrac><mo lspace="0.167em" rspace="0em" id="S4.E5.m1.5.5.2.2" xref="S4.E5.m1.5.5.2.2.cmml">​</mo><mrow id="S4.E5.m1.5.5.2.4" xref="S4.E5.m1.5.5.2.4.cmml"><mi id="S4.E5.m1.5.5.2.4.1" xref="S4.E5.m1.5.5.2.4.1.cmml">log</mi><mo lspace="0.167em" id="S4.E5.m1.5.5.2.4a" xref="S4.E5.m1.5.5.2.4.cmml">⁡</mo><mi id="S4.E5.m1.5.5.2.4.2" xref="S4.E5.m1.5.5.2.4.2.cmml">𝔼</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E5.m1.5.5.2.2a" xref="S4.E5.m1.5.5.2.2.cmml">​</mo><mrow id="S4.E5.m1.5.5.2.1.1" xref="S4.E5.m1.5.5.2.1.2.cmml"><mo id="S4.E5.m1.5.5.2.1.1.2" xref="S4.E5.m1.5.5.2.1.2.1.cmml">[</mo><msup id="S4.E5.m1.5.5.2.1.1.1" xref="S4.E5.m1.5.5.2.1.1.1.cmml"><mrow id="S4.E5.m1.5.5.2.1.1.1.2.2" xref="S4.E5.m1.2.2.cmml"><mo id="S4.E5.m1.5.5.2.1.1.1.2.2.1" xref="S4.E5.m1.2.2.cmml">(</mo><mfrac id="S4.E5.m1.2.2" xref="S4.E5.m1.2.2.cmml"><mrow id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.1.1.1.3" xref="S4.E5.m1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.1.2" xref="S4.E5.m1.1.1.1.2.cmml">​</mo><mrow id="S4.E5.m1.1.1.1.4.2" xref="S4.E5.m1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.1.1.1.4.2.1" xref="S4.E5.m1.1.1.1.cmml">(</mo><mi id="S4.E5.m1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S4.E5.m1.1.1.1.4.2.2" xref="S4.E5.m1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.E5.m1.2.2.2" xref="S4.E5.m1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.2.2.2.3" xref="S4.E5.m1.2.2.2.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.2.2" xref="S4.E5.m1.2.2.2.2.cmml">​</mo><mrow id="S4.E5.m1.2.2.2.1.1" xref="S4.E5.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.2.2.2.1.1.2" xref="S4.E5.m1.2.2.2.1.1.1.cmml">(</mo><msup id="S4.E5.m1.2.2.2.1.1.1" xref="S4.E5.m1.2.2.2.1.1.1.cmml"><mi id="S4.E5.m1.2.2.2.1.1.1.2" xref="S4.E5.m1.2.2.2.1.1.1.2.cmml">x</mi><mo id="S4.E5.m1.2.2.2.1.1.1.3" xref="S4.E5.m1.2.2.2.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.E5.m1.2.2.2.1.1.3" xref="S4.E5.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S4.E5.m1.5.5.2.1.1.1.2.2.2" xref="S4.E5.m1.2.2.cmml">)</mo></mrow><mi id="S4.E5.m1.5.5.2.1.1.1.3" xref="S4.E5.m1.5.5.2.1.1.1.3.cmml">α</mi></msup><mo id="S4.E5.m1.5.5.2.1.1.3" xref="S4.E5.m1.5.5.2.1.2.1.cmml">]</mo></mrow></mrow><mo id="S4.E5.m1.5.5.5" xref="S4.E5.m1.5.5.5.cmml">≤</mo><mi id="S4.E5.m1.5.5.6" xref="S4.E5.m1.5.5.6.cmml">ρ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.5b"><apply id="S4.E5.m1.5.5.cmml" xref="S4.E5.m1.5.5"><and id="S4.E5.m1.5.5a.cmml" xref="S4.E5.m1.5.5"></and><apply id="S4.E5.m1.5.5b.cmml" xref="S4.E5.m1.5.5"><ci id="S4.E5.m1.5.5.4.cmml" xref="S4.E5.m1.5.5.4">←</ci><apply id="S4.E5.m1.4.4.1.cmml" xref="S4.E5.m1.4.4.1"><times id="S4.E5.m1.4.4.1.2.cmml" xref="S4.E5.m1.4.4.1.2"></times><apply id="S4.E5.m1.4.4.1.3.cmml" xref="S4.E5.m1.4.4.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.3.1.cmml" xref="S4.E5.m1.4.4.1.3">subscript</csymbol><ci id="S4.E5.m1.4.4.1.3.2.cmml" xref="S4.E5.m1.4.4.1.3.2">𝐷</ci><ci id="S4.E5.m1.4.4.1.3.3.cmml" xref="S4.E5.m1.4.4.1.3.3">𝛼</ci></apply><apply id="S4.E5.m1.4.4.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1"><csymbol cd="latexml" id="S4.E5.m1.4.4.1.1.2.1.cmml" xref="S4.E5.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S4.E5.m1.4.4.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S4.E5.m1.4.4.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2">conditional</csymbol><apply id="S4.E5.m1.4.4.1.1.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.3"><times id="S4.E5.m1.4.4.1.1.1.1.3.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.3.1"></times><ci id="S4.E5.m1.4.4.1.1.1.1.3.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.3.2">ℳ</ci><ci id="S4.E5.m1.3.3.cmml" xref="S4.E5.m1.3.3">𝑥</ci></apply><apply id="S4.E5.m1.4.4.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1"><times id="S4.E5.m1.4.4.1.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.2"></times><ci id="S4.E5.m1.4.4.1.1.1.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.3">ℳ</ci><apply id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></apply></apply><apply id="S4.E5.m1.5.5.2.cmml" xref="S4.E5.m1.5.5.2"><times id="S4.E5.m1.5.5.2.2.cmml" xref="S4.E5.m1.5.5.2.2"></times><apply id="S4.E5.m1.5.5.2.3.cmml" xref="S4.E5.m1.5.5.2.3"><divide id="S4.E5.m1.5.5.2.3.1.cmml" xref="S4.E5.m1.5.5.2.3"></divide><cn type="integer" id="S4.E5.m1.5.5.2.3.2.cmml" xref="S4.E5.m1.5.5.2.3.2">1</cn><apply id="S4.E5.m1.5.5.2.3.3.cmml" xref="S4.E5.m1.5.5.2.3.3"><minus id="S4.E5.m1.5.5.2.3.3.1.cmml" xref="S4.E5.m1.5.5.2.3.3.1"></minus><ci id="S4.E5.m1.5.5.2.3.3.2.cmml" xref="S4.E5.m1.5.5.2.3.3.2">𝛼</ci><cn type="integer" id="S4.E5.m1.5.5.2.3.3.3.cmml" xref="S4.E5.m1.5.5.2.3.3.3">1</cn></apply></apply><apply id="S4.E5.m1.5.5.2.4.cmml" xref="S4.E5.m1.5.5.2.4"><log id="S4.E5.m1.5.5.2.4.1.cmml" xref="S4.E5.m1.5.5.2.4.1"></log><ci id="S4.E5.m1.5.5.2.4.2.cmml" xref="S4.E5.m1.5.5.2.4.2">𝔼</ci></apply><apply id="S4.E5.m1.5.5.2.1.2.cmml" xref="S4.E5.m1.5.5.2.1.1"><csymbol cd="latexml" id="S4.E5.m1.5.5.2.1.2.1.cmml" xref="S4.E5.m1.5.5.2.1.1.2">delimited-[]</csymbol><apply id="S4.E5.m1.5.5.2.1.1.1.cmml" xref="S4.E5.m1.5.5.2.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.5.5.2.1.1.1.1.cmml" xref="S4.E5.m1.5.5.2.1.1.1">superscript</csymbol><apply id="S4.E5.m1.2.2.cmml" xref="S4.E5.m1.5.5.2.1.1.1.2.2"><divide id="S4.E5.m1.2.2.3.cmml" xref="S4.E5.m1.5.5.2.1.1.1.2.2"></divide><apply id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"><times id="S4.E5.m1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.2"></times><ci id="S4.E5.m1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.3">ℳ</ci><ci id="S4.E5.m1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1">𝑥</ci></apply><apply id="S4.E5.m1.2.2.2.cmml" xref="S4.E5.m1.2.2.2"><times id="S4.E5.m1.2.2.2.2.cmml" xref="S4.E5.m1.2.2.2.2"></times><ci id="S4.E5.m1.2.2.2.3.cmml" xref="S4.E5.m1.2.2.2.3">ℳ</ci><apply id="S4.E5.m1.2.2.2.1.1.1.cmml" xref="S4.E5.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.2.1.1.1.1.cmml" xref="S4.E5.m1.2.2.2.1.1">superscript</csymbol><ci id="S4.E5.m1.2.2.2.1.1.1.2.cmml" xref="S4.E5.m1.2.2.2.1.1.1.2">𝑥</ci><ci id="S4.E5.m1.2.2.2.1.1.1.3.cmml" xref="S4.E5.m1.2.2.2.1.1.1.3">′</ci></apply></apply></apply><ci id="S4.E5.m1.5.5.2.1.1.1.3.cmml" xref="S4.E5.m1.5.5.2.1.1.1.3">𝛼</ci></apply></apply></apply></apply><apply id="S4.E5.m1.5.5c.cmml" xref="S4.E5.m1.5.5"><leq id="S4.E5.m1.5.5.5.cmml" xref="S4.E5.m1.5.5.5"></leq><share href="#S4.E5.m1.5.5.2.cmml" id="S4.E5.m1.5.5d.cmml" xref="S4.E5.m1.5.5"></share><ci id="S4.E5.m1.5.5.6.cmml" xref="S4.E5.m1.5.5.6">𝜌</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.5c">D_{\alpha}[\mathcal{M}(x)\parallel\mathcal{M}(x^{\prime})]\leftarrow\frac{1}{\alpha-1}\log\mathbb{E}\left[\left(\frac{\mathcal{M}(x)}{\mathcal{M}(x^{\prime})}\right)^{\alpha}\right]\leq\rho</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="Thmtheorem2.p1.9" class="ltx_p"><span id="Thmtheorem2.p1.9.1" class="ltx_text ltx_font_italic">where the expectation is taken over <math id="Thmtheorem2.p1.9.1.m1.1" class="ltx_Math" alttext="\mathcal{M}(x^{\prime})" display="inline"><semantics id="Thmtheorem2.p1.9.1.m1.1a"><mrow id="Thmtheorem2.p1.9.1.m1.1.1" xref="Thmtheorem2.p1.9.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmtheorem2.p1.9.1.m1.1.1.3" xref="Thmtheorem2.p1.9.1.m1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="Thmtheorem2.p1.9.1.m1.1.1.2" xref="Thmtheorem2.p1.9.1.m1.1.1.2.cmml">​</mo><mrow id="Thmtheorem2.p1.9.1.m1.1.1.1.1" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="Thmtheorem2.p1.9.1.m1.1.1.1.1.2" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.cmml">(</mo><msup id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.cmml"><mi id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.2" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.2.cmml">x</mi><mo id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.3" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="Thmtheorem2.p1.9.1.m1.1.1.1.1.3" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem2.p1.9.1.m1.1b"><apply id="Thmtheorem2.p1.9.1.m1.1.1.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1"><times id="Thmtheorem2.p1.9.1.m1.1.1.2.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1.2"></times><ci id="Thmtheorem2.p1.9.1.m1.1.1.3.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1.3">ℳ</ci><apply id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.1.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1">superscript</csymbol><ci id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.2.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.2">𝑥</ci><ci id="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.3.cmml" xref="Thmtheorem2.p1.9.1.m1.1.1.1.1.1.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem2.p1.9.1.m1.1c">\mathcal{M}(x^{\prime})</annotation></semantics></math>.
<span id="Thmtheorem2.p1.9.1.1" class="ltx_text ltx_align_floatright"></span></span></p>
</div>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">RDP offers several advantages for federated learning, which are encapsulated in the following points <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>:</p>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.4" class="ltx_p">It is compatible with the Gaussian mechanism, and it can be proven that when employing a Gaussian noise mechanism, the relationship is given by <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\sigma^{2}=\frac{(\Delta f)^{2}\alpha}{2\rho}" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mrow id="S4.I1.i1.p1.1.m1.1.2" xref="S4.I1.i1.p1.1.m1.1.2.cmml"><msup id="S4.I1.i1.p1.1.m1.1.2.2" xref="S4.I1.i1.p1.1.m1.1.2.2.cmml"><mi id="S4.I1.i1.p1.1.m1.1.2.2.2" xref="S4.I1.i1.p1.1.m1.1.2.2.2.cmml">σ</mi><mn id="S4.I1.i1.p1.1.m1.1.2.2.3" xref="S4.I1.i1.p1.1.m1.1.2.2.3.cmml">2</mn></msup><mo id="S4.I1.i1.p1.1.m1.1.2.1" xref="S4.I1.i1.p1.1.m1.1.2.1.cmml">=</mo><mfrac id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml"><mrow id="S4.I1.i1.p1.1.m1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.cmml"><msup id="S4.I1.i1.p1.1.m1.1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.1.cmml"><mrow id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.3.cmml">f</mi></mrow><mo stretchy="false" id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S4.I1.i1.p1.1.m1.1.1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.1.1.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.1.2.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.1.3.cmml">α</mi></mrow><mrow id="S4.I1.i1.p1.1.m1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.3.cmml"><mn id="S4.I1.i1.p1.1.m1.1.1.3.2" xref="S4.I1.i1.p1.1.m1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.1" xref="S4.I1.i1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3" xref="S4.I1.i1.p1.1.m1.1.1.3.3.cmml">ρ</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><apply id="S4.I1.i1.p1.1.m1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.2"><eq id="S4.I1.i1.p1.1.m1.1.2.1.cmml" xref="S4.I1.i1.p1.1.m1.1.2.1"></eq><apply id="S4.I1.i1.p1.1.m1.1.2.2.cmml" xref="S4.I1.i1.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S4.I1.i1.p1.1.m1.1.2.2.1.cmml" xref="S4.I1.i1.p1.1.m1.1.2.2">superscript</csymbol><ci id="S4.I1.i1.p1.1.m1.1.2.2.2.cmml" xref="S4.I1.i1.p1.1.m1.1.2.2.2">𝜎</ci><cn type="integer" id="S4.I1.i1.p1.1.m1.1.2.2.3.cmml" xref="S4.I1.i1.p1.1.m1.1.2.2.3">2</cn></apply><apply id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1"><divide id="S4.I1.i1.p1.1.m1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1"></divide><apply id="S4.I1.i1.p1.1.m1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1"><times id="S4.I1.i1.p1.1.m1.1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.2"></times><apply id="S4.I1.i1.p1.1.m1.1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1"><times id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.1"></times><ci id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.2">Δ</ci><ci id="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.1.1.3">𝑓</ci></apply><cn type="integer" id="S4.I1.i1.p1.1.m1.1.1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.3">2</cn></apply><ci id="S4.I1.i1.p1.1.m1.1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.3">𝛼</ci></apply><apply id="S4.I1.i1.p1.1.m1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3"><times id="S4.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S4.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2">2</cn><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3">𝜌</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">\sigma^{2}=\frac{(\Delta f)^{2}\alpha}{2\rho}</annotation></semantics></math>, where <math id="S4.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\Delta f" display="inline"><semantics id="S4.I1.i1.p1.2.m2.1a"><mrow id="S4.I1.i1.p1.2.m2.1.1" xref="S4.I1.i1.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S4.I1.i1.p1.2.m2.1.1.2" xref="S4.I1.i1.p1.2.m2.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.2.m2.1.1.1" xref="S4.I1.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.2.m2.1.1.3" xref="S4.I1.i1.p1.2.m2.1.1.3.cmml">f</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.m2.1b"><apply id="S4.I1.i1.p1.2.m2.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1"><times id="S4.I1.i1.p1.2.m2.1.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1.1"></times><ci id="S4.I1.i1.p1.2.m2.1.1.2.cmml" xref="S4.I1.i1.p1.2.m2.1.1.2">Δ</ci><ci id="S4.I1.i1.p1.2.m2.1.1.3.cmml" xref="S4.I1.i1.p1.2.m2.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.m2.1c">\Delta f</annotation></semantics></math> refers to the sensitivity of function <math id="S4.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.I1.i1.p1.3.m3.1a"><mi id="S4.I1.i1.p1.3.m3.1.1" xref="S4.I1.i1.p1.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.3.m3.1b"><ci id="S4.I1.i1.p1.3.m3.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.3.m3.1c">f</annotation></semantics></math> and defined as <math id="S4.I1.i1.p1.4.m4.4" class="ltx_Math" alttext="\Delta f\leftarrow\max_{x,x^{\prime}\,\text{adjacent}}\left\|f(x)-f(x^{\prime})\right\|_{2}" display="inline"><semantics id="S4.I1.i1.p1.4.m4.4a"><mrow id="S4.I1.i1.p1.4.m4.4.4" xref="S4.I1.i1.p1.4.m4.4.4.cmml"><mrow id="S4.I1.i1.p1.4.m4.4.4.3" xref="S4.I1.i1.p1.4.m4.4.4.3.cmml"><mi mathvariant="normal" id="S4.I1.i1.p1.4.m4.4.4.3.2" xref="S4.I1.i1.p1.4.m4.4.4.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.4.4.3.1" xref="S4.I1.i1.p1.4.m4.4.4.3.1.cmml">​</mo><mi id="S4.I1.i1.p1.4.m4.4.4.3.3" xref="S4.I1.i1.p1.4.m4.4.4.3.3.cmml">f</mi></mrow><mo stretchy="false" id="S4.I1.i1.p1.4.m4.4.4.2" xref="S4.I1.i1.p1.4.m4.4.4.2.cmml">←</mo><mrow id="S4.I1.i1.p1.4.m4.4.4.1" xref="S4.I1.i1.p1.4.m4.4.4.1.cmml"><msub id="S4.I1.i1.p1.4.m4.4.4.1.2" xref="S4.I1.i1.p1.4.m4.4.4.1.2.cmml"><mi id="S4.I1.i1.p1.4.m4.4.4.1.2.2" xref="S4.I1.i1.p1.4.m4.4.4.1.2.2.cmml">max</mi><mrow id="S4.I1.i1.p1.4.m4.2.2.2.2" xref="S4.I1.i1.p1.4.m4.2.2.2.3.cmml"><mi id="S4.I1.i1.p1.4.m4.1.1.1.1" xref="S4.I1.i1.p1.4.m4.1.1.1.1.cmml">x</mi><mo id="S4.I1.i1.p1.4.m4.2.2.2.2.2" xref="S4.I1.i1.p1.4.m4.2.2.2.3.cmml">,</mo><mrow id="S4.I1.i1.p1.4.m4.2.2.2.2.1" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.cmml"><msup id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.cmml"><mi id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.2" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.2.cmml">x</mi><mo id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.3" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.2.2.2.2.1.1" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.1.cmml">​</mo><mtext id="S4.I1.i1.p1.4.m4.2.2.2.2.1.3" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.3a.cmml">adjacent</mtext></mrow></mrow></msub><mo id="S4.I1.i1.p1.4.m4.4.4.1a" xref="S4.I1.i1.p1.4.m4.4.4.1.cmml">⁡</mo><msub id="S4.I1.i1.p1.4.m4.4.4.1.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.cmml"><mrow id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.2.cmml"><mo id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.2.1.cmml">‖</mo><mrow id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.cmml"><mrow id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.cmml"><mi id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.1.cmml">​</mo><mrow id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.3.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.3.2.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.cmml">(</mo><mi id="S4.I1.i1.p1.4.m4.3.3" xref="S4.I1.i1.p1.4.m4.3.3.cmml">x</mi><mo stretchy="false" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.3.2.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.2.cmml">−</mo><mrow id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.cmml"><mi id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.3" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.2" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.3" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.3" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.3" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S4.I1.i1.p1.4.m4.4.4.1.1.3" xref="S4.I1.i1.p1.4.m4.4.4.1.1.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.4.m4.4b"><apply id="S4.I1.i1.p1.4.m4.4.4.cmml" xref="S4.I1.i1.p1.4.m4.4.4"><ci id="S4.I1.i1.p1.4.m4.4.4.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.2">←</ci><apply id="S4.I1.i1.p1.4.m4.4.4.3.cmml" xref="S4.I1.i1.p1.4.m4.4.4.3"><times id="S4.I1.i1.p1.4.m4.4.4.3.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.3.1"></times><ci id="S4.I1.i1.p1.4.m4.4.4.3.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.3.2">Δ</ci><ci id="S4.I1.i1.p1.4.m4.4.4.3.3.cmml" xref="S4.I1.i1.p1.4.m4.4.4.3.3">𝑓</ci></apply><apply id="S4.I1.i1.p1.4.m4.4.4.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1"><apply id="S4.I1.i1.p1.4.m4.4.4.1.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.2"><csymbol cd="ambiguous" id="S4.I1.i1.p1.4.m4.4.4.1.2.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.2">subscript</csymbol><max id="S4.I1.i1.p1.4.m4.4.4.1.2.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.2.2"></max><list id="S4.I1.i1.p1.4.m4.2.2.2.3.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2"><ci id="S4.I1.i1.p1.4.m4.1.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1.1.1">𝑥</ci><apply id="S4.I1.i1.p1.4.m4.2.2.2.2.1.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1"><times id="S4.I1.i1.p1.4.m4.2.2.2.2.1.1.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.1"></times><apply id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2"><csymbol cd="ambiguous" id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.1.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2">superscript</csymbol><ci id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.2.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.2">𝑥</ci><ci id="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.3.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.2.3">′</ci></apply><ci id="S4.I1.i1.p1.4.m4.2.2.2.2.1.3a.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.3"><mtext mathsize="70%" id="S4.I1.i1.p1.4.m4.2.2.2.2.1.3.cmml" xref="S4.I1.i1.p1.4.m4.2.2.2.2.1.3">adjacent</mtext></ci></apply></list></apply><apply id="S4.I1.i1.p1.4.m4.4.4.1.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.4.m4.4.4.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1">subscript</csymbol><apply id="S4.I1.i1.p1.4.m4.4.4.1.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1"><csymbol cd="latexml" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.2.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.2">norm</csymbol><apply id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1"><minus id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.2"></minus><apply id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3"><times id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.1"></times><ci id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.3.2">𝑓</ci><ci id="S4.I1.i1.p1.4.m4.3.3.cmml" xref="S4.I1.i1.p1.4.m4.3.3">𝑥</ci></apply><apply id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1"><times id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.2"></times><ci id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.3.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.3">𝑓</ci><apply id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></apply><cn type="integer" id="S4.I1.i1.p1.4.m4.4.4.1.1.3.cmml" xref="S4.I1.i1.p1.4.m4.4.4.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.4.m4.4c">\Delta f\leftarrow\max_{x,x^{\prime}\,\text{adjacent}}\left\|f(x)-f(x^{\prime})\right\|_{2}</annotation></semantics></math>;</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.3" class="ltx_p">RDP is amenable to composition, meaning that the outcomes processed sequentially through <math id="S4.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="(\alpha,\rho_{1})" display="inline"><semantics id="S4.I1.i2.p1.1.m1.2a"><mrow id="S4.I1.i2.p1.1.m1.2.2.1" xref="S4.I1.i2.p1.1.m1.2.2.2.cmml"><mo stretchy="false" id="S4.I1.i2.p1.1.m1.2.2.1.2" xref="S4.I1.i2.p1.1.m1.2.2.2.cmml">(</mo><mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">α</mi><mo id="S4.I1.i2.p1.1.m1.2.2.1.3" xref="S4.I1.i2.p1.1.m1.2.2.2.cmml">,</mo><msub id="S4.I1.i2.p1.1.m1.2.2.1.1" xref="S4.I1.i2.p1.1.m1.2.2.1.1.cmml"><mi id="S4.I1.i2.p1.1.m1.2.2.1.1.2" xref="S4.I1.i2.p1.1.m1.2.2.1.1.2.cmml">ρ</mi><mn id="S4.I1.i2.p1.1.m1.2.2.1.1.3" xref="S4.I1.i2.p1.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="S4.I1.i2.p1.1.m1.2.2.1.4" xref="S4.I1.i2.p1.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.2b"><interval closure="open" id="S4.I1.i2.p1.1.m1.2.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2.1"><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">𝛼</ci><apply id="S4.I1.i2.p1.1.m1.2.2.1.1.cmml" xref="S4.I1.i2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.I1.i2.p1.1.m1.2.2.1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S4.I1.i2.p1.1.m1.2.2.1.1.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2.1.1.2">𝜌</ci><cn type="integer" id="S4.I1.i2.p1.1.m1.2.2.1.1.3.cmml" xref="S4.I1.i2.p1.1.m1.2.2.1.1.3">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.2c">(\alpha,\rho_{1})</annotation></semantics></math>-RDP and <math id="S4.I1.i2.p1.2.m2.2" class="ltx_Math" alttext="(\alpha,\rho_{2})" display="inline"><semantics id="S4.I1.i2.p1.2.m2.2a"><mrow id="S4.I1.i2.p1.2.m2.2.2.1" xref="S4.I1.i2.p1.2.m2.2.2.2.cmml"><mo stretchy="false" id="S4.I1.i2.p1.2.m2.2.2.1.2" xref="S4.I1.i2.p1.2.m2.2.2.2.cmml">(</mo><mi id="S4.I1.i2.p1.2.m2.1.1" xref="S4.I1.i2.p1.2.m2.1.1.cmml">α</mi><mo id="S4.I1.i2.p1.2.m2.2.2.1.3" xref="S4.I1.i2.p1.2.m2.2.2.2.cmml">,</mo><msub id="S4.I1.i2.p1.2.m2.2.2.1.1" xref="S4.I1.i2.p1.2.m2.2.2.1.1.cmml"><mi id="S4.I1.i2.p1.2.m2.2.2.1.1.2" xref="S4.I1.i2.p1.2.m2.2.2.1.1.2.cmml">ρ</mi><mn id="S4.I1.i2.p1.2.m2.2.2.1.1.3" xref="S4.I1.i2.p1.2.m2.2.2.1.1.3.cmml">2</mn></msub><mo stretchy="false" id="S4.I1.i2.p1.2.m2.2.2.1.4" xref="S4.I1.i2.p1.2.m2.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.2b"><interval closure="open" id="S4.I1.i2.p1.2.m2.2.2.2.cmml" xref="S4.I1.i2.p1.2.m2.2.2.1"><ci id="S4.I1.i2.p1.2.m2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1">𝛼</ci><apply id="S4.I1.i2.p1.2.m2.2.2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S4.I1.i2.p1.2.m2.2.2.1.1.1.cmml" xref="S4.I1.i2.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S4.I1.i2.p1.2.m2.2.2.1.1.2.cmml" xref="S4.I1.i2.p1.2.m2.2.2.1.1.2">𝜌</ci><cn type="integer" id="S4.I1.i2.p1.2.m2.2.2.1.1.3.cmml" xref="S4.I1.i2.p1.2.m2.2.2.1.1.3">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.2c">(\alpha,\rho_{2})</annotation></semantics></math>-RDP mechanisms satisfy the composition property of <math id="S4.I1.i2.p1.3.m3.2" class="ltx_Math" alttext="(\alpha,\rho_{1}+\rho_{2})" display="inline"><semantics id="S4.I1.i2.p1.3.m3.2a"><mrow id="S4.I1.i2.p1.3.m3.2.2.1" xref="S4.I1.i2.p1.3.m3.2.2.2.cmml"><mo stretchy="false" id="S4.I1.i2.p1.3.m3.2.2.1.2" xref="S4.I1.i2.p1.3.m3.2.2.2.cmml">(</mo><mi id="S4.I1.i2.p1.3.m3.1.1" xref="S4.I1.i2.p1.3.m3.1.1.cmml">α</mi><mo id="S4.I1.i2.p1.3.m3.2.2.1.3" xref="S4.I1.i2.p1.3.m3.2.2.2.cmml">,</mo><mrow id="S4.I1.i2.p1.3.m3.2.2.1.1" xref="S4.I1.i2.p1.3.m3.2.2.1.1.cmml"><msub id="S4.I1.i2.p1.3.m3.2.2.1.1.2" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2.cmml"><mi id="S4.I1.i2.p1.3.m3.2.2.1.1.2.2" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2.2.cmml">ρ</mi><mn id="S4.I1.i2.p1.3.m3.2.2.1.1.2.3" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2.3.cmml">1</mn></msub><mo id="S4.I1.i2.p1.3.m3.2.2.1.1.1" xref="S4.I1.i2.p1.3.m3.2.2.1.1.1.cmml">+</mo><msub id="S4.I1.i2.p1.3.m3.2.2.1.1.3" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3.cmml"><mi id="S4.I1.i2.p1.3.m3.2.2.1.1.3.2" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3.2.cmml">ρ</mi><mn id="S4.I1.i2.p1.3.m3.2.2.1.1.3.3" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S4.I1.i2.p1.3.m3.2.2.1.4" xref="S4.I1.i2.p1.3.m3.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.3.m3.2b"><interval closure="open" id="S4.I1.i2.p1.3.m3.2.2.2.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1"><ci id="S4.I1.i2.p1.3.m3.1.1.cmml" xref="S4.I1.i2.p1.3.m3.1.1">𝛼</ci><apply id="S4.I1.i2.p1.3.m3.2.2.1.1.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1"><plus id="S4.I1.i2.p1.3.m3.2.2.1.1.1.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.1"></plus><apply id="S4.I1.i2.p1.3.m3.2.2.1.1.2.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.I1.i2.p1.3.m3.2.2.1.1.2.1.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2">subscript</csymbol><ci id="S4.I1.i2.p1.3.m3.2.2.1.1.2.2.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2.2">𝜌</ci><cn type="integer" id="S4.I1.i2.p1.3.m3.2.2.1.1.2.3.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.2.3">1</cn></apply><apply id="S4.I1.i2.p1.3.m3.2.2.1.1.3.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.I1.i2.p1.3.m3.2.2.1.1.3.1.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3">subscript</csymbol><ci id="S4.I1.i2.p1.3.m3.2.2.1.1.3.2.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3.2">𝜌</ci><cn type="integer" id="S4.I1.i2.p1.3.m3.2.2.1.1.3.3.cmml" xref="S4.I1.i2.p1.3.m3.2.2.1.1.3.3">2</cn></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.3.m3.2c">(\alpha,\rho_{1}+\rho_{2})</annotation></semantics></math>-RDP.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">RDP can be transformed into the classical DP, facilitating comparative analysis of privacy with other mechanisms.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.SSS2.p4" class="ltx_para">
<p id="S4.SS1.SSS2.p4.1" class="ltx_p">More recent research in the field of federated learning has replaced classical DP with RDP as the basis for privacy. DP-FedSAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite> is proposed under the consideration of RDP on how to improve the optimizer to enhance model utility. Fed-SMP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite> considers how to apply RDP’s privacy guarantee to the model after sparsification.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS3.5.1.1" class="ltx_text">IV-A</span>3 </span>DP with Heterogeneity</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">In real-world environments, federated learning frameworks with Differential Privacy may encounter several issues due to heterogeneity. We categorize these issues as follows:</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">Different clients have varying requirements for privacy, making it difficult to determine the privacy of the entire system;</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">If a client’s privacy budget is too small, the model information from that client is likely to affect model performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>;</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">Data heterogeneity itself can lead to a loss in model utility, and DP can make this loss more apparent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">In response to these issues, the academic community has proposed some solutions. PFA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite> classifies clients into public and private categories based on their privacy budgets. After the models of the two types of clients are aggregated separately according to the privacy budget, the model of the private client is projected into the space of the public client’s model. This takes into account the different credibility of information with different privacy levels and does not waste data with stronger privacy. In some cases, the network environment where the federated learning algorithm is deployed also has heterogeneity, and FedSeC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite> has proposed improvements from this perspective. There are also works like DP-SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>, which advance from the perspective of reducing model utility loss.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Secure Multi-party Computation</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Secure Multi-party Computation (SMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite> refers to methods that ensure the security of distributed computation in complex network environments, often with security guarantees provided by cryptography. Due to the nature of cryptography <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite>, the model information processed by SMC is almost undamaged, ensuring that the utility of the model does not decrease. However, these methods often involve complex computational processes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>, leading to significant time and space overhead during the model training process.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span>Homomorphic Encryption</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.3" class="ltx_p">Homomorphic encryption (HE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite> is a specialized cryptographic scheme that imposes additional requirements on certain computational properties to be preserved beyond traditional encryption/decryption functionalities. Different types of HE satisfy distinct properties as follows <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite>. Assuming that <math id="S4.SS2.SSS1.p1.1.m1.2" class="ltx_Math" alttext="+,\cdot" display="inline"><semantics id="S4.SS2.SSS1.p1.1.m1.2a"><mrow id="S4.SS2.SSS1.p1.1.m1.2.3.2" xref="S4.SS2.SSS1.p1.1.m1.2.3.1.cmml"><mo rspace="0em" id="S4.SS2.SSS1.p1.1.m1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.cmml">+</mo><mo rspace="0em" id="S4.SS2.SSS1.p1.1.m1.2.3.2.1" xref="S4.SS2.SSS1.p1.1.m1.2.3.1.cmml">,</mo><mo lspace="0em" id="S4.SS2.SSS1.p1.1.m1.2.2" xref="S4.SS2.SSS1.p1.1.m1.2.2.cmml">⋅</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.1.m1.2b"><list id="S4.SS2.SSS1.p1.1.m1.2.3.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.2.3.2"><plus id="S4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1"></plus><ci id="S4.SS2.SSS1.p1.1.m1.2.2.cmml" xref="S4.SS2.SSS1.p1.1.m1.2.2">⋅</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.1.m1.2c">+,\cdot</annotation></semantics></math> are addition and multiplication on plaintext space and <math id="S4.SS2.SSS1.p1.2.m2.2" class="ltx_Math" alttext="\oplus,\odot" display="inline"><semantics id="S4.SS2.SSS1.p1.2.m2.2a"><mrow id="S4.SS2.SSS1.p1.2.m2.2.3.2" xref="S4.SS2.SSS1.p1.2.m2.2.3.1.cmml"><mo rspace="0em" id="S4.SS2.SSS1.p1.2.m2.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.cmml">⊕</mo><mo rspace="0em" id="S4.SS2.SSS1.p1.2.m2.2.3.2.1" xref="S4.SS2.SSS1.p1.2.m2.2.3.1.cmml">,</mo><mo lspace="0em" id="S4.SS2.SSS1.p1.2.m2.2.2" xref="S4.SS2.SSS1.p1.2.m2.2.2.cmml">⊙</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.2.m2.2b"><list id="S4.SS2.SSS1.p1.2.m2.2.3.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.2.3.2"><csymbol cd="latexml" id="S4.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1">direct-sum</csymbol><csymbol cd="latexml" id="S4.SS2.SSS1.p1.2.m2.2.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.2.2">direct-product</csymbol></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.2.m2.2c">\oplus,\odot</annotation></semantics></math> are ones on cipher space, and <math id="S4.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\mathsf{E}" display="inline"><semantics id="S4.SS2.SSS1.p1.3.m3.1a"><mi id="S4.SS2.SSS1.p1.3.m3.1.1" xref="S4.SS2.SSS1.p1.3.m3.1.1.cmml">𝖤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.3.m3.1b"><ci id="S4.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1">𝖤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.3.m3.1c">\mathsf{E}</annotation></semantics></math> refers to encryption operation.</p>
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.2" class="ltx_p"><span id="S4.I3.i1.p1.2.1" class="ltx_text ltx_font_bold">Addictive Homomorphism.</span> <math id="S4.I3.i1.p1.1.m1.3" class="ltx_Math" alttext="\mathsf{E}(a+b)=\mathsf{E}(a)\oplus\mathsf{E}(b)" display="inline"><semantics id="S4.I3.i1.p1.1.m1.3a"><mrow id="S4.I3.i1.p1.1.m1.3.3" xref="S4.I3.i1.p1.1.m1.3.3.cmml"><mrow id="S4.I3.i1.p1.1.m1.3.3.1" xref="S4.I3.i1.p1.1.m1.3.3.1.cmml"><mi id="S4.I3.i1.p1.1.m1.3.3.1.3" xref="S4.I3.i1.p1.1.m1.3.3.1.3.cmml">𝖤</mi><mo lspace="0em" rspace="0em" id="S4.I3.i1.p1.1.m1.3.3.1.2" xref="S4.I3.i1.p1.1.m1.3.3.1.2.cmml">​</mo><mrow id="S4.I3.i1.p1.1.m1.3.3.1.1.1" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.I3.i1.p1.1.m1.3.3.1.1.1.2" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.cmml"><mi id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.2" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.2.cmml">a</mi><mo id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.1" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.1.cmml">+</mo><mi id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.3" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.3.cmml">b</mi></mrow><mo stretchy="false" id="S4.I3.i1.p1.1.m1.3.3.1.1.1.3" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.I3.i1.p1.1.m1.3.3.2" xref="S4.I3.i1.p1.1.m1.3.3.2.cmml">=</mo><mrow id="S4.I3.i1.p1.1.m1.3.3.3" xref="S4.I3.i1.p1.1.m1.3.3.3.cmml"><mrow id="S4.I3.i1.p1.1.m1.3.3.3.2" xref="S4.I3.i1.p1.1.m1.3.3.3.2.cmml"><mi id="S4.I3.i1.p1.1.m1.3.3.3.2.2" xref="S4.I3.i1.p1.1.m1.3.3.3.2.2.cmml">𝖤</mi><mo lspace="0em" rspace="0em" id="S4.I3.i1.p1.1.m1.3.3.3.2.1" xref="S4.I3.i1.p1.1.m1.3.3.3.2.1.cmml">​</mo><mrow id="S4.I3.i1.p1.1.m1.3.3.3.2.3.2" xref="S4.I3.i1.p1.1.m1.3.3.3.2.cmml"><mo stretchy="false" id="S4.I3.i1.p1.1.m1.3.3.3.2.3.2.1" xref="S4.I3.i1.p1.1.m1.3.3.3.2.cmml">(</mo><mi id="S4.I3.i1.p1.1.m1.1.1" xref="S4.I3.i1.p1.1.m1.1.1.cmml">a</mi><mo stretchy="false" id="S4.I3.i1.p1.1.m1.3.3.3.2.3.2.2" xref="S4.I3.i1.p1.1.m1.3.3.3.2.cmml">)</mo></mrow></mrow><mo id="S4.I3.i1.p1.1.m1.3.3.3.1" xref="S4.I3.i1.p1.1.m1.3.3.3.1.cmml">⊕</mo><mrow id="S4.I3.i1.p1.1.m1.3.3.3.3" xref="S4.I3.i1.p1.1.m1.3.3.3.3.cmml"><mi id="S4.I3.i1.p1.1.m1.3.3.3.3.2" xref="S4.I3.i1.p1.1.m1.3.3.3.3.2.cmml">𝖤</mi><mo lspace="0em" rspace="0em" id="S4.I3.i1.p1.1.m1.3.3.3.3.1" xref="S4.I3.i1.p1.1.m1.3.3.3.3.1.cmml">​</mo><mrow id="S4.I3.i1.p1.1.m1.3.3.3.3.3.2" xref="S4.I3.i1.p1.1.m1.3.3.3.3.cmml"><mo stretchy="false" id="S4.I3.i1.p1.1.m1.3.3.3.3.3.2.1" xref="S4.I3.i1.p1.1.m1.3.3.3.3.cmml">(</mo><mi id="S4.I3.i1.p1.1.m1.2.2" xref="S4.I3.i1.p1.1.m1.2.2.cmml">b</mi><mo stretchy="false" id="S4.I3.i1.p1.1.m1.3.3.3.3.3.2.2" xref="S4.I3.i1.p1.1.m1.3.3.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.1.m1.3b"><apply id="S4.I3.i1.p1.1.m1.3.3.cmml" xref="S4.I3.i1.p1.1.m1.3.3"><eq id="S4.I3.i1.p1.1.m1.3.3.2.cmml" xref="S4.I3.i1.p1.1.m1.3.3.2"></eq><apply id="S4.I3.i1.p1.1.m1.3.3.1.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1"><times id="S4.I3.i1.p1.1.m1.3.3.1.2.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1.2"></times><ci id="S4.I3.i1.p1.1.m1.3.3.1.3.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1.3">𝖤</ci><apply id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1"><plus id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.1"></plus><ci id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.2.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.2">𝑎</ci><ci id="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.3.cmml" xref="S4.I3.i1.p1.1.m1.3.3.1.1.1.1.3">𝑏</ci></apply></apply><apply id="S4.I3.i1.p1.1.m1.3.3.3.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3"><csymbol cd="latexml" id="S4.I3.i1.p1.1.m1.3.3.3.1.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.1">direct-sum</csymbol><apply id="S4.I3.i1.p1.1.m1.3.3.3.2.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.2"><times id="S4.I3.i1.p1.1.m1.3.3.3.2.1.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.2.1"></times><ci id="S4.I3.i1.p1.1.m1.3.3.3.2.2.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.2.2">𝖤</ci><ci id="S4.I3.i1.p1.1.m1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1">𝑎</ci></apply><apply id="S4.I3.i1.p1.1.m1.3.3.3.3.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.3"><times id="S4.I3.i1.p1.1.m1.3.3.3.3.1.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.3.1"></times><ci id="S4.I3.i1.p1.1.m1.3.3.3.3.2.cmml" xref="S4.I3.i1.p1.1.m1.3.3.3.3.2">𝖤</ci><ci id="S4.I3.i1.p1.1.m1.2.2.cmml" xref="S4.I3.i1.p1.1.m1.2.2">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.1.m1.3c">\mathsf{E}(a+b)=\mathsf{E}(a)\oplus\mathsf{E}(b)</annotation></semantics></math> for any plaintexts <math id="S4.I3.i1.p1.2.m2.2" class="ltx_Math" alttext="a,b" display="inline"><semantics id="S4.I3.i1.p1.2.m2.2a"><mrow id="S4.I3.i1.p1.2.m2.2.3.2" xref="S4.I3.i1.p1.2.m2.2.3.1.cmml"><mi id="S4.I3.i1.p1.2.m2.1.1" xref="S4.I3.i1.p1.2.m2.1.1.cmml">a</mi><mo id="S4.I3.i1.p1.2.m2.2.3.2.1" xref="S4.I3.i1.p1.2.m2.2.3.1.cmml">,</mo><mi id="S4.I3.i1.p1.2.m2.2.2" xref="S4.I3.i1.p1.2.m2.2.2.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.2.m2.2b"><list id="S4.I3.i1.p1.2.m2.2.3.1.cmml" xref="S4.I3.i1.p1.2.m2.2.3.2"><ci id="S4.I3.i1.p1.2.m2.1.1.cmml" xref="S4.I3.i1.p1.2.m2.1.1">𝑎</ci><ci id="S4.I3.i1.p1.2.m2.2.2.cmml" xref="S4.I3.i1.p1.2.m2.2.2">𝑏</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.2.m2.2c">a,b</annotation></semantics></math>;</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.2" class="ltx_p"><span id="S4.I3.i2.p1.2.1" class="ltx_text ltx_font_bold">Multiplicative Homomorphism.</span> <math id="S4.I3.i2.p1.1.m1.3" class="ltx_Math" alttext="\mathsf{E}(a\cdot b)=\mathsf{E}(a)\odot\mathsf{E}(b)" display="inline"><semantics id="S4.I3.i2.p1.1.m1.3a"><mrow id="S4.I3.i2.p1.1.m1.3.3" xref="S4.I3.i2.p1.1.m1.3.3.cmml"><mrow id="S4.I3.i2.p1.1.m1.3.3.1" xref="S4.I3.i2.p1.1.m1.3.3.1.cmml"><mi id="S4.I3.i2.p1.1.m1.3.3.1.3" xref="S4.I3.i2.p1.1.m1.3.3.1.3.cmml">𝖤</mi><mo lspace="0em" rspace="0em" id="S4.I3.i2.p1.1.m1.3.3.1.2" xref="S4.I3.i2.p1.1.m1.3.3.1.2.cmml">​</mo><mrow id="S4.I3.i2.p1.1.m1.3.3.1.1.1" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.I3.i2.p1.1.m1.3.3.1.1.1.2" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.cmml"><mi id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.2" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.1" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.1.cmml">⋅</mo><mi id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.3" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.3.cmml">b</mi></mrow><mo stretchy="false" id="S4.I3.i2.p1.1.m1.3.3.1.1.1.3" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.I3.i2.p1.1.m1.3.3.2" xref="S4.I3.i2.p1.1.m1.3.3.2.cmml">=</mo><mrow id="S4.I3.i2.p1.1.m1.3.3.3" xref="S4.I3.i2.p1.1.m1.3.3.3.cmml"><mrow id="S4.I3.i2.p1.1.m1.3.3.3.2" xref="S4.I3.i2.p1.1.m1.3.3.3.2.cmml"><mrow id="S4.I3.i2.p1.1.m1.3.3.3.2.2" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.cmml"><mi id="S4.I3.i2.p1.1.m1.3.3.3.2.2.2" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.2.cmml">𝖤</mi><mo lspace="0em" rspace="0em" id="S4.I3.i2.p1.1.m1.3.3.3.2.2.1" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.1.cmml">​</mo><mrow id="S4.I3.i2.p1.1.m1.3.3.3.2.2.3.2" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.cmml"><mo stretchy="false" id="S4.I3.i2.p1.1.m1.3.3.3.2.2.3.2.1" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.cmml">(</mo><mi id="S4.I3.i2.p1.1.m1.1.1" xref="S4.I3.i2.p1.1.m1.1.1.cmml">a</mi><mo rspace="0.055em" stretchy="false" id="S4.I3.i2.p1.1.m1.3.3.3.2.2.3.2.2" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.I3.i2.p1.1.m1.3.3.3.2.1" xref="S4.I3.i2.p1.1.m1.3.3.3.2.1.cmml">⊙</mo><mi id="S4.I3.i2.p1.1.m1.3.3.3.2.3" xref="S4.I3.i2.p1.1.m1.3.3.3.2.3.cmml">𝖤</mi></mrow><mo lspace="0em" rspace="0em" id="S4.I3.i2.p1.1.m1.3.3.3.1" xref="S4.I3.i2.p1.1.m1.3.3.3.1.cmml">​</mo><mrow id="S4.I3.i2.p1.1.m1.3.3.3.3.2" xref="S4.I3.i2.p1.1.m1.3.3.3.cmml"><mo stretchy="false" id="S4.I3.i2.p1.1.m1.3.3.3.3.2.1" xref="S4.I3.i2.p1.1.m1.3.3.3.cmml">(</mo><mi id="S4.I3.i2.p1.1.m1.2.2" xref="S4.I3.i2.p1.1.m1.2.2.cmml">b</mi><mo stretchy="false" id="S4.I3.i2.p1.1.m1.3.3.3.3.2.2" xref="S4.I3.i2.p1.1.m1.3.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.1.m1.3b"><apply id="S4.I3.i2.p1.1.m1.3.3.cmml" xref="S4.I3.i2.p1.1.m1.3.3"><eq id="S4.I3.i2.p1.1.m1.3.3.2.cmml" xref="S4.I3.i2.p1.1.m1.3.3.2"></eq><apply id="S4.I3.i2.p1.1.m1.3.3.1.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1"><times id="S4.I3.i2.p1.1.m1.3.3.1.2.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1.2"></times><ci id="S4.I3.i2.p1.1.m1.3.3.1.3.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1.3">𝖤</ci><apply id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1"><ci id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.1">⋅</ci><ci id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.2.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.2">𝑎</ci><ci id="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.3.cmml" xref="S4.I3.i2.p1.1.m1.3.3.1.1.1.1.3">𝑏</ci></apply></apply><apply id="S4.I3.i2.p1.1.m1.3.3.3.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3"><times id="S4.I3.i2.p1.1.m1.3.3.3.1.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.1"></times><apply id="S4.I3.i2.p1.1.m1.3.3.3.2.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.2"><csymbol cd="latexml" id="S4.I3.i2.p1.1.m1.3.3.3.2.1.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.2.1">direct-product</csymbol><apply id="S4.I3.i2.p1.1.m1.3.3.3.2.2.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2"><times id="S4.I3.i2.p1.1.m1.3.3.3.2.2.1.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.1"></times><ci id="S4.I3.i2.p1.1.m1.3.3.3.2.2.2.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.2.2.2">𝖤</ci><ci id="S4.I3.i2.p1.1.m1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1">𝑎</ci></apply><ci id="S4.I3.i2.p1.1.m1.3.3.3.2.3.cmml" xref="S4.I3.i2.p1.1.m1.3.3.3.2.3">𝖤</ci></apply><ci id="S4.I3.i2.p1.1.m1.2.2.cmml" xref="S4.I3.i2.p1.1.m1.2.2">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.1.m1.3c">\mathsf{E}(a\cdot b)=\mathsf{E}(a)\odot\mathsf{E}(b)</annotation></semantics></math> for any plaintexts <math id="S4.I3.i2.p1.2.m2.2" class="ltx_Math" alttext="a,b" display="inline"><semantics id="S4.I3.i2.p1.2.m2.2a"><mrow id="S4.I3.i2.p1.2.m2.2.3.2" xref="S4.I3.i2.p1.2.m2.2.3.1.cmml"><mi id="S4.I3.i2.p1.2.m2.1.1" xref="S4.I3.i2.p1.2.m2.1.1.cmml">a</mi><mo id="S4.I3.i2.p1.2.m2.2.3.2.1" xref="S4.I3.i2.p1.2.m2.2.3.1.cmml">,</mo><mi id="S4.I3.i2.p1.2.m2.2.2" xref="S4.I3.i2.p1.2.m2.2.2.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.2.m2.2b"><list id="S4.I3.i2.p1.2.m2.2.3.1.cmml" xref="S4.I3.i2.p1.2.m2.2.3.2"><ci id="S4.I3.i2.p1.2.m2.1.1.cmml" xref="S4.I3.i2.p1.2.m2.1.1">𝑎</ci><ci id="S4.I3.i2.p1.2.m2.2.2.cmml" xref="S4.I3.i2.p1.2.m2.2.2">𝑏</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.2.m2.2c">a,b</annotation></semantics></math>;</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">A cryptographic scheme satisfying only one property is termed partially HE, whereas one that satisfies both properties is named fully HE. When HE is employed in federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite>, the model can be encrypted before transmission, preventing even observers or servers from accessing model information. Building upon this foundation, leveraging the properties of homomorphic encryption, servers can perform aggregation operations on the model without acquiring the model information.
In the current landscape of common homomorphic encryption schemes, the Paillier cryptosystem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>]</cite>, as an additive homomorphic encryption scheme, was introduced relatively early and is extensively used in federated learning. The GSW cryptosystem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite> was the first to propose bootstrap, enabling homomorphic multiplication to transition from a finite number of times to an infinite number, achieving full homomorphic encryption in the truest sense. The CKKS cryptosystem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite>, built upon the GSW cryptosystem, enables direct encryption of real number vectors, making it more applicable to machine learning scenarios.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p">However, different clients may hold different keys, and in Homomorphic Encryption (HE), the same key must be used for encryption to perform ciphertext computation. This poses a challenge for HE in heterogeneous scenarios in federated learning. An effective solution is key distribution, where all client keys are managed and distributed by a trustworthy third party (TTP). This scheme is easy to implement, but the security of the system relies on whether the TTP is truly trustworthy. Another method is called key agreement, which does not require a TTP. Each client communicates on their own, negotiating with the keys held by themselves and the other party to generate a consistent session key. Currently, there is a framework called xMK-CKKS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib185" title="" class="ltx_ref">185</a>]</cite>, designed based on the key agreement scheme, that can merge all client public keys into one key for CKKS encryption.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span>Functional Encryption</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.8" class="ltx_p">In conventional cryptographic schemes, possession of the private key implies the ability to fully decrypt the ciphertext. However, functional encryption (FE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite> imposes a limit on the amount of information that a key can access. In FE, a key <math id="S4.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathsf{sk}_{f}" display="inline"><semantics id="S4.SS2.SSS2.p1.1.m1.1a"><msub id="S4.SS2.SSS2.p1.1.m1.1.1" xref="S4.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS2.p1.1.m1.1.1.2" xref="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml">𝗌𝗄</mi><mi id="S4.SS2.SSS2.p1.1.m1.1.1.3" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.1.m1.1b"><apply id="S4.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.2">𝗌𝗄</ci><ci id="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.1.m1.1c">\mathsf{sk}_{f}</annotation></semantics></math> corresponds to a function <math id="S4.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS2.SSS2.p1.2.m2.1a"><mi id="S4.SS2.SSS2.p1.2.m2.1.1" xref="S4.SS2.SSS2.p1.2.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.2.m2.1b"><ci id="S4.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.2.m2.1c">f</annotation></semantics></math>. Assuming there is a plaintext <math id="S4.SS2.SSS2.p1.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS2.SSS2.p1.3.m3.1a"><mi id="S4.SS2.SSS2.p1.3.m3.1.1" xref="S4.SS2.SSS2.p1.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.3.m3.1b"><ci id="S4.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p1.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.3.m3.1c">x</annotation></semantics></math>, an entity possessing <math id="S4.SS2.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\mathsf{sk}_{f}" display="inline"><semantics id="S4.SS2.SSS2.p1.4.m4.1a"><msub id="S4.SS2.SSS2.p1.4.m4.1.1" xref="S4.SS2.SSS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.SSS2.p1.4.m4.1.1.2" xref="S4.SS2.SSS2.p1.4.m4.1.1.2.cmml">𝗌𝗄</mi><mi id="S4.SS2.SSS2.p1.4.m4.1.1.3" xref="S4.SS2.SSS2.p1.4.m4.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.4.m4.1b"><apply id="S4.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1.2">𝗌𝗄</ci><ci id="S4.SS2.SSS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.4.m4.1c">\mathsf{sk}_{f}</annotation></semantics></math> can only obtain <math id="S4.SS2.SSS2.p1.5.m5.1" class="ltx_Math" alttext="f(x)" display="inline"><semantics id="S4.SS2.SSS2.p1.5.m5.1a"><mrow id="S4.SS2.SSS2.p1.5.m5.1.2" xref="S4.SS2.SSS2.p1.5.m5.1.2.cmml"><mi id="S4.SS2.SSS2.p1.5.m5.1.2.2" xref="S4.SS2.SSS2.p1.5.m5.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p1.5.m5.1.2.1" xref="S4.SS2.SSS2.p1.5.m5.1.2.1.cmml">​</mo><mrow id="S4.SS2.SSS2.p1.5.m5.1.2.3.2" xref="S4.SS2.SSS2.p1.5.m5.1.2.cmml"><mo stretchy="false" id="S4.SS2.SSS2.p1.5.m5.1.2.3.2.1" xref="S4.SS2.SSS2.p1.5.m5.1.2.cmml">(</mo><mi id="S4.SS2.SSS2.p1.5.m5.1.1" xref="S4.SS2.SSS2.p1.5.m5.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS2.SSS2.p1.5.m5.1.2.3.2.2" xref="S4.SS2.SSS2.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.5.m5.1b"><apply id="S4.SS2.SSS2.p1.5.m5.1.2.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.2"><times id="S4.SS2.SSS2.p1.5.m5.1.2.1.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.2.1"></times><ci id="S4.SS2.SSS2.p1.5.m5.1.2.2.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.2.2">𝑓</ci><ci id="S4.SS2.SSS2.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.5.m5.1c">f(x)</annotation></semantics></math> after decryption and cannot know the information of <math id="S4.SS2.SSS2.p1.6.m6.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS2.SSS2.p1.6.m6.1a"><mi id="S4.SS2.SSS2.p1.6.m6.1.1" xref="S4.SS2.SSS2.p1.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.6.m6.1b"><ci id="S4.SS2.SSS2.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS2.p1.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.6.m6.1c">x</annotation></semantics></math> (unless <math id="S4.SS2.SSS2.p1.7.m7.1" class="ltx_Math" alttext="f(x)=x" display="inline"><semantics id="S4.SS2.SSS2.p1.7.m7.1a"><mrow id="S4.SS2.SSS2.p1.7.m7.1.2" xref="S4.SS2.SSS2.p1.7.m7.1.2.cmml"><mrow id="S4.SS2.SSS2.p1.7.m7.1.2.2" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.cmml"><mi id="S4.SS2.SSS2.p1.7.m7.1.2.2.2" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p1.7.m7.1.2.2.1" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.1.cmml">​</mo><mrow id="S4.SS2.SSS2.p1.7.m7.1.2.2.3.2" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.cmml"><mo stretchy="false" id="S4.SS2.SSS2.p1.7.m7.1.2.2.3.2.1" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.cmml">(</mo><mi id="S4.SS2.SSS2.p1.7.m7.1.1" xref="S4.SS2.SSS2.p1.7.m7.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS2.SSS2.p1.7.m7.1.2.2.3.2.2" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.cmml">)</mo></mrow></mrow><mo id="S4.SS2.SSS2.p1.7.m7.1.2.1" xref="S4.SS2.SSS2.p1.7.m7.1.2.1.cmml">=</mo><mi id="S4.SS2.SSS2.p1.7.m7.1.2.3" xref="S4.SS2.SSS2.p1.7.m7.1.2.3.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.7.m7.1b"><apply id="S4.SS2.SSS2.p1.7.m7.1.2.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.2"><eq id="S4.SS2.SSS2.p1.7.m7.1.2.1.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.2.1"></eq><apply id="S4.SS2.SSS2.p1.7.m7.1.2.2.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.2.2"><times id="S4.SS2.SSS2.p1.7.m7.1.2.2.1.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.1"></times><ci id="S4.SS2.SSS2.p1.7.m7.1.2.2.2.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.2.2.2">𝑓</ci><ci id="S4.SS2.SSS2.p1.7.m7.1.1.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.1">𝑥</ci></apply><ci id="S4.SS2.SSS2.p1.7.m7.1.2.3.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.2.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.7.m7.1c">f(x)=x</annotation></semantics></math> happens to be true). In a heterogeneous environment, FE requires a TTP to distribute various private keys <math id="S4.SS2.SSS2.p1.8.m8.1" class="ltx_Math" alttext="\mathsf{sk}" display="inline"><semantics id="S4.SS2.SSS2.p1.8.m8.1a"><mi id="S4.SS2.SSS2.p1.8.m8.1.1" xref="S4.SS2.SSS2.p1.8.m8.1.1.cmml">𝗌𝗄</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.8.m8.1b"><ci id="S4.SS2.SSS2.p1.8.m8.1.1.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1">𝗌𝗄</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.8.m8.1c">\mathsf{sk}</annotation></semantics></math>, which implies that the security of the entire system depends on the trustworthiness of the TTP.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">In federated learning, the function <math id="S4.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS2.SSS2.p2.1.m1.1a"><mi id="S4.SS2.SSS2.p2.1.m1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.1b"><ci id="S4.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.1c">f</annotation></semantics></math> corresponding to the key is often set as Multi-Input Functional Encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite>, as in HybridAlpha <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib188" title="" class="ltx_ref">188</a>]</cite>. This setting can effectively prevent inference attacks. In response to the security issues of the TTP, Chotard et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib189" title="" class="ltx_ref">189</a>]</cite> proposed a decentralized scheme, DMCFE, which allows the system to operate without any TTP, thereby enhancing security. Building on this, 2DMCFE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib190" title="" class="ltx_ref">190</a>]</cite> combines the advantages of previous research and can effectively resist mix-and-match attacks.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS3.5.1.1" class="ltx_text">IV-B</span>3 </span>Secrecy Sharing</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.3" class="ltx_p">Secret sharing (SS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib191" title="" class="ltx_ref">191</a>, <a href="#bib.bib192" title="" class="ltx_ref">192</a>]</cite> is a technique for splitting and storing secret information, which can effectively prevent the leakage of secrets due to collusion among multiple participants. The core idea is to split the secret into <math id="S4.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.SSS3.p1.1.m1.1a"><mi id="S4.SS2.SSS3.p1.1.m1.1.1" xref="S4.SS2.SSS3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.1.m1.1b"><ci id="S4.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.1.m1.1c">n</annotation></semantics></math> parts, and at least <math id="S4.SS2.SSS3.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.SSS3.p1.2.m2.1a"><mi id="S4.SS2.SSS3.p1.2.m2.1.1" xref="S4.SS2.SSS3.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.2.m2.1b"><ci id="S4.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.2.m2.1c">t</annotation></semantics></math> slices are needed to fully restore the secret. This scheme is called <math id="S4.SS2.SSS3.p1.3.m3.2" class="ltx_Math" alttext="(t,n)" display="inline"><semantics id="S4.SS2.SSS3.p1.3.m3.2a"><mrow id="S4.SS2.SSS3.p1.3.m3.2.3.2" xref="S4.SS2.SSS3.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p1.3.m3.2.3.2.1" xref="S4.SS2.SSS3.p1.3.m3.2.3.1.cmml">(</mo><mi id="S4.SS2.SSS3.p1.3.m3.1.1" xref="S4.SS2.SSS3.p1.3.m3.1.1.cmml">t</mi><mo id="S4.SS2.SSS3.p1.3.m3.2.3.2.2" xref="S4.SS2.SSS3.p1.3.m3.2.3.1.cmml">,</mo><mi id="S4.SS2.SSS3.p1.3.m3.2.2" xref="S4.SS2.SSS3.p1.3.m3.2.2.cmml">n</mi><mo stretchy="false" id="S4.SS2.SSS3.p1.3.m3.2.3.2.3" xref="S4.SS2.SSS3.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.3.m3.2b"><interval closure="open" id="S4.SS2.SSS3.p1.3.m3.2.3.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.2.3.2"><ci id="S4.SS2.SSS3.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.1.1">𝑡</ci><ci id="S4.SS2.SSS3.p1.3.m3.2.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.2.2">𝑛</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.3.m3.2c">(t,n)</annotation></semantics></math>-secret sharing.</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.6" class="ltx_p">The most classic in SS is the Shamir scheme <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib191" title="" class="ltx_ref">191</a>]</cite>. In this scheme, the secret is encoded as a <math id="S4.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="(t-1)" display="inline"><semantics id="S4.SS2.SSS3.p2.1.m1.1a"><mrow id="S4.SS2.SSS3.p2.1.m1.1.1.1" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p2.1.m1.1.1.1.2" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS3.p2.1.m1.1.1.1.1" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.2" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.2.cmml">t</mi><mo id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.1" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.1.cmml">−</mo><mn id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.3" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS2.SSS3.p2.1.m1.1.1.1.3" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.1.m1.1b"><apply id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.1"><minus id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.1"></minus><ci id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.2">𝑡</ci><cn type="integer" id="S4.SS2.SSS3.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.1.m1.1c">(t-1)</annotation></semantics></math>-dimensional polynomial function <math id="S4.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="P(x)" display="inline"><semantics id="S4.SS2.SSS3.p2.2.m2.1a"><mrow id="S4.SS2.SSS3.p2.2.m2.1.2" xref="S4.SS2.SSS3.p2.2.m2.1.2.cmml"><mi id="S4.SS2.SSS3.p2.2.m2.1.2.2" xref="S4.SS2.SSS3.p2.2.m2.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p2.2.m2.1.2.1" xref="S4.SS2.SSS3.p2.2.m2.1.2.1.cmml">​</mo><mrow id="S4.SS2.SSS3.p2.2.m2.1.2.3.2" xref="S4.SS2.SSS3.p2.2.m2.1.2.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p2.2.m2.1.2.3.2.1" xref="S4.SS2.SSS3.p2.2.m2.1.2.cmml">(</mo><mi id="S4.SS2.SSS3.p2.2.m2.1.1" xref="S4.SS2.SSS3.p2.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS2.SSS3.p2.2.m2.1.2.3.2.2" xref="S4.SS2.SSS3.p2.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.2.m2.1b"><apply id="S4.SS2.SSS3.p2.2.m2.1.2.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.2"><times id="S4.SS2.SSS3.p2.2.m2.1.2.1.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.2.1"></times><ci id="S4.SS2.SSS3.p2.2.m2.1.2.2.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.2.2">𝑃</ci><ci id="S4.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.2.m2.1c">P(x)</annotation></semantics></math>, and each participant is assigned the information of a point on <math id="S4.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="P(x)" display="inline"><semantics id="S4.SS2.SSS3.p2.3.m3.1a"><mrow id="S4.SS2.SSS3.p2.3.m3.1.2" xref="S4.SS2.SSS3.p2.3.m3.1.2.cmml"><mi id="S4.SS2.SSS3.p2.3.m3.1.2.2" xref="S4.SS2.SSS3.p2.3.m3.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p2.3.m3.1.2.1" xref="S4.SS2.SSS3.p2.3.m3.1.2.1.cmml">​</mo><mrow id="S4.SS2.SSS3.p2.3.m3.1.2.3.2" xref="S4.SS2.SSS3.p2.3.m3.1.2.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p2.3.m3.1.2.3.2.1" xref="S4.SS2.SSS3.p2.3.m3.1.2.cmml">(</mo><mi id="S4.SS2.SSS3.p2.3.m3.1.1" xref="S4.SS2.SSS3.p2.3.m3.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS2.SSS3.p2.3.m3.1.2.3.2.2" xref="S4.SS2.SSS3.p2.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.3.m3.1b"><apply id="S4.SS2.SSS3.p2.3.m3.1.2.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.2"><times id="S4.SS2.SSS3.p2.3.m3.1.2.1.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.2.1"></times><ci id="S4.SS2.SSS3.p2.3.m3.1.2.2.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.2.2">𝑃</ci><ci id="S4.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.3.m3.1c">P(x)</annotation></semantics></math>. In this way, <math id="S4.SS2.SSS3.p2.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.SSS3.p2.4.m4.1a"><mi id="S4.SS2.SSS3.p2.4.m4.1.1" xref="S4.SS2.SSS3.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.4.m4.1b"><ci id="S4.SS2.SSS3.p2.4.m4.1.1.cmml" xref="S4.SS2.SSS3.p2.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.4.m4.1c">t</annotation></semantics></math> participants can restore <math id="S4.SS2.SSS3.p2.5.m5.1" class="ltx_Math" alttext="P(x)" display="inline"><semantics id="S4.SS2.SSS3.p2.5.m5.1a"><mrow id="S4.SS2.SSS3.p2.5.m5.1.2" xref="S4.SS2.SSS3.p2.5.m5.1.2.cmml"><mi id="S4.SS2.SSS3.p2.5.m5.1.2.2" xref="S4.SS2.SSS3.p2.5.m5.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS3.p2.5.m5.1.2.1" xref="S4.SS2.SSS3.p2.5.m5.1.2.1.cmml">​</mo><mrow id="S4.SS2.SSS3.p2.5.m5.1.2.3.2" xref="S4.SS2.SSS3.p2.5.m5.1.2.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p2.5.m5.1.2.3.2.1" xref="S4.SS2.SSS3.p2.5.m5.1.2.cmml">(</mo><mi id="S4.SS2.SSS3.p2.5.m5.1.1" xref="S4.SS2.SSS3.p2.5.m5.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS2.SSS3.p2.5.m5.1.2.3.2.2" xref="S4.SS2.SSS3.p2.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.5.m5.1b"><apply id="S4.SS2.SSS3.p2.5.m5.1.2.cmml" xref="S4.SS2.SSS3.p2.5.m5.1.2"><times id="S4.SS2.SSS3.p2.5.m5.1.2.1.cmml" xref="S4.SS2.SSS3.p2.5.m5.1.2.1"></times><ci id="S4.SS2.SSS3.p2.5.m5.1.2.2.cmml" xref="S4.SS2.SSS3.p2.5.m5.1.2.2">𝑃</ci><ci id="S4.SS2.SSS3.p2.5.m5.1.1.cmml" xref="S4.SS2.SSS3.p2.5.m5.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.5.m5.1c">P(x)</annotation></semantics></math> from the known information of <math id="S4.SS2.SSS3.p2.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.SSS3.p2.6.m6.1a"><mi id="S4.SS2.SSS3.p2.6.m6.1.1" xref="S4.SS2.SSS3.p2.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.6.m6.1b"><ci id="S4.SS2.SSS3.p2.6.m6.1.1.cmml" xref="S4.SS2.SSS3.p2.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.6.m6.1c">t</annotation></semantics></math> points according to the Lagrange interpolation method, thereby restoring the secret. The role of the Shamir scheme in federated learning has been discovered by some researchers, such as the SecAgg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib193" title="" class="ltx_ref">193</a>]</cite> and SecAgg+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib194" title="" class="ltx_ref">194</a>]</cite> schemes. The SAFELearn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite> scheme and others extend SS to a multi-server situation. FedShare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib196" title="" class="ltx_ref">196</a>]</cite>, while applying multi-server SS, also optimizes for utility loss and communication costs.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Model Tracing</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In contrast to the methods previously introduced, the methods discussed in this section primarily serve the function of post-hoc tracing. That is, once an attack has been detected, these methods allow for the identification and verification of the source of the attack. While these methods cannot prevent an attack from occurring in advance, they can obtain evidence after the fact, providing administrators or users of the federated learning system with an advantage at the level of rules or law.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS1.5.1.1" class="ltx_text">IV-C</span>1 </span>Digital watermarking</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Digital watermarking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib197" title="" class="ltx_ref">197</a>]</cite> is a technique that uses algorithms to add identifiable symbols to target data without affecting the usability of the original information, effectively tracing the source of the data. In the context of federated learning, digital watermarks can be added to the transmitted model information. Even if the information is stolen or leaked, the digital watermark can be used to track or forensically investigate this violation. Some work has already combined digital watermarking technology in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib198" title="" class="ltx_ref">198</a>]</cite>, and corresponding improvements have been proposed for issues such as compression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib199" title="" class="ltx_ref">199</a>]</cite> or robustness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib200" title="" class="ltx_ref">200</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS2.5.1.1" class="ltx_text">IV-C</span>2 </span>Blockchains</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite> is a distributed ledger that uses cryptography to provide security guarantees, offering immutable information recording capabilities in insecure environments, initially proposed in Bitcoin . Due to its strong security and traceability, blockchain has been extensively applied in areas such as cryptocurrencies and Non-Fungible Tokens (NFTs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib202" title="" class="ltx_ref">202</a>]</cite>. An important derivative application of blockchain is smart contracts, initially proposed by Ethereum. Smart contracts allow the inclusion of code that can be automatically triggered for execution in the blockchain, and the execution of this code is recorded and verified by the blockchain. In the context of federated learning, the role of blockchain is particularly evident due to the following functionalities:</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<ul id="S4.I4" class="ltx_itemize">
<li id="S4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i1.p1" class="ltx_para">
<p id="S4.I4.i1.p1.1" class="ltx_p"><span id="S4.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Malicious Client Identification.</span> Blockchain can record the information uploaded by each client, and this information is immutable, which can be used for evidence collection after an attack is discovered.</p>
</div>
</li>
<li id="S4.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i2.p1" class="ltx_para">
<p id="S4.I4.i2.p1.1" class="ltx_p"><span id="S4.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Supervision on Server.</span> Blockchain can also supervise the behavior of servers in scenarios where clients do not trust the servers, checking whether each aggregation behavior is malicious and constitutes an attack.</p>
</div>
</li>
<li id="S4.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i3.p1" class="ltx_para">
<p id="S4.I4.i3.p1.1" class="ltx_p"><span id="S4.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">Incentive Mechanism.</span> Blockchain can incentivize clients based on the quality of the model they upload, in the form of blockchain cryptocurrencies, which can prevent free-riding attacks, motivate clients to collect better data for training, and ensure a certain level of fairness.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p">Several researchers have proposed numerous federated learning frameworks that incorporate blockchain. Among them, CREAT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib203" title="" class="ltx_ref">203</a>]</cite> uses smart contracts on the blockchain to verify the reliability of model information uploaded by clients. Toyoda and Zhang <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib204" title="" class="ltx_ref">204</a>]</cite> proposed a blockchain federated learning algorithm with an incentive mechanism, which scores each client through a voting scheme to achieve competition among clients. BFLC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, based on blockchain, implements a decentralized federated learning committee mechanism that can be used to resist malicious attacks. Beyond theoretical research, open-source frameworks like VeryFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite> are advancing this field from a practical perspective.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Future Research Directions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">With the rapid development of big data and artificial intelligence technologies, people are paying increasing attention to privacy data containing a large amount of potential value. As a distributed machine learning paradigm that protects privacy, FL is gradually becoming an important tool for processing distributed data. In heterogeneous scenarios, FL faces multiple challenges, including data heterogeneity, model heterogeneity, task heterogeneity, communication heterogeneity, device heterogeneity, and privacy protection defects. Despite the existence of the above-mentioned research methods, there are still some challenges that have not been resolved. In the following, we will summarize some potential research directions as follows:</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Heterogeneity</span>: (1) Data Distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite>: Data heterogeneity is one of the main issues faced by FL in heterogeneous scenarios. Future research can start from the data itself, focusing on preprocessing data across clients and designing more intelligent data selection and filtering mechanisms to improve data quality and model training efficiency. At the same time, we can consider data generalization theory to build a bridge between the source domain and the target domain, thus alleviating the problem of data heterogeneity.
(2) Models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>: Model heterogeneity often leads to differences in model structure, parameter scale, and so on. Future research can focus on model integration and fusion techniques, unifying the semantic information of models to ensure that multiple models with different structures have the same semantic branches, supporting low-loss splicing and fusion of models with different structures. Additionally, for model heterogeneity issues, we can explore optimization techniques such as adaptive training adjustments and model pruning to improve the training efficiency and performance of the model.
(3) Tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite>: Future research can focus on the analysis and utilization of task relevance, improving the generalization ability of the model by exploring the inherent connections between tasks. Furthermore, we can explore dynamic adjustment and adaptation techniques for model tasks to meet the needs of different tasks and improve the adaptability of the model.
(4) Communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib208" title="" class="ltx_ref">208</a>]</cite>: Federated learning relies on the robustness of communication. Studying adaptive network topologies can help mitigate the impact of communication heterogeneity on the central server and improve the overall performance of FL. Additionally, we can focus on the design of fault-tolerant mechanisms for FL to mitigate the negative impact of clients being offline on the overall system. Strategies such as optimizing data transmission formats, reducing communication rounds, and designing efficient communication scheduling strategies are also viable solutions.
(5) Devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>: Device heterogeneity is mainly reflected in differences in the types of devices participating in FL, computing capabilities, storage capacity, and other aspects. Studying the partitioning and distribution strategies of model parameters and techniques such as model compression and quantization will be feasible solutions to address device heterogeneity issues.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Federated Fairness</span>: In heterogeneous scenarios, differences in data distribution, computing resources, and other factors among different participants may lead to fairness issues in the FL process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib209" title="" class="ltx_ref">209</a>]</cite>. Future research can focus on improving the fairness of FL algorithms to ensure that different participants have fair opportunities and benefits during model training. Additionally, we can establish fairness evaluation indicators and mechanisms to quantitatively evaluate and optimize the fairness of FL algorithms.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Secure and Trustworthy Strategies</span>: Security and trustworthiness are important prerequisites for the widespread application of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib210" title="" class="ltx_ref">210</a>]</cite>. Future research can focus on the design and implementation of secure and trustworthy strategies, including participant identity verification, communication encryption, and model update verification. Additionally, we can explore secure and trustworthy solutions based on advanced cryptography techniques such as zero-knowledge proofs and homomorphic encryption to improve the overall security performance of FL.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold">Incentive Mechanisms</span>: In heterogeneous scenarios, due to differences in the interests and contributions of different participants, it is necessary to design reasonable incentive mechanisms to promote their active participation and cooperation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib211" title="" class="ltx_ref">211</a>]</cite>. Future research can focus on the design and optimization of incentive mechanisms, including reward allocation strategies and contribution evaluation methods. Additionally, we can explore incentive mechanism designs based on methods such as game theory and auction theory to achieve more fair and effective resource allocation and interest coordination.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p"><span id="S5.p6.1.1" class="ltx_text ltx_font_bold">Transfer Learning</span>: Transfer learning can transfer knowledge from one domain to another, thereby accelerating model training in new domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib212" title="" class="ltx_ref">212</a>]</cite>. In federated scenarios, data may be generated in real-time. Therefore, studying how to use FL to achieve cross-domain transfer learning has important practical significance for improving the adaptability and performance of FL.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">In conclusion, there are numerous potential research directions in FL, especially in heterogeneous scenarios. Future research should focus on addressing these challenges and exploring new techniques to improve the performance, efficiency, and fairness of FL.</p>
</div>
</section>
<section id="S6" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we provide insights into key concepts in the field of heterogeneous federated learning and the multiple challenges it faces. In particular, we analyze in detail the heterogeneity of data, models, tasks, communications, and devices, which pose numerous algorithmic challenges in federated learning systems. To address these challenges, in this paper, we systematically categorize existing research approaches by classifying them into data-level, model-level, and structure-level according to the processing hierarchy, each of which corresponds to a specific problem and solution strategy.
Our categorization approach provides a clear perspective for understanding the efficacy of various types of algorithms in coping with heterogeneous environments. With this hierarchical strategy, researchers and practitioners can more efficiently select methods that fit their specific needs.
Finally, this paper looks at future research directions in heterogeneous federated learning, which will undoubtedly continue to be a dynamic and challenging research direction in the field of machine learning as technology advances and application needs increase. We look forward to more innovative research results in this field in the future to promote the development of technology and popularization of applications.</p>
</div>
</section>
<section id="Sx1" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The research is supported by the National Key Research and Development Program of China (2023YFB2703700), the National Natural Science Foundation of China (62176269), the Guangzhou Science and Technology Program (2023A04J0314), the National Natural Science Foundation of China and Guangdong Provincial Joint Fund (No. U1911202).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Q. Li, Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He, “A survey on
federated learning systems: Vision, hype and reality for data privacy and
protection,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>,
vol. 35, no. 4, pp. 3347–3366, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
R. S. Antunes, C. André da Costa, A. Küderle, I. A. Yari, and
B. Eskofier, “Federated learning for healthcare: Systematic review and
architecture proposal,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology (TIST)</em>, vol. 13, no. 4, pp. 1–23, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. Nevrataki, A. Iliadou, G. Ntolkeras, I. Sfakianakis, L. Lazaridis,
G. Maraslidis, N. Asimopoulos, and G. F. Fragulis, “A survey on federated
learning applications in healthcare, finance, and data privacy/data
security,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">AIP Conference Proceedings</em>, vol. 2909, no. 1.   AIP Publishing, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and H. V. Poor,
“Federated learning for internet of things: A comprehensive survey,”
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, vol. 23, no. 3, pp.
1622–1658, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Z. Zheng, Y. Zhou, Y. Sun, Z. Wang, B. Liu, and K. Li, “Applications of
federated learning in smart cities: recent advances, taxonomy, and open
challenges,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Connection Science</em>, vol. 34, no. 1, pp. 1–28, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
H. Wang, Z. Kaplan, D. Niu, and B. Li, “Optimizing federated learning on
non-iid data with reinforcement learning,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2020-IEEE
conference on computer communications</em>.   IEEE, 2020, pp. 1698–1707.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
D. Li and J. Wang, “Fedmd: Heterogenous federated learning via model
distillation,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.03581</em>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated multi-task
learning,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
vol. 30, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
M. S. H. Abad, E. Ozfatura, D. Gunduz, and O. Ercetin, “Hierarchical federated
learning across heterogeneous cellular networks,” in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020
IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>.   IEEE, 2020, pp. 8866–8870.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. Pfeiffer, M. Rapp, R. Khalili, and J. Henkel, “Federated learning for
computationally constrained heterogeneous devices: A survey,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">ACM
Computing Surveys</em>, vol. 55, no. 14s, pp. 1–27, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, vol. 32, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller, “Inverting
gradients-how easy is it to break privacy in federated learning?”
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol. 33, pp.
16 937–16 947, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and
privacy (SP)</em>.   IEEE, 2019, pp.
739–753.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, X. Ma, C. Chen, L. Sun, J. Zhao, Q. Yang, and S. Y. Philip,
“Privacy and robustness in federated learning: Attacks and defenses,”
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on neural networks and learning systems</em>, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Ye, X. Fang, B. Du, P. C. Yuen, and D. Tao, “Heterogeneous federated
learning: State-of-the-art and research challenges,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ACM Computing
Surveys</em>, vol. 56, no. 3, pp. 1–44, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Wen, Z. Zhang, Y. Lan, Z. Cui, J. Cai, and W. Zhang, “A survey on federated
learning: challenges and applications,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Journal of
Machine Learning and Cybernetics</em>, vol. 14, no. 2, pp. 513–535, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated
learning,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Ji, Y. Tan, T. Saravirta, Z. Yang, Y. Liu, L. Vasankari, S. Pan, G. Long,
and A. Walid, “Emerging trends in federated learning: From model fusion to
federated x learning,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">International Journal of Machine Learning and
Cybernetics</em>, pp. 1–22, 2024.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D. Gao, X. Yao, and Q. Yang, “A survey on heterogeneous federated learning,”
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.04505</em>, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
T. M. Mengistu, T. Kim, and J.-W. Lin, “A survey on heterogeneity taxonomy,
security and privacy preservation in the integration of iot, wireless sensor
networks and federated learning,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 24, no. 3, p. 968,
2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
B. S. Guendouzi, S. Ouchani, H. E. Assaad, and M. E. Zaher, “A systematic
review of federated learning: Challenges, aggregation methods, and
development tools,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Journal of Network and Computer Applications</em>, p.
103714, 2023.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Z. Lu, H. Pan, Y. Dai, X. Si, and Y. Zhang, “Federated learning with non-iid
data: A survey,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 2024.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology (TIST)</em>, vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J. Zhang, S. Guo, Z. Qu, D. Zeng, Y. Zhan, Q. Liu, and R. Akerkar, “Adaptive
federated learning on non-iid data with resource constraint,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Computers</em>, vol. 71, no. 7, pp. 1655–1667, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
L. Zhang, L. Shen, L. Ding, D. Tao, and L.-Y. Duan, “Fine-tuning global model
via data-free knowledge distillation for non-iid federated learning,” in
<em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition</em>, 2022, pp. 10 174–10 183.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
L. Gao, H. Fu, L. Li, Y. Chen, M. Xu, and C.-Z. Xu, “Feddc: Federated learning
with non-iid data via local drift decoupling and correction,” in
<em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition</em>, 2022, pp. 10 112–10 121.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
X. Ma, J. Zhu, Z. Lin, S. Chen, and Y. Qin, “A state-of-the-art survey on
solving non-iid data in federated learning,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Future Generation
Computer Systems</em>, vol. 135, pp. 244–258, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Z. Wang, Y. Zhu, D. Wang, and Z. Han, “Fedacs: Federated skewness analytics in
heterogeneous decentralized data environments,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/ACM 29th
International Symposium on Quality of Service (IWQOS)</em>.   IEEE, 2021, pp. 1–10.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
J. Zhang, Z. Li, B. Li, J. Xu, S. Wu, S. Ding, and C. Wu, “Federated learning
with label distribution skew via logits calibration,” in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning</em>.   PMLR,
2022, pp. 26 311–26 329.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
X.-C. Li and D.-C. Zhan, “Fedrs: Federated learning with restricted softmax
for label distribution non-iid data,” in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM
SIGKDD Conference on Knowledge Discovery &amp; Data Mining</em>, 2021, pp.
995–1005.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Z. Luo, Y. Wang, Z. Wang, Z. Sun, and T. Tan, “Disentangled federated learning
for tackling attributes skew via invariant aggregation and diversity
transferring,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.06818</em>, 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
T. Zhou, J. Zhang, and D. H. Tsang, “Fedfa: Federated learning with feature
anchors to align features and classifiers for heterogeneous data,”
<em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
T. Chen, X. Jin, Y. Sun, and W. Yin, “Vafl: a method of vertical asynchronous
federated learning,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.06081</em>, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, C. Ma, M. Ding, S. Wei, F. Wu, G. Chen, and T. Ranbaduge,
“Vertical federated learning: Challenges, methodologies and experiments,”
<em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.04309</em>, 2022.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
S. Yang, H. Park, J. Byun, and C. Kim, “Robust federated learning with noisy
labels,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, vol. 37, no. 2, pp. 35–43, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
J. Xu, Z. Chen, T. Q. Quek, and K. F. E. Chong, “Fedcorr: Multi-stage
federated learning for label noise correction,” in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition</em>, 2022, pp.
10 184–10 193.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
X. Fang and M. Ye, “Robust federated learning with noisy and heterogeneous
clients,” in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, 2022, pp. 10 072–10 081.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
L. Wang, J. Bian, and J. Xu, “Federated learning with instance-dependent noisy
label,” in <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ICASSP 2024-2024 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2024, pp. 8916–8920.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Z. Chai, A. Ali, S. Zawad, S. Truex, A. Anwar, N. Baracaldo, Y. Zhou,
H. Ludwig, F. Yan, and Y. Cheng, “Tifl: A tier-based federated learning
system,” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th international symposium on
high-performance parallel and distributed computing</em>, 2020, pp. 125–136.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Q. Li, Y. Diao, Q. Chen, and B. He, “Federated learning on non-iid data silos:
An experimental study,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">2022 IEEE 38th international conference on
data engineering (ICDE)</em>.   IEEE, 2022,
pp. 965–978.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
L. Qu, N. Balachandar, and D. L. Rubin, “An experimental study of data
heterogeneity in federated learning methods for medical imaging,”
<em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.08371</em>, 2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,
“Federated optimization in heterogeneous networks,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of
Machine learning and systems</em>, vol. 2, pp. 429–450, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
S. Alam, L. Liu, M. Yan, and M. Zhang, “Fedrolex: Model-heterogeneous
federated learning with rolling sub-model extraction,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, vol. 35, pp. 29 677–29 690, 2022.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
L. Yi, G. Wang, X. Liu, Z. Shi, and H. Yu, “Fedgh: Heterogeneous federated
learning with generalized global header,” in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st
ACM International Conference on Multimedia</em>, 2023, pp. 8686–8696.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
T. Castiglia, S. Wang, and S. Patterson, “Flexible vertical federated learning
with heterogeneous parties,” <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and
Learning Systems</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
A. M. Abdelmoniem, C.-Y. Ho, P. Papageorgiou, and M. Canini, “A comprehensive
empirical study of heterogeneity in federated learning,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IEEE Internet
of Things Journal</em>, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
L. Yao, D. Gao, Z. Wang, Y. Xie, W. Kuang, D. Chen, H. Wang, C. Dong, B. Ding,
and Y. Li, “A benchmark for federated hetero-task learning,” <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2206.03436</em>, 2022.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Y. SarcheshmehPour, Y. Tian, L. Zhang, and A. Jung, “Networked federated
multi-task learning,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Authorea Preprints</em>, 2023.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Z. Zhu, J. Hong, S. Drew, and J. Zhou, “Resilient and communication efficient
learning for heterogeneous federated systems,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of machine
learning research</em>, vol. 162, p. 27504, 2022.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
E. Diao, J. Ding, and V. Tarokh, “Heterofl: Computation and communication
efficient federated learning for heterogeneous clients,” <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2010.01264</em>, 2020.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
A. A. Abdellatif, N. Mhaisen, A. Mohamed, A. Erbad, M. Guizani, Z. Dawy, and
W. Nasreddine, “Communication-efficient hierarchical federated learning for
iot heterogeneous systems with imbalanced data,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Future Generation
Computer Systems</em>, vol. 128, pp. 406–419, 2022.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with
heterogeneous resources in mobile edge,” in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">ICC 2019-2019 IEEE
international conference on communications (ICC)</em>.   IEEE, 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
L. Li, D. Shi, R. Hou, H. Li, M. Pan, and Z. Han, “To talk or to work:
Flexible communication compression for energy efficient federated learning
over heterogeneous mobile edge devices,” in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2021-IEEE
Conference on Computer Communications</em>.   IEEE, 2021, pp. 1–10.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
S. Wang, M. Lee, S. Hosseinalipour, R. Morabito, M. Chiang, and C. G. Brinton,
“Device sampling for heterogeneous federated learning: Theory, algorithms,
and implementation,” in <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2021-IEEE Conference on Computer
Communications</em>.   IEEE, 2021, pp.
1–10.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
X. Xu, S. Duan, J. Zhang, Y. Luo, and D. Zhang, “Optimizing federated learning
on device heterogeneity with a sampling strategy,” in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/ACM
29th International Symposium on Quality of Service (IWQOS)</em>.   IEEE, 2021, pp. 1–10.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
A. Li, L. Zhang, J. Tan, Y. Qin, J. Wang, and X.-Y. Li, “Sample-level data
selection for federated learning,” in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2021-IEEE
Conference on Computer Communications</em>.   IEEE, 2021, pp. 1–10.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
L. Ma, Q. Pei, L. Zhou, H. Zhu, L. Wang, and Y. Ji, “Federated data cleaning:
Collaborative and privacy-preserving data cleaning for edge intelligence,”
<em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 8, no. 8, pp. 6757–6770, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
L. Chen, F. Ang, Y. Chen, and W. Wang, “Robust federated learning with noisy
labeled data through loss function correction,” <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Network Science and Engineering</em>, vol. 10, no. 3, pp. 1501–1511, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
S. Duan, C. Liu, Z. Cao, X. Jin, and P. Han, “Fed-dr-filter: Using global data
representation to reduce the impact of noisy labels on the performance of
federated learning,” <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 137,
pp. 336–348, 2022.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
V. Tsouvalas, A. Saeed, T. Ozcelebi, and N. Meratnia, “Labeling chaos to
learning harmony: Federated learning with noisy labels,” <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">ACM
Transactions on Intelligent Systems and Technology</em>, vol. 15, no. 2, pp.
1–26, 2024.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
J. Li, G. Li, H. Cheng, Z. Liao, and Y. Yu, “Feddiv: Collaborative noise
filtering for federated learning with noisy labels,” in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the AAAI Conference on Artificial Intelligence</em>, vol. 38, no. 4, 2024, pp.
3118–3126.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
X. Xu, H. Li, Z. Li, and X. Zhou, “Safe: Synergic data filtering for federated
learning in cloud-edge computing,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial
Informatics</em>, vol. 19, no. 2, pp. 1655–1665, 2022.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
W. Hao, M. El-Khamy, J. Lee, J. Zhang, K. J. Liang, C. Chen, and L. C. Duke,
“Towards fair federated learning with zero-shot data augmentation,” in
<em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition</em>, 2021, pp. 3310–3319.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
H. Chen, A. Frikha, D. Krompass, J. Gu, and V. Tresp, “Fraug: Tackling
federated learning with non-iid features via representation augmentation,”
in <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer
Vision</em>, 2023, pp. 4849–4859.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
D. Lewy, J. Mańdziuk, M. Ganzha, and M. Paprzycki, “Statmix: Data
augmentation method that relies on image statistics in federated learning,”
in <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">International Conference on Neural Information Processing</em>.   Springer, 2022, pp. 574–585.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
B. Xin, W. Yang, Y. Geng, S. Chen, S. Wang, and L. Huang, “Private fl-gan:
Differential privacy synthetic data generation based on federated learning,”
in <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP)</em>.   IEEE,
2020, pp. 2927–2931.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
X. Zhang, J. M. Parra-Ullauri, S. Moazzeni, X. Vasilakos, R. Nejabati, and
D. Simeonidou, “Federated analytics with data augmentation in domain
generalization towards future networks,” <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Machine
Learning in Communications and Networking</em>, 2024.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
J. Zhang and Y. Jiang, “A data augmentation method for vertical federated
learning,” <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Wireless Communications and Mobile Computing</em>, vol. 2022,
pp. 1–16, 2022.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Y. Xiao, X. Li, T. Li, R. Wang, Y. Pang, and G. Wang, “A distributed
generative adversarial network for data augmentation under vertical federated
learning,” <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>, 2024.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang, “A secure federated transfer
learning framework,” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, vol. 35, no. 4, pp.
70–82, 2020.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
A. Li, J. Sun, X. Zeng, M. Zhang, H. Li, and Y. Chen, “Fedmask: Joint
computation and communication-efficient personalized federated learning via
heterogeneous masking,” in <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM Conference on
Embedded Networked Sensor Systems</em>, 2021, pp. 42–55.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
F. Zhang, K. Kuang, L. Chen, Z. You, T. Shen, J. Xiao, Y. Zhang, C. Wu, F. Wu,
Y. Zhuang <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated unsupervised representation learning,”
<em id="bib.bib73.2.2" class="ltx_emph ltx_font_italic">Frontiers of Information Technology &amp; Electronic Engineering</em>,
vol. 24, no. 8, pp. 1181–1193, 2023.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
B. van Berlo, A. Saeed, and T. Ozcelebi, “Towards federated unsupervised
representation learning,” in <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Proceedings of the third ACM
international workshop on edge systems, analytics and networking</em>, 2020, pp.
31–36.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Z. Wu, Q. Li, and B. He, “Practical vertical federated learning with
unsupervised representation learning,” <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>,
2022.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Q. Li, B. He, and D. Song, “Model-contrastive federated learning,” in
<em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition</em>, 2021, pp. 10 713–10 722.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
J. Jang, H. Ha, D. Jung, and S. Yoon, “Fedclassavg: Local representation
learning for personalized federated learning on heterogeneous neural
networks,” in <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 51st International Conference on
Parallel Processing</em>, 2022, pp. 1–10.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Y. Tan, G. Long, L. Liu, T. Zhou, Q. Lu, J. Jiang, and C. Zhang, “Fedproto:
Federated prototype learning across heterogeneous clients,” in
<em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
vol. 36, no. 8, 2022, pp. 8432–8440.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
M. G. Arivazhagan, V. Aggarwal, A. K. Singh, and S. Choudhary, “Federated
learning with personalization layers,” <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1912.00818</em>, 2019.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
L. Collins, H. Hassani, A. Mokhtari, and S. Shakkottai, “Exploiting shared
representations for personalized federated learning,” in <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">International
conference on machine learning</em>.   PMLR,
2021, pp. 2089–2099.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
M. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, and J. Feng, “No fear of
heterogeneity: Classifier calibration for federated learning with non-iid
data,” <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 34,
pp. 5972–5984, 2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
X. Shang, Y. Lu, G. Huang, and H. Wang, “Federated learning on heterogeneous
and long-tailed data via classifier re-training with federated features,”
<em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.13399</em>, 2022.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
P. P. Liang, T. Liu, L. Ziyin, N. B. Allen, R. P. Auerbach, D. Brent,
R. Salakhutdinov, and L.-P. Morency, “Think locally, act globally: Federated
learning with local and global representations,” <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2001.01523</em>, 2020.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
J. Xu, X. Tong, and S.-L. Huang, “Personalized federated learning with feature
alignment and classifier collaboration,” <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2306.11867</em>, 2023.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Y. Shen, Y. Zhou, and L. Yu, “Cd2-pfed: Cyclic distillation-guided channel
decoupling for model personalization in federated learning,” in
<em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition</em>, 2022, pp. 10 041–10 050.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
J. Chen, J. Zhu, Q. Zheng, Z. Li, and Z. Tian, “Watch your head: Assembling
projection heads to save the reliability of federated models,” <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2402.16255</em>, 2024.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
K. Pillutla, K. Malik, A.-R. Mohamed, M. Rabbat, M. Sanjabi, and L. Xiao,
“Federated learning with partial model personalization,” in
<em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2022, pp. 17 716–17 758.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
J. Wang, X. Yang, S. Cui, L. Che, L. Lyu, D. D. Xu, and F. Ma, “Towards
personalized federated learning via heterogeneous model reassembly,”
<em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
K. Yi, N. Gazagnadou, P. Richtárik, and L. Lyu, “Fedp3: Federated
personalized and privacy-friendly network pruning under model
heterogeneity,” <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.09816</em>, 2024.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
K. Pfeiffer, R. Khalili, and J. Henkel, “Aggregating capacity in fl through
successive layer training for computationally-constrained devices,”
<em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar, “signsgd:
Compressed optimisation for non-convex problems,” in <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning</em>.   PMLR,
2018, pp. 560–569.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek, “Robust and
communication-efficient federated learning from non-iid data,” <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">IEEE
transactions on neural networks and learning systems</em>, vol. 31, no. 9, pp.
3400–3413, 2019.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
M. M. Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, “Federated learning
with quantized global model updates,” <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2006.10672</em>, 2020.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
S. M. Shah and V. K. Lau, “Model compression for communication efficient
federated learning,” <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning
Systems</em>, vol. 34, no. 9, pp. 5937–5951, 2021.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Z. Tang, Y. Wang, and T.-H. Chang, “z-signfedavg: A unified stochastic
sign-based compression for federated learning,” in <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, vol. 38, no. 14, 2024, pp.
15 301–15 309.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
D. Yao, W. Pan, M. J. O’Neill, Y. Dai, Y. Wan, H. Jin, and L. Sun, “Fedhm:
Efficient federated learning for heterogeneous models via low-rank
factorization,” <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.14655</em>, 2021.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
W. Jeong and S. J. Hwang, “Factorized-fl: Personalized federated learning with
parameter factorization &amp; similarity matching,” <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, vol. 35, pp. 35 684–35 695, 2022.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Y. Chen, H. Vikalo, and C. Wang, “Fed-qssl: A framework for personalized
federated learning under bitwidth and data heterogeneity,” in
<em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
vol. 38, no. 10, 2024, pp. 11 443–11 452.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
network,” <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>, 2015.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
W. Huang, M. Ye, and B. Du, “Learn from others and be yourself in
heterogeneous federated learning,” in <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition</em>, 2022, pp.
10 143–10 153.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Z. Zhu, J. Hong, and J. Zhou, “Data-free knowledge distillation for
heterogeneous federated learning,” in <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">International conference on
machine learning</em>.   PMLR, 2021, pp.
12 878–12 889.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
Z. Chen, H. Yang, T. Quek, and K. F. E. Chong, “Spectral co-distillation for
personalized federated learning,” <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
L. Corinzia, A. Beuret, and J. M. Buhmann, “Variational federated multi-task
learning,” <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.06268</em>, 2019.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
R. Li, F. Ma, W. Jiang, and J. Gao, “Online federated multitask learning,” in
<em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International Conference on Big Data (Big Data)</em>.   IEEE, 2019, pp. 215–220.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
C. T. Dinh, T. T. Vu, N. H. Tran, M. N. Dao, and H. Zhang, “Fedu: A unified
framework for federated multi-task learning with laplacian regularization,”
<em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.07148</em>, vol. 400, 2021.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
O. Marfoq, G. Neglia, A. Bellet, L. Kameni, and R. Vidal, “Federated
multi-task learning under a mixture of distributions,” <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">Advances in
Neural Information Processing Systems</em>, vol. 34, pp. 15 434–15 447, 2021.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
F. Chen, M. Luo, Z. Dong, Z. Li, and X. He, “Federated meta-learning with fast
convergence and efficient communication,” <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1802.07876</em>, 2018.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
I. Jeon, M. Hong, J. Yun, and G. Kim, “Federated learning via meta-variational
dropout,” <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 36,
2024.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
R. Lee, M. Kim, D. Li, X. Qiu, T. Hospedales, F. Huszár, and N. Lane,
“Fedl2p: Federated learning to personalize,” <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
J. Scott, H. Zakerinia, and C. H. Lampert, “Pefll: Personalized federated
learning by learning to learn,” in <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">The Twelfth International
Conference on Learning Representations</em>, 2023.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
J. Kim, G. Kim, and B. Han, “Multi-level branched regularization for federated
learning,” in <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2022, pp. 11 058–11 073.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
N. Shoham, T. Avidor, A. Keren, N. Israel, D. Benditkis, L. Mor-Yosef, and
I. Zeitak, “Overcoming forgetting in federated learning on non-iid data,”
<em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.07796</em>, 2019.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
X. Yao and L. Sun, “Continual local training for better initialization of
federated models,” in <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Conference on Image
Processing (ICIP)</em>.   IEEE, 2020, pp.
1736–1740.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
C. T Dinh, N. Tran, and J. Nguyen, “Personalized federated learning with
moreau envelopes,” <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
vol. 33, pp. 21 394–21 405, 2020.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh,
“Scaffold: Stochastic controlled averaging for federated learning,” in
<em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2020, pp. 5132–5143.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
F. Hanzely and P. Richtárik, “Federated learning of a mixture of global
and local models,” <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.05516</em>, 2020.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
T. Li, S. Hu, A. Beirami, and V. Smith, “Ditto: Fair and robust federated
learning through personalization,” in <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">International conference on
machine learning</em>.   PMLR, 2021, pp.
6357–6368.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
X. Zhou and X. Wang, “Federated label-noise learning with local diversity
product regularization,” in <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, vol. 38, no. 15, 2024, pp. 17 141–17 149.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
M. Zhi, Y. Bi, W. Xu, H. Wang, and T. Xiang, “Knowledge-aware parameter
coaching for personalized federated learning,” in <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, vol. 38, no. 15, 2024, pp.
17 069–17 077.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
J. Li, A. Li, C. Tian, Q. Ho, E. Xing, and H. Wang, “Fednar: Federated
optimization with normalized annealing regularization,” <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">Advances in
Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
Y. Wang and B. Kantarci, “A novel reputation-aware client selection scheme for
federated learning within mobile environments,” in <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">2020 IEEE 25th
International Workshop on Computer Aided Modeling and Design of Communication
Links and Networks (CAMAD)</em>.   IEEE,
2020, pp. 1–6.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
T. Huang, W. Lin, L. Shen, K. Li, and A. Y. Zomaya, “Stochastic client
selection for federated learning with volatile clients,” <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">IEEE Internet
of Things Journal</em>, vol. 9, no. 20, pp. 20 055–20 070, 2022.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
N. Yoshida, T. Nishio, M. Morikura, K. Yamamoto, and R. Yonetani, “Hybrid-fl
for wireless networks: Cooperative learning mechanism using non-iid data,”
in <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference On Communications
(ICC)</em>.   IEEE, 2020, pp. 1–7.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
J. Xu and H. Wang, “Client selection and bandwidth allocation in wireless
federated learning networks: A long-term perspective,” <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, vol. 20, no. 2, pp. 1188–1200,
2020.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
F. Lai, X. Zhu, H. V. Madhyastha, and M. Chowdhury, “Oort: Efficient federated
learning via guided participant selection,” in <em id="bib.bib125.4.4" class="ltx_emph ltx_font_italic">15th <math id="bib.bib125.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib125.1.1.m1.1a"><mo stretchy="false" id="bib.bib125.1.1.m1.1.1" xref="bib.bib125.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.1.1.m1.1b"><ci id="bib.bib125.1.1.m1.1.1.cmml" xref="bib.bib125.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib125.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib125.2.2.m2.1a"><mo stretchy="false" id="bib.bib125.2.2.m2.1.1" xref="bib.bib125.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.2.2.m2.1b"><ci id="bib.bib125.2.2.m2.1.1.cmml" xref="bib.bib125.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.2.2.m2.1c">\}</annotation></semantics></math>
Symposium on Operating Systems Design and Implementation (<math id="bib.bib125.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib125.3.3.m3.1a"><mo stretchy="false" id="bib.bib125.3.3.m3.1.1" xref="bib.bib125.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.3.3.m3.1b"><ci id="bib.bib125.3.3.m3.1.1.cmml" xref="bib.bib125.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.3.3.m3.1c">\{</annotation></semantics></math>OSDI<math id="bib.bib125.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib125.4.4.m4.1a"><mo stretchy="false" id="bib.bib125.4.4.m4.1.1" xref="bib.bib125.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.4.4.m4.1b"><ci id="bib.bib125.4.4.m4.1.1.cmml" xref="bib.bib125.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.4.4.m4.1c">\}</annotation></semantics></math> 21)</em>,
2021, pp. 19–35.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
H. Wu and P. Wang, “Node selection toward faster convergence for federated
learning on non-iid data,” <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and
Engineering</em>, vol. 9, no. 5, pp. 3099–3111, 2022.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
Y. J. Cho, J. Wang, and G. Joshi, “Towards understanding biased client
selection in federated learning,” in <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">International Conference on
Artificial Intelligence and Statistics</em>.   PMLR, 2022, pp. 10 351–10 375.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
C. Li, X. Zeng, M. Zhang, and Z. Cao, “Pyramidfl: A fine-grained client
selection framework for efficient federated learning,” in <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 28th Annual International Conference on Mobile Computing And
Networking</em>, 2022, pp. 158–171.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
M. Ribero, H. Vikalo, and G. De Veciana, “Federated learning under
intermittent client availability and time-varying communication
constraints,” <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</em>,
vol. 17, no. 1, pp. 98–111, 2022.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
F. Sattler, K.-R. Müller, and W. Samek, “Clustered federated learning:
Model-agnostic distributed multitask optimization under privacy
constraints,” <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Llearning
Systems</em>, vol. 32, no. 8, pp. 3710–3722, 2020.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
A. Ghosh, J. Chung, D. Yin, and K. Ramchandran, “An efficient framework for
clustered federated learning,” <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information
Theory</em>, vol. 68, no. 12, pp. 8076–8091, 2022.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
S. Vahidian, M. Morafah, W. Wang, V. Kungurtsev, C. Chen, M. Shah, and B. Lin,
“Efficient distribution similarity identification in clustered federated
learning via principal angles between client data subspaces,” in
<em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2023,
pp. 10 043–10 052.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
Y. Ruan and C. Joe-Wong, “Fedsoft: Soft clustered federated learning with
proximal local updating,” in <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on
artificial intelligence</em>, vol. 36, no. 7, 2022, pp. 8124–8131.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
R. Lu, W. Zhang, Y. Wang, Q. Li, X. Zhong, H. Yang, and D. Wang,
“Auction-based cluster federated learning in mobile edge computing
systems,” <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>,
vol. 34, no. 4, pp. 1145–1158, 2023.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
L. Liu, J. Zhang, S. Song, and K. B. Letaief, “Client-edge-cloud hierarchical
federated learning,” in <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE international conference on
communications (ICC)</em>.   IEEE, 2020, pp.
1–6.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
C. Briggs, Z. Fan, and P. Andras, “Federated learning with hierarchical
clustering of local updates to improve training on non-iid data,” in
<em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">2020 International Joint Conference on Neural Networks (IJCNN)</em>.   IEEE, 2020, pp. 1–9.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
B. Xu, W. Xia, W. Wen, P. Liu, H. Zhao, and H. Zhu, “Adaptive hierarchical
federated learning over wireless networks,” <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Vehicular Technology</em>, vol. 71, no. 2, pp. 2070–2083, 2021.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, J. S. Ng, Z. Xiong, D. Niyato, C. Miao, and D. I. Kim, “Dynamic
edge association and resource allocation in self-organizing hierarchical
federated learning networks,” <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in
Communications</em>, vol. 39, no. 12, pp. 3640–3653, 2021.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
X. Zhou, X. Ye, I. Kevin, K. Wang, W. Liang, N. K. C. Nair, S. Shimizu, Z. Yan,
and Q. Jin, “Hierarchical federated learning with social context
clustering-based participant selection for internet of medical things
applications,” <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Computational Social Systems</em>,
2023.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
Q. Ma, Y. Xu, H. Xu, J. Liu, and L. Huang, “Feduc: A unified clustering
approach for hierarchical federated learning,” <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Mobile Computing</em>, 2024.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
Y. Deng, F. Lyu, T. Xia, Y. Zhou, Y. Zhang, J. Ren, and Y. Yang, “A
communication-efficient hierarchical federated learning framework via shaping
data distribution at edge,” <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Networking</em>,
2024.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
Y. Li, C. Chen, N. Liu, H. Huang, Z. Zheng, and Q. Yan, “A blockchain-based
decentralized federated learning framework with committee consensus,”
<em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 35, no. 1, pp. 234–241, 2020.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
C. Che, X. Li, C. Chen, X. He, and Z. Zheng, “A decentralized federated
learning framework via committee mechanism with convergence guarantee,”
<em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>, vol. 33,
no. 12, pp. 4783–4800, 2022.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, J. S. Ng, Z. Xiong, J. Jin, Y. Zhang, D. Niyato, C. Leung, and
C. Miao, “Decentralized edge intelligence: A dynamic resource allocation
framework for hierarchical federated learning,” <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Parallel and Distributed Systems</em>, vol. 33, no. 3, pp. 536–550, 2021.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
H. Ye, L. Liang, and G. Y. Li, “Decentralized federated learning with
unreliable communications,” <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">IEEE journal of selected topics in signal
processing</em>, vol. 16, no. 3, pp. 487–500, 2022.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
C. Pappas, D. Chatzopoulos, S. Lalis, and M. Vavalis, “Ipls: A framework for
decentralized federated learning,” in <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">2021 IFIP Networking Conference
(IFIP Networking)</em>.   IEEE, 2021, pp.
1–6.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
W. Liu, L. Chen, and W. Zhang, “Decentralized federated learning: Balancing
communication and computing costs,” <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal and
Information Processing over Networks</em>, vol. 8, pp. 131–143, 2022.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
S. Kalra, J. Wen, J. C. Cresswell, M. Volkovs, and H. R. Tizhoosh,
“Decentralized federated learning through proxy model sharing,”
<em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">Nature communications</em>, vol. 14, no. 1, p. 2899, 2023.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
I. Hegedűs, G. Danner, and M. Jelasity, “Decentralized learning works:
An empirical comparison of gossip learning and federated learning,”
<em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Journal of Parallel and Distributed Computing</em>, vol. 148, pp. 109–124,
2021.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
Y. Qu, H. Dai, Y. Zhuang, J. Chen, C. Dong, F. Wu, and S. Guo, “Decentralized
federated learning for uav networks: Architecture, challenges, and
opportunities,” <em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 35, no. 6, pp. 156–162, 2021.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
E. T. M. Beltrán, Á. L. P. Gómez, C. Feng, P. M. S. Sánchez,
S. L. Bernal, G. Bovet, M. G. Pérez, G. M. Pérez, and A. H.
Celdrán, “Fedstellar: A platform for decentralized federated learning,”
<em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>, vol. 242, p. 122861, 2024.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
Y. Zhou, M. Shi, Y. Tian, Q. Ye, and J. Lv, “Defta: A plug-and-play
peer-to-peer decentralized federated learning framework,” <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">Information
Sciences</em>, p. 120582, 2024.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
P.-C. Cheng, K. Eykholt, Z. Gu, H. Jamjoom, K. Jayaram, E. Valdez, and
A. Verma, “Deta: Minimizing data leaks in federated learning via
decentralized and trustworthy aggregation,” in <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Nineteenth European Conference on Computer Systems</em>, 2024, pp. 219–235.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras, and
T. Goldstein, “Poison frogs! targeted clean-label poisoning attacks on
neural networks,” <em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
vol. 31, 2018.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
L. Su and J. Xu, “Securing distributed gradient descent in high dimensional
statistical learning,” <em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Measurement and
Analysis of Computing Systems</em>, vol. 3, no. 1, pp. 1–41, 2019.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, “Exploiting unintended
feature leakage in collaborative learning,” in <em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on
security and privacy (SP)</em>.   IEEE,
2019, pp. 691–706.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
X. Yin, Y. Zhu, and J. Hu, “A comprehensive survey of privacy-preserving
federated learning: A taxonomy, review, and future directions,” <em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">ACM
Computing Surveys (CSUR)</em>, vol. 54, no. 6, pp. 1–36, 2021.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
G. Xia, J. Chen, C. Yu, and J. Ma, “Poisoning attacks in federated learning: A
survey,” <em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 11, pp. 10 708–10 722, 2023.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
X. Zhang, Y. Kang, K. Chen, L. Fan, and Q. Yang, “Trading off privacy,
utility, and efficiency in federated learning,” <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on
Intelligent Systems and Technology</em>, vol. 14, no. 6, pp. 1–32, 2023.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
Y. Li, T. Wang, C. Chen, J. Lou, B. Chen, L. Yang, and Z. Zheng, “Clients
collaborate: Flexible differentially private federated learning with
guaranteed improvement of utility-privacy trade-off,” <em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2402.07002</em>, 2024.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
C. Dwork, “Differential privacy,” in <em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">International colloquium on
automata, languages, and programming</em>.   Springer, 2006, pp. 1–12.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
C. Dwork, A. Roth <em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “The algorithmic foundations of differential
privacy,” <em id="bib.bib162.2.2" class="ltx_emph ltx_font_italic">Foundations and Trends® in Theoretical
Computer Science</em>, vol. 9, no. 3–4, pp. 211–407, 2014.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang, “Deep learning with differential privacy,” in <em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2016 ACM SIGSAC conference on computer and communications security</em>,
2016, pp. 308–318.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang, “Learning differentially
private recurrent language models,” <em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.06963</em>,
2017.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin, T. Q. Quek, and
H. V. Poor, “Federated learning with differential privacy: Algorithms and
performance analysis,” <em id="bib.bib165.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on information forensics and
security</em>, vol. 15, pp. 3454–3469, 2020.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
M. Seif, R. Tandon, and M. Li, “Wireless federated learning with local
differential privacy,” in <em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Symposium on
Information Theory (ISIT)</em>.   IEEE,
2020, pp. 2604–2609.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
A. Girgis, D. Data, S. Diggavi, P. Kairouz, and A. T. Suresh, “Shuffled model
of differential privacy in federated learning,” in <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">International
Conference on Artificial Intelligence and Statistics</em>.   PMLR, 2021, pp. 2521–2529.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
W. Wei, L. Liu, Y. Wu, G. Su, and A. Iyengar, “Gradient-leakage resilient
federated learning,” in <em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">2021 IEEE 41st International Conference on
Distributed Computing Systems (ICDCS)</em>.   IEEE, 2021, pp. 797–807.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
I. Mironov, “Rényi differential privacy,” in <em id="bib.bib169.1.1" class="ltx_emph ltx_font_italic">2017 IEEE 30th
computer security foundations symposium (CSF)</em>.   IEEE, 2017, pp. 263–275.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
Y. Shi, Y. Liu, K. Wei, L. Shen, X. Wang, and D. Tao, “Make landscape flatter
in differentially private federated learning,” in <em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp.
24 552–24 562.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
R. Hu, Y. Guo, and Y. Gong, “Federated learning with sparsified model
perturbation: Improving accuracy under client-level differential privacy,”
<em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>, 2023.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
Z. Xiong, Z. Cai, D. Takabi, and W. Li, “Privacy threat and defense for
federated learning with non-iid data in aiot,” <em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Industrial Informatics</em>, vol. 18, no. 2, pp. 1310–1321, 2021.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
J. Liu, J. Lou, L. Xiong, J. Liu, and X. Meng, “Projected federated averaging
with heterogeneous differential privacy,” <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB
Endowment</em>, vol. 15, no. 4, pp. 828–840, 2021.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
Z. Gao, Y. Duan, Y. Yang, L. Rui, and C. Zhao, “Fedsec: a robust differential
private federated learning framework in heterogeneous networks,” in
<em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">2022 IEEE Wireless Communications and Networking Conference
(WCNC)</em>.   IEEE, 2022, pp. 1868–1873.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
M. Noble, A. Bellet, and A. Dieuleveut, “Differentially private federated
learning on heterogeneous data,” in <em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">International Conference on
Artificial Intelligence and Statistics</em>.   PMLR, 2022, pp. 10 110–10 145.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
O. Goldreich, “Secure multi-party computation,” <em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">Manuscript. Preliminary
version</em>, vol. 78, no. 110, pp. 1–108, 1998.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
A. J. Menezes, P. C. Van Oorschot, and S. A. Vanstone, <em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">Handbook of
applied cryptography</em>.   CRC press,
2018.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
D. Evans, V. Kolesnikov, M. Rosulek <em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A pragmatic introduction
to secure multi-party computation,” <em id="bib.bib178.2.2" class="ltx_emph ltx_font_italic">Foundations and
Trends® in Privacy and Security</em>, vol. 2, no. 2-3, pp.
70–246, 2018.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
R. L. Rivest, L. Adleman, M. L. Dertouzos <em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “On data banks and
privacy homomorphisms,” <em id="bib.bib179.2.2" class="ltx_emph ltx_font_italic">Foundations of secure computation</em>, vol. 4,
no. 11, pp. 169–180, 1978.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
A. Acar, H. Aksu, A. S. Uluagac, and M. Conti, “A survey on homomorphic
encryption schemes: Theory and implementation,” <em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys
(Csur)</em>, vol. 51, no. 4, pp. 1–35, 2018.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
Y. Aono, T. Hayashi, L. Wang, S. Moriai <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Privacy-preserving
deep learning via additively homomorphic encryption,” <em id="bib.bib181.2.2" class="ltx_emph ltx_font_italic">IEEE
transactions on information forensics and security</em>, vol. 13, no. 5, pp.
1333–1345, 2017.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
P. Paillier, “Public-key cryptosystems based on composite degree residuosity
classes,” in <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">International conference on the theory and applications
of cryptographic techniques</em>.   Springer, 1999, pp. 223–238.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock">
C. Gentry, A. Sahai, and B. Waters, “Homomorphic encryption from learning with
errors: Conceptually-simpler, asymptotically-faster, attribute-based,” in
<em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">Advances in Cryptology–CRYPTO 2013: 33rd Annual Cryptology Conference,
Santa Barbara, CA, USA, August 18-22, 2013. Proceedings, Part I</em>.   Springer, 2013, pp. 75–92.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock">
J. H. Cheon, A. Kim, M. Kim, and Y. Song, “Homomorphic encryption for
arithmetic of approximate numbers,” in <em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">Advances in
Cryptology–ASIACRYPT 2017: 23rd International Conference on the Theory and
Applications of Cryptology and Information Security, Hong Kong, China,
December 3-7, 2017, Proceedings, Part I 23</em>.   Springer, 2017, pp. 409–437.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock">
J. Ma, S.-A. Naas, S. Sigg, and X. Lyu, “Privacy-preserving federated learning
based on multi-key homomorphic encryption,” <em id="bib.bib185.1.1" class="ltx_emph ltx_font_italic">International Journal of
Intelligent Systems</em>, vol. 37, no. 9, pp. 5880–5901, 2022.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock">
D. Boneh, A. Sahai, and B. Waters, “Functional encryption: Definitions and
challenges,” in <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">Theory of Cryptography: 8th Theory of Cryptography
Conference, TCC 2011, Providence, RI, USA, March 28-30, 2011. Proceedings
8</em>.   Springer, 2011, pp. 253–273.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock">
S. Goldwasser, S. D. Gordon, V. Goyal, A. Jain, J. Katz, F.-H. Liu, A. Sahai,
E. Shi, and H.-S. Zhou, “Multi-input functional encryption,” in
<em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">Advances in Cryptology–EUROCRYPT 2014: 33rd Annual International
Conference on the Theory and Applications of Cryptographic Techniques,
Copenhagen, Denmark, May 11-15, 2014. Proceedings 33</em>.   Springer, 2014, pp. 578–602.

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock">
R. Xu, N. Baracaldo, Y. Zhou, A. Anwar, and H. Ludwig, “Hybridalpha: An
efficient approach for privacy-preserving federated learning,” in
<em id="bib.bib188.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM workshop on artificial intelligence and
security</em>, 2019, pp. 13–23.

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock">
J. Chotard, E. Dufour Sans, R. Gay, D. H. Phan, and D. Pointcheval,
“Decentralized multi-client functional encryption for inner product,” in
<em id="bib.bib189.1.1" class="ltx_emph ltx_font_italic">Advances in Cryptology–ASIACRYPT 2018: 24th International Conference
on the Theory and Application of Cryptology and Information Security,
Brisbane, QLD, Australia, December 2–6, 2018, Proceedings, Part II
24</em>.   Springer, 2018, pp. 703–732.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock">
Y. Chang, K. Zhang, J. Gong, and H. Qian, “Privacy-preserving federated
learning via functional encryption, revisited,” <em id="bib.bib190.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol. 18, pp. 1855–1869, 2023.

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock">
A. Shamir, “How to share a secret,” <em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>,
vol. 22, no. 11, pp. 612–613, 1979.

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[192]</span>
<span class="ltx_bibblock">
G. R. Blakley, “Safeguarding cryptographic keys,” in <em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">Managing
requirements knowledge, international workshop on</em>.   IEEE Computer Society, 1979, pp. 313–313.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[193]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for
privacy-preserving machine learning,” in <em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security</em>, 2017, pp.
1175–1191.

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[194]</span>
<span class="ltx_bibblock">
J. H. Bell, K. A. Bonawitz, A. Gascón, T. Lepoint, and M. Raykova, “Secure
single-server aggregation with (poly) logarithmic overhead,” in
<em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 ACM SIGSAC Conference on Computer and
Communications Security</em>, 2020, pp. 1253–1269.

</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[195]</span>
<span class="ltx_bibblock">
H. Fereidooni, S. Marchal, M. Miettinen, A. Mirhoseini, H. Möllering, T. D.
Nguyen, P. Rieger, A.-R. Sadeghi, T. Schneider, H. Yalame <em id="bib.bib195.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Safelearn: Secure aggregation for private federated learning,” in
<em id="bib.bib195.2.2" class="ltx_emph ltx_font_italic">2021 IEEE Security and Privacy Workshops (SPW)</em>.   IEEE, 2021, pp. 56–62.

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[196]</span>
<span class="ltx_bibblock">
H. Fazli Khojir, D. Alhadidi, S. Rouhani, and N. Mohammed, “Fedshare: secure
aggregation based on additive secret sharing in federated learning,” in
<em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th International Database Engineered Applications
Symposium</em>, 2023, pp. 25–33.

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[197]</span>
<span class="ltx_bibblock">
I. Cox, M. Miller, J. Bloom, and C. Honsinger, “Digital watermarking,”
<em id="bib.bib197.1.1" class="ltx_emph ltx_font_italic">Journal of Electronic Imaging</em>, vol. 11, no. 3, pp. 414–414, 2002.

</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[198]</span>
<span class="ltx_bibblock">
B. G. Tekgul, Y. Xia, S. Marchal, and N. Asokan, “Waffle: Watermarking in
federated learning,” in <em id="bib.bib198.1.1" class="ltx_emph ltx_font_italic">2021 40th International Symposium on Reliable
Distributed Systems (SRDS)</em>.   IEEE,
2021, pp. 310–320.

</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[199]</span>
<span class="ltx_bibblock">
H. Nie and S. Lu, “Fedcrmw: Federated model ownership verification with
compression-resistant model watermarking,” <em id="bib.bib199.1.1" class="ltx_emph ltx_font_italic">Expert Systems with
Applications</em>, p. 123776, 2024.

</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[200]</span>
<span class="ltx_bibblock">
B. Han, R. H. Jhaveri, H. Wang, D. Qiao, and J. Du, “Application of robust
zero-watermarking scheme based on federated learning for securing the
healthcare data,” <em id="bib.bib200.1.1" class="ltx_emph ltx_font_italic">IEEE journal of biomedical and health informatics</em>,
vol. 27, no. 2, pp. 804–813, 2021.

</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[201]</span>
<span class="ltx_bibblock">
S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,” 2008.

</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[202]</span>
<span class="ltx_bibblock">
Q. Wang, R. Li, Q. Wang, and S. Chen, “Non-fungible token (nft): Overview,
evaluation, opportunities and challenges,” <em id="bib.bib202.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2105.07447</em>, 2021.

</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[203]</span>
<span class="ltx_bibblock">
L. Cui, X. Su, Z. Ming, Z. Chen, S. Yang, Y. Zhou, and W. Xiao, “Creat:
Blockchain-assisted compression algorithm of federated learning for content
caching in edge computing,” <em id="bib.bib203.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 9,
no. 16, pp. 14 151–14 161, 2020.

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[204]</span>
<span class="ltx_bibblock">
K. Toyoda and A. N. Zhang, “Mechanism design for an incentive-aware
blockchain-enabled federated learning platform,” in <em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">2019 IEEE
international conference on big data (Big Data)</em>.   IEEE, 2019, pp. 395–403.

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[205]</span>
<span class="ltx_bibblock">
Y. Li, Y. Lai, C. Chen, and Z. Zheng, “Veryfl: A verify federated learning
framework embedded with blockchain,” <em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.15617</em>,
2023.

</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[206]</span>
<span class="ltx_bibblock">
Y. Huang, L. Chu, Z. Zhou, L. Wang, J. Liu, J. Pei, and Y. Zhang,
“Personalized cross-silo federated learning on non-iid data,” in
<em id="bib.bib206.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</em>,
vol. 35, no. 9, 2021, pp. 7865–7873.

</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[207]</span>
<span class="ltx_bibblock">
H. Jiang, M. Liu, B. Yang, Q. Liu, J. Li, and X. Guo, “Customized federated
learning for accelerated edge computing with heterogeneous task targets,”
<em id="bib.bib207.1.1" class="ltx_emph ltx_font_italic">Computer Networks</em>, vol. 183, p. 107569, 2020.

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[208]</span>
<span class="ltx_bibblock">
P. Zheng, Y. Zhu, Y. Hu, Z. Zhang, and A. Schmeink, “Federated learning in
heterogeneous networks with unreliable communication,” <em id="bib.bib208.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, 2023.

</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[209]</span>
<span class="ltx_bibblock">
Y. H. Ezzeldin, S. Yan, C. He, E. Ferrara, and A. S. Avestimehr, “Fairfed:
Enabling group fairness in federated learning,” in <em id="bib.bib209.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, vol. 37, no. 6, 2023, pp.
7494–7502.

</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[210]</span>
<span class="ltx_bibblock">
F.-Y. Wang, R. Qin, J. Li, X. Wang, H. Qi, X. Jia, and B. Hu, “Federated
management: Toward federated services and federated security in federated
ecology,” <em id="bib.bib210.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Computational Social Systems</em>, vol. 8,
no. 6, pp. 1283–1290, 2021.

</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[211]</span>
<span class="ltx_bibblock">
Z. Wang, Q. Hu, R. Li, M. Xu, and Z. Xiong, “Incentive mechanism design for
joint resource allocation in blockchain-based federated learning,”
<em id="bib.bib211.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>, vol. 34, no. 5,
pp. 1536–1547, 2023.

</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[212]</span>
<span class="ltx_bibblock">
S. Feng, B. Li, H. Yu, Y. Liu, and Q. Yang, “Semi-supervised federated
heterogeneous transfer learning,” <em id="bib.bib212.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 252,
p. 109384, 2022.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.09838" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.09839" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.09839">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.09839" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.09840" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 15:57:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
