<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.06643] Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images</title><meta property="og:description" content="Federated learning (FL) is gaining increasing popularity in the medical domain for analyzing medical images, which is considered an effective technique to safeguard sensitive patient data and comply with privacy regulaâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.06643">

<!--Generated on Tue Feb 27 19:21:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Gradient Leakage Attack,  Medical Image Analysis,  Privacy Risk.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Badhan Chandra Das
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_font_italic">Knight Foundation School of</span>
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_italic">Computing and Information Sciences 
<br class="ltx_break"></span>Miami, Florida, USA. 
<br class="ltx_break">bdas004@fiu.edu
</span></span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">M. Hadi Amini
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_font_italic">Knight Foundation School of</span>
<br class="ltx_break"><span id="id4.2.id2" class="ltx_text ltx_font_italic">Computing and Information Sciences
<br class="ltx_break"></span>Miami, Florida, USA.
<br class="ltx_break">moamini@fiu.edu
</span></span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanzhao Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_font_italic">Knight Foundation School of</span>
<br class="ltx_break"><span id="id6.2.id2" class="ltx_text ltx_font_italic">Computing and Information Sciences
<br class="ltx_break"></span>Miami, Florida, USA. 
<br class="ltx_break">yawu@fiu.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Federated learning (FL) is gaining increasing popularity in the medical domain for analyzing medical images, which is considered an effective technique to safeguard sensitive patient data and comply with privacy regulations.
However, several recent studies have revealed that the default settings of FL may leak private training data under privacy attacks. Thus, it is still unclear whether and to what extent such privacy risks of FL exist in the medical domain, and if so, â€œhow to mitigate such risks?â€. In this paper, first, we propose a holistic framework for Medical
data Privacy risk analysis and mitigation in Federated
Learning (MedPFL) to analyze privacy risks and develop effective mitigation strategies in FL for protecting private medical data.
Second, we demonstrate the substantial privacy risks of using FL to process medical images, where adversaries can easily perform privacy attacks to reconstruct private medical images accurately.
Third, we show that the defense approach of adding random noises may not always work effectively to protect medical images against privacy attacks in FL, which poses unique and pressing challenges associated with medical data for privacy protection.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Gradient Leakage Attack, Medical Image Analysis, Privacy Risk.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">FL distributes training data across multiple devices, reducing systemic privacy risks by keeping private data decentralized on clients and sharing only gradient updatesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. FL has emerged as a promising learning technique in healthcare by enabling privacy-compliant ML models without sharing raw data among distributed clients like hospitals and clinicsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Medical data, like X-rays and diabetic test reports, contain highly sensitive and personal details, e.g., birth dates that can be used to identify individuals. Breaching such data can lead to severe consequences like stigma, discrimination, or job and insurance loss for patients. Global data protection regulations like HIPPAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> are in place to safeguard private health information, emphasizing the need for privacy.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text ltx_font_bold">Related Works.</span> Several recent studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> have made attempts to recover the private training data and proposed several privacy leakage attacks as Client Privacy Leakage (CPL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, Deep Leakage from Gradients (DLG)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and Inverting Gradients (GradInv)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, which demonstrated that the default privacy framework in FL may not be sufficient to prevent privacy leakage in a general FL setting. Introducing random noises in deep learning training can be a viable method to defend against privacy attacks for deep learning models, such as training with Gaussian noiseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> or Laplacian noiseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. However, it lacks in-depth systematic studies of potential risks, privacy attacks, and defense strategies for medical data in FL settings. In the medical domain, Kaissis et. al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> reported privacy-preservation methods for chest X-rays classification and segmenting CT scans in deep learning training.
To the best of our knowledge, no frameworks have been proposed to analyze the privacy risks of medical data and its mitigation strategies in the FL environments. Furthermore, we have identified some unique challenges, including complex types, statistical variance, higher dimensionality, and latent pathological information in medical images, which complicate privacy concerns of medical data in FL.
Therefore, it remains unclear to what extent FL applications in the medical domain are vulnerable to privacy attacks and how to mitigate such privacy risks, especially when FL involves confidential medical data, such as skin cancer images, X-ray images, and MRI scans of patients.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Contributions.</span> We argue that it is imperative to investigate the privacy risks and develop mitigation strategies to prevent privacy attacks against FL applications in the medical domain.
This paper presents three original contributions. <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">First,</span> we present a systematic framework for <span id="S1.p3.1.3" class="ltx_text ltx_font_bold">Med</span>ical data <span id="S1.p3.1.4" class="ltx_text ltx_font_bold">P</span>rivacy risk analysis and mitigation in <span id="S1.p3.1.5" class="ltx_text ltx_font_bold">F</span>ederated <span id="S1.p3.1.6" class="ltx_text ltx_font_bold">L</span>earning (MedPFL). This framework contains a suite of datasets, models, attack methods, defense mechanisms, and evaluation metrics to evaluate the attack and defense with different configurations. <span id="S1.p3.1.7" class="ltx_text ltx_font_italic">Second,</span> we demonstrate the severe privacy leakage risks of leveraging FL to analyze medical images. Our empirical evaluations show how an adversary can easily perform privacy attacks and reconstruct patientsâ€™ private medical data with high reconstruction accuracy. <span id="S1.p3.1.8" class="ltx_text ltx_font_italic">Third,</span> we vary the defense configurations to prevent privacy leakage by introducing different levels of random noises in FL with the goal of safeguarding private medical data, which reveals the unique research challenges for protecting private medical data. Experiments are conducted with our MedPFL framework on several benchmark medical image datasets to analyze and mitigate the privacy risks of FL for medical images. We conjecture that this study will draw the attention of the research community toward privacy-preserving techniques in FL for medical applications. The source codes are available on GitHub at <a target="_blank" href="https://github.com/mlsysx/MedPFL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/mlsysx/MedPFL</a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Framework Overview</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We propose MedPFL, a framework for <span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Med</span>ical data <span id="S2.p1.1.2" class="ltx_text ltx_font_bold">P</span>rivacy risk analysis and mitigation in <span id="S2.p1.1.3" class="ltx_text ltx_font_bold">F</span>ederated <span id="S2.p1.1.4" class="ltx_text ltx_font_bold">L</span>earning. This framework contains five major components to facilitate the evaluation, comparison, and mitigation of privacy risks of processing medical data in FL settings as illustrated in FigureÂ <a href="#S2.F1" title="Figure 1 â€£ II Framework Overview â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2311.06643/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="132" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The overview of MedPFL: a framework for <span id="S2.F1.5.1" class="ltx_text ltx_font_bold">Med</span>ical Data <span id="S2.F1.6.2" class="ltx_text ltx_font_bold">P</span>rivacy risk analysis and mitigation in <span id="S2.F1.7.3" class="ltx_text ltx_font_bold">F</span>ederated <span id="S2.F1.8.4" class="ltx_text ltx_font_bold">L</span>earning</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Framework Components</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">Datasets.</span> Our framework offers publicly available diverse real-world medical datasets, including Melanoma Skin Cancer, COVID-19 X-rays, and Brain Tumor MRI scans, to assess privacy risks. We also provide the APIs to incorporate new datasets in our framework.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Models.</span>
In our MedPFL framework, we support a variety of popular deep learning models for processing medical data, such as LeNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and ResNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> for medical image classification. These models represent the mainstream DNN architectures for medical data analysis. It can effectively reflect the research challenges by comparing their privacy vulnerabilities and exploring potential mitigation strategies.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Attack Methods.</span>
For the privacy attacks, we implemented a set of attack methods to analyze the privacy risks in medical data analysis, including CPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, DLGÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and GradInvÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. We leverage these attack methods to perform privacy attacks against different medical datasets and models for analyzing their potential privacy risks. These privacy attack methods are evaluated with widely known evaluation metrics.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Defense Mechanisms.</span>
In a vanilla FL setting, several defense mechanisms can prevent the different types of privacy attacks, such as gradient perturbationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, gradient compressionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, secure multi-party computationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and differential privacyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. However, for medical data, in-depth studies of the effectiveness and configurations of these defense mechanisms against various privacy attacks are lacking. Our MedPFL framework offers diverse defense mechanisms for exploring their efficacy and the factors impact their performance. We also include a range of evaluation metrics to quantify their privacy protection for medical data.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para ltx_noindent">
<p id="S2.SS1.p5.1" class="ltx_p"><span id="S2.SS1.p5.1.1" class="ltx_text ltx_font_bold">Evaluation Metrics.</span> Our framework consists of several core evaluation metrics described as follows. Attack Success Rate (ASR) is the percent of successfully reconstructed samples over the number of attacked samples. Mean Squared Error (MSE) is used to quantify dissimilarity between images, where lower MSE values denote more effective attacks and higher values indicate stronger defense in the context of MedFPL. The Structural Similarity Index Measure (SSIM) assesses the similarity between images, with higher values indicating successful attacks and lower values reflecting stronger defense.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methodology</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.6" class="ltx_p">In the healthcare domain, FL involves replicating the ML models from the centralized server and distributing them among a group of clients, which can be clinics, hospitals, and healthcare centers. It typically involves the following steps:
At step 1, each client receives a global model <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\theta</annotation></semantics></math> at round <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">t</annotation></semantics></math> from the trusted centralized server. We denote it as <math id="S3.p1.3.m3.2" class="ltx_Math" alttext="\theta(i,t)" display="inline"><semantics id="S3.p1.3.m3.2a"><mrow id="S3.p1.3.m3.2.3" xref="S3.p1.3.m3.2.3.cmml"><mi id="S3.p1.3.m3.2.3.2" xref="S3.p1.3.m3.2.3.2.cmml">Î¸</mi><mo lspace="0em" rspace="0em" id="S3.p1.3.m3.2.3.1" xref="S3.p1.3.m3.2.3.1.cmml">â€‹</mo><mrow id="S3.p1.3.m3.2.3.3.2" xref="S3.p1.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.p1.3.m3.2.3.3.2.1" xref="S3.p1.3.m3.2.3.3.1.cmml">(</mo><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">i</mi><mo id="S3.p1.3.m3.2.3.3.2.2" xref="S3.p1.3.m3.2.3.3.1.cmml">,</mo><mi id="S3.p1.3.m3.2.2" xref="S3.p1.3.m3.2.2.cmml">t</mi><mo stretchy="false" id="S3.p1.3.m3.2.3.3.2.3" xref="S3.p1.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.2b"><apply id="S3.p1.3.m3.2.3.cmml" xref="S3.p1.3.m3.2.3"><times id="S3.p1.3.m3.2.3.1.cmml" xref="S3.p1.3.m3.2.3.1"></times><ci id="S3.p1.3.m3.2.3.2.cmml" xref="S3.p1.3.m3.2.3.2">ğœƒ</ci><interval closure="open" id="S3.p1.3.m3.2.3.3.1.cmml" xref="S3.p1.3.m3.2.3.3.2"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ğ‘–</ci><ci id="S3.p1.3.m3.2.2.cmml" xref="S3.p1.3.m3.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.2c">\theta(i,t)</annotation></semantics></math> for Client <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">i</annotation></semantics></math>. Each client starts to train its local model <math id="S3.p1.5.m5.2" class="ltx_Math" alttext="\theta(i,t)" display="inline"><semantics id="S3.p1.5.m5.2a"><mrow id="S3.p1.5.m5.2.3" xref="S3.p1.5.m5.2.3.cmml"><mi id="S3.p1.5.m5.2.3.2" xref="S3.p1.5.m5.2.3.2.cmml">Î¸</mi><mo lspace="0em" rspace="0em" id="S3.p1.5.m5.2.3.1" xref="S3.p1.5.m5.2.3.1.cmml">â€‹</mo><mrow id="S3.p1.5.m5.2.3.3.2" xref="S3.p1.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S3.p1.5.m5.2.3.3.2.1" xref="S3.p1.5.m5.2.3.3.1.cmml">(</mo><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">i</mi><mo id="S3.p1.5.m5.2.3.3.2.2" xref="S3.p1.5.m5.2.3.3.1.cmml">,</mo><mi id="S3.p1.5.m5.2.2" xref="S3.p1.5.m5.2.2.cmml">t</mi><mo stretchy="false" id="S3.p1.5.m5.2.3.3.2.3" xref="S3.p1.5.m5.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.2b"><apply id="S3.p1.5.m5.2.3.cmml" xref="S3.p1.5.m5.2.3"><times id="S3.p1.5.m5.2.3.1.cmml" xref="S3.p1.5.m5.2.3.1"></times><ci id="S3.p1.5.m5.2.3.2.cmml" xref="S3.p1.5.m5.2.3.2">ğœƒ</ci><interval closure="open" id="S3.p1.5.m5.2.3.3.1.cmml" xref="S3.p1.5.m5.2.3.3.2"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ğ‘–</ci><ci id="S3.p1.5.m5.2.2.cmml" xref="S3.p1.5.m5.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.2c">\theta(i,t)</annotation></semantics></math> using its private medical data at step 2. Then in step 3, the local model update (gradients, <math id="S3.p1.6.m6.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S3.p1.6.m6.2a"><mrow id="S3.p1.6.m6.2.3" xref="S3.p1.6.m6.2.3.cmml"><mrow id="S3.p1.6.m6.2.3.2" xref="S3.p1.6.m6.2.3.2.cmml"><mo rspace="0.167em" id="S3.p1.6.m6.2.3.2.1" xref="S3.p1.6.m6.2.3.2.1.cmml">âˆ‡</mo><mi id="S3.p1.6.m6.2.3.2.2" xref="S3.p1.6.m6.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S3.p1.6.m6.2.3.1" xref="S3.p1.6.m6.2.3.1.cmml">â€‹</mo><mrow id="S3.p1.6.m6.2.3.3.2" xref="S3.p1.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="S3.p1.6.m6.2.3.3.2.1" xref="S3.p1.6.m6.2.3.3.1.cmml">(</mo><mi id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">i</mi><mo id="S3.p1.6.m6.2.3.3.2.2" xref="S3.p1.6.m6.2.3.3.1.cmml">,</mo><mi id="S3.p1.6.m6.2.2" xref="S3.p1.6.m6.2.2.cmml">t</mi><mo stretchy="false" id="S3.p1.6.m6.2.3.3.2.3" xref="S3.p1.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.2b"><apply id="S3.p1.6.m6.2.3.cmml" xref="S3.p1.6.m6.2.3"><times id="S3.p1.6.m6.2.3.1.cmml" xref="S3.p1.6.m6.2.3.1"></times><apply id="S3.p1.6.m6.2.3.2.cmml" xref="S3.p1.6.m6.2.3.2"><ci id="S3.p1.6.m6.2.3.2.1.cmml" xref="S3.p1.6.m6.2.3.2.1">âˆ‡</ci><ci id="S3.p1.6.m6.2.3.2.2.cmml" xref="S3.p1.6.m6.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S3.p1.6.m6.2.3.3.1.cmml" xref="S3.p1.6.m6.2.3.3.2"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">ğ‘–</ci><ci id="S3.p1.6.m6.2.2.cmml" xref="S3.p1.6.m6.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.2c">\nabla\theta(i,t)</annotation></semantics></math>) will be sent to the central server. The central server aggregates local model updates received from clients and updates its global model, which can be performed by using an aggregation strategy, such as Federated Averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. This process keeps repeating until the stopping criteria are met, e.g., the number of iterations or desired accuracy.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2311.06643/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of the Attack Method</figcaption>
</figure>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.5" class="ltx_p"><span id="S3.p2.5.1" class="ltx_text ltx_font_bold">Attack Method.</span>
In Figure <a href="#S3.F2" title="Figure 2 â€£ III Methodology â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show how an adversary can intercept the local gradient update and reconstruct the patientsâ€™ confidential medical data. At step 3, while the local model update (gradients) <math id="S3.p2.1.m1.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S3.p2.1.m1.2a"><mrow id="S3.p2.1.m1.2.3" xref="S3.p2.1.m1.2.3.cmml"><mrow id="S3.p2.1.m1.2.3.2" xref="S3.p2.1.m1.2.3.2.cmml"><mo rspace="0.167em" id="S3.p2.1.m1.2.3.2.1" xref="S3.p2.1.m1.2.3.2.1.cmml">âˆ‡</mo><mi id="S3.p2.1.m1.2.3.2.2" xref="S3.p2.1.m1.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S3.p2.1.m1.2.3.1" xref="S3.p2.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S3.p2.1.m1.2.3.3.2" xref="S3.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.p2.1.m1.2.3.3.2.1" xref="S3.p2.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">i</mi><mo id="S3.p2.1.m1.2.3.3.2.2" xref="S3.p2.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.p2.1.m1.2.2" xref="S3.p2.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S3.p2.1.m1.2.3.3.2.3" xref="S3.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.2b"><apply id="S3.p2.1.m1.2.3.cmml" xref="S3.p2.1.m1.2.3"><times id="S3.p2.1.m1.2.3.1.cmml" xref="S3.p2.1.m1.2.3.1"></times><apply id="S3.p2.1.m1.2.3.2.cmml" xref="S3.p2.1.m1.2.3.2"><ci id="S3.p2.1.m1.2.3.2.1.cmml" xref="S3.p2.1.m1.2.3.2.1">âˆ‡</ci><ci id="S3.p2.1.m1.2.3.2.2.cmml" xref="S3.p2.1.m1.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S3.p2.1.m1.2.3.3.1.cmml" xref="S3.p2.1.m1.2.3.3.2"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ğ‘–</ci><ci id="S3.p2.1.m1.2.2.cmml" xref="S3.p2.1.m1.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.2c">\nabla\theta(i,t)</annotation></semantics></math> is shared with a central server, an attacker <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="a_{i}" display="inline"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">a</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ‘</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">a_{i}</annotation></semantics></math>, can intercept the transmission of <math id="S3.p2.3.m3.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S3.p2.3.m3.2a"><mrow id="S3.p2.3.m3.2.3" xref="S3.p2.3.m3.2.3.cmml"><mrow id="S3.p2.3.m3.2.3.2" xref="S3.p2.3.m3.2.3.2.cmml"><mo rspace="0.167em" id="S3.p2.3.m3.2.3.2.1" xref="S3.p2.3.m3.2.3.2.1.cmml">âˆ‡</mo><mi id="S3.p2.3.m3.2.3.2.2" xref="S3.p2.3.m3.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.2.3.1" xref="S3.p2.3.m3.2.3.1.cmml">â€‹</mo><mrow id="S3.p2.3.m3.2.3.3.2" xref="S3.p2.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.p2.3.m3.2.3.3.2.1" xref="S3.p2.3.m3.2.3.3.1.cmml">(</mo><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">i</mi><mo id="S3.p2.3.m3.2.3.3.2.2" xref="S3.p2.3.m3.2.3.3.1.cmml">,</mo><mi id="S3.p2.3.m3.2.2" xref="S3.p2.3.m3.2.2.cmml">t</mi><mo stretchy="false" id="S3.p2.3.m3.2.3.3.2.3" xref="S3.p2.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.2b"><apply id="S3.p2.3.m3.2.3.cmml" xref="S3.p2.3.m3.2.3"><times id="S3.p2.3.m3.2.3.1.cmml" xref="S3.p2.3.m3.2.3.1"></times><apply id="S3.p2.3.m3.2.3.2.cmml" xref="S3.p2.3.m3.2.3.2"><ci id="S3.p2.3.m3.2.3.2.1.cmml" xref="S3.p2.3.m3.2.3.2.1">âˆ‡</ci><ci id="S3.p2.3.m3.2.3.2.2.cmml" xref="S3.p2.3.m3.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S3.p2.3.m3.2.3.3.1.cmml" xref="S3.p2.3.m3.2.3.3.2"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">ğ‘–</ci><ci id="S3.p2.3.m3.2.2.cmml" xref="S3.p2.3.m3.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.2c">\nabla\theta(i,t)</annotation></semantics></math> and acquire the local model update for the corresponding client <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.4.m4.1a"><mi id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><ci id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">i</annotation></semantics></math>. Then, this attacker can analyze the periodic local model updates to perform privacy attacks, such asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and potentially reconstruct the private data of the client <math id="S3.p2.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.5.m5.1a"><mi id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><ci id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">i</annotation></semantics></math>. The privacy attack often starts by initiating dummy data and dummy label that matches the size of the private training data. The attacker then utilizes the dummy data, labels, local model updates (gradients intercepted during step 3), and the shared global model to iteratively update the dummy data and dummy label to reconstruct the clientâ€™s private training data. This process leverages a reconstruction loss function to minimize the distance between the local gradients on the private data and the dummy gradients on the dummy data and dummy label such that the dummy data gradually becomes close to the private training data to incur privacy leakage.</p>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.2" class="ltx_p"><span id="S3.p3.2.1" class="ltx_text ltx_font_bold">Defense Mechanism.</span>
There exist several methods to defend against privacy leakage attacks in the vanilla FL setting, which can be potentially applied to protect the privacy of medical data. Gradient perturbationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> involves adding a controlled amount of Laplacian or Gaussian noise to the local model update <math id="S3.p3.1.m1.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S3.p3.1.m1.2a"><mrow id="S3.p3.1.m1.2.3" xref="S3.p3.1.m1.2.3.cmml"><mrow id="S3.p3.1.m1.2.3.2" xref="S3.p3.1.m1.2.3.2.cmml"><mo rspace="0.167em" id="S3.p3.1.m1.2.3.2.1" xref="S3.p3.1.m1.2.3.2.1.cmml">âˆ‡</mo><mi id="S3.p3.1.m1.2.3.2.2" xref="S3.p3.1.m1.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S3.p3.1.m1.2.3.1" xref="S3.p3.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S3.p3.1.m1.2.3.3.2" xref="S3.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.p3.1.m1.2.3.3.2.1" xref="S3.p3.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">i</mi><mo id="S3.p3.1.m1.2.3.3.2.2" xref="S3.p3.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.p3.1.m1.2.2" xref="S3.p3.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S3.p3.1.m1.2.3.3.2.3" xref="S3.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.2b"><apply id="S3.p3.1.m1.2.3.cmml" xref="S3.p3.1.m1.2.3"><times id="S3.p3.1.m1.2.3.1.cmml" xref="S3.p3.1.m1.2.3.1"></times><apply id="S3.p3.1.m1.2.3.2.cmml" xref="S3.p3.1.m1.2.3.2"><ci id="S3.p3.1.m1.2.3.2.1.cmml" xref="S3.p3.1.m1.2.3.2.1">âˆ‡</ci><ci id="S3.p3.1.m1.2.3.2.2.cmml" xref="S3.p3.1.m1.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S3.p3.1.m1.2.3.3.1.cmml" xref="S3.p3.1.m1.2.3.3.2"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">ğ‘–</ci><ci id="S3.p3.1.m1.2.2.cmml" xref="S3.p3.1.m1.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.2c">\nabla\theta(i,t)</annotation></semantics></math> at step 3 in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ III Methodology â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Noise added to <math id="S3.p3.2.m2.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S3.p3.2.m2.2a"><mrow id="S3.p3.2.m2.2.3" xref="S3.p3.2.m2.2.3.cmml"><mrow id="S3.p3.2.m2.2.3.2" xref="S3.p3.2.m2.2.3.2.cmml"><mo rspace="0.167em" id="S3.p3.2.m2.2.3.2.1" xref="S3.p3.2.m2.2.3.2.1.cmml">âˆ‡</mo><mi id="S3.p3.2.m2.2.3.2.2" xref="S3.p3.2.m2.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S3.p3.2.m2.2.3.1" xref="S3.p3.2.m2.2.3.1.cmml">â€‹</mo><mrow id="S3.p3.2.m2.2.3.3.2" xref="S3.p3.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.p3.2.m2.2.3.3.2.1" xref="S3.p3.2.m2.2.3.3.1.cmml">(</mo><mi id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">i</mi><mo id="S3.p3.2.m2.2.3.3.2.2" xref="S3.p3.2.m2.2.3.3.1.cmml">,</mo><mi id="S3.p3.2.m2.2.2" xref="S3.p3.2.m2.2.2.cmml">t</mi><mo stretchy="false" id="S3.p3.2.m2.2.3.3.2.3" xref="S3.p3.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.2b"><apply id="S3.p3.2.m2.2.3.cmml" xref="S3.p3.2.m2.2.3"><times id="S3.p3.2.m2.2.3.1.cmml" xref="S3.p3.2.m2.2.3.1"></times><apply id="S3.p3.2.m2.2.3.2.cmml" xref="S3.p3.2.m2.2.3.2"><ci id="S3.p3.2.m2.2.3.2.1.cmml" xref="S3.p3.2.m2.2.3.2.1">âˆ‡</ci><ci id="S3.p3.2.m2.2.3.2.2.cmml" xref="S3.p3.2.m2.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S3.p3.2.m2.2.3.3.1.cmml" xref="S3.p3.2.m2.2.3.3.2"><ci id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">ğ‘–</ci><ci id="S3.p3.2.m2.2.2.cmml" xref="S3.p3.2.m2.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.2c">\nabla\theta(i,t)</annotation></semantics></math> introduces uncertainty in local updates, obscures details, and prevents the accurate reconstruction of private data, e.g., medical images by adversaries. Differential Privacy (DP) is used to add controlled noise to private data, preserving statistical characteristics while hiding individual valuesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. This safeguards privacy by preventing the identification of specific data points. Gradient compressionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and secure multi-party computationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> are also used to prevent privacy leakage in federated learning.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental Analysis</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">CPL attack has been performed on three representative medical image datasets: Melanoma Skin Cancer, COVID X-ray, and Brain Tumor MRI scans, which contain 10000, 317, and 7022 samples with two, three, and four classes respectively, containing different sizes of images. For example, the Melanoma Skin Cancer dataset consists of images with 300<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><times id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\times</annotation></semantics></math>300 size. COVID X-ray images and brain tumor MRI scans were sized in various shapes. In our experiments, we converted all images into 32<math id="S4.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.2.m2.1a"><mo id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><times id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\times</annotation></semantics></math>32 size and normalized the data with the mean and standard deviation during data preprocessing. For all the datasets, a 3:1 train-test ratio was maintained. We use 7-layer and 4-layer CNN with a fully connected layer which takes input images with 3 channels followingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> andÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> for performing the CPL attack and DLG respectively on the medical image datasets. We also perform GradInvÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> on Melanoma Skin Cancer images to compare with CPL and DLG.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.6" class="ltx_p"><span id="S4.p2.6.1" class="ltx_text ltx_font_bold">Attack and Defense Configuration.</span>
Both CPL and DLG attack starts with intercepting the local model update <math id="S4.p2.1.m1.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p2.1.m1.2a"><mrow id="S4.p2.1.m1.2.3" xref="S4.p2.1.m1.2.3.cmml"><mrow id="S4.p2.1.m1.2.3.2" xref="S4.p2.1.m1.2.3.2.cmml"><mo rspace="0.167em" id="S4.p2.1.m1.2.3.2.1" xref="S4.p2.1.m1.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p2.1.m1.2.3.2.2" xref="S4.p2.1.m1.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p2.1.m1.2.3.1" xref="S4.p2.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.p2.1.m1.2.3.3.2" xref="S4.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.p2.1.m1.2.3.3.2.1" xref="S4.p2.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">i</mi><mo id="S4.p2.1.m1.2.3.3.2.2" xref="S4.p2.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.p2.1.m1.2.2" xref="S4.p2.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S4.p2.1.m1.2.3.3.2.3" xref="S4.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.2b"><apply id="S4.p2.1.m1.2.3.cmml" xref="S4.p2.1.m1.2.3"><times id="S4.p2.1.m1.2.3.1.cmml" xref="S4.p2.1.m1.2.3.1"></times><apply id="S4.p2.1.m1.2.3.2.cmml" xref="S4.p2.1.m1.2.3.2"><ci id="S4.p2.1.m1.2.3.2.1.cmml" xref="S4.p2.1.m1.2.3.2.1">âˆ‡</ci><ci id="S4.p2.1.m1.2.3.2.2.cmml" xref="S4.p2.1.m1.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p2.1.m1.2.3.3.1.cmml" xref="S4.p2.1.m1.2.3.3.2"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">ğ‘–</ci><ci id="S4.p2.1.m1.2.2.cmml" xref="S4.p2.1.m1.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.2c">\nabla\theta(i,t)</annotation></semantics></math> for a client <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">i</annotation></semantics></math> and initializing the dummy image of the same size and the dummy label. Then the dummy image will be iteratively updated to optimize the reconstruction loss to minimize the <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">â€‹</mo><mn id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><times id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1"></times><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">ğ¿</ci><cn type="integer" id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">L2</annotation></semantics></math> distance between the actual gradient <math id="S4.p2.4.m4.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p2.4.m4.2a"><mrow id="S4.p2.4.m4.2.3" xref="S4.p2.4.m4.2.3.cmml"><mrow id="S4.p2.4.m4.2.3.2" xref="S4.p2.4.m4.2.3.2.cmml"><mo rspace="0.167em" id="S4.p2.4.m4.2.3.2.1" xref="S4.p2.4.m4.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p2.4.m4.2.3.2.2" xref="S4.p2.4.m4.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p2.4.m4.2.3.1" xref="S4.p2.4.m4.2.3.1.cmml">â€‹</mo><mrow id="S4.p2.4.m4.2.3.3.2" xref="S4.p2.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S4.p2.4.m4.2.3.3.2.1" xref="S4.p2.4.m4.2.3.3.1.cmml">(</mo><mi id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">i</mi><mo id="S4.p2.4.m4.2.3.3.2.2" xref="S4.p2.4.m4.2.3.3.1.cmml">,</mo><mi id="S4.p2.4.m4.2.2" xref="S4.p2.4.m4.2.2.cmml">t</mi><mo stretchy="false" id="S4.p2.4.m4.2.3.3.2.3" xref="S4.p2.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.2b"><apply id="S4.p2.4.m4.2.3.cmml" xref="S4.p2.4.m4.2.3"><times id="S4.p2.4.m4.2.3.1.cmml" xref="S4.p2.4.m4.2.3.1"></times><apply id="S4.p2.4.m4.2.3.2.cmml" xref="S4.p2.4.m4.2.3.2"><ci id="S4.p2.4.m4.2.3.2.1.cmml" xref="S4.p2.4.m4.2.3.2.1">âˆ‡</ci><ci id="S4.p2.4.m4.2.3.2.2.cmml" xref="S4.p2.4.m4.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p2.4.m4.2.3.3.1.cmml" xref="S4.p2.4.m4.2.3.3.2"><ci id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">ğ‘–</ci><ci id="S4.p2.4.m4.2.2.cmml" xref="S4.p2.4.m4.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.2c">\nabla\theta(i,t)</annotation></semantics></math> on the private training data and the dummy gradients on the dummy data. L-BFGS optimization method is employed as suggested byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> for performing the privacy attack.
The GradInv attack basically works on the gradients, <math id="S4.p2.5.m5.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p2.5.m5.2a"><mrow id="S4.p2.5.m5.2.3" xref="S4.p2.5.m5.2.3.cmml"><mrow id="S4.p2.5.m5.2.3.2" xref="S4.p2.5.m5.2.3.2.cmml"><mo rspace="0.167em" id="S4.p2.5.m5.2.3.2.1" xref="S4.p2.5.m5.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p2.5.m5.2.3.2.2" xref="S4.p2.5.m5.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p2.5.m5.2.3.1" xref="S4.p2.5.m5.2.3.1.cmml">â€‹</mo><mrow id="S4.p2.5.m5.2.3.3.2" xref="S4.p2.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S4.p2.5.m5.2.3.3.2.1" xref="S4.p2.5.m5.2.3.3.1.cmml">(</mo><mi id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">i</mi><mo id="S4.p2.5.m5.2.3.3.2.2" xref="S4.p2.5.m5.2.3.3.1.cmml">,</mo><mi id="S4.p2.5.m5.2.2" xref="S4.p2.5.m5.2.2.cmml">t</mi><mo stretchy="false" id="S4.p2.5.m5.2.3.3.2.3" xref="S4.p2.5.m5.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.2b"><apply id="S4.p2.5.m5.2.3.cmml" xref="S4.p2.5.m5.2.3"><times id="S4.p2.5.m5.2.3.1.cmml" xref="S4.p2.5.m5.2.3.1"></times><apply id="S4.p2.5.m5.2.3.2.cmml" xref="S4.p2.5.m5.2.3.2"><ci id="S4.p2.5.m5.2.3.2.1.cmml" xref="S4.p2.5.m5.2.3.2.1">âˆ‡</ci><ci id="S4.p2.5.m5.2.3.2.2.cmml" xref="S4.p2.5.m5.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p2.5.m5.2.3.3.1.cmml" xref="S4.p2.5.m5.2.3.3.2"><ci id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">ğ‘–</ci><ci id="S4.p2.5.m5.2.2.cmml" xref="S4.p2.5.m5.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.2c">\nabla\theta(i,t)</annotation></semantics></math> of the local training data to reconstruct the original images with a network formed with fully connected layersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
Given that the non-zero gradient condition is met, it iteratively analyzes the <math id="S4.p2.6.m6.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p2.6.m6.2a"><mrow id="S4.p2.6.m6.2.3" xref="S4.p2.6.m6.2.3.cmml"><mrow id="S4.p2.6.m6.2.3.2" xref="S4.p2.6.m6.2.3.2.cmml"><mo rspace="0.167em" id="S4.p2.6.m6.2.3.2.1" xref="S4.p2.6.m6.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p2.6.m6.2.3.2.2" xref="S4.p2.6.m6.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p2.6.m6.2.3.1" xref="S4.p2.6.m6.2.3.1.cmml">â€‹</mo><mrow id="S4.p2.6.m6.2.3.3.2" xref="S4.p2.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="S4.p2.6.m6.2.3.3.2.1" xref="S4.p2.6.m6.2.3.3.1.cmml">(</mo><mi id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">i</mi><mo id="S4.p2.6.m6.2.3.3.2.2" xref="S4.p2.6.m6.2.3.3.1.cmml">,</mo><mi id="S4.p2.6.m6.2.2" xref="S4.p2.6.m6.2.2.cmml">t</mi><mo stretchy="false" id="S4.p2.6.m6.2.3.3.2.3" xref="S4.p2.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.2b"><apply id="S4.p2.6.m6.2.3.cmml" xref="S4.p2.6.m6.2.3"><times id="S4.p2.6.m6.2.3.1.cmml" xref="S4.p2.6.m6.2.3.1"></times><apply id="S4.p2.6.m6.2.3.2.cmml" xref="S4.p2.6.m6.2.3.2"><ci id="S4.p2.6.m6.2.3.2.1.cmml" xref="S4.p2.6.m6.2.3.2.1">âˆ‡</ci><ci id="S4.p2.6.m6.2.3.2.2.cmml" xref="S4.p2.6.m6.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p2.6.m6.2.3.3.1.cmml" xref="S4.p2.6.m6.2.3.3.2"><ci id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">ğ‘–</ci><ci id="S4.p2.6.m6.2.2.cmml" xref="S4.p2.6.m6.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.2c">\nabla\theta(i,t)</annotation></semantics></math> to optimize the loss function (cosine similarity) to reconstruct the networkâ€™s input.
As suggested by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, we employed Adam as an optimization algorithm.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.2" class="ltx_p">In this research, gradient perturbation is performed as a defense mechanism to prevent privacy leakage attacks. Here, we insert a controlled amount of Laplacian noise with zero means to the gradients while transmitting <math id="S4.p3.1.m1.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p3.1.m1.2a"><mrow id="S4.p3.1.m1.2.3" xref="S4.p3.1.m1.2.3.cmml"><mrow id="S4.p3.1.m1.2.3.2" xref="S4.p3.1.m1.2.3.2.cmml"><mo rspace="0.167em" id="S4.p3.1.m1.2.3.2.1" xref="S4.p3.1.m1.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p3.1.m1.2.3.2.2" xref="S4.p3.1.m1.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p3.1.m1.2.3.1" xref="S4.p3.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.p3.1.m1.2.3.3.2" xref="S4.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.p3.1.m1.2.3.3.2.1" xref="S4.p3.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">i</mi><mo id="S4.p3.1.m1.2.3.3.2.2" xref="S4.p3.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.p3.1.m1.2.2" xref="S4.p3.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S4.p3.1.m1.2.3.3.2.3" xref="S4.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.2b"><apply id="S4.p3.1.m1.2.3.cmml" xref="S4.p3.1.m1.2.3"><times id="S4.p3.1.m1.2.3.1.cmml" xref="S4.p3.1.m1.2.3.1"></times><apply id="S4.p3.1.m1.2.3.2.cmml" xref="S4.p3.1.m1.2.3.2"><ci id="S4.p3.1.m1.2.3.2.1.cmml" xref="S4.p3.1.m1.2.3.2.1">âˆ‡</ci><ci id="S4.p3.1.m1.2.3.2.2.cmml" xref="S4.p3.1.m1.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p3.1.m1.2.3.3.1.cmml" xref="S4.p3.1.m1.2.3.3.2"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">ğ‘–</ci><ci id="S4.p3.1.m1.2.2.cmml" xref="S4.p3.1.m1.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.2c">\nabla\theta(i,t)</annotation></semantics></math> to the central server. Noise added to <math id="S4.p3.2.m2.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p3.2.m2.2a"><mrow id="S4.p3.2.m2.2.3" xref="S4.p3.2.m2.2.3.cmml"><mrow id="S4.p3.2.m2.2.3.2" xref="S4.p3.2.m2.2.3.2.cmml"><mo rspace="0.167em" id="S4.p3.2.m2.2.3.2.1" xref="S4.p3.2.m2.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p3.2.m2.2.3.2.2" xref="S4.p3.2.m2.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p3.2.m2.2.3.1" xref="S4.p3.2.m2.2.3.1.cmml">â€‹</mo><mrow id="S4.p3.2.m2.2.3.3.2" xref="S4.p3.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S4.p3.2.m2.2.3.3.2.1" xref="S4.p3.2.m2.2.3.3.1.cmml">(</mo><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">i</mi><mo id="S4.p3.2.m2.2.3.3.2.2" xref="S4.p3.2.m2.2.3.3.1.cmml">,</mo><mi id="S4.p3.2.m2.2.2" xref="S4.p3.2.m2.2.2.cmml">t</mi><mo stretchy="false" id="S4.p3.2.m2.2.3.3.2.3" xref="S4.p3.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.2b"><apply id="S4.p3.2.m2.2.3.cmml" xref="S4.p3.2.m2.2.3"><times id="S4.p3.2.m2.2.3.1.cmml" xref="S4.p3.2.m2.2.3.1"></times><apply id="S4.p3.2.m2.2.3.2.cmml" xref="S4.p3.2.m2.2.3.2"><ci id="S4.p3.2.m2.2.3.2.1.cmml" xref="S4.p3.2.m2.2.3.2.1">âˆ‡</ci><ci id="S4.p3.2.m2.2.3.2.2.cmml" xref="S4.p3.2.m2.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p3.2.m2.2.3.3.1.cmml" xref="S4.p3.2.m2.2.3.3.2"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">ğ‘–</ci><ci id="S4.p3.2.m2.2.2.cmml" xref="S4.p3.2.m2.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.2c">\nabla\theta(i,t)</annotation></semantics></math> introduces uncertainty in local updates, hides details, and prevents accurate reconstruction of private data of medical images by adversaries. Our empirical analysis revealed that the default amount of noise may not always provide sufficient defense for medical images. Thus, we vary noise levels to identify stronger defense settings.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Performance Comparison of CPL attack on all three medical datasets for 100 images.</figcaption>
<div id="S4.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:291.9pt;height:89.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.5pt,11.2pt) scale(0.8,0.8) ;">
<table id="S4.T1.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.3.4.1" class="ltx_tr">
<th id="S4.T1.3.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.3.3.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S4.T1.3.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.3.3.4.1.2.1" class="ltx_text ltx_font_bold">ASR</span></th>
<th id="S4.T1.3.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.3.3.4.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.3.3.4.1.3.1.1" class="ltx_tr">
<td id="S4.T1.3.3.4.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.4.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr id="S4.T1.3.3.4.1.3.1.2" class="ltx_tr">
<td id="S4.T1.3.3.4.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.4.1.3.1.2.1.1" class="ltx_text ltx_font_bold">SSIM</span></td>
</tr>
</table>
</th>
<th id="S4.T1.3.3.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.3.3.4.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.3.3.4.1.4.1.1" class="ltx_tr">
<td id="S4.T1.3.3.4.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.4.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr id="S4.T1.3.3.4.1.4.1.2" class="ltx_tr">
<td id="S4.T1.3.3.4.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.4.1.4.1.2.1.1" class="ltx_text ltx_font_bold">MSE</span></td>
</tr>
</table>
</th>
<th id="S4.T1.3.3.4.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.3.3.4.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.3.3.4.1.5.1.1" class="ltx_tr">
<td id="S4.T1.3.3.4.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.4.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Avg, Duration</span></td>
</tr>
<tr id="S4.T1.3.3.4.1.5.1.2" class="ltx_tr">
<td id="S4.T1.3.3.4.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.4.1.5.1.2.1.1" class="ltx_text ltx_font_bold">per Image (in seconds)</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<table id="S4.T1.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.1.1.1.2.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Melanoma Skin Cancer</span></td>
</tr>
</table>
</td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49<math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</td>
<td id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0762</td>
<td id="S4.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.847</td>
</tr>
<tr id="S4.T1.2.2.2" class="ltx_tr">
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<table id="S4.T1.2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.2.2.2.2.1.1" class="ltx_tr">
<td id="S4.T1.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">COVID-19 X-ray Images</span></td>
</tr>
</table>
</td>
<td id="S4.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55<math id="S4.T1.2.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.2.2.2.1.m1.1a"><mo id="S4.T1.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S4.T1.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.1.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.55</td>
<td id="S4.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0641</td>
<td id="S4.T1.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.245</td>
</tr>
<tr id="S4.T1.3.3.3" class="ltx_tr">
<td id="S4.T1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<table id="S4.T1.3.3.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.3.3.3.2.1.1" class="ltx_tr">
<td id="S4.T1.3.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.3.3.3.2.1.1.1.1" class="ltx_text ltx_font_bold">Brain Tumor MRI Scans</span></td>
</tr>
</table>
</td>
<td id="S4.T1.3.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">76<math id="S4.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.3.3.3.1.m1.1a"><mo id="S4.T1.3.3.3.1.m1.1.1" xref="S4.T1.3.3.3.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S4.T1.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.1.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.75</td>
<td id="S4.T1.3.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.0586</td>
<td id="S4.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">103.12</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2311.06643/assets/skin_attack.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="286" height="60" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>CPL attack on Melanoma Skin Cancer Dataset</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2311.06643/assets/covid_X_ray_attack.png" id="S4.F4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="286" height="60" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>CPL attack on COVID X-ray Images Dataset</figcaption>
</figure>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.3" class="ltx_p"><span id="S4.p4.3.1" class="ltx_text ltx_font_bold">Performance of Attack Methods.</span>
We show the performance comparison of the CPL attack framework on different medical image datasets in TableÂ <a href="#S4.T1" title="TABLE I â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> for randomly sampled 100 images. We observe that the SSIM measures (in the 3rd column) are 0.5, 0.55, and 0.75 for Skin Cancer dataset, COVID-19 dataset, and Brain MRI dataset respectively. When computing ASR, an SSIM value of 0.9 or higher between the original private images and the attack-reconstructed image has been considered as a successful attack for all methods in this study. From the ASR values (2nd column) we observe that around 50<math id="S4.p4.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.p4.1.m1.1a"><mo id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><csymbol cd="latexml" id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">\%</annotation></semantics></math> 55<math id="S4.p4.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.p4.2.m2.1a"><mo id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><csymbol cd="latexml" id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">\%</annotation></semantics></math> and 75<math id="S4.p4.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.p4.3.m3.1a"><mo id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.1b"><csymbol cd="latexml" id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.1c">\%</annotation></semantics></math> images have been reconstructed successfully for the Skin Cancer dataset, COVID-19 dataset, and Brain MRI dataset respectively. We also compare their execution time to perform the privacy attacks in all cases (5th column in Table <a href="#S4.T1" title="TABLE I â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>). FigureÂ <a href="#S4.F4" title="Figure 4 â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Â <a href="#S4.F4" title="Figure 4 â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>
visually show the intermediate reconstructed images by a successful CPL attack on Skin Cancer and COVID-19 datasets for 200 iterations respectively, where the private medical images can be accurately reconstructed with a very small noise.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Performance Comparison of three attack methods on Melanoma Skin Cancer dataset for 100 images.</figcaption>
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.2.3.1" class="ltx_tr">
<th id="S4.T2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.2.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Method</span></th>
<th id="S4.T2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.2.3.1.2.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Model</span></th>
<th id="S4.T2.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.2.3.1.3.1" class="ltx_text ltx_font_bold" style="font-size:50%;">ASR</span></th>
<th id="S4.T2.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T2.2.3.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.3.1.4.1.1" class="ltx_tr">
<td id="S4.T2.2.3.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.3.1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Avg.</span></td>
</tr>
<tr id="S4.T2.2.3.1.4.1.2" class="ltx_tr">
<td id="S4.T2.2.3.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.3.1.4.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">SSIM</span></td>
</tr>
</table>
</th>
<th id="S4.T2.2.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T2.2.3.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.3.1.5.1.1" class="ltx_tr">
<td id="S4.T2.2.3.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.3.1.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Avg.</span></td>
</tr>
<tr id="S4.T2.2.3.1.5.1.2" class="ltx_tr">
<td id="S4.T2.2.3.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.3.1.5.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">MSE</span></td>
</tr>
</table>
</th>
<th id="S4.T2.2.3.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T2.2.3.1.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.3.1.6.1.1" class="ltx_tr">
<td id="S4.T2.2.3.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.3.1.6.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Avg, Duration</span></td>
</tr>
<tr id="S4.T2.2.3.1.6.1.2" class="ltx_tr">
<td id="S4.T2.2.3.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.3.1.6.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">per Image (in seconds)</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.2.4.1" class="ltx_tr">
<td id="S4.T2.2.4.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.2.4.1.1.1" class="ltx_text" style="font-size:50%;">
<span id="S4.T2.2.4.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T2.2.4.1.1.1.1.1" class="ltx_tr">
<span id="S4.T2.2.4.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">GradInv</span></span>
</span></span></td>
<td id="S4.T2.2.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T2.2.4.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.4.1.2.1.1" class="ltx_tr">
<td id="S4.T2.2.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.4.1.2.1.1.1.1" class="ltx_text" style="font-size:50%;">ResNet-18 Untrained</span></td>
</tr>
</table>
</td>
<td id="S4.T2.2.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.4.1.3.1" class="ltx_text" style="font-size:50%;">62%</span></td>
<td id="S4.T2.2.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.4.1.4.1" class="ltx_text" style="font-size:50%;">0.9029</span></td>
<td id="S4.T2.2.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.4.1.5.1" class="ltx_text" style="font-size:50%;">0.9434</span></td>
<td id="S4.T2.2.4.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.4.1.6.1" class="ltx_text" style="font-size:50%;">6019.84</span></td>
</tr>
<tr id="S4.T2.2.5.2" class="ltx_tr">
<td id="S4.T2.2.5.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T2.2.5.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.5.2.1.1.1" class="ltx_tr">
<td id="S4.T2.2.5.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.5.2.1.1.1.1.1" class="ltx_text" style="font-size:50%;">ResNet-18 Trained</span></td>
</tr>
<tr id="S4.T2.2.5.2.1.1.2" class="ltx_tr">
<td id="S4.T2.2.5.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.2.5.2.1.1.2.1.1" class="ltx_text" style="font-size:50%;">with ImageNet</span></td>
</tr>
</table>
</td>
<td id="S4.T2.2.5.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.5.2.2.1" class="ltx_text ltx_font_bold" style="font-size:50%;">82%</span></td>
<td id="S4.T2.2.5.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.5.2.3.1" class="ltx_text ltx_font_bold" style="font-size:50%;">0.9271</span></td>
<td id="S4.T2.2.5.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.5.2.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">0.8027</span></td>
<td id="S4.T2.2.5.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.5.2.5.1" class="ltx_text ltx_font_bold" style="font-size:50%;">4880.58</span></td>
</tr>
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.1.1.2.1" class="ltx_text" style="font-size:50%;">CPL</span></td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.3.1" class="ltx_text" style="font-size:50%;">CNN</span></td>
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T2.1.1.1.1" class="ltx_text" style="font-size:50%;">49</span><math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mo mathsize="50%" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.4.1" class="ltx_text" style="font-size:50%;">0.50</span></td>
<td id="S4.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.5.1" class="ltx_text" style="font-size:50%;">0.0762</span></td>
<td id="S4.T2.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.6.1" class="ltx_text" style="font-size:50%;">50.847</span></td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.2.2.2.1" class="ltx_text" style="font-size:50%;">DLG</span></td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.2.3.1" class="ltx_text" style="font-size:50%;">CNN</span></td>
<td id="S4.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.1.1" class="ltx_text" style="font-size:50%;">47</span><math id="S4.T2.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T2.2.2.1.m1.1a"><mo mathsize="50%" id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><csymbol cd="latexml" id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.2.4.1" class="ltx_text" style="font-size:50%;">0.48</span></td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.2.5.1" class="ltx_text" style="font-size:50%;">0.0957</span></td>
<td id="S4.T2.2.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.2.6.1" class="ltx_text" style="font-size:50%;">60.128</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">We also compare GradInv on the Skin Cancer dataset on randomly sampled 100 images for both ResNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> trained and untrained versions with CPL and DLG attacks. We show the performance of GradInv in the first two rows of TableÂ <a href="#S4.T2" title="TABLE II â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. We observed that the performance of GradInv is better on the trained ResNet-18 than the untrained one in terms of all evaluation metrics (higher ASR, higher SSIM, and lower MSE). The GradInv attack on the trained ResNet-18 also takes less time to reconstruct the original private medical images than the untrained ResNet-18. FigureÂ <a href="#S4.F5" title="Figure 5 â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> visually demonstrates the attack performance by the GradInv on Melanoma Skin Cancer Dataset for 24,000 iterations which supports our observations from TableÂ <a href="#S4.T2" title="TABLE II â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Comparing the performance of CPL and DLG (bottom two rows in Table <a href="#S4.T2" title="TABLE II â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>), we observe that GradInv can reconstruct high-quality images by analyzing the models which are well-trained, such as trained ResNet-18. Though GradInv takes much longer time than CPL and DLG, the performance is much better in terms of reconstruction quality as evaluated by ASR, SSIM and MSE.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2311.06643/assets/x3.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="164" height="84" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>GradInv attack recovered images by untrained and trained ResNet-18
</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>CPL attack and defense performance for different noise levels on three benchmark datasets.</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:269.0pt;height:218.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-44.8pt,36.4pt) scale(0.75,0.75) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2" rowspan="2"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">CPL Attack</span></td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Defense</span></td>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<td id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.2.1.1" class="ltx_text ltx_font_bold">MSE</span></td>
<td id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.2.2.1" class="ltx_text ltx_font_bold">SSIM</span></td>
<td id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.2.2.3.1.1" class="ltx_tr">
<td id="S4.T3.1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.2.2.3.1.1.1.1" class="ltx_text ltx_font_bold">Noise</span></td>
</tr>
<tr id="S4.T3.1.1.2.2.3.1.2" class="ltx_tr">
<td id="S4.T3.1.1.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.2.2.3.1.2.1.1" class="ltx_text ltx_font_bold">Levels</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.2.4.1" class="ltx_text ltx_font_bold">MSE</span></td>
<td id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.2.5.1" class="ltx_text ltx_font_bold">SSIM</span></td>
</tr>
<tr id="S4.T3.1.1.3.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">1.</td>
<td id="S4.T3.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Melanoma Skin Cancer</td>
<td id="S4.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0762</td>
<td id="S4.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</td>
<td id="S4.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.3.3.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.3.3.5.1.1" class="ltx_tr">
<td id="S4.T3.1.1.3.3.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">100</td>
</tr>
<tr id="S4.T3.1.1.3.3.5.1.2" class="ltx_tr">
<td id="S4.T3.1.1.3.3.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">200</td>
</tr>
<tr id="S4.T3.1.1.3.3.5.1.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">300</td>
</tr>
<tr id="S4.T3.1.1.3.3.5.1.4" class="ltx_tr">
<td id="S4.T3.1.1.3.3.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.3.3.5.1.4.1.1" class="ltx_text ltx_font_bold">400</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.3.3.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.3.3.6.1.1" class="ltx_tr">
<td id="S4.T3.1.1.3.3.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">0.1306</td>
</tr>
<tr id="S4.T3.1.1.3.3.6.1.2" class="ltx_tr">
<td id="S4.T3.1.1.3.3.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">0.1468</td>
</tr>
<tr id="S4.T3.1.1.3.3.6.1.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">0.1497</td>
</tr>
<tr id="S4.T3.1.1.3.3.6.1.4" class="ltx_tr">
<td id="S4.T3.1.1.3.3.6.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.3.3.6.1.4.1.1" class="ltx_text ltx_font_bold">0.1503</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.3.3.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.3.3.7.1.1" class="ltx_tr">
<td id="S4.T3.1.1.3.3.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0154</td>
</tr>
<tr id="S4.T3.1.1.3.3.7.1.2" class="ltx_tr">
<td id="S4.T3.1.1.3.3.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0131</td>
</tr>
<tr id="S4.T3.1.1.3.3.7.1.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0121</td>
</tr>
<tr id="S4.T3.1.1.3.3.7.1.4" class="ltx_tr">
<td id="S4.T3.1.1.3.3.7.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.3.3.7.1.4.1.1" class="ltx_text ltx_font_bold">0.0101</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.1.1.4.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">2.</td>
<td id="S4.T3.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">COVID X-ray Images</td>
<td id="S4.T3.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0641</td>
<td id="S4.T3.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.55</td>
<td id="S4.T3.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.4.4.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.4.4.5.1.1" class="ltx_tr">
<td id="S4.T3.1.1.4.4.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">100</td>
</tr>
<tr id="S4.T3.1.1.4.4.5.1.2" class="ltx_tr">
<td id="S4.T3.1.1.4.4.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">200</td>
</tr>
<tr id="S4.T3.1.1.4.4.5.1.3" class="ltx_tr">
<td id="S4.T3.1.1.4.4.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">300</td>
</tr>
<tr id="S4.T3.1.1.4.4.5.1.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.4.4.5.1.4.1.1" class="ltx_text ltx_font_bold">400</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.4.4.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.4.4.6.1.1" class="ltx_tr">
<td id="S4.T3.1.1.4.4.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0013</td>
</tr>
<tr id="S4.T3.1.1.4.4.6.1.2" class="ltx_tr">
<td id="S4.T3.1.1.4.4.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0157</td>
</tr>
<tr id="S4.T3.1.1.4.4.6.1.3" class="ltx_tr">
<td id="S4.T3.1.1.4.4.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0206</td>
</tr>
<tr id="S4.T3.1.1.4.4.6.1.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.6.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.4.4.6.1.4.1.1" class="ltx_text ltx_font_bold">0.0578</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.4.4.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.4.4.7.1.1" class="ltx_tr">
<td id="S4.T3.1.1.4.4.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">0.9815</td>
</tr>
<tr id="S4.T3.1.1.4.4.7.1.2" class="ltx_tr">
<td id="S4.T3.1.1.4.4.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">0.7410</td>
</tr>
<tr id="S4.T3.1.1.4.4.7.1.3" class="ltx_tr">
<td id="S4.T3.1.1.4.4.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">0.7000</td>
</tr>
<tr id="S4.T3.1.1.4.4.7.1.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.7.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.4.4.7.1.4.1.1" class="ltx_text ltx_font_bold">0.4605</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.1.1.5.5" class="ltx_tr">
<td id="S4.T3.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">3.</td>
<td id="S4.T3.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Brain Tumor MRI Scans</td>
<td id="S4.T3.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.0586</td>
<td id="S4.T3.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.75</td>
<td id="S4.T3.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.5.5.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.5.5.5.1.1" class="ltx_tr">
<td id="S4.T3.1.1.5.5.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">100</td>
</tr>
<tr id="S4.T3.1.1.5.5.5.1.2" class="ltx_tr">
<td id="S4.T3.1.1.5.5.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">200</td>
</tr>
<tr id="S4.T3.1.1.5.5.5.1.3" class="ltx_tr">
<td id="S4.T3.1.1.5.5.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">300</td>
</tr>
<tr id="S4.T3.1.1.5.5.5.1.4" class="ltx_tr">
<td id="S4.T3.1.1.5.5.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.5.5.5.1.4.1.1" class="ltx_text ltx_font_bold">400</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.5.5.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.5.5.6.1.1" class="ltx_tr">
<td id="S4.T3.1.1.5.5.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0207</td>
</tr>
<tr id="S4.T3.1.1.5.5.6.1.2" class="ltx_tr">
<td id="S4.T3.1.1.5.5.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0686</td>
</tr>
<tr id="S4.T3.1.1.5.5.6.1.3" class="ltx_tr">
<td id="S4.T3.1.1.5.5.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">0.0300</td>
</tr>
<tr id="S4.T3.1.1.5.5.6.1.4" class="ltx_tr">
<td id="S4.T3.1.1.5.5.6.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.5.5.6.1.4.1.1" class="ltx_text ltx_font_bold">0.1705</span></td>
</tr>
</table>
</td>
<td id="S4.T3.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<table id="S4.T3.1.1.5.5.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.5.5.7.1.1" class="ltx_tr">
<td id="S4.T3.1.1.5.5.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">0.6657</td>
</tr>
<tr id="S4.T3.1.1.5.5.7.1.2" class="ltx_tr">
<td id="S4.T3.1.1.5.5.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">0.2383</td>
</tr>
<tr id="S4.T3.1.1.5.5.7.1.3" class="ltx_tr">
<td id="S4.T3.1.1.5.5.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">0.3661</td>
</tr>
<tr id="S4.T3.1.1.5.5.7.1.4" class="ltx_tr">
<td id="S4.T3.1.1.5.5.7.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.1.1.5.5.7.1.4.1.1" class="ltx_text ltx_font_bold">0.0699</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p id="S4.p6.1" class="ltx_p"><span id="S4.p6.1.1" class="ltx_text ltx_font_bold">Performance of Defense Mechanisms.</span>
The goal of defending privacy attacks is to maximize the dissimilarity (e.g., MSE) and minimize the similarity (e.g., SSIM) between the original training images and the attack reconstructed images. TableÂ <a href="#S4.T3" title="TABLE III â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, shows as we increase the level of Laplacian noise the defense becomes stronger. The addition of random noise to <math id="S4.p6.1.m1.2" class="ltx_Math" alttext="\nabla\theta(i,t)" display="inline"><semantics id="S4.p6.1.m1.2a"><mrow id="S4.p6.1.m1.2.3" xref="S4.p6.1.m1.2.3.cmml"><mrow id="S4.p6.1.m1.2.3.2" xref="S4.p6.1.m1.2.3.2.cmml"><mo rspace="0.167em" id="S4.p6.1.m1.2.3.2.1" xref="S4.p6.1.m1.2.3.2.1.cmml">âˆ‡</mo><mi id="S4.p6.1.m1.2.3.2.2" xref="S4.p6.1.m1.2.3.2.2.cmml">Î¸</mi></mrow><mo lspace="0em" rspace="0em" id="S4.p6.1.m1.2.3.1" xref="S4.p6.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.p6.1.m1.2.3.3.2" xref="S4.p6.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.p6.1.m1.2.3.3.2.1" xref="S4.p6.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.p6.1.m1.1.1" xref="S4.p6.1.m1.1.1.cmml">i</mi><mo id="S4.p6.1.m1.2.3.3.2.2" xref="S4.p6.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.p6.1.m1.2.2" xref="S4.p6.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S4.p6.1.m1.2.3.3.2.3" xref="S4.p6.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.2b"><apply id="S4.p6.1.m1.2.3.cmml" xref="S4.p6.1.m1.2.3"><times id="S4.p6.1.m1.2.3.1.cmml" xref="S4.p6.1.m1.2.3.1"></times><apply id="S4.p6.1.m1.2.3.2.cmml" xref="S4.p6.1.m1.2.3.2"><ci id="S4.p6.1.m1.2.3.2.1.cmml" xref="S4.p6.1.m1.2.3.2.1">âˆ‡</ci><ci id="S4.p6.1.m1.2.3.2.2.cmml" xref="S4.p6.1.m1.2.3.2.2">ğœƒ</ci></apply><interval closure="open" id="S4.p6.1.m1.2.3.3.1.cmml" xref="S4.p6.1.m1.2.3.3.2"><ci id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1">ğ‘–</ci><ci id="S4.p6.1.m1.2.2.cmml" xref="S4.p6.1.m1.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.2c">\nabla\theta(i,t)</annotation></semantics></math> increases the difficulty of extracting private information from the local gradients. FigureÂ <a href="#S4.F6" title="Figure 6 â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> visualizes the outcome of the defense mechanism for different noise levels for the COVID X-ray dataset. When the noise level is relatively low, such as 100, private information can still be extracted under the CPL attack (first row of FigureÂ <a href="#S4.F6" title="Figure 6 â€£ IV Experimental Analysis â€£ Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>), which indicates that adding random noise may not always provide adequate privacy protection for medical data in FL.
We found similar observations consistently for the other two medical datasets.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2311.06643/assets/x4.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="193" height="82" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Defense against CPL attack on COVID X-ray Dataset</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This paper introduces MedPFL, a framework for privacy risk analysis and mitigation in FL with medical images. We highlight the extensive privacy risks in processing medical data in FL, emphasizing the need for stronger defenses against adversarial attacks. We use different levels of random noise for defense, noting that while higher noise levels enhance privacy protection, they may not suffice. We demonstrate real-world scenarios of privacy attacks on medical images across benchmark datasets, which further illustrate the critical challenges of mitigating privacy risks in FL in the medical domain. Our future work will explore additional privacy attacks and innovative techniques to protect medical data in FL.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B.Â McMahan <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œCommunication-efficient learning of deep networks from decentralized data,â€ in <span id="bib.bib1.2.2" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pp.Â 1273â€“1282, PMLR, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
D.Â C. Nguyen <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œFederated learning for smart healthcare: A survey,â€ <span id="bib.bib2.2.2" class="ltx_text ltx_font_italic">ACM Computing Surveys (CSUR)</span>, vol.Â 55, no.Â 3, pp.Â 1â€“37, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
V.Â S. Cheng <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œHealth insurance portability and accountability act (HIPPA) compliant access control model for web services,â€ <span id="bib.bib3.2.2" class="ltx_text ltx_font_italic">International Journal of Healthcare Information Systems and Informatics (IJHISI)</span>, vol.Â 1, no.Â 1, pp.Â 22â€“39, 2006.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L.Â Zhu <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œDeep leakage from gradients,â€ <span id="bib.bib4.2.2" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, vol.Â 32, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J.Â Geiping <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œInverting gradients-how easy is it to break privacy in federated learning?,â€ <span id="bib.bib5.2.2" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, vol.Â 33, pp.Â 16937â€“16947, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
W.Â Wei <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œA framework for evaluating client privacy leakages in federated learning,â€ in <span id="bib.bib6.2.2" class="ltx_text ltx_font_italic">Computer Security-25th European Symposium on Research in Computer Security, ESORICS 2020, Guildford, UK, September 14â€“18, 2020, Proceedings, Part I 25</span>, pp.Â 545â€“566, Springer, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
W.Â Wei <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œGradient-leakage resilient federated learning,â€ in <span id="bib.bib7.2.2" class="ltx_text ltx_font_italic">2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS)</span>, pp.Â 797â€“807, IEEE, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
P.Â Liu, X.Â Xu, and W.Â Wang, â€œThreats, attacks and defenses to federated learning: issues, taxonomy and perspectives,â€ <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Cybersecurity</span>, vol.Â 5, no.Â 1, pp.Â 1â€“19, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M.Â E. Dahlgaard <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œAnalysing the influence of attack configurations on the reconstruction of medical images in federated learning,â€ <span id="bib.bib9.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2204.13808</span>, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
W.Â Wei <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œSecuring distributed SGD against gradient leakage threats,â€ <span id="bib.bib10.2.2" class="ltx_text ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</span>, vol.Â 34, no.Â 7, pp.Â 2040â€“2054, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
W.Â Wei, K.-H. Chow, F.Â Ilhan, Y.Â Wu, and L.Â Liu, â€œModel cloaking against gradient leakage,â€ in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">2023 IEEE International Conference on Data Mining (ICDM)</span>, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M.Â Abadi <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œDeep learning with differential privacy,â€ in <span id="bib.bib12.2.2" class="ltx_text ltx_font_italic">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</span>, pp.Â 308â€“318, 2016.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
L.Â Melis <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œEfficient private statistics with succinct sketches,â€ <span id="bib.bib13.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1508.06110</span>, 2015.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G.Â A. Kaissis <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œSecure, privacy-preserving and federated machine learning in medical imaging,â€ <span id="bib.bib14.2.2" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, vol.Â 2, no.Â 6, pp.Â 305â€“311, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y.Â LeCun <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œGradient-based learning applied to document recognition,â€ <span id="bib.bib15.2.2" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, vol.Â 86, no.Â 11, pp.Â 2278â€“2324, 1998.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
K.Â He <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œDeep residual learning for image recognition,â€ in <span id="bib.bib16.2.2" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</span>, pp.Â 770â€“778, 2016.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
O.Â Goldreich, â€œSecure multi-party computation,â€ <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Manuscript. Preliminary version</span>, vol.Â 78, no.Â 110, 1998.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
X.Â Li <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œMulti-site fmri analysis using privacy-preserving federated learning and domain adaptation: Abide results,â€ <span id="bib.bib18.2.2" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, vol.Â 65, p.Â 101765, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A.Â Nilsson <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œA performance evaluation of federated learning algorithms,â€ in <span id="bib.bib19.2.2" class="ltx_text ltx_font_italic">Proceedings of the second workshop on distributed infrastructures for deep learning</span>, pp.Â 1â€“8, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D.Â Cynthia, â€œDifferential privacy in automata, languages and programming, bugliesi michele, preneel bart, sassone vladimiro, and wegener ingo,â€ 2006.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.06642" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.06643" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.06643">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.06643" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.06644" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 19:21:48 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
