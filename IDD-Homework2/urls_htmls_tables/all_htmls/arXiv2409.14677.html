<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections</title>
<!--Generated on Mon Sep 23 02:56:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.14677v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S1" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S2" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span> SynMirror: A synthetic dataset of mirror reflections</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.SS1" title="In 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset Generation and Processing</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.SS1.SSS0.Px1" title="In 3.1 Dataset Generation and Processing ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title">Object Source.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS1" title="In 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Preliminaries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2" title="In 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>MirrorFusion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS1" title="In 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Model architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS2" title="In 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Depth conditioning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS3" title="In 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Depth Normalization</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments &amp; Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.SS1" title="In 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Qualitative Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.SS1.SSS0.Px1" title="In 5.1 Qualitative Results ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title">Comparison with Zero-shot Baselines.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.SS2" title="In 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Ablation studies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S6" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.SS1" title="In Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Filtering out Spurious objects</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.SS2" title="In Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Preparation of MirrorBench</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2.SS1" title="In Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Training Details: MirrorFusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2.SS2" title="In Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Training Details for Baseline Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2.SS3" title="In Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Inference Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS1" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>More Results on Google Scanned Objects (GSO)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS2" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Results on real-world scenes.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS3" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Comparison with Commercial Products.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS4" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.4 </span>Robustness to pre-trained monocular depth estimation methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS5" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.5 </span>More Qualitative Comparisons</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A4" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Limitations and Social Impact</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS1" title="In Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Results from recent T2I methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS2" title="In Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Text prompts used in the experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS3" title="In Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.3 </span>Generation of Segmentation Masks for computing metrics</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">
Reflecting Reality: Enabling Diffusion Models to Produce
<br class="ltx_break"/>Faithful Mirror Reflections
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ankit Dhiman<sup class="ltx_sup" id="id14.10.id1"><span class="ltx_text ltx_font_italic" id="id14.10.id1.1">1,2</span></sup>  Manan Shah<sup class="ltx_sup" id="id15.11.id2"><span class="ltx_text ltx_font_italic" id="id15.11.id2.1">1</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>  Rishubh Parihar<sup class="ltx_sup" id="id16.12.id3">1</sup>  Yash Bhalgat<sup class="ltx_sup" id="id17.13.id4">3</sup>
<br class="ltx_break"/>Lokesh R Boregowda<sup class="ltx_sup" id="id18.14.id5">2</sup>  R Venkatesh Babu<sup class="ltx_sup" id="id19.15.id6">1</sup>
<br class="ltx_break"/>
<br class="ltx_break"/><sup class="ltx_sup" id="id20.16.id7">1</sup>Vision and AI Lab, IISc Bangalore  <sup class="ltx_sup" id="id21.17.id8">2</sup>Samsung R &amp; D Institute India - Bangalore  
<br class="ltx_break"/><sup class="ltx_sup" id="id22.18.id9">3</sup>Visual Geometry Group, University of Oxford
</span><span class="ltx_author_notes"></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.2">We tackle the problem of generating highly realistic and plausible mirror reflections using diffusion-based generative models. We formulate this problem as an image inpainting task, allowing for more user control over the placement of mirrors during the generation process. To enable this, we create SynMirror, a large-scale dataset of diverse synthetic scenes with objects placed in front of mirrors. SynMirror contains around <math alttext="198K" class="ltx_Math" display="inline" id="id10.1.m1.1"><semantics id="id10.1.m1.1a"><mrow id="id10.1.m1.1.1" xref="id10.1.m1.1.1.cmml"><mn id="id10.1.m1.1.1.2" xref="id10.1.m1.1.1.2.cmml">198</mn><mo id="id10.1.m1.1.1.1" xref="id10.1.m1.1.1.1.cmml">⁢</mo><mi id="id10.1.m1.1.1.3" xref="id10.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="id10.1.m1.1b"><apply id="id10.1.m1.1.1.cmml" xref="id10.1.m1.1.1"><times id="id10.1.m1.1.1.1.cmml" xref="id10.1.m1.1.1.1"></times><cn id="id10.1.m1.1.1.2.cmml" type="integer" xref="id10.1.m1.1.1.2">198</cn><ci id="id10.1.m1.1.1.3.cmml" xref="id10.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id10.1.m1.1c">198K</annotation><annotation encoding="application/x-llamapun" id="id10.1.m1.1d">198 italic_K</annotation></semantics></math> samples rendered from <math alttext="66K" class="ltx_Math" display="inline" id="id11.2.m2.1"><semantics id="id11.2.m2.1a"><mrow id="id11.2.m2.1.1" xref="id11.2.m2.1.1.cmml"><mn id="id11.2.m2.1.1.2" xref="id11.2.m2.1.1.2.cmml">66</mn><mo id="id11.2.m2.1.1.1" xref="id11.2.m2.1.1.1.cmml">⁢</mo><mi id="id11.2.m2.1.1.3" xref="id11.2.m2.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="id11.2.m2.1b"><apply id="id11.2.m2.1.1.cmml" xref="id11.2.m2.1.1"><times id="id11.2.m2.1.1.1.cmml" xref="id11.2.m2.1.1.1"></times><cn id="id11.2.m2.1.1.2.cmml" type="integer" xref="id11.2.m2.1.1.2">66</cn><ci id="id11.2.m2.1.1.3.cmml" xref="id11.2.m2.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.2.m2.1c">66K</annotation><annotation encoding="application/x-llamapun" id="id11.2.m2.1d">66 italic_K</annotation></semantics></math> unique 3D objects, along with their associated depth maps, normal maps and instance-wise segmentation masks, to capture relevant geometric properties of the scene. Using this dataset, we propose a novel depth-conditioned inpainting method called <em class="ltx_emph ltx_font_italic" id="id11.2.1">MirrorFusion</em>, which generates high-quality geometrically consistent and photo-realistic mirror reflections given an input image and a mask depicting the mirror region. <em class="ltx_emph ltx_font_italic" id="id11.2.2">MirrorFusion</em> outperforms state-of-the-art methods on SynMirror, as demonstrated by extensive quantitative and qualitative analysis. To the best of our knowledge, we are the first to successfully tackle the challenging problem of generating controlled and faithful mirror reflections of an object in a scene using diffusion based models. SynMirror and <em class="ltx_emph ltx_font_italic" id="id11.2.3">MirrorFusion</em> open up new avenues for image editing and augmented reality applications for practitioners and researchers alike. The project page is available at: <a class="ltx_ref ltx_href" href="https://val.cds.iisc.ac.in/reflecting-reality.github.io/" title="">https://val.cds.iisc.ac.in/reflecting-reality.github.io/</a>.</p>
</div>
<div class="ltx_logical-block" id="id13">
<div class="ltx_para" id="id13.p1">
<img alt="[Uncaptioned image]" class="ltx_graphics ltx_centering ltx_img_landscape" height="455" id="id12.g1" src="x1.png" width="932"/>
</div>
<figure class="ltx_figure ltx_align_center" id="S0.F1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S0.F1.4.2" style="font-size:90%;">
We present MirrorFusion, a diffusion-based inpainting model, which generates high-quality geometrically consistent and photo-realistic mirror reflections given an input image and a mask depicting the mirror region. Our method shows superior quality generations as compared to previous state-of-the-art diffusion-based text-to-image and inpainting methods. All the images were generated by prefixing the mirror text prompt: <span class="ltx_text ltx_inline-quote ltx_outerquote" id="S0.F1.4.2.1">“A perfect plain mirror reflection of ”</span> to the input object description.
</span></figcaption>
</figure>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span>*Equal Contribution.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent diffusion-based generative models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">38</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">46</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite> have achieved remarkable results, producing visually appealing images across various domains. These models can be conditioned using several modalities, such as text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>, depth-image <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>, sketch <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>, for controlled generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib59" title=""><span class="ltx_text" style="font-size:90%;">59</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib56" title=""><span class="ltx_text" style="font-size:90%;">56</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib61" title=""><span class="ltx_text" style="font-size:90%;">61</span></a>]</cite>, enabling various interesting applications. Despite their success, these models struggle to capture subtle geometric cues such as shadows, lighting and specular reflections, as noted in previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">44</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite>. Specifically, the task of generating realistic and controllable mirror reflections remains an unsolved challenge. Existing methods, which tackle perspective issues <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib61" title=""><span class="ltx_text" style="font-size:90%;">61</span></a>]</cite> and address specular reflections for object removal <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite> do not address mirror reflections in particular.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To illustrate this limitation, we prompt Stable Diffusion-2.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> with the instruction to generate a scene with a mirror reflection. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">2</span></a> shows that Stable Diffusion-2.1 fails to generate plausible and consistent mirror reflections. Further, various state-of-the-art inpainting methods such as Stable Diffusion Inpainting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> and PowerPaint <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib64" title=""><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite> also fail at the task of generating plausible and controlled reflections, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S0.F1" title="Figure 1 ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a> (b) &amp; (c).</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we pose the problem of generating mirror reflections as an <em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">Image Inpainting task</em>. This formulation provides two distinctive advantages: (1) Posing it as an inpainting method aids the reflection generation process to take cues from the input image and (2) allow greater control on the placement of mirrors.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.2">Existing datasets for tasks such as mirror segmentation, detection or novel-view synthesis as shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.T1" title="Table 1 ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a> contain mirrors reflecting generic backgrounds and also lack the scale making them unsuitable for the task of training generative models for generating photo-realistic mirror reflections. Therefore, to address this, we introduce SynMirror, a training dataset and MirrorBench, a benchmark dataset designed to train and evaluate the capability of generative models to produce photo-realistic mirror reflections.SynMirror contains <math alttext="198,204" class="ltx_Math" display="inline" id="S1.p4.1.m1.2"><semantics id="S1.p4.1.m1.2a"><mrow id="S1.p4.1.m1.2.3.2" xref="S1.p4.1.m1.2.3.1.cmml"><mn id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">198</mn><mo id="S1.p4.1.m1.2.3.2.1" xref="S1.p4.1.m1.2.3.1.cmml">,</mo><mn id="S1.p4.1.m1.2.2" xref="S1.p4.1.m1.2.2.cmml">204</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.2b"><list id="S1.p4.1.m1.2.3.1.cmml" xref="S1.p4.1.m1.2.3.2"><cn id="S1.p4.1.m1.1.1.cmml" type="integer" xref="S1.p4.1.m1.1.1">198</cn><cn id="S1.p4.1.m1.2.2.cmml" type="integer" xref="S1.p4.1.m1.2.2">204</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.2c">198,204</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.2d">198 , 204</annotation></semantics></math> samples from rendering <math alttext="66,068" class="ltx_Math" display="inline" id="S1.p4.2.m2.2"><semantics id="S1.p4.2.m2.2a"><mrow id="S1.p4.2.m2.2.3.2" xref="S1.p4.2.m2.2.3.1.cmml"><mn id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">66</mn><mo id="S1.p4.2.m2.2.3.2.1" xref="S1.p4.2.m2.2.3.1.cmml">,</mo><mn id="S1.p4.2.m2.2.2" xref="S1.p4.2.m2.2.2.cmml">068</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.2b"><list id="S1.p4.2.m2.2.3.1.cmml" xref="S1.p4.2.m2.2.3.2"><cn id="S1.p4.2.m2.1.1.cmml" type="integer" xref="S1.p4.2.m2.1.1">66</cn><cn id="S1.p4.2.m2.2.2.cmml" type="integer" xref="S1.p4.2.m2.2.2">068</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.2c">66,068</annotation><annotation encoding="application/x-llamapun" id="S1.p4.2.m2.2d">66 , 068</annotation></semantics></math> unique 3D objects sourced from Objaverse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> and Amazon Berkeley Objects (ABO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Samples from SynMirror are created by rendering synthetic scenes with objects placed in front of a mirror using the cycles rendering engine from Blender. To further obtain instance segmentation, depth and normal maps, we utilize <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.1">Blenderproc</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>, a procedural Blender pipeline for photorealistic rendering. The generated scenes have diverse mirrors, floor textures and backgrounds.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">When recent inpainting methods such as BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> are fine-tuned on SynMirror, we observe that they fail in generating correct geometry and depth of an object in the mirror reflection as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F7" title="Figure 7 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">7</span></a>.
We hypothesize that providing additional cues, such as depth maps, could help to alleviate the issue in generating geometrically consistent reflections on the mirror. To this end, we propose <em class="ltx_emph ltx_font_italic" id="S1.p6.1.1">MirrorFusion</em>, a depth conditioned inpainting method that generates high-quality controlled and photo-realistic mirror reflections. Our method significantly outperforms state-of-the-art diffusion-based inpainting methods on SynMirror, as evidenced by extensive quantitative and qualitative evaluations.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">We summarize our contributions below:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">To the best of our knowledge, we are the first to address and tackle the challenging problem of generating controlled photo-realistic and geometrically consistent mirror reflections of objects using diffusion models by formulating it as an image inpainting task.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">For this purpose, we present <em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.1">SynMirror</em>, a large-scale synthetic dataset of objects with accurate mirror reflections. We also create MirrorBench, a subset of <em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.2">SynMirror</em>, for benchmarking the capabilities of generative models in generating photo-realistic mirror reflections of diverse objects.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We further propose <em class="ltx_emph ltx_font_italic" id="S1.I1.i3.p1.1.1">MirrorFusion</em>, a novel depth conditioned inpainting method, which produces photo-realistic and controlled mirror reflections in the masked region of an input image, when trained on <em class="ltx_emph ltx_font_italic" id="S1.I1.i3.p1.1.2">SynMirror</em>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Diffusion based generative models.</span> Diffusion-based models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> have revolutionized the field of image synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite>. These generative models are further extended to other modalities such as video <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">12</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib45" title=""><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>, audio <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>and text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>.
Further, text-to-image(T2I) models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">40</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">36</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite> have the capability to generate photo-realistic images with any arbitrary text prompt.
However, these methods do not work for generating realistic reflections, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="380" id="S2.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.3.2" style="font-size:90%;">Images generated from Stable Diffusion 2.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite>. Text-to-image models, when prompted to generate reflections, struggle to generate consistent and controlled mirror reflections.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Image inpainting methods.</span> Recent advancements in diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite> have led to significant progress in the inpainting task. Diffusion based inpainting methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">28</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">1</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib58" title=""><span class="ltx_text" style="font-size:90%;">58</span></a>]</cite> have shown tremendous improvement in this task compared to GAN based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">26</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">63</span></a>]</cite>. A common approach to inpaint with diffusion models involves modifying the standard denoising strategy: sampling masked regions from a pre-trained diffusion model and unmasked areas from the given image. While this method produces satisfactory results, it does not generalize to complex scenes and shapes. Stable Diffusion Inpainting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> fine-tunes a diffusion model by taking the noisy latents, mask and masked image as inputs to the U-Net architecture. Methods like HD-Painter <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> further enhance this method. A recent method, BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>, divides the masked image features and noisy latents into separate branches, which increases textual coherence and improves masked image preservation. We show in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S0.F1" title="Figure 1 ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a> that these methods do not perform well for generating reflections on the mirror.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Reflection in vision tasks.</span> Reflection has been extensively explored for image enhancement tasks such as single image reflection removal <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib52" title=""><span class="ltx_text" style="font-size:90%;">52</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>. This task is ill-posed in nature and requires additional priors to be solved. Other methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">20</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite> use multiple images to solve this task. Specifically, they use polarization cues to remove reflection from the input image. Further, reflection cues are used to detect the glass/reflective surfaces in the real world <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">31</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>. Recently, PromptRR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> uses diffusion models for solving the single image reflection removal task. Further, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">34</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib57" title=""><span class="ltx_text" style="font-size:90%;">57</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite> solves the challenge of reconstructing mirror reflections in a 3D scene for the novel-view synthesis task. In this work, we attempt to solve the challenging task of generating controlled photo-realistic and geometrically consistent mirror reflections for an object in an input image, which has not been addressed in previous works to the best of our knowledge.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span> SynMirror: A synthetic dataset of mirror reflections</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We observe that state-of-the-art diffusion models struggle to generate geometrically consistent results for mirror reflections as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S0.F1" title="Figure 1 ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">2</span></a>. We hypothesize that the cause of this inferior performance is due to the limited number of samples of images with realistic mirror reflections in various existing datasets used to train these models. Further, we find that existing mirror datasets are inadequate for training generative models as they are primarily designed for reflective mirror detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> and lack object diversity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite>, which is required to incorporate the priors of mirror reflections in diffusion models. To address this, we propose SynMirror, a first-of-its-kind large-scale synthetic dataset on mirror reflections, with diverse <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">mirror types, objects, camera poses, HDRI backgrounds</span> and <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">floor textures</span>. We provide a comprehensive characteristic comparison of SynMirror with existing mirror datasets in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.T1" title="Table 1 ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a>. Note that SynMirror is more than six times larger than all the existing mirror datasets combined. Further, our data generation pipeline renders color images, instance segmentation masks, depth maps and normal maps as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.F3" title="Figure 3 ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Additionally, we create MirrorBench, a subset of SynMirror, which serves as a challenging benchmark for generative tasks on mirror reflections. SynMirror can also be leveraged to benchmark other downstream tasks such as monocular depth estimation and novel-view synthesis.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text ltx_font_bold" id="S3.T1.4.2" style="font-size:90%;">A comparison between SynMirror and other mirror datasets.<span class="ltx_text ltx_font_medium" id="S3.T1.4.2.1"> The proposed dataset has more attributes and is six times larger in size than all other existing datasets combined.</span></span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T1.5" style="width:550.3pt;height:163pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S3.T1.5.1"><span class="ltx_text" id="S3.T1.5.1.1">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.5.1.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="S3.T1.5.1.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.5.1.1.1.1.1.1">Dataset</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.5.1.1.1.1.1.2">Type</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.5.1.1.1.1.1.3">Size</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.5.1.1.1.1.1.4">Attributes</span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S3.T1.5.1.1.1.2.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.5.1.1.1.2.1.1">MSD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.1.1.1.2.1.2">Real</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.1.1.1.2.1.3">4018</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.1.1.1.2.1.4">RGB, Masks</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.3.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.5.1.1.1.3.2.1">Mirror-NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib57" title=""><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite></span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.3.2.2">Real &amp; Synthetic</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.3.2.3">9 scenes</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.3.2.4">RGB, Masks, Multi-View</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.4.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.5.1.1.1.4.3.1">DLSU-OMRS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite></span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.4.3.2">Real</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.4.3.3">454</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.4.3.4">RGB, Mask</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.5.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.5.1.1.1.5.4.1">TROSD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite></span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.5.4.2">Real</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.5.4.3">11060</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.5.4.4">RGB, Mask</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.6.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.5.1.1.1.6.5.1">PMD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite></span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.6.5.2">Real</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.6.5.3">6461</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.6.5.4">RGB, Masks</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.7.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.5.1.1.1.7.6.1">RGBD-Mirror <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite></span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.7.6.2">Real</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.7.6.3">3049</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.7.6.4">RGB, Depth</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.8.7">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.5.1.1.1.8.7.1">Mirror3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite></span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.8.7.2">Real</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.8.7.3">7011</span>
<span class="ltx_td ltx_align_center" id="S3.T1.5.1.1.1.8.7.4">RGB, Masks, Depth</span></span>
<span class="ltx_tr" id="S3.T1.5.1.1.1.9.8">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.5.1.1.1.9.8.1"><span class="ltx_text ltx_font_bold" id="S3.T1.5.1.1.1.9.8.1.1">SynMirror (Ours)</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.5.1.1.1.9.8.2">Synthetic</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.5.1.1.1.9.8.3"><span class="ltx_text ltx_font_bold" id="S3.T1.5.1.1.1.9.8.3.1">198204</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.5.1.1.1.9.8.4">RGB, Depth, Masks, Normals, Multi-View</span></span>
</span>
</span></span></p>
</span></div>
</figure>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="288" id="S3.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.4.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.5.2" style="font-size:90%;"> SynMirror: a) <span class="ltx_text ltx_font_bold" id="S3.F3.5.2.1">Dataset creation pipeline</span> - We sample diverse 3D objects, mirrors as 2D planes and diverse floor textures to compose a scene in a blender environment. To enhance realism, we sample high-quality HDRI environment maps as backgrounds. We sample cameras from varied viewpoints, capturing the mirror and the object, and use Blender to render RGB images and dense 2D annotations. b) <span class="ltx_text ltx_font_bold" id="S3.F3.5.2.2">Samples from SynMirror</span> - The generated scenes have complex geometry, textures, and high diversity. The renderings have accurate dense annotations for semantic, depth and normal maps at the original image resolution.</span></figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset Generation and Processing</h3>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Object Source.</h5>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.5">SynMirror consists of 3D assets from two widely used 3D object datasets - Objaverse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> and Amazon Berkeley Objects (ABO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite>. Objaverse is a large scale dataset consisting of <math alttext="800K" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">800</mn><mo id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1"><times id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1"></times><cn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2">800</cn><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">800K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.1.m1.1d">800 italic_K</annotation></semantics></math> 3D assets with diverse categories and ABO contains catalogued 3D models with complex geometries that correspond to real world household objects. However, some objects from Objaverse are poorly rendered or have low-quality textures. Thus, we use a filtered list of <math alttext="64K" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mn id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">64</mn><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><times id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1"></times><cn id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">64</cn><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">64K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.2.m2.1d">64 italic_K</annotation></semantics></math> 3D objects as filtered by OBJECT 3DIT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>. Despite this initial filtering, some <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p1.5.1">“spurious”</span> objects do not show mirror reflections pertaining to specific shader properties of objects. We elaborate on the filtering method to remove <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p1.5.2">“spurious”</span> objects in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.SS1" title="A.1 Filtering out Spurious objects ‣ Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">A.1</span></a>. Post filtering, we obtain a subset of <math alttext="58,115" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.3.m3.2"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.2a"><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.2.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.2.3.1.cmml"><mn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">58</mn><mo id="S3.SS1.SSS0.Px1.p1.3.m3.2.3.2.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px1.p1.3.m3.2.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.2.2.cmml">115</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.2b"><list id="S3.SS1.SSS0.Px1.p1.3.m3.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.2.3.2"><cn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1">58</cn><cn id="S3.SS1.SSS0.Px1.p1.3.m3.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.3.m3.2.2">115</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.2c">58,115</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.3.m3.2d">58 , 115</annotation></semantics></math> high-quality 3D assets from Objaverse.
We include all <math alttext="7,953" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.4.m4.2"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.2a"><mrow id="S3.SS1.SSS0.Px1.p1.4.m4.2.3.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.2.3.1.cmml"><mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">7</mn><mo id="S3.SS1.SSS0.Px1.p1.4.m4.2.3.2.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.2.3.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px1.p1.4.m4.2.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.2.2.cmml">953</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.2b"><list id="S3.SS1.SSS0.Px1.p1.4.m4.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.2.3.2"><cn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1">7</cn><cn id="S3.SS1.SSS0.Px1.p1.4.m4.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.4.m4.2.2">953</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.2c">7,953</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.4.m4.2d">7 , 953</annotation></semantics></math> objects from the ABO dataset to cover a wide range of object shapes and appearances, and thus resulting in <math alttext="66,068" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.5.m5.2"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.2a"><mrow id="S3.SS1.SSS0.Px1.p1.5.m5.2.3.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.2.3.1.cmml"><mn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml">66</mn><mo id="S3.SS1.SSS0.Px1.p1.5.m5.2.3.2.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.2.3.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px1.p1.5.m5.2.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.2.2.cmml">068</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.2b"><list id="S3.SS1.SSS0.Px1.p1.5.m5.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.2.3.2"><cn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">66</cn><cn id="S3.SS1.SSS0.Px1.p1.5.m5.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.5.m5.2.2">068</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.2c">66,068</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.5.m5.2d">66 , 068</annotation></semantics></math> total objects.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS0.Px1.p2.1.1">Scene Setting.</span>
We use a virtual environment in Blender to compose scenes with realistic reflections. We follow a set of heuristic rules to compose a scene with the 3D asset, a floor, and a mirror; an example is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.F3" title="Figure 3 ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3</span></a>. We model mirrors as rectangular planes of varying sizes and frame textures. The floor is modeled as a plane with a diverse set of textures sampled from <math alttext="1182" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p2.1.m1.1a"><mn id="S3.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p2.1.m1.1.1.cmml">1182</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p2.1.m1.1b"><cn id="S3.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p2.1.m1.1.1">1182</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p2.1.m1.1c">1182</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p2.1.m1.1d">1182</annotation></semantics></math> CC-textures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p3.3">We compose a scene, by first placing a mirror vertically at a fixed location. Next, we define a region at a fixed distance to the mirror where the 3D object will be placed, represented as a unit cube. We normalize the object to fit in the unit cube. We also rotate the 3D object around its <math alttext="y-axis" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p3.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p3.1.m1.1a"><mrow id="S3.SS1.SSS0.Px1.p3.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.2.cmml">y</mi><mo id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.1" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.1.cmml">−</mo><mrow id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.2" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.2.cmml">a</mi><mo id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.3" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.3.cmml">x</mi><mo id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1a" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.4" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.4.cmml">i</mi><mo id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1b" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.5" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.5.cmml">s</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p3.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1"><minus id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.1"></minus><ci id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.2">𝑦</ci><apply id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3"><times id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.2">𝑎</ci><ci id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.3">𝑥</ci><ci id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.4.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.4">𝑖</ci><ci id="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.5.cmml" xref="S3.SS1.SSS0.Px1.p3.1.m1.1.1.3.5">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p3.1.m1.1c">y-axis</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p3.1.m1.1d">italic_y - italic_a italic_x italic_i italic_s</annotation></semantics></math> to increase diversity in object poses. For modeling the background, we use <math alttext="359" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p3.2.m2.1"><semantics id="S3.SS1.SSS0.Px1.p3.2.m2.1a"><mn id="S3.SS1.SSS0.Px1.p3.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p3.2.m2.1.1.cmml">359</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p3.2.m2.1b"><cn id="S3.SS1.SSS0.Px1.p3.2.m2.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p3.2.m2.1.1">359</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p3.2.m2.1c">359</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p3.2.m2.1d">359</annotation></semantics></math> high-quality HDRI environment maps from PolyHeaven <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>. We categorize the floor textures and HDRI maps into <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p3.3.1">indoor</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p3.3.2">outdoor</span> categories to simulate realistic <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p3.3.3">indoor</span>/<span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p3.3.4">outdoor</span> scenes enhancing photorealism of the renderings. For illuminating the scene, we use an area light placed slightly above and behind the object at a <math alttext="45" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p3.3.m3.1"><semantics id="S3.SS1.SSS0.Px1.p3.3.m3.1a"><mn id="S3.SS1.SSS0.Px1.p3.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p3.3.m3.1.1.cmml">45</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p3.3.m3.1b"><cn id="S3.SS1.SSS0.Px1.p3.3.m3.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p3.3.m3.1.1">45</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p3.3.m3.1c">45</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p3.3.m3.1d">45</annotation></semantics></math> degree angle pointing towards the object and the mirror.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px1.p4">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p4.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS0.Px1.p4.2.1">Rendering.</span>
We te a pool of <math alttext="19" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p4.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p4.1.m1.1a"><mn id="S3.SS1.SSS0.Px1.p4.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p4.1.m1.1.1.cmml">19</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p4.1.m1.1b"><cn id="S3.SS1.SSS0.Px1.p4.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p4.1.m1.1.1">19</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p4.1.m1.1c">19</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p4.1.m1.1d">19</annotation></semantics></math> camera poses by interpolating between two extreme camera poses while ensuring that the object and its reflection in the mirror are visible. For each scene iteration, we randomly sample 3 camera poses and render the scene from these virtual cameras by leveraging BlenderProc <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>, to obtain RGB, depth maps, surface normal maps, and semantic labels. To obtain high-quality photo-realistic renderings, we render at a <math alttext="512\times 512" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p4.2.m2.1"><semantics id="S3.SS1.SSS0.Px1.p4.2.m2.1a"><mrow id="S3.SS1.SSS0.Px1.p4.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.cmml"><mn id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.2.cmml">512</mn><mo id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p4.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1"><times id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.1"></times><cn id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.2.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.2">512</cn><cn id="S3.SS1.SSS0.Px1.p4.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p4.2.m2.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p4.2.m2.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p4.2.m2.1d">512 × 512</annotation></semantics></math> resolution using 1024 cycles from Blender’s Cycles renderer. This allows us to create a rich and comprehensively annotated SynMirror dataset for studying a variety of mirror related tasks. More details about the dataset are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1" title="Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We briefly introduce diffusion models in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS1" title="4.1 Preliminaries ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4.1</span></a>. Then, we present our method MirrorFusion in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2" title="4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4.2</span></a>. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F4" title="Figure 4 ‣ 4.1 Preliminaries ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4</span></a> provides an overview of our method.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Preliminaries</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.10">Diffusion models are a family of generative models that generate images by iterative denoising. In the forward diffusion process, a Gaussian noise <math alttext="\epsilon\sim\mathcal{N}\left(0,1\right)" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.2"><semantics id="S4.SS1.p1.1.m1.2a"><mrow id="S4.SS1.p1.1.m1.2.3" xref="S4.SS1.p1.1.m1.2.3.cmml"><mi id="S4.SS1.p1.1.m1.2.3.2" xref="S4.SS1.p1.1.m1.2.3.2.cmml">ϵ</mi><mo id="S4.SS1.p1.1.m1.2.3.1" xref="S4.SS1.p1.1.m1.2.3.1.cmml">∼</mo><mrow id="S4.SS1.p1.1.m1.2.3.3" xref="S4.SS1.p1.1.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.1.m1.2.3.3.2" xref="S4.SS1.p1.1.m1.2.3.3.2.cmml">𝒩</mi><mo id="S4.SS1.p1.1.m1.2.3.3.1" xref="S4.SS1.p1.1.m1.2.3.3.1.cmml">⁢</mo><mrow id="S4.SS1.p1.1.m1.2.3.3.3.2" xref="S4.SS1.p1.1.m1.2.3.3.3.1.cmml"><mo id="S4.SS1.p1.1.m1.2.3.3.3.2.1" xref="S4.SS1.p1.1.m1.2.3.3.3.1.cmml">(</mo><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">0</mn><mo id="S4.SS1.p1.1.m1.2.3.3.3.2.2" xref="S4.SS1.p1.1.m1.2.3.3.3.1.cmml">,</mo><mn id="S4.SS1.p1.1.m1.2.2" xref="S4.SS1.p1.1.m1.2.2.cmml">1</mn><mo id="S4.SS1.p1.1.m1.2.3.3.3.2.3" xref="S4.SS1.p1.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.2b"><apply id="S4.SS1.p1.1.m1.2.3.cmml" xref="S4.SS1.p1.1.m1.2.3"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.2.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.1">similar-to</csymbol><ci id="S4.SS1.p1.1.m1.2.3.2.cmml" xref="S4.SS1.p1.1.m1.2.3.2">italic-ϵ</ci><apply id="S4.SS1.p1.1.m1.2.3.3.cmml" xref="S4.SS1.p1.1.m1.2.3.3"><times id="S4.SS1.p1.1.m1.2.3.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.3.1"></times><ci id="S4.SS1.p1.1.m1.2.3.3.2.cmml" xref="S4.SS1.p1.1.m1.2.3.3.2">𝒩</ci><interval closure="open" id="S4.SS1.p1.1.m1.2.3.3.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.3.3.2"><cn id="S4.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1">0</cn><cn id="S4.SS1.p1.1.m1.2.2.cmml" type="integer" xref="S4.SS1.p1.1.m1.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.2c">\epsilon\sim\mathcal{N}\left(0,1\right)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.2d">italic_ϵ ∼ caligraphic_N ( 0 , 1 )</annotation></semantics></math>; is sequentially added for <math alttext="T" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_T</annotation></semantics></math> timesteps to a clean sample <math alttext="x_{0}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">x</mi><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝑥</ci><cn id="S4.SS1.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.SS1.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">x_{0}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> to get a noisy sample <math alttext="x_{T}" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">x</mi><mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝑥</ci><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">x_{T}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math>. In the backward diffusion process, a clean image <math alttext="x_{0}" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><msub id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">x</mi><mn id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">𝑥</ci><cn id="S4.SS1.p1.5.m5.1.1.3.cmml" type="integer" xref="S4.SS1.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">x_{0}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> is generated by iterative denoising of noisy image <math alttext="x_{T}" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><msub id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">x</mi><mi id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">𝑥</ci><ci id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">x_{T}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math>. The iterative denoising process is modeled with a denoising network <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><msub id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2" xref="S4.SS1.p1.7.m7.1.1.2.cmml">ϵ</mi><mi id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2">italic-ϵ</ci><ci id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> conditioned on the timestep <math alttext="t\in\{1,T\}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.2"><semantics id="S4.SS1.p1.8.m8.2a"><mrow id="S4.SS1.p1.8.m8.2.3" xref="S4.SS1.p1.8.m8.2.3.cmml"><mi id="S4.SS1.p1.8.m8.2.3.2" xref="S4.SS1.p1.8.m8.2.3.2.cmml">t</mi><mo id="S4.SS1.p1.8.m8.2.3.1" xref="S4.SS1.p1.8.m8.2.3.1.cmml">∈</mo><mrow id="S4.SS1.p1.8.m8.2.3.3.2" xref="S4.SS1.p1.8.m8.2.3.3.1.cmml"><mo id="S4.SS1.p1.8.m8.2.3.3.2.1" stretchy="false" xref="S4.SS1.p1.8.m8.2.3.3.1.cmml">{</mo><mn id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">1</mn><mo id="S4.SS1.p1.8.m8.2.3.3.2.2" xref="S4.SS1.p1.8.m8.2.3.3.1.cmml">,</mo><mi id="S4.SS1.p1.8.m8.2.2" xref="S4.SS1.p1.8.m8.2.2.cmml">T</mi><mo id="S4.SS1.p1.8.m8.2.3.3.2.3" stretchy="false" xref="S4.SS1.p1.8.m8.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.2b"><apply id="S4.SS1.p1.8.m8.2.3.cmml" xref="S4.SS1.p1.8.m8.2.3"><in id="S4.SS1.p1.8.m8.2.3.1.cmml" xref="S4.SS1.p1.8.m8.2.3.1"></in><ci id="S4.SS1.p1.8.m8.2.3.2.cmml" xref="S4.SS1.p1.8.m8.2.3.2">𝑡</ci><set id="S4.SS1.p1.8.m8.2.3.3.1.cmml" xref="S4.SS1.p1.8.m8.2.3.3.2"><cn id="S4.SS1.p1.8.m8.1.1.cmml" type="integer" xref="S4.SS1.p1.8.m8.1.1">1</cn><ci id="S4.SS1.p1.8.m8.2.2.cmml" xref="S4.SS1.p1.8.m8.2.2">𝑇</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.2c">t\in\{1,T\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.2d">italic_t ∈ { 1 , italic_T }</annotation></semantics></math> and optional conditioning <math alttext="c" class="ltx_Math" display="inline" id="S4.SS1.p1.9.m9.1"><semantics id="S4.SS1.p1.9.m9.1a"><mi id="S4.SS1.p1.9.m9.1.1" xref="S4.SS1.p1.9.m9.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.1b"><ci id="S4.SS1.p1.9.m9.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.9.m9.1d">italic_c</annotation></semantics></math> (e.g. text prompts, inpainting masks). The denoiser is trained with simple mean square loss <math alttext="L_{DM}" class="ltx_Math" display="inline" id="S4.SS1.p1.10.m10.1"><semantics id="S4.SS1.p1.10.m10.1a"><msub id="S4.SS1.p1.10.m10.1.1" xref="S4.SS1.p1.10.m10.1.1.cmml"><mi id="S4.SS1.p1.10.m10.1.1.2" xref="S4.SS1.p1.10.m10.1.1.2.cmml">L</mi><mrow id="S4.SS1.p1.10.m10.1.1.3" xref="S4.SS1.p1.10.m10.1.1.3.cmml"><mi id="S4.SS1.p1.10.m10.1.1.3.2" xref="S4.SS1.p1.10.m10.1.1.3.2.cmml">D</mi><mo id="S4.SS1.p1.10.m10.1.1.3.1" xref="S4.SS1.p1.10.m10.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.10.m10.1.1.3.3" xref="S4.SS1.p1.10.m10.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m10.1b"><apply id="S4.SS1.p1.10.m10.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.10.m10.1.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS1.p1.10.m10.1.1.2.cmml" xref="S4.SS1.p1.10.m10.1.1.2">𝐿</ci><apply id="S4.SS1.p1.10.m10.1.1.3.cmml" xref="S4.SS1.p1.10.m10.1.1.3"><times id="S4.SS1.p1.10.m10.1.1.3.1.cmml" xref="S4.SS1.p1.10.m10.1.1.3.1"></times><ci id="S4.SS1.p1.10.m10.1.1.3.2.cmml" xref="S4.SS1.p1.10.m10.1.1.3.2">𝐷</ci><ci id="S4.SS1.p1.10.m10.1.1.3.3.cmml" xref="S4.SS1.p1.10.m10.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m10.1c">L_{DM}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.10.m10.1d">italic_L start_POSTSUBSCRIPT italic_D italic_M end_POSTSUBSCRIPT</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{DM}=\;\;E_{x_{0},\epsilon\sim\mathcal{N}\left(0,I\right),t}||\epsilon-%
\epsilon_{\theta}\left(z_{t},t,c\right)||^{2}" class="ltx_Math" display="block" id="S4.E1.m1.8"><semantics id="S4.E1.m1.8a"><mrow id="S4.E1.m1.8.8" xref="S4.E1.m1.8.8.cmml"><msub id="S4.E1.m1.8.8.3" xref="S4.E1.m1.8.8.3.cmml"><mi id="S4.E1.m1.8.8.3.2" xref="S4.E1.m1.8.8.3.2.cmml">L</mi><mrow id="S4.E1.m1.8.8.3.3" xref="S4.E1.m1.8.8.3.3.cmml"><mi id="S4.E1.m1.8.8.3.3.2" xref="S4.E1.m1.8.8.3.3.2.cmml">D</mi><mo id="S4.E1.m1.8.8.3.3.1" xref="S4.E1.m1.8.8.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.8.8.3.3.3" xref="S4.E1.m1.8.8.3.3.3.cmml">M</mi></mrow></msub><mo id="S4.E1.m1.8.8.2" rspace="0.838em" xref="S4.E1.m1.8.8.2.cmml">=</mo><mrow id="S4.E1.m1.8.8.1" xref="S4.E1.m1.8.8.1.cmml"><msub id="S4.E1.m1.8.8.1.3" xref="S4.E1.m1.8.8.1.3.cmml"><mi id="S4.E1.m1.8.8.1.3.2" xref="S4.E1.m1.8.8.1.3.2.cmml">E</mi><mrow id="S4.E1.m1.5.5.5.5" xref="S4.E1.m1.5.5.5.6.cmml"><mrow id="S4.E1.m1.5.5.5.5.1" xref="S4.E1.m1.5.5.5.5.1.cmml"><mrow id="S4.E1.m1.5.5.5.5.1.1.1" xref="S4.E1.m1.5.5.5.5.1.1.2.cmml"><msub id="S4.E1.m1.5.5.5.5.1.1.1.1" xref="S4.E1.m1.5.5.5.5.1.1.1.1.cmml"><mi id="S4.E1.m1.5.5.5.5.1.1.1.1.2" xref="S4.E1.m1.5.5.5.5.1.1.1.1.2.cmml">x</mi><mn id="S4.E1.m1.5.5.5.5.1.1.1.1.3" xref="S4.E1.m1.5.5.5.5.1.1.1.1.3.cmml">0</mn></msub><mo id="S4.E1.m1.5.5.5.5.1.1.1.2" xref="S4.E1.m1.5.5.5.5.1.1.2.cmml">,</mo><mi id="S4.E1.m1.3.3.3.3" xref="S4.E1.m1.3.3.3.3.cmml">ϵ</mi></mrow><mo id="S4.E1.m1.5.5.5.5.1.2" xref="S4.E1.m1.5.5.5.5.1.2.cmml">∼</mo><mrow id="S4.E1.m1.5.5.5.5.1.3" xref="S4.E1.m1.5.5.5.5.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.5.5.5.5.1.3.2" xref="S4.E1.m1.5.5.5.5.1.3.2.cmml">𝒩</mi><mo id="S4.E1.m1.5.5.5.5.1.3.1" xref="S4.E1.m1.5.5.5.5.1.3.1.cmml">⁢</mo><mrow id="S4.E1.m1.5.5.5.5.1.3.3.2" xref="S4.E1.m1.5.5.5.5.1.3.3.1.cmml"><mo id="S4.E1.m1.5.5.5.5.1.3.3.2.1" xref="S4.E1.m1.5.5.5.5.1.3.3.1.cmml">(</mo><mn id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml">0</mn><mo id="S4.E1.m1.5.5.5.5.1.3.3.2.2" xref="S4.E1.m1.5.5.5.5.1.3.3.1.cmml">,</mo><mi id="S4.E1.m1.2.2.2.2" xref="S4.E1.m1.2.2.2.2.cmml">I</mi><mo id="S4.E1.m1.5.5.5.5.1.3.3.2.3" xref="S4.E1.m1.5.5.5.5.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E1.m1.5.5.5.5.2" xref="S4.E1.m1.5.5.5.6a.cmml">,</mo><mi id="S4.E1.m1.4.4.4.4" xref="S4.E1.m1.4.4.4.4.cmml">t</mi></mrow></msub><mo id="S4.E1.m1.8.8.1.2" xref="S4.E1.m1.8.8.1.2.cmml">⁢</mo><msup id="S4.E1.m1.8.8.1.1" xref="S4.E1.m1.8.8.1.1.cmml"><mrow id="S4.E1.m1.8.8.1.1.1.1" xref="S4.E1.m1.8.8.1.1.1.2.cmml"><mo id="S4.E1.m1.8.8.1.1.1.1.2" stretchy="false" xref="S4.E1.m1.8.8.1.1.1.2.1.cmml">‖</mo><mrow id="S4.E1.m1.8.8.1.1.1.1.1" xref="S4.E1.m1.8.8.1.1.1.1.1.cmml"><mi id="S4.E1.m1.8.8.1.1.1.1.1.3" xref="S4.E1.m1.8.8.1.1.1.1.1.3.cmml">ϵ</mi><mo id="S4.E1.m1.8.8.1.1.1.1.1.2" xref="S4.E1.m1.8.8.1.1.1.1.1.2.cmml">−</mo><mrow id="S4.E1.m1.8.8.1.1.1.1.1.1" xref="S4.E1.m1.8.8.1.1.1.1.1.1.cmml"><msub id="S4.E1.m1.8.8.1.1.1.1.1.1.3" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3.cmml"><mi id="S4.E1.m1.8.8.1.1.1.1.1.1.3.2" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3.2.cmml">ϵ</mi><mi id="S4.E1.m1.8.8.1.1.1.1.1.1.3.3" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S4.E1.m1.8.8.1.1.1.1.1.1.2" xref="S4.E1.m1.8.8.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.2.cmml"><mo id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S4.E1.m1.6.6" xref="S4.E1.m1.6.6.cmml">t</mi><mo id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.4" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S4.E1.m1.7.7" xref="S4.E1.m1.7.7.cmml">c</mi><mo id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.5" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E1.m1.8.8.1.1.1.1.3" stretchy="false" xref="S4.E1.m1.8.8.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S4.E1.m1.8.8.1.1.3" xref="S4.E1.m1.8.8.1.1.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.8b"><apply id="S4.E1.m1.8.8.cmml" xref="S4.E1.m1.8.8"><eq id="S4.E1.m1.8.8.2.cmml" xref="S4.E1.m1.8.8.2"></eq><apply id="S4.E1.m1.8.8.3.cmml" xref="S4.E1.m1.8.8.3"><csymbol cd="ambiguous" id="S4.E1.m1.8.8.3.1.cmml" xref="S4.E1.m1.8.8.3">subscript</csymbol><ci id="S4.E1.m1.8.8.3.2.cmml" xref="S4.E1.m1.8.8.3.2">𝐿</ci><apply id="S4.E1.m1.8.8.3.3.cmml" xref="S4.E1.m1.8.8.3.3"><times id="S4.E1.m1.8.8.3.3.1.cmml" xref="S4.E1.m1.8.8.3.3.1"></times><ci id="S4.E1.m1.8.8.3.3.2.cmml" xref="S4.E1.m1.8.8.3.3.2">𝐷</ci><ci id="S4.E1.m1.8.8.3.3.3.cmml" xref="S4.E1.m1.8.8.3.3.3">𝑀</ci></apply></apply><apply id="S4.E1.m1.8.8.1.cmml" xref="S4.E1.m1.8.8.1"><times id="S4.E1.m1.8.8.1.2.cmml" xref="S4.E1.m1.8.8.1.2"></times><apply id="S4.E1.m1.8.8.1.3.cmml" xref="S4.E1.m1.8.8.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.8.8.1.3.1.cmml" xref="S4.E1.m1.8.8.1.3">subscript</csymbol><ci id="S4.E1.m1.8.8.1.3.2.cmml" xref="S4.E1.m1.8.8.1.3.2">𝐸</ci><apply id="S4.E1.m1.5.5.5.6.cmml" xref="S4.E1.m1.5.5.5.5"><csymbol cd="ambiguous" id="S4.E1.m1.5.5.5.6a.cmml" xref="S4.E1.m1.5.5.5.5.2">formulae-sequence</csymbol><apply id="S4.E1.m1.5.5.5.5.1.cmml" xref="S4.E1.m1.5.5.5.5.1"><csymbol cd="latexml" id="S4.E1.m1.5.5.5.5.1.2.cmml" xref="S4.E1.m1.5.5.5.5.1.2">similar-to</csymbol><list id="S4.E1.m1.5.5.5.5.1.1.2.cmml" xref="S4.E1.m1.5.5.5.5.1.1.1"><apply id="S4.E1.m1.5.5.5.5.1.1.1.1.cmml" xref="S4.E1.m1.5.5.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.5.5.5.5.1.1.1.1.1.cmml" xref="S4.E1.m1.5.5.5.5.1.1.1.1">subscript</csymbol><ci id="S4.E1.m1.5.5.5.5.1.1.1.1.2.cmml" xref="S4.E1.m1.5.5.5.5.1.1.1.1.2">𝑥</ci><cn id="S4.E1.m1.5.5.5.5.1.1.1.1.3.cmml" type="integer" xref="S4.E1.m1.5.5.5.5.1.1.1.1.3">0</cn></apply><ci id="S4.E1.m1.3.3.3.3.cmml" xref="S4.E1.m1.3.3.3.3">italic-ϵ</ci></list><apply id="S4.E1.m1.5.5.5.5.1.3.cmml" xref="S4.E1.m1.5.5.5.5.1.3"><times id="S4.E1.m1.5.5.5.5.1.3.1.cmml" xref="S4.E1.m1.5.5.5.5.1.3.1"></times><ci id="S4.E1.m1.5.5.5.5.1.3.2.cmml" xref="S4.E1.m1.5.5.5.5.1.3.2">𝒩</ci><interval closure="open" id="S4.E1.m1.5.5.5.5.1.3.3.1.cmml" xref="S4.E1.m1.5.5.5.5.1.3.3.2"><cn id="S4.E1.m1.1.1.1.1.cmml" type="integer" xref="S4.E1.m1.1.1.1.1">0</cn><ci id="S4.E1.m1.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2">𝐼</ci></interval></apply></apply><ci id="S4.E1.m1.4.4.4.4.cmml" xref="S4.E1.m1.4.4.4.4">𝑡</ci></apply></apply><apply id="S4.E1.m1.8.8.1.1.cmml" xref="S4.E1.m1.8.8.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.8.8.1.1.2.cmml" xref="S4.E1.m1.8.8.1.1">superscript</csymbol><apply id="S4.E1.m1.8.8.1.1.1.2.cmml" xref="S4.E1.m1.8.8.1.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.8.8.1.1.1.2.1.cmml" xref="S4.E1.m1.8.8.1.1.1.1.2">norm</csymbol><apply id="S4.E1.m1.8.8.1.1.1.1.1.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1"><minus id="S4.E1.m1.8.8.1.1.1.1.1.2.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.2"></minus><ci id="S4.E1.m1.8.8.1.1.1.1.1.3.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.3">italic-ϵ</ci><apply id="S4.E1.m1.8.8.1.1.1.1.1.1.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1"><times id="S4.E1.m1.8.8.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.2"></times><apply id="S4.E1.m1.8.8.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.8.8.1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.8.8.1.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3.2">italic-ϵ</ci><ci id="S4.E1.m1.8.8.1.1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.3.3">𝜃</ci></apply><vector id="S4.E1.m1.8.8.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1"><apply id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S4.E1.m1.6.6.cmml" xref="S4.E1.m1.6.6">𝑡</ci><ci id="S4.E1.m1.7.7.cmml" xref="S4.E1.m1.7.7">𝑐</ci></vector></apply></apply></apply><cn id="S4.E1.m1.8.8.1.1.3.cmml" type="integer" xref="S4.E1.m1.8.8.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.8c">L_{DM}=\;\;E_{x_{0},\epsilon\sim\mathcal{N}\left(0,I\right),t}||\epsilon-%
\epsilon_{\theta}\left(z_{t},t,c\right)||^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.8d">italic_L start_POSTSUBSCRIPT italic_D italic_M end_POSTSUBSCRIPT = italic_E start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_ϵ ∼ caligraphic_N ( 0 , italic_I ) , italic_t end_POSTSUBSCRIPT | | italic_ϵ - italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Training diffusion models directly on the large resolution images <math alttext="x_{0}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><msub id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">x_{0}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> is computationally demanding as it needs several denoising steps to generate a single image. Latent Diffusion Models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> propose to apply a diffusion process in a compressed latent space of a pre-trained Variational Autoencoder. This enables efficient training and fast inference for generating large-resolution images.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="266" id="S4.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.31.15.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F4.28.14" style="font-size:90%;">Overview of the architecture.<span class="ltx_text ltx_font_medium" id="S4.F4.28.14.14"> We encode the input image <math alttext="x" class="ltx_Math" display="inline" id="S4.F4.15.1.1.m1.1"><semantics id="S4.F4.15.1.1.m1.1b"><mi id="S4.F4.15.1.1.m1.1.1" xref="S4.F4.15.1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.F4.15.1.1.m1.1c"><ci id="S4.F4.15.1.1.m1.1.1.cmml" xref="S4.F4.15.1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.15.1.1.m1.1d">x</annotation><annotation encoding="application/x-llamapun" id="S4.F4.15.1.1.m1.1e">italic_x</annotation></semantics></math> using a pre-trained image encoder from Stable Diffusion to get <math alttext="z_{m}" class="ltx_Math" display="inline" id="S4.F4.16.2.2.m2.1"><semantics id="S4.F4.16.2.2.m2.1b"><msub id="S4.F4.16.2.2.m2.1.1" xref="S4.F4.16.2.2.m2.1.1.cmml"><mi id="S4.F4.16.2.2.m2.1.1.2" xref="S4.F4.16.2.2.m2.1.1.2.cmml">z</mi><mi id="S4.F4.16.2.2.m2.1.1.3" xref="S4.F4.16.2.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.16.2.2.m2.1c"><apply id="S4.F4.16.2.2.m2.1.1.cmml" xref="S4.F4.16.2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F4.16.2.2.m2.1.1.1.cmml" xref="S4.F4.16.2.2.m2.1.1">subscript</csymbol><ci id="S4.F4.16.2.2.m2.1.1.2.cmml" xref="S4.F4.16.2.2.m2.1.1.2">𝑧</ci><ci id="S4.F4.16.2.2.m2.1.1.3.cmml" xref="S4.F4.16.2.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.16.2.2.m2.1d">z_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.16.2.2.m2.1e">italic_z start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>. Subsequently, we resize the mirror mask <math alttext="m" class="ltx_Math" display="inline" id="S4.F4.17.3.3.m3.1"><semantics id="S4.F4.17.3.3.m3.1b"><mi id="S4.F4.17.3.3.m3.1.1" xref="S4.F4.17.3.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.F4.17.3.3.m3.1c"><ci id="S4.F4.17.3.3.m3.1.1.cmml" xref="S4.F4.17.3.3.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.17.3.3.m3.1d">m</annotation><annotation encoding="application/x-llamapun" id="S4.F4.17.3.3.m3.1e">italic_m</annotation></semantics></math> and depth map <math alttext="d" class="ltx_Math" display="inline" id="S4.F4.18.4.4.m4.1"><semantics id="S4.F4.18.4.4.m4.1b"><mi id="S4.F4.18.4.4.m4.1.1" xref="S4.F4.18.4.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.F4.18.4.4.m4.1c"><ci id="S4.F4.18.4.4.m4.1.1.cmml" xref="S4.F4.18.4.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.18.4.4.m4.1d">d</annotation><annotation encoding="application/x-llamapun" id="S4.F4.18.4.4.m4.1e">italic_d</annotation></semantics></math> to obtain resized mask <math alttext="x_{m}" class="ltx_Math" display="inline" id="S4.F4.19.5.5.m5.1"><semantics id="S4.F4.19.5.5.m5.1b"><msub id="S4.F4.19.5.5.m5.1.1" xref="S4.F4.19.5.5.m5.1.1.cmml"><mi id="S4.F4.19.5.5.m5.1.1.2" xref="S4.F4.19.5.5.m5.1.1.2.cmml">x</mi><mi id="S4.F4.19.5.5.m5.1.1.3" xref="S4.F4.19.5.5.m5.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.19.5.5.m5.1c"><apply id="S4.F4.19.5.5.m5.1.1.cmml" xref="S4.F4.19.5.5.m5.1.1"><csymbol cd="ambiguous" id="S4.F4.19.5.5.m5.1.1.1.cmml" xref="S4.F4.19.5.5.m5.1.1">subscript</csymbol><ci id="S4.F4.19.5.5.m5.1.1.2.cmml" xref="S4.F4.19.5.5.m5.1.1.2">𝑥</ci><ci id="S4.F4.19.5.5.m5.1.1.3.cmml" xref="S4.F4.19.5.5.m5.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.19.5.5.m5.1d">x_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.19.5.5.m5.1e">italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> and depth <math alttext="x_{d}" class="ltx_Math" display="inline" id="S4.F4.20.6.6.m6.1"><semantics id="S4.F4.20.6.6.m6.1b"><msub id="S4.F4.20.6.6.m6.1.1" xref="S4.F4.20.6.6.m6.1.1.cmml"><mi id="S4.F4.20.6.6.m6.1.1.2" xref="S4.F4.20.6.6.m6.1.1.2.cmml">x</mi><mi id="S4.F4.20.6.6.m6.1.1.3" xref="S4.F4.20.6.6.m6.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.20.6.6.m6.1c"><apply id="S4.F4.20.6.6.m6.1.1.cmml" xref="S4.F4.20.6.6.m6.1.1"><csymbol cd="ambiguous" id="S4.F4.20.6.6.m6.1.1.1.cmml" xref="S4.F4.20.6.6.m6.1.1">subscript</csymbol><ci id="S4.F4.20.6.6.m6.1.1.2.cmml" xref="S4.F4.20.6.6.m6.1.1.2">𝑥</ci><ci id="S4.F4.20.6.6.m6.1.1.3.cmml" xref="S4.F4.20.6.6.m6.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.20.6.6.m6.1d">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.20.6.6.m6.1e">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>. Then, we concatenate noisy latents <math alttext="z_{t}" class="ltx_Math" display="inline" id="S4.F4.21.7.7.m7.1"><semantics id="S4.F4.21.7.7.m7.1b"><msub id="S4.F4.21.7.7.m7.1.1" xref="S4.F4.21.7.7.m7.1.1.cmml"><mi id="S4.F4.21.7.7.m7.1.1.2" xref="S4.F4.21.7.7.m7.1.1.2.cmml">z</mi><mi id="S4.F4.21.7.7.m7.1.1.3" xref="S4.F4.21.7.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.21.7.7.m7.1c"><apply id="S4.F4.21.7.7.m7.1.1.cmml" xref="S4.F4.21.7.7.m7.1.1"><csymbol cd="ambiguous" id="S4.F4.21.7.7.m7.1.1.1.cmml" xref="S4.F4.21.7.7.m7.1.1">subscript</csymbol><ci id="S4.F4.21.7.7.m7.1.1.2.cmml" xref="S4.F4.21.7.7.m7.1.1.2">𝑧</ci><ci id="S4.F4.21.7.7.m7.1.1.3.cmml" xref="S4.F4.21.7.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.21.7.7.m7.1d">z_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.21.7.7.m7.1e">italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="z_{m}" class="ltx_Math" display="inline" id="S4.F4.22.8.8.m8.1"><semantics id="S4.F4.22.8.8.m8.1b"><msub id="S4.F4.22.8.8.m8.1.1" xref="S4.F4.22.8.8.m8.1.1.cmml"><mi id="S4.F4.22.8.8.m8.1.1.2" xref="S4.F4.22.8.8.m8.1.1.2.cmml">z</mi><mi id="S4.F4.22.8.8.m8.1.1.3" xref="S4.F4.22.8.8.m8.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.22.8.8.m8.1c"><apply id="S4.F4.22.8.8.m8.1.1.cmml" xref="S4.F4.22.8.8.m8.1.1"><csymbol cd="ambiguous" id="S4.F4.22.8.8.m8.1.1.1.cmml" xref="S4.F4.22.8.8.m8.1.1">subscript</csymbol><ci id="S4.F4.22.8.8.m8.1.1.2.cmml" xref="S4.F4.22.8.8.m8.1.1.2">𝑧</ci><ci id="S4.F4.22.8.8.m8.1.1.3.cmml" xref="S4.F4.22.8.8.m8.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.22.8.8.m8.1d">z_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.22.8.8.m8.1e">italic_z start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="x_{m}" class="ltx_Math" display="inline" id="S4.F4.23.9.9.m9.1"><semantics id="S4.F4.23.9.9.m9.1b"><msub id="S4.F4.23.9.9.m9.1.1" xref="S4.F4.23.9.9.m9.1.1.cmml"><mi id="S4.F4.23.9.9.m9.1.1.2" xref="S4.F4.23.9.9.m9.1.1.2.cmml">x</mi><mi id="S4.F4.23.9.9.m9.1.1.3" xref="S4.F4.23.9.9.m9.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.23.9.9.m9.1c"><apply id="S4.F4.23.9.9.m9.1.1.cmml" xref="S4.F4.23.9.9.m9.1.1"><csymbol cd="ambiguous" id="S4.F4.23.9.9.m9.1.1.1.cmml" xref="S4.F4.23.9.9.m9.1.1">subscript</csymbol><ci id="S4.F4.23.9.9.m9.1.1.2.cmml" xref="S4.F4.23.9.9.m9.1.1.2">𝑥</ci><ci id="S4.F4.23.9.9.m9.1.1.3.cmml" xref="S4.F4.23.9.9.m9.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.23.9.9.m9.1d">x_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.23.9.9.m9.1e">italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="x_{d}" class="ltx_Math" display="inline" id="S4.F4.24.10.10.m10.1"><semantics id="S4.F4.24.10.10.m10.1b"><msub id="S4.F4.24.10.10.m10.1.1" xref="S4.F4.24.10.10.m10.1.1.cmml"><mi id="S4.F4.24.10.10.m10.1.1.2" xref="S4.F4.24.10.10.m10.1.1.2.cmml">x</mi><mi id="S4.F4.24.10.10.m10.1.1.3" xref="S4.F4.24.10.10.m10.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.24.10.10.m10.1c"><apply id="S4.F4.24.10.10.m10.1.1.cmml" xref="S4.F4.24.10.10.m10.1.1"><csymbol cd="ambiguous" id="S4.F4.24.10.10.m10.1.1.1.cmml" xref="S4.F4.24.10.10.m10.1.1">subscript</csymbol><ci id="S4.F4.24.10.10.m10.1.1.2.cmml" xref="S4.F4.24.10.10.m10.1.1.2">𝑥</ci><ci id="S4.F4.24.10.10.m10.1.1.3.cmml" xref="S4.F4.24.10.10.m10.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.24.10.10.m10.1d">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.24.10.10.m10.1e">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> which are fed into the Conditioning U-Net <math alttext="\epsilon^{{}^{\prime}}_{\theta}" class="ltx_Math" display="inline" id="S4.F4.25.11.11.m11.1"><semantics id="S4.F4.25.11.11.m11.1b"><msubsup id="S4.F4.25.11.11.m11.1.1" xref="S4.F4.25.11.11.m11.1.1.cmml"><mi id="S4.F4.25.11.11.m11.1.1.2.2" xref="S4.F4.25.11.11.m11.1.1.2.2.cmml">ϵ</mi><mi id="S4.F4.25.11.11.m11.1.1.3" xref="S4.F4.25.11.11.m11.1.1.3.cmml">θ</mi><msup id="S4.F4.25.11.11.m11.1.1.2.3" xref="S4.F4.25.11.11.m11.1.1.2.3.cmml"><mi id="S4.F4.25.11.11.m11.1.1.2.3b" xref="S4.F4.25.11.11.m11.1.1.2.3.cmml"></mi><mo id="S4.F4.25.11.11.m11.1.1.2.3.1" xref="S4.F4.25.11.11.m11.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S4.F4.25.11.11.m11.1c"><apply id="S4.F4.25.11.11.m11.1.1.cmml" xref="S4.F4.25.11.11.m11.1.1"><csymbol cd="ambiguous" id="S4.F4.25.11.11.m11.1.1.1.cmml" xref="S4.F4.25.11.11.m11.1.1">subscript</csymbol><apply id="S4.F4.25.11.11.m11.1.1.2.cmml" xref="S4.F4.25.11.11.m11.1.1"><csymbol cd="ambiguous" id="S4.F4.25.11.11.m11.1.1.2.1.cmml" xref="S4.F4.25.11.11.m11.1.1">superscript</csymbol><ci id="S4.F4.25.11.11.m11.1.1.2.2.cmml" xref="S4.F4.25.11.11.m11.1.1.2.2">italic-ϵ</ci><apply id="S4.F4.25.11.11.m11.1.1.2.3.cmml" xref="S4.F4.25.11.11.m11.1.1.2.3"><ci id="S4.F4.25.11.11.m11.1.1.2.3.1.cmml" xref="S4.F4.25.11.11.m11.1.1.2.3.1">′</ci></apply></apply><ci id="S4.F4.25.11.11.m11.1.1.3.cmml" xref="S4.F4.25.11.11.m11.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.25.11.11.m11.1d">\epsilon^{{}^{\prime}}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.25.11.11.m11.1e">italic_ϵ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. Each layer of the Generation U-Net <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S4.F4.26.12.12.m12.1"><semantics id="S4.F4.26.12.12.m12.1b"><msub id="S4.F4.26.12.12.m12.1.1" xref="S4.F4.26.12.12.m12.1.1.cmml"><mi id="S4.F4.26.12.12.m12.1.1.2" xref="S4.F4.26.12.12.m12.1.1.2.cmml">ϵ</mi><mi id="S4.F4.26.12.12.m12.1.1.3" xref="S4.F4.26.12.12.m12.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.26.12.12.m12.1c"><apply id="S4.F4.26.12.12.m12.1.1.cmml" xref="S4.F4.26.12.12.m12.1.1"><csymbol cd="ambiguous" id="S4.F4.26.12.12.m12.1.1.1.cmml" xref="S4.F4.26.12.12.m12.1.1">subscript</csymbol><ci id="S4.F4.26.12.12.m12.1.1.2.cmml" xref="S4.F4.26.12.12.m12.1.1.2">italic-ϵ</ci><ci id="S4.F4.26.12.12.m12.1.1.3.cmml" xref="S4.F4.26.12.12.m12.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.26.12.12.m12.1d">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.26.12.12.m12.1e">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> is conditioned via zero convolutions with corresponding layers of <math alttext="\epsilon^{{}^{\prime}}_{\theta}" class="ltx_Math" display="inline" id="S4.F4.27.13.13.m13.1"><semantics id="S4.F4.27.13.13.m13.1b"><msubsup id="S4.F4.27.13.13.m13.1.1" xref="S4.F4.27.13.13.m13.1.1.cmml"><mi id="S4.F4.27.13.13.m13.1.1.2.2" xref="S4.F4.27.13.13.m13.1.1.2.2.cmml">ϵ</mi><mi id="S4.F4.27.13.13.m13.1.1.3" xref="S4.F4.27.13.13.m13.1.1.3.cmml">θ</mi><msup id="S4.F4.27.13.13.m13.1.1.2.3" xref="S4.F4.27.13.13.m13.1.1.2.3.cmml"><mi id="S4.F4.27.13.13.m13.1.1.2.3b" xref="S4.F4.27.13.13.m13.1.1.2.3.cmml"></mi><mo id="S4.F4.27.13.13.m13.1.1.2.3.1" xref="S4.F4.27.13.13.m13.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S4.F4.27.13.13.m13.1c"><apply id="S4.F4.27.13.13.m13.1.1.cmml" xref="S4.F4.27.13.13.m13.1.1"><csymbol cd="ambiguous" id="S4.F4.27.13.13.m13.1.1.1.cmml" xref="S4.F4.27.13.13.m13.1.1">subscript</csymbol><apply id="S4.F4.27.13.13.m13.1.1.2.cmml" xref="S4.F4.27.13.13.m13.1.1"><csymbol cd="ambiguous" id="S4.F4.27.13.13.m13.1.1.2.1.cmml" xref="S4.F4.27.13.13.m13.1.1">superscript</csymbol><ci id="S4.F4.27.13.13.m13.1.1.2.2.cmml" xref="S4.F4.27.13.13.m13.1.1.2.2">italic-ϵ</ci><apply id="S4.F4.27.13.13.m13.1.1.2.3.cmml" xref="S4.F4.27.13.13.m13.1.1.2.3"><ci id="S4.F4.27.13.13.m13.1.1.2.3.1.cmml" xref="S4.F4.27.13.13.m13.1.1.2.3.1">′</ci></apply></apply><ci id="S4.F4.27.13.13.m13.1.1.3.cmml" xref="S4.F4.27.13.13.m13.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.27.13.13.m13.1d">\epsilon^{{}^{\prime}}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.27.13.13.m13.1e">italic_ϵ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. Additionally, <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S4.F4.28.14.14.m14.1"><semantics id="S4.F4.28.14.14.m14.1b"><msub id="S4.F4.28.14.14.m14.1.1" xref="S4.F4.28.14.14.m14.1.1.cmml"><mi id="S4.F4.28.14.14.m14.1.1.2" xref="S4.F4.28.14.14.m14.1.1.2.cmml">ϵ</mi><mi id="S4.F4.28.14.14.m14.1.1.3" xref="S4.F4.28.14.14.m14.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.28.14.14.m14.1c"><apply id="S4.F4.28.14.14.m14.1.1.cmml" xref="S4.F4.28.14.14.m14.1.1"><csymbol cd="ambiguous" id="S4.F4.28.14.14.m14.1.1.1.cmml" xref="S4.F4.28.14.14.m14.1.1">subscript</csymbol><ci id="S4.F4.28.14.14.m14.1.1.2.cmml" xref="S4.F4.28.14.14.m14.1.1.2">italic-ϵ</ci><ci id="S4.F4.28.14.14.m14.1.1.3.cmml" xref="S4.F4.28.14.14.m14.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.28.14.14.m14.1d">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.28.14.14.m14.1e">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> is conditioned by text embeddings. The pre-trained decoder then decodes the denoised latent to produce an image with mirror reflections. Detailed information can be found in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2" title="4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4.2</span></a></span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>MirrorFusion</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Though trained on large-scale datasets, existing state-of-the-art diffusion models fail to generate consistent reflections with accurate object shape and scene appearance as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S0.F1" title="Figure 1 ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a>. We propose MirrorFusion, a novel framework for generating accurate mirror reflections by formulating it as an inpainting problem. Given an input scene image and a mirror mask, MirrorFusion fills the masked region with the consistent reflection of the object and the scene. Generating accurate reflections requires a precise 3D understanding of the scene to reason about the distance of objects from the mirror and the shapes of objects. Hence, modeling reflections with just a 2D inpainting model is suboptimal, and we need to inject explicit 3D cues during the inpainting process. Thus, we propose to condition the inpainting approach with depth maps. The geometric signal from the depth map enables us to generate accurate and consistent reflections that adhere to the 3D structure of the scene and the object. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F4" title="Figure 4 ‣ 4.1 Preliminaries ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4</span></a> shows the overview of our method.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Model architecture</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.4">MirrorFusion is a diffusion-based inpainting model conditioned on the input mirror mask and depth map. We use a base dual branch architecture for inpainting following BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F4" title="Figure 4 ‣ 4.1 Preliminaries ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4</span></a>. The core idea is to clone a pretrained diffusion model <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p1.1.m1.1"><semantics id="S4.SS2.SSS1.p1.1.m1.1a"><msub id="S4.SS2.SSS1.p1.1.m1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS1.p1.1.m1.1.1.2" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml">ϵ</mi><mi id="S4.SS2.SSS1.p1.1.m1.1.1.3" xref="S4.SS2.SSS1.p1.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.1.m1.1b"><apply id="S4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2">italic-ϵ</ci><ci id="S4.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.1.m1.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p1.1.m1.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> without cross-attention layers to <math alttext="\epsilon^{{}^{\prime}}_{\theta}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p1.2.m2.1"><semantics id="S4.SS2.SSS1.p1.2.m2.1a"><msubsup id="S4.SS2.SSS1.p1.2.m2.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS1.p1.2.m2.1.1.2.2" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.2.cmml">ϵ</mi><mi id="S4.SS2.SSS1.p1.2.m2.1.1.3" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml">θ</mi><msup id="S4.SS2.SSS1.p1.2.m2.1.1.2.3" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.3.cmml"><mi id="S4.SS2.SSS1.p1.2.m2.1.1.2.3a" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.3.cmml"></mi><mo id="S4.SS2.SSS1.p1.2.m2.1.1.2.3.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.2.m2.1b"><apply id="S4.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><apply id="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.2">italic-ϵ</ci><apply id="S4.SS2.SSS1.p1.2.m2.1.1.2.3.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.3"><ci id="S4.SS2.SSS1.p1.2.m2.1.1.2.3.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.3.1">′</ci></apply></apply><ci id="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.2.m2.1c">\epsilon^{{}^{\prime}}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p1.2.m2.1d">italic_ϵ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. Subsequently, the features from the conditioning model <math alttext="\epsilon^{{}^{\prime}}_{\theta}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p1.3.m3.1"><semantics id="S4.SS2.SSS1.p1.3.m3.1a"><msubsup id="S4.SS2.SSS1.p1.3.m3.1.1" xref="S4.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S4.SS2.SSS1.p1.3.m3.1.1.2.2" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.2.cmml">ϵ</mi><mi id="S4.SS2.SSS1.p1.3.m3.1.1.3" xref="S4.SS2.SSS1.p1.3.m3.1.1.3.cmml">θ</mi><msup id="S4.SS2.SSS1.p1.3.m3.1.1.2.3" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.3.cmml"><mi id="S4.SS2.SSS1.p1.3.m3.1.1.2.3a" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.3.cmml"></mi><mo id="S4.SS2.SSS1.p1.3.m3.1.1.2.3.1" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.3.m3.1b"><apply id="S4.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1">subscript</csymbol><apply id="S4.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1">superscript</csymbol><ci id="S4.SS2.SSS1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.2">italic-ϵ</ci><apply id="S4.SS2.SSS1.p1.3.m3.1.1.2.3.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.3"><ci id="S4.SS2.SSS1.p1.3.m3.1.1.2.3.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1.2.3.1">′</ci></apply></apply><ci id="S4.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.3.m3.1c">\epsilon^{{}^{\prime}}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p1.3.m3.1d">italic_ϵ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> are inserted into the generation model <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p1.4.m4.1"><semantics id="S4.SS2.SSS1.p1.4.m4.1a"><msub id="S4.SS2.SSS1.p1.4.m4.1.1" xref="S4.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S4.SS2.SSS1.p1.4.m4.1.1.2" xref="S4.SS2.SSS1.p1.4.m4.1.1.2.cmml">ϵ</mi><mi id="S4.SS2.SSS1.p1.4.m4.1.1.3" xref="S4.SS2.SSS1.p1.4.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.4.m4.1b"><apply id="S4.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S4.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S4.SS2.SSS1.p1.4.m4.1.1.2">italic-ϵ</ci><ci id="S4.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S4.SS2.SSS1.p1.4.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.4.m4.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p1.4.m4.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> using zero-convolutional layers. During training, <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS1.p1.4.1">only the conditioning model is updated, keeping the generation model frozen</span>. This conditioning mechanism provides a strong hierarchical conditioning for generation without altering the original generation model.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Depth conditioning</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.10">Geometric information about objects and scenes is crucial for generating 3D consistent reflections. Recent works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib37" title=""><span class="ltx_text" style="font-size:90%;">37</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> show that injecting depth maps enables 3D geometric control in the diffusion models.
Inspired by this, we utilize depth-conditioning for our inpainting architecture. Specifically, the noisy latent <math alttext="z_{t}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.1.m1.1"><semantics id="S4.SS2.SSS2.p1.1.m1.1a"><msub id="S4.SS2.SSS2.p1.1.m1.1.1" xref="S4.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS2.p1.1.m1.1.1.2" xref="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml">z</mi><mi id="S4.SS2.SSS2.p1.1.m1.1.1.3" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.1.m1.1b"><apply id="S4.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.2">𝑧</ci><ci id="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.1.m1.1c">z_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, masked image latent <math alttext="z_{m}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.2.m2.1"><semantics id="S4.SS2.SSS2.p1.2.m2.1a"><msub id="S4.SS2.SSS2.p1.2.m2.1.1" xref="S4.SS2.SSS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS2.p1.2.m2.1.1.2" xref="S4.SS2.SSS2.p1.2.m2.1.1.2.cmml">z</mi><mi id="S4.SS2.SSS2.p1.2.m2.1.1.3" xref="S4.SS2.SSS2.p1.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.2.m2.1b"><apply id="S4.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1.2">𝑧</ci><ci id="S4.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.2.m2.1c">z_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, inpainting mask <math alttext="x_{m}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.3.m3.1"><semantics id="S4.SS2.SSS2.p1.3.m3.1a"><msub id="S4.SS2.SSS2.p1.3.m3.1.1" xref="S4.SS2.SSS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.SSS2.p1.3.m3.1.1.2" xref="S4.SS2.SSS2.p1.3.m3.1.1.2.cmml">x</mi><mi id="S4.SS2.SSS2.p1.3.m3.1.1.3" xref="S4.SS2.SSS2.p1.3.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.3.m3.1b"><apply id="S4.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.SSS2.p1.3.m3.1.1.2">𝑥</ci><ci id="S4.SS2.SSS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.SSS2.p1.3.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.3.m3.1c">x_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.3.m3.1d">italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, and the depth map <math alttext="x_{d}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.4.m4.1"><semantics id="S4.SS2.SSS2.p1.4.m4.1a"><msub id="S4.SS2.SSS2.p1.4.m4.1.1" xref="S4.SS2.SSS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.SSS2.p1.4.m4.1.1.2" xref="S4.SS2.SSS2.p1.4.m4.1.1.2.cmml">x</mi><mi id="S4.SS2.SSS2.p1.4.m4.1.1.3" xref="S4.SS2.SSS2.p1.4.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.4.m4.1b"><apply id="S4.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1.2">𝑥</ci><ci id="S4.SS2.SSS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.SSS2.p1.4.m4.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.4.m4.1c">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.4.m4.1d">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> are all concatenated and passed as input to the conditioning U-Net <math alttext="{\epsilon^{{}^{\prime}}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.5.m5.1"><semantics id="S4.SS2.SSS2.p1.5.m5.1a"><msup id="S4.SS2.SSS2.p1.5.m5.1.1" xref="S4.SS2.SSS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.SSS2.p1.5.m5.1.1.2" xref="S4.SS2.SSS2.p1.5.m5.1.1.2.cmml">ϵ</mi><msup id="S4.SS2.SSS2.p1.5.m5.1.1.3" xref="S4.SS2.SSS2.p1.5.m5.1.1.3.cmml"><mi id="S4.SS2.SSS2.p1.5.m5.1.1.3a" xref="S4.SS2.SSS2.p1.5.m5.1.1.3.cmml"></mi><mo id="S4.SS2.SSS2.p1.5.m5.1.1.3.1" xref="S4.SS2.SSS2.p1.5.m5.1.1.3.1.cmml">′</mo></msup></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.5.m5.1b"><apply id="S4.SS2.SSS2.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.1">superscript</csymbol><ci id="S4.SS2.SSS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.1.2">italic-ϵ</ci><apply id="S4.SS2.SSS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.1.3"><ci id="S4.SS2.SSS2.p1.5.m5.1.1.3.1.cmml" xref="S4.SS2.SSS2.p1.5.m5.1.1.3.1">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.5.m5.1c">{\epsilon^{{}^{\prime}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.5.m5.1d">italic_ϵ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>. The generation U-Net <math alttext="{\epsilon}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.6.m6.1"><semantics id="S4.SS2.SSS2.p1.6.m6.1a"><mi id="S4.SS2.SSS2.p1.6.m6.1.1" xref="S4.SS2.SSS2.p1.6.m6.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.6.m6.1b"><ci id="S4.SS2.SSS2.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS2.p1.6.m6.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.6.m6.1c">{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.6.m6.1d">italic_ϵ</annotation></semantics></math> is an unaltered text-to-image diffusion model, which takes a noisy latent <math alttext="z_{t}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.7.m7.1"><semantics id="S4.SS2.SSS2.p1.7.m7.1a"><msub id="S4.SS2.SSS2.p1.7.m7.1.1" xref="S4.SS2.SSS2.p1.7.m7.1.1.cmml"><mi id="S4.SS2.SSS2.p1.7.m7.1.1.2" xref="S4.SS2.SSS2.p1.7.m7.1.1.2.cmml">z</mi><mi id="S4.SS2.SSS2.p1.7.m7.1.1.3" xref="S4.SS2.SSS2.p1.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.7.m7.1b"><apply id="S4.SS2.SSS2.p1.7.m7.1.1.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.1.2">𝑧</ci><ci id="S4.SS2.SSS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.SSS2.p1.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.7.m7.1c">z_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.7.m7.1d">italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and predicts a cleaner version <math alttext="z_{t-1}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.8.m8.1"><semantics id="S4.SS2.SSS2.p1.8.m8.1a"><msub id="S4.SS2.SSS2.p1.8.m8.1.1" xref="S4.SS2.SSS2.p1.8.m8.1.1.cmml"><mi id="S4.SS2.SSS2.p1.8.m8.1.1.2" xref="S4.SS2.SSS2.p1.8.m8.1.1.2.cmml">z</mi><mrow id="S4.SS2.SSS2.p1.8.m8.1.1.3" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.cmml"><mi id="S4.SS2.SSS2.p1.8.m8.1.1.3.2" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.2.cmml">t</mi><mo id="S4.SS2.SSS2.p1.8.m8.1.1.3.1" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.1.cmml">−</mo><mn id="S4.SS2.SSS2.p1.8.m8.1.1.3.3" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.8.m8.1b"><apply id="S4.SS2.SSS2.p1.8.m8.1.1.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.8.m8.1.1.1.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.8.m8.1.1.2.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1.2">𝑧</ci><apply id="S4.SS2.SSS2.p1.8.m8.1.1.3.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1.3"><minus id="S4.SS2.SSS2.p1.8.m8.1.1.3.1.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.1"></minus><ci id="S4.SS2.SSS2.p1.8.m8.1.1.3.2.cmml" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.2">𝑡</ci><cn id="S4.SS2.SSS2.p1.8.m8.1.1.3.3.cmml" type="integer" xref="S4.SS2.SSS2.p1.8.m8.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.8.m8.1c">z_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.8.m8.1d">italic_z start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math>. Each layer of generation U-Net <math alttext="{\epsilon_{i}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.9.m9.1"><semantics id="S4.SS2.SSS2.p1.9.m9.1a"><msub id="S4.SS2.SSS2.p1.9.m9.1.1" xref="S4.SS2.SSS2.p1.9.m9.1.1.cmml"><mi id="S4.SS2.SSS2.p1.9.m9.1.1.2" xref="S4.SS2.SSS2.p1.9.m9.1.1.2.cmml">ϵ</mi><mi id="S4.SS2.SSS2.p1.9.m9.1.1.3" xref="S4.SS2.SSS2.p1.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.9.m9.1b"><apply id="S4.SS2.SSS2.p1.9.m9.1.1.cmml" xref="S4.SS2.SSS2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.9.m9.1.1.1.cmml" xref="S4.SS2.SSS2.p1.9.m9.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.9.m9.1.1.2.cmml" xref="S4.SS2.SSS2.p1.9.m9.1.1.2">italic-ϵ</ci><ci id="S4.SS2.SSS2.p1.9.m9.1.1.3.cmml" xref="S4.SS2.SSS2.p1.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.9.m9.1c">{\epsilon_{i}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.9.m9.1d">italic_ϵ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is conditioned with the corresponding layer of conditioning U-Net using zero-convolutions (<math alttext="\mathcal{Z}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.10.m10.1"><semantics id="S4.SS2.SSS2.p1.10.m10.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS2.p1.10.m10.1.1" xref="S4.SS2.SSS2.p1.10.m10.1.1.cmml">𝒵</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.10.m10.1b"><ci id="S4.SS2.SSS2.p1.10.m10.1.1.cmml" xref="S4.SS2.SSS2.p1.10.m10.1.1">𝒵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.10.m10.1c">\mathcal{Z}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p1.10.m10.1d">caligraphic_Z</annotation></semantics></math>) as follows:</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\epsilon_{\theta}\left(z_{t},t,c\right)_{i}=\epsilon_{\theta}\left(z_{t},t,c%
\right)_{i}+w\cdot\mathcal{Z}\left(\epsilon_{\theta}^{{}^{\prime}}\left(\left[%
z_{t},z_{m},x_{m},x_{d}\right],t\right)_{i}\right)" class="ltx_Math" display="block" id="S4.E2.m1.8"><semantics id="S4.E2.m1.8a"><mrow id="S4.E2.m1.8.8" xref="S4.E2.m1.8.8.cmml"><mrow id="S4.E2.m1.6.6.1" xref="S4.E2.m1.6.6.1.cmml"><msub id="S4.E2.m1.6.6.1.3" xref="S4.E2.m1.6.6.1.3.cmml"><mi id="S4.E2.m1.6.6.1.3.2" xref="S4.E2.m1.6.6.1.3.2.cmml">ϵ</mi><mi id="S4.E2.m1.6.6.1.3.3" xref="S4.E2.m1.6.6.1.3.3.cmml">θ</mi></msub><mo id="S4.E2.m1.6.6.1.2" xref="S4.E2.m1.6.6.1.2.cmml">⁢</mo><msub id="S4.E2.m1.6.6.1.1" xref="S4.E2.m1.6.6.1.1.cmml"><mrow id="S4.E2.m1.6.6.1.1.1.1" xref="S4.E2.m1.6.6.1.1.1.2.cmml"><mo id="S4.E2.m1.6.6.1.1.1.1.2" xref="S4.E2.m1.6.6.1.1.1.2.cmml">(</mo><msub id="S4.E2.m1.6.6.1.1.1.1.1" xref="S4.E2.m1.6.6.1.1.1.1.1.cmml"><mi id="S4.E2.m1.6.6.1.1.1.1.1.2" xref="S4.E2.m1.6.6.1.1.1.1.1.2.cmml">z</mi><mi id="S4.E2.m1.6.6.1.1.1.1.1.3" xref="S4.E2.m1.6.6.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E2.m1.6.6.1.1.1.1.3" xref="S4.E2.m1.6.6.1.1.1.2.cmml">,</mo><mi id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml">t</mi><mo id="S4.E2.m1.6.6.1.1.1.1.4" xref="S4.E2.m1.6.6.1.1.1.2.cmml">,</mo><mi id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml">c</mi><mo id="S4.E2.m1.6.6.1.1.1.1.5" xref="S4.E2.m1.6.6.1.1.1.2.cmml">)</mo></mrow><mi id="S4.E2.m1.6.6.1.1.3" xref="S4.E2.m1.6.6.1.1.3.cmml">i</mi></msub></mrow><mo id="S4.E2.m1.8.8.4" xref="S4.E2.m1.8.8.4.cmml">=</mo><mrow id="S4.E2.m1.8.8.3" xref="S4.E2.m1.8.8.3.cmml"><mrow id="S4.E2.m1.7.7.2.1" xref="S4.E2.m1.7.7.2.1.cmml"><msub id="S4.E2.m1.7.7.2.1.3" xref="S4.E2.m1.7.7.2.1.3.cmml"><mi id="S4.E2.m1.7.7.2.1.3.2" xref="S4.E2.m1.7.7.2.1.3.2.cmml">ϵ</mi><mi id="S4.E2.m1.7.7.2.1.3.3" xref="S4.E2.m1.7.7.2.1.3.3.cmml">θ</mi></msub><mo id="S4.E2.m1.7.7.2.1.2" xref="S4.E2.m1.7.7.2.1.2.cmml">⁢</mo><msub id="S4.E2.m1.7.7.2.1.1" xref="S4.E2.m1.7.7.2.1.1.cmml"><mrow id="S4.E2.m1.7.7.2.1.1.1.1" xref="S4.E2.m1.7.7.2.1.1.1.2.cmml"><mo id="S4.E2.m1.7.7.2.1.1.1.1.2" xref="S4.E2.m1.7.7.2.1.1.1.2.cmml">(</mo><msub id="S4.E2.m1.7.7.2.1.1.1.1.1" xref="S4.E2.m1.7.7.2.1.1.1.1.1.cmml"><mi id="S4.E2.m1.7.7.2.1.1.1.1.1.2" xref="S4.E2.m1.7.7.2.1.1.1.1.1.2.cmml">z</mi><mi id="S4.E2.m1.7.7.2.1.1.1.1.1.3" xref="S4.E2.m1.7.7.2.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E2.m1.7.7.2.1.1.1.1.3" xref="S4.E2.m1.7.7.2.1.1.1.2.cmml">,</mo><mi id="S4.E2.m1.3.3" xref="S4.E2.m1.3.3.cmml">t</mi><mo id="S4.E2.m1.7.7.2.1.1.1.1.4" xref="S4.E2.m1.7.7.2.1.1.1.2.cmml">,</mo><mi id="S4.E2.m1.4.4" xref="S4.E2.m1.4.4.cmml">c</mi><mo id="S4.E2.m1.7.7.2.1.1.1.1.5" xref="S4.E2.m1.7.7.2.1.1.1.2.cmml">)</mo></mrow><mi id="S4.E2.m1.7.7.2.1.1.3" xref="S4.E2.m1.7.7.2.1.1.3.cmml">i</mi></msub></mrow><mo id="S4.E2.m1.8.8.3.3" xref="S4.E2.m1.8.8.3.3.cmml">+</mo><mrow id="S4.E2.m1.8.8.3.2" xref="S4.E2.m1.8.8.3.2.cmml"><mrow id="S4.E2.m1.8.8.3.2.3" xref="S4.E2.m1.8.8.3.2.3.cmml"><mi id="S4.E2.m1.8.8.3.2.3.2" xref="S4.E2.m1.8.8.3.2.3.2.cmml">w</mi><mo id="S4.E2.m1.8.8.3.2.3.1" lspace="0.222em" rspace="0.222em" xref="S4.E2.m1.8.8.3.2.3.1.cmml">⋅</mo><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.8.8.3.2.3.3" xref="S4.E2.m1.8.8.3.2.3.3.cmml">𝒵</mi></mrow><mo id="S4.E2.m1.8.8.3.2.2" xref="S4.E2.m1.8.8.3.2.2.cmml">⁢</mo><mrow id="S4.E2.m1.8.8.3.2.1.1" xref="S4.E2.m1.8.8.3.2.1.1.1.cmml"><mo id="S4.E2.m1.8.8.3.2.1.1.2" xref="S4.E2.m1.8.8.3.2.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.8.8.3.2.1.1.1" xref="S4.E2.m1.8.8.3.2.1.1.1.cmml"><msubsup id="S4.E2.m1.8.8.3.2.1.1.1.3" xref="S4.E2.m1.8.8.3.2.1.1.1.3.cmml"><mi id="S4.E2.m1.8.8.3.2.1.1.1.3.2.2" xref="S4.E2.m1.8.8.3.2.1.1.1.3.2.2.cmml">ϵ</mi><mi id="S4.E2.m1.8.8.3.2.1.1.1.3.2.3" xref="S4.E2.m1.8.8.3.2.1.1.1.3.2.3.cmml">θ</mi><msup id="S4.E2.m1.8.8.3.2.1.1.1.3.3" xref="S4.E2.m1.8.8.3.2.1.1.1.3.3.cmml"><mi id="S4.E2.m1.8.8.3.2.1.1.1.3.3a" xref="S4.E2.m1.8.8.3.2.1.1.1.3.3.cmml"></mi><mo id="S4.E2.m1.8.8.3.2.1.1.1.3.3.1" xref="S4.E2.m1.8.8.3.2.1.1.1.3.3.1.cmml">′</mo></msup></msubsup><mo id="S4.E2.m1.8.8.3.2.1.1.1.2" xref="S4.E2.m1.8.8.3.2.1.1.1.2.cmml">⁢</mo><msub id="S4.E2.m1.8.8.3.2.1.1.1.1" xref="S4.E2.m1.8.8.3.2.1.1.1.1.cmml"><mrow id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.2.cmml"><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.2" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.2.cmml">(</mo><mrow id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml"><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.5" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml">[</mo><msub id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.6" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml">,</mo><msub id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.2" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.2.cmml">z</mi><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.3.cmml">m</mi></msub><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.7" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml">,</mo><msub id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.2" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.2.cmml">x</mi><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.3.cmml">m</mi></msub><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.8" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml">,</mo><msub id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.cmml"><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.2" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.2.cmml">x</mi><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.3.cmml">d</mi></msub><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.9" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml">]</mo></mrow><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.2.cmml">,</mo><mi id="S4.E2.m1.5.5" xref="S4.E2.m1.5.5.cmml">t</mi><mo id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.4" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.2.cmml">)</mo></mrow><mi id="S4.E2.m1.8.8.3.2.1.1.1.1.3" xref="S4.E2.m1.8.8.3.2.1.1.1.1.3.cmml">i</mi></msub></mrow><mo id="S4.E2.m1.8.8.3.2.1.1.3" xref="S4.E2.m1.8.8.3.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.8b"><apply id="S4.E2.m1.8.8.cmml" xref="S4.E2.m1.8.8"><eq id="S4.E2.m1.8.8.4.cmml" xref="S4.E2.m1.8.8.4"></eq><apply id="S4.E2.m1.6.6.1.cmml" xref="S4.E2.m1.6.6.1"><times id="S4.E2.m1.6.6.1.2.cmml" xref="S4.E2.m1.6.6.1.2"></times><apply id="S4.E2.m1.6.6.1.3.cmml" xref="S4.E2.m1.6.6.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.1.3.1.cmml" xref="S4.E2.m1.6.6.1.3">subscript</csymbol><ci id="S4.E2.m1.6.6.1.3.2.cmml" xref="S4.E2.m1.6.6.1.3.2">italic-ϵ</ci><ci id="S4.E2.m1.6.6.1.3.3.cmml" xref="S4.E2.m1.6.6.1.3.3">𝜃</ci></apply><apply id="S4.E2.m1.6.6.1.1.cmml" xref="S4.E2.m1.6.6.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.1.1.2.cmml" xref="S4.E2.m1.6.6.1.1">subscript</csymbol><vector id="S4.E2.m1.6.6.1.1.1.2.cmml" xref="S4.E2.m1.6.6.1.1.1.1"><apply id="S4.E2.m1.6.6.1.1.1.1.1.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.1.1.1.1.1.1.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.6.6.1.1.1.1.1.2.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1.2">𝑧</ci><ci id="S4.E2.m1.6.6.1.1.1.1.1.3.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1.3">𝑡</ci></apply><ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1">𝑡</ci><ci id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2">𝑐</ci></vector><ci id="S4.E2.m1.6.6.1.1.3.cmml" xref="S4.E2.m1.6.6.1.1.3">𝑖</ci></apply></apply><apply id="S4.E2.m1.8.8.3.cmml" xref="S4.E2.m1.8.8.3"><plus id="S4.E2.m1.8.8.3.3.cmml" xref="S4.E2.m1.8.8.3.3"></plus><apply id="S4.E2.m1.7.7.2.1.cmml" xref="S4.E2.m1.7.7.2.1"><times id="S4.E2.m1.7.7.2.1.2.cmml" xref="S4.E2.m1.7.7.2.1.2"></times><apply id="S4.E2.m1.7.7.2.1.3.cmml" xref="S4.E2.m1.7.7.2.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.2.1.3.1.cmml" xref="S4.E2.m1.7.7.2.1.3">subscript</csymbol><ci id="S4.E2.m1.7.7.2.1.3.2.cmml" xref="S4.E2.m1.7.7.2.1.3.2">italic-ϵ</ci><ci id="S4.E2.m1.7.7.2.1.3.3.cmml" xref="S4.E2.m1.7.7.2.1.3.3">𝜃</ci></apply><apply id="S4.E2.m1.7.7.2.1.1.cmml" xref="S4.E2.m1.7.7.2.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.2.1.1.2.cmml" xref="S4.E2.m1.7.7.2.1.1">subscript</csymbol><vector id="S4.E2.m1.7.7.2.1.1.1.2.cmml" xref="S4.E2.m1.7.7.2.1.1.1.1"><apply id="S4.E2.m1.7.7.2.1.1.1.1.1.cmml" xref="S4.E2.m1.7.7.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.2.1.1.1.1.1.1.cmml" xref="S4.E2.m1.7.7.2.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.7.7.2.1.1.1.1.1.2.cmml" xref="S4.E2.m1.7.7.2.1.1.1.1.1.2">𝑧</ci><ci id="S4.E2.m1.7.7.2.1.1.1.1.1.3.cmml" xref="S4.E2.m1.7.7.2.1.1.1.1.1.3">𝑡</ci></apply><ci id="S4.E2.m1.3.3.cmml" xref="S4.E2.m1.3.3">𝑡</ci><ci id="S4.E2.m1.4.4.cmml" xref="S4.E2.m1.4.4">𝑐</ci></vector><ci id="S4.E2.m1.7.7.2.1.1.3.cmml" xref="S4.E2.m1.7.7.2.1.1.3">𝑖</ci></apply></apply><apply id="S4.E2.m1.8.8.3.2.cmml" xref="S4.E2.m1.8.8.3.2"><times id="S4.E2.m1.8.8.3.2.2.cmml" xref="S4.E2.m1.8.8.3.2.2"></times><apply id="S4.E2.m1.8.8.3.2.3.cmml" xref="S4.E2.m1.8.8.3.2.3"><ci id="S4.E2.m1.8.8.3.2.3.1.cmml" xref="S4.E2.m1.8.8.3.2.3.1">⋅</ci><ci id="S4.E2.m1.8.8.3.2.3.2.cmml" xref="S4.E2.m1.8.8.3.2.3.2">𝑤</ci><ci id="S4.E2.m1.8.8.3.2.3.3.cmml" xref="S4.E2.m1.8.8.3.2.3.3">𝒵</ci></apply><apply id="S4.E2.m1.8.8.3.2.1.1.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1"><times id="S4.E2.m1.8.8.3.2.1.1.1.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.2"></times><apply id="S4.E2.m1.8.8.3.2.1.1.1.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.3.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3">superscript</csymbol><apply id="S4.E2.m1.8.8.3.2.1.1.1.3.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.3.2.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.8.8.3.2.1.1.1.3.2.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3.2.2">italic-ϵ</ci><ci id="S4.E2.m1.8.8.3.2.1.1.1.3.2.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3.2.3">𝜃</ci></apply><apply id="S4.E2.m1.8.8.3.2.1.1.1.3.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3.3"><ci id="S4.E2.m1.8.8.3.2.1.1.1.3.3.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.3.3.1">′</ci></apply></apply><apply id="S4.E2.m1.8.8.3.2.1.1.1.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1">subscript</csymbol><interval closure="open" id="S4.E2.m1.8.8.3.2.1.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1"><list id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.5.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4"><apply id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.2">𝑧</ci><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.2.2.3">𝑚</ci></apply><apply id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.2">𝑥</ci><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.3.3.3">𝑚</ci></apply><apply id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.1.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4">subscript</csymbol><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.2.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.2">𝑥</ci><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.1.1.1.4.4.3">𝑑</ci></apply></list><ci id="S4.E2.m1.5.5.cmml" xref="S4.E2.m1.5.5">𝑡</ci></interval><ci id="S4.E2.m1.8.8.3.2.1.1.1.1.3.cmml" xref="S4.E2.m1.8.8.3.2.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.8c">\epsilon_{\theta}\left(z_{t},t,c\right)_{i}=\epsilon_{\theta}\left(z_{t},t,c%
\right)_{i}+w\cdot\mathcal{Z}\left(\epsilon_{\theta}^{{}^{\prime}}\left(\left[%
z_{t},z_{m},x_{m},x_{d}\right],t\right)_{i}\right)</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.8d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_w ⋅ caligraphic_Z ( italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( [ italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ] , italic_t ) start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.3"><math alttext="w" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.1.m1.1"><semantics id="S4.SS2.SSS2.p3.1.m1.1a"><mi id="S4.SS2.SSS2.p3.1.m1.1.1" xref="S4.SS2.SSS2.p3.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.1.m1.1b"><ci id="S4.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p3.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.1.m1.1d">italic_w</annotation></semantics></math> is the preservation scale to adjust the influence of conditioning. We set <math alttext="w" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.2.m2.1"><semantics id="S4.SS2.SSS2.p3.2.m2.1a"><mi id="S4.SS2.SSS2.p3.2.m2.1.1" xref="S4.SS2.SSS2.p3.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.2.m2.1b"><ci id="S4.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p3.2.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.2.m2.1c">w</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.2.m2.1d">italic_w</annotation></semantics></math> to be <math alttext="1.0" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.3.m3.1"><semantics id="S4.SS2.SSS2.p3.3.m3.1a"><mn id="S4.SS2.SSS2.p3.3.m3.1.1" xref="S4.SS2.SSS2.p3.3.m3.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.3.m3.1b"><cn id="S4.SS2.SSS2.p3.3.m3.1.1.cmml" type="float" xref="S4.SS2.SSS2.p3.3.m3.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.3.m3.1c">1.0</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.3.m3.1d">1.0</annotation></semantics></math> for all our experiments. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p4">
<p class="ltx_p" id="S4.SS2.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p4.1.1">Impact of Depth Conditioning.</span>

We demonstrate the importance of depth conditioning for the reflection generation task as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F5" title="Figure 5 ‣ 4.2.3 Depth Normalization ‣ 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">5</span></a>.
From Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F5" title="Figure 5 ‣ 4.2.3 Depth Normalization ‣ 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">5</span></a> (a), it can be clearly seen that BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> fine-tuned on SynMirror fails to generate accurate mirror reflection of the object in the input image with high fidelity. For a simple object like a “baseball ball”, the <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p4.1.2">“w/o depth”</span> BrushNet-FT model generates a ball in which the shape is not preserved.
Similarly, in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F5" title="Figure 5 ‣ 4.2.3 Depth Normalization ‣ 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">5</span></a> (b), the shape of “chair” is asymmetrical. These examples show that depth information provided with the proposed normalization scheme generates better reflections on the mirror.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Depth Normalization</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.2">The range of input depth is between <math alttext="[0,\infty)" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.1.m1.2"><semantics id="S4.SS2.SSS3.p1.1.m1.2a"><mrow id="S4.SS2.SSS3.p1.1.m1.2.3.2" xref="S4.SS2.SSS3.p1.1.m1.2.3.1.cmml"><mo id="S4.SS2.SSS3.p1.1.m1.2.3.2.1" stretchy="false" xref="S4.SS2.SSS3.p1.1.m1.2.3.1.cmml">[</mo><mn id="S4.SS2.SSS3.p1.1.m1.1.1" xref="S4.SS2.SSS3.p1.1.m1.1.1.cmml">0</mn><mo id="S4.SS2.SSS3.p1.1.m1.2.3.2.2" xref="S4.SS2.SSS3.p1.1.m1.2.3.1.cmml">,</mo><mi id="S4.SS2.SSS3.p1.1.m1.2.2" mathvariant="normal" xref="S4.SS2.SSS3.p1.1.m1.2.2.cmml">∞</mi><mo id="S4.SS2.SSS3.p1.1.m1.2.3.2.3" stretchy="false" xref="S4.SS2.SSS3.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.1.m1.2b"><interval closure="closed-open" id="S4.SS2.SSS3.p1.1.m1.2.3.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.2.3.2"><cn id="S4.SS2.SSS3.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p1.1.m1.1.1">0</cn><infinity id="S4.SS2.SSS3.p1.1.m1.2.2.cmml" xref="S4.SS2.SSS3.p1.1.m1.2.2"></infinity></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.1.m1.2c">[0,\infty)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.1.m1.2d">[ 0 , ∞ )</annotation></semantics></math>. The encoder of the U-Net expects the input to be in the range <math alttext="[-1,1]" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.2.m2.2"><semantics id="S4.SS2.SSS3.p1.2.m2.2a"><mrow id="S4.SS2.SSS3.p1.2.m2.2.2.1" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.cmml"><mo id="S4.SS2.SSS3.p1.2.m2.2.2.1.2" stretchy="false" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.cmml">[</mo><mrow id="S4.SS2.SSS3.p1.2.m2.2.2.1.1" xref="S4.SS2.SSS3.p1.2.m2.2.2.1.1.cmml"><mo id="S4.SS2.SSS3.p1.2.m2.2.2.1.1a" xref="S4.SS2.SSS3.p1.2.m2.2.2.1.1.cmml">−</mo><mn id="S4.SS2.SSS3.p1.2.m2.2.2.1.1.2" xref="S4.SS2.SSS3.p1.2.m2.2.2.1.1.2.cmml">1</mn></mrow><mo id="S4.SS2.SSS3.p1.2.m2.2.2.1.3" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.cmml">,</mo><mn id="S4.SS2.SSS3.p1.2.m2.1.1" xref="S4.SS2.SSS3.p1.2.m2.1.1.cmml">1</mn><mo id="S4.SS2.SSS3.p1.2.m2.2.2.1.4" stretchy="false" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.2.m2.2b"><interval closure="closed" id="S4.SS2.SSS3.p1.2.m2.2.2.2.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.2.1"><apply id="S4.SS2.SSS3.p1.2.m2.2.2.1.1.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.2.1.1"><minus id="S4.SS2.SSS3.p1.2.m2.2.2.1.1.1.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.2.1.1"></minus><cn id="S4.SS2.SSS3.p1.2.m2.2.2.1.1.2.cmml" type="integer" xref="S4.SS2.SSS3.p1.2.m2.2.2.1.1.2">1</cn></apply><cn id="S4.SS2.SSS3.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p1.2.m2.1.1">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.2.m2.2c">[-1,1]</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.2.m2.2d">[ - 1 , 1 ]</annotation></semantics></math>. Hence, we need to normalize the input depth. As discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, using affine-invariant depth scaling can bring the input depth into the desired range. Image reflection tasks only require the relative distance between the mirror and the scene it reflects. Depth values behind the mirror will not be critical for the reflection generation task. Hence, we use a specifically tailored normalization for our task which is computed as:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{d}=\left(\frac{d_{clipped}}{d_{max}+\Delta_{depth}}-0.5\right)\times 2," class="ltx_Math" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mover accent="true" id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.3.2.cmml">d</mi><mo id="S4.E3.m1.1.1.1.1.3.1" xref="S4.E3.m1.1.1.1.1.3.1.cmml">^</mo></mover><mo id="S4.E3.m1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml"><mfrac id="S4.E3.m1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">d</mi><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">c</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">l</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1a" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.4" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.4.cmml">i</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1b" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.5" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.5.cmml">p</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1c" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.6" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.6.cmml">p</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1d" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.7" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.7.cmml">e</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1e" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.8" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.8.cmml">d</mi></mrow></msub><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml"><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">d</mi><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.2.cmml">m</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.3.cmml">a</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.1a" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.4" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.4.cmml">x</mi></mrow></msub><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">+</mo><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.2" mathvariant="normal" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.2.cmml">Δ</mi><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.2.cmml">d</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.3.cmml">e</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1a" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.4" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.4.cmml">p</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1b" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.5" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.5.cmml">t</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1c" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.6" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.6.cmml">h</mi></mrow></msub></mrow></mfrac><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.E3.m1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml">0.5</mn></mrow><mo id="S4.E3.m1.1.1.1.1.1.1.1.3" rspace="0.055em" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E3.m1.1.1.1.1.1.2" rspace="0.222em" xref="S4.E3.m1.1.1.1.1.1.2.cmml">×</mo><mn id="S4.E3.m1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.3.cmml">2</mn></mrow></mrow><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><eq id="S4.E3.m1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.2"></eq><apply id="S4.E3.m1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.3"><ci id="S4.E3.m1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3.1">^</ci><ci id="S4.E3.m1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.2">𝑑</ci></apply><apply id="S4.E3.m1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1"><times id="S4.E3.m1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.2"></times><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1"><minus id="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2"><divide id="S4.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2"></divide><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.2">𝑑</ci><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3"><times id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.1"></times><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.2">𝑐</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.3">𝑙</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.4.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.4">𝑖</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.5.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.5">𝑝</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.6.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.6">𝑝</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.7.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.7">𝑒</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.8.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.2.3.8">𝑑</ci></apply></apply><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3"><plus id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.1"></plus><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.2">𝑑</ci><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3"><times id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.1"></times><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.2">𝑚</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.3">𝑎</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.4.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.2.3.4">𝑥</ci></apply></apply><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.2">Δ</ci><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3"><times id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.1"></times><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.2">𝑑</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.3">𝑒</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.4.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.4">𝑝</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.5.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.5">𝑡</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.6.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.3.3.3.6">ℎ</ci></apply></apply></apply></apply><cn id="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml" type="float" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3">0.5</cn></apply><cn id="S4.E3.m1.1.1.1.1.1.3.cmml" type="integer" xref="S4.E3.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\hat{d}=\left(\frac{d_{clipped}}{d_{max}+\Delta_{depth}}-0.5\right)\times 2,</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">over^ start_ARG italic_d end_ARG = ( divide start_ARG italic_d start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p italic_p italic_e italic_d end_POSTSUBSCRIPT end_ARG start_ARG italic_d start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT + roman_Δ start_POSTSUBSCRIPT italic_d italic_e italic_p italic_t italic_h end_POSTSUBSCRIPT end_ARG - 0.5 ) × 2 ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS3.p1.8">where <math alttext="d_{clipped}" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.3.m1.1"><semantics id="S4.SS2.SSS3.p1.3.m1.1a"><msub id="S4.SS2.SSS3.p1.3.m1.1.1" xref="S4.SS2.SSS3.p1.3.m1.1.1.cmml"><mi id="S4.SS2.SSS3.p1.3.m1.1.1.2" xref="S4.SS2.SSS3.p1.3.m1.1.1.2.cmml">d</mi><mrow id="S4.SS2.SSS3.p1.3.m1.1.1.3" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.cmml"><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.2" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.2.cmml">c</mi><mo id="S4.SS2.SSS3.p1.3.m1.1.1.3.1" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.3" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.3.cmml">l</mi><mo id="S4.SS2.SSS3.p1.3.m1.1.1.3.1a" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.4" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.4.cmml">i</mi><mo id="S4.SS2.SSS3.p1.3.m1.1.1.3.1b" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.5" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.5.cmml">p</mi><mo id="S4.SS2.SSS3.p1.3.m1.1.1.3.1c" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.6" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.6.cmml">p</mi><mo id="S4.SS2.SSS3.p1.3.m1.1.1.3.1d" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.7" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.7.cmml">e</mi><mo id="S4.SS2.SSS3.p1.3.m1.1.1.3.1e" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.3.m1.1.1.3.8" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.8.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.3.m1.1b"><apply id="S4.SS2.SSS3.p1.3.m1.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m1.1.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.3.m1.1.1.2.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.2">𝑑</ci><apply id="S4.SS2.SSS3.p1.3.m1.1.1.3.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3"><times id="S4.SS2.SSS3.p1.3.m1.1.1.3.1.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.1"></times><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.2.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.2">𝑐</ci><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.3.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.3">𝑙</ci><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.4.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.4">𝑖</ci><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.5.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.5">𝑝</ci><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.6.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.6">𝑝</ci><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.7.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.7">𝑒</ci><ci id="S4.SS2.SSS3.p1.3.m1.1.1.3.8.cmml" xref="S4.SS2.SSS3.p1.3.m1.1.1.3.8">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.3.m1.1c">d_{clipped}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.3.m1.1d">italic_d start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p italic_p italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math> is input depth clipped between range <math alttext="[0,d_{max}+\Delta_{depth}]" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.4.m2.2"><semantics id="S4.SS2.SSS3.p1.4.m2.2a"><mrow id="S4.SS2.SSS3.p1.4.m2.2.2.1" xref="S4.SS2.SSS3.p1.4.m2.2.2.2.cmml"><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.2" stretchy="false" xref="S4.SS2.SSS3.p1.4.m2.2.2.2.cmml">[</mo><mn id="S4.SS2.SSS3.p1.4.m2.1.1" xref="S4.SS2.SSS3.p1.4.m2.1.1.cmml">0</mn><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.3" xref="S4.SS2.SSS3.p1.4.m2.2.2.2.cmml">,</mo><mrow id="S4.SS2.SSS3.p1.4.m2.2.2.1.1" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.cmml"><msub id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.cmml"><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.2" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.2.cmml">d</mi><mrow id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.cmml"><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.2" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.2.cmml">m</mi><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.1" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.3" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.3.cmml">a</mi><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.1a" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.4" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.1" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.1.cmml">+</mo><msub id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.cmml"><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.2" mathvariant="normal" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.2.cmml">Δ</mi><mrow id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.cmml"><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.2" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.2.cmml">d</mi><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.3" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.3.cmml">e</mi><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1a" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.4" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.4.cmml">p</mi><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1b" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.5" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.5.cmml">t</mi><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1c" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.6" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.6.cmml">h</mi></mrow></msub></mrow><mo id="S4.SS2.SSS3.p1.4.m2.2.2.1.4" stretchy="false" xref="S4.SS2.SSS3.p1.4.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.4.m2.2b"><interval closure="closed" id="S4.SS2.SSS3.p1.4.m2.2.2.2.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1"><cn id="S4.SS2.SSS3.p1.4.m2.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p1.4.m2.1.1">0</cn><apply id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1"><plus id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.1.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.1"></plus><apply id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.1.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.2.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.2">𝑑</ci><apply id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3"><times id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.1.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.1"></times><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.2.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.2">𝑚</ci><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.3.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.3">𝑎</ci><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.4.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.2.3.4">𝑥</ci></apply></apply><apply id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.1.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3">subscript</csymbol><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.2.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.2">Δ</ci><apply id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3"><times id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.1"></times><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.2.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.2">𝑑</ci><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.3.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.3">𝑒</ci><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.4.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.4">𝑝</ci><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.5.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.5">𝑡</ci><ci id="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.6.cmml" xref="S4.SS2.SSS3.p1.4.m2.2.2.1.1.3.3.6">ℎ</ci></apply></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.4.m2.2c">[0,d_{max}+\Delta_{depth}]</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.4.m2.2d">[ 0 , italic_d start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT + roman_Δ start_POSTSUBSCRIPT italic_d italic_e italic_p italic_t italic_h end_POSTSUBSCRIPT ]</annotation></semantics></math>. <math alttext="d_{max}" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.5.m3.1"><semantics id="S4.SS2.SSS3.p1.5.m3.1a"><msub id="S4.SS2.SSS3.p1.5.m3.1.1" xref="S4.SS2.SSS3.p1.5.m3.1.1.cmml"><mi id="S4.SS2.SSS3.p1.5.m3.1.1.2" xref="S4.SS2.SSS3.p1.5.m3.1.1.2.cmml">d</mi><mrow id="S4.SS2.SSS3.p1.5.m3.1.1.3" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.cmml"><mi id="S4.SS2.SSS3.p1.5.m3.1.1.3.2" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.2.cmml">m</mi><mo id="S4.SS2.SSS3.p1.5.m3.1.1.3.1" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.5.m3.1.1.3.3" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.3.cmml">a</mi><mo id="S4.SS2.SSS3.p1.5.m3.1.1.3.1a" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.5.m3.1.1.3.4" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.5.m3.1b"><apply id="S4.SS2.SSS3.p1.5.m3.1.1.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.5.m3.1.1.1.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.5.m3.1.1.2.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1.2">𝑑</ci><apply id="S4.SS2.SSS3.p1.5.m3.1.1.3.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1.3"><times id="S4.SS2.SSS3.p1.5.m3.1.1.3.1.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.1"></times><ci id="S4.SS2.SSS3.p1.5.m3.1.1.3.2.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.2">𝑚</ci><ci id="S4.SS2.SSS3.p1.5.m3.1.1.3.3.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.3">𝑎</ci><ci id="S4.SS2.SSS3.p1.5.m3.1.1.3.4.cmml" xref="S4.SS2.SSS3.p1.5.m3.1.1.3.4">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.5.m3.1c">d_{max}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.5.m3.1d">italic_d start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT</annotation></semantics></math> represents the maximum depth on the mirror mask <math alttext="m" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.6.m4.1"><semantics id="S4.SS2.SSS3.p1.6.m4.1a"><mi id="S4.SS2.SSS3.p1.6.m4.1.1" xref="S4.SS2.SSS3.p1.6.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.6.m4.1b"><ci id="S4.SS2.SSS3.p1.6.m4.1.1.cmml" xref="S4.SS2.SSS3.p1.6.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.6.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.6.m4.1d">italic_m</annotation></semantics></math>. We set <math alttext="\Delta_{depth}" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.7.m5.1"><semantics id="S4.SS2.SSS3.p1.7.m5.1a"><msub id="S4.SS2.SSS3.p1.7.m5.1.1" xref="S4.SS2.SSS3.p1.7.m5.1.1.cmml"><mi id="S4.SS2.SSS3.p1.7.m5.1.1.2" mathvariant="normal" xref="S4.SS2.SSS3.p1.7.m5.1.1.2.cmml">Δ</mi><mrow id="S4.SS2.SSS3.p1.7.m5.1.1.3" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.cmml"><mi id="S4.SS2.SSS3.p1.7.m5.1.1.3.2" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.2.cmml">d</mi><mo id="S4.SS2.SSS3.p1.7.m5.1.1.3.1" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.7.m5.1.1.3.3" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.3.cmml">e</mi><mo id="S4.SS2.SSS3.p1.7.m5.1.1.3.1a" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.7.m5.1.1.3.4" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.4.cmml">p</mi><mo id="S4.SS2.SSS3.p1.7.m5.1.1.3.1b" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.7.m5.1.1.3.5" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.5.cmml">t</mi><mo id="S4.SS2.SSS3.p1.7.m5.1.1.3.1c" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.SSS3.p1.7.m5.1.1.3.6" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.6.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.7.m5.1b"><apply id="S4.SS2.SSS3.p1.7.m5.1.1.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.7.m5.1.1.1.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.7.m5.1.1.2.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.2">Δ</ci><apply id="S4.SS2.SSS3.p1.7.m5.1.1.3.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3"><times id="S4.SS2.SSS3.p1.7.m5.1.1.3.1.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.1"></times><ci id="S4.SS2.SSS3.p1.7.m5.1.1.3.2.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.2">𝑑</ci><ci id="S4.SS2.SSS3.p1.7.m5.1.1.3.3.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.3">𝑒</ci><ci id="S4.SS2.SSS3.p1.7.m5.1.1.3.4.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.4">𝑝</ci><ci id="S4.SS2.SSS3.p1.7.m5.1.1.3.5.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.5">𝑡</ci><ci id="S4.SS2.SSS3.p1.7.m5.1.1.3.6.cmml" xref="S4.SS2.SSS3.p1.7.m5.1.1.3.6">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.7.m5.1c">\Delta_{depth}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.7.m5.1d">roman_Δ start_POSTSUBSCRIPT italic_d italic_e italic_p italic_t italic_h end_POSTSUBSCRIPT</annotation></semantics></math> to the value of <math alttext="0.5" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.8.m6.1"><semantics id="S4.SS2.SSS3.p1.8.m6.1a"><mn id="S4.SS2.SSS3.p1.8.m6.1.1" xref="S4.SS2.SSS3.p1.8.m6.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.8.m6.1b"><cn id="S4.SS2.SSS3.p1.8.m6.1.1.cmml" type="float" xref="S4.SS2.SSS3.p1.8.m6.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.8.m6.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.8.m6.1d">0.5</annotation></semantics></math>. This normalization aids us in adapting to any of the pre-trained monocular depth estimation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib54" title=""><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS3.p2">
<p class="ltx_p" id="S4.SS2.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p2.1.1">Inference.</span>
During inference, we assume a predefined mask is available to indicate where the mirror reflection should be generated. The user can easily create this mask, giving better control over the generation of the reflections. We leverage Marigold <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, a monocular depth estimation method to generate the scene depth map. Then, we feed these inputs to our pipeline as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.F4" title="Figure 4 ‣ 4.1 Preliminaries ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4</span></a>. We show in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS4" title="C.4 Robustness to pre-trained monocular depth estimation methods ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">C.4</span></a> that we can utilize alternative methods, such as DepthAnything <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib54" title=""><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite> as a preferred monocular depth estimation technique, demonstrating the robustness of our method to the choice of different monocular depth estimation techniques.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="458" id="S4.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.5.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F5.6.2" style="font-size:90%;">Impact of depth conditioning<span class="ltx_text ltx_font_medium" id="S4.F5.6.2.1"> on the reflection generation quality. Notice the irregular shape of the “baseball” and “chair” marked in <span class="ltx_text" id="S4.F5.6.2.1.1" style="color:#FF0000;">red</span>. In comparison, our method preserves the structure of the object (marked in <span class="ltx_text" id="S4.F5.6.2.1.2" style="color:#00FF00;">green</span>).</span></span></figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments &amp; Results</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we discuss the dataset, baseline comparisons, and extensive experiments used to evaluate our model. We provide additional training and implementation details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2" title="Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.6"><span class="ltx_text ltx_font_bold" id="S5.p2.6.1">Dataset.</span>
As discussed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.SS1" title="3.1 Dataset Generation and Processing ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3.1</span></a>, SynMirror consists of <math alttext="66,068" class="ltx_Math" display="inline" id="S5.p2.1.m1.2"><semantics id="S5.p2.1.m1.2a"><mrow id="S5.p2.1.m1.2.3.2" xref="S5.p2.1.m1.2.3.1.cmml"><mn id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">66</mn><mo id="S5.p2.1.m1.2.3.2.1" xref="S5.p2.1.m1.2.3.1.cmml">,</mo><mn id="S5.p2.1.m1.2.2" xref="S5.p2.1.m1.2.2.cmml">068</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.2b"><list id="S5.p2.1.m1.2.3.1.cmml" xref="S5.p2.1.m1.2.3.2"><cn id="S5.p2.1.m1.1.1.cmml" type="integer" xref="S5.p2.1.m1.1.1">66</cn><cn id="S5.p2.1.m1.2.2.cmml" type="integer" xref="S5.p2.1.m1.2.2">068</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.2c">66,068</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.2d">66 , 068</annotation></semantics></math> objects and <math alttext="198,204" class="ltx_Math" display="inline" id="S5.p2.2.m2.2"><semantics id="S5.p2.2.m2.2a"><mrow id="S5.p2.2.m2.2.3.2" xref="S5.p2.2.m2.2.3.1.cmml"><mn id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">198</mn><mo id="S5.p2.2.m2.2.3.2.1" xref="S5.p2.2.m2.2.3.1.cmml">,</mo><mn id="S5.p2.2.m2.2.2" xref="S5.p2.2.m2.2.2.cmml">204</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.2b"><list id="S5.p2.2.m2.2.3.1.cmml" xref="S5.p2.2.m2.2.3.2"><cn id="S5.p2.2.m2.1.1.cmml" type="integer" xref="S5.p2.2.m2.1.1">198</cn><cn id="S5.p2.2.m2.2.2.cmml" type="integer" xref="S5.p2.2.m2.2.2">204</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.2c">198,204</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.2d">198 , 204</annotation></semantics></math> rendered images. We sample <math alttext="1000" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><mn id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><cn id="S5.p2.3.m3.1.1.cmml" type="integer" xref="S5.p2.3.m3.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">1000</annotation></semantics></math> objects from the full dataset to create  MirrorBench, a benchmark to evaluate our method and various other baselines. In this benchmark, we have <math alttext="1497" class="ltx_Math" display="inline" id="S5.p2.4.m4.1"><semantics id="S5.p2.4.m4.1a"><mn id="S5.p2.4.m4.1.1" xref="S5.p2.4.m4.1.1.cmml">1497</mn><annotation-xml encoding="MathML-Content" id="S5.p2.4.m4.1b"><cn id="S5.p2.4.m4.1.1.cmml" type="integer" xref="S5.p2.4.m4.1.1">1497</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.m4.1c">1497</annotation><annotation encoding="application/x-llamapun" id="S5.p2.4.m4.1d">1497</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.p2.6.2">“known”</span> class samples, i.e., these object categories were seen during training, and <math alttext="1494" class="ltx_Math" display="inline" id="S5.p2.5.m5.1"><semantics id="S5.p2.5.m5.1a"><mn id="S5.p2.5.m5.1.1" xref="S5.p2.5.m5.1.1.cmml">1494</mn><annotation-xml encoding="MathML-Content" id="S5.p2.5.m5.1b"><cn id="S5.p2.5.m5.1.1.cmml" type="integer" xref="S5.p2.5.m5.1.1">1494</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.5.m5.1c">1494</annotation><annotation encoding="application/x-llamapun" id="S5.p2.5.m5.1d">1494</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.p2.6.3">“unknown”</span> class samples, i.e., these object categories were unseen during training. MirrorBench thus comprises of a total of <math alttext="2991" class="ltx_Math" display="inline" id="S5.p2.6.m6.1"><semantics id="S5.p2.6.m6.1a"><mn id="S5.p2.6.m6.1.1" xref="S5.p2.6.m6.1.1.cmml">2991</mn><annotation-xml encoding="MathML-Content" id="S5.p2.6.m6.1b"><cn id="S5.p2.6.m6.1.1.cmml" type="integer" xref="S5.p2.6.m6.1.1">2991</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.6.m6.1c">2991</annotation><annotation encoding="application/x-llamapun" id="S5.p2.6.m6.1d">2991</annotation></semantics></math> images. We also show the generalization capabilities of our method on a few samples from the Google Scanned Objects(GSO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite> dataset.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="673" id="S5.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.3.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F6.4.2" style="font-size:90%;">Additional Results.<span class="ltx_text ltx_font_medium" id="S5.F6.4.2.1"> Our method effectively preserves the shape of objects, as demonstrated in (a) the lawn chair and (b) the swivel chair. Check in the zoomed-in regions. Additionally, our method accurately positions the objects within the mirror (c) and (d), corroborating the effectiveness of depth-conditioning in our method. Text-prompts used are described in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS2" title="E.2 Text prompts used in the experiments ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">E.2</span></a>.</span></span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">Baselines.</span>
As discussed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4" title="4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4</span></a>, we formulate generating reflection of an object as an image-inpainting problem. We evaluate various state-of-the-art inpainting methods on MirrorBench. We compare our method with pre-trained Stable-Diffusion-Inpainting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite>, PowerPaint <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib64" title=""><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite> and BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>. We denote zero-shot methods by appending “<span class="ltx_text ltx_font_bold" id="S5.p3.1.2">-ZS</span>” to their names. We fine-tune BrushNet on  SynMirror and refer to this fine-tuned version as <span class="ltx_text ltx_font_bold" id="S5.p3.1.3">“BrushNet-FT”</span> hereafter.</p>
</div>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="813" id="S5.F7.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F7.5.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F7.6.2" style="font-size:90%;">Reflection generation comparison with general inpainting methods.<span class="ltx_text ltx_font_medium" id="S5.F7.6.2.1"> We compare our results with zero-shot baselines Stable Diffusion 1.5 Inpainting-ZS, PowerPaint-ZS and BrushNet-ZS. Further, we finetune BrushNet on SynMirror and refer to it as BrushNet-FT. The top four rows compare results on <span class="ltx_text ltx_font_italic" id="S5.F7.6.2.1.1">“unknown”</span> categories, and the bottom two rows show results on <span class="ltx_text ltx_font_italic" id="S5.F7.6.2.1.2">“known”</span> categories from MirrorBench. Zero-shot methods either fail to generate a reflection on the mirror or generate a reflection at an incorrect position. In comparison, BrushNet-FT generates plausible reflections, but with geometric inaccuracies. Our method improves on shape preservation of the object, floor texture and correct placement of the object in the mirror reflection.</span></span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.p4">
<p class="ltx_p" id="S5.p4.1"><span class="ltx_text ltx_font_bold" id="S5.p4.1.1">Metrics.</span>
We benchmark based on four aspects: masked region preservation, reflection generation quality, Reflection Geometry and text alignment.</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.I1.i1.p1.1.1">Masked Region Preservation.</span> We report Peak-Signal-to-Noise ratio (PSNR), Structural Similarity (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib60" title=""><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite> in the unmasked region between generated and the real image. This shows how much original image content is preserved by an inpainting method.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.I1.i2.p1.1.1">Reflection Generation Quality.</span></p>
</div>
<div class="ltx_para" id="S5.I1.i2.p2">
<p class="ltx_p" id="S5.I1.i2.p2.1">For measuring the quality of the reflection of the object and the scene, we compute PSNR, SSIM and LPIPS on the masked region containing the object and floor of the ground truth image.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.I1.i3.p1.1.1">Reflection Geometry.</span> We measure the geometric accuracy of the generated reflection using Intersection over Union (IoU) between the segmentation mask of the ground-truth object and the generated object in the reflection region specified by the input mirror mask. We utilize SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> to get the mask of an object in the reflection region. More details are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS3" title="E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">E.3</span></a>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.I1.i4.p1.1.1">Text Alignment.</span> To evaluate the text-image consistency between the generated image and the text prompts, we use CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite> Similarity.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Qualitative Results</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Comparison with Zero-shot Baselines.</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">We observe that all zero-shot baselines fail in generating realistic reflections on the mirror. PowerPaint generates the “lipstick” at the incorrect position, whereas Stable Diffusion 1.5 Inpainting generates two reflections when only one is present. No zero-shot method is able to provide a plausible reflection for a “cement mixer” as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F7" title="Figure 7 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">7</span></a> (top row). BrushNet-FT performs better than the zero-shot methods, which shows the utility of the proposed dataset. However, it has issues such as the incorrect size of the object in the generated reflections for “cement mixer” and “lipstick” as shown in the first two rows of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F7" title="Figure 7 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">7</span></a>. In comparison, our method is able to generate realistic reflections of the objects.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.1">Additional Results.</span>
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F6" title="Figure 6 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">6</span></a> shows more comparisons between BrushNet-FT and our method. First row shows that there are some structural inaccuracies in the generated reflection. Check how BrushNet-FT is not able to get the structure of the “lawn chair” in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F6" title="Figure 6 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">6</span></a> (a) and swivel chair in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F6" title="Figure 6 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">6</span></a> (b). However, our method is able to generate the reflection of the object in a geometrically accurate position. Further in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F6" title="Figure 6 ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">6</span></a> (c) and (d), notice that the reflection is generated at wrong position in the mirror by BrushNet-FT.</p>
</div>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="416" id="S5.F8.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.3.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F8.4.2" style="font-size:90%;">Change of Viewpoints for mirror and object.<span class="ltx_text ltx_font_medium" id="S5.F8.4.2.1">
Our method preserves the shape of the object from different viewpoints. This illustrates our method’s ability to utilize 3D cues and generate accurate reflection of the object.</span></span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="250" id="S5.F9.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F9.3.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F9.4.2" style="font-size:90%;">Generalization on GSO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite>.<span class="ltx_text ltx_font_medium" id="S5.F9.4.2.1"> Our method generates accurate reflections for unseen real-world scanned objects. This substantiates the generalization capabilities of our method.</span></span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p3.1.1">Qualitative Results on GSO.</span>
We further benchmark the performance of our method on a completely held-out set of GSO objects. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F9" title="Figure 9 ‣ Comparison with Zero-shot Baselines. ‣ 5.1 Qualitative Results ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">9</span></a> compares our method with the fine-tuned baseline: BrushNet-FT. Notice that the bowl is floating in the air for BrushNet-FT and the size of the bag in the reflection is large and unnatural. In comparison, our method generates the reflection with better photo-realism and geometric accuracy.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p4">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p4.1.1">Change of Viewpoints.</span>
To evaluate the consistency of our method in generating reflections across varying viewpoints, we designed a continuous trajectory for testing. The results inferred from our method, as depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.F8" title="Figure 8 ‣ Comparison with Zero-shot Baselines. ‣ 5.1 Qualitative Results ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">8</span></a>, demonstrate that the reflection of the “sofa-seat” remains consistent as the viewpoint shifts. Additionally, our method preserves high-fidelity reflections for the floor.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Ablation studies</h3>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.8.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text ltx_font_bold" id="S5.T2.9.2" style="font-size:90%;">Image Generation Quality.<span class="ltx_text ltx_font_medium" id="S5.T2.9.2.1"> We compare the quality of the inpainted image with fine-tuned baseline method. The best results are shown in </span>bold<span class="ltx_text ltx_font_medium" id="S5.T2.9.2.2">. Our method outperforms the baseline across all metrics, proving its effectiveness.</span></span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.4" style="width:415.2pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S5.T2.4.4"><span class="ltx_text" id="S5.T2.4.4.4">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.4.4.4.4">
<span class="ltx_thead">
<span class="ltx_tr" id="S5.T2.4.4.4.4.5.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T2.4.4.4.4.5.1.1">Metrics</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_colspan ltx_colspan_3" id="S5.T2.4.4.4.4.5.1.2">Masked Image Preservation</span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.4.4.4.4.5.1.3">Text Alignment</span></span>
<span class="ltx_tr" id="S5.T2.4.4.4.4.4">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.4.4.4.4.4.5">Models</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.1.1.1">PSNR</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.1.1.1.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T2.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.2.2.2.2.2.2.1">SSIM</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.2.2.2.2.2.2.m1.1"><semantics id="S5.T2.2.2.2.2.2.2.m1.1a"><mo id="S5.T2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T2.2.2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.2.2.2.m1.1d">↑</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S5.T2.3.3.3.3.3.3.1">LPIPS</span> <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.3.3.3.3.3.3.m1.1"><semantics id="S5.T2.3.3.3.3.3.3.m1.1a"><mo id="S5.T2.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T2.3.3.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.3.3.3.m1.1d">↓</annotation></semantics></math></span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.4.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.4.4.1">CLIP Sim</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.4.4.4.4.4.4.m1.1"><semantics id="S5.T2.4.4.4.4.4.4.m1.1a"><mo id="S5.T2.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T2.4.4.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.4.4.m1.1b"><ci id="S5.T2.4.4.4.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.4.4.4.4.m1.1d">↑</annotation></semantics></math></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T2.4.4.4.4.6.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.4.4.4.4.6.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.6.1.1.1">Brushnet-FT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.4.4.6.1.2">23.06</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.4.4.6.1.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.6.1.3.1">0.84</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.4.4.4.4.6.1.4">0.058</span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T2.4.4.4.4.6.1.5">24.90</span></span>
<span class="ltx_tr" id="S5.T2.4.4.4.4.7.2">
<span class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T2.4.4.4.4.7.2.1"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.7.2.1.1">Ours</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.4.7.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.7.2.2.1">24.22</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.4.7.2.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.7.2.3.1">0.84</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.4.4.4.4.7.2.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.7.2.4.1">0.051</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.4.7.2.5"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.7.2.5.1">25.23</span></span></span>
</span>
</span></span></p>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.8.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text ltx_font_bold" id="S5.T3.9.2" style="font-size:90%;">Reflection Quality.<span class="ltx_text ltx_font_medium" id="S5.T3.9.2.1"> We compare the quality of the generated reflection image with the baseline method. We observe that our method has better object quality metrics. Best results are shown in </span>bold<span class="ltx_text ltx_font_medium" id="S5.T3.9.2.2">.</span></span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.4" style="width:436.5pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S5.T3.4.4"><span class="ltx_text" id="S5.T3.4.4.4">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.4.4.4.4">
<span class="ltx_thead">
<span class="ltx_tr" id="S5.T3.4.4.4.4.5.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T3.4.4.4.4.5.1.1">Metrics</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_colspan ltx_colspan_3" id="S5.T3.4.4.4.4.5.1.2">Reflection Generation Quality</span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.4.4.4.4.5.1.3">Reflection Geometry</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.4">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.4.5">Models</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.1.1.1">PSNR</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.1.1.1.m1.1a"><mo id="S5.T3.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T3.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.1.m1.1b"><ci id="S5.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T3.2.2.2.2.2.2.1">SSIM</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.2.2.2.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.2.2.2.m1.1a"><mo id="S5.T3.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T3.2.2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.2.2.m1.1b"><ci id="S5.T3.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.2.2.2.m1.1d">↑</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S5.T3.3.3.3.3.3.3.1">LPIPS</span> <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.3.3.3.3.3.3.m1.1"><semantics id="S5.T3.3.3.3.3.3.3.m1.1a"><mo id="S5.T3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T3.3.3.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.3.3.m1.1b"><ci id="S5.T3.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.3.3.3.m1.1d">↓</annotation></semantics></math></span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.4.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.4.4.1">IoU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.4.4.4.4.4.4.m1.1"><semantics id="S5.T3.4.4.4.4.4.4.m1.1a"><mo id="S5.T3.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T3.4.4.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.4.4.4.m1.1b"><ci id="S5.T3.4.4.4.4.4.4.m1.1.1.cmml" xref="S5.T3.4.4.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.4.4.4.4.m1.1d">↑</annotation></semantics></math></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.4.4.4.4.6.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.6.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.6.1.1.1">Brushnet-FT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.1.2">19.15</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.6.1.3.1">0.84</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.6.1.4">0.082</span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.1.5">0.566</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.7.2">
<span class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T3.4.4.4.4.7.2.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.7.2.1.1">Ours</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.4.4.4.7.2.2"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.7.2.2.1">20.35</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.4.4.4.7.2.3"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.7.2.3.1">0.84</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T3.4.4.4.4.7.2.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.7.2.4.1">0.075</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T3.4.4.4.4.7.2.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.7.2.5.1">0.567</span></span></span>
</span>
</span></span></p>
</span></div>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.T2" title="Table 2 ‣ 5.2 Ablation studies ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">2</span></a> &amp; <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.T3" title="Table 3 ‣ 5.2 Ablation studies ‣ 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3</span></a> quantitatively compare BrushNet-FT and MirrorFusion on the image quality and the generated reflection quality. These values are reported on MirrorBench. We generate <math alttext="4" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mn id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><cn id="S5.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">4</annotation></semantics></math> outputs for each test sample using different random seeds. We then select the image with the best mask SSIM score as the representative image out of the four images. The reported value for any metric is the average of that metric for all representative images across the dataset. MirrorFusion (Ours) with depth cues outperforms BrushNet-FT, which doesn’t take depth as an input. This corroborates the necessity of adding depth as an input to the model. We discuss limitations and societal impact in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A4" title="Appendix D Limitations and Social Impact ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we propose SynMirror, a large-scale scale challenging and diverse dataset to train generative models for the task of generating realistic mirror reflections. We identify shortcomings in current models and propose MirrorFusion, a novel inpainting method conditioned on depth maps for generating geometrically accurate mirror reflections.
Extensive qualitative and quantitative results on MirrorBench shows the superior performance of MirrorFusion in comparison to other methods. Our work is the first step towards generating geometrically accurate and plausible mirror reflections using diffusion based generative models. We believe that SynMirror and MirrorBench will pave way for research in several mirror-related tasks.
</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S1" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S2" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span> SynMirror: A synthetic dataset of mirror reflections</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.SS1" title="In 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset Generation and Processing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS1" title="In 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Preliminaries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2" title="In 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>MirrorFusion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS1" title="In 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Model architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS2" title="In 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Depth conditioning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS3" title="In 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Depth Normalization</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments &amp; Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.SS1" title="In 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Qualitative Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5.SS2" title="In 5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Ablation studies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S6" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.SS1" title="In Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Filtering out Spurious objects</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.SS2" title="In Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Preparation of MirrorBench</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2.SS1" title="In Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Training Details: MirrorFusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2.SS2" title="In Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Training Details for Baseline Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A2.SS3" title="In Appendix B Implementation Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Inference Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS1" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>More Results on Google Scanned Objects (GSO)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS2" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Results on real-world scenes.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS3" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Comparison with Commercial Products.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS4" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.4 </span>Robustness to pre-trained monocular depth estimation methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS5" title="In Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.5 </span>More Qualitative Comparisons</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A4" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Limitations and Social Impact</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5" title="In Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS1" title="In Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Results from recent T2I methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS2" title="In Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Text prompts used in the experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.SS3" title="In Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.3 </span>Generation of Segmentation Masks for computing metrics</span></a></li>
</ol>
</li>
</ol></nav>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.4">Our dataset consists of <math alttext="198,204" class="ltx_Math" display="inline" id="A1.p1.1.m1.2"><semantics id="A1.p1.1.m1.2a"><mrow id="A1.p1.1.m1.2.3.2" xref="A1.p1.1.m1.2.3.1.cmml"><mn id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">198</mn><mo id="A1.p1.1.m1.2.3.2.1" xref="A1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.p1.1.m1.2.2" xref="A1.p1.1.m1.2.2.cmml">204</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.2b"><list id="A1.p1.1.m1.2.3.1.cmml" xref="A1.p1.1.m1.2.3.2"><cn id="A1.p1.1.m1.1.1.cmml" type="integer" xref="A1.p1.1.m1.1.1">198</cn><cn id="A1.p1.1.m1.2.2.cmml" type="integer" xref="A1.p1.1.m1.2.2">204</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.2c">198,204</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.2d">198 , 204</annotation></semantics></math> rendered images from <math alttext="66,068" class="ltx_Math" display="inline" id="A1.p1.2.m2.2"><semantics id="A1.p1.2.m2.2a"><mrow id="A1.p1.2.m2.2.3.2" xref="A1.p1.2.m2.2.3.1.cmml"><mn id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">66</mn><mo id="A1.p1.2.m2.2.3.2.1" xref="A1.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.p1.2.m2.2.2" xref="A1.p1.2.m2.2.2.cmml">068</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.2b"><list id="A1.p1.2.m2.2.3.1.cmml" xref="A1.p1.2.m2.2.3.2"><cn id="A1.p1.2.m2.1.1.cmml" type="integer" xref="A1.p1.2.m2.1.1">66</cn><cn id="A1.p1.2.m2.2.2.cmml" type="integer" xref="A1.p1.2.m2.2.2">068</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.2c">66,068</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.m2.2d">66 , 068</annotation></semantics></math> objects: <math alttext="58,115" class="ltx_Math" display="inline" id="A1.p1.3.m3.2"><semantics id="A1.p1.3.m3.2a"><mrow id="A1.p1.3.m3.2.3.2" xref="A1.p1.3.m3.2.3.1.cmml"><mn id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml">58</mn><mo id="A1.p1.3.m3.2.3.2.1" xref="A1.p1.3.m3.2.3.1.cmml">,</mo><mn id="A1.p1.3.m3.2.2" xref="A1.p1.3.m3.2.2.cmml">115</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.2b"><list id="A1.p1.3.m3.2.3.1.cmml" xref="A1.p1.3.m3.2.3.2"><cn id="A1.p1.3.m3.1.1.cmml" type="integer" xref="A1.p1.3.m3.1.1">58</cn><cn id="A1.p1.3.m3.2.2.cmml" type="integer" xref="A1.p1.3.m3.2.2">115</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.2c">58,115</annotation><annotation encoding="application/x-llamapun" id="A1.p1.3.m3.2d">58 , 115</annotation></semantics></math> objects from Objaverse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> and <math alttext="7,953" class="ltx_Math" display="inline" id="A1.p1.4.m4.2"><semantics id="A1.p1.4.m4.2a"><mrow id="A1.p1.4.m4.2.3.2" xref="A1.p1.4.m4.2.3.1.cmml"><mn id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml">7</mn><mo id="A1.p1.4.m4.2.3.2.1" xref="A1.p1.4.m4.2.3.1.cmml">,</mo><mn id="A1.p1.4.m4.2.2" xref="A1.p1.4.m4.2.2.cmml">953</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.2b"><list id="A1.p1.4.m4.2.3.1.cmml" xref="A1.p1.4.m4.2.3.2"><cn id="A1.p1.4.m4.1.1.cmml" type="integer" xref="A1.p1.4.m4.1.1">7</cn><cn id="A1.p1.4.m4.2.2.cmml" type="integer" xref="A1.p1.4.m4.2.2">953</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.2c">7,953</annotation><annotation encoding="application/x-llamapun" id="A1.p1.4.m4.2d">7 , 953</annotation></semantics></math> from the ABO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> dataset. We utilize captions provided by Cap3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite> during training. We provide more details in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3" title="3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3</span></a>. To illustrate the diversity in 3D objects, floor textures and HDRI backgrounds, we present more samples in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.F10" title="Figure 10 ‣ A.2 Preparation of MirrorBench ‣ Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.F11" title="Figure 11 ‣ A.2 Preparation of MirrorBench ‣ Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Filtering out Spurious objects</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">We discuss how we filter 3D objects from Objaverse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> and Amazon Berkeley Objects (ABO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3.SS1" title="3.1 Dataset Generation and Processing ‣ 3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3.1</span></a>. In spite of the initial filtering, we observe some “spurious” objects, for which the reflection is not visible in the mirror. Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#alg1" title="Algorithm 1 ‣ A.1 Filtering out Spurious objects ‣ Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the pseudo-code to identify such “spurious” objects. Specifically, using Blender’s Python API, we check the material property of each <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.1">child</span> in the input mesh <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><ci id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">caligraphic_M</annotation></semantics></math> of a 3D object. We expect the 3D objects to be in standard 3D formats: <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.2">“*.glb, *.gltf, *.obj, *.fbx”</span>. If any node in the material property has the attributes: “Mix-Shader”, and the name of the input to this node is “Fac,” and the name of the linked node is “Light Path”, then we observe that the reflection of such a 3D model does not appear in the mirror. We prune out such objects from the initial filtered list. The new filtered list will be made public along with the dataset for future research.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.3.1.1">Algorithm 1</span> </span> Determine if a 3D Object is Spurious</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="alg1.1"><span class="ltx_text ltx_font_bold" id="alg1.1.1">Input</span>: A 3D model <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="alg1.1.m1.1"><semantics id="alg1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.1.m1.1.1" xref="alg1.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="alg1.1.m1.1b"><ci id="alg1.1.m1.1.1.cmml" xref="alg1.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="alg1.1.m1.1d">caligraphic_M</annotation></semantics></math>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="alg1.1.2">Output</span>: True, if a 3D model is spurious, else False</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_listing ltx_figure_panel ltx_listing" id="alg1.4">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l1.2">for</span> <math alttext="\mathcal{C}\leftarrow" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mrow id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">𝒞</mi><mo id="alg1.l1.m1.1.1.1" stretchy="false" xref="alg1.l1.m1.1.1.1.cmml">←</mo><mi id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><ci id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1">←</ci><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">𝒞</ci><csymbol cd="latexml" id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\mathcal{C}\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">caligraphic_C ←</annotation></semantics></math> child <math alttext="\in\mathcal{M}" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><mrow id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mi id="alg1.l1.m2.1.1.2" xref="alg1.l1.m2.1.1.2.cmml"></mi><mo id="alg1.l1.m2.1.1.1" xref="alg1.l1.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3.cmml">ℳ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><in id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1.1"></in><csymbol cd="latexml" id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">absent</csymbol><ci id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3">ℳ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\in\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">∈ caligraphic_M</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l1.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l2.2">for</span> <math alttext="\mathcal{T}\leftarrow" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">𝒯</mi><mo id="alg1.l2.m1.1.1.1" stretchy="false" xref="alg1.l2.m1.1.1.1.cmml">←</mo><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><ci id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1">←</ci><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝒯</ci><csymbol cd="latexml" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\mathcal{T}\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">caligraphic_T ←</annotation></semantics></math> material <math alttext="\in\mathcal{C}" class="ltx_Math" display="inline" id="alg1.l2.m2.1"><semantics id="alg1.l2.m2.1a"><mrow id="alg1.l2.m2.1.1" xref="alg1.l2.m2.1.1.cmml"><mi id="alg1.l2.m2.1.1.2" xref="alg1.l2.m2.1.1.2.cmml"></mi><mo id="alg1.l2.m2.1.1.1" xref="alg1.l2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l2.m2.1.1.3" xref="alg1.l2.m2.1.1.3.cmml">𝒞</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m2.1b"><apply id="alg1.l2.m2.1.1.cmml" xref="alg1.l2.m2.1.1"><in id="alg1.l2.m2.1.1.1.cmml" xref="alg1.l2.m2.1.1.1"></in><csymbol cd="latexml" id="alg1.l2.m2.1.1.2.cmml" xref="alg1.l2.m2.1.1.2">absent</csymbol><ci id="alg1.l2.m2.1.1.3.cmml" xref="alg1.l2.m2.1.1.3">𝒞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m2.1c">\in\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m2.1d">∈ caligraphic_C</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l2.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>         <span class="ltx_text ltx_font_bold" id="alg1.l3.2">for</span> <math alttext="\mathcal{N}\leftarrow" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">𝒩</mi><mo id="alg1.l3.m1.1.1.1" stretchy="false" xref="alg1.l3.m1.1.1.1.cmml">←</mo><mi id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">←</ci><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">𝒩</ci><csymbol cd="latexml" id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">\mathcal{N}\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">caligraphic_N ←</annotation></semantics></math> node <math alttext="\in\mathcal{T}" class="ltx_Math" display="inline" id="alg1.l3.m2.1"><semantics id="alg1.l3.m2.1a"><mrow id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml"><mi id="alg1.l3.m2.1.1.2" xref="alg1.l3.m2.1.1.2.cmml"></mi><mo id="alg1.l3.m2.1.1.1" xref="alg1.l3.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l3.m2.1.1.3" xref="alg1.l3.m2.1.1.3.cmml">𝒯</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><apply id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1"><in id="alg1.l3.m2.1.1.1.cmml" xref="alg1.l3.m2.1.1.1"></in><csymbol cd="latexml" id="alg1.l3.m2.1.1.2.cmml" xref="alg1.l3.m2.1.1.2">absent</csymbol><ci id="alg1.l3.m2.1.1.3.cmml" xref="alg1.l3.m2.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.1d">∈ caligraphic_T</annotation></semantics></math>.material <span class="ltx_text ltx_font_bold" id="alg1.l3.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span>              <span class="ltx_text ltx_font_bold" id="alg1.l4.2">if</span>  (<math alttext="\mathcal{N}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">caligraphic_N</annotation></semantics></math>.name <math alttext="==" class="ltx_Math" display="inline" id="alg1.l4.m2.1"><semantics id="alg1.l4.m2.1a"><mrow id="alg1.l4.m2.1.1" xref="alg1.l4.m2.1.1.cmml"><mi id="alg1.l4.m2.1.1.2" xref="alg1.l4.m2.1.1.2.cmml"></mi><mo id="alg1.l4.m2.1.1.1" rspace="0em" xref="alg1.l4.m2.1.1.1.cmml">=</mo><mo id="alg1.l4.m2.1.1.3" lspace="0em" xref="alg1.l4.m2.1.1.3.cmml">=</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><apply id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1"><eq id="alg1.l4.m2.1.1.1.cmml" xref="alg1.l4.m2.1.1.1"></eq><csymbol cd="latexml" id="alg1.l4.m2.1.1.2.cmml" xref="alg1.l4.m2.1.1.2">absent</csymbol><eq id="alg1.l4.m2.1.1.3.cmml" xref="alg1.l4.m2.1.1.3"></eq></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">==</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m2.1d">= =</annotation></semantics></math> “Mix-Shader”) 
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l5.2">and</span> (<math alttext="\mathcal{N}" class="ltx_Math" display="inline" id="alg1.l5.m1.1"><semantics id="alg1.l5.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><ci id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.1d">caligraphic_N</annotation></semantics></math>.input.name <math alttext="==" class="ltx_Math" display="inline" id="alg1.l5.m2.1"><semantics id="alg1.l5.m2.1a"><mrow id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml"><mi id="alg1.l5.m2.1.1.2" xref="alg1.l5.m2.1.1.2.cmml"></mi><mo id="alg1.l5.m2.1.1.1" rspace="0em" xref="alg1.l5.m2.1.1.1.cmml">=</mo><mo id="alg1.l5.m2.1.1.3" lspace="0em" xref="alg1.l5.m2.1.1.3.cmml">=</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><apply id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1"><eq id="alg1.l5.m2.1.1.1.cmml" xref="alg1.l5.m2.1.1.1"></eq><csymbol cd="latexml" id="alg1.l5.m2.1.1.2.cmml" xref="alg1.l5.m2.1.1.2">absent</csymbol><eq id="alg1.l5.m2.1.1.3.cmml" xref="alg1.l5.m2.1.1.3"></eq></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">==</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m2.1d">= =</annotation></semantics></math> “Fac”) 
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l6.2">and</span> (<math alttext="\mathcal{N}" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">caligraphic_N</annotation></semantics></math>.linked.name <math alttext="==" class="ltx_Math" display="inline" id="alg1.l6.m2.1"><semantics id="alg1.l6.m2.1a"><mrow id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml"><mi id="alg1.l6.m2.1.1.2" xref="alg1.l6.m2.1.1.2.cmml"></mi><mo id="alg1.l6.m2.1.1.1" rspace="0em" xref="alg1.l6.m2.1.1.1.cmml">=</mo><mo id="alg1.l6.m2.1.1.3" lspace="0em" xref="alg1.l6.m2.1.1.3.cmml">=</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><apply id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1"><eq id="alg1.l6.m2.1.1.1.cmml" xref="alg1.l6.m2.1.1.1"></eq><csymbol cd="latexml" id="alg1.l6.m2.1.1.2.cmml" xref="alg1.l6.m2.1.1.2">absent</csymbol><eq id="alg1.l6.m2.1.1.3.cmml" xref="alg1.l6.m2.1.1.3"></eq></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">==</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m2.1d">= =</annotation></semantics></math> “Light Path”) <span class="ltx_text ltx_font_bold" id="alg1.l6.3">then</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>                  <span class="ltx_text ltx_font_smallcaps" id="alg1.l7.2">Return</span>(True)

</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>              <span class="ltx_text ltx_font_bold" id="alg1.l8.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l8.3">if</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>         <span class="ltx_text ltx_font_bold" id="alg1.l9.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l9.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l10.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l10.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l11.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l11.3">for</span>
</div>
</div>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Preparation of MirrorBench</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.2">MirrorBench aims to benchmark various generative models at the task of generating perfect mirror reflections. MirrorBench is created by sampling around <math alttext="1,000" class="ltx_Math" display="inline" id="A1.SS2.p1.1.m1.2"><semantics id="A1.SS2.p1.1.m1.2a"><mrow id="A1.SS2.p1.1.m1.2.3.2" xref="A1.SS2.p1.1.m1.2.3.1.cmml"><mn id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml">1</mn><mo id="A1.SS2.p1.1.m1.2.3.2.1" xref="A1.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS2.p1.1.m1.2.2" xref="A1.SS2.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.2b"><list id="A1.SS2.p1.1.m1.2.3.1.cmml" xref="A1.SS2.p1.1.m1.2.3.2"><cn id="A1.SS2.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS2.p1.1.m1.1.1">1</cn><cn id="A1.SS2.p1.1.m1.2.2.cmml" type="integer" xref="A1.SS2.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.2c">1,000</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.m1.2d">1 , 000</annotation></semantics></math> objects from SynMirror, with 3 rendered samples per object, totalling to <math alttext="2,991" class="ltx_Math" display="inline" id="A1.SS2.p1.2.m2.2"><semantics id="A1.SS2.p1.2.m2.2a"><mrow id="A1.SS2.p1.2.m2.2.3.2" xref="A1.SS2.p1.2.m2.2.3.1.cmml"><mn id="A1.SS2.p1.2.m2.1.1" xref="A1.SS2.p1.2.m2.1.1.cmml">2</mn><mo id="A1.SS2.p1.2.m2.2.3.2.1" xref="A1.SS2.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.SS2.p1.2.m2.2.2" xref="A1.SS2.p1.2.m2.2.2.cmml">991</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m2.2b"><list id="A1.SS2.p1.2.m2.2.3.1.cmml" xref="A1.SS2.p1.2.m2.2.3.2"><cn id="A1.SS2.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS2.p1.2.m2.1.1">2</cn><cn id="A1.SS2.p1.2.m2.2.2.cmml" type="integer" xref="A1.SS2.p1.2.m2.2.2">991</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m2.2c">2,991</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.2.m2.2d">2 , 991</annotation></semantics></math> samples. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.F12" title="Figure 12 ‣ A.2 Preparation of MirrorBench ‣ Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">12</span></a> shows samples of MirrorBench, which consist of two types:</p>
<ol class="ltx_enumerate" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.2"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.2.1">“Unknown”</span> class objects, referring to categories not present in the training set. We take the first <math alttext="500" class="ltx_Math" display="inline" id="A1.I1.i1.p1.1.m1.1"><semantics id="A1.I1.i1.p1.1.m1.1a"><mn id="A1.I1.i1.p1.1.m1.1.1" xref="A1.I1.i1.p1.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.1.m1.1b"><cn id="A1.I1.i1.p1.1.m1.1.1.cmml" type="integer" xref="A1.I1.i1.p1.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="A1.I1.i1.p1.1.m1.1d">500</annotation></semantics></math> objects from Objaverse in <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.2.2">“Unknown”</span> category, sorted in the increasing order of category frequency and keep the remaining categories in the training set as <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.2.3">“Known”</span> categories. There are <math alttext="1494" class="ltx_Math" display="inline" id="A1.I1.i1.p1.2.m2.1"><semantics id="A1.I1.i1.p1.2.m2.1a"><mn id="A1.I1.i1.p1.2.m2.1.1" xref="A1.I1.i1.p1.2.m2.1.1.cmml">1494</mn><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.2.m2.1b"><cn id="A1.I1.i1.p1.2.m2.1.1.cmml" type="integer" xref="A1.I1.i1.p1.2.m2.1.1">1494</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.2.m2.1c">1494</annotation><annotation encoding="application/x-llamapun" id="A1.I1.i1.p1.2.m2.1d">1494</annotation></semantics></math> samples generated from the objects of <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.2.4">“Unknown”</span> category.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.3"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.3.1">“Known”</span> class objects, referring to categories included in the training set. There are <math alttext="1497" class="ltx_Math" display="inline" id="A1.I1.i2.p1.1.m1.1"><semantics id="A1.I1.i2.p1.1.m1.1a"><mn id="A1.I1.i2.p1.1.m1.1.1" xref="A1.I1.i2.p1.1.m1.1.1.cmml">1497</mn><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.1.m1.1b"><cn id="A1.I1.i2.p1.1.m1.1.1.cmml" type="integer" xref="A1.I1.i2.p1.1.m1.1.1">1497</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.1.m1.1c">1497</annotation><annotation encoding="application/x-llamapun" id="A1.I1.i2.p1.1.m1.1d">1497</annotation></semantics></math> images from this category. This includes renderings from around <math alttext="250" class="ltx_Math" display="inline" id="A1.I1.i2.p1.2.m2.1"><semantics id="A1.I1.i2.p1.2.m2.1a"><mn id="A1.I1.i2.p1.2.m2.1.1" xref="A1.I1.i2.p1.2.m2.1.1.cmml">250</mn><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.2.m2.1b"><cn id="A1.I1.i2.p1.2.m2.1.1.cmml" type="integer" xref="A1.I1.i2.p1.2.m2.1.1">250</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.2.m2.1c">250</annotation><annotation encoding="application/x-llamapun" id="A1.I1.i2.p1.2.m2.1d">250</annotation></semantics></math> objects from Objaverse and around <math alttext="250" class="ltx_Math" display="inline" id="A1.I1.i2.p1.3.m3.1"><semantics id="A1.I1.i2.p1.3.m3.1a"><mn id="A1.I1.i2.p1.3.m3.1.1" xref="A1.I1.i2.p1.3.m3.1.1.cmml">250</mn><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.3.m3.1b"><cn id="A1.I1.i2.p1.3.m3.1.1.cmml" type="integer" xref="A1.I1.i2.p1.3.m3.1.1">250</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.3.m3.1c">250</annotation><annotation encoding="application/x-llamapun" id="A1.I1.i2.p1.3.m3.1d">250</annotation></semantics></math> objects from ABO.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="A1.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1019" id="A1.F10.g1" src="x10.png" width="768"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F10.3.1.1" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text ltx_font_bold" id="A1.F10.4.2" style="font-size:90%;">Samples from SynMirror.<span class="ltx_text ltx_font_medium" id="A1.F10.4.2.1"> </span></span></figcaption>
</figure>
<figure class="ltx_figure" id="A1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1019" id="A1.F11.g1" src="x11.png" width="768"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F11.3.1.1" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text ltx_font_bold" id="A1.F11.4.2" style="font-size:90%;">Samples from SynMirror.<span class="ltx_text ltx_font_medium" id="A1.F11.4.2.1"> </span></span></figcaption>
</figure>
<figure class="ltx_figure" id="A1.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1053" id="A1.F12.g1" src="x12.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F12.5.1.1" style="font-size:90%;">Figure 12</span>: </span><span class="ltx_text ltx_font_bold" id="A1.F12.6.2" style="font-size:90%;">Samples from MirrorBench.<span class="ltx_text ltx_font_medium" id="A1.F12.6.2.1"> The first two rows contain samples from </span>“Unknown”<span class="ltx_text ltx_font_medium" id="A1.F12.6.2.2"> categories and the bottom two rows contain samples from </span>“Known”<span class="ltx_text ltx_font_medium" id="A1.F12.6.2.3"> categories. Notice the challenging nature of MirrorBench. We provide more details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A1.SS2" title="A.2 Preparation of MirrorBench ‣ Appendix A Dataset ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">A.2</span></a></span></span></figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation Details</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Training Details: MirrorFusion</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.10">We follow the BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> architecture for MirrorFusion and provide depth conditioning as discussed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2" title="4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4.2</span></a>. The Generation and Conditional U-Net weights are initialized from the Stable Diffusion v1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> checkpoint. During training, the weights of the generation U-Net are kept frozen, while the weights of the conditioning network are updated. The extra channels processing the down-sampled depth and mask images in the first convolution layer of the conditioning U-Net are initialized to zero. We train MirrorFusion on SynMirror, using the original input image resolution of <math alttext="512\times 512" class="ltx_Math" display="inline" id="A2.SS1.p1.1.m1.1"><semantics id="A2.SS1.p1.1.m1.1a"><mrow id="A2.SS1.p1.1.m1.1.1" xref="A2.SS1.p1.1.m1.1.1.cmml"><mn id="A2.SS1.p1.1.m1.1.1.2" xref="A2.SS1.p1.1.m1.1.1.2.cmml">512</mn><mo id="A2.SS1.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="A2.SS1.p1.1.m1.1.1.3" xref="A2.SS1.p1.1.m1.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.1.m1.1b"><apply id="A2.SS1.p1.1.m1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1"><times id="A2.SS1.p1.1.m1.1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1.1"></times><cn id="A2.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="A2.SS1.p1.1.m1.1.1.2">512</cn><cn id="A2.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="A2.SS1.p1.1.m1.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.1.m1.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.1.m1.1d">512 × 512</annotation></semantics></math>. We utilize the AdamW optimizer with a learning rate <math alttext="1e-5" class="ltx_Math" display="inline" id="A2.SS1.p1.2.m2.1"><semantics id="A2.SS1.p1.2.m2.1a"><mrow id="A2.SS1.p1.2.m2.1.1" xref="A2.SS1.p1.2.m2.1.1.cmml"><mrow id="A2.SS1.p1.2.m2.1.1.2" xref="A2.SS1.p1.2.m2.1.1.2.cmml"><mn id="A2.SS1.p1.2.m2.1.1.2.2" xref="A2.SS1.p1.2.m2.1.1.2.2.cmml">1</mn><mo id="A2.SS1.p1.2.m2.1.1.2.1" xref="A2.SS1.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="A2.SS1.p1.2.m2.1.1.2.3" xref="A2.SS1.p1.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="A2.SS1.p1.2.m2.1.1.1" xref="A2.SS1.p1.2.m2.1.1.1.cmml">−</mo><mn id="A2.SS1.p1.2.m2.1.1.3" xref="A2.SS1.p1.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.2.m2.1b"><apply id="A2.SS1.p1.2.m2.1.1.cmml" xref="A2.SS1.p1.2.m2.1.1"><minus id="A2.SS1.p1.2.m2.1.1.1.cmml" xref="A2.SS1.p1.2.m2.1.1.1"></minus><apply id="A2.SS1.p1.2.m2.1.1.2.cmml" xref="A2.SS1.p1.2.m2.1.1.2"><times id="A2.SS1.p1.2.m2.1.1.2.1.cmml" xref="A2.SS1.p1.2.m2.1.1.2.1"></times><cn id="A2.SS1.p1.2.m2.1.1.2.2.cmml" type="integer" xref="A2.SS1.p1.2.m2.1.1.2.2">1</cn><ci id="A2.SS1.p1.2.m2.1.1.2.3.cmml" xref="A2.SS1.p1.2.m2.1.1.2.3">𝑒</ci></apply><cn id="A2.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS1.p1.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.2.m2.1c">1e-5</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.2.m2.1d">1 italic_e - 5</annotation></semantics></math>. We train our model for <math alttext="20,000" class="ltx_Math" display="inline" id="A2.SS1.p1.3.m3.2"><semantics id="A2.SS1.p1.3.m3.2a"><mrow id="A2.SS1.p1.3.m3.2.3.2" xref="A2.SS1.p1.3.m3.2.3.1.cmml"><mn id="A2.SS1.p1.3.m3.1.1" xref="A2.SS1.p1.3.m3.1.1.cmml">20</mn><mo id="A2.SS1.p1.3.m3.2.3.2.1" xref="A2.SS1.p1.3.m3.2.3.1.cmml">,</mo><mn id="A2.SS1.p1.3.m3.2.2" xref="A2.SS1.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.3.m3.2b"><list id="A2.SS1.p1.3.m3.2.3.1.cmml" xref="A2.SS1.p1.3.m3.2.3.2"><cn id="A2.SS1.p1.3.m3.1.1.cmml" type="integer" xref="A2.SS1.p1.3.m3.1.1">20</cn><cn id="A2.SS1.p1.3.m3.2.2.cmml" type="integer" xref="A2.SS1.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.3.m3.2c">20,000</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.3.m3.2d">20 , 000</annotation></semantics></math> steps on <math alttext="8" class="ltx_Math" display="inline" id="A2.SS1.p1.4.m4.1"><semantics id="A2.SS1.p1.4.m4.1a"><mn id="A2.SS1.p1.4.m4.1.1" xref="A2.SS1.p1.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.4.m4.1b"><cn id="A2.SS1.p1.4.m4.1.1.cmml" type="integer" xref="A2.SS1.p1.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.4.m4.1c">8</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.4.m4.1d">8</annotation></semantics></math> NVIDIA A6000 GPUs with an effective batch size of <math alttext="16" class="ltx_Math" display="inline" id="A2.SS1.p1.5.m5.1"><semantics id="A2.SS1.p1.5.m5.1a"><mn id="A2.SS1.p1.5.m5.1.1" xref="A2.SS1.p1.5.m5.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.5.m5.1b"><cn id="A2.SS1.p1.5.m5.1.1.cmml" type="integer" xref="A2.SS1.p1.5.m5.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.5.m5.1c">16</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.5.m5.1d">16</annotation></semantics></math>, which takes around <math alttext="12" class="ltx_Math" display="inline" id="A2.SS1.p1.6.m6.1"><semantics id="A2.SS1.p1.6.m6.1a"><mn id="A2.SS1.p1.6.m6.1.1" xref="A2.SS1.p1.6.m6.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.6.m6.1b"><cn id="A2.SS1.p1.6.m6.1.1.cmml" type="integer" xref="A2.SS1.p1.6.m6.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.6.m6.1c">12</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.6.m6.1d">12</annotation></semantics></math> hours. During training, we randomly drop text prompts <math alttext="20\%" class="ltx_Math" display="inline" id="A2.SS1.p1.7.m7.1"><semantics id="A2.SS1.p1.7.m7.1a"><mrow id="A2.SS1.p1.7.m7.1.1" xref="A2.SS1.p1.7.m7.1.1.cmml"><mn id="A2.SS1.p1.7.m7.1.1.2" xref="A2.SS1.p1.7.m7.1.1.2.cmml">20</mn><mo id="A2.SS1.p1.7.m7.1.1.1" xref="A2.SS1.p1.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.7.m7.1b"><apply id="A2.SS1.p1.7.m7.1.1.cmml" xref="A2.SS1.p1.7.m7.1.1"><csymbol cd="latexml" id="A2.SS1.p1.7.m7.1.1.1.cmml" xref="A2.SS1.p1.7.m7.1.1.1">percent</csymbol><cn id="A2.SS1.p1.7.m7.1.1.2.cmml" type="integer" xref="A2.SS1.p1.7.m7.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.7.m7.1c">20\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.7.m7.1d">20 %</annotation></semantics></math> of the time to allow the model to take cues from the input depth map. We find the checkpoint at <math alttext="15,000" class="ltx_Math" display="inline" id="A2.SS1.p1.8.m8.2"><semantics id="A2.SS1.p1.8.m8.2a"><mrow id="A2.SS1.p1.8.m8.2.3.2" xref="A2.SS1.p1.8.m8.2.3.1.cmml"><mn id="A2.SS1.p1.8.m8.1.1" xref="A2.SS1.p1.8.m8.1.1.cmml">15</mn><mo id="A2.SS1.p1.8.m8.2.3.2.1" xref="A2.SS1.p1.8.m8.2.3.1.cmml">,</mo><mn id="A2.SS1.p1.8.m8.2.2" xref="A2.SS1.p1.8.m8.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.8.m8.2b"><list id="A2.SS1.p1.8.m8.2.3.1.cmml" xref="A2.SS1.p1.8.m8.2.3.2"><cn id="A2.SS1.p1.8.m8.1.1.cmml" type="integer" xref="A2.SS1.p1.8.m8.1.1">15</cn><cn id="A2.SS1.p1.8.m8.2.2.cmml" type="integer" xref="A2.SS1.p1.8.m8.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.8.m8.2c">15,000</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.8.m8.2d">15 , 000</annotation></semantics></math> to produce the best qualitative results and use it for further inference.
We also run an additional experiment where we make the generation U-Net trainable. We call this model<span class="ltx_text ltx_font_bold" id="A2.SS1.p1.9.1"> MirrorFusion<math alttext="{}^{\text{*}}" class="ltx_Math" display="inline" id="A2.SS1.p1.9.1.m1.1"><semantics id="A2.SS1.p1.9.1.m1.1a"><msup id="A2.SS1.p1.9.1.m1.1.1" xref="A2.SS1.p1.9.1.m1.1.1.cmml"><mi id="A2.SS1.p1.9.1.m1.1.1a" xref="A2.SS1.p1.9.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="A2.SS1.p1.9.1.m1.1.1.1" xref="A2.SS1.p1.9.1.m1.1.1.1a.cmml">*</mtext></msup><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.9.1.m1.1b"><apply id="A2.SS1.p1.9.1.m1.1.1.cmml" xref="A2.SS1.p1.9.1.m1.1.1"><ci id="A2.SS1.p1.9.1.m1.1.1.1a.cmml" xref="A2.SS1.p1.9.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" id="A2.SS1.p1.9.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.SS1.p1.9.1.m1.1.1.1">*</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.9.1.m1.1c">{}^{\text{*}}</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.9.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>. We use the same training hyper-parameters and consider the checkpoint at <math alttext="17,000" class="ltx_Math" display="inline" id="A2.SS1.p1.10.m9.2"><semantics id="A2.SS1.p1.10.m9.2a"><mrow id="A2.SS1.p1.10.m9.2.3.2" xref="A2.SS1.p1.10.m9.2.3.1.cmml"><mn id="A2.SS1.p1.10.m9.1.1" xref="A2.SS1.p1.10.m9.1.1.cmml">17</mn><mo id="A2.SS1.p1.10.m9.2.3.2.1" xref="A2.SS1.p1.10.m9.2.3.1.cmml">,</mo><mn id="A2.SS1.p1.10.m9.2.2" xref="A2.SS1.p1.10.m9.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.10.m9.2b"><list id="A2.SS1.p1.10.m9.2.3.1.cmml" xref="A2.SS1.p1.10.m9.2.3.2"><cn id="A2.SS1.p1.10.m9.1.1.cmml" type="integer" xref="A2.SS1.p1.10.m9.1.1">17</cn><cn id="A2.SS1.p1.10.m9.2.2.cmml" type="integer" xref="A2.SS1.p1.10.m9.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.10.m9.2c">17,000</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.10.m9.2d">17 , 000</annotation></semantics></math> steps.
From Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F17" title="Figure 17 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">17</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F18" title="Figure 18 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">18</span></a>, we can see improved results compared to the frozen generation U-Net. However, the VRAM requirements and training time almost double, due to the increase in the number of trainable parameters.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Training Details for Baseline Methods</h3>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.SS2.p1.1.1">Fine-tuning of BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>.</span>
Keeping the generation U-Net frozen, we fine-tune BrushNet using the input mask and masked image using the same hyperparameters used to train MirrorFusion. We do not randomly drop text prompts and select the checkpoint at <math alttext="17,000" class="ltx_Math" display="inline" id="A2.SS2.p1.1.m1.2"><semantics id="A2.SS2.p1.1.m1.2a"><mrow id="A2.SS2.p1.1.m1.2.3.2" xref="A2.SS2.p1.1.m1.2.3.1.cmml"><mn id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml">17</mn><mo id="A2.SS2.p1.1.m1.2.3.2.1" xref="A2.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="A2.SS2.p1.1.m1.2.2" xref="A2.SS2.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.2b"><list id="A2.SS2.p1.1.m1.2.3.1.cmml" xref="A2.SS2.p1.1.m1.2.3.2"><cn id="A2.SS2.p1.1.m1.1.1.cmml" type="integer" xref="A2.SS2.p1.1.m1.1.1">17</cn><cn id="A2.SS2.p1.1.m1.2.2.cmml" type="integer" xref="A2.SS2.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.2c">17,000</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.1.m1.2d">17 , 000</annotation></semantics></math> steps for evaluation. We refer to this model as <span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.SS2.p1.1.2">“BrushNet-FT”</span> in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5" title="5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">5</span></a> of the main paper and compare our results against it. We found that initializing the weights from the Stable Diffusion v1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> checkpoint was superior as compared to initializing from the pre-trained BrushNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> checkpoint.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Inference Details</h3>
<div class="ltx_para" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.2">During inference, we set the classifier free guidance scale (CFG) to <math alttext="7.5" class="ltx_Math" display="inline" id="A2.SS3.p1.1.m1.1"><semantics id="A2.SS3.p1.1.m1.1a"><mn id="A2.SS3.p1.1.m1.1.1" xref="A2.SS3.p1.1.m1.1.1.cmml">7.5</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.1.m1.1b"><cn id="A2.SS3.p1.1.m1.1.1.cmml" type="float" xref="A2.SS3.p1.1.m1.1.1">7.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.1.m1.1c">7.5</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.1.m1.1d">7.5</annotation></semantics></math> and use the UniPC scheduler <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> for <math alttext="50" class="ltx_Math" display="inline" id="A2.SS3.p1.2.m2.1"><semantics id="A2.SS3.p1.2.m2.1a"><mn id="A2.SS3.p1.2.m2.1.1" xref="A2.SS3.p1.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.2.m2.1b"><cn id="A2.SS3.p1.2.m2.1.1.cmml" type="integer" xref="A2.SS3.p1.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.2.m2.1c">50</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.2.m2.1d">50</annotation></semantics></math> time-steps across all experiments.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional Results</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>More Results on Google Scanned Objects (GSO)</h3>
<figure class="ltx_figure" id="A3.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="537" id="A3.F13.g1" src="x13.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F13.3.1.1" style="font-size:90%;">Figure 13</span>: </span><span class="ltx_text ltx_font_bold" id="A3.F13.4.2" style="font-size:90%;">Performance on Real-world scenes<span class="ltx_text ltx_font_medium" id="A3.F13.4.2.1"> We show results on images from MSD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> dataset (a) &amp; (b) and examples from images captured using a smartphone device (c) &amp; (d). Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS2" title="C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">C.2</span></a> describes the experimental details and text prompts used for the inference. We observe that “BrushNet-FT” does not generate accurate reflections, whereas our method is able to generate plausible reflections on the mirror.</span></span></figcaption>
</figure>
<div class="ltx_para" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">We provide additional results on 3D models from Google Scanned Objects (GSO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite> in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F15" title="Figure 15 ‣ C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">15</span></a>. GSO contains real-world scanned objects. We create renderings using these objects with the pipeline discussed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S3" title="3 SynMirror: A synthetic dataset of mirror reflections ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">3</span></a>. We notice that our method  MirrorFusion<math alttext="{}^{\text{*}}" class="ltx_Math" display="inline" id="A3.SS1.p1.1.m1.1"><semantics id="A3.SS1.p1.1.m1.1a"><msup id="A3.SS1.p1.1.m1.1.1" xref="A3.SS1.p1.1.m1.1.1.cmml"><mi id="A3.SS1.p1.1.m1.1.1a" xref="A3.SS1.p1.1.m1.1.1.cmml"></mi><mtext id="A3.SS1.p1.1.m1.1.1.1" xref="A3.SS1.p1.1.m1.1.1.1a.cmml">*</mtext></msup><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.1.m1.1b"><apply id="A3.SS1.p1.1.m1.1.1.cmml" xref="A3.SS1.p1.1.m1.1.1"><ci id="A3.SS1.p1.1.m1.1.1.1a.cmml" xref="A3.SS1.p1.1.m1.1.1.1"><mtext id="A3.SS1.p1.1.m1.1.1.1.cmml" mathsize="70%" xref="A3.SS1.p1.1.m1.1.1.1">*</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.1.m1.1c">{}^{\text{*}}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
consistently generates accurate reflections of objects and floors in the mirror. However, <span class="ltx_text ltx_font_italic" id="A3.SS1.p1.1.1">“BrushNet-FT”</span>, is not able to generate the reflection of the floor correctly in image with blue ball (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F15" title="Figure 15 ‣ C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">15</span></a> (o), and (p)) and carton (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F15" title="Figure 15 ‣ C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">15</span></a> (l))
Further, it does not get the appearance of the pencil-box right, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F15" title="Figure 15 ‣ C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">15</span></a> (g) and (h). Additionally, it generates the reflection with the wrong structure in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F15" title="Figure 15 ‣ C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">15</span></a> (c) and (d). These results further substantiate the generalization capabilities of our method.</p>
</div>
<div class="ltx_para" id="A3.SS1.p2">
<p class="ltx_p" id="A3.SS1.p2.1">Text prompts used for results in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F15" title="Figure 15 ‣ C.2 Results on real-world scenes. ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">15</span></a> are as follows:</p>
<ul class="ltx_itemize" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i1.p1.1.1">(a) &amp; (b).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i1.p1.1.2">“A perfect plane mirror reflection of a sofa with purple cushioning.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.p1.1.1">(c) &amp; (d).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i2.p1.1.2">“A perfect plane mirror reflection of a yellow chair.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i3.p1.1.1">(e) &amp; (f).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i3.p1.1.2">“A perfect plane mirror reflection of a white stool with a purple top.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i4.p1">
<p class="ltx_p" id="A3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i4.p1.1.1">(g) &amp; (h).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i4.p1.1.2">“A perfect plane mirror reflection of a purple bag with bluish circular patterns.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i5.p1">
<p class="ltx_p" id="A3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i5.p1.1.1">(i) &amp; (j).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i5.p1.1.2">“A perfect plane mirror reflection of a camouflaged military-style bag.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i6.p1">
<p class="ltx_p" id="A3.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i6.p1.1.1">(k) &amp; (l).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i6.p1.1.2">“A perfect plane mirror reflection of a cardboard box on a patterned floor.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i7.p1">
<p class="ltx_p" id="A3.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i7.p1.1.1">(m) &amp; (n).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i7.p1.1.2">“A perfect plane mirror reflection of a yellow and white mug on a grey surface.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i8.p1">
<p class="ltx_p" id="A3.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i8.p1.1.1">(o) &amp; (p).</span> <span class="ltx_text ltx_font_italic" id="A3.I1.i8.p1.1.2">“A perfect plane mirror reflection of a blue ball with an orange cover.”</span></p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="A3.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="542" id="A3.F14.g1" src="x14.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F14.3.1.1" style="font-size:90%;">Figure 14</span>: </span><span class="ltx_text ltx_font_bold" id="A3.F14.4.2" style="font-size:90%;">Qualitative Comparison with Commercial Products<span class="ltx_text ltx_font_medium" id="A3.F14.4.2.1"> We compare our results with Adobe Firefly. Our method is significantly better than the existing commercial product. This highlights the challenging nature of the task and the effectiveness of our proposed method in addressing it.</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Results on real-world scenes.</h3>
<div class="ltx_para" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">We present real-world examples from the MSD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> dataset in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F13" title="Figure 13 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">13</span></a> (a) and (b), utilizing the ground truth (GT) masks provided within the dataset as the corresponding mirror masks. Since our method requires depth, we infer it from Marigold and normalize it as described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S4.SS2.SSS1" title="4.2.1 Model architecture ‣ 4.2 MirrorFusion ‣ 4 Method ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">4.2.1</span></a>. We observe that the baseline method fails to position the object accurately and produces incorrect color in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F13" title="Figure 13 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">13</span></a> (a). In contrast, our method generates better reflections on the mirror.</p>
</div>
<div class="ltx_para" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.1">We also capture more examples from a hand-held smartphone device in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F13" title="Figure 13 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">13</span></a> (c) &amp; (d). We manually annotate the mask corresponding to the mirror location and infer the depth from Marigold <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> as described above. Similar to the previous observation, our method preserves the shape of the object. Check the lid in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F13" title="Figure 13 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">13</span></a> (c) and the roundness of the ball in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F13" title="Figure 13 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">13</span></a> (d). These results show that our method generates better reflections than the baselines on real-world settings. Our method shows promising results on real-world settings, but still has scope for improvement, showing the challenging nature of this task.</p>
</div>
<div class="ltx_para" id="A3.SS2.p3">
<p class="ltx_p" id="A3.SS2.p3.1">Text prompts used for generating the results in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F13" title="Figure 13 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">13</span></a> are as follows:</p>
<ul class="ltx_itemize" id="A3.I2">
<li class="ltx_item" id="A3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I2.i1.p1">
<p class="ltx_p" id="A3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I2.i1.p1.1.1">(a).</span> <span class="ltx_text ltx_font_italic" id="A3.I2.i1.p1.1.2">“A perfect plane mirror reflection of a rose gold colored portable power-bank.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I2.i2.p1">
<p class="ltx_p" id="A3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I2.i2.p1.1.1">(b).</span> <span class="ltx_text ltx_font_italic" id="A3.I2.i2.p1.1.2">“A perfect plane mirror reflection of a white ceramic teapot.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I2.i3.p1">
<p class="ltx_p" id="A3.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I2.i3.p1.1.1">(c).</span> <span class="ltx_text ltx_font_italic" id="A3.I2.i3.p1.1.2">“A perfect plane mirror reflection of a black round box with a black lid on it.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I2.i4.p1">
<p class="ltx_p" id="A3.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I2.i4.p1.1.1">(d).</span> <span class="ltx_text ltx_font_italic" id="A3.I2.i4.p1.1.2">“A perfect plane mirror reflection of a green color round ball.”</span></p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="A3.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="513" id="A3.F15.g1" src="x15.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F15.3.1.1" style="font-size:90%;">Figure 15</span>: </span><span class="ltx_text ltx_font_bold" id="A3.F15.4.2" style="font-size:90%;">Qualitative Comparison on unseen 3D assets from GSO.<span class="ltx_text ltx_font_medium" id="A3.F15.4.2.1"> We show results from (a) &amp; (b) “3D Dollhouse Sofa”, (c) &amp; (d) “3D Dollhouse Swing”, (e) &amp; (f) “3D Dollhouse TablePurple”, (g) &amp; (h) “Big Dot Aqua Pencil Case”, (i) &amp; (j) “Digital Camo Double Decker Lunch Bag”, (k) &amp; (l) “INTERNATIONAL PAPER Willamette 4 Brown Bag” , (m) &amp; (n) “Room Essentials Mug White Yellow” and (o) &amp; (p) “Toys R Us Treat Dispenser Smart Puzzle Foobler”. Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.SS1" title="C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">C.1</span></a> describes how images are generated and text-prompts used for the inference. We observe that “BrushNet-FT” does not generate accurate reflections in (c),(d),(f),(g),(h) whereas our method is able to generate correct reflections on the mirror. </span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Comparison with Commercial Products.</h3>
<div class="ltx_para" id="A3.SS3.p1">
<p class="ltx_p" id="A3.SS3.p1.1">We compare our method with commercial products such as Adobe Firefly in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F14" title="Figure 14 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">14</span></a>. Our method significantly outperforms existing commercial solutions. Results from Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F14" title="Figure 14 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">14</span></a> highlight the challenging nature of the task of generating plausible mirror reflections and the critical gap that exists in current state-of-the-art methods. Text prompts used in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F14" title="Figure 14 ‣ C.1 More Results on Google Scanned Objects (GSO) ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">14</span></a> are as follows:</p>
<ul class="ltx_itemize" id="A3.I3">
<li class="ltx_item" id="A3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i1.p1">
<p class="ltx_p" id="A3.I3.i1.p1.1"><math alttext="1^{st}" class="ltx_Math" display="inline" id="A3.I3.i1.p1.1.m1.1"><semantics id="A3.I3.i1.p1.1.m1.1a"><msup id="A3.I3.i1.p1.1.m1.1.1" xref="A3.I3.i1.p1.1.m1.1.1.cmml"><mn id="A3.I3.i1.p1.1.m1.1.1.2" xref="A3.I3.i1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="A3.I3.i1.p1.1.m1.1.1.3" xref="A3.I3.i1.p1.1.m1.1.1.3.cmml"><mi id="A3.I3.i1.p1.1.m1.1.1.3.2" xref="A3.I3.i1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="A3.I3.i1.p1.1.m1.1.1.3.1" xref="A3.I3.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I3.i1.p1.1.m1.1.1.3.3" xref="A3.I3.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I3.i1.p1.1.m1.1b"><apply id="A3.I3.i1.p1.1.m1.1.1.cmml" xref="A3.I3.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I3.i1.p1.1.m1.1.1.1.cmml" xref="A3.I3.i1.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I3.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I3.i1.p1.1.m1.1.1.2">1</cn><apply id="A3.I3.i1.p1.1.m1.1.1.3.cmml" xref="A3.I3.i1.p1.1.m1.1.1.3"><times id="A3.I3.i1.p1.1.m1.1.1.3.1.cmml" xref="A3.I3.i1.p1.1.m1.1.1.3.1"></times><ci id="A3.I3.i1.p1.1.m1.1.1.3.2.cmml" xref="A3.I3.i1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="A3.I3.i1.p1.1.m1.1.1.3.3.cmml" xref="A3.I3.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I3.i1.p1.1.m1.1c">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A3.I3.i1.p1.1.m1.1d">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I3.i1.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I3.i1.p1.1.2">“A perfect plane mirror reflection of a black bottle of liquor.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i2.p1">
<p class="ltx_p" id="A3.I3.i2.p1.1"><math alttext="2^{nd}" class="ltx_Math" display="inline" id="A3.I3.i2.p1.1.m1.1"><semantics id="A3.I3.i2.p1.1.m1.1a"><msup id="A3.I3.i2.p1.1.m1.1.1" xref="A3.I3.i2.p1.1.m1.1.1.cmml"><mn id="A3.I3.i2.p1.1.m1.1.1.2" xref="A3.I3.i2.p1.1.m1.1.1.2.cmml">2</mn><mrow id="A3.I3.i2.p1.1.m1.1.1.3" xref="A3.I3.i2.p1.1.m1.1.1.3.cmml"><mi id="A3.I3.i2.p1.1.m1.1.1.3.2" xref="A3.I3.i2.p1.1.m1.1.1.3.2.cmml">n</mi><mo id="A3.I3.i2.p1.1.m1.1.1.3.1" xref="A3.I3.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I3.i2.p1.1.m1.1.1.3.3" xref="A3.I3.i2.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I3.i2.p1.1.m1.1b"><apply id="A3.I3.i2.p1.1.m1.1.1.cmml" xref="A3.I3.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I3.i2.p1.1.m1.1.1.1.cmml" xref="A3.I3.i2.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I3.i2.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I3.i2.p1.1.m1.1.1.2">2</cn><apply id="A3.I3.i2.p1.1.m1.1.1.3.cmml" xref="A3.I3.i2.p1.1.m1.1.1.3"><times id="A3.I3.i2.p1.1.m1.1.1.3.1.cmml" xref="A3.I3.i2.p1.1.m1.1.1.3.1"></times><ci id="A3.I3.i2.p1.1.m1.1.1.3.2.cmml" xref="A3.I3.i2.p1.1.m1.1.1.3.2">𝑛</ci><ci id="A3.I3.i2.p1.1.m1.1.1.3.3.cmml" xref="A3.I3.i2.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I3.i2.p1.1.m1.1c">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A3.I3.i2.p1.1.m1.1d">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I3.i2.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I3.i2.p1.1.2">“A perfect plane mirror reflection of a red kettle-ball with a handle.”</span></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.4 </span>Robustness to pre-trained monocular depth estimation methods</h3>
<div class="ltx_para" id="A3.SS4.p1">
<p class="ltx_p" id="A3.SS4.p1.1">Our method is invariant to the choice of the pre-trained monocular depth estimation method. We present results from two state-of-the-art methods, Marigold <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> and DepthAnythingV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib54" title=""><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite>, in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F16" title="Figure 16 ‣ C.4 Robustness to pre-trained monocular depth estimation methods ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">16</span></a>. We observe minimal variation in the generation of reflections between both options, thereby confirming the robustness of our approach to the preference of the pre-trained monocular depth estimation method.</p>
</div>
<div class="ltx_para" id="A3.SS4.p2">
<p class="ltx_p" id="A3.SS4.p2.1">Text prompts for Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A3.F16" title="Figure 16 ‣ C.4 Robustness to pre-trained monocular depth estimation methods ‣ Appendix C Additional Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">16</span></a> are as follows, each row uses the same text prompt:</p>
<ul class="ltx_itemize" id="A3.I4">
<li class="ltx_item" id="A3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i1.p1">
<p class="ltx_p" id="A3.I4.i1.p1.1"><math alttext="1^{st}" class="ltx_Math" display="inline" id="A3.I4.i1.p1.1.m1.1"><semantics id="A3.I4.i1.p1.1.m1.1a"><msup id="A3.I4.i1.p1.1.m1.1.1" xref="A3.I4.i1.p1.1.m1.1.1.cmml"><mn id="A3.I4.i1.p1.1.m1.1.1.2" xref="A3.I4.i1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="A3.I4.i1.p1.1.m1.1.1.3" xref="A3.I4.i1.p1.1.m1.1.1.3.cmml"><mi id="A3.I4.i1.p1.1.m1.1.1.3.2" xref="A3.I4.i1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="A3.I4.i1.p1.1.m1.1.1.3.1" xref="A3.I4.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I4.i1.p1.1.m1.1.1.3.3" xref="A3.I4.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I4.i1.p1.1.m1.1b"><apply id="A3.I4.i1.p1.1.m1.1.1.cmml" xref="A3.I4.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I4.i1.p1.1.m1.1.1.1.cmml" xref="A3.I4.i1.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I4.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I4.i1.p1.1.m1.1.1.2">1</cn><apply id="A3.I4.i1.p1.1.m1.1.1.3.cmml" xref="A3.I4.i1.p1.1.m1.1.1.3"><times id="A3.I4.i1.p1.1.m1.1.1.3.1.cmml" xref="A3.I4.i1.p1.1.m1.1.1.3.1"></times><ci id="A3.I4.i1.p1.1.m1.1.1.3.2.cmml" xref="A3.I4.i1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="A3.I4.i1.p1.1.m1.1.1.3.3.cmml" xref="A3.I4.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I4.i1.p1.1.m1.1c">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A3.I4.i1.p1.1.m1.1d">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I4.i1.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I4.i1.p1.1.2">“A perfect plane mirror reflection of a rectangular cabinet with a door, two drawers, a truncated triangular base, and a triangular top.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i2.p1">
<p class="ltx_p" id="A3.I4.i2.p1.1"><math alttext="2^{nd}" class="ltx_Math" display="inline" id="A3.I4.i2.p1.1.m1.1"><semantics id="A3.I4.i2.p1.1.m1.1a"><msup id="A3.I4.i2.p1.1.m1.1.1" xref="A3.I4.i2.p1.1.m1.1.1.cmml"><mn id="A3.I4.i2.p1.1.m1.1.1.2" xref="A3.I4.i2.p1.1.m1.1.1.2.cmml">2</mn><mrow id="A3.I4.i2.p1.1.m1.1.1.3" xref="A3.I4.i2.p1.1.m1.1.1.3.cmml"><mi id="A3.I4.i2.p1.1.m1.1.1.3.2" xref="A3.I4.i2.p1.1.m1.1.1.3.2.cmml">n</mi><mo id="A3.I4.i2.p1.1.m1.1.1.3.1" xref="A3.I4.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I4.i2.p1.1.m1.1.1.3.3" xref="A3.I4.i2.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I4.i2.p1.1.m1.1b"><apply id="A3.I4.i2.p1.1.m1.1.1.cmml" xref="A3.I4.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I4.i2.p1.1.m1.1.1.1.cmml" xref="A3.I4.i2.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I4.i2.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I4.i2.p1.1.m1.1.1.2">2</cn><apply id="A3.I4.i2.p1.1.m1.1.1.3.cmml" xref="A3.I4.i2.p1.1.m1.1.1.3"><times id="A3.I4.i2.p1.1.m1.1.1.3.1.cmml" xref="A3.I4.i2.p1.1.m1.1.1.3.1"></times><ci id="A3.I4.i2.p1.1.m1.1.1.3.2.cmml" xref="A3.I4.i2.p1.1.m1.1.1.3.2">𝑛</ci><ci id="A3.I4.i2.p1.1.m1.1.1.3.3.cmml" xref="A3.I4.i2.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I4.i2.p1.1.m1.1c">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A3.I4.i2.p1.1.m1.1d">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I4.i2.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I4.i2.p1.1.2">“A perfect plane mirror reflection of a swivel chair with curved backrest, slanted seat, curved armrests, and a triangular top.”</span></p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="A3.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="883" id="A3.F16.g1" src="x16.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F16.3.1.1" style="font-size:90%;">Figure 16</span>: </span><span class="ltx_text ltx_font_bold" id="A3.F16.4.2" style="font-size:90%;">Choice of pre-trained monocular depth estimation method during inference.<span class="ltx_text ltx_font_medium" id="A3.F16.4.2.1"> We observe negligible differences in the reflection generation across both choices, Marigold <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> and DepthAnythingV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib54" title=""><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite>, supporting the stability of our method regardless of the chosen pre-trained monocular depth estimation technique. We use “Marigold” in all our experiments.</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.5 </span>More Qualitative Comparisons</h3>
<div class="ltx_para" id="A3.SS5.p1">
<p class="ltx_p" id="A3.SS5.p1.1">As discussed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5" title="5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">5</span></a>, we compare our method with zero-shot baselines, denoted by <span class="ltx_text ltx_font_italic" id="A3.SS5.p1.1.1">“-ZS”</span> and baselines trained on SynMirror, denoted by <span class="ltx_text ltx_font_italic" id="A3.SS5.p1.1.2">“-FT”</span>. We provide additional results in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F17" title="Figure 17 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">17</span></a> and  <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F18" title="Figure 18 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">18</span></a>. Consistent with the findings in the main paper, our method generates better mirror reflections while preserving the fidelity of both the object’s appearance and the floor.</p>
</div>
<div class="ltx_para" id="A3.SS5.p2">
<p class="ltx_p" id="A3.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="A3.SS5.p2.1.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F17" title="Figure 17 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">17</span></a></span> Each row in this figure uses the same text prompt. Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A3.I5">
<li class="ltx_item" id="A3.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I5.i1.p1">
<p class="ltx_p" id="A3.I5.i1.p1.1"><math alttext="1^{st}" class="ltx_Math" display="inline" id="A3.I5.i1.p1.1.m1.1"><semantics id="A3.I5.i1.p1.1.m1.1a"><msup id="A3.I5.i1.p1.1.m1.1.1" xref="A3.I5.i1.p1.1.m1.1.1.cmml"><mn id="A3.I5.i1.p1.1.m1.1.1.2" xref="A3.I5.i1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="A3.I5.i1.p1.1.m1.1.1.3" xref="A3.I5.i1.p1.1.m1.1.1.3.cmml"><mi id="A3.I5.i1.p1.1.m1.1.1.3.2" xref="A3.I5.i1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="A3.I5.i1.p1.1.m1.1.1.3.1" xref="A3.I5.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I5.i1.p1.1.m1.1.1.3.3" xref="A3.I5.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I5.i1.p1.1.m1.1b"><apply id="A3.I5.i1.p1.1.m1.1.1.cmml" xref="A3.I5.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I5.i1.p1.1.m1.1.1.1.cmml" xref="A3.I5.i1.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I5.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I5.i1.p1.1.m1.1.1.2">1</cn><apply id="A3.I5.i1.p1.1.m1.1.1.3.cmml" xref="A3.I5.i1.p1.1.m1.1.1.3"><times id="A3.I5.i1.p1.1.m1.1.1.3.1.cmml" xref="A3.I5.i1.p1.1.m1.1.1.3.1"></times><ci id="A3.I5.i1.p1.1.m1.1.1.3.2.cmml" xref="A3.I5.i1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="A3.I5.i1.p1.1.m1.1.1.3.3.cmml" xref="A3.I5.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I5.i1.p1.1.m1.1c">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A3.I5.i1.p1.1.m1.1d">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I5.i1.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I5.i1.p1.1.2">“A perfect plane mirror reflection of a multifunctional electronic device, including HDMI Blu-ray player, stereo receiver, amplifier, CD, and DVD player.”</span>
</p>
</div>
</li>
<li class="ltx_item" id="A3.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I5.i2.p1">
<p class="ltx_p" id="A3.I5.i2.p1.1"><math alttext="2^{nd}" class="ltx_Math" display="inline" id="A3.I5.i2.p1.1.m1.1"><semantics id="A3.I5.i2.p1.1.m1.1a"><msup id="A3.I5.i2.p1.1.m1.1.1" xref="A3.I5.i2.p1.1.m1.1.1.cmml"><mn id="A3.I5.i2.p1.1.m1.1.1.2" xref="A3.I5.i2.p1.1.m1.1.1.2.cmml">2</mn><mrow id="A3.I5.i2.p1.1.m1.1.1.3" xref="A3.I5.i2.p1.1.m1.1.1.3.cmml"><mi id="A3.I5.i2.p1.1.m1.1.1.3.2" xref="A3.I5.i2.p1.1.m1.1.1.3.2.cmml">n</mi><mo id="A3.I5.i2.p1.1.m1.1.1.3.1" xref="A3.I5.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I5.i2.p1.1.m1.1.1.3.3" xref="A3.I5.i2.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I5.i2.p1.1.m1.1b"><apply id="A3.I5.i2.p1.1.m1.1.1.cmml" xref="A3.I5.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I5.i2.p1.1.m1.1.1.1.cmml" xref="A3.I5.i2.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I5.i2.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I5.i2.p1.1.m1.1.1.2">2</cn><apply id="A3.I5.i2.p1.1.m1.1.1.3.cmml" xref="A3.I5.i2.p1.1.m1.1.1.3"><times id="A3.I5.i2.p1.1.m1.1.1.3.1.cmml" xref="A3.I5.i2.p1.1.m1.1.1.3.1"></times><ci id="A3.I5.i2.p1.1.m1.1.1.3.2.cmml" xref="A3.I5.i2.p1.1.m1.1.1.3.2">𝑛</ci><ci id="A3.I5.i2.p1.1.m1.1.1.3.3.cmml" xref="A3.I5.i2.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I5.i2.p1.1.m1.1c">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A3.I5.i2.p1.1.m1.1d">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I5.i2.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I5.i2.p1.1.2">“A perfect plane mirror reflection of a red flashlight with a metal pipe.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I5.i3.p1">
<p class="ltx_p" id="A3.I5.i3.p1.1"><math alttext="3^{rd}" class="ltx_Math" display="inline" id="A3.I5.i3.p1.1.m1.1"><semantics id="A3.I5.i3.p1.1.m1.1a"><msup id="A3.I5.i3.p1.1.m1.1.1" xref="A3.I5.i3.p1.1.m1.1.1.cmml"><mn id="A3.I5.i3.p1.1.m1.1.1.2" xref="A3.I5.i3.p1.1.m1.1.1.2.cmml">3</mn><mrow id="A3.I5.i3.p1.1.m1.1.1.3" xref="A3.I5.i3.p1.1.m1.1.1.3.cmml"><mi id="A3.I5.i3.p1.1.m1.1.1.3.2" xref="A3.I5.i3.p1.1.m1.1.1.3.2.cmml">r</mi><mo id="A3.I5.i3.p1.1.m1.1.1.3.1" xref="A3.I5.i3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I5.i3.p1.1.m1.1.1.3.3" xref="A3.I5.i3.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I5.i3.p1.1.m1.1b"><apply id="A3.I5.i3.p1.1.m1.1.1.cmml" xref="A3.I5.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I5.i3.p1.1.m1.1.1.1.cmml" xref="A3.I5.i3.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I5.i3.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I5.i3.p1.1.m1.1.1.2">3</cn><apply id="A3.I5.i3.p1.1.m1.1.1.3.cmml" xref="A3.I5.i3.p1.1.m1.1.1.3"><times id="A3.I5.i3.p1.1.m1.1.1.3.1.cmml" xref="A3.I5.i3.p1.1.m1.1.1.3.1"></times><ci id="A3.I5.i3.p1.1.m1.1.1.3.2.cmml" xref="A3.I5.i3.p1.1.m1.1.1.3.2">𝑟</ci><ci id="A3.I5.i3.p1.1.m1.1.1.3.3.cmml" xref="A3.I5.i3.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I5.i3.p1.1.m1.1c">3^{rd}</annotation><annotation encoding="application/x-llamapun" id="A3.I5.i3.p1.1.m1.1d">3 start_POSTSUPERSCRIPT italic_r italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I5.i3.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I5.i3.p1.1.2">“A perfect plane mirror reflection of a red kettlebell with a handle.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I5.i4.p1">
<p class="ltx_p" id="A3.I5.i4.p1.1"><math alttext="4^{th}" class="ltx_Math" display="inline" id="A3.I5.i4.p1.1.m1.1"><semantics id="A3.I5.i4.p1.1.m1.1a"><msup id="A3.I5.i4.p1.1.m1.1.1" xref="A3.I5.i4.p1.1.m1.1.1.cmml"><mn id="A3.I5.i4.p1.1.m1.1.1.2" xref="A3.I5.i4.p1.1.m1.1.1.2.cmml">4</mn><mrow id="A3.I5.i4.p1.1.m1.1.1.3" xref="A3.I5.i4.p1.1.m1.1.1.3.cmml"><mi id="A3.I5.i4.p1.1.m1.1.1.3.2" xref="A3.I5.i4.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A3.I5.i4.p1.1.m1.1.1.3.1" xref="A3.I5.i4.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I5.i4.p1.1.m1.1.1.3.3" xref="A3.I5.i4.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I5.i4.p1.1.m1.1b"><apply id="A3.I5.i4.p1.1.m1.1.1.cmml" xref="A3.I5.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I5.i4.p1.1.m1.1.1.1.cmml" xref="A3.I5.i4.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I5.i4.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I5.i4.p1.1.m1.1.1.2">4</cn><apply id="A3.I5.i4.p1.1.m1.1.1.3.cmml" xref="A3.I5.i4.p1.1.m1.1.1.3"><times id="A3.I5.i4.p1.1.m1.1.1.3.1.cmml" xref="A3.I5.i4.p1.1.m1.1.1.3.1"></times><ci id="A3.I5.i4.p1.1.m1.1.1.3.2.cmml" xref="A3.I5.i4.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A3.I5.i4.p1.1.m1.1.1.3.3.cmml" xref="A3.I5.i4.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I5.i4.p1.1.m1.1c">4^{th}</annotation><annotation encoding="application/x-llamapun" id="A3.I5.i4.p1.1.m1.1d">4 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I5.i4.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I5.i4.p1.1.2">“A perfect plane mirror reflection of a concrete block.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I5.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I5.i5.p1">
<p class="ltx_p" id="A3.I5.i5.p1.1"><math alttext="5^{th}" class="ltx_Math" display="inline" id="A3.I5.i5.p1.1.m1.1"><semantics id="A3.I5.i5.p1.1.m1.1a"><msup id="A3.I5.i5.p1.1.m1.1.1" xref="A3.I5.i5.p1.1.m1.1.1.cmml"><mn id="A3.I5.i5.p1.1.m1.1.1.2" xref="A3.I5.i5.p1.1.m1.1.1.2.cmml">5</mn><mrow id="A3.I5.i5.p1.1.m1.1.1.3" xref="A3.I5.i5.p1.1.m1.1.1.3.cmml"><mi id="A3.I5.i5.p1.1.m1.1.1.3.2" xref="A3.I5.i5.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A3.I5.i5.p1.1.m1.1.1.3.1" xref="A3.I5.i5.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I5.i5.p1.1.m1.1.1.3.3" xref="A3.I5.i5.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I5.i5.p1.1.m1.1b"><apply id="A3.I5.i5.p1.1.m1.1.1.cmml" xref="A3.I5.i5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I5.i5.p1.1.m1.1.1.1.cmml" xref="A3.I5.i5.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I5.i5.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I5.i5.p1.1.m1.1.1.2">5</cn><apply id="A3.I5.i5.p1.1.m1.1.1.3.cmml" xref="A3.I5.i5.p1.1.m1.1.1.3"><times id="A3.I5.i5.p1.1.m1.1.1.3.1.cmml" xref="A3.I5.i5.p1.1.m1.1.1.3.1"></times><ci id="A3.I5.i5.p1.1.m1.1.1.3.2.cmml" xref="A3.I5.i5.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A3.I5.i5.p1.1.m1.1.1.3.3.cmml" xref="A3.I5.i5.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I5.i5.p1.1.m1.1c">5^{th}</annotation><annotation encoding="application/x-llamapun" id="A3.I5.i5.p1.1.m1.1d">5 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I5.i5.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I5.i5.p1.1.2">“A perfect plane mirror reflection of a wooden barrel.”</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A3.SS5.p3">
<p class="ltx_p" id="A3.SS5.p3.1"><span class="ltx_text ltx_font_bold" id="A3.SS5.p3.1.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F18" title="Figure 18 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">18</span></a></span> Each row in this figure uses the same text prompt. Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A3.I6">
<li class="ltx_item" id="A3.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I6.i1.p1">
<p class="ltx_p" id="A3.I6.i1.p1.1"><math alttext="1^{st}" class="ltx_Math" display="inline" id="A3.I6.i1.p1.1.m1.1"><semantics id="A3.I6.i1.p1.1.m1.1a"><msup id="A3.I6.i1.p1.1.m1.1.1" xref="A3.I6.i1.p1.1.m1.1.1.cmml"><mn id="A3.I6.i1.p1.1.m1.1.1.2" xref="A3.I6.i1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="A3.I6.i1.p1.1.m1.1.1.3" xref="A3.I6.i1.p1.1.m1.1.1.3.cmml"><mi id="A3.I6.i1.p1.1.m1.1.1.3.2" xref="A3.I6.i1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="A3.I6.i1.p1.1.m1.1.1.3.1" xref="A3.I6.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I6.i1.p1.1.m1.1.1.3.3" xref="A3.I6.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I6.i1.p1.1.m1.1b"><apply id="A3.I6.i1.p1.1.m1.1.1.cmml" xref="A3.I6.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I6.i1.p1.1.m1.1.1.1.cmml" xref="A3.I6.i1.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I6.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I6.i1.p1.1.m1.1.1.2">1</cn><apply id="A3.I6.i1.p1.1.m1.1.1.3.cmml" xref="A3.I6.i1.p1.1.m1.1.1.3"><times id="A3.I6.i1.p1.1.m1.1.1.3.1.cmml" xref="A3.I6.i1.p1.1.m1.1.1.3.1"></times><ci id="A3.I6.i1.p1.1.m1.1.1.3.2.cmml" xref="A3.I6.i1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="A3.I6.i1.p1.1.m1.1.1.3.3.cmml" xref="A3.I6.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I6.i1.p1.1.m1.1c">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A3.I6.i1.p1.1.m1.1d">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I6.i1.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I6.i1.p1.1.2">“A perfect plane mirror reflection of a large, red, rusty metal barrel.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I6.i2.p1">
<p class="ltx_p" id="A3.I6.i2.p1.1"><math alttext="2^{nd}" class="ltx_Math" display="inline" id="A3.I6.i2.p1.1.m1.1"><semantics id="A3.I6.i2.p1.1.m1.1a"><msup id="A3.I6.i2.p1.1.m1.1.1" xref="A3.I6.i2.p1.1.m1.1.1.cmml"><mn id="A3.I6.i2.p1.1.m1.1.1.2" xref="A3.I6.i2.p1.1.m1.1.1.2.cmml">2</mn><mrow id="A3.I6.i2.p1.1.m1.1.1.3" xref="A3.I6.i2.p1.1.m1.1.1.3.cmml"><mi id="A3.I6.i2.p1.1.m1.1.1.3.2" xref="A3.I6.i2.p1.1.m1.1.1.3.2.cmml">n</mi><mo id="A3.I6.i2.p1.1.m1.1.1.3.1" xref="A3.I6.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I6.i2.p1.1.m1.1.1.3.3" xref="A3.I6.i2.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I6.i2.p1.1.m1.1b"><apply id="A3.I6.i2.p1.1.m1.1.1.cmml" xref="A3.I6.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I6.i2.p1.1.m1.1.1.1.cmml" xref="A3.I6.i2.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I6.i2.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I6.i2.p1.1.m1.1.1.2">2</cn><apply id="A3.I6.i2.p1.1.m1.1.1.3.cmml" xref="A3.I6.i2.p1.1.m1.1.1.3"><times id="A3.I6.i2.p1.1.m1.1.1.3.1.cmml" xref="A3.I6.i2.p1.1.m1.1.1.3.1"></times><ci id="A3.I6.i2.p1.1.m1.1.1.3.2.cmml" xref="A3.I6.i2.p1.1.m1.1.1.3.2">𝑛</ci><ci id="A3.I6.i2.p1.1.m1.1.1.3.3.cmml" xref="A3.I6.i2.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I6.i2.p1.1.m1.1c">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A3.I6.i2.p1.1.m1.1d">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I6.i2.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I6.i2.p1.1.2">“A perfect plane mirror reflection of a small stuffed animal toy.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I6.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I6.i3.p1">
<p class="ltx_p" id="A3.I6.i3.p1.1"><math alttext="3^{rd}" class="ltx_Math" display="inline" id="A3.I6.i3.p1.1.m1.1"><semantics id="A3.I6.i3.p1.1.m1.1a"><msup id="A3.I6.i3.p1.1.m1.1.1" xref="A3.I6.i3.p1.1.m1.1.1.cmml"><mn id="A3.I6.i3.p1.1.m1.1.1.2" xref="A3.I6.i3.p1.1.m1.1.1.2.cmml">3</mn><mrow id="A3.I6.i3.p1.1.m1.1.1.3" xref="A3.I6.i3.p1.1.m1.1.1.3.cmml"><mi id="A3.I6.i3.p1.1.m1.1.1.3.2" xref="A3.I6.i3.p1.1.m1.1.1.3.2.cmml">r</mi><mo id="A3.I6.i3.p1.1.m1.1.1.3.1" xref="A3.I6.i3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I6.i3.p1.1.m1.1.1.3.3" xref="A3.I6.i3.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I6.i3.p1.1.m1.1b"><apply id="A3.I6.i3.p1.1.m1.1.1.cmml" xref="A3.I6.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I6.i3.p1.1.m1.1.1.1.cmml" xref="A3.I6.i3.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I6.i3.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I6.i3.p1.1.m1.1.1.2">3</cn><apply id="A3.I6.i3.p1.1.m1.1.1.3.cmml" xref="A3.I6.i3.p1.1.m1.1.1.3"><times id="A3.I6.i3.p1.1.m1.1.1.3.1.cmml" xref="A3.I6.i3.p1.1.m1.1.1.3.1"></times><ci id="A3.I6.i3.p1.1.m1.1.1.3.2.cmml" xref="A3.I6.i3.p1.1.m1.1.1.3.2">𝑟</ci><ci id="A3.I6.i3.p1.1.m1.1.1.3.3.cmml" xref="A3.I6.i3.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I6.i3.p1.1.m1.1c">3^{rd}</annotation><annotation encoding="application/x-llamapun" id="A3.I6.i3.p1.1.m1.1d">3 start_POSTSUPERSCRIPT italic_r italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I6.i3.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I6.i3.p1.1.2">“A perfect plane mirror reflection of a modern office chair with a blue upholstered seat, back, and headrest.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I6.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I6.i4.p1">
<p class="ltx_p" id="A3.I6.i4.p1.1"><math alttext="4^{th}" class="ltx_Math" display="inline" id="A3.I6.i4.p1.1.m1.1"><semantics id="A3.I6.i4.p1.1.m1.1a"><msup id="A3.I6.i4.p1.1.m1.1.1" xref="A3.I6.i4.p1.1.m1.1.1.cmml"><mn id="A3.I6.i4.p1.1.m1.1.1.2" xref="A3.I6.i4.p1.1.m1.1.1.2.cmml">4</mn><mrow id="A3.I6.i4.p1.1.m1.1.1.3" xref="A3.I6.i4.p1.1.m1.1.1.3.cmml"><mi id="A3.I6.i4.p1.1.m1.1.1.3.2" xref="A3.I6.i4.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A3.I6.i4.p1.1.m1.1.1.3.1" xref="A3.I6.i4.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I6.i4.p1.1.m1.1.1.3.3" xref="A3.I6.i4.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I6.i4.p1.1.m1.1b"><apply id="A3.I6.i4.p1.1.m1.1.1.cmml" xref="A3.I6.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I6.i4.p1.1.m1.1.1.1.cmml" xref="A3.I6.i4.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I6.i4.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I6.i4.p1.1.m1.1.1.2">4</cn><apply id="A3.I6.i4.p1.1.m1.1.1.3.cmml" xref="A3.I6.i4.p1.1.m1.1.1.3"><times id="A3.I6.i4.p1.1.m1.1.1.3.1.cmml" xref="A3.I6.i4.p1.1.m1.1.1.3.1"></times><ci id="A3.I6.i4.p1.1.m1.1.1.3.2.cmml" xref="A3.I6.i4.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A3.I6.i4.p1.1.m1.1.1.3.3.cmml" xref="A3.I6.i4.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I6.i4.p1.1.m1.1c">4^{th}</annotation><annotation encoding="application/x-llamapun" id="A3.I6.i4.p1.1.m1.1d">4 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I6.i4.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I6.i4.p1.1.2">“A perfect plane mirror reflection of a Gaft Shower Gel Box.”</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I6.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I6.i5.p1">
<p class="ltx_p" id="A3.I6.i5.p1.1"><math alttext="5^{th}" class="ltx_Math" display="inline" id="A3.I6.i5.p1.1.m1.1"><semantics id="A3.I6.i5.p1.1.m1.1a"><msup id="A3.I6.i5.p1.1.m1.1.1" xref="A3.I6.i5.p1.1.m1.1.1.cmml"><mn id="A3.I6.i5.p1.1.m1.1.1.2" xref="A3.I6.i5.p1.1.m1.1.1.2.cmml">5</mn><mrow id="A3.I6.i5.p1.1.m1.1.1.3" xref="A3.I6.i5.p1.1.m1.1.1.3.cmml"><mi id="A3.I6.i5.p1.1.m1.1.1.3.2" xref="A3.I6.i5.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A3.I6.i5.p1.1.m1.1.1.3.1" xref="A3.I6.i5.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.I6.i5.p1.1.m1.1.1.3.3" xref="A3.I6.i5.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A3.I6.i5.p1.1.m1.1b"><apply id="A3.I6.i5.p1.1.m1.1.1.cmml" xref="A3.I6.i5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I6.i5.p1.1.m1.1.1.1.cmml" xref="A3.I6.i5.p1.1.m1.1.1">superscript</csymbol><cn id="A3.I6.i5.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.I6.i5.p1.1.m1.1.1.2">5</cn><apply id="A3.I6.i5.p1.1.m1.1.1.3.cmml" xref="A3.I6.i5.p1.1.m1.1.1.3"><times id="A3.I6.i5.p1.1.m1.1.1.3.1.cmml" xref="A3.I6.i5.p1.1.m1.1.1.3.1"></times><ci id="A3.I6.i5.p1.1.m1.1.1.3.2.cmml" xref="A3.I6.i5.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A3.I6.i5.p1.1.m1.1.1.3.3.cmml" xref="A3.I6.i5.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I6.i5.p1.1.m1.1c">5^{th}</annotation><annotation encoding="application/x-llamapun" id="A3.I6.i5.p1.1.m1.1d">5 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A3.I6.i5.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A3.I6.i5.p1.1.2">“A perfect plane mirror reflection of a black cowboy hat.”</span></p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Limitations and Social Impact</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1"><span class="ltx_text ltx_font_bold" id="A4.p1.1.1">Limitations.</span> As our method leverages synthetic data to train a model capable of producing realistic mirror reflections, the model still has scope for improvement in generating reflections for highly complex objects and scenarios. Although our model generates plausible results on real-world images, there is significant scope for improvement, which can be achieved by using more advanced photo-realistic simulators or collecting large-scale real-world images. We aim to address these issues in our future work.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p2">
<p class="ltx_p" id="A4.p2.1"><span class="ltx_text ltx_font_bold" id="A4.p2.1.1">Social Impact.</span> Our method uses diffusion-based generative models, which, despite their potential, can be exploited for spreading misinformation. Therefore, it is crucial to use these models responsibly.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional Details</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Results from recent T2I methods</h3>
<div class="ltx_para" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">We present additional results from the recent Stable Diffusion 3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite> model in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F19" title="Figure 19 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">19</span></a>.
Text prompts are generated by using the prefix: <span class="ltx_text ltx_font_italic" id="A5.SS1.p1.1.1">“A perfect plane mirror reflection of”</span> and suffix: <span class="ltx_text ltx_font_italic" id="A5.SS1.p1.1.2">“in front of the mirror positioned at an angle with respect to the mirror.”</span> to the object description of the input image. We observe that standalone text-to-image methods are inadequate in generating controlled and realistic mirror reflections.</p>
</div>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Text prompts used in the experiments</h3>
<div class="ltx_para" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">This section provides the text prompts for the image generations in the main paper.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p2">
<p class="ltx_p" id="A5.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p2.1.1">Figure 1.</span> Each row in this figure uses the same text prompt. Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A5.I1">
<li class="ltx_item" id="A5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I1.i1.p1">
<p class="ltx_p" id="A5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I1.i1.p1.1.1">First row.</span> <span class="ltx_text ltx_font_italic" id="A5.I1.i1.p1.1.2">“A perfect plane mirror reflection of a swivel chair with a curved backrest, slanted seat, slender metal frame, and padded seat and backrest.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I1.i2.p1">
<p class="ltx_p" id="A5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I1.i2.p1.1.1">Second row.</span> <span class="ltx_text ltx_font_italic" id="A5.I1.i2.p1.1.2">“A perfect plane mirror reflection of a large red, yellow, and black industrial cement mixer.”</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p3">
<p class="ltx_p" id="A5.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p3.1.1">Figure 2.</span> Text prompts are already mentioned in the Figure of the main paper.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p4">
<p class="ltx_p" id="A5.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p4.1.1">Figure 5.</span> Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A5.I2">
<li class="ltx_item" id="A5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I2.i1.p1">
<p class="ltx_p" id="A5.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I2.i1.p1.1.1">(a).</span> <span class="ltx_text ltx_font_italic" id="A5.I2.i1.p1.1.2">“A perfect plane mirror reflection of a white golf ball with a red stripe and the letter O on it.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I2.i2.p1">
<p class="ltx_p" id="A5.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I2.i2.p1.1.1">(b).</span> <span class="ltx_text ltx_font_italic" id="A5.I2.i2.p1.1.2">“A perfect plane mirror reflection of a chair with a curved slatted frame, tufted backrest, and curved seat.”</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p5">
<p class="ltx_p" id="A5.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p5.1.1">Figure 6.</span> Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A5.I3">
<li class="ltx_item" id="A5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I3.i1.p1">
<p class="ltx_p" id="A5.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I3.i1.p1.1.1">(a).</span> <span class="ltx_text ltx_font_italic" id="A5.I3.i1.p1.1.2">“A perfect plane mirror reflection of a modern wooden chaise lounge with a white cushion.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I3.i2.p1">
<p class="ltx_p" id="A5.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I3.i2.p1.1.1">(b).</span> <span class="ltx_text ltx_font_italic" id="A5.I3.i2.p1.1.2">“A perfect plane mirror reflection of a swivel chair with a curved backrest, slender armrest, and swivel base.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I3.i3.p1">
<p class="ltx_p" id="A5.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I3.i3.p1.1.1">(c).</span> <span class="ltx_text ltx_font_italic" id="A5.I3.i3.p1.1.2">“A perfect plane mirror reflection of a black cylindrical with a lid.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I3.i4.p1">
<p class="ltx_p" id="A5.I3.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I3.i4.p1.1.1">(d).</span> <span class="ltx_text ltx_font_italic" id="A5.I3.i4.p1.1.2">“A perfect plane mirror reflection of a wooden box with intricate floral and heart-shaped carvings on each side, featuring a dark brown hue with visible wood grain texture.”</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A5.SS2.p6">
<p class="ltx_p" id="A5.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p6.1.1">Figure 7.</span> Each row in this figure uses the same text prompt. Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A5.I4">
<li class="ltx_item" id="A5.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I4.i1.p1">
<p class="ltx_p" id="A5.I4.i1.p1.1"><math alttext="1^{st}" class="ltx_Math" display="inline" id="A5.I4.i1.p1.1.m1.1"><semantics id="A5.I4.i1.p1.1.m1.1a"><msup id="A5.I4.i1.p1.1.m1.1.1" xref="A5.I4.i1.p1.1.m1.1.1.cmml"><mn id="A5.I4.i1.p1.1.m1.1.1.2" xref="A5.I4.i1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="A5.I4.i1.p1.1.m1.1.1.3" xref="A5.I4.i1.p1.1.m1.1.1.3.cmml"><mi id="A5.I4.i1.p1.1.m1.1.1.3.2" xref="A5.I4.i1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="A5.I4.i1.p1.1.m1.1.1.3.1" xref="A5.I4.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I4.i1.p1.1.m1.1.1.3.3" xref="A5.I4.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I4.i1.p1.1.m1.1b"><apply id="A5.I4.i1.p1.1.m1.1.1.cmml" xref="A5.I4.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I4.i1.p1.1.m1.1.1.1.cmml" xref="A5.I4.i1.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I4.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I4.i1.p1.1.m1.1.1.2">1</cn><apply id="A5.I4.i1.p1.1.m1.1.1.3.cmml" xref="A5.I4.i1.p1.1.m1.1.1.3"><times id="A5.I4.i1.p1.1.m1.1.1.3.1.cmml" xref="A5.I4.i1.p1.1.m1.1.1.3.1"></times><ci id="A5.I4.i1.p1.1.m1.1.1.3.2.cmml" xref="A5.I4.i1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="A5.I4.i1.p1.1.m1.1.1.3.3.cmml" xref="A5.I4.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I4.i1.p1.1.m1.1c">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A5.I4.i1.p1.1.m1.1d">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I4.i1.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I4.i1.p1.1.2">“A perfect plane mirror reflection of a large red, yellow, and black industrial cement mixer.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I4.i2.p1">
<p class="ltx_p" id="A5.I4.i2.p1.1"><math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.I4.i2.p1.1.m1.1"><semantics id="A5.I4.i2.p1.1.m1.1a"><msup id="A5.I4.i2.p1.1.m1.1.1" xref="A5.I4.i2.p1.1.m1.1.1.cmml"><mn id="A5.I4.i2.p1.1.m1.1.1.2" xref="A5.I4.i2.p1.1.m1.1.1.2.cmml">2</mn><mrow id="A5.I4.i2.p1.1.m1.1.1.3" xref="A5.I4.i2.p1.1.m1.1.1.3.cmml"><mi id="A5.I4.i2.p1.1.m1.1.1.3.2" xref="A5.I4.i2.p1.1.m1.1.1.3.2.cmml">n</mi><mo id="A5.I4.i2.p1.1.m1.1.1.3.1" xref="A5.I4.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I4.i2.p1.1.m1.1.1.3.3" xref="A5.I4.i2.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I4.i2.p1.1.m1.1b"><apply id="A5.I4.i2.p1.1.m1.1.1.cmml" xref="A5.I4.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I4.i2.p1.1.m1.1.1.1.cmml" xref="A5.I4.i2.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I4.i2.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I4.i2.p1.1.m1.1.1.2">2</cn><apply id="A5.I4.i2.p1.1.m1.1.1.3.cmml" xref="A5.I4.i2.p1.1.m1.1.1.3"><times id="A5.I4.i2.p1.1.m1.1.1.3.1.cmml" xref="A5.I4.i2.p1.1.m1.1.1.3.1"></times><ci id="A5.I4.i2.p1.1.m1.1.1.3.2.cmml" xref="A5.I4.i2.p1.1.m1.1.1.3.2">𝑛</ci><ci id="A5.I4.i2.p1.1.m1.1.1.3.3.cmml" xref="A5.I4.i2.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I4.i2.p1.1.m1.1c">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.I4.i2.p1.1.m1.1d">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I4.i2.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I4.i2.p1.1.2">“A perfect plane mirror reflection of a gold lipstick container.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I4.i3.p1">
<p class="ltx_p" id="A5.I4.i3.p1.1"><math alttext="3^{rd}" class="ltx_Math" display="inline" id="A5.I4.i3.p1.1.m1.1"><semantics id="A5.I4.i3.p1.1.m1.1a"><msup id="A5.I4.i3.p1.1.m1.1.1" xref="A5.I4.i3.p1.1.m1.1.1.cmml"><mn id="A5.I4.i3.p1.1.m1.1.1.2" xref="A5.I4.i3.p1.1.m1.1.1.2.cmml">3</mn><mrow id="A5.I4.i3.p1.1.m1.1.1.3" xref="A5.I4.i3.p1.1.m1.1.1.3.cmml"><mi id="A5.I4.i3.p1.1.m1.1.1.3.2" xref="A5.I4.i3.p1.1.m1.1.1.3.2.cmml">r</mi><mo id="A5.I4.i3.p1.1.m1.1.1.3.1" xref="A5.I4.i3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I4.i3.p1.1.m1.1.1.3.3" xref="A5.I4.i3.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I4.i3.p1.1.m1.1b"><apply id="A5.I4.i3.p1.1.m1.1.1.cmml" xref="A5.I4.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I4.i3.p1.1.m1.1.1.1.cmml" xref="A5.I4.i3.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I4.i3.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I4.i3.p1.1.m1.1.1.2">3</cn><apply id="A5.I4.i3.p1.1.m1.1.1.3.cmml" xref="A5.I4.i3.p1.1.m1.1.1.3"><times id="A5.I4.i3.p1.1.m1.1.1.3.1.cmml" xref="A5.I4.i3.p1.1.m1.1.1.3.1"></times><ci id="A5.I4.i3.p1.1.m1.1.1.3.2.cmml" xref="A5.I4.i3.p1.1.m1.1.1.3.2">𝑟</ci><ci id="A5.I4.i3.p1.1.m1.1.1.3.3.cmml" xref="A5.I4.i3.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I4.i3.p1.1.m1.1c">3^{rd}</annotation><annotation encoding="application/x-llamapun" id="A5.I4.i3.p1.1.m1.1d">3 start_POSTSUPERSCRIPT italic_r italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I4.i3.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I4.i3.p1.1.2">“A perfect plane mirror reflection of a cylindrical object with a cream-colored exterior and a central hollow core; vertical seams divide the outer surface.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I4.i4.p1">
<p class="ltx_p" id="A5.I4.i4.p1.1"><math alttext="4^{th}" class="ltx_Math" display="inline" id="A5.I4.i4.p1.1.m1.1"><semantics id="A5.I4.i4.p1.1.m1.1a"><msup id="A5.I4.i4.p1.1.m1.1.1" xref="A5.I4.i4.p1.1.m1.1.1.cmml"><mn id="A5.I4.i4.p1.1.m1.1.1.2" xref="A5.I4.i4.p1.1.m1.1.1.2.cmml">4</mn><mrow id="A5.I4.i4.p1.1.m1.1.1.3" xref="A5.I4.i4.p1.1.m1.1.1.3.cmml"><mi id="A5.I4.i4.p1.1.m1.1.1.3.2" xref="A5.I4.i4.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A5.I4.i4.p1.1.m1.1.1.3.1" xref="A5.I4.i4.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I4.i4.p1.1.m1.1.1.3.3" xref="A5.I4.i4.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I4.i4.p1.1.m1.1b"><apply id="A5.I4.i4.p1.1.m1.1.1.cmml" xref="A5.I4.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I4.i4.p1.1.m1.1.1.1.cmml" xref="A5.I4.i4.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I4.i4.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I4.i4.p1.1.m1.1.1.2">4</cn><apply id="A5.I4.i4.p1.1.m1.1.1.3.cmml" xref="A5.I4.i4.p1.1.m1.1.1.3"><times id="A5.I4.i4.p1.1.m1.1.1.3.1.cmml" xref="A5.I4.i4.p1.1.m1.1.1.3.1"></times><ci id="A5.I4.i4.p1.1.m1.1.1.3.2.cmml" xref="A5.I4.i4.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A5.I4.i4.p1.1.m1.1.1.3.3.cmml" xref="A5.I4.i4.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I4.i4.p1.1.m1.1c">4^{th}</annotation><annotation encoding="application/x-llamapun" id="A5.I4.i4.p1.1.m1.1d">4 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I4.i4.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I4.i4.p1.1.2">“A perfect plane mirror reflection of a weathered wooden treasure chest with metal reinforcements, large metal ring on the side, and mossy accents.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I4.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I4.i5.p1">
<p class="ltx_p" id="A5.I4.i5.p1.1"><math alttext="5^{th}" class="ltx_Math" display="inline" id="A5.I4.i5.p1.1.m1.1"><semantics id="A5.I4.i5.p1.1.m1.1a"><msup id="A5.I4.i5.p1.1.m1.1.1" xref="A5.I4.i5.p1.1.m1.1.1.cmml"><mn id="A5.I4.i5.p1.1.m1.1.1.2" xref="A5.I4.i5.p1.1.m1.1.1.2.cmml">5</mn><mrow id="A5.I4.i5.p1.1.m1.1.1.3" xref="A5.I4.i5.p1.1.m1.1.1.3.cmml"><mi id="A5.I4.i5.p1.1.m1.1.1.3.2" xref="A5.I4.i5.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A5.I4.i5.p1.1.m1.1.1.3.1" xref="A5.I4.i5.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I4.i5.p1.1.m1.1.1.3.3" xref="A5.I4.i5.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I4.i5.p1.1.m1.1b"><apply id="A5.I4.i5.p1.1.m1.1.1.cmml" xref="A5.I4.i5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I4.i5.p1.1.m1.1.1.1.cmml" xref="A5.I4.i5.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I4.i5.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I4.i5.p1.1.m1.1.1.2">5</cn><apply id="A5.I4.i5.p1.1.m1.1.1.3.cmml" xref="A5.I4.i5.p1.1.m1.1.1.3"><times id="A5.I4.i5.p1.1.m1.1.1.3.1.cmml" xref="A5.I4.i5.p1.1.m1.1.1.3.1"></times><ci id="A5.I4.i5.p1.1.m1.1.1.3.2.cmml" xref="A5.I4.i5.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A5.I4.i5.p1.1.m1.1.1.3.3.cmml" xref="A5.I4.i5.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I4.i5.p1.1.m1.1c">5^{th}</annotation><annotation encoding="application/x-llamapun" id="A5.I4.i5.p1.1.m1.1d">5 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I4.i5.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I4.i5.p1.1.2">“A perfect plane mirror reflection of a grey cabinet with gold legs and chest of drawers.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I4.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I4.i6.p1">
<p class="ltx_p" id="A5.I4.i6.p1.1"><math alttext="6^{th}" class="ltx_Math" display="inline" id="A5.I4.i6.p1.1.m1.1"><semantics id="A5.I4.i6.p1.1.m1.1a"><msup id="A5.I4.i6.p1.1.m1.1.1" xref="A5.I4.i6.p1.1.m1.1.1.cmml"><mn id="A5.I4.i6.p1.1.m1.1.1.2" xref="A5.I4.i6.p1.1.m1.1.1.2.cmml">6</mn><mrow id="A5.I4.i6.p1.1.m1.1.1.3" xref="A5.I4.i6.p1.1.m1.1.1.3.cmml"><mi id="A5.I4.i6.p1.1.m1.1.1.3.2" xref="A5.I4.i6.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A5.I4.i6.p1.1.m1.1.1.3.1" xref="A5.I4.i6.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I4.i6.p1.1.m1.1.1.3.3" xref="A5.I4.i6.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I4.i6.p1.1.m1.1b"><apply id="A5.I4.i6.p1.1.m1.1.1.cmml" xref="A5.I4.i6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I4.i6.p1.1.m1.1.1.1.cmml" xref="A5.I4.i6.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I4.i6.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I4.i6.p1.1.m1.1.1.2">6</cn><apply id="A5.I4.i6.p1.1.m1.1.1.3.cmml" xref="A5.I4.i6.p1.1.m1.1.1.3"><times id="A5.I4.i6.p1.1.m1.1.1.3.1.cmml" xref="A5.I4.i6.p1.1.m1.1.1.3.1"></times><ci id="A5.I4.i6.p1.1.m1.1.1.3.2.cmml" xref="A5.I4.i6.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A5.I4.i6.p1.1.m1.1.1.3.3.cmml" xref="A5.I4.i6.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I4.i6.p1.1.m1.1c">6^{th}</annotation><annotation encoding="application/x-llamapun" id="A5.I4.i6.p1.1.m1.1d">6 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I4.i6.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I4.i6.p1.1.2">“A perfect plane mirror reflection of a black stone with intricate swirl designs on it.”</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A5.SS2.p7">
<p class="ltx_p" id="A5.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p7.1.1">Figure 8.</span> Each row in this figure uses the same text prompt. Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A5.I5">
<li class="ltx_item" id="A5.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I5.i1.p1">
<p class="ltx_p" id="A5.I5.i1.p1.1"><math alttext="1^{st}" class="ltx_Math" display="inline" id="A5.I5.i1.p1.1.m1.1"><semantics id="A5.I5.i1.p1.1.m1.1a"><msup id="A5.I5.i1.p1.1.m1.1.1" xref="A5.I5.i1.p1.1.m1.1.1.cmml"><mn id="A5.I5.i1.p1.1.m1.1.1.2" xref="A5.I5.i1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="A5.I5.i1.p1.1.m1.1.1.3" xref="A5.I5.i1.p1.1.m1.1.1.3.cmml"><mi id="A5.I5.i1.p1.1.m1.1.1.3.2" xref="A5.I5.i1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="A5.I5.i1.p1.1.m1.1.1.3.1" xref="A5.I5.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I5.i1.p1.1.m1.1.1.3.3" xref="A5.I5.i1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I5.i1.p1.1.m1.1b"><apply id="A5.I5.i1.p1.1.m1.1.1.cmml" xref="A5.I5.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I5.i1.p1.1.m1.1.1.1.cmml" xref="A5.I5.i1.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I5.i1.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I5.i1.p1.1.m1.1.1.2">1</cn><apply id="A5.I5.i1.p1.1.m1.1.1.3.cmml" xref="A5.I5.i1.p1.1.m1.1.1.3"><times id="A5.I5.i1.p1.1.m1.1.1.3.1.cmml" xref="A5.I5.i1.p1.1.m1.1.1.3.1"></times><ci id="A5.I5.i1.p1.1.m1.1.1.3.2.cmml" xref="A5.I5.i1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="A5.I5.i1.p1.1.m1.1.1.3.3.cmml" xref="A5.I5.i1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I5.i1.p1.1.m1.1c">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A5.I5.i1.p1.1.m1.1d">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I5.i1.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I5.i1.p1.1.2">“A perfect plane mirror reflection of a slanted-top cuboid footstool.”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I5.i2.p1">
<p class="ltx_p" id="A5.I5.i2.p1.1"><math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.I5.i2.p1.1.m1.1"><semantics id="A5.I5.i2.p1.1.m1.1a"><msup id="A5.I5.i2.p1.1.m1.1.1" xref="A5.I5.i2.p1.1.m1.1.1.cmml"><mn id="A5.I5.i2.p1.1.m1.1.1.2" xref="A5.I5.i2.p1.1.m1.1.1.2.cmml">2</mn><mrow id="A5.I5.i2.p1.1.m1.1.1.3" xref="A5.I5.i2.p1.1.m1.1.1.3.cmml"><mi id="A5.I5.i2.p1.1.m1.1.1.3.2" xref="A5.I5.i2.p1.1.m1.1.1.3.2.cmml">n</mi><mo id="A5.I5.i2.p1.1.m1.1.1.3.1" xref="A5.I5.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.I5.i2.p1.1.m1.1.1.3.3" xref="A5.I5.i2.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.I5.i2.p1.1.m1.1b"><apply id="A5.I5.i2.p1.1.m1.1.1.cmml" xref="A5.I5.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.I5.i2.p1.1.m1.1.1.1.cmml" xref="A5.I5.i2.p1.1.m1.1.1">superscript</csymbol><cn id="A5.I5.i2.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.I5.i2.p1.1.m1.1.1.2">2</cn><apply id="A5.I5.i2.p1.1.m1.1.1.3.cmml" xref="A5.I5.i2.p1.1.m1.1.1.3"><times id="A5.I5.i2.p1.1.m1.1.1.3.1.cmml" xref="A5.I5.i2.p1.1.m1.1.1.3.1"></times><ci id="A5.I5.i2.p1.1.m1.1.1.3.2.cmml" xref="A5.I5.i2.p1.1.m1.1.1.3.2">𝑛</ci><ci id="A5.I5.i2.p1.1.m1.1.1.3.3.cmml" xref="A5.I5.i2.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.I5.i2.p1.1.m1.1c">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.I5.i2.p1.1.m1.1d">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A5.I5.i2.p1.1.1"> row.</span> <span class="ltx_text ltx_font_italic" id="A5.I5.i2.p1.1.2">“A perfect plane mirror reflection of a footstool with a cuboid base, spherical top, seat, and backrest.”</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A5.SS2.p8">
<p class="ltx_p" id="A5.SS2.p8.1"><span class="ltx_text ltx_font_bold" id="A5.SS2.p8.1.1">Figure 9.</span>Text prompts are as follows:</p>
<ul class="ltx_itemize" id="A5.I6">
<li class="ltx_item" id="A5.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I6.i1.p1">
<p class="ltx_p" id="A5.I6.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I6.i1.p1.1.1">(a).</span> <span class="ltx_text ltx_font_italic" id="A5.I6.i1.p1.1.2">“A perfect plane mirror reflection of a white ceramic bowl on a textured gray surface..”</span></p>
</div>
</li>
<li class="ltx_item" id="A5.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A5.I6.i2.p1">
<p class="ltx_p" id="A5.I6.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A5.I6.i2.p1.1.1">(b).</span> <span class="ltx_text ltx_font_italic" id="A5.I6.i2.p1.1.2">“A perfect plane mirror reflection of a camouflaged military-style bag”</span></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.3 </span>Generation of Segmentation Masks for computing metrics</h3>
<div class="ltx_para" id="A5.SS3.p1">
<p class="ltx_p" id="A5.SS3.p1.1">We compare the accuracy of the geometry of the generated reflection by comparing IoU between the segmentation mask of the reflection in the ground-truth object and the segmentation mask of the reflection in the generated object in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#S5" title="5 Experiments &amp; Results ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">5</span></a>. We utilize SAM to generate these segmentation masks. We provide initial seed points to SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> along with a rough bounding box. SAM then segments out the reflection of the object in ground truth as well as the generated image. Camera viewpoint variations within our dataset pose a challenge for reliable seed point initialization. We address this by manually creating a mapping to select seed points based on the camera pose. To accelerate the evaluation, we cache the segmentation masks of the ground-truth images.</p>
</div>
<figure class="ltx_figure" id="A5.F17"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="863" id="A5.F17.g1" src="x17.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F17.16.7.1" style="font-size:90%;">Figure 17</span>: </span><span class="ltx_text ltx_font_bold" id="A5.F17.12.6" style="font-size:90%;">Qualitative Comparison.<span class="ltx_text ltx_font_medium" id="A5.F17.12.6.6"> We observe that the state-of-the-art inpainting method “BrushNet-ZS” is not able to generate plausible reflections </span>(<math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.F17.7.1.m1.1"><semantics id="A5.F17.7.1.m1.1b"><msup id="A5.F17.7.1.m1.1.1" xref="A5.F17.7.1.m1.1.1.cmml"><mn id="A5.F17.7.1.m1.1.1.2" xref="A5.F17.7.1.m1.1.1.2.cmml">2</mn><mrow id="A5.F17.7.1.m1.1.1.3" xref="A5.F17.7.1.m1.1.1.3.cmml"><mi id="A5.F17.7.1.m1.1.1.3.2" xref="A5.F17.7.1.m1.1.1.3.2.cmml">n</mi><mo id="A5.F17.7.1.m1.1.1.3.1" xref="A5.F17.7.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.F17.7.1.m1.1.1.3.3" xref="A5.F17.7.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F17.7.1.m1.1c"><apply id="A5.F17.7.1.m1.1.1.cmml" xref="A5.F17.7.1.m1.1.1"><csymbol cd="ambiguous" id="A5.F17.7.1.m1.1.1.1.cmml" xref="A5.F17.7.1.m1.1.1">superscript</csymbol><cn id="A5.F17.7.1.m1.1.1.2.cmml" type="integer" xref="A5.F17.7.1.m1.1.1.2">2</cn><apply id="A5.F17.7.1.m1.1.1.3.cmml" xref="A5.F17.7.1.m1.1.1.3"><times id="A5.F17.7.1.m1.1.1.3.1.cmml" xref="A5.F17.7.1.m1.1.1.3.1"></times><ci id="A5.F17.7.1.m1.1.1.3.2.cmml" xref="A5.F17.7.1.m1.1.1.3.2">𝑛</ci><ci id="A5.F17.7.1.m1.1.1.3.3.cmml" xref="A5.F17.7.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F17.7.1.m1.1d">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.F17.7.1.m1.1e">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> column)<span class="ltx_text ltx_font_medium" id="A5.F17.8.2.1">. “BrushNet-FT” which is fine-tuned on SynMirror is able to generate plausible reflections, <math alttext="3^{rd}" class="ltx_Math" display="inline" id="A5.F17.8.2.1.m1.1"><semantics id="A5.F17.8.2.1.m1.1b"><msup id="A5.F17.8.2.1.m1.1.1" xref="A5.F17.8.2.1.m1.1.1.cmml"><mn id="A5.F17.8.2.1.m1.1.1.2" xref="A5.F17.8.2.1.m1.1.1.2.cmml">3</mn><mrow id="A5.F17.8.2.1.m1.1.1.3" xref="A5.F17.8.2.1.m1.1.1.3.cmml"><mi id="A5.F17.8.2.1.m1.1.1.3.2" xref="A5.F17.8.2.1.m1.1.1.3.2.cmml">r</mi><mo id="A5.F17.8.2.1.m1.1.1.3.1" xref="A5.F17.8.2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.F17.8.2.1.m1.1.1.3.3" xref="A5.F17.8.2.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F17.8.2.1.m1.1c"><apply id="A5.F17.8.2.1.m1.1.1.cmml" xref="A5.F17.8.2.1.m1.1.1"><csymbol cd="ambiguous" id="A5.F17.8.2.1.m1.1.1.1.cmml" xref="A5.F17.8.2.1.m1.1.1">superscript</csymbol><cn id="A5.F17.8.2.1.m1.1.1.2.cmml" type="integer" xref="A5.F17.8.2.1.m1.1.1.2">3</cn><apply id="A5.F17.8.2.1.m1.1.1.3.cmml" xref="A5.F17.8.2.1.m1.1.1.3"><times id="A5.F17.8.2.1.m1.1.1.3.1.cmml" xref="A5.F17.8.2.1.m1.1.1.3.1"></times><ci id="A5.F17.8.2.1.m1.1.1.3.2.cmml" xref="A5.F17.8.2.1.m1.1.1.3.2">𝑟</ci><ci id="A5.F17.8.2.1.m1.1.1.3.3.cmml" xref="A5.F17.8.2.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F17.8.2.1.m1.1d">3^{rd}</annotation><annotation encoding="application/x-llamapun" id="A5.F17.8.2.1.m1.1e">3 start_POSTSUPERSCRIPT italic_r italic_d end_POSTSUPERSCRIPT</annotation></semantics></math></span> column<span class="ltx_text ltx_font_medium" id="A5.F17.12.6.5">, but fails to accurately get the shape of the object. For example, the top surface of “dvd-player” in <math alttext="1^{st}" class="ltx_Math" display="inline" id="A5.F17.9.3.2.m1.1"><semantics id="A5.F17.9.3.2.m1.1b"><msup id="A5.F17.9.3.2.m1.1.1" xref="A5.F17.9.3.2.m1.1.1.cmml"><mn id="A5.F17.9.3.2.m1.1.1.2" xref="A5.F17.9.3.2.m1.1.1.2.cmml">1</mn><mrow id="A5.F17.9.3.2.m1.1.1.3" xref="A5.F17.9.3.2.m1.1.1.3.cmml"><mi id="A5.F17.9.3.2.m1.1.1.3.2" xref="A5.F17.9.3.2.m1.1.1.3.2.cmml">s</mi><mo id="A5.F17.9.3.2.m1.1.1.3.1" xref="A5.F17.9.3.2.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.F17.9.3.2.m1.1.1.3.3" xref="A5.F17.9.3.2.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F17.9.3.2.m1.1c"><apply id="A5.F17.9.3.2.m1.1.1.cmml" xref="A5.F17.9.3.2.m1.1.1"><csymbol cd="ambiguous" id="A5.F17.9.3.2.m1.1.1.1.cmml" xref="A5.F17.9.3.2.m1.1.1">superscript</csymbol><cn id="A5.F17.9.3.2.m1.1.1.2.cmml" type="integer" xref="A5.F17.9.3.2.m1.1.1.2">1</cn><apply id="A5.F17.9.3.2.m1.1.1.3.cmml" xref="A5.F17.9.3.2.m1.1.1.3"><times id="A5.F17.9.3.2.m1.1.1.3.1.cmml" xref="A5.F17.9.3.2.m1.1.1.3.1"></times><ci id="A5.F17.9.3.2.m1.1.1.3.2.cmml" xref="A5.F17.9.3.2.m1.1.1.3.2">𝑠</ci><ci id="A5.F17.9.3.2.m1.1.1.3.3.cmml" xref="A5.F17.9.3.2.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F17.9.3.2.m1.1d">1^{st}</annotation><annotation encoding="application/x-llamapun" id="A5.F17.9.3.2.m1.1e">1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> row is completely missing. The ”flashlight” reflection’s structure and appearance do not correspond with the object (<math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.F17.10.4.3.m2.1"><semantics id="A5.F17.10.4.3.m2.1b"><msup id="A5.F17.10.4.3.m2.1.1" xref="A5.F17.10.4.3.m2.1.1.cmml"><mn id="A5.F17.10.4.3.m2.1.1.2" xref="A5.F17.10.4.3.m2.1.1.2.cmml">2</mn><mrow id="A5.F17.10.4.3.m2.1.1.3" xref="A5.F17.10.4.3.m2.1.1.3.cmml"><mi id="A5.F17.10.4.3.m2.1.1.3.2" xref="A5.F17.10.4.3.m2.1.1.3.2.cmml">n</mi><mo id="A5.F17.10.4.3.m2.1.1.3.1" xref="A5.F17.10.4.3.m2.1.1.3.1.cmml">⁢</mo><mi id="A5.F17.10.4.3.m2.1.1.3.3" xref="A5.F17.10.4.3.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F17.10.4.3.m2.1c"><apply id="A5.F17.10.4.3.m2.1.1.cmml" xref="A5.F17.10.4.3.m2.1.1"><csymbol cd="ambiguous" id="A5.F17.10.4.3.m2.1.1.1.cmml" xref="A5.F17.10.4.3.m2.1.1">superscript</csymbol><cn id="A5.F17.10.4.3.m2.1.1.2.cmml" type="integer" xref="A5.F17.10.4.3.m2.1.1.2">2</cn><apply id="A5.F17.10.4.3.m2.1.1.3.cmml" xref="A5.F17.10.4.3.m2.1.1.3"><times id="A5.F17.10.4.3.m2.1.1.3.1.cmml" xref="A5.F17.10.4.3.m2.1.1.3.1"></times><ci id="A5.F17.10.4.3.m2.1.1.3.2.cmml" xref="A5.F17.10.4.3.m2.1.1.3.2">𝑛</ci><ci id="A5.F17.10.4.3.m2.1.1.3.3.cmml" xref="A5.F17.10.4.3.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F17.10.4.3.m2.1d">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.F17.10.4.3.m2.1e">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> row). Compared to these baselines MirrorFusion generates plausible reflections. Still there is issue in the shape of the “flashlight” in <math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.F17.11.5.4.m3.1"><semantics id="A5.F17.11.5.4.m3.1b"><msup id="A5.F17.11.5.4.m3.1.1" xref="A5.F17.11.5.4.m3.1.1.cmml"><mn id="A5.F17.11.5.4.m3.1.1.2" xref="A5.F17.11.5.4.m3.1.1.2.cmml">2</mn><mrow id="A5.F17.11.5.4.m3.1.1.3" xref="A5.F17.11.5.4.m3.1.1.3.cmml"><mi id="A5.F17.11.5.4.m3.1.1.3.2" xref="A5.F17.11.5.4.m3.1.1.3.2.cmml">n</mi><mo id="A5.F17.11.5.4.m3.1.1.3.1" xref="A5.F17.11.5.4.m3.1.1.3.1.cmml">⁢</mo><mi id="A5.F17.11.5.4.m3.1.1.3.3" xref="A5.F17.11.5.4.m3.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F17.11.5.4.m3.1c"><apply id="A5.F17.11.5.4.m3.1.1.cmml" xref="A5.F17.11.5.4.m3.1.1"><csymbol cd="ambiguous" id="A5.F17.11.5.4.m3.1.1.1.cmml" xref="A5.F17.11.5.4.m3.1.1">superscript</csymbol><cn id="A5.F17.11.5.4.m3.1.1.2.cmml" type="integer" xref="A5.F17.11.5.4.m3.1.1.2">2</cn><apply id="A5.F17.11.5.4.m3.1.1.3.cmml" xref="A5.F17.11.5.4.m3.1.1.3"><times id="A5.F17.11.5.4.m3.1.1.3.1.cmml" xref="A5.F17.11.5.4.m3.1.1.3.1"></times><ci id="A5.F17.11.5.4.m3.1.1.3.2.cmml" xref="A5.F17.11.5.4.m3.1.1.3.2">𝑛</ci><ci id="A5.F17.11.5.4.m3.1.1.3.3.cmml" xref="A5.F17.11.5.4.m3.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F17.11.5.4.m3.1d">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.F17.11.5.4.m3.1e">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> row. These issues are mitigated by  MirrorFusion<math alttext="{}^{\text{*}}" class="ltx_Math" display="inline" id="A5.F17.12.6.5.m4.1"><semantics id="A5.F17.12.6.5.m4.1b"><msup id="A5.F17.12.6.5.m4.1.1" xref="A5.F17.12.6.5.m4.1.1.cmml"><mi id="A5.F17.12.6.5.m4.1.1b" xref="A5.F17.12.6.5.m4.1.1.cmml"></mi><mtext id="A5.F17.12.6.5.m4.1.1.1" xref="A5.F17.12.6.5.m4.1.1.1a.cmml">*</mtext></msup><annotation-xml encoding="MathML-Content" id="A5.F17.12.6.5.m4.1c"><apply id="A5.F17.12.6.5.m4.1.1.cmml" xref="A5.F17.12.6.5.m4.1.1"><ci id="A5.F17.12.6.5.m4.1.1.1a.cmml" xref="A5.F17.12.6.5.m4.1.1.1"><mtext id="A5.F17.12.6.5.m4.1.1.1.cmml" mathsize="70%" xref="A5.F17.12.6.5.m4.1.1.1">*</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F17.12.6.5.m4.1d">{}^{\text{*}}</annotation><annotation encoding="application/x-llamapun" id="A5.F17.12.6.5.m4.1e">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>, which generates realistic, plausible and geometrically accurate reflections on the mirror. </span></span></figcaption>
</figure>
<figure class="ltx_figure" id="A5.F18"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="858" id="A5.F18.g1" src="x18.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F18.14.6.1" style="font-size:90%;">Figure 18</span>: </span><span class="ltx_text ltx_font_bold" id="A5.F18.10.5" style="font-size:90%;">Qualitative Comparison.<span class="ltx_text ltx_font_medium" id="A5.F18.10.5.5"> Similar to the observation in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#A5.F17" title="Figure 17 ‣ E.3 Generation of Segmentation Masks for computing metrics ‣ Appendix E Additional Details ‣ Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections"><span class="ltx_text ltx_ref_tag">17</span></a>, we observe that the state-of-the-art inpainting method “BrushNet-ZS” is not able to generate plausible reflections </span>(<math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.F18.6.1.m1.1"><semantics id="A5.F18.6.1.m1.1b"><msup id="A5.F18.6.1.m1.1.1" xref="A5.F18.6.1.m1.1.1.cmml"><mn id="A5.F18.6.1.m1.1.1.2" xref="A5.F18.6.1.m1.1.1.2.cmml">2</mn><mrow id="A5.F18.6.1.m1.1.1.3" xref="A5.F18.6.1.m1.1.1.3.cmml"><mi id="A5.F18.6.1.m1.1.1.3.2" xref="A5.F18.6.1.m1.1.1.3.2.cmml">n</mi><mo id="A5.F18.6.1.m1.1.1.3.1" xref="A5.F18.6.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.F18.6.1.m1.1.1.3.3" xref="A5.F18.6.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F18.6.1.m1.1c"><apply id="A5.F18.6.1.m1.1.1.cmml" xref="A5.F18.6.1.m1.1.1"><csymbol cd="ambiguous" id="A5.F18.6.1.m1.1.1.1.cmml" xref="A5.F18.6.1.m1.1.1">superscript</csymbol><cn id="A5.F18.6.1.m1.1.1.2.cmml" type="integer" xref="A5.F18.6.1.m1.1.1.2">2</cn><apply id="A5.F18.6.1.m1.1.1.3.cmml" xref="A5.F18.6.1.m1.1.1.3"><times id="A5.F18.6.1.m1.1.1.3.1.cmml" xref="A5.F18.6.1.m1.1.1.3.1"></times><ci id="A5.F18.6.1.m1.1.1.3.2.cmml" xref="A5.F18.6.1.m1.1.1.3.2">𝑛</ci><ci id="A5.F18.6.1.m1.1.1.3.3.cmml" xref="A5.F18.6.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F18.6.1.m1.1d">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.F18.6.1.m1.1e">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> column)<span class="ltx_text ltx_font_medium" id="A5.F18.7.2.1">. “BrushNet-FT” which is fine-tuned on SynMirror is able to generate plausible reflections, <math alttext="3^{rd}" class="ltx_Math" display="inline" id="A5.F18.7.2.1.m1.1"><semantics id="A5.F18.7.2.1.m1.1b"><msup id="A5.F18.7.2.1.m1.1.1" xref="A5.F18.7.2.1.m1.1.1.cmml"><mn id="A5.F18.7.2.1.m1.1.1.2" xref="A5.F18.7.2.1.m1.1.1.2.cmml">3</mn><mrow id="A5.F18.7.2.1.m1.1.1.3" xref="A5.F18.7.2.1.m1.1.1.3.cmml"><mi id="A5.F18.7.2.1.m1.1.1.3.2" xref="A5.F18.7.2.1.m1.1.1.3.2.cmml">r</mi><mo id="A5.F18.7.2.1.m1.1.1.3.1" xref="A5.F18.7.2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.F18.7.2.1.m1.1.1.3.3" xref="A5.F18.7.2.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F18.7.2.1.m1.1c"><apply id="A5.F18.7.2.1.m1.1.1.cmml" xref="A5.F18.7.2.1.m1.1.1"><csymbol cd="ambiguous" id="A5.F18.7.2.1.m1.1.1.1.cmml" xref="A5.F18.7.2.1.m1.1.1">superscript</csymbol><cn id="A5.F18.7.2.1.m1.1.1.2.cmml" type="integer" xref="A5.F18.7.2.1.m1.1.1.2">3</cn><apply id="A5.F18.7.2.1.m1.1.1.3.cmml" xref="A5.F18.7.2.1.m1.1.1.3"><times id="A5.F18.7.2.1.m1.1.1.3.1.cmml" xref="A5.F18.7.2.1.m1.1.1.3.1"></times><ci id="A5.F18.7.2.1.m1.1.1.3.2.cmml" xref="A5.F18.7.2.1.m1.1.1.3.2">𝑟</ci><ci id="A5.F18.7.2.1.m1.1.1.3.3.cmml" xref="A5.F18.7.2.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F18.7.2.1.m1.1d">3^{rd}</annotation><annotation encoding="application/x-llamapun" id="A5.F18.7.2.1.m1.1e">3 start_POSTSUPERSCRIPT italic_r italic_d end_POSTSUPERSCRIPT</annotation></semantics></math></span> column<span class="ltx_text ltx_font_medium" id="A5.F18.10.5.4"> but fails to get shape of the object in the reflection. For example, observe the “chair” in <math alttext="3^{rd}" class="ltx_Math" display="inline" id="A5.F18.8.3.2.m1.1"><semantics id="A5.F18.8.3.2.m1.1b"><msup id="A5.F18.8.3.2.m1.1.1" xref="A5.F18.8.3.2.m1.1.1.cmml"><mn id="A5.F18.8.3.2.m1.1.1.2" xref="A5.F18.8.3.2.m1.1.1.2.cmml">3</mn><mrow id="A5.F18.8.3.2.m1.1.1.3" xref="A5.F18.8.3.2.m1.1.1.3.cmml"><mi id="A5.F18.8.3.2.m1.1.1.3.2" xref="A5.F18.8.3.2.m1.1.1.3.2.cmml">r</mi><mo id="A5.F18.8.3.2.m1.1.1.3.1" xref="A5.F18.8.3.2.m1.1.1.3.1.cmml">⁢</mo><mi id="A5.F18.8.3.2.m1.1.1.3.3" xref="A5.F18.8.3.2.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F18.8.3.2.m1.1c"><apply id="A5.F18.8.3.2.m1.1.1.cmml" xref="A5.F18.8.3.2.m1.1.1"><csymbol cd="ambiguous" id="A5.F18.8.3.2.m1.1.1.1.cmml" xref="A5.F18.8.3.2.m1.1.1">superscript</csymbol><cn id="A5.F18.8.3.2.m1.1.1.2.cmml" type="integer" xref="A5.F18.8.3.2.m1.1.1.2">3</cn><apply id="A5.F18.8.3.2.m1.1.1.3.cmml" xref="A5.F18.8.3.2.m1.1.1.3"><times id="A5.F18.8.3.2.m1.1.1.3.1.cmml" xref="A5.F18.8.3.2.m1.1.1.3.1"></times><ci id="A5.F18.8.3.2.m1.1.1.3.2.cmml" xref="A5.F18.8.3.2.m1.1.1.3.2">𝑟</ci><ci id="A5.F18.8.3.2.m1.1.1.3.3.cmml" xref="A5.F18.8.3.2.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F18.8.3.2.m1.1d">3^{rd}</annotation><annotation encoding="application/x-llamapun" id="A5.F18.8.3.2.m1.1e">3 start_POSTSUPERSCRIPT italic_r italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> row, the head of the chair is missing. The pose of the toy in <math alttext="2^{nd}" class="ltx_Math" display="inline" id="A5.F18.9.4.3.m2.1"><semantics id="A5.F18.9.4.3.m2.1b"><msup id="A5.F18.9.4.3.m2.1.1" xref="A5.F18.9.4.3.m2.1.1.cmml"><mn id="A5.F18.9.4.3.m2.1.1.2" xref="A5.F18.9.4.3.m2.1.1.2.cmml">2</mn><mrow id="A5.F18.9.4.3.m2.1.1.3" xref="A5.F18.9.4.3.m2.1.1.3.cmml"><mi id="A5.F18.9.4.3.m2.1.1.3.2" xref="A5.F18.9.4.3.m2.1.1.3.2.cmml">n</mi><mo id="A5.F18.9.4.3.m2.1.1.3.1" xref="A5.F18.9.4.3.m2.1.1.3.1.cmml">⁢</mo><mi id="A5.F18.9.4.3.m2.1.1.3.3" xref="A5.F18.9.4.3.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A5.F18.9.4.3.m2.1c"><apply id="A5.F18.9.4.3.m2.1.1.cmml" xref="A5.F18.9.4.3.m2.1.1"><csymbol cd="ambiguous" id="A5.F18.9.4.3.m2.1.1.1.cmml" xref="A5.F18.9.4.3.m2.1.1">superscript</csymbol><cn id="A5.F18.9.4.3.m2.1.1.2.cmml" type="integer" xref="A5.F18.9.4.3.m2.1.1.2">2</cn><apply id="A5.F18.9.4.3.m2.1.1.3.cmml" xref="A5.F18.9.4.3.m2.1.1.3"><times id="A5.F18.9.4.3.m2.1.1.3.1.cmml" xref="A5.F18.9.4.3.m2.1.1.3.1"></times><ci id="A5.F18.9.4.3.m2.1.1.3.2.cmml" xref="A5.F18.9.4.3.m2.1.1.3.2">𝑛</ci><ci id="A5.F18.9.4.3.m2.1.1.3.3.cmml" xref="A5.F18.9.4.3.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F18.9.4.3.m2.1d">2^{nd}</annotation><annotation encoding="application/x-llamapun" id="A5.F18.9.4.3.m2.1e">2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> row does not correspond to that of the real object. Compared to this MirrorFusion and  MirrorFusion<math alttext="{}^{\text{*}}" class="ltx_Math" display="inline" id="A5.F18.10.5.4.m3.1"><semantics id="A5.F18.10.5.4.m3.1b"><msup id="A5.F18.10.5.4.m3.1.1" xref="A5.F18.10.5.4.m3.1.1.cmml"><mi id="A5.F18.10.5.4.m3.1.1b" xref="A5.F18.10.5.4.m3.1.1.cmml"></mi><mtext id="A5.F18.10.5.4.m3.1.1.1" xref="A5.F18.10.5.4.m3.1.1.1a.cmml">*</mtext></msup><annotation-xml encoding="MathML-Content" id="A5.F18.10.5.4.m3.1c"><apply id="A5.F18.10.5.4.m3.1.1.cmml" xref="A5.F18.10.5.4.m3.1.1"><ci id="A5.F18.10.5.4.m3.1.1.1a.cmml" xref="A5.F18.10.5.4.m3.1.1.1"><mtext id="A5.F18.10.5.4.m3.1.1.1.cmml" mathsize="70%" xref="A5.F18.10.5.4.m3.1.1.1">*</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F18.10.5.4.m3.1d">{}^{\text{*}}</annotation><annotation encoding="application/x-llamapun" id="A5.F18.10.5.4.m3.1e">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math> generates plausible reflections on the mirror. </span></span></figcaption>
</figure>
<figure class="ltx_figure" id="A5.F19"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="788" id="A5.F19.g1" src="x19.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F19.5.1.1" style="font-size:90%;">Figure 19</span>: </span><span class="ltx_text ltx_font_bold" id="A5.F19.6.2" style="font-size:90%;">Additional results of images generated from Stable Diffusion 3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.14677v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>.<span class="ltx_text ltx_font_medium" id="A5.F19.6.2.1"> Text-to-image models struggle to produce consistent and controlled mirror reflections when prompted to generate them. We use the prefix <span class="ltx_text ltx_font_italic" id="A5.F19.6.2.1.1">“A perfect plane mirror reflection of”</span> and suffix <span class="ltx_text ltx_font_italic" id="A5.F19.6.2.1.2">“in front of the mirror positioned at an angle with respect to the mirror.”</span> along with the object description.</span></span></figcaption>
</figure>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.5.5.1" style="font-size:90%;">Avrahami et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.7.1" style="font-size:90%;">
Omri Avrahami, Dani Lischinski, and Ohad Fried.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.8.1" style="font-size:90%;">Blended diffusion for text-driven editing of natural images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib1.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib1.11.3" style="font-size:90%;">, pages 18208–18218, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.5.5.1" style="font-size:90%;">Bhat et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">
Shariq Farooq Bhat, Niloy Mitra, and Peter Wonka.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.8.1" style="font-size:90%;">Loosecontrol: Lifting controlnet for generalized depth conditioning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib2.10.2" style="font-size:90%;">ACM SIGGRAPH 2024 Conference Papers</em><span class="ltx_text" id="bib.bib2.11.3" style="font-size:90%;">, pages 1–11, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.5.5.1" style="font-size:90%;">Collins et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.7.1" style="font-size:90%;">
Jasmine Collins, Shubham Goel, Kenan Deng, Achleshwar Luthra, Leon Xu, Erhan Gundogdu, Xi Zhang, Tomas F Yago Vicente, Thomas Dideriksen, Himanshu Arora, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.8.1" style="font-size:90%;">Abo: Dataset and benchmarks for real-world 3d object understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib3.11.3" style="font-size:90%;">, pages 21126–21136, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.5.5.1" style="font-size:90%;">Corneanu et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.7.1" style="font-size:90%;">
Ciprian Corneanu, Raghudeep Gadde, and Aleix M Martinez.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.8.1" style="font-size:90%;">Latentpaint: Image inpainting in latent space with diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib4.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em><span class="ltx_text" id="bib.bib4.11.3" style="font-size:90%;">, pages 4334–4343, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.5.5.1" style="font-size:90%;">Deitke et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">
Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.8.1" style="font-size:90%;">Objaverse: A universe of annotated 3d objects.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib5.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib5.11.3" style="font-size:90%;">, pages 13142–13153, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">Denninger et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
Maximilian Denninger, Dominik Winkelbauer, Martin Sundermeyer, Wout Boerdijk, Markus Knauer, Klaus H. Strobl, Matthias Humt, and Rudolph Triebel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">Blenderproc2: A procedural pipeline for photorealistic rendering.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.9.1" style="font-size:90%;">Journal of Open Source Software</em><span class="ltx_text" id="bib.bib6.10.2" style="font-size:90%;">, 8(82):4901, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.5.5.1" style="font-size:90%;">Downs et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.7.1" style="font-size:90%;">
Laura Downs, Anthony Francis, Nate Koenig, Brandon Kinman, Ryan Hickman, Krista Reymann, Thomas B McHugh, and Vincent Vanhoucke.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.8.1" style="font-size:90%;">Google scanned objects: A high-quality dataset of 3d scanned household items.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.10.2" style="font-size:90%;">2022 International Conference on Robotics and Automation (ICRA)</em><span class="ltx_text" id="bib.bib7.11.3" style="font-size:90%;">, pages 2553–2560. IEEE, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">Esser et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.7.1" style="font-size:90%;">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, and Robin Rombach.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.8.1" style="font-size:90%;">Scaling Rectified Flow Transformers for High-Resolution Image Synthesis.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.9.1" style="font-size:90%;">arXiv</em><span class="ltx_text" id="bib.bib8.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.5.5.1" style="font-size:90%;">Gonzales et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.7.1" style="font-size:90%;">
Mark Edward M. Gonzales, Lorene C. Uy, and Joel P. Ilao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.8.1" style="font-size:90%;">Designing a lightweight edge-guided convolutional neural network for segmenting mirrors and reflective surfaces.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.9.1" style="font-size:90%;">Computer Science Research Notes</em><span class="ltx_text" id="bib.bib9.10.2" style="font-size:90%;">, 3301:107–116, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.4.4.1" style="font-size:90%;">Haven [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.6.1" style="font-size:90%;">
Poly Haven.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.7.1" style="font-size:90%;">Poly haven : The public 3d asset library, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.8.1" style="font-size:90%;">Accessed: 2024-08-10.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">Ho et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.7.1" style="font-size:90%;">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.8.1" style="font-size:90%;">Denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib11.10.2" style="font-size:90%;">, 33:6840–6851, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">Ho et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J Fleet.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">Video diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib12.10.2" style="font-size:90%;">, 35:8633–8646, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.4.4.1" style="font-size:90%;">Hu and Guo [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.6.1" style="font-size:90%;">
Qiming Hu and Xiaojie Guo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">Single image reflection separation via component synergy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.9.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib13.10.3" style="font-size:90%;">, pages 13138–13147, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">Ju et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.7.1" style="font-size:90%;">
Xuan Ju, Xian Liu, Xintao Wang, Yuxuan Bian, Ying Shan, and Qiang Xu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.8.1" style="font-size:90%;">Brushnet: A plug-and-play image inpainting model with decomposed dual-branch diffusion.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.9.1" style="font-size:90%;">arXiv preprint arXiv:2403.06976</em><span class="ltx_text" id="bib.bib14.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">Ke et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.7.1" style="font-size:90%;">
Bingxin Ke, Anton Obukhov, Shengyu Huang, Nando Metzger, Rodrigo Caye Daudt, and Konrad Schindler.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.8.1" style="font-size:90%;">Repurposing diffusion-based image generators for monocular depth estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib15.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib15.11.3" style="font-size:90%;">, pages 9492–9502, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.5.5.1" style="font-size:90%;">Kirillov et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">Segment anything.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib16.11.3" style="font-size:90%;">, pages 4015–4026, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">Koley et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.7.1" style="font-size:90%;">
Subhadeep Koley, Ayan Kumar Bhunia, Deeptanshu Sekhri, Aneeshan Sain, Pinaki Nath Chowdhury, Tao Xiang, and Yi-Zhe Song.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.8.1" style="font-size:90%;">It’s all about your sketch: Democratising sketch control in diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib17.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib17.11.3" style="font-size:90%;">, pages 7204–7214, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.5.5.1" style="font-size:90%;">Kong et al. [2011]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">
Naejin Kong, Yu-Wing Tai, and Sung Yong Shin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.8.1" style="font-size:90%;">High-quality reflection separation using polarized images.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.9.1" style="font-size:90%;">IEEE Transactions on Image Processing</em><span class="ltx_text" id="bib.bib18.10.2" style="font-size:90%;">, 20(12):3393–3405, 2011.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.5.5.1" style="font-size:90%;">Kong et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.8.1" style="font-size:90%;">Diffwave: A versatile diffusion model for audio synthesis.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.9.1" style="font-size:90%;">arXiv preprint arXiv:2009.09761</em><span class="ltx_text" id="bib.bib19.10.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">Lei et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
Chenyang Lei, Xuhua Huang, Mengdi Zhang, Qiong Yan, Wenxiu Sun, and Qifeng Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">Polarized reflection removal with perfect alignment in the wild.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib20.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib20.11.3" style="font-size:90%;">, pages 1750–1758, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.5.5.1" style="font-size:90%;">Levin et al. [2004]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.7.1" style="font-size:90%;">
Anat Levin, Assaf Zomet, and Yair Weiss.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.8.1" style="font-size:90%;">Separating reflections from a single image using local features.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib21.10.2" style="font-size:90%;">Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.</em><span class="ltx_text" id="bib.bib21.11.3" style="font-size:90%;">, pages I–I. IEEE, 2004.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.5.5.1" style="font-size:90%;">Li et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.7.1" style="font-size:90%;">
Rui Li, Simeng Qiu, Guangming Zang, and Wolfgang Heidrich.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.8.1" style="font-size:90%;">Reflection separation via multi-bounce polarization state tracing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.10.2" style="font-size:90%;">Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16</em><span class="ltx_text" id="bib.bib22.11.3" style="font-size:90%;">, pages 781–796. Springer, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.5.5.1" style="font-size:90%;">Li et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.7.1" style="font-size:90%;">
Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang, and Tatsunori B Hashimoto.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.8.1" style="font-size:90%;">Diffusion-lm improves controllable text generation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib23.10.2" style="font-size:90%;">, 35:4328–4343, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">Lin et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
Jiaying Lin, Guodong Wang, and Rynson W.H. Lau.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">Progressive mirror detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib24.10.2" style="font-size:90%;">Proc. CVPR</em><span class="ltx_text" id="bib.bib24.11.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">Lin et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
Jiaying Lin, Zebang He, and Rynson WH Lau.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">Rich context aggregation with reflection prior for glass surface detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib25.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib25.11.3" style="font-size:90%;">, pages 13415–13424, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">Liu et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
Hongyu Liu, Ziyu Wan, Wei Huang, Yibing Song, Xintong Han, and Jing Liao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">Pd-gan: Probabilistic diverse gan for image inpainting.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib26.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib26.11.3" style="font-size:90%;">, pages 9371–9381, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">Liu et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.7.1" style="font-size:90%;">
Jiayue Liu, Xiao Tang, Freeman Cheng, Roy Yang, Zhihao Li, Jianzhuang Liu, Yi Huang, Jiaqi Lin, Shiyong Liu, Xiaofei Wu, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.8.1" style="font-size:90%;">Mirrorgaussian: Reflecting 3d gaussians for reconstructing mirror reflections.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.9.1" style="font-size:90%;">arXiv preprint arXiv:2405.11921</em><span class="ltx_text" id="bib.bib27.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">Lugmayr et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc Van Gool.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">Repaint: Inpainting using denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib28.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib28.11.3" style="font-size:90%;">, pages 11461–11471, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.5.5.1" style="font-size:90%;">Luo et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">
Tiange Luo, Chris Rockwell, Honglak Lee, and Justin Johnson.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.8.1" style="font-size:90%;">Scalable 3d captioning with pretrained models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib29.10.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">Manukyan et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.7.1" style="font-size:90%;">
Hayk Manukyan, Andranik Sargsyan, Barsegh Atanyan, Zhangyang Wang, Shant Navasardyan, and Humphrey Shi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.8.1" style="font-size:90%;">Hd-painter: high-resolution and prompt-faithful text-guided image inpainting with diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.14091</em><span class="ltx_text" id="bib.bib30.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">Mei et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.7.1" style="font-size:90%;">
Haiyang Mei, Xin Yang, Yang Wang, Yuanyuan Liu, Shengfeng He, Qiang Zhang, Xiaopeng Wei, and Rynson WH Lau.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.8.1" style="font-size:90%;">Don’t hit me! glass detection in real-world scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib31.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib31.11.3" style="font-size:90%;">, pages 3687–3696, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">Mei et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.7.1" style="font-size:90%;">
Haiyang Mei, Bo Dong, Wen Dong, Pieter Peers, Xin Yang, Qiang Zhang, and Xiaopeng Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.8.1" style="font-size:90%;">Depth-aware mirror segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib32.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib32.11.3" style="font-size:90%;">, pages 3044–3053, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.5.5.1" style="font-size:90%;">Meng et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.7.1" style="font-size:90%;">
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.8.1" style="font-size:90%;">Sdedit: Guided image synthesis and editing with stochastic differential equations.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.9.1" style="font-size:90%;">arXiv preprint arXiv:2108.01073</em><span class="ltx_text" id="bib.bib33.10.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.5.5.1" style="font-size:90%;">Meng et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.7.1" style="font-size:90%;">
Jiarui Meng, Haijie Li, Yanmin Wu, Qiankun Gao, Shuzhou Yang, Jian Zhang, and Siwei Ma.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.8.1" style="font-size:90%;">Mirror-3dgs: Incorporating mirror reflections into 3d gaussian splatting.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.9.1" style="font-size:90%;">arXiv preprint arXiv:2404.01168</em><span class="ltx_text" id="bib.bib34.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.5.5.1" style="font-size:90%;">Michel et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">
Oscar Michel, Anand Bhattad, Eli VanderBilt, Ranjay Krishna, Aniruddha Kembhavi, and Tanmay Gupta.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.8.1" style="font-size:90%;">Object 3dit: Language-guided 3d-aware image editing.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib35.10.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.5.5.1" style="font-size:90%;">Nichol et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.7.1" style="font-size:90%;">
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.8.1" style="font-size:90%;">Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.9.1" style="font-size:90%;">arXiv preprint arXiv:2112.10741</em><span class="ltx_text" id="bib.bib36.10.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.5.5.1" style="font-size:90%;">Pandey et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.7.1" style="font-size:90%;">
Karran Pandey, Paul Guerrero, Matheus Gadelha, Yannick Hold-Geoffroy, Karan Singh, and Niloy J Mitra.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.8.1" style="font-size:90%;">Diffusion handles enabling 3d edits for diffusion models by lifting activations to 3d.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib37.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib37.11.3" style="font-size:90%;">, pages 7695–7704, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.5.5.1" style="font-size:90%;">Podell et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.7.1" style="font-size:90%;">
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, and Robin Rombach.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.8.1" style="font-size:90%;">Sdxl: Improving latent diffusion models for high-resolution image synthesis.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.9.1" style="font-size:90%;">arXiv preprint arXiv:2307.01952</em><span class="ltx_text" id="bib.bib38.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.5.5.1" style="font-size:90%;">Radford et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.7.1" style="font-size:90%;">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.8.1" style="font-size:90%;">Learning transferable visual models from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib39.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib39.11.3" style="font-size:90%;">, pages 8748–8763. PMLR, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.5.5.1" style="font-size:90%;">Ramesh et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.7.1" style="font-size:90%;">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.8.1" style="font-size:90%;">Hierarchical text-conditional image generation with clip latents.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.9.1" style="font-size:90%;">arXiv preprint arXiv:2204.06125</em><span class="ltx_text" id="bib.bib40.10.2" style="font-size:90%;">, 1(2):3, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.5.5.1" style="font-size:90%;">Rombach et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.7.1" style="font-size:90%;">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.8.1" style="font-size:90%;">High-resolution image synthesis with latent diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib41.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib41.11.3" style="font-size:90%;">, pages 10684–10695, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.5.5.1" style="font-size:90%;">Saharia et al. [2022a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.7.1" style="font-size:90%;">
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.8.1" style="font-size:90%;">Palette: Image-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib42.10.2" style="font-size:90%;">ACM SIGGRAPH 2022 conference proceedings</em><span class="ltx_text" id="bib.bib42.11.3" style="font-size:90%;">, pages 1–10, 2022a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.5.5.1" style="font-size:90%;">Saharia et al. [2022b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.7.1" style="font-size:90%;">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.8.1" style="font-size:90%;">Photorealistic text-to-image diffusion models with deep language understanding.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib43.10.2" style="font-size:90%;">, 35:36479–36494, 2022b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.5.5.1" style="font-size:90%;">Sarkar et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.7.1" style="font-size:90%;">
Ayush Sarkar, Hanlin Mai, Amitabh Mahapatra, Svetlana Lazebnik, David A Forsyth, and Anand Bhattad.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.8.1" style="font-size:90%;">Shadows don’t lie and lines can’t bend! generative models don’t know projective geometry… for now.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.9.1" style="font-size:90%;">arXiv preprint arXiv:2311.17138</em><span class="ltx_text" id="bib.bib44.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.5.5.1" style="font-size:90%;">Singer et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.7.1" style="font-size:90%;">
Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.8.1" style="font-size:90%;">Make-a-video: Text-to-video generation without text-video data.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.9.1" style="font-size:90%;">arXiv preprint arXiv:2209.14792</em><span class="ltx_text" id="bib.bib45.10.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.5.5.1" style="font-size:90%;">Sohl-Dickstein et al. [2015]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.7.1" style="font-size:90%;">
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.8.1" style="font-size:90%;">Deep unsupervised learning using nonequilibrium thermodynamics.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib46.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib46.11.3" style="font-size:90%;">, pages 2256–2265. PMLR, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.5.5.1" style="font-size:90%;">Sun et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.7.1" style="font-size:90%;">
Tianyu Sun, Guodong Zhang, Wenming Yang, Jing-Hao Xue, and Guijin Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.8.1" style="font-size:90%;">Trosd: A new rgb-d dataset for transparent and reflective object segmentation in practice.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.9.1" style="font-size:90%;">IEEE Transactions on Circuits and Systems for Video Technology</em><span class="ltx_text" id="bib.bib47.10.2" style="font-size:90%;">, 33(10):5721–5733, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.5.5.1" style="font-size:90%;">Tan et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.7.1" style="font-size:90%;">
Jiaqi Tan, Weijie Lin, Angel X Chang, and Manolis Savva.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.8.1" style="font-size:90%;">Mirror3D: Depth refinement for mirror surfaces.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib48.10.2" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em><span class="ltx_text" id="bib.bib48.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.5.5.1" style="font-size:90%;">Tyszkiewicz et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.7.1" style="font-size:90%;">
Michał J Tyszkiewicz, Pascal Fua, and Eduard Trulls.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.8.1" style="font-size:90%;">Gecco: Geometrically-conditioned point diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib49.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib49.11.3" style="font-size:90%;">, pages 2128–2138, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib50.5.5.1" style="font-size:90%;">Upadhyay et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.7.1" style="font-size:90%;">
Rishi Upadhyay, Howard Zhang, Yunhao Ba, Ethan Yang, Blake Gella, Sicheng Jiang, Alex Wong, and Achuta Kadambi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.8.1" style="font-size:90%;">Enhancing diffusion models with 3d perspective geometry constraints.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.9.1" style="font-size:90%;">ACM Transactions on Graphics (TOG)</em><span class="ltx_text" id="bib.bib50.10.2" style="font-size:90%;">, 42(6):1–15, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib51.5.5.1" style="font-size:90%;">Wang et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.7.1" style="font-size:90%;">
Tao Wang, Wanglong Lu, Kaihao Zhang, Wenhan Luo, Tae-Kyun Kim, Tong Lu, Hongdong Li, and Ming-Hsuan Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.8.1" style="font-size:90%;">Promptrr: Diffusion models as prompt generators for single image reflection removal.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.9.1" style="font-size:90%;">arXiv preprint arXiv:2402.02374</em><span class="ltx_text" id="bib.bib51.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib52.5.5.1" style="font-size:90%;">Wei et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.7.1" style="font-size:90%;">
Kaixuan Wei, Jiaolong Yang, Ying Fu, David Wipf, and Hua Huang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.8.1" style="font-size:90%;">Single image reflection removal exploiting misaligned training data and network enhancements.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib52.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib52.11.3" style="font-size:90%;">, pages 8178–8187, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib53.5.5.1" style="font-size:90%;">Winter et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.7.1" style="font-size:90%;">
Daniel Winter, Matan Cohen, Shlomi Fruchter, Yael Pritch, Alex Rav-Acha, and Yedid Hoshen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.8.1" style="font-size:90%;">Objectdrop: Bootstrapping counterfactuals for photorealistic object removal and insertion.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.9.1" style="font-size:90%;">arXiv preprint arXiv:2403.18818</em><span class="ltx_text" id="bib.bib53.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib54.5.5.1" style="font-size:90%;">Yang et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.7.1" style="font-size:90%;">
Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, and Hengshuang Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.8.1" style="font-size:90%;">Depth anything v2.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.9.1" style="font-size:90%;">arXiv preprint arXiv:2406.09414</em><span class="ltx_text" id="bib.bib54.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib55.5.5.1" style="font-size:90%;">Yang et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.7.1" style="font-size:90%;">
Xin Yang, Haiyang Mei, Ke Xu, Xiaopeng Wei, Baocai Yin, and Rynson W.H. Lau.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.8.1" style="font-size:90%;">Where is my mirror?
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib55.10.2" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</em><span class="ltx_text" id="bib.bib55.11.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib56.5.5.1" style="font-size:90%;">Ye et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.7.1" style="font-size:90%;">
Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.8.1" style="font-size:90%;">Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.9.1" style="font-size:90%;">arXiv preprint arxiv:2308.06721</em><span class="ltx_text" id="bib.bib56.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib57.5.5.1" style="font-size:90%;">Zeng et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.7.1" style="font-size:90%;">
Junyi Zeng, Chong Bao, Rui Chen, Zilong Dong, Guofeng Zhang, Hujun Bao, and Zhaopeng Cui.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.8.1" style="font-size:90%;">Mirror-nerf: Learning neural radiance fields for mirrors with whitted-style ray tracing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib57.10.2" style="font-size:90%;">Proceedings of the 31st ACM International Conference on Multimedia</em><span class="ltx_text" id="bib.bib57.11.3" style="font-size:90%;">, pages 4606–4615, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib58.5.5.1" style="font-size:90%;">Zhang et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.7.1" style="font-size:90%;">
Guanhua Zhang, Jiabao Ji, Yang Zhang, Mo Yu, T. Jaakkola, and Shiyu Chang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.8.1" style="font-size:90%;">Towards coherent image inpainting using denoising diffusion implicit models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib58.10.2" style="font-size:90%;">International Conference on Machine Learning</em><span class="ltx_text" id="bib.bib58.11.3" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib59.5.5.1" style="font-size:90%;">Zhang et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.7.1" style="font-size:90%;">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.8.1" style="font-size:90%;">Adding conditional control to text-to-image diffusion models, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib60.5.5.1" style="font-size:90%;">Zhang et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.7.1" style="font-size:90%;">
Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.8.1" style="font-size:90%;">The unreasonable effectiveness of deep features as a perceptual metric.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib60.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib60.11.3" style="font-size:90%;">, pages 586–595, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib61.5.5.1" style="font-size:90%;">Zhao et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.7.1" style="font-size:90%;">
Shihao Zhao, Dongdong Chen, Yen-Chun Chen, Jianmin Bao, Shaozhe Hao, Lu Yuan, and Kwan-Yee K Wong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.8.1" style="font-size:90%;">Uni-controlnet: All-in-one control to text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib61.10.2" style="font-size:90%;">, 36, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib62.5.5.1" style="font-size:90%;">Zhao et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.7.1" style="font-size:90%;">
Wenliang Zhao, Lujia Bai, Yongming Rao, Jie Zhou, and Jiwen Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.8.1" style="font-size:90%;">Unipc: A unified predictor-corrector framework for fast sampling of diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib62.10.2" style="font-size:90%;">, 36, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib63.5.5.1" style="font-size:90%;">Zheng et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.7.1" style="font-size:90%;">
Haitian Zheng, Zhe Lin, Jingwan Lu, Scott Cohen, Eli Shechtman, Connelly Barnes, Jianming Zhang, Ning Xu, Sohrab Amirghodsi, and Jiebo Luo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.8.1" style="font-size:90%;">Image inpainting with cascaded modulation gan and object-aware training.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib63.10.2" style="font-size:90%;">European Conference on Computer Vision</em><span class="ltx_text" id="bib.bib63.11.3" style="font-size:90%;">, pages 277–296. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib64.5.5.1" style="font-size:90%;">Zhuang et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.7.1" style="font-size:90%;">
Junhao Zhuang, Yanhong Zeng, Wenran Liu, Chun Yuan, and Kai Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.8.1" style="font-size:90%;">A task is worth one word: Learning with task prompts for high-quality versatile image inpainting.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.03594</em><span class="ltx_text" id="bib.bib64.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep 23 02:56:12 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
