<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems</title>
<!--Generated on Sun Oct  6 11:11:51 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.04452v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S1" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S2" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S2.SS1" title="In 2 Related Work ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Cognitive biases in LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S2.SS2" title="In 2 Related Work ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>LLM-based Multi-Agent System</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S3" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Problem Definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S4" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Dataset Construction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S4.SS1" title="In 4 Dataset Construction ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Static dataset construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S4.SS2" title="In 4 Dataset Construction ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Dynamic dataset construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S4.SS3" title="In 4 Dataset Construction ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Validation of the validity of assessment tools</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS1" title="In 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>The foundational architecture of RuleGen</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS2" title="In 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Rule-Based Multi-Agent Communication</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS2.SSS1" title="In 5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Automated rule-based scenario construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS2.SSS2" title="In 5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Multi-Dimensional Agent Behavior Monitoring</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS3" title="In 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Detecting Cognitive Bias Without Labels</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS3.SSS1" title="In 5.3 Detecting Cognitive Bias Without Labels ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>Cognitive Bias Recognition and Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS3.SSS2" title="In 5.3 Detecting Cognitive Bias Without Labels ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>Debate competition based on loser trees</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS3.SSS3" title="In 5.3 Detecting Cognitive Bias Without Labels ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.3 </span>Decision module based on reinforcement learning</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS1" title="In 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Proficiency testing of GPT-4 as an evaluator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS2" title="In 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Cognitive bias in different LLMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS2.SSS1" title="In 6.2 Cognitive bias in different LLMs ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.1 </span>Cognitive bias detection in static dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS2.SSS2" title="In 6.2 Cognitive bias in different LLMs ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.2 </span>Cognitive bias detection in dynamic datasets</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS3" title="In 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>The effectiveness of the detection framework</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS3.SSS1" title="In 6.3 The effectiveness of the detection framework ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.1 </span>evaluation metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS3.SSS2" title="In 6.3 The effectiveness of the detection framework ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.2 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS3.SSS3" title="In 6.3 The effectiveness of the detection framework ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.3 </span>Ablation Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.SS4" title="In 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Case study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S7" title="In MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhentao¬†Xie
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiabao¬†Zhao
</span><span class="ltx_author_notes">Corresponding Author, Email: jbzhao@mail.ecnu.edu.cn</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yilei¬†Wang
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinxin¬†Shi
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanhong¬†Bai
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xingjiao¬†Wu
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liang¬†He
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">School of Computer Science and Technology, East China Normal University
</span>
<span class="ltx_contact ltx_role_address">School of Computer Science, Fudan University
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Detecting cognitive biases in large language models (LLMs) is a fascinating task that aims to probe the existing cognitive biases within these models. Current methods for detecting cognitive biases in language models generally suffer from incomplete detection capabilities and a restricted range of detectable bias types. To address this issue, we introduced the ‚ÄôMindScope‚Äô dataset, which distinctively integrates static and dynamic elements. The static component comprises 5,170 open-ended questions spanning 72 cognitive bias categories. The dynamic component leverages a rule-based, multi-agent communication framework to facilitate the generation of multi-round dialogues. This framework is flexible and readily adaptable for various psychological experiments involving LLMs. In addition, we introduce a multi-agent detection method applicable to a wide range of detection tasks, which integrates Retrieval-Augmented Generation (RAG), competitive debate, and a reinforcement learning-based decision module. Demonstrating substantial effectiveness, this method has shown to improve detection accuracy by as much as 35.10% compared to GPT-4. Codes and appendix are available at https://github.com/2279072142/MindScope.</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\paperid</span>
<p class="ltx_p" id="p1.2">123</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent studies have uncovered a gradual emergence of human-like cognitive biases within LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib14" title="">14</a>]</cite>. Cognitive biases represent systematic errors in processing information and decision-making <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib10" title="">10</a>]</cite>, which introduce unforeseeable risks in LLM-based applications. In the financial field, cognitive biases might manifest as an overemphasis on specific market trends or an inability to adequately reflect risks, leading to suboptimal investment decisions. In the medical field, LLMs can collaboratively diagnose diseases and predict patient outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib25" title="">25</a>]</cite>. However, some cognitive biases such as the anchoring effect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib34" title="">34</a>]</cite> and overconfidence <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib19" title="">19</a>]</cite> may lead to inaccurate medical advice or diagnosis. Hence, it is urgent and imperative to establish a robust mechanism for detecting cognitive biases, encompassing the development of comprehensive datasets that can effectively identify cognitive biases in LLMS, as well as reliable methods for detection and evaluation. There are three challenges: (1) It is difficult to construct comprehensive and standardized datasets with large-scale samples. (2) High annotation cost for detection. (3) With more cognitive bias types and scenarios involved, the detection accuracy may decrease.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Prior studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib29" title="">29</a>]</cite> have explored cognitive biases in LLMs, while the type of cognitive biases is limited or the data is small-scale. Hence, we collected 72 decision-related cognitive biases from Wikipedia and proposed a human-machine collaborative method for constructing static and dynamic datasets. It provides both single and multi-turn dialogues, effectively capturing the nuances of cognitive biases in LLMs. And it can be well extended to other emerging cognitive biases. The static dataset includes open-ended questions, whereas the dynamic dataset is enriched with scenario-based scripts including tasks, goals, roles, and rules. And we use a multi-agent system based on LLMs to
generate the large-scale multi-turn dialogues based on scripts. It can improve the control and variability in experimental settings.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">However, when constructing dynamic datasets by Camel <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib20" title="">20</a>]</cite> and AutoGen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib38" title="">38</a>]</cite>, they fall short in controllably generating multi-turn dialogues based on our scripts. To improve the flexibility, interactive diversity and controllability of multi-agent system, we proposed RuleGen, a rule-based multi-agent communication framework. It is used for generating multi-turn dialogues involving multi-role interactions based on our scripts. RuleGen also allows users to generate personalized and large-scale test samples based on their scripts. Specifically, we extract elements from scripts through a rule interpreter, enabling flexible scenario construction. To control the role behavior, we introduced system agents to supervise and correct agent behaviors, ensuring their actions are in line with scenario tasks and goals.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib4" title="">4</a>]</cite> shows that LLMs are better than humans at annotating whether there is cognitive bias in text, but the LLMs need to know the kind of bias it is annotating. However, if LLMs do not know the type,
the annotation accuracy may decrease. Hence, we proposed a multi-agent detection method. In detail, rough detection agents identify potential cognitive biases to construct a candidate set.
To mitigate the hallucinations caused by LLMs, we incorporate the RAG technique. This technique initializes a competitive detection agent by retrieving knowledge related to bias detection and optimizes its competitive debate structure using a loser‚Äôs tree algorithm.
Furthermore, we introduced a referee agent tasked with evaluating the outcomes of the debates. Lastly, a decision module based on reinforcement learning was employed to determine the winning side of each debate.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In summary, our contributions are as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We constructed a dataset for cognitive biases detection, comprising both static and dynamic components. We test 12 LLMs and offer a detailed analysis.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">A rule-based multi-agent communication framework is proposed for dynamic dataset construction, providing an effective tool for researchers to conduct normative psychological experiments.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We propose a multi-agent detection method, incorporating RAG, competitive debate, and a reinforcement learning decision module. Without knowing the type of bias, our method performed 35.1% better on the cognitive bias detection task than GPT-4.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Cognitive biases in LLMs</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">There has been a trend in utilizing LLMs to accomplish various tasks in specific domains, such as BloombergGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib39" title="">39</a>]</cite> and Med-PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib31" title="">31</a>]</cite>. However, just as humans exhibit systematic errors, known as cognitive biases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib5" title="">5</a>]</cite>, in information processing and decision-making, LLMs also display similar biases in their decision processes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib4" title="">4</a>]</cite>. Current research of cognitive biases in LLMs primarily focuses on three areas: detecting biases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib23" title="">23</a>]</cite>, mitigating biases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib12" title="">12</a>]</cite>, and utilizing them for social experiments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib30" title="">30</a>]</cite>. Study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib14" title="">14</a>]</cite> has revealed previously unobserved cognitive biases in fine-tuned models. In terms of bias mitigation, researchers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib12" title="">12</a>]</cite> have successfully reduced known biases by explicitly alerting the models to their potential cognitive biases. For social experiments, researchers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib30" title="">30</a>]</cite> have created emails with embedded cognitive biases to compare against manually crafted scam emails. Despite these efforts, existing research is often limited by overly simplistic testing methods or a narrow scope of biases. To overcome these limitations, we introduce the MindScope dataset, designed to systematically and comprehensively assess cognitive biases in LLMs.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="420" id="S2.F1.g1" src="x1.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the Construction of the MindScope Dataset.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>LLM-based Multi-Agent System</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Multi-agent systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib15" title="">15</a>]</cite> enhance capabilities by specializing LLMs into distinct agents with unique skills, enabling them to interact dynamically and simulate complex environments effectively.
Current research is mainly divided into problem solving and world simulation. In terms of problem-solving, this involves software development <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib28" title="">28</a>]</cite>, embodied agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib41" title="">41</a>]</cite>, scientific experiments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib44" title="">44</a>]</cite>, and scientific debate <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib11" title="">11</a>]</cite>. For example, multi-agent collaboration in software development <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib13" title="">13</a>]</cite> significantly reduces costs, while in embodied agents, agents perform complex real-world planning tasks to address physical challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib41" title="">41</a>]</cite>. World simulation has made rapid progress in fields such as social simulation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib27" title="">27</a>]</cite>, gaming <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib35" title="">35</a>]</cite>, psychology <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib2" title="">2</a>]</cite>, and economics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib21" title="">21</a>]</cite>. For instance,
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib27" title="">27</a>]</cite> established a town simulation system consisting of 25 agents to study social interactions, while <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib2" title="">2</a>]</cite> explored how agents can acquire and develop social skills such as shared attention and cultural learning through psychological principles. In economics, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib21" title="">21</a>]</cite> introduced an LLM-based multi-agent method for financial transactions, which enhances decision robustness through personalized transaction roles. However, when these systems are directly applied to cognitive bias detection, they encounter significant challenges such as difficulty in detecting unlabeled biases, lack of comprehensive consideration, and poor interpretability. To overcome these limitations, we propose a new detection method that integrates RAG, competitive debate, and reinforcement learning decision modules.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Definition</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This work aims to detect both explicit and implicit cognitive biases in LLMs by single-round or multi-round scene-based dialogues. In addition to detecting existing categories, users can also expand the evaluation scope according to their own needs and do more standard cognitive bias experiments. We designed two tasks: labeled cognitive bias detection and unlabeled cognitive bias detection. The labeled cognitive bias detection task aims to detect biases by explicitly providing the types of cognitive biases and evaluation criteria. Unlabeled cognitive bias detection does not provide specific kinds of cognitive biases. During the detection process, candidates need to be selected from various possible biases based on the current scene and undergo more detailed scrutiny. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S4.SS1" title="4.1 Static dataset construction ‚Ä£ 4 Dataset Construction ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">4.1</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S4.SS2" title="4.2 Dynamic dataset construction ‚Ä£ 4 Dataset Construction ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we employed the labeled cognitive bias detection method to provide comprehensive detection results quickly. In addition, our proposed detection method in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS3" title="5.3 Detecting Cognitive Bias Without Labels ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">5.3</span></a> aims to address unlabeled cognitive bias detection task, which is more suitable for real-world situations.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Dataset Construction</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In addressing cognitive biases in decision-making, we construct the MindScope dataset, which includes both static and dynamic scenarios. The static portion comprises 5170 open-ended questions addressing 72 different cognitive biases, while the dynamic portion includes scripts for multi-round dialogues in over 100 scenarios. Additionally, users can use these scripts to generate tailored and large-scale datasets automatically. With the combination of static and dynamic scenarios, we can more precisely and comprehensively identify and quantify cognitive biases. During the construction, each scenario was designed to contain only one cognitive bias.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Static dataset construction</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Since we mainly explore cognitive biases related to decision-making, we selected 72 cognitive biases from the list of decision-making cognitive biases in Wikipedia‚Äôs repository for in-depth analysis (see Appendix A, Tables 2-4). Initially, we extracted classic examples of cognitive biases from literature and Wikipedia to ensure the authenticity and accuracy. With the assistance of cognitive science experts, we employed GPT-4 to create corresponding scenario texts based on these examples. Guided by these scene generation texts (see Appendix A, Table 5), we prompted GPT-4 to generate diverse open-ended questions and assessment criteria. Subsequently, cognitive science experts conducted a thorough validity review of the generated scenarios, focusing on the appropriateness of the test questions, the accuracy of the assessment criteria, and the unbiased nature of the scenarios. Notably, we employed three cognitive science experts and they underwent standard training for the consistency of annotation.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Dynamic dataset construction</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">While static datasets have played a role in revealing cognitive biases of LLMs, they exhibit limitations in capturing complex biases that require multiple interactions to manifest, such as order biases and planning fallacies. These dynamic biases rely on continuous decision-making processes, which are difficult to fully capture in a single response. Hence, we developed a dynamic dataset capable of simulating and capturing cognitive biases within ongoing interactions. It comprises multi-role scenario scripts, encompassing background settings, characters, tasks, and the logic of interactions between characters. Users can modify these scripts to generate personalized data. There are three distinct roles in the scripts: the Subject, the Confederate, and the Moderator. The Subject is the focal point for cognitive biases detection, the Confederate is to induce the Subject to display the targeted biases, while the Moderator neutrally responds to the Subject‚Äôs queries and poses impartial questions. Due to constraints in time and cost, psychology experts guided us in selecting 10 cognitive biases suitable for multi-turn dialogue tests. Then psychology experts authored scenario generation texts, including details and output formats; these were further processed by GPT-4 to generate complete dialogue scripts covering scenario purposes, backgrounds, characters, rules, and evaluation methods. For specific scenario rules, refer to <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS2" title="5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">5.2</span></a>; finally, psychology professionals volunteered to fine-tune each GPT-4 generated dialogue script to ensure it aligns with experimental requirements. The reasons for the scripting and the experimental setup are detailed in Appendix B.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Validation of the validity of assessment tools</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We employed volunteers to do the validity review for MindScope, focusing on the appropriateness of samples, the accuracy of assessment criteria, and unbiased nature of the scenarios themselves. Moreover, we explored the correlation between human experts and GPT-4 in the assessment of cognitive biases. The Kappa coefficient reached 0.7167 and the accuracy is 88.08%. This result affirms the efficacy of LLMs as assessment tools. More details are in Appendix C.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Method</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The existing multi-agent frameworks based on LLMs cannot meet the controllability requirement for cognitive biases detection, and they are inflexible to construct dynamic multi-round dialogues. Hence, we propose a rule-based multi-agent communication framework (RuleGen), which allows agents to interact in an orderly and controllable manner. Moreover, to detect unlabeled biases in open environments, we propose a learnable bias detection method based on multi-agent framework. In detail, Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS1" title="5.1 The foundational architecture of RuleGen ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">5.1</span></a> explains the foundational architecture of RuleGen; Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS2" title="5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">5.2</span></a> introduces the rules and steps for automatically building scenarios and how to supervise and correct agent behaviors; Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.SS3" title="5.3 Detecting Cognitive Bias Without Labels ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">5.3</span></a> describes the bias detection method involving cognitive bias identification, debate competition module, and the learnable decision module.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>The foundational architecture of RuleGen</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">RuleGen is proposed for simulating the multi-round dialogue in real-world scenarios according to the given script. It needs to control the fine behaviors of agents based on the rules of the current detection task. Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib27" title="">27</a>]</cite>, the role agents in RuleGen are composed of memory, planning, reflection, action, and agent configuration modules (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F2" title="Figure 2 ‚Ä£ 5.1 The foundational architecture of RuleGen ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">Memory module</span>: Short-term memory stores the recent k-round dialogues. When it reaches the threshold, it will be summarized and stored in the long-term memory. The agent will retrieve the necessary memory as required.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">Planning module</span>: To ensure that the intelligent agent can generate effective responses, we follow the <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib36" title="">36</a>]</cite> settings, requiring the agent to decompose the request in the plan chain before responding.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p4.1.1">Reflection module</span>: Agents evaluate their behaviors, identify potential problems, and propose corresponding solution strategies. It aims at learning from historical experiences.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p5.1.1">Action module</span>: Based on the provided interaction rules, along with the memory, reflection, and planning modules, it makes specific and appropriate responses.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="S5.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S5.F2.2.1">RuleGen</span> is a rule-based, multi-dimensional behavior monitoring multi-agent communication framework that enables users to automate scenario construction through no-code operations. It offers researchers an efficient tool for studying large-scale model scenario simulations.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p6.1.1">Agent configuration</span>: As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F2" title="Figure 2 ‚Ä£ 5.1 The foundational architecture of RuleGen ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">2</span></a>, we have established two distinct types of agents: role agents and system agents. In order to adapt to different scenarios and show personalized differences, RuleGen guides and constrains the action space of the role agents by setting the names, identities, tasks, and background stories. In addition to role agents, we also need system agents to allocate script resources, and supervise and correct the behaviors of role agents.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Rule-Based Multi-Agent Communication</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">In order to solve the problem of poor flexibility, controllability and limited interaction mode, we propose a novel rule-based multi-agent communication mechanism, that focuses on automatic scenario construction and multi-dimensional agent behavior monitoring.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Automated rule-based scenario construction</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F2" title="Figure 2 ‚Ä£ 5.1 The foundational architecture of RuleGen ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">2</span></a>, this part is divided into two key components: rule generation and rule interpreter, aiming at constructing various scenarios precisely according to the preset rules alone, without modifying the agent‚Äôs prompt and related codes.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p2">
<p class="ltx_p" id="S5.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p2.1.1">Scenario rule generation</span>: Scenario rules consist of five key attributes: initiated role, received role, mode of transmission, interaction purpose, and interaction content. The initiating object and receiving object both refer to the role of agents in the scenario. The propagation mode covers four types of information dissemination: unicast (one-to-one), broadcast (one-to-all), multicast (one-to-many), and self-receival (receiving information from the system). The interaction purpose is built according to the nine basic communication objectives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib6" title="">6</a>]</cite> and the received system information. The interaction content describes the tasks that the current role agent needs to perform.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p3">
<p class="ltx_p" id="S5.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p3.1.1">Rule Interpreter</span>:
The rule interpreter module functions as the semantic parser for the scenario rules, orchestrating the flow of responses from the initiator to the recipient aligned with the chosen transmission mode, thereby ensuring the transmission‚Äôs precision and efficacy. Concretely, the module processes a rule by pinpointing the initiator and recipient, assimilating the interaction purpose and content into a structured request to the initiator, and facilitating the appropriate dissemination of the initiator‚Äôs response to the recipient as per the prescribed transmission mode.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Multi-Dimensional Agent Behavior Monitoring</h4>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p" id="S5.SS2.SSS2.p1.1">To address the problem of unpredictable and uncontrollable agent behavior, the RuleGen framework institutes a hierarchical behavior regulation mechanism through system agents to manage and rectify agent actions within the simulation.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p2">
<p class="ltx_p" id="S5.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p2.1.1">Macro Behavior Monitoring</span>: At the macro scale, system agents govern the overarching actions of role agents relative to the scenario‚Äôs objectives. Deviations from the established scenario blueprint are promptly adjusted by the system agent to realign participant actions with scenario specifications.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p3">
<p class="ltx_p" id="S5.SS2.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p3.1.1">Micro Behavior Monitoring</span>: As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F2" title="Figure 2 ‚Ä£ 5.1 The foundational architecture of RuleGen ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">2</span></a>, micro-level behavior monitoring involves system agents conducting meticulous monitoring of role agents‚Äô interactions. These system agents evaluate responses against predefined interaction objectives and content. Employing Zero-Shot CoT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib36" title="">36</a>]</cite> methodologies, the system agent assesses the appropriateness of a participant agent‚Äôs actions at each timestep <math alttext="t" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p3.1.m1.1"><semantics id="S5.SS2.SSS2.p3.1.m1.1a"><mi id="S5.SS2.SSS2.p3.1.m1.1.1" xref="S5.SS2.SSS2.p3.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p3.1.m1.1b"><ci id="S5.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p3.1.m1.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p3.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p3.1.m1.1d">italic_t</annotation></semantics></math>, and guides corrective measures in the event of deviations. This process includes issuing a rectification directive when a role agent‚Äôs behavior diverges from the script or interaction goals. The role agent then adjusts its actions to ensure adherence to designated interaction protocols. Conversely, adherence to expected behavior is confirmed through a verification instruction.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="365" id="S5.F3.g1" src="x3.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S5.F3.2.1">Overview of learnable multi-agent detection method based on RAG, competitive debate and decision module.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Detecting Cognitive Bias Without Labels</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Existing models performed well when they were told what type of bias to detect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib4" title="">4</a>]</cite>. However, cognitive bias detection without the type label is more difficult. This paper focuses on a deeper exploration of unlabeled cognitive bias detection, which is more in line with actual application. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F3" title="Figure 3 ‚Ä£ 5.2.2 Multi-Dimensional Agent Behavior Monitoring ‚Ä£ 5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">3</span></a>, a cognitive bias detection method (CBDC) is proposed to solve the challenges of detecting potential cognitive bias and improving interpretability.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Cognitive Bias Recognition and Detection</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p" id="S5.SS3.SSS1.p1.2">In order to enhance the recognition and understanding capabilities of agents for recognizing cognitive biases, we constructed an external knowledge vector library <math alttext="K" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p1.1.m1.1"><semantics id="S5.SS3.SSS1.p1.1.m1.1a"><mi id="S5.SS3.SSS1.p1.1.m1.1.1" xref="S5.SS3.SSS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p1.1.m1.1b"><ci id="S5.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS1.p1.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p1.1.m1.1d">italic_K</annotation></semantics></math>, which consists of detailed descriptions of 72 cognitive biases. This library stores detailed information about various cognitive biases. During the initialization of each competitive detection agent, we will retrieve the information on the corresponding biases from <math alttext="K" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p1.2.m2.1"><semantics id="S5.SS3.SSS1.p1.2.m2.1a"><mi id="S5.SS3.SSS1.p1.2.m2.1.1" xref="S5.SS3.SSS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p1.2.m2.1b"><ci id="S5.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS1.p1.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p1.2.m2.1d">italic_K</annotation></semantics></math> and pass this information to the corresponding agent, enabling them to gain a deeper understanding.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p2">
<p class="ltx_p" id="S5.SS3.SSS1.p2.14">As the details shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F3" title="Figure 3 ‚Ä£ 5.2.2 Multi-Dimensional Agent Behavior Monitoring ‚Ä£ 5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">3</span></a>, firstly, we screen the test text <math alttext="T" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.1.m1.1"><semantics id="S5.SS3.SSS1.p2.1.m1.1a"><mi id="S5.SS3.SSS1.p2.1.m1.1.1" xref="S5.SS3.SSS1.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.1.m1.1b"><ci id="S5.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS1.p2.1.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.1.m1.1d">italic_T</annotation></semantics></math> through two agents with different personalities: Aggressive <math alttext="A_{r}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.2.m2.1"><semantics id="S5.SS3.SSS1.p2.2.m2.1a"><msub id="S5.SS3.SSS1.p2.2.m2.1.1" xref="S5.SS3.SSS1.p2.2.m2.1.1.cmml"><mi id="S5.SS3.SSS1.p2.2.m2.1.1.2" xref="S5.SS3.SSS1.p2.2.m2.1.1.2.cmml">A</mi><mi id="S5.SS3.SSS1.p2.2.m2.1.1.3" xref="S5.SS3.SSS1.p2.2.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.2.m2.1b"><apply id="S5.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S5.SS3.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.2.m2.1.1.1.cmml" xref="S5.SS3.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.2.m2.1.1.2.cmml" xref="S5.SS3.SSS1.p2.2.m2.1.1.2">ùê¥</ci><ci id="S5.SS3.SSS1.p2.2.m2.1.1.3.cmml" xref="S5.SS3.SSS1.p2.2.m2.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.2.m2.1c">A_{r}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.2.m2.1d">italic_A start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and Conservative <math alttext="A_{c}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.3.m3.1"><semantics id="S5.SS3.SSS1.p2.3.m3.1a"><msub id="S5.SS3.SSS1.p2.3.m3.1.1" xref="S5.SS3.SSS1.p2.3.m3.1.1.cmml"><mi id="S5.SS3.SSS1.p2.3.m3.1.1.2" xref="S5.SS3.SSS1.p2.3.m3.1.1.2.cmml">A</mi><mi id="S5.SS3.SSS1.p2.3.m3.1.1.3" xref="S5.SS3.SSS1.p2.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.3.m3.1b"><apply id="S5.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S5.SS3.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.3.m3.1.1.1.cmml" xref="S5.SS3.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.3.m3.1.1.2.cmml" xref="S5.SS3.SSS1.p2.3.m3.1.1.2">ùê¥</ci><ci id="S5.SS3.SSS1.p2.3.m3.1.1.3.cmml" xref="S5.SS3.SSS1.p2.3.m3.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.3.m3.1c">A_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.3.m3.1d">italic_A start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, and obtain cognitive bias sets <math alttext="B_{r}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.4.m4.1"><semantics id="S5.SS3.SSS1.p2.4.m4.1a"><msub id="S5.SS3.SSS1.p2.4.m4.1.1" xref="S5.SS3.SSS1.p2.4.m4.1.1.cmml"><mi id="S5.SS3.SSS1.p2.4.m4.1.1.2" xref="S5.SS3.SSS1.p2.4.m4.1.1.2.cmml">B</mi><mi id="S5.SS3.SSS1.p2.4.m4.1.1.3" xref="S5.SS3.SSS1.p2.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.4.m4.1b"><apply id="S5.SS3.SSS1.p2.4.m4.1.1.cmml" xref="S5.SS3.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.4.m4.1.1.1.cmml" xref="S5.SS3.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.4.m4.1.1.2.cmml" xref="S5.SS3.SSS1.p2.4.m4.1.1.2">ùêµ</ci><ci id="S5.SS3.SSS1.p2.4.m4.1.1.3.cmml" xref="S5.SS3.SSS1.p2.4.m4.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.4.m4.1c">B_{r}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.4.m4.1d">italic_B start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="B_{c}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.5.m5.1"><semantics id="S5.SS3.SSS1.p2.5.m5.1a"><msub id="S5.SS3.SSS1.p2.5.m5.1.1" xref="S5.SS3.SSS1.p2.5.m5.1.1.cmml"><mi id="S5.SS3.SSS1.p2.5.m5.1.1.2" xref="S5.SS3.SSS1.p2.5.m5.1.1.2.cmml">B</mi><mi id="S5.SS3.SSS1.p2.5.m5.1.1.3" xref="S5.SS3.SSS1.p2.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.5.m5.1b"><apply id="S5.SS3.SSS1.p2.5.m5.1.1.cmml" xref="S5.SS3.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.5.m5.1.1.1.cmml" xref="S5.SS3.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.5.m5.1.1.2.cmml" xref="S5.SS3.SSS1.p2.5.m5.1.1.2">ùêµ</ci><ci id="S5.SS3.SSS1.p2.5.m5.1.1.3.cmml" xref="S5.SS3.SSS1.p2.5.m5.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.5.m5.1c">B_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.5.m5.1d">italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. In order to prevent the real bias from being overlooked, <math alttext="B_{r}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.6.m6.1"><semantics id="S5.SS3.SSS1.p2.6.m6.1a"><msub id="S5.SS3.SSS1.p2.6.m6.1.1" xref="S5.SS3.SSS1.p2.6.m6.1.1.cmml"><mi id="S5.SS3.SSS1.p2.6.m6.1.1.2" xref="S5.SS3.SSS1.p2.6.m6.1.1.2.cmml">B</mi><mi id="S5.SS3.SSS1.p2.6.m6.1.1.3" xref="S5.SS3.SSS1.p2.6.m6.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.6.m6.1b"><apply id="S5.SS3.SSS1.p2.6.m6.1.1.cmml" xref="S5.SS3.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.6.m6.1.1.1.cmml" xref="S5.SS3.SSS1.p2.6.m6.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.6.m6.1.1.2.cmml" xref="S5.SS3.SSS1.p2.6.m6.1.1.2">ùêµ</ci><ci id="S5.SS3.SSS1.p2.6.m6.1.1.3.cmml" xref="S5.SS3.SSS1.p2.6.m6.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.6.m6.1c">B_{r}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.6.m6.1d">italic_B start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="B_{c}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.7.m7.1"><semantics id="S5.SS3.SSS1.p2.7.m7.1a"><msub id="S5.SS3.SSS1.p2.7.m7.1.1" xref="S5.SS3.SSS1.p2.7.m7.1.1.cmml"><mi id="S5.SS3.SSS1.p2.7.m7.1.1.2" xref="S5.SS3.SSS1.p2.7.m7.1.1.2.cmml">B</mi><mi id="S5.SS3.SSS1.p2.7.m7.1.1.3" xref="S5.SS3.SSS1.p2.7.m7.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.7.m7.1b"><apply id="S5.SS3.SSS1.p2.7.m7.1.1.cmml" xref="S5.SS3.SSS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.7.m7.1.1.1.cmml" xref="S5.SS3.SSS1.p2.7.m7.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.7.m7.1.1.2.cmml" xref="S5.SS3.SSS1.p2.7.m7.1.1.2">ùêµ</ci><ci id="S5.SS3.SSS1.p2.7.m7.1.1.3.cmml" xref="S5.SS3.SSS1.p2.7.m7.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.7.m7.1c">B_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.7.m7.1d">italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> are further merged to obtain the candidate set <math alttext="B" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.8.m8.1"><semantics id="S5.SS3.SSS1.p2.8.m8.1a"><mi id="S5.SS3.SSS1.p2.8.m8.1.1" xref="S5.SS3.SSS1.p2.8.m8.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.8.m8.1b"><ci id="S5.SS3.SSS1.p2.8.m8.1.1.cmml" xref="S5.SS3.SSS1.p2.8.m8.1.1">ùêµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.8.m8.1c">B</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.8.m8.1d">italic_B</annotation></semantics></math>. Next, a specific bias category <math alttext="B_{i}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.9.m9.1"><semantics id="S5.SS3.SSS1.p2.9.m9.1a"><msub id="S5.SS3.SSS1.p2.9.m9.1.1" xref="S5.SS3.SSS1.p2.9.m9.1.1.cmml"><mi id="S5.SS3.SSS1.p2.9.m9.1.1.2" xref="S5.SS3.SSS1.p2.9.m9.1.1.2.cmml">B</mi><mi id="S5.SS3.SSS1.p2.9.m9.1.1.3" xref="S5.SS3.SSS1.p2.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.9.m9.1b"><apply id="S5.SS3.SSS1.p2.9.m9.1.1.cmml" xref="S5.SS3.SSS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.9.m9.1.1.1.cmml" xref="S5.SS3.SSS1.p2.9.m9.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.9.m9.1.1.2.cmml" xref="S5.SS3.SSS1.p2.9.m9.1.1.2">ùêµ</ci><ci id="S5.SS3.SSS1.p2.9.m9.1.1.3.cmml" xref="S5.SS3.SSS1.p2.9.m9.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.9.m9.1c">B_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.9.m9.1d">italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in the candidate set <math alttext="B" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.10.m10.1"><semantics id="S5.SS3.SSS1.p2.10.m10.1a"><mi id="S5.SS3.SSS1.p2.10.m10.1.1" xref="S5.SS3.SSS1.p2.10.m10.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.10.m10.1b"><ci id="S5.SS3.SSS1.p2.10.m10.1.1.cmml" xref="S5.SS3.SSS1.p2.10.m10.1.1">ùêµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.10.m10.1c">B</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.10.m10.1d">italic_B</annotation></semantics></math> will be passed to a specific competitive detection agent <math alttext="\textit{CA}_{i}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.11.m11.1"><semantics id="S5.SS3.SSS1.p2.11.m11.1a"><msub id="S5.SS3.SSS1.p2.11.m11.1.1" xref="S5.SS3.SSS1.p2.11.m11.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS1.p2.11.m11.1.1.2" xref="S5.SS3.SSS1.p2.11.m11.1.1.2a.cmml">CA</mtext><mi id="S5.SS3.SSS1.p2.11.m11.1.1.3" xref="S5.SS3.SSS1.p2.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.11.m11.1b"><apply id="S5.SS3.SSS1.p2.11.m11.1.1.cmml" xref="S5.SS3.SSS1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.11.m11.1.1.1.cmml" xref="S5.SS3.SSS1.p2.11.m11.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.11.m11.1.1.2a.cmml" xref="S5.SS3.SSS1.p2.11.m11.1.1.2"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS1.p2.11.m11.1.1.2.cmml" xref="S5.SS3.SSS1.p2.11.m11.1.1.2">CA</mtext></ci><ci id="S5.SS3.SSS1.p2.11.m11.1.1.3.cmml" xref="S5.SS3.SSS1.p2.11.m11.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.11.m11.1c">\textit{CA}_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.11.m11.1d">CA start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="\textit{CA}_{i}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.12.m12.1"><semantics id="S5.SS3.SSS1.p2.12.m12.1a"><msub id="S5.SS3.SSS1.p2.12.m12.1.1" xref="S5.SS3.SSS1.p2.12.m12.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS1.p2.12.m12.1.1.2" xref="S5.SS3.SSS1.p2.12.m12.1.1.2a.cmml">CA</mtext><mi id="S5.SS3.SSS1.p2.12.m12.1.1.3" xref="S5.SS3.SSS1.p2.12.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.12.m12.1b"><apply id="S5.SS3.SSS1.p2.12.m12.1.1.cmml" xref="S5.SS3.SSS1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.12.m12.1.1.1.cmml" xref="S5.SS3.SSS1.p2.12.m12.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.12.m12.1.1.2a.cmml" xref="S5.SS3.SSS1.p2.12.m12.1.1.2"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS1.p2.12.m12.1.1.2.cmml" xref="S5.SS3.SSS1.p2.12.m12.1.1.2">CA</mtext></ci><ci id="S5.SS3.SSS1.p2.12.m12.1.1.3.cmml" xref="S5.SS3.SSS1.p2.12.m12.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.12.m12.1c">\textit{CA}_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.12.m12.1d">CA start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> will then determine whether the text <math alttext="T" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.13.m13.1"><semantics id="S5.SS3.SSS1.p2.13.m13.1a"><mi id="S5.SS3.SSS1.p2.13.m13.1.1" xref="S5.SS3.SSS1.p2.13.m13.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.13.m13.1b"><ci id="S5.SS3.SSS1.p2.13.m13.1.1.cmml" xref="S5.SS3.SSS1.p2.13.m13.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.13.m13.1c">T</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.13.m13.1d">italic_T</annotation></semantics></math> contains the bias category <math alttext="B_{i}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p2.14.m14.1"><semantics id="S5.SS3.SSS1.p2.14.m14.1a"><msub id="S5.SS3.SSS1.p2.14.m14.1.1" xref="S5.SS3.SSS1.p2.14.m14.1.1.cmml"><mi id="S5.SS3.SSS1.p2.14.m14.1.1.2" xref="S5.SS3.SSS1.p2.14.m14.1.1.2.cmml">B</mi><mi id="S5.SS3.SSS1.p2.14.m14.1.1.3" xref="S5.SS3.SSS1.p2.14.m14.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p2.14.m14.1b"><apply id="S5.SS3.SSS1.p2.14.m14.1.1.cmml" xref="S5.SS3.SSS1.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p2.14.m14.1.1.1.cmml" xref="S5.SS3.SSS1.p2.14.m14.1.1">subscript</csymbol><ci id="S5.SS3.SSS1.p2.14.m14.1.1.2.cmml" xref="S5.SS3.SSS1.p2.14.m14.1.1.2">ùêµ</ci><ci id="S5.SS3.SSS1.p2.14.m14.1.1.3.cmml" xref="S5.SS3.SSS1.p2.14.m14.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p2.14.m14.1c">B_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS1.p2.14.m14.1d">italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Debate competition based on loser trees</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p" id="S5.SS3.SSS2.p1.2">The same sample may be identified as different cognitive biases by different agents. To improve stability, we propose a multi-agent competitive debate mechanism. However, if the size of candidates is N, the complexity will be <math alttext="O(N)" class="ltx_Math" display="inline" id="S5.SS3.SSS2.p1.1.m1.1"><semantics id="S5.SS3.SSS2.p1.1.m1.1a"><mrow id="S5.SS3.SSS2.p1.1.m1.1.2" xref="S5.SS3.SSS2.p1.1.m1.1.2.cmml"><mi id="S5.SS3.SSS2.p1.1.m1.1.2.2" xref="S5.SS3.SSS2.p1.1.m1.1.2.2.cmml">O</mi><mo id="S5.SS3.SSS2.p1.1.m1.1.2.1" xref="S5.SS3.SSS2.p1.1.m1.1.2.1.cmml">‚Å¢</mo><mrow id="S5.SS3.SSS2.p1.1.m1.1.2.3.2" xref="S5.SS3.SSS2.p1.1.m1.1.2.cmml"><mo id="S5.SS3.SSS2.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S5.SS3.SSS2.p1.1.m1.1.2.cmml">(</mo><mi id="S5.SS3.SSS2.p1.1.m1.1.1" xref="S5.SS3.SSS2.p1.1.m1.1.1.cmml">N</mi><mo id="S5.SS3.SSS2.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S5.SS3.SSS2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p1.1.m1.1b"><apply id="S5.SS3.SSS2.p1.1.m1.1.2.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.2"><times id="S5.SS3.SSS2.p1.1.m1.1.2.1.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.2.1"></times><ci id="S5.SS3.SSS2.p1.1.m1.1.2.2.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.2.2">ùëÇ</ci><ci id="S5.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.1">ùëÅ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p1.1.m1.1c">O(N)</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS2.p1.1.m1.1d">italic_O ( italic_N )</annotation></semantics></math>. Therefore, we innovatively propose a debate competition method based on a loser tree, reducing the complexity to <math alttext="O(log_{2}^{N})" class="ltx_Math" display="inline" id="S5.SS3.SSS2.p1.2.m2.1"><semantics id="S5.SS3.SSS2.p1.2.m2.1a"><mrow id="S5.SS3.SSS2.p1.2.m2.1.1" xref="S5.SS3.SSS2.p1.2.m2.1.1.cmml"><mi id="S5.SS3.SSS2.p1.2.m2.1.1.3" xref="S5.SS3.SSS2.p1.2.m2.1.1.3.cmml">O</mi><mo id="S5.SS3.SSS2.p1.2.m2.1.1.2" xref="S5.SS3.SSS2.p1.2.m2.1.1.2.cmml">‚Å¢</mo><mrow id="S5.SS3.SSS2.p1.2.m2.1.1.1.1" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.cmml"><mo id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.2" stretchy="false" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.cmml"><mi id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.2" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.2.cmml">l</mi><mo id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.1" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.3" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.3.cmml">o</mi><mo id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.1a" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.1.cmml">‚Å¢</mo><msubsup id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.cmml"><mi id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.2" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.2.cmml">g</mi><mn id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.3" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.3.cmml">2</mn><mi id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.3" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.3.cmml">N</mi></msubsup></mrow><mo id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.3" stretchy="false" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p1.2.m2.1b"><apply id="S5.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1"><times id="S5.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.2"></times><ci id="S5.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.3">ùëÇ</ci><apply id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1"><times id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.1"></times><ci id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.2.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.2">ùëô</ci><ci id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.3.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.3">ùëú</ci><apply id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.1.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4">superscript</csymbol><apply id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.1.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4">subscript</csymbol><ci id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.2.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.2">ùëî</ci><cn id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.3.cmml" type="integer" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.2.3">2</cn></apply><ci id="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.3.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1.1.1.1.4.3">ùëÅ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p1.2.m2.1c">O(log_{2}^{N})</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS2.p1.2.m2.1d">italic_O ( italic_l italic_o italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p2">
<p class="ltx_p" id="S5.SS3.SSS2.p2.1">As revealed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F3" title="Figure 3 ‚Ä£ 5.2.2 Multi-Dimensional Agent Behavior Monitoring ‚Ä£ 5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">3</span></a>, the constructed loser tree has <math alttext="N" class="ltx_Math" display="inline" id="S5.SS3.SSS2.p2.1.m1.1"><semantics id="S5.SS3.SSS2.p2.1.m1.1a"><mi id="S5.SS3.SSS2.p2.1.m1.1.1" xref="S5.SS3.SSS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.1.m1.1b"><ci id="S5.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS2.p2.1.m1.1d">italic_N</annotation></semantics></math> leaf nodes, each node represents a competitive detection agent dedicated to detecting a specific cognitive bias. This approach can transform unlabeled detection into labeled detection, effectively simplifying the detection process. Subsequently, the agent employs labeled detection techniques to assess the presence of cognitive biases. It then constructs a loser tree for all leaf nodes that exhibit cognitive biases. These agents follow the structure of the loser tree and carry out an orderly and efficient debate in the order of: <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p2.1.1">1).</span> Opening (introducing the features and cases of the cognitive bias); <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p2.1.2">2).</span> Argument (citing evidence of the cognitive bias); <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p2.1.3">3).</span> Refutation (refuting the opponent‚Äôs views according to the previous debate content); <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p2.1.4">4).</span> Summarize views. The competition process continues until finally only one competitive detection agent is left. It is considered as the final cognitive bias type.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.3 </span>Decision module based on reinforcement learning</h4>
<div class="ltx_para" id="S5.SS3.SSS3.p1">
<p class="ltx_p" id="S5.SS3.SSS3.p1.2">In the debate, the competition between agents is decided by the referee agent. In order to ensure the reliability of the decision, we innovatively introduce two referee agents, <math alttext="\textit{JA}_{1}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p1.1.m1.1"><semantics id="S5.SS3.SSS3.p1.1.m1.1a"><msub id="S5.SS3.SSS3.p1.1.m1.1.1" xref="S5.SS3.SSS3.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS3.p1.1.m1.1.1.2" xref="S5.SS3.SSS3.p1.1.m1.1.1.2a.cmml">JA</mtext><mn id="S5.SS3.SSS3.p1.1.m1.1.1.3" xref="S5.SS3.SSS3.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p1.1.m1.1b"><apply id="S5.SS3.SSS3.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p1.1.m1.1.1.2a.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1.2">JA</mtext></ci><cn id="S5.SS3.SSS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.SSS3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p1.1.m1.1c">\textit{JA}_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p1.1.m1.1d">JA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\textit{JA}_{2}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p1.2.m2.1"><semantics id="S5.SS3.SSS3.p1.2.m2.1a"><msub id="S5.SS3.SSS3.p1.2.m2.1.1" xref="S5.SS3.SSS3.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS3.p1.2.m2.1.1.2" xref="S5.SS3.SSS3.p1.2.m2.1.1.2a.cmml">JA</mtext><mn id="S5.SS3.SSS3.p1.2.m2.1.1.3" xref="S5.SS3.SSS3.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p1.2.m2.1b"><apply id="S5.SS3.SSS3.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p1.2.m2.1.1.2a.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1.2"><mtext class="ltx_mathvariant_italic" id="S5.SS3.SSS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1.2">JA</mtext></ci><cn id="S5.SS3.SSS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS3.SSS3.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p1.2.m2.1c">\textit{JA}_{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p1.2.m2.1d">JA start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>, with different decision-making styles. Inspired by the scoring rules of debate competitions, we score the performance of different competitive agents from six different indicator dimensions, including argument support, logical consistency, effective rebuttal, argument completeness, persuasiveness, and reasonable assessment of cognitive bias. Lastly, we use a reinforcement learning model trained by DQN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib24" title="">24</a>]</cite> to make decisions.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p2">
<p class="ltx_p" id="S5.SS3.SSS3.p2.19">As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S5.F3" title="Figure 3 ‚Ä£ 5.2.2 Multi-Dimensional Agent Behavior Monitoring ‚Ä£ 5.2 Rule-Based Multi-Agent Communication ‚Ä£ 5 Method ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">3</span></a>, the decision module is divided into two stages: the training stage and the decision stage. Specifically, we set up a decision task to assess the performance of two agents within a given environment and make decisions based on a set of weights. In the training phase, we initialize a replay buffer with capacity <math alttext="N" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.1.m1.1"><semantics id="S5.SS3.SSS3.p2.1.m1.1a"><mi id="S5.SS3.SSS3.p2.1.m1.1.1" xref="S5.SS3.SSS3.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.1.m1.1b"><ci id="S5.SS3.SSS3.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS3.p2.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.1.m1.1d">italic_N</annotation></semantics></math> and define an action-value function <math alttext="Q" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.2.m2.1"><semantics id="S5.SS3.SSS3.p2.2.m2.1a"><mi id="S5.SS3.SSS3.p2.2.m2.1.1" xref="S5.SS3.SSS3.p2.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.2.m2.1b"><ci id="S5.SS3.SSS3.p2.2.m2.1.1.cmml" xref="S5.SS3.SSS3.p2.2.m2.1.1">ùëÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.2.m2.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.2.m2.1d">italic_Q</annotation></semantics></math> with random initial weights <math alttext="\theta" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.3.m3.1"><semantics id="S5.SS3.SSS3.p2.3.m3.1a"><mi id="S5.SS3.SSS3.p2.3.m3.1.1" xref="S5.SS3.SSS3.p2.3.m3.1.1.cmml">Œ∏</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.3.m3.1b"><ci id="S5.SS3.SSS3.p2.3.m3.1.1.cmml" xref="S5.SS3.SSS3.p2.3.m3.1.1">ùúÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.3.m3.1d">italic_Œ∏</annotation></semantics></math>. Concurrently, the target action-value function <math alttext="\hat{Q}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.4.m4.1"><semantics id="S5.SS3.SSS3.p2.4.m4.1a"><mover accent="true" id="S5.SS3.SSS3.p2.4.m4.1.1" xref="S5.SS3.SSS3.p2.4.m4.1.1.cmml"><mi id="S5.SS3.SSS3.p2.4.m4.1.1.2" xref="S5.SS3.SSS3.p2.4.m4.1.1.2.cmml">Q</mi><mo id="S5.SS3.SSS3.p2.4.m4.1.1.1" xref="S5.SS3.SSS3.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.4.m4.1b"><apply id="S5.SS3.SSS3.p2.4.m4.1.1.cmml" xref="S5.SS3.SSS3.p2.4.m4.1.1"><ci id="S5.SS3.SSS3.p2.4.m4.1.1.1.cmml" xref="S5.SS3.SSS3.p2.4.m4.1.1.1">^</ci><ci id="S5.SS3.SSS3.p2.4.m4.1.1.2.cmml" xref="S5.SS3.SSS3.p2.4.m4.1.1.2">ùëÑ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.4.m4.1c">\hat{Q}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.4.m4.1d">over^ start_ARG italic_Q end_ARG</annotation></semantics></math> is initialized with <math alttext="\theta^{\prime}=\theta" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.5.m5.1"><semantics id="S5.SS3.SSS3.p2.5.m5.1a"><mrow id="S5.SS3.SSS3.p2.5.m5.1.1" xref="S5.SS3.SSS3.p2.5.m5.1.1.cmml"><msup id="S5.SS3.SSS3.p2.5.m5.1.1.2" xref="S5.SS3.SSS3.p2.5.m5.1.1.2.cmml"><mi id="S5.SS3.SSS3.p2.5.m5.1.1.2.2" xref="S5.SS3.SSS3.p2.5.m5.1.1.2.2.cmml">Œ∏</mi><mo id="S5.SS3.SSS3.p2.5.m5.1.1.2.3" xref="S5.SS3.SSS3.p2.5.m5.1.1.2.3.cmml">‚Ä≤</mo></msup><mo id="S5.SS3.SSS3.p2.5.m5.1.1.1" xref="S5.SS3.SSS3.p2.5.m5.1.1.1.cmml">=</mo><mi id="S5.SS3.SSS3.p2.5.m5.1.1.3" xref="S5.SS3.SSS3.p2.5.m5.1.1.3.cmml">Œ∏</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.5.m5.1b"><apply id="S5.SS3.SSS3.p2.5.m5.1.1.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1"><eq id="S5.SS3.SSS3.p2.5.m5.1.1.1.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1.1"></eq><apply id="S5.SS3.SSS3.p2.5.m5.1.1.2.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.5.m5.1.1.2.1.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1.2">superscript</csymbol><ci id="S5.SS3.SSS3.p2.5.m5.1.1.2.2.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1.2.2">ùúÉ</ci><ci id="S5.SS3.SSS3.p2.5.m5.1.1.2.3.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1.2.3">‚Ä≤</ci></apply><ci id="S5.SS3.SSS3.p2.5.m5.1.1.3.cmml" xref="S5.SS3.SSS3.p2.5.m5.1.1.3">ùúÉ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.5.m5.1c">\theta^{\prime}=\theta</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.5.m5.1d">italic_Œ∏ start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT = italic_Œ∏</annotation></semantics></math>. Over <math alttext="M" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.6.m6.1"><semantics id="S5.SS3.SSS3.p2.6.m6.1a"><mi id="S5.SS3.SSS3.p2.6.m6.1.1" xref="S5.SS3.SSS3.p2.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.6.m6.1b"><ci id="S5.SS3.SSS3.p2.6.m6.1.1.cmml" xref="S5.SS3.SSS3.p2.6.m6.1.1">ùëÄ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.6.m6.1c">M</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.6.m6.1d">italic_M</annotation></semantics></math> episodes, each episode starts with the initial state and its preprocessed sequence. At each time step <math alttext="t" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.7.m7.1"><semantics id="S5.SS3.SSS3.p2.7.m7.1a"><mi id="S5.SS3.SSS3.p2.7.m7.1.1" xref="S5.SS3.SSS3.p2.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.7.m7.1b"><ci id="S5.SS3.SSS3.p2.7.m7.1.1.cmml" xref="S5.SS3.SSS3.p2.7.m7.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.7.m7.1c">t</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.7.m7.1d">italic_t</annotation></semantics></math>, the agent uses a genetic algorithm strategy to search for the selection of an action <math alttext="a_{t}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.8.m8.1"><semantics id="S5.SS3.SSS3.p2.8.m8.1a"><msub id="S5.SS3.SSS3.p2.8.m8.1.1" xref="S5.SS3.SSS3.p2.8.m8.1.1.cmml"><mi id="S5.SS3.SSS3.p2.8.m8.1.1.2" xref="S5.SS3.SSS3.p2.8.m8.1.1.2.cmml">a</mi><mi id="S5.SS3.SSS3.p2.8.m8.1.1.3" xref="S5.SS3.SSS3.p2.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.8.m8.1b"><apply id="S5.SS3.SSS3.p2.8.m8.1.1.cmml" xref="S5.SS3.SSS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.8.m8.1.1.1.cmml" xref="S5.SS3.SSS3.p2.8.m8.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p2.8.m8.1.1.2.cmml" xref="S5.SS3.SSS3.p2.8.m8.1.1.2">ùëé</ci><ci id="S5.SS3.SSS3.p2.8.m8.1.1.3.cmml" xref="S5.SS3.SSS3.p2.8.m8.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.8.m8.1c">a_{t}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.8.m8.1d">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> to be performed in the environment. The resulting transition tuple <math alttext="(s_{t},a_{t},r_{t},s_{t+1})" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.9.m9.4"><semantics id="S5.SS3.SSS3.p2.9.m9.4a"><mrow id="S5.SS3.SSS3.p2.9.m9.4.4.4" xref="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml"><mo id="S5.SS3.SSS3.p2.9.m9.4.4.4.5" stretchy="false" xref="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml">(</mo><msub id="S5.SS3.SSS3.p2.9.m9.1.1.1.1" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1.cmml"><mi id="S5.SS3.SSS3.p2.9.m9.1.1.1.1.2" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1.2.cmml">s</mi><mi id="S5.SS3.SSS3.p2.9.m9.1.1.1.1.3" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1.3.cmml">t</mi></msub><mo id="S5.SS3.SSS3.p2.9.m9.4.4.4.6" xref="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml">,</mo><msub id="S5.SS3.SSS3.p2.9.m9.2.2.2.2" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2.cmml"><mi id="S5.SS3.SSS3.p2.9.m9.2.2.2.2.2" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2.2.cmml">a</mi><mi id="S5.SS3.SSS3.p2.9.m9.2.2.2.2.3" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2.3.cmml">t</mi></msub><mo id="S5.SS3.SSS3.p2.9.m9.4.4.4.7" xref="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml">,</mo><msub id="S5.SS3.SSS3.p2.9.m9.3.3.3.3" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3.cmml"><mi id="S5.SS3.SSS3.p2.9.m9.3.3.3.3.2" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3.2.cmml">r</mi><mi id="S5.SS3.SSS3.p2.9.m9.3.3.3.3.3" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3.3.cmml">t</mi></msub><mo id="S5.SS3.SSS3.p2.9.m9.4.4.4.8" xref="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml">,</mo><msub id="S5.SS3.SSS3.p2.9.m9.4.4.4.4" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.cmml"><mi id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.2" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.2.cmml">s</mi><mrow id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.cmml"><mi id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.2" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.2.cmml">t</mi><mo id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.1" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.1.cmml">+</mo><mn id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.3" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.3.cmml">1</mn></mrow></msub><mo id="S5.SS3.SSS3.p2.9.m9.4.4.4.9" stretchy="false" xref="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.9.m9.4b"><vector id="S5.SS3.SSS3.p2.9.m9.4.4.5.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4"><apply id="S5.SS3.SSS3.p2.9.m9.1.1.1.1.cmml" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.9.m9.1.1.1.1.1.cmml" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p2.9.m9.1.1.1.1.2.cmml" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1.2">ùë†</ci><ci id="S5.SS3.SSS3.p2.9.m9.1.1.1.1.3.cmml" xref="S5.SS3.SSS3.p2.9.m9.1.1.1.1.3">ùë°</ci></apply><apply id="S5.SS3.SSS3.p2.9.m9.2.2.2.2.cmml" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.9.m9.2.2.2.2.1.cmml" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2">subscript</csymbol><ci id="S5.SS3.SSS3.p2.9.m9.2.2.2.2.2.cmml" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2.2">ùëé</ci><ci id="S5.SS3.SSS3.p2.9.m9.2.2.2.2.3.cmml" xref="S5.SS3.SSS3.p2.9.m9.2.2.2.2.3">ùë°</ci></apply><apply id="S5.SS3.SSS3.p2.9.m9.3.3.3.3.cmml" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.9.m9.3.3.3.3.1.cmml" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3">subscript</csymbol><ci id="S5.SS3.SSS3.p2.9.m9.3.3.3.3.2.cmml" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3.2">ùëü</ci><ci id="S5.SS3.SSS3.p2.9.m9.3.3.3.3.3.cmml" xref="S5.SS3.SSS3.p2.9.m9.3.3.3.3.3">ùë°</ci></apply><apply id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.1.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4">subscript</csymbol><ci id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.2.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.2">ùë†</ci><apply id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3"><plus id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.1.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.1"></plus><ci id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.2.cmml" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.2">ùë°</ci><cn id="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.3.cmml" type="integer" xref="S5.SS3.SSS3.p2.9.m9.4.4.4.4.3.3">1</cn></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.9.m9.4c">(s_{t},a_{t},r_{t},s_{t+1})</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.9.m9.4d">( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT )</annotation></semantics></math> is stored in the replay buffer <math alttext="D" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.10.m10.1"><semantics id="S5.SS3.SSS3.p2.10.m10.1a"><mi id="S5.SS3.SSS3.p2.10.m10.1.1" xref="S5.SS3.SSS3.p2.10.m10.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.10.m10.1b"><ci id="S5.SS3.SSS3.p2.10.m10.1.1.cmml" xref="S5.SS3.SSS3.p2.10.m10.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.10.m10.1c">D</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.10.m10.1d">italic_D</annotation></semantics></math>. A minibatch of transitions is randomly sampled from <math alttext="D" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.11.m11.1"><semantics id="S5.SS3.SSS3.p2.11.m11.1a"><mi id="S5.SS3.SSS3.p2.11.m11.1.1" xref="S5.SS3.SSS3.p2.11.m11.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.11.m11.1b"><ci id="S5.SS3.SSS3.p2.11.m11.1.1.cmml" xref="S5.SS3.SSS3.p2.11.m11.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.11.m11.1c">D</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.11.m11.1d">italic_D</annotation></semantics></math>, and the target <math alttext="y_{j}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.12.m12.1"><semantics id="S5.SS3.SSS3.p2.12.m12.1a"><msub id="S5.SS3.SSS3.p2.12.m12.1.1" xref="S5.SS3.SSS3.p2.12.m12.1.1.cmml"><mi id="S5.SS3.SSS3.p2.12.m12.1.1.2" xref="S5.SS3.SSS3.p2.12.m12.1.1.2.cmml">y</mi><mi id="S5.SS3.SSS3.p2.12.m12.1.1.3" xref="S5.SS3.SSS3.p2.12.m12.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.12.m12.1b"><apply id="S5.SS3.SSS3.p2.12.m12.1.1.cmml" xref="S5.SS3.SSS3.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.12.m12.1.1.1.cmml" xref="S5.SS3.SSS3.p2.12.m12.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p2.12.m12.1.1.2.cmml" xref="S5.SS3.SSS3.p2.12.m12.1.1.2">ùë¶</ci><ci id="S5.SS3.SSS3.p2.12.m12.1.1.3.cmml" xref="S5.SS3.SSS3.p2.12.m12.1.1.3">ùëó</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.12.m12.1c">y_{j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.12.m12.1d">italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> for each transition is computed as follows: <math alttext="y_{j}=r_{j}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.13.m13.1"><semantics id="S5.SS3.SSS3.p2.13.m13.1a"><mrow id="S5.SS3.SSS3.p2.13.m13.1.1" xref="S5.SS3.SSS3.p2.13.m13.1.1.cmml"><msub id="S5.SS3.SSS3.p2.13.m13.1.1.2" xref="S5.SS3.SSS3.p2.13.m13.1.1.2.cmml"><mi id="S5.SS3.SSS3.p2.13.m13.1.1.2.2" xref="S5.SS3.SSS3.p2.13.m13.1.1.2.2.cmml">y</mi><mi id="S5.SS3.SSS3.p2.13.m13.1.1.2.3" xref="S5.SS3.SSS3.p2.13.m13.1.1.2.3.cmml">j</mi></msub><mo id="S5.SS3.SSS3.p2.13.m13.1.1.1" xref="S5.SS3.SSS3.p2.13.m13.1.1.1.cmml">=</mo><msub id="S5.SS3.SSS3.p2.13.m13.1.1.3" xref="S5.SS3.SSS3.p2.13.m13.1.1.3.cmml"><mi id="S5.SS3.SSS3.p2.13.m13.1.1.3.2" xref="S5.SS3.SSS3.p2.13.m13.1.1.3.2.cmml">r</mi><mi id="S5.SS3.SSS3.p2.13.m13.1.1.3.3" xref="S5.SS3.SSS3.p2.13.m13.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.13.m13.1b"><apply id="S5.SS3.SSS3.p2.13.m13.1.1.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1"><eq id="S5.SS3.SSS3.p2.13.m13.1.1.1.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.1"></eq><apply id="S5.SS3.SSS3.p2.13.m13.1.1.2.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.13.m13.1.1.2.1.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.2">subscript</csymbol><ci id="S5.SS3.SSS3.p2.13.m13.1.1.2.2.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.2.2">ùë¶</ci><ci id="S5.SS3.SSS3.p2.13.m13.1.1.2.3.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.2.3">ùëó</ci></apply><apply id="S5.SS3.SSS3.p2.13.m13.1.1.3.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.3"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.13.m13.1.1.3.1.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.3">subscript</csymbol><ci id="S5.SS3.SSS3.p2.13.m13.1.1.3.2.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.3.2">ùëü</ci><ci id="S5.SS3.SSS3.p2.13.m13.1.1.3.3.cmml" xref="S5.SS3.SSS3.p2.13.m13.1.1.3.3">ùëó</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.13.m13.1c">y_{j}=r_{j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.13.m13.1d">italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> if the episode ends at the next step; otherwise <math alttext="y_{j}=r_{j}+\gamma\max_{a^{\prime}}\hat{Q}(s_{j+1},a^{\prime};\theta^{\prime})" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.14.m14.3"><semantics id="S5.SS3.SSS3.p2.14.m14.3a"><mrow id="S5.SS3.SSS3.p2.14.m14.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.cmml"><msub id="S5.SS3.SSS3.p2.14.m14.3.3.5" xref="S5.SS3.SSS3.p2.14.m14.3.3.5.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.5.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.5.2.cmml">y</mi><mi id="S5.SS3.SSS3.p2.14.m14.3.3.5.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.5.3.cmml">j</mi></msub><mo id="S5.SS3.SSS3.p2.14.m14.3.3.4" xref="S5.SS3.SSS3.p2.14.m14.3.3.4.cmml">=</mo><mrow id="S5.SS3.SSS3.p2.14.m14.3.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.cmml"><msub id="S5.SS3.SSS3.p2.14.m14.3.3.3.5" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.5.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5.2.cmml">r</mi><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.5.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5.3.cmml">j</mi></msub><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.4" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.4.cmml">+</mo><mrow id="S5.SS3.SSS3.p2.14.m14.3.3.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.5" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.5.cmml">Œ≥</mi><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.4" lspace="0.167em" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.4.cmml">‚Å¢</mo><mrow id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.cmml"><msub id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.2.cmml">max</mi><msup id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.2.cmml">a</mi><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.3.cmml">‚Ä≤</mo></msup></msub><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6a" lspace="0.167em" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.cmml">‚Å°</mo><mover accent="true" id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.2.cmml">Q</mi><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.1" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.1.cmml">^</mo></mover></mrow><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.4a" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.4.cmml">‚Å¢</mo><mrow id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.4.cmml"><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.4" stretchy="false" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.4.cmml">(</mo><msub id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.2" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.2.cmml">s</mi><mrow id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.2" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.2.cmml">j</mi><mo id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.1" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.1.cmml">+</mo><mn id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.3" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.5" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.4.cmml">,</mo><msup id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.2" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.2.cmml">a</mi><mo id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.3" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.3.cmml">‚Ä≤</mo></msup><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.6" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.4.cmml">;</mo><msup id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.cmml"><mi id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.2" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.2.cmml">Œ∏</mi><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.3" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.3.cmml">‚Ä≤</mo></msup><mo id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.7" stretchy="false" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.14.m14.3b"><apply id="S5.SS3.SSS3.p2.14.m14.3.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3"><eq id="S5.SS3.SSS3.p2.14.m14.3.3.4.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.4"></eq><apply id="S5.SS3.SSS3.p2.14.m14.3.3.5.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.5"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.3.3.5.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.5">subscript</csymbol><ci id="S5.SS3.SSS3.p2.14.m14.3.3.5.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.5.2">ùë¶</ci><ci id="S5.SS3.SSS3.p2.14.m14.3.3.5.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.5.3">ùëó</ci></apply><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3"><plus id="S5.SS3.SSS3.p2.14.m14.3.3.3.4.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.4"></plus><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.5.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.3.3.3.5.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5">subscript</csymbol><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.5.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5.2">ùëü</ci><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.5.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.5.3">ùëó</ci></apply><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3"><times id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.4.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.4"></times><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.5.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.5">ùõæ</ci><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6"><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1">subscript</csymbol><max id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.2"></max><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3">superscript</csymbol><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.2">ùëé</ci><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.1.3.3">‚Ä≤</ci></apply></apply><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2"><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.1">^</ci><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.6.2.2">ùëÑ</ci></apply></apply><vector id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.4.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3"><apply id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.2">ùë†</ci><apply id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3"><plus id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.1"></plus><ci id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.2">ùëó</ci><cn id="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S5.SS3.SSS3.p2.14.m14.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2">superscript</csymbol><ci id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.2">ùëé</ci><ci id="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.2.2.2.2.2.2.2.3">‚Ä≤</ci></apply><apply id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.1.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3">superscript</csymbol><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.2.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.2">ùúÉ</ci><ci id="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.3.cmml" xref="S5.SS3.SSS3.p2.14.m14.3.3.3.3.3.3.3.3">‚Ä≤</ci></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.14.m14.3c">y_{j}=r_{j}+\gamma\max_{a^{\prime}}\hat{Q}(s_{j+1},a^{\prime};\theta^{\prime})</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.14.m14.3d">italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Œ≥ roman_max start_POSTSUBSCRIPT italic_a start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT over^ start_ARG italic_Q end_ARG ( italic_s start_POSTSUBSCRIPT italic_j + 1 end_POSTSUBSCRIPT , italic_a start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT ; italic_Œ∏ start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT )</annotation></semantics></math>.The network parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.15.m15.1"><semantics id="S5.SS3.SSS3.p2.15.m15.1a"><mi id="S5.SS3.SSS3.p2.15.m15.1.1" xref="S5.SS3.SSS3.p2.15.m15.1.1.cmml">Œ∏</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.15.m15.1b"><ci id="S5.SS3.SSS3.p2.15.m15.1.1.cmml" xref="S5.SS3.SSS3.p2.15.m15.1.1">ùúÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.15.m15.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.15.m15.1d">italic_Œ∏</annotation></semantics></math> are updated by minimizing the squared error loss <math alttext="(y_{j}-Q(s_{j},a_{j};\theta))^{2}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.16.m16.2"><semantics id="S5.SS3.SSS3.p2.16.m16.2a"><msup id="S5.SS3.SSS3.p2.16.m16.2.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.cmml"><mrow id="S5.SS3.SSS3.p2.16.m16.2.2.1.1" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.cmml"><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.2" stretchy="false" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.cmml">(</mo><mrow id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.cmml"><msub id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.cmml"><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.2.cmml">y</mi><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.3" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.3.cmml">j</mi></msub><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.3" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.3.cmml">‚àí</mo><mrow id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.cmml"><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.4" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.4.cmml">Q</mi><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.3" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.3.cmml">‚Å¢</mo><mrow id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.3.cmml"><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.3" stretchy="false" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.3.cmml">(</mo><msub id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.cmml"><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.3" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.4" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.3.cmml">,</mo><msub id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.cmml"><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.2" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.2.cmml">a</mi><mi id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.3" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.3.cmml">j</mi></msub><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.5" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.3.cmml">;</mo><mi id="S5.SS3.SSS3.p2.16.m16.1.1" xref="S5.SS3.SSS3.p2.16.m16.1.1.cmml">Œ∏</mi><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.6" stretchy="false" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.3" stretchy="false" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.cmml">)</mo></mrow><mn id="S5.SS3.SSS3.p2.16.m16.2.2.3" xref="S5.SS3.SSS3.p2.16.m16.2.2.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.16.m16.2b"><apply id="S5.SS3.SSS3.p2.16.m16.2.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.16.m16.2.2.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2">superscript</csymbol><apply id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1"><minus id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.3.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.3"></minus><apply id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.1.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4">subscript</csymbol><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.2">ùë¶</ci><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.3.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.4.3">ùëó</ci></apply><apply id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2"><times id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.3.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.3"></times><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.4.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.4">ùëÑ</ci><vector id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.3.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2"><apply id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.2">ùë†</ci><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.3.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.1.1.1.1.3">ùëó</ci></apply><apply id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.1.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2">subscript</csymbol><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.2.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.2">ùëé</ci><ci id="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.3.cmml" xref="S5.SS3.SSS3.p2.16.m16.2.2.1.1.1.2.2.2.2.3">ùëó</ci></apply><ci id="S5.SS3.SSS3.p2.16.m16.1.1.cmml" xref="S5.SS3.SSS3.p2.16.m16.1.1">ùúÉ</ci></vector></apply></apply><cn id="S5.SS3.SSS3.p2.16.m16.2.2.3.cmml" type="integer" xref="S5.SS3.SSS3.p2.16.m16.2.2.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.16.m16.2c">(y_{j}-Q(s_{j},a_{j};\theta))^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.16.m16.2d">( italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_Q ( italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ; italic_Œ∏ ) ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> through gradient descent. To ensure stability, the weights <math alttext="\theta^{\prime}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.17.m17.1"><semantics id="S5.SS3.SSS3.p2.17.m17.1a"><msup id="S5.SS3.SSS3.p2.17.m17.1.1" xref="S5.SS3.SSS3.p2.17.m17.1.1.cmml"><mi id="S5.SS3.SSS3.p2.17.m17.1.1.2" xref="S5.SS3.SSS3.p2.17.m17.1.1.2.cmml">Œ∏</mi><mo id="S5.SS3.SSS3.p2.17.m17.1.1.3" xref="S5.SS3.SSS3.p2.17.m17.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.17.m17.1b"><apply id="S5.SS3.SSS3.p2.17.m17.1.1.cmml" xref="S5.SS3.SSS3.p2.17.m17.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS3.p2.17.m17.1.1.1.cmml" xref="S5.SS3.SSS3.p2.17.m17.1.1">superscript</csymbol><ci id="S5.SS3.SSS3.p2.17.m17.1.1.2.cmml" xref="S5.SS3.SSS3.p2.17.m17.1.1.2">ùúÉ</ci><ci id="S5.SS3.SSS3.p2.17.m17.1.1.3.cmml" xref="S5.SS3.SSS3.p2.17.m17.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.17.m17.1c">\theta^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.17.m17.1d">italic_Œ∏ start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> of the target network are updated to match the current Q-network weights <math alttext="\theta" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.18.m18.1"><semantics id="S5.SS3.SSS3.p2.18.m18.1a"><mi id="S5.SS3.SSS3.p2.18.m18.1.1" xref="S5.SS3.SSS3.p2.18.m18.1.1.cmml">Œ∏</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.18.m18.1b"><ci id="S5.SS3.SSS3.p2.18.m18.1.1.cmml" xref="S5.SS3.SSS3.p2.18.m18.1.1">ùúÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.18.m18.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.18.m18.1d">italic_Œ∏</annotation></semantics></math> every <math alttext="C" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p2.19.m19.1"><semantics id="S5.SS3.SSS3.p2.19.m19.1a"><mi id="S5.SS3.SSS3.p2.19.m19.1.1" xref="S5.SS3.SSS3.p2.19.m19.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p2.19.m19.1b"><ci id="S5.SS3.SSS3.p2.19.m19.1.1.cmml" xref="S5.SS3.SSS3.p2.19.m19.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p2.19.m19.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS3.p2.19.m19.1d">italic_C</annotation></semantics></math> step. This process refines the policy for optimal decision-making in the specified environment. In the decision phase, we leverage the best-performing weights from the training phase as the decision weights, comparing the scores of two agents to declare a winner. The specific experimental setup is detailed in Appendix F.3.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Experiments</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This section details extensive experiments and analyses on the MindScope dataset, focusing on key issues: (1) Assessing GPT-4‚Äôs capability as a cognitive bias evaluator. (2) Evaluating cognitive bias in various LLMs. (3) Testing the effectiveness of RuleGen and CBDC. The specific models used are GPT-4-turbo and GPT-3.5-turbo-16k, respectively.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Proficiency testing of GPT-4 as an evaluator</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.p1.1.1">Experimental Design.</span> We sampled 10% of the data for each bias type from the static dataset and recruited three psychology graduate and PhD students for manual annotation. We ensure reliable correlation between annotators. The detailed annotation strategy can be viewed in Appendix C.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.p2.1.1">Evaluation Method.</span> We use accuracy, Pearson‚Äôs coefficient, and the Kappa statistic to calculate the correlation between the evaluation results of GPT-4 and human evaluators. GPT-4 conducted assessments via interpretable zero-shot prompts, judging the presence of specific cognitive biases based on current scenarios, evaluation criteria, and the names and descriptions of biases. To ensure consistency, the temperature parameter was set to 0, and GPT-4‚Äôs evaluation was repeated three times.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.p3.1.1">Result analysis.</span> The average results from three evaluations reveal a significant correlation between GPT-4 and humans in the annotation task. Notably, the average kappa statistic is 0.7180, the Pearson correlation coefficient is 0.7230, and the average accuracy is 88.08%. Specifically, the Kappa statistics for the three evaluations of GPT-4 are 0.9395, 0.9546, and 0.9402, respectively. These highly consistent statistics underscore the robustness and reliability of its assessment process. more details in Appendix C.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Cognitive bias in different LLMs</h3>
<section class="ltx_subsubsection" id="S6.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>Cognitive bias detection in static dataset</h4>
<div class="ltx_para" id="S6.SS2.SSS1.p1">
<p class="ltx_p" id="S6.SS2.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS1.p1.1.1">Testing Methodology on static dataset:</span> To evaluate the level of cognitive biases in LLMs, we employed the static data in MindScope to test 12 LLMs, including GPT-4, GPT-3.5-Turbo, Gemini-Pro <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib32" title="">32</a>]</cite>, Llama2 series <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib33" title="">33</a>]</cite> and Vicuna series <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib43" title="">43</a>]</cite>. To ensure fairness, the same prompts were input to LLMs. The outputs were recorded in the format: <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS1.p1.1.2">&lt;Question - Evaluation Tag - Answer - Model - Presence of Bias - Name of Bias&gt;</span>, more details in Appendix E.1.</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="138" id="S6.F4.g1" src="extracted/5904870/static_frequent.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S6.F4.2.1">Cognitive Bias Frequency in LLMs</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS2.SSS1.p2">
<p class="ltx_p" id="S6.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS1.p2.1.1">Evaluation Approach:</span> Preceding experiments validated GPT-4 was an effective evaluator. Here, we utilized GPT-4 to assess the LLMs‚Äô performance on MindScope.</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS1.p3">
<p class="ltx_p" id="S6.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS1.p3.1.1">Frequency Analysis of Cognitive Biases:</span> Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.F4" title="Figure 4 ‚Ä£ 6.2.1 Cognitive bias detection in static dataset ‚Ä£ 6.2 Cognitive bias in different LLMs ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">4</span></a> reveals cognitive bias frequencies in 12 LLMs. GPT-4 showed the lowest, while ChatGLM-6B had the highest, which mainly trained on Chinese. From Llama2-7b to Llama2-70B and Vicuna-7b to Vicuna-33B, the degree of cognitive bias decreased with the increase of model parameters. Intriguingly, we also noted that fine-tuning models could introduce new cognitive biases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib14" title="">14</a>]</cite>. The Vicuna series, derived from extensive fine-tuning of the Llama2 system, generally exhibited higher cognitive bias frequencies than the Llama2 series, warranting further investigation and attention. Lastly, the Gemini-Pro model opts to refuse answers when facing elements with potential biases (like race or gender), although it prevents direct expression of bias, it is not a standard approach for other LLMs.</p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="502" id="S6.F5.g1" src="extracted/5904870/half_more.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S6.F5.2.1">Cognitive Bias Frequency in LLMs</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS2.SSS1.p4">
<p class="ltx_p" id="S6.SS2.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS1.p4.1.1">Inter-Model Analysis of Cognitive Biases: </span>We visualized the extent of various cognitive biases across 12 LLMs using heatmaps, ranging from 0 (no occurrence) to 1 (highest frequency ratio). Due to space constraints, we only display heatmaps for four models, with the rest in Appendix E.1.
Firstly, we can find that the ten models show poor performance in IKEA effect, Impact bias, and subadditivity effect. Next we will give the examples to analyze the harm when LLMs make decision with these cognitive biases.</p>
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">IKEA Effect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib26" title="">26</a>]</cite>: </span>Defined as the tendency to overvalue an object due to personal labor or emotional investment, a significant IKEA effect was evident in all ten models. This indicates that LLMs may overrate their generated content, leading to difficulty in self-correcting errors or inaccuracies during generation. Additionally, there‚Äôs a risk of neglecting user feedback, as the model may continue producing what it "believes" to be quality content, thus failing to meet user needs.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">Impact Bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib37" title="">37</a>]</cite>:</span> This bias refers to the tendency to overestimate the duration or intensity of future emotional states. In LLMs, impact bias could lead to overestimating or underestimating the influence of certain inputs or events, resulting in predictions or generated outcomes that are significantly misaligned with reality, affecting the effectiveness of decision-making.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S6.SS2.SSS1.p5">
<p class="ltx_p" id="S6.SS2.SSS1.p5.1">Secondly, GPT-4 exhibited the fewest cognitive biases. However, it showed some pronounced biases such as the Framing Effect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib17" title="">17</a>]</cite>, Risk Compensation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib3" title="">3</a>]</cite>, and so on. In comparing Llama2-7B with Llama2-70B, an increase in model size generally led to a reduction in most cognitive biases. Yet, for certain biases, such as the Curse of Knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib8" title="">8</a>]</cite> and Survivorship Bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#bib.bib7" title="">7</a>]</cite>, the opposite was true. A similar trend was observed in the Vicuna series. These findings show that merely increasing model size does not alleviate all cognitive biases.</p>
</div>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="138" id="S6.F6.g1" src="extracted/5904870/dy_frequent.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="S6.F6.2.1">Cognitive Bias Frequency in LLMs</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S6.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>Cognitive bias detection in dynamic datasets</h4>
<div class="ltx_para" id="S6.SS2.SSS2.p1">
<p class="ltx_p" id="S6.SS2.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p1.1.1">Testing Methodology</span>: We employed RuleGen for transforming scripts into test samples formatted as mulit-round dialogues, including initializing system agents and role agents, and controlling the interaction based on the rules. We used GPT4 to detect whether the Subject agent has the cognitive bias, more detail in Appendix E.2.</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS2.p2">
<p class="ltx_p" id="S6.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p2.1.1">Result analysis.</span> We systematically tested 12 different cognitive biases in dynamic scenarios. As indicated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.F5" title="Figure 5 ‚Ä£ 6.2.1 Cognitive bias detection in static dataset ‚Ä£ 6.2 Cognitive bias in different LLMs ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">5</span></a>, in the static evaluation data, both GPT-4 and GPT-3.5 showed almost no cognitive biases in Sunk Cost Fallacy, Planning Fallacy, and Unit Bias. However, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.F6" title="Figure 6 ‚Ä£ 6.2.1 Cognitive bias detection in static dataset ‚Ä£ 6.2 Cognitive bias in different LLMs ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">6</span></a>, these cognitive biases were significantly more pronounced in multi-round dialogues. That demonstrates a notable difference from the static dataset. This finding reveals that cognitive biases may be more prominent in complex interactions.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>The effectiveness of the detection framework</h3>
<section class="ltx_subsubsection" id="S6.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.1 </span>evaluation metrics</h4>
<div class="ltx_para" id="S6.SS3.SSS1.p1">
<ul class="ltx_itemize" id="S6.I2">
<li class="ltx_item" id="S6.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S6.I2.i1.p1">
<p class="ltx_p" id="S6.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I2.i1.p1.1.1">Overall Accuracy(Acc (%))</span>: The ratio of cases correctly identified by the algorithm to the total number of cases.</p>
</div>
</li>
<li class="ltx_item" id="S6.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S6.I2.i2.p1">
<p class="ltx_p" id="S6.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I2.i2.p1.1.1">Bias Case Accuracy(Acc<sub class="ltx_sub" id="S6.I2.i2.p1.1.1.1">bias</sub> (%))</span>: The proportion of actual bias-present cases that the algorithm correctly identifies.</p>
</div>
</li>
<li class="ltx_item" id="S6.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S6.I2.i3.p1">
<p class="ltx_p" id="S6.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I2.i3.p1.1.1">No-Bias Case Accuracy(Acc<sub class="ltx_sub" id="S6.I2.i3.p1.1.1.1">nobias</sub> (%))</span>: The proportion of actual bias-absent cases that the algorithm correctly identifies.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.2 </span>Main Results</h4>
<div class="ltx_para" id="S6.SS3.SSS2.p1">
<p class="ltx_p" id="S6.SS3.SSS2.p1.1">We utilized 301 static test samples annotated by psychology experts as a test dataset.
As Table <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.T2" title="Table 2 ‚Ä£ 6.3.3 Ablation Study ‚Ä£ 6.3 The effectiveness of the detection framework ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates, our multi-agent detection method significantly outperforms existing techniques. Compared to GPT-4, our method improved overall accuracy by 35.10%. This notable enhancement is especially prominent in complex cases with cognitive biases, where our detection accuracy for such cases increased by nearly 26.48% compared to GPT-4. The experimental results indicate a clear advantage of our method in identifying cases with cognitive biases. Moreover, in cases without cognitive biases, our method achieved an improvement of approximately 38.37% over GPT-4.</p>
</div>
<figure class="ltx_table" id="S6.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance evaluation of different methods</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T1.1">
<tr class="ltx_tr" id="S6.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.1.1.1">Methods</span></td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S6.T1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.1.2.1">
<span class="ltx_p" id="S6.T1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.1.2.1.1.1">Acc(%)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S6.T1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.1.3.1">
<span class="ltx_p" id="S6.T1.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.1.3.1.1.1">Acc<sub class="ltx_sub" id="S6.T1.1.1.3.1.1.1.1">bias</sub>(%)</span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_tt" id="S6.T1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.1.4.1">
<span class="ltx_p" id="S6.T1.1.1.4.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.1.4.1.1.1">Acc<sub class="ltx_sub" id="S6.T1.1.1.4.1.1.1.1">nobias</sub>(%)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T1.1.2.1">GPT-4</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S6.T1.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.2.2.1">
<span class="ltx_p" id="S6.T1.1.2.2.1.1">34.43</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S6.T1.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.2.3.1">
<span class="ltx_p" id="S6.T1.1.2.3.1.1">37.80</span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" id="S6.T1.1.2.4">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.2.4.1">
<span class="ltx_p" id="S6.T1.1.2.4.1.1">33.18</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T1.1.3">
<td class="ltx_td ltx_align_left" id="S6.T1.1.3.1">GPT-4+CoT</td>
<td class="ltx_td ltx_align_justify" id="S6.T1.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.3.2.1">
<span class="ltx_p" id="S6.T1.1.3.2.1.1">36.75</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S6.T1.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.3.3.1">
<span class="ltx_p" id="S6.T1.1.3.3.1.1">31.70</span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify" id="S6.T1.1.3.4">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.3.4.1">
<span class="ltx_p" id="S6.T1.1.3.4.1.1">38.63</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T1.1.4">
<td class="ltx_td ltx_align_left" id="S6.T1.1.4.1">CAMEL based GPT-4</td>
<td class="ltx_td ltx_align_justify" id="S6.T1.1.4.2">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.4.2.1">
<span class="ltx_p" id="S6.T1.1.4.2.1.1">29.13</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S6.T1.1.4.3">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.4.3.1">
<span class="ltx_p" id="S6.T1.1.4.3.1.1">25.60</span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify" id="S6.T1.1.4.4">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.4.4.1">
<span class="ltx_p" id="S6.T1.1.4.4.1.1">30.45</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T1.1.5">
<td class="ltx_td ltx_align_left" id="S6.T1.1.5.1">AutoGen based GPT-4</td>
<td class="ltx_td ltx_align_justify" id="S6.T1.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.5.2.1">
<span class="ltx_p" id="S6.T1.1.5.2.1.1">42.71</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S6.T1.1.5.3">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.5.3.1">
<span class="ltx_p" id="S6.T1.1.5.3.1.1">9.75</span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify" id="S6.T1.1.5.4">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.5.4.1">
<span class="ltx_p" id="S6.T1.1.5.4.1.1">55.01</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T1.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T1.1.6.1">Ours based GPT-4</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S6.T1.1.6.2">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.6.2.1">
<span class="ltx_p" id="S6.T1.1.6.2.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.6.2.1.1.1">69.53</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S6.T1.1.6.3">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.6.3.1">
<span class="ltx_p" id="S6.T1.1.6.3.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.6.3.1.1.1">64.28</span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_bb" id="S6.T1.1.6.4">
<span class="ltx_inline-block ltx_align_top" id="S6.T1.1.6.4.1">
<span class="ltx_p" id="S6.T1.1.6.4.1.1"><span class="ltx_text ltx_font_bold" id="S6.T1.1.6.4.1.1.1">71.55</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S6.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.3 </span>Ablation Study</h4>
<div class="ltx_para" id="S6.SS3.SSS3.p1">
<p class="ltx_p" id="S6.SS3.SSS3.p1.1">First, we analyzed the basic framework combining candidate generation and knowledge retrieval to detect cognitive biases. An initial agent identifies biases and construct the candidate set. The final detection is made by another agent. Next, we added the pruned loser tree method to improve debate and decision-making among agents, with a referee agent finalizing the decision. Lastly, we integrated a reinforcement learning decision module to enhance the referee agent‚Äôs decision-making and adaptability. Results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.T2" title="Table 2 ‚Ä£ 6.3.3 Ablation Study ‚Ä£ 6.3 The effectiveness of the detection framework ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">2</span></a> show notable improvements. Also as shown in Table 3, we use various optimization algorithms on our selected debate scenario training set as well as test set. The results show that the optimization of weights by reinforcement learning is optimal on both the training and test sets. The specific experimental setup can be found in Appendix F.2.</p>
</div>
<figure class="ltx_table" id="S6.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation studies. Comparison of module performance</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T2.1">
<tr class="ltx_tr" id="S6.T2.1.1">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S6.T2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.1.1.1">
<span class="ltx_p" id="S6.T2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.1.1.1">Module</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.2.1">(A)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.3.1">(B)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.4.1">(C)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.5.1">Ours</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.2">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S6.T2.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.2.1.1">
<span class="ltx_p" id="S6.T2.1.2.1.1.1">Candidate set+Detection agents</span>
</span>
</td>
<td class="ltx_td ltx_border_t" id="S6.T2.1.2.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.3">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.4">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.5">‚úì</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.3">
<td class="ltx_td ltx_align_justify" id="S6.T2.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.3.1.1">
<span class="ltx_p" id="S6.T2.1.3.1.1.1">Loser tree+Referee agents</span>
</span>
</td>
<td class="ltx_td" id="S6.T2.1.3.2"></td>
<td class="ltx_td" id="S6.T2.1.3.3"></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.4">‚úì</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.5">‚úì</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.4">
<td class="ltx_td ltx_align_justify" id="S6.T2.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.4.1.1">
<span class="ltx_p" id="S6.T2.1.4.1.1.1">Decision module</span>
</span>
</td>
<td class="ltx_td" id="S6.T2.1.4.2"></td>
<td class="ltx_td" id="S6.T2.1.4.3"></td>
<td class="ltx_td" id="S6.T2.1.4.4"></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.4.5">‚úì</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.5">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S6.T2.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.5.1.1">
<span class="ltx_p" id="S6.T2.1.5.1.1.1">Acc (%)</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.5.2">34.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.5.3">39.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.5.4">59.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.5.5"><span class="ltx_text ltx_font_bold" id="S6.T2.1.5.5.1">69.53</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.6">
<td class="ltx_td ltx_align_justify" id="S6.T2.1.6.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.6.1.1">
<span class="ltx_p" id="S6.T2.1.6.1.1.1">Acc<sub class="ltx_sub" id="S6.T2.1.6.1.1.1.1">bias</sub> (%)</span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.2">37.80</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.3">37.80</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.4">43.90</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.5"><span class="ltx_text ltx_font_bold" id="S6.T2.1.6.5.1">64.28</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.7">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S6.T2.1.7.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T2.1.7.1.1">
<span class="ltx_p" id="S6.T2.1.7.1.1.1">Acc<sub class="ltx_sub" id="S6.T2.1.7.1.1.1.1">nobias</sub> (%)</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.7.2">33.18</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.7.3">40.45</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.7.4">65.90</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.7.5"><span class="ltx_text ltx_font_bold" id="S6.T2.1.7.5.1">71.55</span></td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S6.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of Decision Module Accuracy under Different Algorithms</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T3.1">
<tr class="ltx_tr" id="S6.T3.1.1">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S6.T3.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T3.1.1.1.1">
<span class="ltx_p" id="S6.T3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.1.1.1">Algorithms</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T3.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.2.1">Acc<sub class="ltx_sub" id="S6.T3.1.1.2.1.1">train</sub>(%)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T3.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.3.1">Acc<sub class="ltx_sub" id="S6.T3.1.1.3.1.1">test</sub>(%)</span></td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.2">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S6.T3.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T3.1.2.1.1">
<span class="ltx_p" id="S6.T3.1.2.1.1.1">Genetic Algorithm(GA)</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.1.2.2">91.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.1.2.3">86.95</td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.3">
<td class="ltx_td ltx_align_justify" id="S6.T3.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T3.1.3.1.1">
<span class="ltx_p" id="S6.T3.1.3.1.1.1">Simulated annealing Algorithm(SAA)</span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T3.1.3.2">88.33</td>
<td class="ltx_td ltx_align_center" id="S6.T3.1.3.3">79.51</td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.4">
<td class="ltx_td ltx_align_justify" id="S6.T3.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T3.1.4.1.1">
<span class="ltx_p" id="S6.T3.1.4.1.1.1">Ant Colony Optimization(ACO)</span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T3.1.4.2">86.38</td>
<td class="ltx_td ltx_align_center" id="S6.T3.1.4.3">75.90</td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.5">
<td class="ltx_td ltx_align_justify ltx_border_b" id="S6.T3.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S6.T3.1.5.1.1">
<span class="ltx_p" id="S6.T3.1.5.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.1.5.1.1.1.1">DQN+GA search</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S6.T3.1.5.2"><span class="ltx_text ltx_font_bold" id="S6.T3.1.5.2.1">92.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S6.T3.1.5.3"><span class="ltx_text ltx_font_bold" id="S6.T3.1.5.3.1">89.15</span></td>
</tr>
</table>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Case study</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">To explore how different decision-making styles affect cognitive biases in LLMs, we crafted a scenario script and use RuleGen to generate the multi-round dialogues. The key focus was on the character ‚ÄôSubject‚Äô to assess the impact of the sunk cost effect. We simulated this scenario twice, once with an aggressive and once with a conservative decision-making style. As shown by the red text in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04452v1#S6.F7" title="Figure 7 ‚Ä£ 6.4 Case study ‚Ä£ 6 Experiments ‚Ä£ MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems"><span class="ltx_text ltx_ref_tag">7</span></a>, the sunk cost effect emerged in the aggressive style but not in the conservative. This indicates that decision-making styles can influence the occurrence of cognitive biases in LLMs.</p>
</div>
<figure class="ltx_figure" id="S6.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="735" id="S6.F7.g1" src="x4.png" width="788"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Case study in investment scenario</figcaption>
</figure>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">In summary, GPT-4 has robust capability in detecting cognitive biases under labeled conditions. For static datasets, we evaluated 12 LLMs, focusing on the differences in cognitive biases. The results indicate that different LLMs have significant disparities in cognitive biases, but the overall trend suggests that stronger LLMs have lower frequencies of cognitive biases. In dynamic datasets, we assessed the bias results of GPT-4 and GPT-3.5, confirming our hypothesis of higher frequency cognitive biases in multi-turn dialogues. Through a range of quantitative experiments, we validated that our detection framework outperforms current multi-agent frameworks. Moreover, ablation studies confirmed the significant effectiveness of the learnable MCDA module.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This paper introduces a new benchmark called MindScope for exploring the cognitive biases of LLMs. MindScope consists of both static and dynamic parts, resulting in a series of interesting findings for decision-making and model tuning. In particular, based on our proposed RuleGen, multi-round conversation can be generated controllably through a simple script. Users also can generate large personalized dataset and complete many psychological experiments by RuleGen. Moreover, we introduce a multi-agent detection method using loser trees and a decision module based on reinforcement learning for cognitive bias detection without labels.</p>
</div>
<div class="ltx_para" id="S7.p2">
<span class="ltx_ERROR undefined" id="S7.p2.1">{ack}</span>
<p class="ltx_p" id="S7.p2.2">This work is supported by the National Natural Science Foundation of China (Grant No. 62207013), the Science and Technology Commission of Shanghai Municipality (Grant No. 22511106103), and CCF-Baidu202322.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et¬†al. [2022]</span>
<span class="ltx_bibblock">
M.¬†Agrawal, S.¬†Hegselmann, H.¬†Lang, Y.¬†Kim, and D.¬†Sontag.

</span>
<span class="ltx_bibblock">Large language models are few-shot clinical information extractors.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 26th Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1998‚Äì2022, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aher et¬†al. [2023]</span>
<span class="ltx_bibblock">
G.¬†V. Aher, R.¬†I. Arriaga, and A.¬†T. Kalai.

</span>
<span class="ltx_bibblock">Using large language models to simulate multiple humans and replicate human subject studies.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 40th International Conference on Machine Learning (ICML)</em>, pages 337‚Äì371, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assum et¬†al. [1999]</span>
<span class="ltx_bibblock">
T.¬†Assum, T.¬†Bj√∏rnskau, S.¬†Fosser, and F.¬†Sagberg.

</span>
<span class="ltx_bibblock">Risk compensation‚Äîthe case of road lighting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Accident Analysis &amp; Prevention</em>, 31(5):545‚Äì553, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Atreides and Kelley [2023]</span>
<span class="ltx_bibblock">
K.¬†Atreides and D.¬†J. Kelley.

</span>
<span class="ltx_bibblock">Cognitive biases in natural language: Automatically detecting, differentiating, and measuring bias in text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Differentiating, and Measuring Bias in Text</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baron [2023]</span>
<span class="ltx_bibblock">
J.¬†Baron.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Thinking and deciding</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biber et¬†al. [2021]</span>
<span class="ltx_bibblock">
D.¬†Biber, J.¬†Egbert, D.¬†Keller, and S.¬†Wizner.

</span>
<span class="ltx_bibblock">Towards a taxonomy of conversational discourse types: An empirical corpus-based analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Journal of Pragmatics</em>, 171:20‚Äì35, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et¬†al. [1992]</span>
<span class="ltx_bibblock">
S.¬†J. Brown, W.¬†Goetzmann, R.¬†G. Ibbotson, and S.¬†A. Ross.

</span>
<span class="ltx_bibblock">Survivorship bias in performance studies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">The Review of Financial Studies</em>, 5(4):553‚Äì580, 1992.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Camerer et¬†al. [1989]</span>
<span class="ltx_bibblock">
C.¬†Camerer, G.¬†Loewenstein, and M.¬†Weber.

</span>
<span class="ltx_bibblock">The curse of knowledge in economic settings: An experimental analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Journal of political Economy</em>, 97(5):1232‚Äì1254, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et¬†al. [2024]</span>
<span class="ltx_bibblock">
W.¬†Chen, Y.¬†Su, J.¬†Zuo, C.¬†Yang, C.¬†Yuan, C.-M. Chan, H.¬†Yu, Y.¬†Lu, Y.-H. Hung, C.¬†Qian, Y.¬†Qin, X.¬†Cong, R.¬†Xie, Z.¬†Liu, M.¬†Sun, and J.¬†Zhou.

</span>
<span class="ltx_bibblock">Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 12th International Conference on Learning Representations (ICLR)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Daniel [1982]</span>
<span class="ltx_bibblock">
K.¬†Daniel.

</span>
<span class="ltx_bibblock">Judgment under uncertainty: Heuristics and biases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Facts versus fears: Understanding perceived risk</em>, pages 463‚Äì489, 1982.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et¬†al. [2023]</span>
<span class="ltx_bibblock">
Y.¬†Du, S.¬†Li, A.¬†Torralba, J.¬†B. Tenenbaum, and I.¬†Mordatch.

</span>
<span class="ltx_bibblock">Improving factuality and reasoning in language models through multiagent debate.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint arXiv:2305.14325</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Echterhoff et¬†al. [2024]</span>
<span class="ltx_bibblock">
J.¬†Echterhoff, Y.¬†Liu, A.¬†Alessa, J.¬†McAuley, and Z.¬†He.

</span>
<span class="ltx_bibblock">Cognitive bias in high-stakes decision-making with llms, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et¬†al. [2024]</span>
<span class="ltx_bibblock">
S.¬†Hong, M.¬†Zhuge, J.¬†Chen, X.¬†Zheng, Y.¬†Cheng, J.¬†Wang, C.¬†Zhang, Z.¬†Wang, S.¬†K.¬†S. Yau, Z.¬†Lin, L.¬†Zhou, C.¬†Ran, L.¬†Xiao, C.¬†Wu, and J.¬†Schmidhuber.

</span>
<span class="ltx_bibblock">MetaGPT: Meta programming for a multi-agent collaborative framework.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 12th International Conference on Learning Representations (ICLR)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Itzhak et¬†al. [2024]</span>
<span class="ltx_bibblock">
I.¬†Itzhak, G.¬†Stanovsky, N.¬†Rosenfeld, and Y.¬†Belinkov.

</span>
<span class="ltx_bibblock">Instructed to bias: Instruction-tuned language models exhibit emergent cognitive bias.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Transactions of the Association for Computational Linguistics</em>, 12:771‚Äì785, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jinxin et¬†al. [2023]</span>
<span class="ltx_bibblock">
S.¬†Jinxin, Z.¬†Jiabao, W.¬†Yilei, W.¬†Xingjiao, L.¬†Jiawen, and H.¬†Liang.

</span>
<span class="ltx_bibblock">Cgmi: Configurable general multi-agent interaction framework.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint arXiv:2308.12503</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jones and Steinhardt [2022]</span>
<span class="ltx_bibblock">
E.¬†Jones and J.¬†Steinhardt.

</span>
<span class="ltx_bibblock">Capturing failures of large language models via human cognitive biases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, 35:11785‚Äì11799, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kahneman and Tversky [2013]</span>
<span class="ltx_bibblock">
D.¬†Kahneman and A.¬†Tversky.

</span>
<span class="ltx_bibblock">Prospect theory: An analysis of decision under risk.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Handbook of the fundamentals of financial decision making: Part I</em>, pages 99‚Äì127. 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koo et¬†al. [2024]</span>
<span class="ltx_bibblock">
R.¬†Koo, M.¬†Lee, V.¬†Raheja, J.¬†I. Park, Z.¬†M. Kim, and D.¬†Kang.

</span>
<span class="ltx_bibblock">Benchmarking cognitive biases in large language models as evaluators.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 62nd Association for Computational Linguistics (ACL)</em>, pages 517‚Äì545, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kruger and Dunning [1999]</span>
<span class="ltx_bibblock">
J.¬†Kruger and D.¬†Dunning.

</span>
<span class="ltx_bibblock">Unskilled and unaware of it: how difficulties in recognizing one‚Äôs own incompetence lead to inflated self-assessments.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Journal of personality and social psychology</em>, 77(6):1121, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et¬†al. [2023a]</span>
<span class="ltx_bibblock">
G.¬†Li, H.¬†A. A.¬†K. Hammoud, H.¬†Itani, D.¬†Khizbullin, and B.¬†Ghanem.

</span>
<span class="ltx_bibblock">CAMEL: Communicative agents for ‚Äùmind‚Äù exploration of large language model society.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 37th Neural Information Processing Systems (NeurIPS)</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et¬†al. [2023b]</span>
<span class="ltx_bibblock">
Y.¬†Li, Y.¬†Yu, H.¬†Li, Z.¬†Chen, and K.¬†Khashanah.

</span>
<span class="ltx_bibblock">Tradinggpt: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint arXiv:2309.03736</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Ng [2023]</span>
<span class="ltx_bibblock">
R.¬†Lin and H.¬†T. Ng.

</span>
<span class="ltx_bibblock">Mind the biases: Quantifying cognitive biases in language model prompting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 61st Association for Computational Linguistics (ACL)</em>, pages 5269‚Äì5281, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macmillan-Scott and Musolesi [2024]</span>
<span class="ltx_bibblock">
O.¬†Macmillan-Scott and M.¬†Musolesi.

</span>
<span class="ltx_bibblock">(ir) rationality and cognitive biases in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Royal Society Open Science</em>, 11(6):240255, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mnih et¬†al. [2013]</span>
<span class="ltx_bibblock">
V.¬†Mnih, K.¬†Kavukcuoglu, D.¬†Silver, A.¬†Graves, I.¬†Antonoglou, D.¬†Wierstra, and M.¬†Riedmiller.

</span>
<span class="ltx_bibblock">Playing atari with deep reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Preprint arXiv:1312.5602</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et¬†al. [2023]</span>
<span class="ltx_bibblock">
H.¬†Nori, Y.¬†T. Lee, S.¬†Zhang, D.¬†Carignan, R.¬†Edgar, N.¬†Fusi, N.¬†King, J.¬†Larson, Y.¬†Li, W.¬†Liu, et¬†al.

</span>
<span class="ltx_bibblock">Can generalist foundation models outcompete special-purpose tuning? case study in medicine.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint arXiv:2311.16452</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Norton et¬†al. [2012]</span>
<span class="ltx_bibblock">
M.¬†I. Norton, D.¬†Mochon, and D.¬†Ariely.

</span>
<span class="ltx_bibblock">The ikea effect: When labor leads to love.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Journal of consumer psychology</em>, 22(3):453‚Äì460, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et¬†al. [2023]</span>
<span class="ltx_bibblock">
J.¬†S. Park, J.¬†O‚ÄôBrien, C.¬†J. Cai, M.¬†R. Morris, P.¬†Liang, and M.¬†S. Bernstein.

</span>
<span class="ltx_bibblock">Generative agents: Interactive simulacra of human behavior.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology (UIST)</em>, pages 1‚Äì22, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian et¬†al. [2024]</span>
<span class="ltx_bibblock">
C.¬†Qian, Y.¬†Dang, J.¬†Li, W.¬†Liu, Z.¬†Xie, Y.¬†Wang, W.¬†Chen, C.¬†Yang, X.¬†Cong, X.¬†Che, Z.¬†Liu, and M.¬†Sun.

</span>
<span class="ltx_bibblock">Experiential co-learning of software-developing agents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)</em>, pages 5628‚Äì5640, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schmidgall et¬†al. [2024]</span>
<span class="ltx_bibblock">
S.¬†Schmidgall, C.¬†Harris, I.¬†Essien, D.¬†Olshvang, T.¬†Rahman, J.¬†W. Kim, R.¬†Ziaei, J.¬†Eshraghian, P.¬†Abadir, and R.¬†Chellappa.

</span>
<span class="ltx_bibblock">Addressing cognitive bias in medical language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Preprint arXiv:2402.08113</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et¬†al. [2023]</span>
<span class="ltx_bibblock">
M.¬†Sharma, K.¬†Singh, P.¬†Aggarwal, and V.¬†Dutt.

</span>
<span class="ltx_bibblock">How well does gpt phish people? an investigation involving cognitive biases and feedback.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&amp;PW)</em>, pages 451‚Äì457, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et¬†al. [2023]</span>
<span class="ltx_bibblock">
K.¬†Singhal, S.¬†Azizi, T.¬†Tu, S.¬†S. Mahdavi, J.¬†Wei, H.¬†W. Chung, N.¬†Scales, A.¬†Tanwani, H.¬†Cole-Lewis, S.¬†Pfohl, et¬†al.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Nature</em>, 620(7972):172‚Äì180, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et¬†al. [2023]</span>
<span class="ltx_bibblock">
G.¬†Team, R.¬†Anil, S.¬†Borgeaud, Y.¬†Wu, J.-B. Alayrac, J.¬†Yu, R.¬†Soricut, J.¬†Schalkwyk, A.¬†M. Dai, A.¬†Hauth, et¬†al.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Preprint arXiv:2312.11805</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et¬†al. [2023]</span>
<span class="ltx_bibblock">
H.¬†Touvron, T.¬†Lavril, G.¬†Izacard, X.¬†Martinet, M.-A. Lachaux, T.¬†Lacroix, B.¬†Rozi√®re, N.¬†Goyal, E.¬†Hambro, F.¬†Azhar, et¬†al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tversky and Kahneman [1974]</span>
<span class="ltx_bibblock">
A.¬†Tversky and D.¬†Kahneman.

</span>
<span class="ltx_bibblock">Judgment under uncertainty: Heuristics and biases: Biases in judgments reveal some heuristics of thinking under uncertainty.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Science</em>, 185(4157):1124‚Äì1131, 1974.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et¬†al. [2023]</span>
<span class="ltx_bibblock">
S.¬†Wang, C.¬†Liu, Z.¬†Zheng, S.¬†Qi, S.¬†Chen, Q.¬†Yang, A.¬†Zhao, C.¬†Wang, S.¬†Song, and G.¬†Huang.

</span>
<span class="ltx_bibblock">Avalon‚Äôs game of thoughts: Battle against deception through recursive contemplation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Preprint arXiv:2310.01320</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et¬†al. [2022]</span>
<span class="ltx_bibblock">
J.¬†Wei, X.¬†Wang, D.¬†Schuurmans, M.¬†Bosma, F.¬†Xia, E.¬†Chi, Q.¬†V. Le, D.¬†Zhou, et¬†al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Advances in Neural Information Processing Systems</em>, 35:24824‚Äì24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilson and Gilbert [2013]</span>
<span class="ltx_bibblock">
T.¬†D. Wilson and D.¬†T. Gilbert.

</span>
<span class="ltx_bibblock">The impact bias is alive and well.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Journal of Personality and Social Psychology</em>, 105(5):740‚Äì748, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et¬†al. [2024]</span>
<span class="ltx_bibblock">
Q.¬†Wu, G.¬†Bansal, J.¬†Zhang, Y.¬†Wu, B.¬†Li, E.¬†Zhu, L.¬†Jiang, X.¬†Zhang, S.¬†Zhang, J.¬†Liu, A.¬†H. Awadallah, R.¬†W. White, D.¬†Burger, and C.¬†Wang.

</span>
<span class="ltx_bibblock">Autogen: Enabling next-gen LLM applications via multi-agent conversation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 12th International Conference on Learning Representations (ICLR) Workshop on Large Language Model (LLM) Agents</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et¬†al. [2023]</span>
<span class="ltx_bibblock">
S.¬†Wu, O.¬†Irsoy, S.¬†Lu, V.¬†Dabravolski, M.¬†Dredze, S.¬†Gehrmann, P.¬†Kambadur, D.¬†Rosenberg, and G.¬†Mann.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Preprint arXiv:2303.17564</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et¬†al. [2024]</span>
<span class="ltx_bibblock">
C.¬†Ye, E.¬†Zweck, Z.¬†Ma, J.¬†Smith, and S.¬†Katz.

</span>
<span class="ltx_bibblock">Doctor versus artificial intelligence: Patient and physician evaluation of large language model responses to rheumatology patient questions in a cross-sectional study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Arthritis &amp; Rheumatology</em>, 76(3):479‚Äì484, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et¬†al. [2024]</span>
<span class="ltx_bibblock">
H.¬†Zhang, W.¬†Du, J.¬†Shan, Q.¬†Zhou, Y.¬†Du, J.¬†B. Tenenbaum, T.¬†Shu, and C.¬†Gan.

</span>
<span class="ltx_bibblock">Building cooperative embodied agents modularly with large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 12th International Conference on Learning Representations (ICLR)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et¬†al. [2021]</span>
<span class="ltx_bibblock">
Z.¬†Zhao, E.¬†Wallace, S.¬†Feng, D.¬†Klein, and S.¬†Singh.

</span>
<span class="ltx_bibblock">Calibrate before use: Improving few-shot performance of language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 38th International Conference on Machine Learning (ICML)</em>, pages 12697‚Äì12706, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et¬†al. [2023a]</span>
<span class="ltx_bibblock">
L.¬†Zheng, W.-L. Chiang, Y.¬†Sheng, S.¬†Zhuang, Z.¬†Wu, Y.¬†Zhuang, Z.¬†Lin, Z.¬†Li, D.¬†Li, E.¬†Xing, H.¬†Zhang, J.¬†E. Gonzalez, and I.¬†Stoica.

</span>
<span class="ltx_bibblock">Judging LLM-as-a-judge with MT-bench and chatbot arena.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 37th Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS)</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et¬†al. [2023b]</span>
<span class="ltx_bibblock">
Z.¬†Zheng, O.¬†Zhang, H.¬†L. Nguyen, N.¬†Rampal, A.¬†H. Alawadhi, Z.¬†Rong, T.¬†Head-Gordon, C.¬†Borgs, J.¬†T. Chayes, and O.¬†M. Yaghi.

</span>
<span class="ltx_bibblock">Chatgpt research group for optimizing the crystallinity of mofs and cofs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">ACS Central Science</em>, 9(11):2161‚Äì2170, 2023b.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Oct  6 11:11:51 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
