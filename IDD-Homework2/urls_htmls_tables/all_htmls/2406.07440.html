<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Textual Similarity as a Key Metric in Machine Translation Quality Estimation</title>
<!--Generated on Mon Jul  1 09:30:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.07440v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S1" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2.SS1" title="In 2 Methods â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2.SS2" title="In 2 Methods â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Textual similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2.SS3" title="In 2 Methods â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Regression statistical analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.SS1" title="In 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Result 1: Correlations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.SS2" title="In 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Result 2: Cross language pairs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.SS3" title="In 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Result 3: Individual language pair</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S4" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:173%;">Textual Similarity as a Key Metric in Machine Translation Quality Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text" id="id1.1.id1" style="font-size:80%;">Kun Sun</span>
</span><span class="ltx_author_notes"><span class="ltx_text ltx_font_typewriter" id="id2.2.id1" style="font-size:80%;">kun.sun@uni-tuebingen.de</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text" id="id3.3.id1" style="font-size:80%;">Department of Linguistics, University of TÃ¼bingen, Germany</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text" id="id4.1.id1" style="font-size:80%;">Rong Wang</span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Institute of Natural Language Processing, Stuttgart University, Stuttgart, Germany
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1"><span class="ltx_text" id="id5.id1.1" lang="en" style="font-size:80%;">Machine Translation (MT) Quality Estimation (QE) assesses translation reliability without reference texts. This study introduces â€œtextual similarityâ€ as a new metric for QE, using sentence transformers and cosine similarity to measure semantic closeness. Analyzing data from the MLQE-PE dataset, we found that textual similarity exhibits stronger correlations with human scores than traditional metrics (hter, model evaluation, sentence probability etc.). Employing GAMMs as a statistical tool, we demonstrated that textual similarity consistently outperforms other metrics across multiple language pairs in predicting human scores. We also found that â€œhterâ€ actually failed to predict human scores in QE. Our findings highlight the effectiveness of textual similarity as a robust QE metric, recommending its integration with other metrics into QE frameworks and MT system training for improved accuracy and usability.</span></p>
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1" lang="en" style="font-size:90%;">Keywords:<span class="ltx_text ltx_font_medium" id="p1.1.1.1"> translation quality evaluation, sentence transformers, cosine similarity, regression analysis, key metric</span></span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><span class="ltx_text" id="S1.p1.1.1" style="font-size:90%;">There are two kinds of quality evaluations in machine translation (MT): â€œMT quality evaluationâ€ and â€œMT quality estimationâ€ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">13</span></a><span class="ltx_text" id="S1.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.4" style="font-size:90%;">. Each field has distinct standards and applications, ensuring comprehensive translation quality assessment. The former is used to compare the quality of translated texts when the reference translations are available. In contrast, the latter, also named as MT â€œquality estimation (QE)â€, involves assessing the quality of MT outputs without reference translations </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a><span class="ltx_text" id="S1.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.7" style="font-size:90%;">. QE is essential for various applications, such as determining whether an automatically translated sentence or document is ready for the end user or requires human post-editing. It can flag passages with critical errors, serve as a quality metric when reference translations are unavailable, and assist in computer-aided translation interfaces by highlighting text needing human revision and estimating the required human effort. The current study focuses on the latter, quality estimation.</span></p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1"><span class="ltx_text" id="S1.p2.1.1" style="font-size:90%;">â€œMT quality evaluationâ€ involves using various automatic metrics to assess translation accuracy and effort. Common metrics include BLEU, which measures n-gram overlap with reference translations and applies a brevity penalty; METEOR, which considers precision, recall, synonyms, and stemming; TER, which calculates the number of edits needed to match a reference translation; chrF, which evaluates character n-grams, useful for morphologically rich languages; and BERTScore, which uses pre-trained embeddings to assess semantic similarity. Moreover, supervised metrics, trained using human-judged data often show a higher correlation with human evaluations, and some metrics were used such as BEER, BLEND </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a><span class="ltx_text" id="S1.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p2.1.4" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text" id="S1.p3.1.1" style="font-size:90%;">However, in MT QE, several features play pivotal roles in both quality estimation and enhancing the overall translation process. The â€œmodel eveluationâ€ (ML_eval) quantifies the MT modelâ€™s confidence in its translations. This metric is typically derived from the log-likelihood of the translation given the source sentence. Higher scores reflect greater confidence, indicating that the translation aligns well with the modelâ€™s learned patterns from the training data. These scores are crucial for quality estimation TM systems, helping to predict the reliability of translations from TM models and highlight areas that may require further human intervention or correction </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2</span></a><span class="ltx_text" id="S1.p3.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.4" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a><span class="ltx_text" id="S1.p3.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.7" style="font-size:90%;">. Moreover, in many cases, sentences with higher probabilities from n-gram models do tend to be more natural-sounding. This is because these models are trained on large corpora of text, capturing common patterns in language use. Sentence probabilities for translated texts are also used to evaluate translation quality without reference translations.</span></p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text" id="S1.p4.1.1" style="font-size:90%;">Another significant feature is â€œhuman translation edit rateâ€ (hter) </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">12</span></a><span class="ltx_text" id="S1.p4.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p4.1.4" style="font-size:90%;">, and it measures the number of edits required to correct a translation output from MT to match a human reference. It accounts for insertions, deletions, substitutions, and shifts, providing a quantitative measure of the effort needed for post-editing. This makes </span><span class="ltx_text ltx_font_typewriter" id="S1.p4.1.5" style="font-size:90%;">hter</span><span class="ltx_text" id="S1.p4.1.6" style="font-size:90%;"> a practical metric for assessing the quality of MT systems, as it directly correlates with the human effort required to produce accurate translations.</span></p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text" id="S1.p5.1.1" style="font-size:90%;">In MT quality estimation, â€œML_evalâ€ often serve as one key feature in helping to gauge the reliability and quality of TM systems when the reference translations are not available. The metric of â€œML_evalâ€, combined with linguistic features and contextual embeddings, enhance the accuracy of TM quality assessments. They help identify translations that may require human review or post-editing. Further, in the training or fine-tuning of NMT (neural machine translation) or LLMs-based TM models, the metric of â€œML_evalâ€ still plays an important role, such as on optimizing translation performance by leveraging large parallel corpora, word alignments, and contextual learning techniques </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p5.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a><span class="ltx_text" id="S1.p5.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p5.1.4" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p5.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">9</span></a><span class="ltx_text" id="S1.p5.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p5.1.7" style="font-size:90%;">. Even if the metric is not directly used in training or fine-tuning, it still could provide valuable feedback on the translation quality, guiding iterative improvements and fine-tuning of the model. This distinction underscores the dual role of â€œML_evalâ€ in both evaluating and enhancing translation quality.</span></p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text" id="S1.p6.1.1" style="font-size:90%;">While â€œML_evalâ€ provides valuable insights into QE, the metric has certain limitations. One significant issue is the tendency to overestimate confidence in poor translations, often due to overfitting or a lack of diverse training data. This overconfidence can lead to inaccuracies in QE. Moreover, the metric is sensitive to the training data distribution, and meaning biases or gaps in the data can skew the scores. Third, this metric may also fail to capture contextual meaning and subtle semantic differences that human evaluators can detect, leading to discrepancies between model scores and perceived translation quality. Additionally, although higher probability from an n-gram model often correlates with more natural-sounding sentences, this metric may not be a ideal indicator. The reason for this is that the relationship between statistical probability and perceived naturalness is complex and influenced by many factors beyond n-gram probabilities.</span></p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text" id="S1.p7.1.1" style="font-size:90%;">The metric, â€œhterâ€, has also some weaknesses. First, the variability in human editing styles and preferences can lead to inconsistent hter scores, making it challenging to standardize quality assessments. Additionally, â€œhterâ€ focuses on the number of edits rather than the nature of the changes, failing to differentiate between minor stylistic tweaks and substantial corrections. This can skew the perception of translation quality. Furthermore, the metric relies on the availability of high-quality reference translations, which may not always be accessible, limiting its applicability in certain contexts. These limitations suggest that while â€œhterâ€ is useful, it should be complemented with other evaluation methods for a more comprehensive assessment of translation quality.</span></p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1"><span class="ltx_text" id="S1.p8.1.1" style="font-size:90%;">We have identified some limitations in the two key metrics used in Quality Estimation (QE). Despite these, traditional QE methods face a significant, often overlooked problem: the reliance on </span><span class="ltx_text ltx_font_bold" id="S1.p8.1.2" style="font-size:90%;">correlation</span><span class="ltx_text" id="S1.p8.1.3" style="font-size:90%;"> statistical analysis for evaluation. Correlation is primarily used to understand the relationship between two data sets. Correlation only indicates the degree to which two sets of data are related, but it does not establish a relationship between them. However, to determine the effect of one variable on another, regression analysis is essential. For a deeper insight into key features affecting machine learning quality estimation data, regression analysis provides a more robust approach. For example, if we want to determine whether â€œhterâ€ has an effect on human scores, regression analysis is necessary. The correlation between â€œhterâ€ and human scores does not provide this level of insight.</span></p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1"><span class="ltx_text" id="S1.p9.1.1" style="font-size:90%;">To address these weaknesses, it is crucial to complement existing metrics with additional features, continuously update and diversify training data, and incorporate new features to enhance the reliability and usability of QE. Upgrading statistical analysis methods is also necessary to gain deeper insights. This study proposes that â€œtextual similarityâ€ could be considered a key feature in MT quality estimation and training. Using existing MT quality estimation datasets, we employed advanced statistical methods to compare this new metric with existing features and explore their advantages.</span></p>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Dataset</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text" id="S2.SS1.p1.1.1" style="font-size:90%;">This study utilized two distinct datasets. The first dataset, </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p1.1.3" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.4.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a><span class="ltx_text" id="S2.SS1.p1.1.5.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.6" style="font-size:90%;">, and the second dataset, used in </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p1.1.7" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p1.1.8" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.9.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a><span class="ltx_text" id="S2.SS1.p1.1.10.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.11" style="font-size:90%;">. Although the datasets differ in size, they can both be effectively employed for cross-validation purposes.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p2.1.1" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p2.1.2" style="font-size:90%;"> is a comprehensive dataset for MT QE and Automatic Post-Editing, covering eleven language pairs, including both high- and low-resource languages </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p2.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a><span class="ltx_text" id="S2.SS1.p2.1.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p2.1.5" style="font-size:90%;">. The dataset features up to 10,000 translations per language pair, annotated with sentence-level direct assessments, post-editing effort, and word-level binary good/bad labels. Each source-translation pair includes the post-edited sentence, article titles, and details of the neural MT models used. The dataset is thoroughly documented and analyzed, and the information on the baseline system performances is included.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1"><span class="ltx_text" id="S2.SS1.p3.1.1" style="font-size:90%;">The main variables in the </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p3.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p3.1.3" style="font-size:90%;"> includes:
original (original sentence), translation (MT output),
scores (list of DA [direct assessment] scores by all annotators - the number of annotators may vary), mean (average of DA scores),
z_scores (list of z-standardized DA scores), z_mean (average of z-standardized DA scores), model_scores (NMT model score for sentence). The other information on sentence translation such as â€œhterâ€ (human translation edit rate) is also included in the dataset. Note that â€œmodel_scoresâ€ is the the MT modelâ€™s confidence in its translation. According to MLQE-PE, these MT systems are SOTA ones, representing the recent advancements in MT models. In this way, â€œmodel_scoresâ€ signifies a direct indication of the translationâ€™s reliability from MT, that is, the translation quality assessment. The higher scores represents the higher translation quality. Conversely, a lower â€œhterâ€ indicates that a translation needs more human efforts to post-edit, that is, the translation quality is higher. Moreover, we also created some factors. For instance, the standard variation (sd) of different human scores for the same translation, and the human annotator number.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1"><span class="ltx_text" id="S2.SS1.p4.1.1" style="font-size:90%;">There are 11 language pairs available: English-German (en-de), English-Chinese (en-zh), Romanian-English (ro-en), Estonian-English (et-en), Nepalese-English (ne-en), Sinhala-English (si-en), and Russian-English (ru-en). </span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Although the paper on MLQE-PE claimed that their dataset also includes other language pairs, the dataset on these language pairs in the <span class="ltx_text ltx_font_typewriter" id="footnote1.1">github</span> they provided is not available.</span></span></span><span class="ltx_text" id="S2.SS1.p4.1.2" style="font-size:90%;"></span></p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1"><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.1" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.2" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p5.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a><span class="ltx_text" id="S2.SS1.p5.1.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p5.1.5" style="font-size:90%;"> includes a variety of datasets. However, we selected only the datasets for evaluating machine translation quality without reference translations. In this case, there are two language pairs: English-Chinese and English-German. The dataset includes the following variables: n-gram sentence probability, language model score, HTER, and human score (z_mean). â€œSentence probabilityâ€ refers to the likelihood of a particular sequence of words (sentence) occurring. This can be computed using n-grams. For example, if bi-grams are used, it is termed â€œbi-gram sentence probabilityâ€, and if tri-grams are used, it is â€œtri-gram sentence probabilityâ€. </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.6" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.7" style="font-size:90%;"> provides five types of sentence probabilities using 1-5 grams.
The â€œlanguage model scoreâ€ is a metric related to the language probability score (â€œlanâ€ is indicated in the </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.8" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.9" style="font-size:90%;">). This score is part of the quality estimation process that evaluates how likely a translation is accurate based on linguistic features and models, without referencing the actual translated text. </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.10" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.11" style="font-size:90%;"> also provides â€œhterâ€, which is computed using the same method as in </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.12" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p5.1.13" style="font-size:90%;">. Additionally, </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.14" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.15" style="font-size:90%;"> provides only the â€œhuman score (z_mean)â€.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Textual similarity</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text" id="S2.SS2.p1.1.1" style="font-size:90%;">Textual similarity (or sentence similarity) measures how similar or different two pieces of text are semantically. This can involve comparing sentences, paragraphs, or entire documents to see how closely they match in meaning or content. It can be calculated using various techniques, such as comparing word overlaps, semantic similarity, or using machine learning models to assess how alike the texts are. However, after transformers revolutionized deep learning, textual similarity can now be effectively measured using existing language models. </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a><span class="ltx_text" id="S2.SS2.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.4" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a><span class="ltx_text" id="S2.SS2.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.7" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a><span class="ltx_text" id="S2.SS2.p1.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.10" style="font-size:90%;"></span></p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text" id="S2.SS2.p2.1.1" style="font-size:90%;">Pretrained </span><span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.2" style="font-size:90%;">sentence transformers</span><span class="ltx_text" id="S2.SS2.p2.1.3" style="font-size:90%;"> are highly effective for generating sentence or textual embeddings due to their ability to capture deep semantic meanings </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p2.1.4.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a><span class="ltx_text" id="S2.SS2.p2.1.5.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p2.1.6" style="font-size:90%;">. By leveraging the Transformer architecture, these models encode sentences into high-dimensional vectors that reflect their contextual and semantic content, rather than merely their lexical features. This allows for accurate comparisons of semantic similarity between sentences or texts, which is crucial for tasks like paraphrase detection, information retrieval, and clustering.</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text" id="S2.SS2.p3.1.1" style="font-size:90%;">The â€œsentence-transformers/paraphrase-multilingual-MiniLM-L12-v2â€ model creates dense vector representations of sentences, capturing the semantic essence of the text. These vectors are placed in a shared embedding space where similar meanings are mapped to nearby points. The modelâ€™s fine-tuning for tasks like paraphrase identification ensures that sentences with similar meanings are close in this space. The use of sentence transformers is particularly valuable in multilingual contexts, as they support multiple languages and capture semantic nuances effectively. The task in the current study is to understand the source text in one language and the translated texts in the other language. The capability of multilingual sentence transformer models is essential for applications to explore the semantic similarity among languages. The current study employs this multilingual sentence transformer model to compute semantic similarity for one source sentence and its translation. Our fundamental approach involves using the sentence transformer to generate text embeddings and then calculating their similarity using the cosine method. We applied the method to process the two datasets to compute â€œtextual similarityâ€ between a source text and its translated text. </span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Regression statistical analysis</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1"><span class="ltx_text" id="S2.SS3.p1.1.1" style="font-size:90%;">We applied Generalized Additive Mixed Models (</span><span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.2" style="font-size:90%;">GAMM</span><span class="ltx_text" id="S2.SS3.p1.1.3" style="font-size:90%;">) in analyzing how factors influence human scores. GAMMs incorporate non-linear relationships between the dependent and independent variables through smooth functions </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.4.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a><span class="ltx_text" id="S2.SS3.p1.1.5.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p1.1.6" style="font-size:90%;">. GAMMs allow for both fixed and random effects, accommodating complex variations within hierarchical data structures. The â€œadditiveâ€ part of GAMM means that the model expresses the dependent variable as a sum of smooth functions of predictors, along with any random effects and an error term. This flexibility makes GAMMs particularly useful for modeling non-linear trends in data, where the effect of variables is not strictly linear and may vary by group or over time.</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text" id="S2.SS3.p2.1.1" style="font-size:90%;">GAMM could leverage the function </span><span class="ltx_text ltx_font_typewriter" id="S2.SS3.p2.1.2" style="font-size:90%;">s()</span><span class="ltx_text" id="S2.SS3.p2.1.3" style="font-size:90%;">. This smooth function better gets model fittings for some factors, and the interaction smooth could find the interaction among some given factors. Some random variables could play a very important role, such as different language pairs in TM. The role of such random variables could be well explored by using GAMMs. GAMMs are friendly to make model comparison by referring to </span><span class="ltx_text ltx_font_typewriter" id="S2.SS3.p2.1.4" style="font-size:90%;">AIC</span><span class="ltx_text" id="S2.SS3.p2.1.5" style="font-size:90%;"> (Akaike information criterion is an estimator of prediction error).</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text" id="S2.SS3.p3.1.1" style="font-size:90%;">In GAMM setups, the independent variable is â€œhuman scoreâ€, and other metrics are dependent variables. Some random factors, such as human evaluator number, different language pairs (source language - target language), could play an essential role </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">1</span></a><span class="ltx_text" id="S2.SS3.p3.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p3.1.4" style="font-size:90%;">. A GAMM fitting should include a number of factors. The reason for this is that various metrics or factor could predict human score or take effect on human score, and these factors co-work to play a role. The purpose of using GAMM fitting is to better explore how these factors take effects on human scores.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Result 1: Correlations</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text" id="S3.SS1.p1.1.1" style="font-size:90%;">We plotted the Pearson correlations among various factors for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S3.SS1.p1.1.3" style="font-size:90%;">, as shown in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F1" style="font-size:90%;" title="Figure 1 â€£ 3.1 Result 1: Correlations â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS1.p1.1.4" style="font-size:90%;">. The results indicate that â€œML_evalâ€ is correlated with the human score (mean) at 0.15, with â€œhterâ€ at 0.06, and with the human score (z-mean) at 0.3. â€œTextual similarityâ€ shows a correlation of 0.47 with the human score (mean), -0.06 with the human score (z-mean), -0.45 with â€œhterâ€, and -0.21 with â€œML_evalâ€. Overall, â€œtextual similarityâ€ exhibits stronger correlations with other factors compared to â€œML_evalâ€.</span></p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="817" id="S3.F1.g1" src="x1.png" width="817"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>correlations among various factors in <span class="ltx_text ltx_font_typewriter" id="S3.F1.5.1">MLQE-PE</span> </figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text" id="S3.SS1.p2.1.1" style="font-size:90%;">Similarly, we plotted the correlation among various factors for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS1.p2.1.3" style="font-size:90%;">, as shown in FigÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#Ax1.F4" style="font-size:90%;" title="Figure 4 â€£ Appendix â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S3.SS1.p2.1.4" style="font-size:90%;"> (see the Appendix). The three variables: â€œn-gram sentence probabilityâ€, â€œhterâ€, and â€œtextual similarityâ€, show similar correlation values with the â€œhuman score (z_mean)â€, each approximately 0.15.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Result 2: Cross language pairs</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1"><span class="ltx_text" id="S3.SS2.p1.1.1" style="font-size:90%;">We established three types of GAMM fittings for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S3.SS2.p1.1.3" style="font-size:90%;">, where â€œhuman score (mean)â€ is the independent variable, and other factors include â€œML_evalâ€, â€œtextual similarityâ€, â€œsd of human scoresâ€. â€œhuman evaluator numberâ€, â€œlanguage pairs (langs)â€ are incorporated as random variables. We chose â€œhuman score (mean)â€ over â€œhuman score (z-mean)â€ as the independent variable primarily because â€œhuman score (mean)â€ closely follows a normal distribution. The GAMM setups are detailed below, and the results are presented in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.T1" style="font-size:90%;" title="Table 1 â€£ 3.2 Result 2: Cross language pairs â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS2.p1.1.4" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text" id="S3.I1.i1.p1.1.1" style="font-size:90%;">base model = bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><mo id="S3.I1.i1.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i1.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i1.p1.1.2" style="font-size:90%;"> s(ML_eval)+s(textual similarity)+s(sd)+</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I1.i1.p1.1.3" style="font-size:90%;">s(hter)+s(evaluator num, bs=â€œreâ€)+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text" id="S3.I1.i2.p1.1.1" style="font-size:90%;">m1=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mo id="S3.I1.i2.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i2.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i2.p1.1.2" style="font-size:90%;"> s(ML_eval)+s(sd)+s(hter)+s(evaluator num, bs=â€œreâ€)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I1.i2.p1.1.3" style="font-size:90%;">+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text" id="S3.I1.i3.p1.1.1" style="font-size:90%;">m2=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mo id="S3.I1.i3.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i3.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i3.p1.1.2" style="font-size:90%;"> s(textual similarity)+s(sd)+s(hter)+s(evaluato num, bs=â€œreâ€)+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text" id="S3.I1.i4.p1.1.1" style="font-size:90%;">m3=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i4.p1.1.m1.1"><semantics id="S3.I1.i4.p1.1.m1.1a"><mo id="S3.I1.i4.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i4.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i4.p1.1.m1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i4.p1.1.2" style="font-size:90%;"> s(ML_eval)+s(textual similarity)+s(sd)+s(evaluator num, bs=â€œreâ€)+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3"><span class="ltx_text" id="S3.SS2.p3.3.1" style="font-size:90%;">The base model demonstrates the best performance when all factors are included. However, each of the remaining models includes only a subset of these factors. The Akaike Information Criterion (AIC) is used to represent the performance of this GAMM fitting. The base model has the lowest AIC. When the AIC of model </span><math alttext="m1" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.2.cmml">m</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">â¢</mo><mn id="S3.SS2.p3.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></times><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ‘š</ci><cn id="S3.SS2.p3.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">m1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_m 1</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.3.2" style="font-size:90%;"> is subtracted from the AIC of the base model, the resulting </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" mathsize="90%" mathvariant="normal" xref="S3.SS2.p3.2.m2.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">roman_Î”</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.3.3" style="font-size:90%;">AIC indicates the contribution of â€œtextual similarityâ€, as â€œm1â€ does not include â€œtextual similarityâ€ compared to the base model. A smaller </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" mathsize="90%" mathvariant="normal" xref="S3.SS2.p3.3.m3.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">roman_Î”</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.3.4" style="font-size:90%;">AIC also indicates better performance and greater contribution for a given factor. The results are shown in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.T1" style="font-size:90%;" title="Table 1 â€£ 3.2 Result 2: Cross language pairs â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS2.p3.3.5" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T1.3.m1.1"><semantics id="S3.T1.3.m1.1b"><mi id="S3.T1.3.m1.1.1" mathvariant="normal" xref="S3.T1.3.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.T1.3.m1.1c"><ci id="S3.T1.3.m1.1.1.cmml" xref="S3.T1.3.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.m1.1e">roman_Î”</annotation></semantics></math>AIC for different GAMM fittings for <span class="ltx_text ltx_font_typewriter" id="S3.T1.11.1">MLQE-PE</span>. A smaller <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T1.4.m2.1"><semantics id="S3.T1.4.m2.1b"><mi id="S3.T1.4.m2.1.1" mathvariant="normal" xref="S3.T1.4.m2.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.T1.4.m2.1c"><ci id="S3.T1.4.m2.1.1.cmml" xref="S3.T1.4.m2.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.m2.1e">roman_Î”</annotation></semantics></math>AIC indicates better performance (n=45886)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.5">
<tr class="ltx_tr" id="S3.T1.5.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.5.1.2"><span class="ltx_text" id="S3.T1.5.1.2.1" style="font-size:90%;">factor (contribution)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.5.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T1.5.1.1.m1.1"><semantics id="S3.T1.5.1.1.m1.1a"><mi id="S3.T1.5.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S3.T1.5.1.1.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.T1.5.1.1.m1.1b"><ci id="S3.T1.5.1.1.m1.1.1.cmml" xref="S3.T1.5.1.1.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.1.1.m1.1d">roman_Î”</annotation></semantics></math><span class="ltx_text" id="S3.T1.5.1.1.1" style="font-size:90%;">AIC</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" id="S3.T1.5.2.1"><span class="ltx_text" id="S3.T1.5.2.1.1" style="font-size:90%;">(m1- base model) contribution of textual similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.5.2.2"><span class="ltx_text" id="S3.T1.5.2.2.1" style="font-size:90%;">848.87</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.5.3.1"><span class="ltx_text" id="S3.T1.5.3.1.1" style="font-size:90%;">(m2- base model) contribution of ML_eval</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.5.3.2"><span class="ltx_text" id="S3.T1.5.3.2.1" style="font-size:90%;">8785.82</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.4">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.5.4.1"><span class="ltx_text" id="S3.T1.5.4.1.1" style="font-size:90%;">(m3-base model) contribution of hter</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.5.4.2"><span class="ltx_text" id="S3.T1.5.4.2.1" style="font-size:90%;">586.3</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text" id="S3.SS2.p4.1.1" style="font-size:90%;">The contribution from â€œtextual similarityâ€ outperforms that from â€œML_evalâ€. However, the contribution of â€œhterâ€ shows the best performance overall. This trend holds for all language pairs. Despite this, it is important to examine the performance for individual language pairs. The next section explores the performance of these factors in each language pair.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text" id="S3.SS2.p5.1.1" style="font-size:90%;">Next, we used similar GAMM methods to explore how different metrics affect human scores for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS2.p5.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS2.p5.1.3" style="font-size:90%;">. In the </span><span class="ltx_text ltx_font_typewriter" id="S3.SS2.p5.1.4" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS2.p5.1.5" style="font-size:90%;"> dataset, â€œhuman score (z_mean)â€ is the dependent variable </span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In this dataset, â€œhuman score (mean)â€ is not available.</span></span></span><span class="ltx_text" id="S3.SS2.p5.1.6" style="font-size:90%;">, and other factors include â€œn-gram sentence probabilityâ€, â€œlanguage model scoreâ€, â€œhterâ€, and â€œtextual similarityâ€. In this dataset, â€œlanguage model scoreâ€ (â€œlm_scoreâ€) has four values, so we treat it as a random factor, and â€œlanguage pairsâ€ (â€œlangsâ€) are incorporated as a random variable. There are five types of â€œn-gram sentence probabilityâ€; however, we chose the optimal one, â€œtrigram sentence probabilityâ€,"for the GAMM fittings. The GAMM setups are detailed below, and the results are presented in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.T2" style="font-size:90%;" title="Table 2 â€£ 3.2 Result 2: Cross language pairs â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS2.p5.1.7" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text" id="S3.I2.i1.p1.1.1" style="font-size:90%;">base model = bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i1.p1.1.m1.1"><semantics id="S3.I2.i1.p1.1.m1.1a"><mo id="S3.I2.i1.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i1.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i1.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i1.p1.1.2" style="font-size:90%;"> s(trigram sent prob)+s(textual </span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i1.p1.1.3" style="font-size:90%;">similarity)+s(hter) +s(lm_score, bs=â€œreâ€)+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text" id="S3.I2.i2.p1.1.1" style="font-size:90%;">t1=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i2.p1.1.m1.1"><semantics id="S3.I2.i2.p1.1.m1.1a"><mo id="S3.I2.i2.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i2.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i2.p1.1.2" style="font-size:90%;"> s(trigram sent prob)+s(hter)+s(lm_score, bs=â€œreâ€)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i2.p1.1.3" style="font-size:90%;">+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text" id="S3.I2.i3.p1.1.1" style="font-size:90%;">t2=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i3.p1.1.m1.1"><semantics id="S3.I2.i3.p1.1.m1.1a"><mo id="S3.I2.i3.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i3.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i3.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i3.p1.1.2" style="font-size:90%;"> s(textual similarity)+s(hter)+s(lm_score, bs=â€œreâ€)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i3.p1.1.3" style="font-size:90%;">+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p" id="S3.I2.i4.p1.1"><span class="ltx_text" id="S3.I2.i4.p1.1.1" style="font-size:90%;">t3=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i4.p1.1.m1.1"><semantics id="S3.I2.i4.p1.1.m1.1a"><mo id="S3.I2.i4.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i4.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i4.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i4.p1.1.m1.1.1.cmml" xref="S3.I2.i4.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i4.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i4.p1.1.m1.1d">âˆ¼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i4.p1.1.2" style="font-size:90%;"> s(trigram sent prob)+s(textual similarity)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i4.p1.1.3" style="font-size:90%;">+s(lm_score, bs=â€œreâ€)+s(langs, bs=â€œreâ€))</span></p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.3.m1.1"><semantics id="S3.T2.3.m1.1b"><mi id="S3.T2.3.m1.1.1" mathvariant="normal" xref="S3.T2.3.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.T2.3.m1.1c"><ci id="S3.T2.3.m1.1.1.cmml" xref="S3.T2.3.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.m1.1e">roman_Î”</annotation></semantics></math>AIC for different GAMM fittings for <span class="ltx_text ltx_font_typewriter" id="S3.T2.11.1">PreQuEL</span>. A smaller <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.4.m2.1"><semantics id="S3.T2.4.m2.1b"><mi id="S3.T2.4.m2.1.1" mathvariant="normal" xref="S3.T2.4.m2.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.T2.4.m2.1c"><ci id="S3.T2.4.m2.1.1.cmml" xref="S3.T2.4.m2.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.m2.1e">roman_Î”</annotation></semantics></math>AIC indicates better performance (n=14706)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.5">
<tr class="ltx_tr" id="S3.T2.5.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.5.1.2"><span class="ltx_text" id="S3.T2.5.1.2.1" style="font-size:90%;">factor (contribution)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.5.1.1.m1.1"><semantics id="S3.T2.5.1.1.m1.1a"><mi id="S3.T2.5.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S3.T2.5.1.1.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.T2.5.1.1.m1.1b"><ci id="S3.T2.5.1.1.m1.1.1.cmml" xref="S3.T2.5.1.1.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.1.1.m1.1d">roman_Î”</annotation></semantics></math><span class="ltx_text" id="S3.T2.5.1.1.1" style="font-size:90%;">AIC</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" id="S3.T2.5.2.1"><span class="ltx_text" id="S3.T2.5.2.1.1" style="font-size:90%;">(t1- base model) contribution of textual similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.5.2.2"><span class="ltx_text" id="S3.T2.5.2.2.1" style="font-size:90%;">237.11</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.5.3.1"><span class="ltx_text" id="S3.T2.5.3.1.1" style="font-size:90%;">(t2- base model) contribution of trigram sentence probability</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.3.2"><span class="ltx_text" id="S3.T2.5.3.2.1" style="font-size:90%;">232.16</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.4">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.5.4.1"><span class="ltx_text" id="S3.T2.5.4.1.1" style="font-size:90%;">(t3-base model) contribution of hter</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.5.4.2"><span class="ltx_text" id="S3.T2.5.4.2.1" style="font-size:90%;">424.29</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1"><span class="ltx_text" id="S3.SS2.p7.1.1" style="font-size:90%;">The contribution of â€œtextual similarityâ€ outperforms that of â€œhterâ€. However, the contribution of â€œtrigram sentence probabilityâ€ shows a similar performance to â€œtextual similarityâ€, with â€œtrigram sentence probabilityâ€ demonstrating the best performance overall. The next section examines the performance for individual language pairs.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Result 3: Individual language pair</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text" id="S3.SS3.p1.1.1" style="font-size:90%;">Using a similar GAMM setup as the base model, we explore how these factors perform across seven language pairs for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S3.SS3.p1.1.3" style="font-size:90%;">. For each language pair, we established the same GAMM and plotted the partial effects for each factor of interest, as shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F2" style="font-size:90%;" title="Figure 2 â€£ 3.3 Result 3: Individual language pair â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS3.p1.1.4" style="font-size:90%;">. When the </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.5" style="font-size:90%;">p</span><span class="ltx_text" id="S3.SS3.p1.1.6" style="font-size:90%;">-value is greater than 0.05, the plot is not significant. Within the same language pair, a smaller </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S3.SS3.p1.1.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">roman_Î”</annotation></semantics></math><span class="ltx_text" id="S3.SS3.p1.1.7" style="font-size:90%;">AIC indicates better performance. Clearly, all cases for â€œML_evalâ€ are significant, and there is only one insignificant case for â€œtextual similarityâ€. In contrast, â€œhterâ€ has only two significant cases, indicating five insignificant cases.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text" id="S3.SS3.p2.1.1" style="font-size:90%;">Compared with â€œML_evalâ€, â€œtextual similarityâ€ outperforms in the cases of â€œGerman-Englishâ€, "English-Chineseâ€, â€œRomanian-Englishâ€, â€œRussian-Englishâ€ and â€œSinhala-Englishâ€. Generally, â€œtextual similarityâ€ demonstrates the best performance across individual language pairs.</span></p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="504" id="S3.F2.g1" src="x2.png" width="904"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The partial effects on human score from different factors for <span class="ltx_text ltx_font_typewriter" id="S3.F2.11.1">MLQE-PE</span>. The <span class="ltx_text ltx_font_italic" id="S3.F2.12.2">x</span>-axis represents the specific metric being analyzed, while the <span class="ltx_text ltx_font_italic" id="S3.F2.13.3">y</span>-axis indicates human score. Each curve within a plot illustrates the relationship between a predictor variable (plotted on the <span class="ltx_text ltx_font_italic" id="S3.F2.14.4">x</span>-axis) and the response variable. Steeper slopes on these curves indicate a stronger influence of the predictor variable on human score. Conversely, gentler slopes imply a weaker influence, indicating that changes in the predictor variable have a less pronounced effect on human score. Such plots could give deep insights on the relationship between one given metric and human score.
</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text" id="S3.SS3.p3.1.1" style="font-size:90%;">Adopting the similar GAMM fittings for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS3.p3.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS3.p3.1.3" style="font-size:90%;">, we explored the performance for each variable of our interest in each language pair, and plotted the partial effects for each factor of interest, as shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F3" style="font-size:90%;" title="Figure 3 â€£ 3.3 Result 3: Individual language pair â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS3.p3.1.4" style="font-size:90%;">. Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F3" style="font-size:90%;" title="Figure 3 â€£ 3.3 Result 3: Individual language pair â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS3.p3.1.5" style="font-size:90%;"> shows that â€œ textual similariyâ€ has the best performance in each individual language pair.</span></p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="549" id="S3.F3.g1" src="x3.png" width="686"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The partial effects on human score from different factors for <span class="ltx_text ltx_font_typewriter" id="S3.F3.17.1">PreQuEL</span>. The <span class="ltx_text ltx_font_italic" id="S3.F3.18.2">x</span>-axis represents the specific metric being analyzed, while the <span class="ltx_text ltx_font_italic" id="S3.F3.19.3">y</span>-axis indicates the human score. The interpretation of the curve is the same as in FigÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F2" title="Figure 2 â€£ 3.3 Result 3: Individual language pair â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>. The layout here differs slightly from that in FigÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F2" title="Figure 2 â€£ 3.3 Result 3: Individual language pair â€£ 3 Results â€£ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>. <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.F3.3.m1.1"><semantics id="S3.F3.3.m1.1b"><mi id="S3.F3.3.m1.1.1" mathvariant="normal" xref="S3.F3.3.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.F3.3.m1.1c"><ci id="S3.F3.3.m1.1.1.cmml" xref="S3.F3.3.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.3.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.F3.3.m1.1e">roman_Î”</annotation></semantics></math>AIC values are compared among three plots for the same language pairs. A lower <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.F3.4.m2.1"><semantics id="S3.F3.4.m2.1b"><mi id="S3.F3.4.m2.1.1" mathvariant="normal" xref="S3.F3.4.m2.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S3.F3.4.m2.1c"><ci id="S3.F3.4.m2.1.1.cmml" xref="S3.F3.4.m2.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.F3.4.m2.1e">roman_Î”</annotation></semantics></math>AIC value indicates better performance.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text" id="S4.p1.1.1" style="font-size:90%;">Considering the correlation in </span><span class="ltx_text ltx_font_typewriter" id="S4.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S4.p1.1.3" style="font-size:90%;">, we found that â€œtextual similarityâ€ exhibits a strong correlation with human scores, â€œML_evalâ€, and â€œhterâ€. In contrast, â€œML_evalâ€ shows a weaker correlation with the human score (mean). When examining the GAMM fittings across various language pairs and in each case of language pair, the performance of â€œtextual similarityâ€ surpasses that of â€œML_evalâ€. On an individual language pair basis, â€œtextual similarityâ€ also outperforms both â€œML_evalâ€ and â€œhterâ€. In </span><span class="ltx_text ltx_font_typewriter" id="S4.p1.1.4" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S4.p1.1.5" style="font-size:90%;">, due to the smaller sample size, the differences in correlation are not obvious. In short, â€œtextual similarityâ€ as a metric could be closely correlated with human score, and is highly capable of predicting human score.</span></p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text" id="S4.p2.1.1" style="font-size:90%;">The following provides a detailed analysis of each metric in </span><span class="ltx_text ltx_font_typewriter" id="S4.p2.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S4.p2.1.3" style="font-size:90%;">. â€œML_evalâ€ demonstrates a significant impact across all language pairs, indicating that this metric is both useful and effective for QE. However, â€œhterâ€ does not show a significant impact on human scores in the most cases, suggesting that this metric may not be suitable for evaluating MT quality in certain language pairs. On the other hand, â€œtextual similarityâ€ predicts human scores in the majority of language pairs, highlighting its potential as an effective metric for QE.</span></p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text" id="S4.p3.1.1" style="font-size:90%;">The present study underscores the importance of selecting appropriate metrics for QE. â€œTextual similarityâ€, in particular, emerges as a robust and reliable metric that consistently correlates with human evaluation scores and effectively predict human scores, making it a valuable tool for improving the accuracy of QE. In contrast, while â€œML_evalâ€ remains a useful metric, its effectiveness varies across different language pairs. â€œhterâ€, despite being commonly used, may not be sufficient in some cases, necessitating the consideration of alternative or supplementary metrics like textual similarity.</span></p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text" id="S4.p4.1.1" style="font-size:90%;">Next, we analyzed the performance of â€œtextual similarityâ€ in </span><span class="ltx_text ltx_font_typewriter" id="S4.p4.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S4.p4.1.3" style="font-size:90%;">. â€œtextual similarityâ€ outperforms â€œhterâ€ consistently across language and within invidiual languages. However, â€œtextual similarityâ€ has the similar performance with â€œn-gram sentence probabilityâ€. It also reveals that â€œn-gram sentence probabilityâ€ may be a useful metric in evaluating MT QE.</span></p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1"><span class="ltx_text" id="S4.p5.1.1" style="font-size:90%;">It is easy to understand why textual similarity is such an effective metric. When a translated text is semantically close to the source text, it indicates that the translation meets a crucial standard of quality: the meaning of the translation should closely match the original text. In contrast, the â€œhterâ€ metric often fails for most language pairs because post-editing efforts do not necessarily reflect changes in meaning. For example, a translation may be very close in meaning to the original text but contain some misspellings. Humans may still consider the translation to be good, even though the post-edit rate is low due to the necessary corrections. Conversely, minor edits to core verbs or key words in a translation text may require minimal edit effort but significantly alter the meaning. However, such a translation text does not necessarily meet the standard of good translation. This discrepancy shows that post-edit rate does not always correlate with translation quality.</span></p>
</div>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1"><span class="ltx_text" id="S4.p6.1.1" style="font-size:90%;">Therefore, exploring the cognitive recognition of what constitutes a good translation for different language users is worthwhile. Understanding this can significantly enhance both machine translation and quality estimation processes by aligning them more closely with human judgments of translation quality. For instance, "n-gram sentence probability" can provide an initial impression of the naturalness or readability of translated texts. If this metric is low, human evaluators might rate the quality of the translations poorly, regardless of how closely they match the original meaning. Simple yet effective metrics should be considered in evaluating machine translation quality, incorporating factors that align with human translation assessment standards and processes. This approach can lead to substantial progress in machine translation quality estimation (MT QE).</span></p>
</div>
<div class="ltx_para" id="S4.p7">
<p class="ltx_p" id="S4.p7.1"><span class="ltx_text" id="S4.p7.1.1" style="font-size:90%;">To date, â€œtextual similarityâ€ has not been proposed as a metric in QE </span><span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Although some studies have proposed using semantic similarity to evaluate MT quality, they have only applied this method in cases where reference translations are provided <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. Specifically, these studies compared the semantic similarity between a candidate translation and a reference translation. In contrast, our study employed cross-lingual the semantic similarity between a text in the source language and its translated text in the target language.</span></span></span><span class="ltx_text" id="S4.p7.1.2" style="font-size:90%;">. Our study applied a variety of statistical methods to analyze data from established QE datasets, demonstrating that this metric is both reliable and effective compared to commonly used metrics in QE. Our findings provide strong evidence that â€œtextual similarityâ€ is a robust metric, making it a valuable addition to the existing suite of QE metrics. Given its proven effectiveness, â€œtextual similarityâ€ should be included as a key metric in QE and incorporated into the training of machine translation (MT) systems. This integration can enhance the accuracy and reliability of MT quality assessments, ultimately improving the performance and usability of MT systems.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.4.1" style="font-size:90%;">
DaleÂ J Barr, Roger Levy, Christoph Scheepers, and HarryÂ J Tily.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.5.1" style="font-size:90%;">Random effects structure for confirmatory hypothesis testing: Keep it
maximal.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.6.1" style="font-size:90%;">Journal of Memory and Language</span><span class="ltx_text" id="bib.bib1.7.2" style="font-size:90%;">, 68(3):255â€“278, 2013.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.2.2.1" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.4.1" style="font-size:90%;">
Frederic Blain, Chrysoula Zerva, Ricardo Rei, NunoÂ M Guerreiro, Diptesh
Kanojia, JosÃ©Â GC deÂ Souza, Beatriz Silva, TÃ¢nia Vaz, Yan Jingxuan,
Fatemeh Azadi, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.5.1" style="font-size:90%;">Findings of the wmt 2023 shared task on quality estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib2.7.2" style="font-size:90%;">Proceedings of the Eighth Conference on Machine Translation</span><span class="ltx_text" id="bib.bib2.8.3" style="font-size:90%;">,
pages 629â€“653, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.2.2.1" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.4.1" style="font-size:90%;">
Julio Castillo and Paula Estrella.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.5.1" style="font-size:90%;">Semantic textual similarity for mt evaluation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib3.7.2" style="font-size:90%;">Proceedings of the Seventh Workshop on Statistical Machine
Translation</span><span class="ltx_text" id="bib.bib3.8.3" style="font-size:90%;">, pages 52â€“58, 2012.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.2.2.1" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.4.1" style="font-size:90%;">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.5.1" style="font-size:90%;">Bert: Pre-training of deep bidirectional transformers for language
understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.6.1" style="font-size:90%;">arXiv preprint arXiv:1810.04805</span><span class="ltx_text" id="bib.bib4.7.2" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.2.2.1" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.4.1" style="font-size:90%;">
Shachar Don-Yehiya, Leshem Choshen, and Omri Abend.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.5.1" style="font-size:90%;">Prequel: Quality estimation of machine translation outputs in
advance.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.6.1" style="font-size:90%;">arXiv preprint arXiv:2205.09178</span><span class="ltx_text" id="bib.bib5.7.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.2.2.1" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.4.1" style="font-size:90%;">
Marina Fomicheva, Shuo Sun, Erick Fonseca, Chrysoula Zerva, FrÃ©dÃ©ric
Blain, Vishrav Chaudhary, Francisco GuzmÃ¡n, Nina Lopatina, Lucia Specia,
and AndrÃ©Â FT Martins.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.5.1" style="font-size:90%;">Mlqe-pe: A multilingual quality estimation and post-editing dataset.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.7.2" style="font-size:90%;">Proceedings of the Thirteenth Language Resources and
Evaluation Conference</span><span class="ltx_text" id="bib.bib6.8.3" style="font-size:90%;">, pages 4963â€“4974, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.2.2.1" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.4.1" style="font-size:90%;">
Francisco GuzmÃ¡n, Peng-Jen Chen, Myle Ott, Juan Pino, Guillaume Lample,
Philipp Koehn, Vishrav Chaudhary, and Marcâ€™Aurelio Ranzato.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.5.1" style="font-size:90%;">The flores evaluation datasets for low-resource machine translation:
Nepali-english and sinhala-english.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.6.1" style="font-size:90%;">arXiv preprint arXiv:1902.01382</span><span class="ltx_text" id="bib.bib7.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.2.2.1" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.4.1" style="font-size:90%;">
Seungjun Lee, Jungseob Lee, Hyeonseok Moon, Chanjun Park, Jaehyung Seo,
Sugyeong Eo, Seonmin Koo, and Heuiseok Lim.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.5.1" style="font-size:90%;">A survey on evaluation metrics for machine translation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.6.1" style="font-size:90%;">Mathematics</span><span class="ltx_text" id="bib.bib8.7.2" style="font-size:90%;">, 11(4):1006, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.2.2.1" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.4.1" style="font-size:90%;">
Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng,
David Grangier, and Michael Auli.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.5.1" style="font-size:90%;">Fairseq: A fast, extensible toolkit for sequence modeling.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.6.1" style="font-size:90%;">arXiv preprint arXiv:1904.01038</span><span class="ltx_text" id="bib.bib9.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.2.2.1" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.4.1" style="font-size:90%;">
Tharindu Ranasinghe, Constantin Orasan, and Ruslan Mitkov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.5.1" style="font-size:90%;">Transquest: Translation quality estimation with cross-lingual
transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.6.1" style="font-size:90%;">arXiv preprint arXiv:2011.01536</span><span class="ltx_text" id="bib.bib10.7.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.2.2.1" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.4.1" style="font-size:90%;">
Nils Reimers and Iryna Gurevych.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.5.1" style="font-size:90%;">Sentence-bert: Sentence embeddings using siamese bert-networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.6.1" style="font-size:90%;">arXiv preprint arXiv:1908.10084</span><span class="ltx_text" id="bib.bib11.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.2.2.1" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.4.1" style="font-size:90%;">
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John
Makhoul.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.5.1" style="font-size:90%;">A study of translation edit rate with targeted human annotation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.7.2" style="font-size:90%;">Proceedings of the 7th Conference of the Association for
Machine Translation in the Americas: Technical Papers</span><span class="ltx_text" id="bib.bib12.8.3" style="font-size:90%;">, pages 223â€“231, 2006.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.2.2.1" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.4.1" style="font-size:90%;">
Lucia Specia, Dhwaj Raj, and Marco Turchi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.5.1" style="font-size:90%;">Machine translation evaluation versus quality estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.6.1" style="font-size:90%;">Machine Translation</span><span class="ltx_text" id="bib.bib13.7.2" style="font-size:90%;">, 24:39â€“50, 2010.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.2.2.1" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.4.1" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.5.1" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.6.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib14.7.2" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.2.2.1" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.4.1" style="font-size:90%;">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtowicz,
etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.5.1" style="font-size:90%;">Transformers: State-of-the-art natural language processing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib15.7.2" style="font-size:90%;">Proceedings of the 2020 conference on empirical methods in
natural language processing: system demonstrations</span><span class="ltx_text" id="bib.bib15.8.3" style="font-size:90%;">, pages 38â€“45, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.2.2.1" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.4.1" style="font-size:90%;">
SimonÂ N Wood.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.5.1" style="font-size:90%;">Generalized additive models: an introduction with R</span><span class="ltx_text" id="bib.bib16.6.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">Chapman and Hall/CRC, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.2.2.1" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.4.1" style="font-size:90%;">
Tianyi Zhang, Varsha Kishore, Felix Wu, KilianÂ Q Weinberger, and Yoav Artzi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.5.1" style="font-size:90%;">Bertscore: Evaluating text generation with bert.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.6.1" style="font-size:90%;">arXiv preprint arXiv:1904.09675</span><span class="ltx_text" id="bib.bib17.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="Ax1" lang="en">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">Appendix</h2>
<figure class="ltx_figure" id="Ax1.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="817" id="Ax1.F4.g1" src="x4.png" width="817"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>correlations among various factors in <span class="ltx_text ltx_font_typewriter" id="Ax1.F4.5.1">PreQuEL</span> </figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Jul  1 09:30:32 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
