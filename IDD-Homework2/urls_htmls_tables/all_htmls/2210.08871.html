<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2210.08871] Industry-Scale Orchestrated Federated Learning for Drug Discovery</title><meta property="og:description" content="To apply federated learning to drug discovery we developed a novel platform in the context of European Innovative Medicines Initiative (IMI) project MELLODDY (grant n°831472), which was comprised of 10 pharmaceutical c…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Industry-Scale Orchestrated Federated Learning for Drug Discovery">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Industry-Scale Orchestrated Federated Learning for Drug Discovery">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2210.08871">

<!--Generated on Thu Mar 14 02:22:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Industry-Scale Orchestrated Federated Learning for Drug Discovery</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Martijn Oldenhof<sup id="id1.1.id1" class="ltx_sup">1</sup>, Gergely Ács<sup id="id2.2.id2" class="ltx_sup">2</sup>, Balázs Pejó<sup id="id3.3.id3" class="ltx_sup">2</sup>, Ansgar Schuffenhauer<sup id="id4.4.id4" class="ltx_sup">4</sup>, Nicholas Holway<sup id="id5.5.id5" class="ltx_sup">4</sup>, Noé Sturm<sup id="id6.6.id6" class="ltx_sup">4</sup>, Arne Dieckmann<sup id="id7.7.id7" class="ltx_sup">5</sup>, Oliver Fortmeier<sup id="id8.8.id8" class="ltx_sup">5</sup>, Eric Boniface<sup id="id9.9.id9" class="ltx_sup">6</sup>, Clément Mayer<sup id="id10.10.id10" class="ltx_sup">6</sup>, Arnaud Gohier<sup id="id11.11.id11" class="ltx_sup">8</sup>, Peter Schmidtke<sup id="id12.12.id12" class="ltx_sup">7</sup>, Ritsuya Niwayama<sup id="id13.13.id13" class="ltx_sup">8</sup>, Dieter Kopecky<sup id="id14.14.id14" class="ltx_sup">9</sup>, Lewis Mervin<sup id="id15.15.id15" class="ltx_sup">10</sup>, Prakash Chandra Rathi<sup id="id16.16.id16" class="ltx_sup">11</sup>, Lukas Friedrich<sup id="id17.17.id17" class="ltx_sup">14</sup>, András Formanek<sup id="id18.18.id18" class="ltx_sup">1, 3</sup>, Peter Antal<sup id="id19.19.id19" class="ltx_sup">3</sup>, Jordon Rahaman<sup id="id20.20.id20" class="ltx_sup">16</sup><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Work was carried out as employee of Amgen.</span></span></span>, Adam Zalewski<sup id="id21.21.id21" class="ltx_sup">15</sup>, Wouter Heyndrickx<sup id="id22.22.id22" class="ltx_sup">17</sup>, Ezron Oluoch<sup id="id23.23.id23" class="ltx_sup">18</sup>, Manuel Stößel<sup id="id24.24.id24" class="ltx_sup">18</sup>, Michal Vančo<sup id="id25.25.id25" class="ltx_sup">18</sup>, David Endico<sup id="id26.26.id26" class="ltx_sup">19</sup>, Fabien Gelus<sup id="id27.27.id27" class="ltx_sup">19</sup>, Thaïs de Boisfossé<sup id="id28.28.id28" class="ltx_sup">19</sup>, Adrien Darbier<sup id="id29.29.id29" class="ltx_sup">19</sup>, Ashley Nicollet<sup id="id30.30.id30" class="ltx_sup">19</sup>, Matthieu Blottière<sup id="id31.31.id31" class="ltx_sup">19</sup>, Maria Telenczuk<sup id="id32.32.id32" class="ltx_sup">19</sup>, Van Tien Nguyen<sup id="id33.33.id33" class="ltx_sup">19</sup>, Thibaud Martinez<sup id="id34.34.id34" class="ltx_sup">19</sup>, Camille Boillet<sup id="id35.35.id35" class="ltx_sup">19</sup>, Kelvin Moutet<sup id="id36.36.id36" class="ltx_sup">19</sup>, Alexandre Picosson<sup id="id37.37.id37" class="ltx_sup">19</sup>, Aurélien Gasser<sup id="id38.38.id38" class="ltx_sup">19</sup>, Inal Djafar<sup id="id39.39.id39" class="ltx_sup">19</sup>, Antoine Simon<sup id="id40.40.id40" class="ltx_sup">19</sup>, Ádám Arany<sup id="id41.41.id41" class="ltx_sup">1</sup>, Jaak Simm<sup id="id42.42.id42" class="ltx_sup">1</sup>, Yves Moreau<sup id="id43.43.id43" class="ltx_sup">1</sup>, Ola Engkvist<sup id="id44.44.id44" class="ltx_sup">12,13</sup>, Hugo Ceulemans<sup id="id45.45.id45" class="ltx_sup">17</sup>, Camille Marini<sup id="id46.46.id46" class="ltx_sup">19</sup> and Mathieu Galtier<sup id="id47.47.id47" class="ltx_sup">19</sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id48.id1" class="ltx_p">To apply federated learning to drug discovery we developed a novel platform in the context of European Innovative Medicines Initiative (IMI) project MELLODDY (grant n°831472), which was comprised of 10 pharmaceutical companies, academic research labs, large industrial companies and startups. The MELLODDY platform was the first industry-scale platform to enable the creation of a global federated model for drug discovery without sharing the confidential data sets of the individual partners. The federated model was trained on the platform by aggregating the gradients of all contributing partners in a cryptographic, secure way following each training iteration. The platform was deployed on an Amazon Web Services (AWS) multi-account architecture running Kubernetes clusters in private subnets. Organisationally, the roles of the different partners were codified as different rights and permissions on the platform and administrated in a decentralized way. The MELLODDY platform generated new scientific discoveries which are described in a companion paper.</p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Introduction</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Billions of Euros in research and development are needed to successfully bring a new drug to the market. Furthermore, drug discovery and development is a high risk process as there is a failure rate of around 90% for drug candidates that reach the clinical studies phase. Therefore, making the early stages of drug discovery more efficient and accurate holds the potential to have a significant impact on the pharmaceutical industry.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Tools and models based on machine learning and artificial intelligence are commonly applied in all stages of drug discovery and development to make the process more efficient. A standard technique is to use quantitative structure-activity relationship (QSAR) machine learning models <cite class="ltx_cite ltx_citemacro_citep">(Ghasemi et al. <a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite> to predict bioactivity or toxicity of small molecules and possible drug candidates. However, the lack of data often limits model performance improvement. A collaborative approach that brings together industry competitors to leverage vast datasets holds the potential to overcome this challenge and enable better model performance.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p">Several levels of collaboration in terms of privacy and computational overhead can be envisioned. For data privacy, the focus is on the proper handling of sensitive data, including confidential data such as intellectual property, and on protecting the confidentiality and immutability of the data. Ensuring data privacy could lead to computational overhead caused by extra process requirements (e.g. authentication and encryption). The most efficient in computation usually means the least effective in privacy (e.g. a centralised server building a model by pooling the data sets from all partners would enable the models to profit from a large pool of data, however it would enable all or some partners accessing data of others). At the other extreme end lies cryptographic techniques such as secure multi-party computation (SMPC) <cite class="ltx_cite ltx_citemacro_citep">(Cramer et al. <a href="#bib.bib7" title="" class="ltx_ref">2015</a>)</cite> and homomorphic encryption <cite class="ltx_cite ltx_citemacro_citep">(Gentry <a href="#bib.bib12" title="" class="ltx_ref">2009</a>)</cite>, that could increase the levels of privacy guarantees but are less practical when applied on big data use cases due to computational overhead. Federated learning <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al. <a href="#bib.bib27" title="" class="ltx_ref">2017</a>)</cite>, by design, provides a minimal required level of privacy as the data stays under control of each participant while computational overhead is still reasonable for big data use cases.</p>
</div>
<figure id="Sx1.F1" class="ltx_figure"><img src="/html/2210.08871/assets/x1.png" id="Sx1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustrating Federated Learning:
within a single training round, the clients update the model (i.e. <math id="Sx1.F1.4.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="Sx1.F1.4.m1.1b"><mi id="Sx1.F1.4.m1.1.1" xref="Sx1.F1.4.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="Sx1.F1.4.m1.1c"><ci id="Sx1.F1.4.m1.1.1.cmml" xref="Sx1.F1.4.m1.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx1.F1.4.m1.1d">W</annotation></semantics></math>) using their local training sets and share only the corresponding gradients (i.e. <math id="Sx1.F1.5.m2.1" class="ltx_Math" alttext="\Delta W_{i}" display="inline"><semantics id="Sx1.F1.5.m2.1b"><mrow id="Sx1.F1.5.m2.1.1" xref="Sx1.F1.5.m2.1.1.cmml"><mi mathvariant="normal" id="Sx1.F1.5.m2.1.1.2" xref="Sx1.F1.5.m2.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="Sx1.F1.5.m2.1.1.1" xref="Sx1.F1.5.m2.1.1.1.cmml">​</mo><msub id="Sx1.F1.5.m2.1.1.3" xref="Sx1.F1.5.m2.1.1.3.cmml"><mi id="Sx1.F1.5.m2.1.1.3.2" xref="Sx1.F1.5.m2.1.1.3.2.cmml">W</mi><mi id="Sx1.F1.5.m2.1.1.3.3" xref="Sx1.F1.5.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="Sx1.F1.5.m2.1c"><apply id="Sx1.F1.5.m2.1.1.cmml" xref="Sx1.F1.5.m2.1.1"><times id="Sx1.F1.5.m2.1.1.1.cmml" xref="Sx1.F1.5.m2.1.1.1"></times><ci id="Sx1.F1.5.m2.1.1.2.cmml" xref="Sx1.F1.5.m2.1.1.2">Δ</ci><apply id="Sx1.F1.5.m2.1.1.3.cmml" xref="Sx1.F1.5.m2.1.1.3"><csymbol cd="ambiguous" id="Sx1.F1.5.m2.1.1.3.1.cmml" xref="Sx1.F1.5.m2.1.1.3">subscript</csymbol><ci id="Sx1.F1.5.m2.1.1.3.2.cmml" xref="Sx1.F1.5.m2.1.1.3.2">𝑊</ci><ci id="Sx1.F1.5.m2.1.1.3.3.cmml" xref="Sx1.F1.5.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx1.F1.5.m2.1d">\Delta W_{i}</annotation></semantics></math>) with the Server, who aggregates them (e.g. by averaging) and broadcast the resulting model update (i.e. <math id="Sx1.F1.6.m3.1" class="ltx_Math" alttext="\Delta W" display="inline"><semantics id="Sx1.F1.6.m3.1b"><mrow id="Sx1.F1.6.m3.1.1" xref="Sx1.F1.6.m3.1.1.cmml"><mi mathvariant="normal" id="Sx1.F1.6.m3.1.1.2" xref="Sx1.F1.6.m3.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="Sx1.F1.6.m3.1.1.1" xref="Sx1.F1.6.m3.1.1.1.cmml">​</mo><mi id="Sx1.F1.6.m3.1.1.3" xref="Sx1.F1.6.m3.1.1.3.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx1.F1.6.m3.1c"><apply id="Sx1.F1.6.m3.1.1.cmml" xref="Sx1.F1.6.m3.1.1"><times id="Sx1.F1.6.m3.1.1.1.cmml" xref="Sx1.F1.6.m3.1.1.1"></times><ci id="Sx1.F1.6.m3.1.1.2.cmml" xref="Sx1.F1.6.m3.1.1.2">Δ</ci><ci id="Sx1.F1.6.m3.1.1.3.cmml" xref="Sx1.F1.6.m3.1.1.3">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx1.F1.6.m3.1d">\Delta W</annotation></semantics></math>) back to the clients.</figcaption>
</figure>
<div id="Sx1.p4" class="ltx_para">
<p id="Sx1.p4.1" class="ltx_p">Federated Learning has already been used in several application fields where the data are sensitive. It originally emerged <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al. <a href="#bib.bib27" title="" class="ltx_ref">2017</a>)</cite> as part of edge computing with mobile applications for which user data were too sensitive to gather in a single place. It has also been used in the automotive industry and more extensively in healthcare where medical data are highly regulated and sometimes too valuable to share openly <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a href="#bib.bib22" title="" class="ltx_ref">2020a</a>)</cite>. There has been numerous academic publications about Federated Learning with virtually split data sets <cite class="ltx_cite ltx_citemacro_citep">(Mammen <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Li et al. <a href="#bib.bib23" title="" class="ltx_ref">2020b</a>)</cite>, but the deployment of such technology in real life has been much scarcer. Industry-scale federated learning comes hand-in-hand with many challenges like scalability (computationally) as well as the synchronization of the data preparation and the orchestration of different partners operationally.</p>
</div>
<div id="Sx1.p5" class="ltx_para">
<p id="Sx1.p5.1" class="ltx_p">In this paper, we describe a real world application for drug discovery in the context of a European Innovative Medicines Initiative (IMI) project called MELLODDY (grant n°831472), which gathered 10 pharmaceutical companies, academic research labs, large industrial companies and startups. The platform developed for MELLODDY project enabled to produce scientific results described in the work of <cite class="ltx_cite ltx_citemacro_citet">Heyndrickx et al. (<a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite>. The data used in MELLODDY were chemical and assay data resulting from research conducted by ten pharmaceutical companies over the span of decades. The companies treat these data as trade secrets, as the vast majority of it is not yet protected by patents and therefore cannot be disclosed to the public or to competitors. Thus, no pharmaceutical company is willing to share its data with another. However, they are interested in sharing common predictive models which have been trained using a scheme visualised in Figure <a href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> on their combined data sets, provided their data sets can not be accessed or inferred by anyone.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">MELLODDY Use Case</h2>

<section id="Sx2.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Data</h3>

<div id="Sx2.SSx1.p1" class="ltx_para">
<p id="Sx2.SSx1.p1.1" class="ltx_p">MELLODDY built machine-learning models on data resulting from in vitro bioassay measurements on small molecule samples in the early phases of drug discovery <cite class="ltx_cite ltx_citemacro_citep">(Hughes et al. <a href="#bib.bib20" title="" class="ltx_ref">2011</a>)</cite>. The main prediction tasks were from assays run in concentration-response mode, where a compound is measured at multiple concentrations from which an AC50 value is derived <cite class="ltx_cite ltx_citemacro_citep">(Beck et al. <a href="#bib.bib3" title="" class="ltx_ref">2004</a>)</cite>, typically by the use of automated curve fitting system <cite class="ltx_cite ltx_citemacro_citep">(Gubler et al. <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>. These data are very sparse; far less than 1% of the structure activity matrix is filled. Single concentration high-throughput screening <cite class="ltx_cite ltx_citemacro_citep">(Macarrón and Hertzberg <a href="#bib.bib25" title="" class="ltx_ref">2011</a>)</cite> data is available in larger volumes, and can be used as auxiliary tasks to be included in the training, but ignored for performance evaluation purposes.
In contrast to other efforts focusing on public data, where results of bioassays on the same target were merged into one task, for example  <cite class="ltx_cite ltx_citemacro_citep">(Sturm et al. <a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite> , each bioassay in MELLODDY was presented as its own task (or group of tasks). This means that there was little overlap between the prediction tasks of different pharmaceutical companies, as the companies may have overlapping target portfolios, but typically do not share assay protocols.</p>
</div>
<div id="Sx2.SSx1.p2" class="ltx_para">
<p id="Sx2.SSx1.p2.1" class="ltx_p">The data preparation process was executed by the pharma partners on premise, according to a data preparation manual <cite class="ltx_cite ltx_citemacro_citep">(Heyndrickx et al. <a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite>. The first stage consisted of extracting the data from the individual data warehouses into a standardized file format. Here the partners selected the assays to include, applied unit conversions and scaling, and assigned the correct assay type. The second stage of the data preparation was done using a shared code package called MELLODDY Tuner <cite class="ltx_cite ltx_citemacro_citep">(Friedrich <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>, which was built on the open source cheminformatics toolkit RDkit <cite class="ltx_cite ltx_citemacro_citep">(Landrum et al. <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite>. MELLODDY Tuner processes the chemical structures and performs structure standardization, calculation of the Morgan Fingerprint representation <cite class="ltx_cite ltx_citemacro_citep">(Rogers and Hahn <a href="#bib.bib37" title="" class="ltx_ref">2010</a>)</cite> used as features for machine learning, and assignment of train-test fold split <cite class="ltx_cite ltx_citemacro_citep">(Simm et al. <a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite>. The following four processing steps were performed on the activity data: (1) plausibility checks on activity values, (2) replication of aggregation, (3) identification and application of classification thresholds for classification models and (4) filtering of tasks by data volume quorum to ensure sufficient data for training and robust performance metric calculation.</p>
</div>
<div id="Sx2.SSx1.p3" class="ltx_para">
<p id="Sx2.SSx1.p3.1" class="ltx_p">Finally, the data was written out in sparse matrix format required for the machine learning algorithm. At this stage, only the data necessary for machine learning was retained, namely the structure feature matrix, the fold allocation information, the matrix with the task labels, and a list of task weights. Different data sets were created this way: a classification data set (CLS) with only classification tasks, a classification data set including auxiliary tasks (CLSAUX), a regression data set with only regression tasks (REG) and a hybrid data set with both classification and regression tasks (HYB). The use of MELLODDY tuner and the jointly-approved Data Preparation Manual ensured the consistency and compatibility of the data prepared by each partner.</p>
</div>
<div id="Sx2.SSx1.p4" class="ltx_para">
<p id="Sx2.SSx1.p4.3" class="ltx_p">The chemical structures originally exported from data warehouses in the first stage, as well as any assay metadata, such as assay names or targets, were removed. This ensured that only the minimally required data set was present on the machine learning platform. On the platform the tasks were identified by the column index in the label matrix, and only the pharma partners kept on their end the metadata file allowing to map back model predictions to the original assays. In total, the pharma partners included data from <math id="Sx2.SSx1.p4.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="Sx2.SSx1.p4.1.m1.1a"><mo id="Sx2.SSx1.p4.1.m1.1.1" xref="Sx2.SSx1.p4.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p4.1.m1.1b"><csymbol cd="latexml" id="Sx2.SSx1.p4.1.m1.1.1.cmml" xref="Sx2.SSx1.p4.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx1.p4.1.m1.1c">\sim</annotation></semantics></math>100 million measurements covering over 40,000 assays and <math id="Sx2.SSx1.p4.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="Sx2.SSx1.p4.2.m2.1a"><mo id="Sx2.SSx1.p4.2.m2.1.1" xref="Sx2.SSx1.p4.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p4.2.m2.1b"><csymbol cd="latexml" id="Sx2.SSx1.p4.2.m2.1.1.cmml" xref="Sx2.SSx1.p4.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx1.p4.2.m2.1c">\sim</annotation></semantics></math>20 million compounds for the main prediction tasks. Added to this this were <math id="Sx2.SSx1.p4.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="Sx2.SSx1.p4.3.m3.1a"><mo id="Sx2.SSx1.p4.3.m3.1.1" xref="Sx2.SSx1.p4.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p4.3.m3.1b"><csymbol cd="latexml" id="Sx2.SSx1.p4.3.m3.1.1.cmml" xref="Sx2.SSx1.p4.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx1.p4.3.m3.1c">\sim</annotation></semantics></math>2 billion measurements from auxiliary assays.</p>
</div>
</section>
<section id="Sx2.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Federated Learning Formulation</h3>

<div id="Sx2.SSx2.p1" class="ltx_para">
<p id="Sx2.SSx2.p1.3" class="ltx_p">The principle goal of federated learning is to train a global model by minimizing a global objective function <math id="Sx2.SSx2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{t}" display="inline"><semantics id="Sx2.SSx2.p1.1.m1.1a"><msub id="Sx2.SSx2.p1.1.m1.1.1" xref="Sx2.SSx2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.1.m1.1.1.2" xref="Sx2.SSx2.p1.1.m1.1.1.2.cmml">ℒ</mi><mi id="Sx2.SSx2.p1.1.m1.1.1.3" xref="Sx2.SSx2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.1.m1.1b"><apply id="Sx2.SSx2.p1.1.m1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.1.m1.1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.1.1">subscript</csymbol><ci id="Sx2.SSx2.p1.1.m1.1.1.2.cmml" xref="Sx2.SSx2.p1.1.m1.1.1.2">ℒ</ci><ci id="Sx2.SSx2.p1.1.m1.1.1.3.cmml" xref="Sx2.SSx2.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.1.m1.1c">\mathcal{L}_{t}</annotation></semantics></math> which represents the weighted sum of the local objective functions <math id="Sx2.SSx2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{p}" display="inline"><semantics id="Sx2.SSx2.p1.2.m2.1a"><msub id="Sx2.SSx2.p1.2.m2.1.1" xref="Sx2.SSx2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.2.m2.1.1.2" xref="Sx2.SSx2.p1.2.m2.1.1.2.cmml">ℒ</mi><mi id="Sx2.SSx2.p1.2.m2.1.1.3" xref="Sx2.SSx2.p1.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.2.m2.1b"><apply id="Sx2.SSx2.p1.2.m2.1.1.cmml" xref="Sx2.SSx2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.2.m2.1.1.1.cmml" xref="Sx2.SSx2.p1.2.m2.1.1">subscript</csymbol><ci id="Sx2.SSx2.p1.2.m2.1.1.2.cmml" xref="Sx2.SSx2.p1.2.m2.1.1.2">ℒ</ci><ci id="Sx2.SSx2.p1.2.m2.1.1.3.cmml" xref="Sx2.SSx2.p1.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.2.m2.1c">\mathcal{L}_{p}</annotation></semantics></math> of each partner contributing with private data <math id="Sx2.SSx2.p1.3.m3.1" class="ltx_Math" alttext="\mathrm{D}_{p}" display="inline"><semantics id="Sx2.SSx2.p1.3.m3.1a"><msub id="Sx2.SSx2.p1.3.m3.1.1" xref="Sx2.SSx2.p1.3.m3.1.1.cmml"><mi mathvariant="normal" id="Sx2.SSx2.p1.3.m3.1.1.2" xref="Sx2.SSx2.p1.3.m3.1.1.2.cmml">D</mi><mi id="Sx2.SSx2.p1.3.m3.1.1.3" xref="Sx2.SSx2.p1.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.3.m3.1b"><apply id="Sx2.SSx2.p1.3.m3.1.1.cmml" xref="Sx2.SSx2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.3.m3.1.1.1.cmml" xref="Sx2.SSx2.p1.3.m3.1.1">subscript</csymbol><ci id="Sx2.SSx2.p1.3.m3.1.1.2.cmml" xref="Sx2.SSx2.p1.3.m3.1.1.2">D</ci><ci id="Sx2.SSx2.p1.3.m3.1.1.3.cmml" xref="Sx2.SSx2.p1.3.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.3.m3.1c">\mathrm{D}_{p}</annotation></semantics></math> to the global federated model:</p>
<table id="Sx2.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="Sx2.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="Sx2.E1X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\min_{\theta}{\mathcal{L}_{t}(\mathrm{D},\theta)}\;\;\text{with}" display="inline"><semantics id="Sx2.E1X.2.1.1.m1.2a"><mrow id="Sx2.E1X.2.1.1.m1.2.3" xref="Sx2.E1X.2.1.1.m1.2.3.cmml"><mrow id="Sx2.E1X.2.1.1.m1.2.3.2" xref="Sx2.E1X.2.1.1.m1.2.3.2.cmml"><munder id="Sx2.E1X.2.1.1.m1.2.3.2.1" xref="Sx2.E1X.2.1.1.m1.2.3.2.1.cmml"><mi id="Sx2.E1X.2.1.1.m1.2.3.2.1.2" xref="Sx2.E1X.2.1.1.m1.2.3.2.1.2.cmml">min</mi><mi id="Sx2.E1X.2.1.1.m1.2.3.2.1.3" xref="Sx2.E1X.2.1.1.m1.2.3.2.1.3.cmml">θ</mi></munder><mo lspace="0.167em" id="Sx2.E1X.2.1.1.m1.2.3.2a" xref="Sx2.E1X.2.1.1.m1.2.3.2.cmml">⁡</mo><msub id="Sx2.E1X.2.1.1.m1.2.3.2.2" xref="Sx2.E1X.2.1.1.m1.2.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.E1X.2.1.1.m1.2.3.2.2.2" xref="Sx2.E1X.2.1.1.m1.2.3.2.2.2.cmml">ℒ</mi><mi id="Sx2.E1X.2.1.1.m1.2.3.2.2.3" xref="Sx2.E1X.2.1.1.m1.2.3.2.2.3.cmml">t</mi></msub></mrow><mo lspace="0em" rspace="0em" id="Sx2.E1X.2.1.1.m1.2.3.1" xref="Sx2.E1X.2.1.1.m1.2.3.1.cmml">​</mo><mrow id="Sx2.E1X.2.1.1.m1.2.3.3.2" xref="Sx2.E1X.2.1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="Sx2.E1X.2.1.1.m1.2.3.3.2.1" xref="Sx2.E1X.2.1.1.m1.2.3.3.1.cmml">(</mo><mi mathvariant="normal" id="Sx2.E1X.2.1.1.m1.1.1" xref="Sx2.E1X.2.1.1.m1.1.1.cmml">D</mi><mo id="Sx2.E1X.2.1.1.m1.2.3.3.2.2" xref="Sx2.E1X.2.1.1.m1.2.3.3.1.cmml">,</mo><mi id="Sx2.E1X.2.1.1.m1.2.2" xref="Sx2.E1X.2.1.1.m1.2.2.cmml">θ</mi><mo stretchy="false" id="Sx2.E1X.2.1.1.m1.2.3.3.2.3" xref="Sx2.E1X.2.1.1.m1.2.3.3.1.cmml">)</mo></mrow><mo lspace="0.560em" rspace="0em" id="Sx2.E1X.2.1.1.m1.2.3.1a" xref="Sx2.E1X.2.1.1.m1.2.3.1.cmml">​</mo><mtext id="Sx2.E1X.2.1.1.m1.2.3.4" xref="Sx2.E1X.2.1.1.m1.2.3.4a.cmml">with</mtext></mrow><annotation-xml encoding="MathML-Content" id="Sx2.E1X.2.1.1.m1.2b"><apply id="Sx2.E1X.2.1.1.m1.2.3.cmml" xref="Sx2.E1X.2.1.1.m1.2.3"><times id="Sx2.E1X.2.1.1.m1.2.3.1.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.1"></times><apply id="Sx2.E1X.2.1.1.m1.2.3.2.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2"><apply id="Sx2.E1X.2.1.1.m1.2.3.2.1.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.1"><csymbol cd="ambiguous" id="Sx2.E1X.2.1.1.m1.2.3.2.1.1.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.1">subscript</csymbol><min id="Sx2.E1X.2.1.1.m1.2.3.2.1.2.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.1.2"></min><ci id="Sx2.E1X.2.1.1.m1.2.3.2.1.3.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.1.3">𝜃</ci></apply><apply id="Sx2.E1X.2.1.1.m1.2.3.2.2.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="Sx2.E1X.2.1.1.m1.2.3.2.2.1.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.2">subscript</csymbol><ci id="Sx2.E1X.2.1.1.m1.2.3.2.2.2.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.2.2">ℒ</ci><ci id="Sx2.E1X.2.1.1.m1.2.3.2.2.3.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.2.2.3">𝑡</ci></apply></apply><interval closure="open" id="Sx2.E1X.2.1.1.m1.2.3.3.1.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.3.2"><ci id="Sx2.E1X.2.1.1.m1.1.1.cmml" xref="Sx2.E1X.2.1.1.m1.1.1">D</ci><ci id="Sx2.E1X.2.1.1.m1.2.2.cmml" xref="Sx2.E1X.2.1.1.m1.2.2">𝜃</ci></interval><ci id="Sx2.E1X.2.1.1.m1.2.3.4a.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.4"><mtext id="Sx2.E1X.2.1.1.m1.2.3.4.cmml" xref="Sx2.E1X.2.1.1.m1.2.3.4">with</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.E1X.2.1.1.m1.2c">\displaystyle\min_{\theta}{\mathcal{L}_{t}(\mathrm{D},\theta)}\;\;\text{with}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr id="Sx2.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="Sx2.E1Xa.2.1.1.m1.3" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{t}(\mathrm{D},\theta)=\sum_{p=1}^{P}{w_{p}\mathcal{L}_{p}(\mathrm{D}_{p},\theta_{p})},\;\;\bigcap_{p=1}^{p}\theta_{p}\neq\varnothing." display="inline"><semantics id="Sx2.E1Xa.2.1.1.m1.3a"><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1"><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.3.cmml"><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.cmml"><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.cmml"><msub id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.2.cmml">ℒ</mi><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.1.cmml">​</mo><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.1.cmml"><mo stretchy="false" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.2.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.1.cmml">(</mo><mi mathvariant="normal" id="Sx2.E1Xa.2.1.1.m1.1.1" xref="Sx2.E1Xa.2.1.1.m1.1.1.cmml">D</mi><mo id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.1.cmml">,</mo><mi id="Sx2.E1Xa.2.1.1.m1.2.2" xref="Sx2.E1Xa.2.1.1.m1.2.2.cmml">θ</mi><mo stretchy="false" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.1.cmml">)</mo></mrow></mrow><mo id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.3.cmml">=</mo><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.cmml"><mstyle displaystyle="true" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.cmml"><munderover id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3a" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.cmml"><mo movablelimits="false" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.2.cmml">∑</mo><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.cmml"><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.2.cmml">p</mi><mo id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.1.cmml">=</mo><mn id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.3.cmml">1</mn></mrow><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.3.cmml">P</mi></munderover></mstyle><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.cmml"><msub id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.cmml"><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.2.cmml">w</mi><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.3.cmml">​</mo><msub id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.2.cmml">ℒ</mi><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.3a" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.3.cmml">​</mo><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.3.cmml"><mo stretchy="false" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.3.cmml">(</mo><msub id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">D</mi><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.4" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.3.cmml">,</mo><msub id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.cmml"><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.2.cmml">θ</mi><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.3.cmml">p</mi></msub><mo stretchy="false" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.5" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo rspace="0.727em" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.3a.cmml">,</mo><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.cmml"><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.cmml"><munderover id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1a" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.cmml"><mo movablelimits="false" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.2.cmml">⋂</mo><mrow id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.cmml"><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.2.cmml">p</mi><mo id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.1.cmml">=</mo><mn id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.3.cmml">1</mn></mrow><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.3.cmml">p</mi></munderover></mstyle><msub id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.cmml"><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.2" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.2.cmml">θ</mi><mi id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.3.cmml">p</mi></msub></mrow><mo id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.1" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.1.cmml">≠</mo><mi mathvariant="normal" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.3" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.3.cmml">∅</mi></mrow></mrow><mo lspace="0em" id="Sx2.E1Xa.2.1.1.m1.3.3.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx2.E1Xa.2.1.1.m1.3b"><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.3a.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1"><eq id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.3"></eq><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4"><times id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.1"></times><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2">subscript</csymbol><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.2">ℒ</ci><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.2.3">𝑡</ci></apply><interval closure="open" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.4.3.2"><ci id="Sx2.E1Xa.2.1.1.m1.1.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.1.1">D</ci><ci id="Sx2.E1Xa.2.1.1.m1.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.2.2">𝜃</ci></interval></apply><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2"><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3">superscript</csymbol><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3">subscript</csymbol><sum id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.2"></sum><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3"><eq id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.1"></eq><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.2">𝑝</ci><cn type="integer" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.2.3.3">1</cn></apply></apply><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.3.3">𝑃</ci></apply><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2"><times id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.3"></times><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4">subscript</csymbol><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.2">𝑤</ci><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.4.3">𝑝</ci></apply><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5">subscript</csymbol><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.2">ℒ</ci><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.5.3">𝑝</ci></apply><interval closure="open" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2"><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.2">D</ci><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.3">𝑝</ci></apply><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.2">𝜃</ci><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.1.1.2.2.2.2.2.3">𝑝</ci></apply></interval></apply></apply></apply><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2"><neq id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.1"></neq><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2"><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1">superscript</csymbol><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1">subscript</csymbol><intersect id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.2"></intersect><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3"><eq id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.1"></eq><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.2">𝑝</ci><cn type="integer" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.2.3.3">1</cn></apply></apply><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.1.3">𝑝</ci></apply><apply id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.1.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.2.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.2">𝜃</ci><ci id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.2.2.3">𝑝</ci></apply></apply><emptyset id="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.3.cmml" xref="Sx2.E1Xa.2.1.1.m1.3.3.1.1.2.2.3"></emptyset></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.E1Xa.2.1.1.m1.3c">\displaystyle\mathcal{L}_{t}(\mathrm{D},\theta)=\sum_{p=1}^{P}{w_{p}\mathcal{L}_{p}(\mathrm{D}_{p},\theta_{p})},\;\;\bigcap_{p=1}^{p}\theta_{p}\neq\varnothing.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="Sx2.SSx2.p1.14" class="ltx_p">The data <math id="Sx2.SSx2.p1.4.m1.1" class="ltx_Math" alttext="\mathrm{D}" display="inline"><semantics id="Sx2.SSx2.p1.4.m1.1a"><mi mathvariant="normal" id="Sx2.SSx2.p1.4.m1.1.1" xref="Sx2.SSx2.p1.4.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.4.m1.1b"><ci id="Sx2.SSx2.p1.4.m1.1.1.cmml" xref="Sx2.SSx2.p1.4.m1.1.1">D</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.4.m1.1c">\mathrm{D}</annotation></semantics></math>, with <math id="Sx2.SSx2.p1.5.m2.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="Sx2.SSx2.p1.5.m2.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.5.m2.1.1" xref="Sx2.SSx2.p1.5.m2.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.5.m2.1b"><ci id="Sx2.SSx2.p1.5.m2.1.1.cmml" xref="Sx2.SSx2.p1.5.m2.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.5.m2.1c">\mathcal{X}</annotation></semantics></math> as feature space, <math id="Sx2.SSx2.p1.6.m3.1" class="ltx_Math" alttext="\mathcal{Y}" display="inline"><semantics id="Sx2.SSx2.p1.6.m3.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.6.m3.1.1" xref="Sx2.SSx2.p1.6.m3.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.6.m3.1b"><ci id="Sx2.SSx2.p1.6.m3.1.1.cmml" xref="Sx2.SSx2.p1.6.m3.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.6.m3.1c">\mathcal{Y}</annotation></semantics></math> as label space and <math id="Sx2.SSx2.p1.7.m4.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="Sx2.SSx2.p1.7.m4.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.7.m4.1.1" xref="Sx2.SSx2.p1.7.m4.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.7.m4.1b"><ci id="Sx2.SSx2.p1.7.m4.1.1.cmml" xref="Sx2.SSx2.p1.7.m4.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.7.m4.1c">\mathcal{I}</annotation></semantics></math> as sample ID space, of the <math id="Sx2.SSx2.p1.8.m5.1" class="ltx_Math" alttext="P" display="inline"><semantics id="Sx2.SSx2.p1.8.m5.1a"><mi id="Sx2.SSx2.p1.8.m5.1.1" xref="Sx2.SSx2.p1.8.m5.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.8.m5.1b"><ci id="Sx2.SSx2.p1.8.m5.1.1.cmml" xref="Sx2.SSx2.p1.8.m5.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.8.m5.1c">P</annotation></semantics></math> partners can have several distribution characteristics. In the work of <cite class="ltx_cite ltx_citemacro_citet">Yang et al. (<a href="#bib.bib46" title="" class="ltx_ref">2019</a>)</cite> a categorisation is proposed for federated learning (FL) depending on the distribution characteristics of the data, e.g. horizontal and vertical FL. In the MELLODDY use case, the feature space <math id="Sx2.SSx2.p1.9.m6.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="Sx2.SSx2.p1.9.m6.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.9.m6.1.1" xref="Sx2.SSx2.p1.9.m6.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.9.m6.1b"><ci id="Sx2.SSx2.p1.9.m6.1.1.cmml" xref="Sx2.SSx2.p1.9.m6.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.9.m6.1c">\mathcal{X}</annotation></semantics></math> is the same for all partners however in general the label space <math id="Sx2.SSx2.p1.10.m7.1" class="ltx_Math" alttext="\mathcal{Y}" display="inline"><semantics id="Sx2.SSx2.p1.10.m7.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.10.m7.1.1" xref="Sx2.SSx2.p1.10.m7.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.10.m7.1b"><ci id="Sx2.SSx2.p1.10.m7.1.1.cmml" xref="Sx2.SSx2.p1.10.m7.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.10.m7.1c">\mathcal{Y}</annotation></semantics></math> and sample ID space <math id="Sx2.SSx2.p1.11.m8.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="Sx2.SSx2.p1.11.m8.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.11.m8.1.1" xref="Sx2.SSx2.p1.11.m8.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.11.m8.1b"><ci id="Sx2.SSx2.p1.11.m8.1.1.cmml" xref="Sx2.SSx2.p1.11.m8.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.11.m8.1c">\mathcal{I}</annotation></semantics></math> would differ:
<math id="Sx2.SSx2.p1.12.m9.2" class="ltx_Math" alttext="\mathcal{X}_{i}=\mathcal{X}_{j},\quad\mathcal{Y}_{i}\neq\mathcal{Y}_{j},\quad\mathcal{I}_{i}\neq\mathcal{I}_{j},\quad\forall\mathrm{D}_{i},\mathrm{D}_{j},i\neq j" display="inline"><semantics id="Sx2.SSx2.p1.12.m9.2a"><mrow id="Sx2.SSx2.p1.12.m9.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.3.cmml"><mrow id="Sx2.SSx2.p1.12.m9.1.1.1.1" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.cmml"><msub id="Sx2.SSx2.p1.12.m9.1.1.1.1.2" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.12.m9.1.1.1.1.2.2" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2.2.cmml">𝒳</mi><mi id="Sx2.SSx2.p1.12.m9.1.1.1.1.2.3" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2.3.cmml">i</mi></msub><mo id="Sx2.SSx2.p1.12.m9.1.1.1.1.1" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.1.cmml">=</mo><msub id="Sx2.SSx2.p1.12.m9.1.1.1.1.3" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.12.m9.1.1.1.1.3.2" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3.2.cmml">𝒳</mi><mi id="Sx2.SSx2.p1.12.m9.1.1.1.1.3.3" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo rspace="1.167em" id="Sx2.SSx2.p1.12.m9.2.2.2.3" xref="Sx2.SSx2.p1.12.m9.2.2.3a.cmml">,</mo><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.3.cmml"><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.cmml"><msub id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.2.cmml">𝒴</mi><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.3.cmml">i</mi></msub><mo id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.1" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.1.cmml">≠</mo><msub id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.2.cmml">𝒴</mi><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.3.cmml">j</mi></msub></mrow><mo rspace="1.167em" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.3a.cmml">,</mo><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.3.cmml"><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.cmml"><msub id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.2.cmml">ℐ</mi><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.3.cmml">i</mi></msub><mo id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.4" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.4.cmml">≠</mo><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.4.cmml"><msub id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.2.cmml">ℐ</mi><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.3.cmml">j</mi></msub><mo rspace="1.167em" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.4" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.4.cmml">,</mo><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.cmml"><mo rspace="0.167em" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.1" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.1.cmml">∀</mo><msub id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.cmml"><mi mathvariant="normal" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.2.cmml">D</mi><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.3.cmml">i</mi></msub></mrow><mo id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.5" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.4.cmml">,</mo><msub id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.cmml"><mi mathvariant="normal" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.2.cmml">D</mi><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.3.cmml">j</mi></msub></mrow></mrow><mo id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.3a.cmml">,</mo><mrow id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.cmml"><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.2" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.2.cmml">i</mi><mo id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.1" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.1.cmml">≠</mo><mi id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.3" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.3.cmml">j</mi></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.12.m9.2b"><apply id="Sx2.SSx2.p1.12.m9.2.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.3a.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.3">formulae-sequence</csymbol><apply id="Sx2.SSx2.p1.12.m9.1.1.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1"><eq id="Sx2.SSx2.p1.12.m9.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.1"></eq><apply id="Sx2.SSx2.p1.12.m9.1.1.1.1.2.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.1.1.1.1.2.1.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.1.1.1.1.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2.2">𝒳</ci><ci id="Sx2.SSx2.p1.12.m9.1.1.1.1.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.2.3">𝑖</ci></apply><apply id="Sx2.SSx2.p1.12.m9.1.1.1.1.3.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.1.1.1.1.3.1.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.1.1.1.1.3.2.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3.2">𝒳</ci><ci id="Sx2.SSx2.p1.12.m9.1.1.1.1.3.3.cmml" xref="Sx2.SSx2.p1.12.m9.1.1.1.1.3.3">𝑗</ci></apply></apply><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.3a.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1"><neq id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.1"></neq><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.2">𝒴</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.2.3">𝑖</ci></apply><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.2">𝒴</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.1.1.3.3">𝑗</ci></apply></apply><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.3a.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1"><neq id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.4.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.4"></neq><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.2">ℐ</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.5.3">𝑖</ci></apply><list id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.4.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3"><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.2">ℐ</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.1.1.1.3">𝑗</ci></apply><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2"><csymbol cd="latexml" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.1">for-all</csymbol><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.2">D</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.2.2.2.2.3">𝑖</ci></apply></apply><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3">subscript</csymbol><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.2">D</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.1.1.3.3.3.3">𝑗</ci></apply></list></apply><apply id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2"><neq id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.1.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.1"></neq><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.2.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.2">𝑖</ci><ci id="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.3.cmml" xref="Sx2.SSx2.p1.12.m9.2.2.2.2.2.2.2.2.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.12.m9.2c">\mathcal{X}_{i}=\mathcal{X}_{j},\quad\mathcal{Y}_{i}\neq\mathcal{Y}_{j},\quad\mathcal{I}_{i}\neq\mathcal{I}_{j},\quad\forall\mathrm{D}_{i},\mathrm{D}_{j},i\neq j</annotation></semantics></math>.
In practice we expect some (slight) overlap among the participating partners in label space <math id="Sx2.SSx2.p1.13.m10.1" class="ltx_Math" alttext="\mathcal{Y}" display="inline"><semantics id="Sx2.SSx2.p1.13.m10.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.13.m10.1.1" xref="Sx2.SSx2.p1.13.m10.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.13.m10.1b"><ci id="Sx2.SSx2.p1.13.m10.1.1.cmml" xref="Sx2.SSx2.p1.13.m10.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.13.m10.1c">\mathcal{Y}</annotation></semantics></math> and sample ID space <math id="Sx2.SSx2.p1.14.m11.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="Sx2.SSx2.p1.14.m11.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.14.m11.1.1" xref="Sx2.SSx2.p1.14.m11.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.14.m11.1b"><ci id="Sx2.SSx2.p1.14.m11.1.1.cmml" xref="Sx2.SSx2.p1.14.m11.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.14.m11.1c">\mathcal{I}</annotation></semantics></math> in order to enable federated transfer learning.</p>
</div>
<div id="Sx2.SSx2.p2" class="ltx_para">
<p id="Sx2.SSx2.p2.1" class="ltx_p">A possible scheme for learning a global model in a federated way would be by using Federated Averaging(FedAvg) <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al. <a href="#bib.bib27" title="" class="ltx_ref">2017</a>)</cite> proposed by Google. In this scheme, a global model is trained based on iterative averaging orchestrated by a central server where the number of participants is typically large. It concerns a cross-device FL setting where the learning takes place remotely for multiple iterations instead of updating the model every iteration to decrease communication at the cost of model performance.</p>
</div>
<div id="Sx2.SSx2.p3" class="ltx_para">
<p id="Sx2.SSx2.p3.1" class="ltx_p">In contrast to cross-device FL, MELLODDY is a cross-silo FL scenario, which involved small number of participants (simply 10 pharmaceutical companies) who participated and contributed to the federated model each learning iteration. The scheme used in MELLODDY was based on secure aggregation for federated learning <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al. <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite> where the gradients of all participating partners were aggregated each iteration in a cryptographic, secure way to update the global model (see Figure <a href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) instead of sending the model weights and averaging them as in FedAvg.</p>
</div>
</section>
<section id="Sx2.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Models</h3>

<section id="Sx2.SSx3.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">SparseChem: Base Model for MELLODDY</h4>

<div id="Sx2.SSx3.SSSx1.p1" class="ltx_para">
<p id="Sx2.SSx3.SSSx1.p1.1" class="ltx_p">Multi-task learning <cite class="ltx_cite ltx_citemacro_citep">(Caruana <a href="#bib.bib6" title="" class="ltx_ref">1997</a>)</cite>, a paradigm also often used in the drug discovery <cite class="ltx_cite ltx_citemacro_citep">(Dahl et al. <a href="#bib.bib8" title="" class="ltx_ref">2014</a>; Simões et al. <a href="#bib.bib41" title="" class="ltx_ref">2018</a>)</cite> field for for quantitative structure–activity relationship (QSAR) models, enables the joint training of a machine learning model where related tasks are involved.
SparseChem <cite class="ltx_cite ltx_citemacro_citep">(Arany et al. <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> offers an easy and efficient way to train an industry-scale (millions of input compounds) multi-task QSAR deep neural network models with high-dimensional sparse input features. SparseChem supports classification, (censored) regression and hybrid (both classification and regression) models and were used as base model for MELLODDY for the single partner baseline models but also for the global model from the federated platform as visualised in Figure <a href="#Sx2.F2" title="Figure 2 ‣ Federated Model: Private Head and Common Trunk ‣ Models ‣ MELLODDY Use Case ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="Sx2.SSx3.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Federated Model: Private Head and Common Trunk</h4>

<div id="Sx2.SSx3.SSSx2.p1" class="ltx_para">
<p id="Sx2.SSx3.SSSx2.p1.1" class="ltx_p">The contributing partners to the global federated model can all have different tasks which should be kept private to each partner; this is therefore split into a private head and a common trunk as visualised in Figure <a href="#Sx2.F2" title="Figure 2 ‣ Federated Model: Private Head and Common Trunk ‣ Models ‣ MELLODDY Use Case ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="Sx2.F2" class="ltx_figure"><img src="/html/2210.08871/assets/x2.png" id="Sx2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="184" height="72" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The SparseChem models in this figure have one hidden layer: <math id="Sx2.F2.4.m1.1" class="ltx_Math" alttext="\mathbf{h_{1}}=\sigma(\mathbf{W_{0}}\mathbf{x})" display="inline"><semantics id="Sx2.F2.4.m1.1b"><mrow id="Sx2.F2.4.m1.1.1" xref="Sx2.F2.4.m1.1.1.cmml"><msub id="Sx2.F2.4.m1.1.1.3" xref="Sx2.F2.4.m1.1.1.3.cmml"><mi id="Sx2.F2.4.m1.1.1.3.2" xref="Sx2.F2.4.m1.1.1.3.2.cmml">𝐡</mi><mn id="Sx2.F2.4.m1.1.1.3.3" xref="Sx2.F2.4.m1.1.1.3.3.cmml">𝟏</mn></msub><mo id="Sx2.F2.4.m1.1.1.2" xref="Sx2.F2.4.m1.1.1.2.cmml">=</mo><mrow id="Sx2.F2.4.m1.1.1.1" xref="Sx2.F2.4.m1.1.1.1.cmml"><mi id="Sx2.F2.4.m1.1.1.1.3" xref="Sx2.F2.4.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Sx2.F2.4.m1.1.1.1.2" xref="Sx2.F2.4.m1.1.1.1.2.cmml">​</mo><mrow id="Sx2.F2.4.m1.1.1.1.1.1" xref="Sx2.F2.4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx2.F2.4.m1.1.1.1.1.1.2" xref="Sx2.F2.4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Sx2.F2.4.m1.1.1.1.1.1.1" xref="Sx2.F2.4.m1.1.1.1.1.1.1.cmml"><msub id="Sx2.F2.4.m1.1.1.1.1.1.1.2" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2.cmml"><mi id="Sx2.F2.4.m1.1.1.1.1.1.1.2.2" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2.2.cmml">𝐖</mi><mn id="Sx2.F2.4.m1.1.1.1.1.1.1.2.3" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2.3.cmml">𝟎</mn></msub><mo lspace="0em" rspace="0em" id="Sx2.F2.4.m1.1.1.1.1.1.1.1" xref="Sx2.F2.4.m1.1.1.1.1.1.1.1.cmml">​</mo><mi id="Sx2.F2.4.m1.1.1.1.1.1.1.3" xref="Sx2.F2.4.m1.1.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo stretchy="false" id="Sx2.F2.4.m1.1.1.1.1.1.3" xref="Sx2.F2.4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx2.F2.4.m1.1c"><apply id="Sx2.F2.4.m1.1.1.cmml" xref="Sx2.F2.4.m1.1.1"><eq id="Sx2.F2.4.m1.1.1.2.cmml" xref="Sx2.F2.4.m1.1.1.2"></eq><apply id="Sx2.F2.4.m1.1.1.3.cmml" xref="Sx2.F2.4.m1.1.1.3"><csymbol cd="ambiguous" id="Sx2.F2.4.m1.1.1.3.1.cmml" xref="Sx2.F2.4.m1.1.1.3">subscript</csymbol><ci id="Sx2.F2.4.m1.1.1.3.2.cmml" xref="Sx2.F2.4.m1.1.1.3.2">𝐡</ci><cn type="integer" id="Sx2.F2.4.m1.1.1.3.3.cmml" xref="Sx2.F2.4.m1.1.1.3.3">1</cn></apply><apply id="Sx2.F2.4.m1.1.1.1.cmml" xref="Sx2.F2.4.m1.1.1.1"><times id="Sx2.F2.4.m1.1.1.1.2.cmml" xref="Sx2.F2.4.m1.1.1.1.2"></times><ci id="Sx2.F2.4.m1.1.1.1.3.cmml" xref="Sx2.F2.4.m1.1.1.1.3">𝜎</ci><apply id="Sx2.F2.4.m1.1.1.1.1.1.1.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1"><times id="Sx2.F2.4.m1.1.1.1.1.1.1.1.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1.1.1"></times><apply id="Sx2.F2.4.m1.1.1.1.1.1.1.2.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Sx2.F2.4.m1.1.1.1.1.1.1.2.1.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="Sx2.F2.4.m1.1.1.1.1.1.1.2.2.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2.2">𝐖</ci><cn type="integer" id="Sx2.F2.4.m1.1.1.1.1.1.1.2.3.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1.1.2.3">0</cn></apply><ci id="Sx2.F2.4.m1.1.1.1.1.1.1.3.cmml" xref="Sx2.F2.4.m1.1.1.1.1.1.1.3">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.F2.4.m1.1d">\mathbf{h_{1}}=\sigma(\mathbf{W_{0}}\mathbf{x})</annotation></semantics></math> where <math id="Sx2.F2.5.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="Sx2.F2.5.m2.1b"><mi id="Sx2.F2.5.m2.1.1" xref="Sx2.F2.5.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="Sx2.F2.5.m2.1c"><ci id="Sx2.F2.5.m2.1.1.cmml" xref="Sx2.F2.5.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.F2.5.m2.1d">\sigma</annotation></semantics></math> can be a chosen non-linearity (e.g. tanh, relu). The output <math id="Sx2.F2.6.m3.1" class="ltx_Math" alttext="\mathbf{\hat{y}_{n}}=\mathbf{W_{n}}\mathbf{h_{1}}" display="inline"><semantics id="Sx2.F2.6.m3.1b"><mrow id="Sx2.F2.6.m3.1.1" xref="Sx2.F2.6.m3.1.1.cmml"><msub id="Sx2.F2.6.m3.1.1.2" xref="Sx2.F2.6.m3.1.1.2.cmml"><mover accent="true" id="Sx2.F2.6.m3.1.1.2.2" xref="Sx2.F2.6.m3.1.1.2.2.cmml"><mi id="Sx2.F2.6.m3.1.1.2.2.2" xref="Sx2.F2.6.m3.1.1.2.2.2.cmml">𝐲</mi><mo id="Sx2.F2.6.m3.1.1.2.2.1" xref="Sx2.F2.6.m3.1.1.2.2.1.cmml">^</mo></mover><mi id="Sx2.F2.6.m3.1.1.2.3" xref="Sx2.F2.6.m3.1.1.2.3.cmml">𝐧</mi></msub><mo id="Sx2.F2.6.m3.1.1.1" xref="Sx2.F2.6.m3.1.1.1.cmml">=</mo><mrow id="Sx2.F2.6.m3.1.1.3" xref="Sx2.F2.6.m3.1.1.3.cmml"><msub id="Sx2.F2.6.m3.1.1.3.2" xref="Sx2.F2.6.m3.1.1.3.2.cmml"><mi id="Sx2.F2.6.m3.1.1.3.2.2" xref="Sx2.F2.6.m3.1.1.3.2.2.cmml">𝐖</mi><mi id="Sx2.F2.6.m3.1.1.3.2.3" xref="Sx2.F2.6.m3.1.1.3.2.3.cmml">𝐧</mi></msub><mo lspace="0em" rspace="0em" id="Sx2.F2.6.m3.1.1.3.1" xref="Sx2.F2.6.m3.1.1.3.1.cmml">​</mo><msub id="Sx2.F2.6.m3.1.1.3.3" xref="Sx2.F2.6.m3.1.1.3.3.cmml"><mi id="Sx2.F2.6.m3.1.1.3.3.2" xref="Sx2.F2.6.m3.1.1.3.3.2.cmml">𝐡</mi><mn id="Sx2.F2.6.m3.1.1.3.3.3" xref="Sx2.F2.6.m3.1.1.3.3.3.cmml">𝟏</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx2.F2.6.m3.1c"><apply id="Sx2.F2.6.m3.1.1.cmml" xref="Sx2.F2.6.m3.1.1"><eq id="Sx2.F2.6.m3.1.1.1.cmml" xref="Sx2.F2.6.m3.1.1.1"></eq><apply id="Sx2.F2.6.m3.1.1.2.cmml" xref="Sx2.F2.6.m3.1.1.2"><csymbol cd="ambiguous" id="Sx2.F2.6.m3.1.1.2.1.cmml" xref="Sx2.F2.6.m3.1.1.2">subscript</csymbol><apply id="Sx2.F2.6.m3.1.1.2.2.cmml" xref="Sx2.F2.6.m3.1.1.2.2"><ci id="Sx2.F2.6.m3.1.1.2.2.1.cmml" xref="Sx2.F2.6.m3.1.1.2.2.1">^</ci><ci id="Sx2.F2.6.m3.1.1.2.2.2.cmml" xref="Sx2.F2.6.m3.1.1.2.2.2">𝐲</ci></apply><ci id="Sx2.F2.6.m3.1.1.2.3.cmml" xref="Sx2.F2.6.m3.1.1.2.3">𝐧</ci></apply><apply id="Sx2.F2.6.m3.1.1.3.cmml" xref="Sx2.F2.6.m3.1.1.3"><times id="Sx2.F2.6.m3.1.1.3.1.cmml" xref="Sx2.F2.6.m3.1.1.3.1"></times><apply id="Sx2.F2.6.m3.1.1.3.2.cmml" xref="Sx2.F2.6.m3.1.1.3.2"><csymbol cd="ambiguous" id="Sx2.F2.6.m3.1.1.3.2.1.cmml" xref="Sx2.F2.6.m3.1.1.3.2">subscript</csymbol><ci id="Sx2.F2.6.m3.1.1.3.2.2.cmml" xref="Sx2.F2.6.m3.1.1.3.2.2">𝐖</ci><ci id="Sx2.F2.6.m3.1.1.3.2.3.cmml" xref="Sx2.F2.6.m3.1.1.3.2.3">𝐧</ci></apply><apply id="Sx2.F2.6.m3.1.1.3.3.cmml" xref="Sx2.F2.6.m3.1.1.3.3"><csymbol cd="ambiguous" id="Sx2.F2.6.m3.1.1.3.3.1.cmml" xref="Sx2.F2.6.m3.1.1.3.3">subscript</csymbol><ci id="Sx2.F2.6.m3.1.1.3.3.2.cmml" xref="Sx2.F2.6.m3.1.1.3.3.2">𝐡</ci><cn type="integer" id="Sx2.F2.6.m3.1.1.3.3.3.cmml" xref="Sx2.F2.6.m3.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.F2.6.m3.1d">\mathbf{\hat{y}_{n}}=\mathbf{W_{n}}\mathbf{h_{1}}</annotation></semantics></math> is a vector where each element represents a different task.</figcaption>
</figure>
<div id="Sx2.SSx3.SSSx2.p2" class="ltx_para">
<p id="Sx2.SSx3.SSSx2.p2.1" class="ltx_p">During execution of the federated MELLODDY platform, the weights of the common trunk were trained jointly by all contributing partners through the application of federated learning using secure aggregation of the individual private gradients.
The weights for the private head however remained private for all individual partners; likewise, no communication was needed while training, as the private gradients were used directly to update the private head.
After federated training, the resulting model for each partner consisted of stacking the common trunk (which should be the same for all partners) with the private head (which is different and private for all partners).</p>
</div>
</section>
<section id="Sx2.SSx3.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Catalogue Fusion Model</h4>

<div id="Sx2.SSx3.SSSx3.p1" class="ltx_para">
<p id="Sx2.SSx3.SSSx3.p1.1" class="ltx_p">As previously mentioned, tasks may vary across partners and should remain private. However, the algorithm and platform also provides the opportunity for partners to agree on some tasks to be shared among all or a subset of partners. This holds the potential to enhance the model performance, as for these tasks the model weights would be shared completely as visualised in Figure <a href="#Sx2.F2" title="Figure 2 ‣ Federated Model: Private Head and Common Trunk ‣ Models ‣ MELLODDY Use Case ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and trained jointly. In the context of MELLODDY and drug discovery for example, the consortium could allow individual partners to contribute to a shared head where the tasks would represent commercial assays such as safety panels <cite class="ltx_cite ltx_citemacro_citep">(Bowes et al. <a href="#bib.bib5" title="" class="ltx_ref">2012</a>)</cite> performed at contract research organisations (CROs). The catalogue (shared) head would only be shared with partners contributing to the catalogue tasks.</p>
</div>
</section>
</section>
<section id="Sx2.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Risk Analysis</h3>

<div id="Sx2.SSx4.p1" class="ltx_para">
<p id="Sx2.SSx4.p1.1" class="ltx_p">The purpose of Risk analysis is to identify and mitigate risk events caused by stealing or manipulating confidential information
which can have potentially negative impact on the benign participants. To make this analysis as comprehensive as possible, we use a systematic approach detailed in <cite class="ltx_cite ltx_citemacro_citep">(Pejo et al. <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<section id="Sx2.SSx4.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Methodology</h4>

<div id="Sx2.SSx4.SSSx1.p1" class="ltx_para">
<p id="Sx2.SSx4.SSSx1.p1.1" class="ltx_p">The initial step of any risk analysis is to define the perimeter, i.e. the actors and the data involved. These are usually referred as Risk Sources and Assets, respectively. The former is a person or non-human entity that can cause a Risk, accidentally or deliberately. The latter are the confidential or private data that the Risk Sources aim to learn or manipulate, thereby causing Risk. The two primary Risk Sources are the participants (pharma companies) and the coordinator (aggregator) server, while the assets are the Chemical Fingerprint, the Targets, the Bioactivity, and the Model.</p>
</div>
<div id="Sx2.SSx4.SSSx1.p2" class="ltx_para">
<p id="Sx2.SSx4.SSSx1.p2.1" class="ltx_p">A Risk represents the goal of the Risk Source which is to infer confidential information about one of the asset.
A Threat is a sequence of actions (or attacks) carried out by a Risk Source to realize one or more Risks. A Risk is characterized by its impact (which is measured by its associated negative impact called Severity), while a Threat is characterised with its feasibility (which measures the technical difficulty for a Risk Source to realize the Threat). Combining the feasibility and the success probability of these attacks form the likelihood of the Risk, and this further combined with the Severity allows for identifying the most dangerous risks which should be mitigated.</p>
</div>
<div id="Sx2.SSx4.SSSx1.p3" class="ltx_para">
<p id="Sx2.SSx4.SSSx1.p3.6" class="ltx_p">For example, a possible risk is that a participating pharmaceutical company <math id="Sx2.SSx4.SSSx1.p3.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="Sx2.SSx4.SSSx1.p3.1.m1.1a"><mi id="Sx2.SSx4.SSSx1.p3.1.m1.1.1" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.1.m1.1b"><ci id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.1.m1.1c">A</annotation></semantics></math> (Risk source) learns that a particular chemical compound (Asset) is used by another participant <math id="Sx2.SSx4.SSSx1.p3.2.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="Sx2.SSx4.SSSx1.p3.2.m2.1a"><mi id="Sx2.SSx4.SSSx1.p3.2.m2.1.1" xref="Sx2.SSx4.SSSx1.p3.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.2.m2.1b"><ci id="Sx2.SSx4.SSSx1.p3.2.m2.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.2.m2.1c">B</annotation></semantics></math> from the model updates sent by <math id="Sx2.SSx4.SSSx1.p3.3.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="Sx2.SSx4.SSSx1.p3.3.m3.1a"><mi id="Sx2.SSx4.SSSx1.p3.3.m3.1.1" xref="Sx2.SSx4.SSSx1.p3.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.3.m3.1b"><ci id="Sx2.SSx4.SSSx1.p3.3.m3.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.3.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.3.m3.1c">B</annotation></semantics></math> for aggregation. A specific threat realizing this risk is that <math id="Sx2.SSx4.SSSx1.p3.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="Sx2.SSx4.SSSx1.p3.4.m4.1a"><mi id="Sx2.SSx4.SSSx1.p3.4.m4.1.1" xref="Sx2.SSx4.SSSx1.p3.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.4.m4.1b"><ci id="Sx2.SSx4.SSSx1.p3.4.m4.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.4.m4.1c">A</annotation></semantics></math> captures the model update of <math id="Sx2.SSx4.SSSx1.p3.5.m5.1" class="ltx_Math" alttext="B" display="inline"><semantics id="Sx2.SSx4.SSSx1.p3.5.m5.1a"><mi id="Sx2.SSx4.SSSx1.p3.5.m5.1.1" xref="Sx2.SSx4.SSSx1.p3.5.m5.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.5.m5.1b"><ci id="Sx2.SSx4.SSSx1.p3.5.m5.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.5.m5.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.5.m5.1c">B</annotation></semantics></math> and launches inference attack on the captured update. This risk has maximum severity since <math id="Sx2.SSx4.SSSx1.p3.6.m6.1" class="ltx_Math" alttext="B" display="inline"><semantics id="Sx2.SSx4.SSSx1.p3.6.m6.1a"><mi id="Sx2.SSx4.SSSx1.p3.6.m6.1.1" xref="Sx2.SSx4.SSSx1.p3.6.m6.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.6.m6.1b"><ci id="Sx2.SSx4.SSSx1.p3.6.m6.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.6.m6.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.6.m6.1c">B</annotation></semantics></math>’s business strategy may be disclosed as a result of a successful attack. The goal of the analysis is to estimate the success probability and feasibility of such an inference attack.</p>
</div>
</section>
<section id="Sx2.SSx4.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Analysis</h4>

<div id="Sx2.SSx4.SSSx2.p1" class="ltx_para">
<p id="Sx2.SSx4.SSSx2.p1.1" class="ltx_p">The platform architecture implies that the code of the clients and the server is audited and verified. Since malicious manipulation of the training data can result in a larger accuracy drop for a malicious party than for the others <cite class="ltx_cite ltx_citemacro_citep">(Pejó et al. <a href="#bib.bib32" title="" class="ltx_ref">2019</a>)</cite>, there is no real incentive for active attacks (e.g., poisoning, back-doors <cite class="ltx_cite ltx_citemacro_citep">(Goldblum et al. <a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>) as long as the adversary also needs good model quality. Consequently, only honest-but-curious adversaries are considered which legitimately participate in the learning protocol. They follow the learning protocol faithfully but also attempt to infer confidential information about the assets. In this setup, passive attacks are still possible: the trunk is shared among all participants, therefore, it is necessary to understand whether its output (i.e., trunk activation values) or its updates (i.e., gradients) leak any information about the assets.</p>
</div>
</section>
<section id="Sx2.SSx4.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Threats</h4>

<div id="Sx2.SSx4.SSSx3.p1" class="ltx_para">
<p id="Sx2.SSx4.SSSx3.p1.1" class="ltx_p">There are many attacks for federated learning; we give a non-comprehensive list below. For more detailed surveys, we refer the reader to <cite class="ltx_cite ltx_citemacro_citep">(Liu et al. <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="Sx2.SSx4.SSSx3.p2" class="ltx_para">
<ul id="Sx2.I1" class="ltx_itemize">
<li id="Sx2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.p1.1" class="ltx_p">Model inversion attacks aim to reconstruct a representative training sample of a class <cite class="ltx_cite ltx_citemacro_citep">(Fredrikson et al. <a href="#bib.bib9" title="" class="ltx_ref">2015</a>)</cite>, i.e. a record that is similar to all records belonging to a class.</p>
</div>
</li>
<li id="Sx2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.p1.1" class="ltx_p">Membership inference attacks aim at inferring if a certain record was part of the target model’s training dataset <cite class="ltx_cite ltx_citemacro_citep">(Hu et al. <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>. The most common techniques rely on shadow models <cite class="ltx_cite ltx_citemacro_citep">(Shokri et al. <a href="#bib.bib39" title="" class="ltx_ref">2016</a>)</cite> and can exploit overfitting <cite class="ltx_cite ltx_citemacro_citep">(Pyrgelis et al. <a href="#bib.bib35" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
</li>
<li id="Sx2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.p1.1" class="ltx_p">Reconstruction attacks take membership inference attacks another step forward by reconstructing complete training samples <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al. <a href="#bib.bib48" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</li>
<li id="Sx2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.i4.p1.1" class="ltx_p">Property inference attacks aim to infer properties of training data that are independent of the features that characterize the classes of the joint model <cite class="ltx_cite ltx_citemacro_citep">(Ganju et al. <a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</li>
<li id="Sx2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.i5.p1.1" class="ltx_p">Model extraction attacks arise when an adversary obtains black-box access to some target model and attempts to learn a model that closely approximates or even matches the original model <cite class="ltx_cite ltx_citemacro_citep">(Tramèr et al. <a href="#bib.bib44" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="Sx2.SSx4.SSSx3.p3" class="ltx_para">
<p id="Sx2.SSx4.SSSx3.p3.1" class="ltx_p">Despite the wide range of attacks, for our analysis, we focus on membership inference attacks, when the adversary checks if a given compound has been used to train the common model or not.
If this elemental attack succeeds, that flags information leakage, while if it does not, that can be a solid empirical argument that other attacks (that potentially leak more information) would probably fail as well. The accuracy of the membership inference is above 90% when it is launched on the model update of a single participant <cite class="ltx_cite ltx_citemacro_citep">(Pejo et al. <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>, which means that the likelihood of the corresponding risk is very large supposing the adversary (e.g., the server) can access the update sent by this participant.</p>
</div>
</section>
<section id="Sx2.SSx4.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Mitigations</h4>

<div id="Sx2.SSx4.SSSx4.p1" class="ltx_para">
<p id="Sx2.SSx4.SSSx4.p1.1" class="ltx_p">In general, there are legal, organisational, and technical controls.
Here, we focus only on technical measures.
A handful of technical mitigation techniques have been proposed against membership inference attacks such as regularization and hyperparameter tuning <cite class="ltx_cite ltx_citemacro_citep">(Yeom et al. <a href="#bib.bib47" title="" class="ltx_ref">2017</a>)</cite>. Differential Privacy <cite class="ltx_cite ltx_citemacro_citep">(Pejó and Desfontaines <a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> can also be applied to provide provable privacy guarantees but comes with unacceptable accuracy degradation in our case <cite class="ltx_cite ltx_citemacro_citep">(Pejo et al. <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>. Besides these, secure aggregation <cite class="ltx_cite ltx_citemacro_citep">(Ács and Castelluccia <a href="#bib.bib1" title="" class="ltx_ref">2011</a>; Bonawitz et al. <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite> is a widely used technical control to prevent access to the individual model update while preserving the functionality of the aggregation protocol. In other words, only the pharmaceutical companies learn the aggregated model, and the server performs aggregation without learning anything about the assets. Although a malicious participant can still learn that one of the parties used a specific training sample by launching a membership attack on the aggregated model update or the output of the trunk, it cannot attribute this membership information to any specific party as long as all of them participate in every single round.
</p>
</div>
<div id="Sx2.SSx4.SSSx4.p2" class="ltx_para">
<p id="Sx2.SSx4.SSSx4.p2.1" class="ltx_p">Nonetheless, parties may join or leave during training, thus, via a successful membership test on the aggregated model update or the output of the trunk model, the attacker can attribute a training sample to the leaving/joining party. This is a differentiation attack that takes advantage of the change in the coalition. Note that this can be mitigated via legal controls, e.g. by allowing the join of leave of parties only in groups. Altogether, secure aggregation coupled with legal controls mitigate most inference attacks without the degradation of model quality such that the remaining risks become acceptable <cite class="ltx_cite ltx_citemacro_citep">(Pejo et al. <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="Sx2.SSx4.SSSx5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Contribution Scoring</h4>

<div id="Sx2.SSx4.SSSx5.p1" class="ltx_para">
<p id="Sx2.SSx4.SSSx5.p1.1" class="ltx_p">Since secure aggregation prevents the disentaglement of the participants’ contributions, it also makes measuring their usefulness within the collaboration more difficult. This additional requirement is often critical when monetary gain is involved, and determining the reward distribution is necessary in case the collaboratively trained model is sold. The silver bullet for contribution score computation is the Shapley value <cite class="ltx_cite ltx_citemacro_citep">(Shapley <a href="#bib.bib38" title="" class="ltx_ref">1997</a>)</cite>, but unfortunately, it is not feasible to compute in many real-world scenarios. Hence, most prior works only approximate that without privacy in mind: they assume access to individual datasets or the corresponding gradients <cite class="ltx_cite ltx_citemacro_citep">(Wang et al. <a href="#bib.bib45" title="" class="ltx_ref">2020</a>)</cite>. Computing contribution scores privately is a largely unexplored direction, the only works considering this setting are <cite class="ltx_cite ltx_citemacro_citep">(Pejó and Biczók <a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Pejó et al. <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite>. The former does not apply to our use case, as it assumes dynamic changes in the training coalition. However, the latter could be adopted with care: the participants compute their scores, thus, verifiable computation techniques should be applied to prevent dishonest reporting.</p>
</div>
</section>
</section>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Platform Blueprint</h2>

<section id="Sx3.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Infrastructure</h3>

<div id="Sx3.SSx1.p1" class="ltx_para">
<p id="Sx3.SSx1.p1.1" class="ltx_p">A cloud setup was selected as the infrastructure for the privacy preserving federated machine learning. To this end, a multi-account setup at Amazon Web Services (AWS) was developed to address the computational demands of MELLODDY while, at the same time, providing a secure environment for the sensitive information of the pharmaceutical partners of the project. The AWS organisation contained all AWS accounts, including two central accounts and a dedicated AWS for each pharmaceutical partner.</p>
</div>
<div id="Sx3.SSx1.p2" class="ltx_para">
<p id="Sx3.SSx1.p2.1" class="ltx_p">The first central account, the “orchestration account”, hosted a Kubernetes cluster providing a version-control system, a setup for a public key infrastructure (PKI), and services for cost aggregation and cost reporting. This account was managed by Kubermatic.
The second central account, the “central ML account,” was utilised to provide the core components of the federated machine learning framework, namely the model dispatcher. The model dispatcher was deployed on a Kubernetes cluster. This AWS account was managed by Owkin.</p>
</div>
<div id="Sx3.SSx1.p3" class="ltx_para">
<p id="Sx3.SSx1.p3.1" class="ltx_p">Each pharmaceutical partner owned a dedicated AWS account containing multiple services to store the sensitive data, to pre-process the data, manage the compute resources in the account and finally to perform the federated machine learning. The key services in the pharmaceutical partner accounts can be described as follows: The sensitive data was stored in a secured S3 bucket and prior to the upload, internet access is removed from both pharma private VPC and shared VPC. A Kubernetes cluster was deployed using EC2 instances, i.e. the control plane was hosted by three instances managing an adaptively adjustable number of worker node. The worker nodes of the Kubernetes cluster were located in a “shared subnet” within a peered VPC (virtual private cloud) to enable high-bandwidth network connectivity between local resources and the model dispatcher. A “console” server was utilised to deploy and manage the Kubernetes cluster and additionally, to host a CLI (command line interface) which was—in turn—used by the partners to adjust the number of worker nodes, to trigger the pre-processing of data, and to initiate the federated machine learning runs. The AWS services were monitored by CloudWatch not only for health status but also for security issues. The infrastructure was deployed using the tool Terraform <cite class="ltx_cite ltx_citemacro_citep">(HashiCorp <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="Sx3.SSx1.p4" class="ltx_para">
<p id="Sx3.SSx1.p4.1" class="ltx_p">The entire MELLODDY platform, including the infrastructure setup at AWS, underwent a thorough security audit by an external auditor (i.e. Cirosec); findings and code were revised by each pharma company’s security experts and the platform was ultimately signed off by all partners. The successful audit is testament that the setup is capable of handling sensitive classified data in the context of drug discovery. To allow changes of the setup after the audit, a review process had been implemented. That is, every change of the underlying code had to be reviewed by at least three pharmaceutical partners for security issues before being deployed to production.</p>
</div>
</section>
<section id="Sx3.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Application Layer</h3>

<section id="Sx3.SSx2.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Platform</h4>

<div id="Sx3.SSx2.SSSx1.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx1.p1.1" class="ltx_p">The platform consists of a set of interconnected organizations. Figure <a href="#Sx3.F3" title="Figure 3 ‣ Platform ‣ Application Layer ‣ Platform Blueprint ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> represents the main components of a deployed platform in two organisations: a pharma partner and a central aggregation one.</p>
</div>
<figure id="Sx3.F3" class="ltx_figure"><img src="/html/2210.08871/assets/img/architecture_bigfont.png" id="Sx3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="239" height="132" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Overview of the deployed platform</figcaption>
</figure>
<div id="Sx3.SSx2.SSSx1.p2" class="ltx_para">
<p id="Sx3.SSx2.SSSx1.p2.1" class="ltx_p">The application layer of MELLODDY relied heavily on Owkin Connect (based on Substra <cite class="ltx_cite ltx_citemacro_citep">(Substra <a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite>, open-source software mainly developed by Owkin), an application to train and evaluate machine learning models on distributed data sets without centralising the data or compromising the privacy of the data maintaining traceability of training and evaluation operations. It supports simple training and evaluation scheme, such as training a model on data in a center A and evaluating the model on data in a center B, or more complex federated learning (FL) schemes, such as Federated Averaging. It also enables both horizontal FL and vertical FL, as well as multi-partners multi-task learning.</p>
</div>
<div id="Sx3.SSx2.SSSx1.p3" class="ltx_para">
<p id="Sx3.SSx2.SSSx1.p3.1" class="ltx_p">The platform uses the following elementary components:</p>
</div>
<div id="Sx3.SSx2.SSSx1.p4" class="ltx_para">
<dl id="Sx3.I2" class="ltx_description">
<dt id="Sx3.I2.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="Sx3.I2.ix1.1.1.1" class="ltx_text ltx_font_bold">Federated Learning (FL) Orchestrator</span></span></dt>
<dd class="ltx_item">
<div id="Sx3.I2.ix1.p1" class="ltx_para">
<p id="Sx3.I2.ix1.p1.1" class="ltx_p">is responsible for the orchestration of ML tasks on distributed datasets: it distributes the tasks to the workers of the different organizations. It stores non-sensitive metadata of assets of Connect, makes it possible to verify the integrity of assets and ensures that permissions on assets are respected. The orchestrator can be a centralized component or used in a decentralised mode through a Distributed Ledger Technology (DLT) <cite class="ltx_cite ltx_citemacro_citep">(Rauchs et al. <a href="#bib.bib36" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</dd>
<dt id="Sx3.I2.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="Sx3.I2.ix2.1.1.1" class="ltx_text ltx_font_bold">Connect-Backend</span></span></dt>
<dd class="ltx_item">
<div id="Sx3.I2.ix2.p1" class="ltx_para">
<p id="Sx3.I2.ix2.p1.1" class="ltx_p">is a core component in each organisation: its REST API is the main entry point to interact with the platform. It also handles the storage of assets like algorithms, data samples and models. One of its main subsystem is the compute engine, where algorithms and data samples meet to create added value. The compute engine can scale horizontally to leverage multiple compute resources (CPU/GPU/memory).</p>
</div>
</dd>
<dt id="Sx3.I2.ix3" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="Sx3.I2.ix3.1.1.1" class="ltx_text ltx_font_bold">Connect Interfaces and Libraries</span></span></dt>
<dd class="ltx_item">
<div id="Sx3.I2.ix3.p1" class="ltx_para">
<p id="Sx3.I2.ix3.p1.1" class="ltx_p">used to interact with the connect backend either by data scientist or IT operational contacts. The most notable ones are the frontend, allowing to monitor assets and compute plan execution; there are also several Substra libraries (substra-tools, substra SDK &amp; CLI) to simplify algorithm definition and API interaction.</p>
</div>
</dd>
<dt id="Sx3.I2.ix4" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="Sx3.I2.ix4.1.1.1" class="ltx_text ltx_font_bold">Melloflow</span></span></dt>
<dd class="ltx_item">
<div id="Sx3.I2.ix4.p1" class="ltx_para">
<p id="Sx3.I2.ix4.p1.1" class="ltx_p">is a library and CLI providing mini-batch generation and data set, algorithm and hard coded compute plan registration in the context of the MELLODDY project. One of the central library is the secure-aggregation used for federated learning of models.</p>
</div>
</dd>
<dt id="Sx3.I2.ix5" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="Sx3.I2.ix5.1.1.1" class="ltx_text ltx_font_bold">Deployment Artifacts and Tools</span></span></dt>
<dd class="ltx_item">
<div id="Sx3.I2.ix5.p1" class="ltx_para">
<p id="Sx3.I2.ix5.p1.1" class="ltx_p">regrouping both Kubernetes manifests to deploy Owkin Connect, melloddy CLI and its associated server providing on-demand manifest generation for pharma operators.</p>
</div>
</dd>
</dl>
</div>
</section>
<section id="Sx3.SSx2.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Compute Plans</h4>

<div id="Sx3.SSx2.SSSx2.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p1.1" class="ltx_p">The ML experiments executed on the platform were registered and executed as compute plans, a concept specific to Connect. A compute plan is a directed acyclic graph of tasks. A task used for training is defined by an algorithm, the data it is executed on and the inputs from its parent tasks. A task used for evaluation is defined by a set of metrics, the train task it evaluates and the data used for the evaluation. An aggregation task is defined by an algorithm and the inputs from its parent tasks.</p>
</div>
<div id="Sx3.SSx2.SSSx2.p2" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p2.1" class="ltx_p">The algorithm contains the code executed by the task and the description of the environment of the execution, via a Dockerfile. The metrics define how to get a score from predictions and the ground truth.</p>
</div>
<div id="Sx3.SSx2.SSSx2.p3" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p3.1" class="ltx_p">In the context of the MELLODDY project, the data was registered under the format of samples, each sample corresponding to one mini-batch of an epoch. The mini-batches were generated from the output of the MELLODDY Tuner <cite class="ltx_cite ltx_citemacro_citep">(Friedrich <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite> library using the Melloflow library.</p>
</div>
<div id="Sx3.SSx2.SSSx2.p4" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p4.1" class="ltx_p">On the platform, the data does not leave the organisation it was registered on. Each task can only be executed on the data from one organisation and the execution takes place on that organisation. The other assets (algorithm, metric and task inputs) move from one organisation to the other as needed.</p>
</div>
<div id="Sx3.SSx2.SSSx2.p5" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p5.1" class="ltx_p">The algorithms and metrics are shared publicly to all organisations. The task input and outputs may contain sensitive information and as such are kept private. The training tasks have two outputs: (1) the full model which does not leave the organisation and (2) the model metadata (e.g. trunk gradients), that is shared with the central aggregation organisation. This model metadata is encrypted using a secure aggregation scheme.</p>
</div>
<div id="Sx3.SSx2.SSSx2.p6" class="ltx_para">
<p id="Sx3.SSx2.SSSx2.p6.1" class="ltx_p">The aggregation task is executed on the central organisation, taking as input the model metadata from other organizations and returning an aggregation of the metadata, which is sent to each organization. The test task outputs a list of metrics, which are anonymised and showed publicly on the frontend.</p>
</div>
</section>
<section id="Sx3.SSx2.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">(Sparse) Secure Aggregation</h4>

<div id="Sx3.SSx2.SSSx3.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx3.p1.1" class="ltx_p">The Secure Aggregation protocol is utilized to prevent attribution of any inferred information from the shared trunk model. Within Connect it is based on <cite class="ltx_cite ltx_citemacro_citep">(Ács and Castelluccia <a href="#bib.bib1" title="" class="ltx_ref">2011</a>; Bonawitz et al. <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite> with two changes: the secret sharing is disabled, but a common secret mask shared among all participants is utilized. The former is not required, since all partners must stay connected all the time in order to prevent differential attacks. The latter is essential to prevent the aggregator from accessing the result of the aggregation: in addition to the pairwise masks, each participant adds another secret mask to their model update that is unknown to the server and can be removed only by the participants. Hence, the aggregator can perform aggregation without learning anything about the model updates <em id="Sx3.SSx2.SSSx3.p1.1.1" class="ltx_emph ltx_font_italic">and</em> their aggregate.</p>
</div>
<div id="Sx3.SSx2.SSSx3.p2" class="ltx_para">
<p id="Sx3.SSx2.SSSx3.p2.1" class="ltx_p">Although the computationally heavy secret sharing is removed, the new protocol still incurs a significant communication and computational cost, as random keys must be generated and added to each gradient value of all participants in each round. Yet, a considerable portion of the gradient update values is zero because the training data within a batch correspond to a small number of tasks and the input chemical fingerprints are also sparse. Therefore, the gradients are sparse as well, and compressing the model update before encryption can increase efficiency with presumable minor accuracy drop. Moreover, these techniques also mitigate confidentiality risks to some extent <cite class="ltx_cite ltx_citemacro_citep">(Pejo et al. <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="Sx3.SSx2.SSSx3.p3" class="ltx_para">
<p id="Sx3.SSx2.SSSx3.p3.1" class="ltx_p">Unfortunately, secure aggregation hides the location of non-zero coordinates, and hence participants do not know which gradient values are non-zero at the other parties.
In MELLODDY, a simple and cheap approach is followed, that is, every participant sends the gradient values at exactly the same random subset of coordinates for aggregation. In particular,
each participant first selects the same random subset of coordinates uniformly at random using a common secret seed, then it sends the encrypted gradient values only at these coordinates for aggregation. After decrypting the aggregate, only the aggregated coordinates are updated, the rest remains unchanged.</p>
</div>
</section>
<section id="Sx3.SSx2.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Partner Weighting</h4>

<div id="Sx3.SSx2.SSSx4.p1" class="ltx_para">
<p id="Sx3.SSx2.SSSx4.p1.1" class="ltx_p">The platform supports runs with different schemes of relative weighting of partner contributions within each training iteration of the federated run. Partner weighting is enabled by scaling each gradient of each partner before aggregating. For default partner weighting the gradients of all partners are scaled by a constant so that each data point is equally weighted and partners with more data contribute more to the aggregated gradient. Other possible schemes are to scale the gradient depending on the mini-batch size or number of non zeros in the mini-batch per partner. This would allow partners to contribute more equally to the aggregated gradients. In the work of <cite class="ltx_cite ltx_citemacro_citet">Heyndrickx et al. (<a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite> it was however found that default weighting was more beneficial for the federated model.</p>
</div>
</section>
</section>
<section id="Sx3.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Platform Tools</h3>

<section id="Sx3.SSx3.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">MELLODDY Federated Learning (FL) Simulator</h4>

<div id="Sx3.SSx3.SSSx1.p1" class="ltx_para">
<p id="Sx3.SSx3.SSSx1.p1.1" class="ltx_p">During the MELLODDY project, many options were considered to improve the performance of the model <cite class="ltx_cite ltx_citemacro_citep">(Heyndrickx et al. <a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite>. In order to quickly assess each option, the partners conducted single partner studies. In these studies, they used the Melloflow <a href="#Sx3.I2.ix4" title="item Melloflow ‣ Platform ‣ Application Layer ‣ Platform Blueprint ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">Melloflow</span></span></a> library to simulate FL experiments locally on public data and their own data, split into n virtual FL partners. This allowed them to get preliminary results for each option, and decide whether to integrate the option into the final experiment.
Melloflow, used on top of Owkin Connect’ local backend, can simulate the FL experiment by running the tasks locally with Python subprocesses or Docker containers on the same development environment.</p>
</div>
</section>
<section id="Sx3.SSx3.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">MELLODDY Predictor</h4>

<div id="Sx3.SSx3.SSSx2.p1" class="ltx_para">
<p id="Sx3.SSx3.SSSx2.p1.1" class="ltx_p">MELLODDY Predictor <cite class="ltx_cite ltx_citemacro_citep">(Owkin <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite> is an open-source Python package made for external data scientists without high knowledge of the MELLODDY stack to perform predictions on new data easily from the models produced during the yearly runs. It is built on top of MELLODDY-Tuner and SparseChem to manage both data pre-processing and model inference steps. It is flexible enough to handle multiple models and data size, and predict on subset on tasks.</p>
</div>
</section>
<section id="Sx3.SSx3.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Model Fusion</h4>

<div id="Sx3.SSx3.SSSx3.p1" class="ltx_para">
<p id="Sx3.SSx3.SSSx3.p1.1" class="ltx_p">Model fusion is a processing option designed to increase the overall performance. It enables selection of the best model per task instead of a single best average performer. To this end, each partner can select the group of already trained models from the pool of single- and multipartner models. The best model for each task is then selected based on the separate dataset and the performance is measured based on the held-out test set <cite class="ltx_cite ltx_citemacro_citep">(Heyndrickx et al. <a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite>.</p>
</div>
</section>
</section>
<section id="Sx3.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Operational Model</h3>

<div id="Sx3.SSx4.p1" class="ltx_para">
<p id="Sx3.SSx4.p1.1" class="ltx_p">The MELLODDY model required the collaboration of partners with different roles in the consortium. These different roles were reflected in the platform as various tasks to perform and security permissions.</p>
</div>
<section id="Sx3.SSx4.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Decentralised Administration</h4>

<div id="Sx3.SSx4.SSSx1.p1" class="ltx_para">
<p id="Sx3.SSx4.SSSx1.p1.1" class="ltx_p">A decentralised approach had to be implemented to meet with the strong confidentiality requirements of MELLODDY and to allow for the industry partners’ private and sensitive data sets to be kept in their respective private IT environments. This also required specific processes and operation sequences to be developed. In particular: (1) partners set up and maintained their own IT platform component environments, (2) each partner was represented for IT operations by an ”Operational Contact” in the project, and (3) a detailed coordination approach was elaborated.</p>
</div>
<div id="Sx3.SSx4.SSSx1.p2" class="ltx_para">
<p id="Sx3.SSx4.SSSx1.p2.1" class="ltx_p">This decentralized approach raised a number of challenges and difficulties: (1) as only the operational contact of each partner was able to access the IT environment of a given industry partner, remote assistance without access was set up in order to resolve bugs, (2) a fine-grained planning of operations was necessary to take into account working hours and time zones, and (3) an error by one partner can potentially result in numerous operations for all other partners.</p>
</div>
</section>
<section id="Sx3.SSx4.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Different Phases of Operation</h4>

<div id="Sx3.SSx4.SSSx2.p1" class="ltx_para">
<p id="Sx3.SSx4.SSSx2.p1.1" class="ltx_p">Operations were split into 3 phases: (1) Phase 1 was used for hyper-parameter tuning of machine learning models. In this phase only 60% of the data was used to train the machine learning models, while 20% of the data was used to evaluate the models and the other 20% is left out. (2) In phase 2 the best hyper-parameters were selected from phase 1 and the machine learning models were retrained using the 80% of the data and evaluated on the 20% left out data in phase 1. (3) In phase 3 100% of data was used to train machine learning models using best hyper-parameters from phase 1. The performance of the models could not be evaluated in phase 3 (100% of data is used as training data) but we assume they perform better compared to phase 2 models as more data was used to train them.
</p>
</div>
</section>
<section id="Sx3.SSx4.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Application Use</h4>

<div id="Sx3.SSx4.SSSx3.p1" class="ltx_para">
<p id="Sx3.SSx4.SSSx3.p1.1" class="ltx_p">The MELLODDY project spanned 3 years, with a run taking place each year using the most recent version of the platform. The performance increased (number of compute plans) each year and in year 3 the platform supported a run of 219 compute plans on the 4 different data sets (see Data Section <a href="#Sx2.SSx1" title="Data ‣ MELLODDY Use Case ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_title">Data</span></a>) over the 3 different operational phases. More precisely, 34 compute plans ran on CLS data set, 47 on CLSAUX data set, 62 on REG data set and 76 on HYB data set. A total of 1.189M US$ compute budget was spent in year 3 with a maximum of 32 workers in parallel per partner.
These 32 workers were distributed over 2 parallel platforms. A single epoch of a compute plan, depending on model complexity and number of data points, would take 1.7 hours to 8.1 hours using 50 mini batches or 2.8 hours to 12.9 hours using 80 mini batches. A compute plan would typically run around 20 epochs to reach model convergence.
During application use the main bottlenecks encountered were communication overhead and memory usage. The communication overhead is inherent to federated learning and increases with number of mini batches but also number of model weights. The memory usage increases when model size increases (e.g. number of tasks) or mini-batch size (e.g. data-points). With these bottlenecks in mind our choice for AWS instances resulted in <span id="Sx3.SSx4.SSSx3.p1.1.1" class="ltx_text ltx_font_italic">c5n.18xlarge</span> (192GiB Memory, 100Gbps Network bandwidth) for the central aggregating node and <span id="Sx3.SSx4.SSSx3.p1.1.2" class="ltx_text ltx_font_italic">r5n.2xlarge</span> (64GiB Memory, up to 25Gbps Network bandwidth) for the workers of the contributing partners.</p>
</div>
<figure id="Sx3.F4" class="ltx_figure"><img src="/html/2210.08871/assets/img/techpaper.png" id="Sx3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="810" height="810" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The multi-partner models trained on the platform resulted in a relative improvement for all partners compared to single partner model for all metrics: (1) the AUC-PR for classification, (2) the <math id="Sx3.F4.2.m1.1" class="ltx_Math" alttext="R^{2}" display="inline"><semantics id="Sx3.F4.2.m1.1b"><msup id="Sx3.F4.2.m1.1.1" xref="Sx3.F4.2.m1.1.1.cmml"><mi id="Sx3.F4.2.m1.1.1.2" xref="Sx3.F4.2.m1.1.1.2.cmml">R</mi><mn id="Sx3.F4.2.m1.1.1.3" xref="Sx3.F4.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="Sx3.F4.2.m1.1c"><apply id="Sx3.F4.2.m1.1.1.cmml" xref="Sx3.F4.2.m1.1.1"><csymbol cd="ambiguous" id="Sx3.F4.2.m1.1.1.1.cmml" xref="Sx3.F4.2.m1.1.1">superscript</csymbol><ci id="Sx3.F4.2.m1.1.1.2.cmml" xref="Sx3.F4.2.m1.1.1.2">𝑅</ci><cn type="integer" id="Sx3.F4.2.m1.1.1.3.cmml" xref="Sx3.F4.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.F4.2.m1.1d">R^{2}</annotation></semantics></math> for regression, and (3) the extension of the domain of applicability as the delta median conformal efficiency for classification.</figcaption>
</figure>
</section>
</section>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Results</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.3" class="ltx_p">The deployed application at scale resulted in improvements across all pharmaceutical partners in the predictive performance of collaboratively trained models over single partner models as shown in Figure <a href="#Sx3.F4" title="Figure 4 ‣ Application Use ‣ Operational Model ‣ Platform Blueprint ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. For the classification models produced by the platform the primary evaluation metric was AUC-PR on average across 100.000+ ML learning tasks representing 40.000+ concentration-response assays. For the regression models the metric reported was the <math id="Sx4.p1.1.m1.1" class="ltx_Math" alttext="R^{2}" display="inline"><semantics id="Sx4.p1.1.m1.1a"><msup id="Sx4.p1.1.m1.1.1" xref="Sx4.p1.1.m1.1.1.cmml"><mi id="Sx4.p1.1.m1.1.1.2" xref="Sx4.p1.1.m1.1.1.2.cmml">R</mi><mn id="Sx4.p1.1.m1.1.1.3" xref="Sx4.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="Sx4.p1.1.m1.1b"><apply id="Sx4.p1.1.m1.1.1.cmml" xref="Sx4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx4.p1.1.m1.1.1.1.cmml" xref="Sx4.p1.1.m1.1.1">superscript</csymbol><ci id="Sx4.p1.1.m1.1.1.2.cmml" xref="Sx4.p1.1.m1.1.1.2">𝑅</ci><cn type="integer" id="Sx4.p1.1.m1.1.1.3.cmml" xref="Sx4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.1.m1.1c">R^{2}</annotation></semantics></math>. Lastly, the extension domain applicability (AD) measured as the delta median conformal efficiency for classification <cite class="ltx_cite ltx_citemacro_citep">(Heyndrickx et al. <a href="#bib.bib17" title="" class="ltx_ref">2022a</a>)</cite> means that the model can support navigation of a broader chemical space previously unknown to that partner. On Figure <a href="#Sx3.F4" title="Figure 4 ‣ Application Use ‣ Operational Model ‣ Platform Blueprint ‣ Industry-Scale Orchestrated Federated Learning for Drug Discovery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> the relative improvements to perfection (where single partner model performance is 0 and perfect model is 1) for the three metrics (AUC-PR, <math id="Sx4.p1.2.m2.1" class="ltx_Math" alttext="R^{2}" display="inline"><semantics id="Sx4.p1.2.m2.1a"><msup id="Sx4.p1.2.m2.1.1" xref="Sx4.p1.2.m2.1.1.cmml"><mi id="Sx4.p1.2.m2.1.1.2" xref="Sx4.p1.2.m2.1.1.2.cmml">R</mi><mn id="Sx4.p1.2.m2.1.1.3" xref="Sx4.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="Sx4.p1.2.m2.1b"><apply id="Sx4.p1.2.m2.1.1.cmml" xref="Sx4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Sx4.p1.2.m2.1.1.1.cmml" xref="Sx4.p1.2.m2.1.1">superscript</csymbol><ci id="Sx4.p1.2.m2.1.1.2.cmml" xref="Sx4.p1.2.m2.1.1.2">𝑅</ci><cn type="integer" id="Sx4.p1.2.m2.1.1.3.cmml" xref="Sx4.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.2.m2.1c">R^{2}</annotation></semantics></math> , CE) are visualized for the cross-company distribution (<math id="Sx4.p1.3.m3.1" class="ltx_Math" alttext="N=10" display="inline"><semantics id="Sx4.p1.3.m3.1a"><mrow id="Sx4.p1.3.m3.1.1" xref="Sx4.p1.3.m3.1.1.cmml"><mi id="Sx4.p1.3.m3.1.1.2" xref="Sx4.p1.3.m3.1.1.2.cmml">N</mi><mo id="Sx4.p1.3.m3.1.1.1" xref="Sx4.p1.3.m3.1.1.1.cmml">=</mo><mn id="Sx4.p1.3.m3.1.1.3" xref="Sx4.p1.3.m3.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p1.3.m3.1b"><apply id="Sx4.p1.3.m3.1.1.cmml" xref="Sx4.p1.3.m3.1.1"><eq id="Sx4.p1.3.m3.1.1.1.cmml" xref="Sx4.p1.3.m3.1.1.1"></eq><ci id="Sx4.p1.3.m3.1.1.2.cmml" xref="Sx4.p1.3.m3.1.1.2">𝑁</ci><cn type="integer" id="Sx4.p1.3.m3.1.1.3.cmml" xref="Sx4.p1.3.m3.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.3.m3.1c">N=10</annotation></semantics></math>) aggregated over all tasks. Across all pharmaceutical partners, federated models were typically 4% better at categorizing molecules as either pharmacologically or toxicologically active or not active. The typical multi-partner model also showed a 10% increase in its applicability domain, its ability to yield confident predictions when applied to new types of molecules. Finally, the federated models were typically 2% better at estimating values of toxicological and pharmacological activities. Performance improvements were more prominent for the subset of assays relating to pharmacokinetics and toxicology and for assays with ongoing data acquisition. For further details, we refer to the work of <cite class="ltx_cite ltx_citemacro_citet">Heyndrickx et al. (<a href="#bib.bib18" title="" class="ltx_ref">2022b</a>)</cite>.</p>
</div>
<div id="Sx4.p2" class="ltx_para">
<p id="Sx4.p2.1" class="ltx_p">Collectively, these results show improvements to predictive models that support the drug discovery process holding the potential benefits for the discovery of new drugs. Models that more accurately predict molecules’ pharmacological and toxicological activities better support the decision-making process of which candidate drug molecules to make and test. All ten pharma partners attest to observing benefits for living and ADME assays and aim to utilise the models in their internal pipelines.</p>
</div>
</section>
<section id="Sx5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Conclusion and Next Steps</h2>

<div id="Sx5.p1" class="ltx_para">
<p id="Sx5.p1.1" class="ltx_p">The ready to use platform described in this work demonstrates that federated learning for drug discovery is possible on industry scale. It enabled a groundbreaking collaboration without sharing data in a industry where data confidentiality is high priority. The platform is deployed easily on a cloud infrastructure using a AWS multi-account setup and has already run for 3 years in production. We also explained how a decentralised administration works as a organizational model in a real case federated setup. Many options remain to be explored in future work such as sparse secure aggregation or partner weighting as well as post processing tools of the platform like model fusion. There is opportunity for the platform to be further optimised so that current bottlenecks like communication and memory limitations are reduced. There is interest to use the platform beyond MELLODDY scope and formalities and initiatives are ongoing.
Finally, code related to the MELLODDY project is made available on GitHub <cite class="ltx_cite ltx_citemacro_citep">(MELLODDY <a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="Sx6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx6.p1" class="ltx_para">
<p id="Sx6.p1.1" class="ltx_p">This project has received funding from the Innovative Medicines Initiative 2 Joint Undertaking under grant agreement N° 831472. This Joint Undertaking receives support from the European Union’s Horizon 2020 research and innovation program and EFPIA. YM, AA, JS, AF and MO are affiliated to Leuven.AI and received funding from the Flemish Government (AI Research Program).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ács and Castelluccia (2011)</span>
<span class="ltx_bibblock">
Ács, G.; and Castelluccia, C. 2011.

</span>
<span class="ltx_bibblock">I Have a DREAM! (DiffeRentially privatE smArt Metering).

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IWIH</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arany et al. (2022)</span>
<span class="ltx_bibblock">
Arany, A.; et al. 2022.

</span>
<span class="ltx_bibblock">SparseChem: Fast and accurate machine learning model for small
molecules.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.04676</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beck et al. (2004)</span>
<span class="ltx_bibblock">
Beck, B.; et al. 2004.

</span>
<span class="ltx_bibblock">Assay Operations for SAR Support.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Assay Guidance Manual</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. (2017)</span>
<span class="ltx_bibblock">
Bonawitz, K.; et al. 2017.

</span>
<span class="ltx_bibblock">Practical Secure Aggregation for Privacy-Preserving Machine
Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proc. ACM Conf. Comput. Commun. Secur.</em>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowes et al. (2012)</span>
<span class="ltx_bibblock">
Bowes, J.; et al. 2012.

</span>
<span class="ltx_bibblock">Reducing safety-related drug attrition: the use of in vitro
pharmacological profiling.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Nat. Rev. Drug Discov</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caruana (1997)</span>
<span class="ltx_bibblock">
Caruana, R. 1997.

</span>
<span class="ltx_bibblock">Multitask learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Machine learning</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cramer et al. (2015)</span>
<span class="ltx_bibblock">
Cramer, R.; et al. 2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Secure Multiparty Computation</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press.

</span>
<span class="ltx_bibblock">ISBN 9781107043053.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dahl et al. (2014)</span>
<span class="ltx_bibblock">
Dahl, G. E.; et al. 2014.

</span>
<span class="ltx_bibblock">Multi-task neural networks for QSAR predictions.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1406.1231</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fredrikson et al. (2015)</span>
<span class="ltx_bibblock">
Fredrikson, M.; et al. 2015.

</span>
<span class="ltx_bibblock">Model Inversion Attacks That Exploit Confidence
Information and Basic Countermeasures.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proc. ACM Conf. Comput. Commun. Secur.</em>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Friedrich (2021)</span>
<span class="ltx_bibblock">
Friedrich, L. 2021.

</span>
<span class="ltx_bibblock">MELLODDY TUNER release v2 public data (1.0) [Data set].

</span>
<span class="ltx_bibblock">10.5281/zenodo.4835670.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganju et al. (2018)</span>
<span class="ltx_bibblock">
Ganju, K.; et al. 2018.

</span>
<span class="ltx_bibblock">Property Inference Attacks on Fully Connected Neural
Networks using Permutation Invariant Representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. ACM Conf. Comput. Commun. Secur.</em>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gentry (2009)</span>
<span class="ltx_bibblock">
Gentry, C. 2009.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">A fully homomorphic encryption scheme</em>.

</span>
<span class="ltx_bibblock">Stanford university.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghasemi et al. (2018)</span>
<span class="ltx_bibblock">
Ghasemi, F.; et al. 2018.

</span>
<span class="ltx_bibblock">Neural network and deep-learning algorithms used in QSAR studies:
merits and drawbacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Drug Discov.</em>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goldblum et al. (2020)</span>
<span class="ltx_bibblock">
Goldblum, M.; et al. 2020.

</span>
<span class="ltx_bibblock">Data Security for Machine Learning: Data Poisoning, Backdoor Attacks,
and Defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.10544</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gubler et al. (2018)</span>
<span class="ltx_bibblock">
Gubler, H.; et al. 2018.

</span>
<span class="ltx_bibblock">Helios: History and Anatomy of a Successful In-House Enterprise
High-Throughput Screening and Profiling Data Analysis System.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">SLAS Discov.</em>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">HashiCorp (2022)</span>
<span class="ltx_bibblock">
HashiCorp. 2022.

</span>
<span class="ltx_bibblock">Terraform by HashiCorp.

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.terraform.io/</span>.

</span>
<span class="ltx_bibblock">Accessed: 2022-11-29.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heyndrickx et al. (2022a)</span>
<span class="ltx_bibblock">
Heyndrickx, W.; et al. 2022a.

</span>
<span class="ltx_bibblock">Conformal efficiency as a metric for comparative model assessment
befitting federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">ChemRxiv preprint</em>.

</span>
<span class="ltx_bibblock">10.26434/chemrxiv-2022-j3xfk.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heyndrickx et al. (2022b)</span>
<span class="ltx_bibblock">
Heyndrickx, W.; et al. 2022b.

</span>
<span class="ltx_bibblock">MELLODDY: cross pharma federated learning at unprecedented scale
unlocks benefits in QSAR without compromising proprietary information.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ChemRxiv preprint</em>.

</span>
<span class="ltx_bibblock">10.26434/chemrxiv-2022-ntd3r.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Hu, H.; et al. 2021.

</span>
<span class="ltx_bibblock">Membership inference attacks on machine learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hughes et al. (2011)</span>
<span class="ltx_bibblock">
Hughes, J. P.; et al. 2011.

</span>
<span class="ltx_bibblock">Principles of early drug discovery.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Br. J. Pharmacol.</em>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Landrum et al. (2021)</span>
<span class="ltx_bibblock">
Landrum, G.; et al. 2021.

</span>
<span class="ltx_bibblock">RDKit: Open-source cheminformatics. https://www.rdkit.org.

</span>
<span class="ltx_bibblock">Accessed: 2022-11-29.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020a)</span>
<span class="ltx_bibblock">
Li, L.; et al. 2020a.

</span>
<span class="ltx_bibblock">A review of applications in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Comput. Ind. Eng.</em>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020b)</span>
<span class="ltx_bibblock">
Li, T.; et al. 2020b.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Process. Mag.</em>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Liu, B.; et al. 2021.

</span>
<span class="ltx_bibblock">When Machine Learning Meets Privacy: A Survey and Outlook.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macarrón and Hertzberg (2011)</span>
<span class="ltx_bibblock">
Macarrón, R.; and Hertzberg, R. P. 2011.

</span>
<span class="ltx_bibblock">Design and implementation of high throughput screening assays.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Mol. Biotechnol.</em>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mammen (2021)</span>
<span class="ltx_bibblock">
Mammen, P. M. 2021.

</span>
<span class="ltx_bibblock">Federated learning: Opportunities and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.05428</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
McMahan, B.; et al. 2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">PMLR</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MELLODDY (2022)</span>
<span class="ltx_bibblock">
MELLODDY. 2022.

</span>
<span class="ltx_bibblock">MELLODDY GitHub Repositories.

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/melloddy</span>.

</span>
<span class="ltx_bibblock">Accessed: 2022-11-29.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Owkin (2022)</span>
<span class="ltx_bibblock">
Owkin. 2022.

</span>
<span class="ltx_bibblock">Melloddy Predictor.

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/melloddy/MELLODDY-Predictor</span>.

</span>
<span class="ltx_bibblock">Accessed: 2022-11-29.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pejó and Biczók (2022)</span>
<span class="ltx_bibblock">
Pejó, B.; and Biczók, G. 2022.

</span>
<span class="ltx_bibblock">Quality Inference in Federated Learning with Secure Aggregation.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.06236</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pejó and Desfontaines (2022)</span>
<span class="ltx_bibblock">
Pejó, B.; and Desfontaines, D. 2022.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Guide to Differential Privacy Modifications: A Taxonomy of
Variants and Extensions</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pejó et al. (2019)</span>
<span class="ltx_bibblock">
Pejó, B.; et al. 2019.

</span>
<span class="ltx_bibblock">Together or Alone: The Price of Privacy in Collaborative Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proc. Priv. Enh. Technol.</em>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pejó et al. (2021)</span>
<span class="ltx_bibblock">
Pejó, B.; et al. 2021.

</span>
<span class="ltx_bibblock">Measuring Contributions in Privacy-Preserving Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">ERCIM NEWS</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pejo et al. (2022)</span>
<span class="ltx_bibblock">
Pejo, B.; et al. 2022.

</span>
<span class="ltx_bibblock">Collaborative Drug Discovery: Inference-level Data Protection
Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.06506</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pyrgelis et al. (2017)</span>
<span class="ltx_bibblock">
Pyrgelis, A.; et al. 2017.

</span>
<span class="ltx_bibblock">Knock Knock, Who’s There? Membership Inference on
Aggregate Location Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.06145</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rauchs et al. (2018)</span>
<span class="ltx_bibblock">
Rauchs, M.; et al. 2018.

</span>
<span class="ltx_bibblock">Distributed ledger technology systems: A conceptual framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Available at SSRN 3230013</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rogers and Hahn (2010)</span>
<span class="ltx_bibblock">
Rogers, D.; and Hahn, M. 2010.

</span>
<span class="ltx_bibblock">Extended-Connectivity Fingerprints.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">J Chem Inf Model</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shapley (1997)</span>
<span class="ltx_bibblock">
Shapley, L. S. 1997.

</span>
<span class="ltx_bibblock">A value for n-person games.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Classics in game theory</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al. (2016)</span>
<span class="ltx_bibblock">
Shokri, R.; et al. 2016.

</span>
<span class="ltx_bibblock">Membership Inference Attacks against Machine Learning
Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05820</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simm et al. (2021)</span>
<span class="ltx_bibblock">
Simm, J.; et al. 2021.

</span>
<span class="ltx_bibblock">Splitting chemical structure data sets for federated
privacy-preserving machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">J. Cheminformatics</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simões et al. (2018)</span>
<span class="ltx_bibblock">
Simões, R. S.; et al. 2018.

</span>
<span class="ltx_bibblock">Transfer and multi-task learning in QSAR modeling: advances and
challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Front. Pharmacol.</em>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sturm et al. (2020)</span>
<span class="ltx_bibblock">
Sturm, N.; et al. 2020.

</span>
<span class="ltx_bibblock">Industry-scale application and evaluation of deep learning for drug
target prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">J. Cheminformatics</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Substra (2022)</span>
<span class="ltx_bibblock">
Substra. 2022.

</span>
<span class="ltx_bibblock">Substra repo.

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/Substra</span>.

</span>
<span class="ltx_bibblock">Accessed: 2022-11-29.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tramèr et al. (2016)</span>
<span class="ltx_bibblock">
Tramèr, F.; et al. 2016.

</span>
<span class="ltx_bibblock">Stealing Machine Learning Models via Prediction APIs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proc. USENIX conf.</em>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
Wang, T.; et al. 2020.

</span>
<span class="ltx_bibblock">A principled approach to data valuation for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Federated Learning</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2019)</span>
<span class="ltx_bibblock">
Yang, Q.; et al. 2019.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol.</em>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeom et al. (2017)</span>
<span class="ltx_bibblock">
Yeom, S.; et al. 2017.

</span>
<span class="ltx_bibblock">Privacy Risk in Machine Learning: Analyzing the Connection
to Overfitting.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1709.01604</em>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2019)</span>
<span class="ltx_bibblock">
Zhu, L.; et al. 2019.

</span>
<span class="ltx_bibblock">Deep Leakage from Gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.08935</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2210.08870" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2210.08871" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2210.08871">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2210.08871" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2210.08872" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 02:22:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
