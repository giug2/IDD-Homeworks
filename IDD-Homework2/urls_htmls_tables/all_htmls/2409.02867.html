<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition</title>
<!--Generated on Wed Sep  4 16:46:41 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Face Recognition Synthetic Data Fairness Biometrics" lang="en" name="keywords"/>
<base href="/html/2409.02867v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S1" title="In The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S2" title="In The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S2.SS0.SSS1" title="In 2 Related Work ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.1 </span>Fairness in Face Recognition.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S2.SS0.SSS2" title="In 2 Related Work ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.2 </span>Synthetic Face Generation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3" title="In The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS1" title="In 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data Preparation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS1.SSS1" title="In 3.1 Data Preparation ‣ 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Authentic Datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS1.SSS2" title="In 3.1 Data Preparation ‣ 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Synthetic Datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS1.SSS3" title="In 3.1 Data Preparation ‣ 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Data Sampling and Balancing.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS1.SSS4" title="In 3.1 Data Preparation ‣ 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.4 </span>Training Data Combination.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS2" title="In 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Model Creation and Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.SS3" title="In 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Model Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4" title="In The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.SS1" title="In 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>RQ1: Accuracy with Separate Synthetic and Real Data Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.SS2" title="In 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>RQ2: Accuracy with Combined, Balanced Training Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.SS3" title="In 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>RQ3: Fairness with Combined, Balanced Training Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S5" title="In The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion and Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Department of Mathematics and Computer Science, University of Cagliari, Italy
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>andrea.atzori@ieee.org, p.cosseddu4@studenti.unica.it,
<br class="ltx_break"/>fenu@unica.it, mirko.marras@acm.org</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrea Atzori<span class="ltx_ERROR undefined" id="id1.1.id1">\orcidlink</span>0000-0002-6910-206X
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pietro Cosseddu<span class="ltx_ERROR undefined" id="id2.1.id1">\orcidlink</span>0009-0006-4998-5164
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gianni Fenu<span class="ltx_ERROR undefined" id="id3.1.id1">\orcidlink</span>0000-0003-4668-2476
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mirko Marras<span class="ltx_ERROR undefined" id="id4.1.id1">\orcidlink</span>0000-0003-1989-6057
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Over the recent years, the advancements in deep face recognition have fueled an increasing demand for large and diverse datasets. Nevertheless, the authentic data acquired to create those datasets is typically sourced from the web, which, in many cases, can lead to significant privacy issues due to the lack of explicit user consent. Furthermore, obtaining a demographically balanced, large dataset is even more difficult because of the natural imbalance in the distribution of images from different demographic groups. In this paper, we investigate the impact of demographically balanced authentic and synthetic data, both individually and in combination, on the accuracy and fairness of face recognition models. Initially, several generative methods were used to balance the demographic representations of the corresponding synthetic datasets. Then a state-of-the-art face encoder was trained and evaluated using (combinations of) synthetic and authentic images. Our findings emphasized two main points: (i) the increased effectiveness of training data generated by diffusion-based models in enhancing accuracy, whether used alone or combined with subsets of authentic data, and (ii) the minimal impact of incorporating balanced data from pre-trained generative methods on fairness (in nearly all tested scenarios using combined datasets, fairness scores remained either unchanged or worsened, even when compared to unbalanced authentic datasets). Source code and data are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cutt.ly/AeQy1K5G" title="">https://cutt.ly/AeQy1K5G</a> for reproducibility.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Face Recognition Synthetic Data Fairness Biometrics
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Face Recognition (FR) is one of the most popular biometric tasks. Its applications range from access control to portable devices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib18" title="">18</a>]</cite>. Extremely high levels of accuracy have been achieved thanks to new deep learning architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib17" title="">17</a>]</cite>, margin-based losses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib37" title="">37</a>]</cite> and the availability of large-scale, annotated face datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib20" title="">20</a>]</cite> collected from the Internet. The collection of data from such sources, however, implies that the users involved cannot directly express consent for the use of their data, thereby raising severe ethical concerns.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The enactment of the General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib1" title="">1</a>]</cite> by the EU in 2018 heightened criticisms regarding privacy issues in this domain. This enactment led to the removal of several databases commonly used in FR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib27" title="">27</a>]</cite> to avert legal complications and cast uncertainty on the future of FR research. The GDPR specifically provides all individuals with the "right to be forgotten" and enforces more rigorous data collection standards. Consequently, there has been a growing focus on synthetic data, which has emerged as a promising substitute for genuine datasets in FR training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib19" title="">19</a>]</cite>. This shift has been facilitated by progress in Deep Generative Models (DGMs), which can create synthetic samples by learning the probability distribution of the real ones.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The majority of DGMs are based on Generative Adversarial Networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib54" title="">54</a>]</cite>, Diffusion Models (DMs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite>, or, occasionally, hybrid implementations of both <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib42" title="">42</a>]</cite>. Presently, FR models using synthetic data typically show a decline in verification accuracy when compared to those trained with authentic data. This performance gap is primarily due to the limited identity discrimination of the training datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib15" title="">15</a>]</cite> or their low intra-class variance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib48" title="">48</a>]</cite>. DMs have gained attention as a plausible alternative to GANs for image synthesis, albeit at the expense of stability and a significant reduction in training performance. Regrettably, several unresolved questions remain regarding the effective combination of authentic and synthetic data to overcome the limitations of both. In a recent study, various combinations of authentic and synthetic data have been used to train FR models and assess the extent to which the use of authentic data can be minimized by introducing synthetic identities, without encountering the aforementioned performance drawbacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib4" title="">4</a>]</cite>. However, the impact of demographically balancing within and among the two sources of data on verification accuracy and fairness has not been considered while training FR models.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This paper aims to investigate the suitability of using combined authentic and synthetic, demographically balanced, training datasets for developing FR models, focusing on both fairness and accuracy. This exploration seeks to determine whether it is possible to simultaneously address performance and fairness concerns while mitigating the privacy-related issues inherent in authentic datasets. By doing so, it may be possible to create accurate and fair FR models with a reduced reliance on authentic data (assuming that synthetic data can be generated without limitation and that a small number of authentic identities can be collected with appropriate user consent). Thus, our contribution is twofold:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We demographically balanced the employed synthetic datasets with respect to the available demographic groups by generating the missing identities using the same methods originally employed, without additional training. The images generated for this study have been made publicly available.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We investigated whether FR models trained on demographically balanced combinations of authentic and synthetic data could achieve comparable accuracy and fairness to models trained on demographically balanced (and unbalanced) authentic-only data.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The rest of the paper is structured as follows. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S2" title="2 Related Work ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">2</span></a> discusses recent progress in face recognition methods and synthetic face generation. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3" title="3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">3</span></a> then describes the data preparation, model creation and training, and model evaluation adopted in our study. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4" title="4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4</span></a> examines the differences in verification accuracy and fairness between FR models trained on synthetic and/or authentic data. Finally, Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S5" title="5 Conclusion and Future Work ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">5</span></a> summarizes our findings and provides directions for future research. Code and data are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cutt.ly/AeQy1K5G" title="">https://cutt.ly/AeQy1K5G</a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our work bridges recent research on fairness in deep face recognition methods and face generation techniques. In this section, we present an overview of both.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.1 </span>Fairness in Face Recognition.</h4>
<div class="ltx_para" id="S2.SS0.SSS1.p1">
<p class="ltx_p" id="S2.SS0.SSS1.p1.1">Derived from machine learning literature <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib12" title="">12</a>]</cite>, the notions of fairness seek to guarantee fair treatment of individuals across various demographic groups using biometric systems that analyze traits like face, fingerprint, or iris <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib39" title="">39</a>]</cite>. Broadly, demographic fairness is encapsulated by three key concepts: parity, equalized odds, and sufficiency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib41" title="">41</a>]</cite>. Parity denotes the requirement that the outcome of an FR system should remain unaffected by subject’s demographic attributes (such as gender or ethnicity). Equalized odds assert that, regardless of demographic characteristics, the rates of false negatives and false positives should be consistent across demographic groups. Sufficiency implies that the available data must provide sufficient information to ensure accurate and fair results in FR without depending on demographic details.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS1.p2">
<p class="ltx_p" id="S2.SS0.SSS1.p2.1">Prior work analyzing fairness in face recognition has shown that, on average, women experienced worse performance than men <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib2" title="">2</a>]</cite>.
Further analyses generally attributed this disparity to the fact that female faces were more similar to each other than male faces, as shown in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib9" title="">9</a>]</cite>. Notable attention was also paid to factors pertaining to the image (e.g., presence of distortions or noise) or to the face (e.g. presence of make-up or mustache) characteristics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib6" title="">6</a>]</cite>.
For instance, poor performance on dark-skinned or poorly-lit subjects <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib7" title="">7</a>]</cite> was associated with the fact that the network learns skin-tone-related characteristics already in the top layers. Another demographic dimension whose groups have been shown to be systematically discriminated against is age. Indeed, children’s faces were more likely to be badly recognized than those of adults <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib33" title="">33</a>]</cite>.
The imbalanced representation of certain groups was also indicated as a possible reason for unfairness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib30" title="">30</a>]</cite>
To counter this, a range of demographically balanced data sets have been created <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib32" title="">32</a>]</cite>. In this study, we analyze the impact of data balancing through the generation of new synthetic identities. Specifically, we are going to analyze how this balancing methodology impacts models trained only on synthetic data and on combined data (authentic and synthetic).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.2 </span>Synthetic Face Generation.</h4>
<div class="ltx_para" id="S2.SS0.SSS2.p1">
<p class="ltx_p" id="S2.SS0.SSS2.p1.1">Over the last years, several works proposed the use of synthetic data in FR development <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib19" title="">19</a>]</cite> due to the success of deep generative models in generating high-quality and realistic face images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib46" title="">46</a>]</cite>. These methods can be categorized as GAN-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib16" title="">16</a>]</cite>, digital rendering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib10" title="">10</a>]</cite>, or diffusion-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS2.p2">
<p class="ltx_p" id="S2.SS0.SSS2.p2.1">In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib54" title="">54</a>]</cite>, an architecture based on previous StyleGAN methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib35" title="">35</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib34" title="">34</a>]</cite> is presented. Such architecture uses a disentangled latent space to train control encoders that map human-interpretable inputs to suitable latent vectors, thus allowing explicit control of attributes such as pose, age, and expression. By doing so it is then possible to generate new synthetic faces with chosen variations using the controllable attributes. Later, SynFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib48" title="">48</a>]</cite> proposed to generate synthetic data using an attribute-conditional GAN model, i.e., DiscoFaceGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib25" title="">25</a>]</cite>, and perform identity and domain mixup, and SFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib15" title="">15</a>]</cite> analyzed the impact of Style-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib36" title="">36</a>]</cite> training under class conditional settings and the extent to which transferring knowledge from the pretrained model on authentic data improves the performance of synthetic-based FR. In contrast, ExFaceGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib16" title="">16</a>]</cite> introduced a framework to disentangle identity information within the latent spaces of unconditional GANs,to produce multiple images for any given synthetic identity.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS2.p3">
<p class="ltx_p" id="S2.SS0.SSS2.p3.1">Among methods of digital rendering, DigiFace-1M <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib10" title="">10</a>]</cite> leveraged facial geometry models, a diverse array of textures, hairstyles, and 3D accessories, along with robust data augmentation techniques during training. However, it comes at a considerable computational cost during the rendering process. DigiFace-1M also proposed combining synthetic and authentic data during FR training to improve the verification accuracy of synthetic-based FR using a small and fixed number of authentic identities.
Recently, IDiff-Face <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>]</cite> and DCFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite> adopted diffusion models to generate synthetic data for FR training, achieving state-of-the-art verification accuracy for synthetic-based FR. Specifically, the former included fuzziness in the identity condition to induce variations in the generated data. Conversely, the latter proposed a two-stage generative framework in which (i) an image of a novel identity using an unconditional diffusion model is generated and an image style from the style bank is selected in order to (ii) be mixed using a dual conditional diffusion model.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS2.p4">
<p class="ltx_p" id="S2.SS0.SSS2.p4.1">Recently, several challenges and competitions have been organized in conjunction with top venues, aiming at promoting privacy-friendly synthetic-based FR development.
FRCSyn competitions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib23" title="">23</a>]</cite> were organized at WACV and CVPR 2024, aiming to explore the use of synthetic data in FR training and to attract the development of solutions for synthetic-based FR. The challenge considered two main tasks, training FR only with synthetic data and training FR with both synthetic and authentic data. The achieved results of the top-performing solutions from FRCSyn <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib43" title="">43</a>]</cite> competition are further investigated and reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib44" title="">44</a>]</cite>. Also, the SDFR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib53" title="">53</a>]</cite> competition was organized in conjunction with FG 2024, to promote the creation of solutions for synthetic-based FR.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="316" id="S3.F1.g1" src="extracted/5833794/Schema3.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.5.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S3.F1.6.2" style="font-size:90%;">In our methodology, firstly synthetic identities are generated to demographically balance the synthetic datasets (<span class="ltx_text ltx_font_bold" id="S3.F1.6.2.1">A</span>). Subsets of authentic and synthetic data are combined to form the training dataset, with only synthetic data augmented using RandAugment (<span class="ltx_text ltx_font_bold" id="S3.F1.6.2.2">B</span>). We trained a ResNet50 backbone on the balanced combined data using CosFace loss (<span class="ltx_text ltx_font_bold" id="S3.F1.6.2.3">C, D</span>). Ultimately, we used different benchmarks to evaluate the FR models’ accuracy and fairness, as per our objectives.
</span></figcaption>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section is dedicated to describing the experimental protocol we followed (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">1</span></a>), including the datasets involved in the experiments, both authentic and synthetic, the training methodologies adopted to combine both types of face data, and the metrics used for model evaluation.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Preparation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For our experiments, we used five different datasets to train the models: two authentic and three synthetic. The datasets were aligned using MTCNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib65" title="">65</a>]</cite> to extract five facial landmarks, after which all images were resized to 112 <math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mo id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><times id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">×</annotation></semantics></math> 112 pixels. Images were normalized to have pixel values between -1 and 1.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Authentic Datasets.</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">For authentic face data used to train the FR models, we adopted the well-known BUPT-Balancedface <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib60" title="">60</a>]</cite> and CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib63" title="">63</a>]</cite> datasets.
BUPT-Balancedface <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib60" title="">60</a>]</cite> consists of 1.3M images from 28K identities and is annotated with both ethnicity and identity labels. Its ethnicity annotations include four demographic groups: African, Asian, Caucasian, and Indian, with 7K identities and approximately 300K images each.
Conversely, CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib63" title="">63</a>]</cite> consists of 0.5M images of 10K identities. It is worth noting that this dataset was included in the experiments as a reference, despite not being demographically balanced. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite>, it is reported a demographic distribution of 63.4% Caucasian, 14.4% Asian, 7.4% African, 7.2% Indian, and 7.4% Others.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Synthetic Datasets.</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">The synthetic datasets were generated using three methods: one GAN-based and two diffusion-based. These datasets are derived from ExFaceGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib55" title="">55</a>]</cite>, DCFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite>, and IDiff-Face Uniform (25% CPD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>]</cite>. Each dataset contains 0.5M images from 10K identities, with 50 images per identity.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">The first synthetic dataset was generated via the pretrained GAN-Control <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib55" title="">55</a>]</cite> generator, which was trained on the FFHQ dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib35" title="">35</a>]</cite> and improved with an identity disentanglement approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib16" title="">16</a>]</cite>.
The second synthetic dataset was generated via DCFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite>, which is based on a two-stage diffusion model. In the first stage, a high-quality face image of a novel identity is generated using unconditional diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib29" title="">29</a>]</cite> trained on FFHQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib35" title="">35</a>]</cite>, with the image style randomly selected from a style bank. In the second stage, the generated images and styles from the first stage are combined using a dual conditional diffusion model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib29" title="">29</a>]</cite> trained on CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib63" title="">63</a>]</cite> to produce an image with a specific identity and style.
Finally, the third synthetic dataset was generated via IDiff-Face <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>]</cite>, a novel approach based on conditional latent diffusion models for synthetic identity generation with realistic identity variations for FR training. IDiff-Face is trained in the latent space of a pretrained autoencoder <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib50" title="">50</a>]</cite> and conditioned on identity contexts (i.e., feature representations extracted using a pretrained FR model, namely ElasticFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib13" title="">13</a>]</cite>).</p>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.2" style="width:433.6pt;height:69.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.8pt,1.4pt) scale(0.961173101377771,0.961173101377771) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S3.T1.2.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.1.1">Generative Method</span> <span class="ltx_ERROR undefined" id="S3.T1.2.1.1.1.1.2">\tabto</span>1cm</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.2.1"># Caucasian IDs</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.3.1"># Indian IDs</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.4.1"># Asian IDs</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S3.T1.2.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.5.1"># African IDs</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.1.2.1.1">ExFaceGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib16" title="">16</a>]</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.2.1.2.1.2">6,218</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.2.1.2.1.3">1,973</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.2.1.2.1.4">1,668</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.2.1.2.1.5">141</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.1.3.2.1">DCFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib38" title="">38</a>]</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.2.1.3.2.2">8,290</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.2.1.3.2.3">887</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.2.1.3.2.4">571</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.2.1.3.2.5">252</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.1.4.3.1">IDiff-Face <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib14" title="">14</a>]</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.1.4.3.2">7,464</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.1.4.3.3">1,090</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.1.4.3.4">915</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S3.T1.2.1.4.3.5">580</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.4.2" style="font-size:90%;">Demographic representation within the synthetic datasets used in our study.</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Data Sampling and Balancing.</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.4">The authentic dataset employed in the majority of our experiments, BUPT-Balancedface, was already demographically balanced, containing an equal number of identities across the four demographic groups. For our experiments, we required 5K unique, demographically balanced identities, aiming for a total of 1,250 identities per demographic group. To achieve this and reduce the randomness in our experiments, we randomly sampled identities ten times, with each iteration including 5K demographically balanced identities from BUPT-Balancedface. We denote the best-performing iteration as BUPT<sub class="ltx_sub" id="S3.SS1.SSS3.p1.4.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p1.4.1.1">sub</span></sub>, which was used in subsequent experiments. The average results across all iterations are referred to as BUPT<sub class="ltx_sub" id="S3.SS1.SSS3.p1.4.2"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p1.4.2.1">avg</span></sub>. Similarly, the average verification accuracy across the ten iterations from CASIA-WebFace is denoted as WF<sub class="ltx_sub" id="S3.SS1.SSS3.p1.4.3"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p1.4.3.1">avg</span></sub>, while the best-performing iteration is referred to as WF<sub class="ltx_sub" id="S3.SS1.SSS3.p1.4.4"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p1.4.4.1">sub</span></sub>.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<p class="ltx_p" id="S3.SS1.SSS3.p2.9">The synthetic datasets were unbalanced towards the Caucasian group, as determined by labeling all the data using a ResNet18 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib28" title="">28</a>]</cite> backbone trained on BUPT-BalancedFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib60" title="">60</a>]</cite> to predict the ethnicity label of each identity. The inferred ethnicity pseudo-labels are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S3.T1" title="Table 1 ‣ 3.1.2 Synthetic Datasets. ‣ 3.1 Data Preparation ‣ 3 Methodology ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">1</span></a>. For our experiments, we required 5K unique, demographically balanced identities, aiming for a total of 1,250 identities per demographic group in each synthetic dataset.
To achieve this, we (i) randomly sampled 1,250 identities (or the available number, if fewer) from the synthetic datasets and (ii) generated new identities for each demographic group until reaching our targets by guiding the generation process with the above-mentioned ResNet18 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib28" title="">28</a>]</cite> backbone. For each synthetic dataset, the additional identities were generated using the pre-trained models made publicly available by the original authors without further training.
We denote the synthetic subsets sampled in the first step as GC<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.1.1">sub</span></sub>, DC<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.2"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.2.1">sub</span></sub>, and IDF<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.3"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.3.1">sub</span></sub>, and the ones generated in the second step as GC<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.4"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.4.1">gen</span></sub>, DC<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.5"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.5.1">gen</span></sub>, and IDF<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.6"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.6.1">gen</span></sub>, using GANControl, DCFace, and IDiff-Face, respectively. Finally, the synthetic, demographically balanced datasets, each comprising 5K identities and derived from the union of the two respective datasets for each method, are referred to as GC<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.7"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.7.1">bal</span></sub>, DC<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.8"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.8.1">bal</span></sub>, and IDF<sub class="ltx_sub" id="S3.SS1.SSS3.p2.9.9"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.9.9.1">bal</span></sub> for the sake of clarity.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4 </span>Training Data Combination.</h4>
<div class="ltx_para" id="S3.SS1.SSS4.p1">
<p class="ltx_p" id="S3.SS1.SSS4.p1.4">We trained FR models using combinations of authentic and synthetic data. The authentic subset involved in each combination was always BUPT<sub class="ltx_sub" id="S3.SS1.SSS4.p1.4.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS4.p1.4.1.1">sub</span></sub>, which consists of 5K identities and is balanced across demographic groups. This subset was then combined with each of the three synthetic, demographically balanced subsets (GC<sub class="ltx_sub" id="S3.SS1.SSS4.p1.4.2"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS4.p1.4.2.1">bal</span></sub>, DC<sub class="ltx_sub" id="S3.SS1.SSS4.p1.4.3"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS4.p1.4.3.1">bal</span></sub>, IDF<sub class="ltx_sub" id="S3.SS1.SSS4.p1.4.4"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS4.p1.4.4.1">bal</span></sub>), all of which have the same demographic distribution and the same number of identities (5K).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Creation and Training</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.19">To train all the FR models we relied on the widely used ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib28" title="">28</a>]</cite> as the backbone and CosFace <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib59" title="">59</a>]</cite> as the loss function. The latter is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{\text{CosFace}}=\frac{1}{N}\sum_{i\in N}-\log\frac{e^{s(\cos(\theta_{y_{i}}%
)-m)}}{e^{s(\cos(\theta_{y_{i}})-m)}+\sum_{j=1,j\neq y_{i}}^{c}e^{s\cos(\theta%
_{j})}}" class="ltx_Math" display="block" id="S3.E1.m1.8"><semantics id="S3.E1.m1.8a"><mrow id="S3.E1.m1.8.9" xref="S3.E1.m1.8.9.cmml"><msub id="S3.E1.m1.8.9.2" xref="S3.E1.m1.8.9.2.cmml"><mi id="S3.E1.m1.8.9.2.2" xref="S3.E1.m1.8.9.2.2.cmml">L</mi><mtext id="S3.E1.m1.8.9.2.3" xref="S3.E1.m1.8.9.2.3a.cmml">CosFace</mtext></msub><mo id="S3.E1.m1.8.9.1" xref="S3.E1.m1.8.9.1.cmml">=</mo><mrow id="S3.E1.m1.8.9.3" xref="S3.E1.m1.8.9.3.cmml"><mrow id="S3.E1.m1.8.9.3.2" xref="S3.E1.m1.8.9.3.2.cmml"><mfrac id="S3.E1.m1.8.9.3.2.2" xref="S3.E1.m1.8.9.3.2.2.cmml"><mn id="S3.E1.m1.8.9.3.2.2.2" xref="S3.E1.m1.8.9.3.2.2.2.cmml">1</mn><mi id="S3.E1.m1.8.9.3.2.2.3" xref="S3.E1.m1.8.9.3.2.2.3.cmml">N</mi></mfrac><mo id="S3.E1.m1.8.9.3.2.1" xref="S3.E1.m1.8.9.3.2.1.cmml">⁢</mo><munder id="S3.E1.m1.8.9.3.2.3" xref="S3.E1.m1.8.9.3.2.3.cmml"><mo id="S3.E1.m1.8.9.3.2.3.2" movablelimits="false" rspace="0em" xref="S3.E1.m1.8.9.3.2.3.2.cmml">∑</mo><mrow id="S3.E1.m1.8.9.3.2.3.3" xref="S3.E1.m1.8.9.3.2.3.3.cmml"><mi id="S3.E1.m1.8.9.3.2.3.3.2" xref="S3.E1.m1.8.9.3.2.3.3.2.cmml">i</mi><mo id="S3.E1.m1.8.9.3.2.3.3.1" xref="S3.E1.m1.8.9.3.2.3.3.1.cmml">∈</mo><mi id="S3.E1.m1.8.9.3.2.3.3.3" xref="S3.E1.m1.8.9.3.2.3.3.3.cmml">N</mi></mrow></munder></mrow><mo id="S3.E1.m1.8.9.3.1" lspace="0em" xref="S3.E1.m1.8.9.3.1.cmml">−</mo><mrow id="S3.E1.m1.8.9.3.3" xref="S3.E1.m1.8.9.3.3.cmml"><mi id="S3.E1.m1.8.9.3.3.1" xref="S3.E1.m1.8.9.3.3.1.cmml">log</mi><mo id="S3.E1.m1.8.9.3.3a" lspace="0.167em" xref="S3.E1.m1.8.9.3.3.cmml">⁡</mo><mfrac id="S3.E1.m1.8.8" xref="S3.E1.m1.8.8.cmml"><msup id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.4.cmml">e</mi><mrow id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.4.cmml">s</mi><mo id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml"><mo id="S3.E1.m1.2.2.2.2.2.2.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">cos</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1a" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml"><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml">(</mo><msub id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.cmml">θ</mi><msub id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml">−</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.1.3.cmml">m</mi></mrow><mo id="S3.E1.m1.2.2.2.2.2.2.1.3" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></msup><mrow id="S3.E1.m1.8.8.8" xref="S3.E1.m1.8.8.8.cmml"><msup id="S3.E1.m1.8.8.8.8" xref="S3.E1.m1.8.8.8.8.cmml"><mi id="S3.E1.m1.8.8.8.8.2" xref="S3.E1.m1.8.8.8.8.2.cmml">e</mi><mrow id="S3.E1.m1.4.4.4.2.2" xref="S3.E1.m1.4.4.4.2.2.cmml"><mi id="S3.E1.m1.4.4.4.2.2.4" xref="S3.E1.m1.4.4.4.2.2.4.cmml">s</mi><mo id="S3.E1.m1.4.4.4.2.2.3" xref="S3.E1.m1.4.4.4.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.4.2.2.2.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.cmml"><mo id="S3.E1.m1.4.4.4.2.2.2.1.2" stretchy="false" xref="S3.E1.m1.4.4.4.2.2.2.1.1.cmml">(</mo><mrow id="S3.E1.m1.4.4.4.2.2.2.1.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.cmml"><mrow id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.2.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.cmml">cos</mi><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1a" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.2.cmml"><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.2.cmml">(</mo><msub id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.2.cmml">θ</mi><msub id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.2" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.3" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.2" xref="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml">−</mo><mi id="S3.E1.m1.4.4.4.2.2.2.1.1.3" xref="S3.E1.m1.4.4.4.2.2.2.1.1.3.cmml">m</mi></mrow><mo id="S3.E1.m1.4.4.4.2.2.2.1.3" stretchy="false" xref="S3.E1.m1.4.4.4.2.2.2.1.1.cmml">)</mo></mrow></mrow></msup><mo id="S3.E1.m1.8.8.8.7" rspace="0.055em" xref="S3.E1.m1.8.8.8.7.cmml">+</mo><mrow id="S3.E1.m1.8.8.8.9" xref="S3.E1.m1.8.8.8.9.cmml"><msubsup id="S3.E1.m1.8.8.8.9.1" xref="S3.E1.m1.8.8.8.9.1.cmml"><mo id="S3.E1.m1.8.8.8.9.1.2.2" xref="S3.E1.m1.8.8.8.9.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.6.6.6.4.2.2" xref="S3.E1.m1.6.6.6.4.2.3.cmml"><mrow id="S3.E1.m1.5.5.5.3.1.1.1" xref="S3.E1.m1.5.5.5.3.1.1.1.cmml"><mi id="S3.E1.m1.5.5.5.3.1.1.1.2" xref="S3.E1.m1.5.5.5.3.1.1.1.2.cmml">j</mi><mo id="S3.E1.m1.5.5.5.3.1.1.1.1" xref="S3.E1.m1.5.5.5.3.1.1.1.1.cmml">=</mo><mn id="S3.E1.m1.5.5.5.3.1.1.1.3" xref="S3.E1.m1.5.5.5.3.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E1.m1.6.6.6.4.2.2.3" xref="S3.E1.m1.6.6.6.4.2.3a.cmml">,</mo><mrow id="S3.E1.m1.6.6.6.4.2.2.2" xref="S3.E1.m1.6.6.6.4.2.2.2.cmml"><mi id="S3.E1.m1.6.6.6.4.2.2.2.2" xref="S3.E1.m1.6.6.6.4.2.2.2.2.cmml">j</mi><mo id="S3.E1.m1.6.6.6.4.2.2.2.1" xref="S3.E1.m1.6.6.6.4.2.2.2.1.cmml">≠</mo><msub id="S3.E1.m1.6.6.6.4.2.2.2.3" xref="S3.E1.m1.6.6.6.4.2.2.2.3.cmml"><mi id="S3.E1.m1.6.6.6.4.2.2.2.3.2" xref="S3.E1.m1.6.6.6.4.2.2.2.3.2.cmml">y</mi><mi id="S3.E1.m1.6.6.6.4.2.2.2.3.3" xref="S3.E1.m1.6.6.6.4.2.2.2.3.3.cmml">i</mi></msub></mrow></mrow><mi id="S3.E1.m1.8.8.8.9.1.3" xref="S3.E1.m1.8.8.8.9.1.3.cmml">c</mi></msubsup><msup id="S3.E1.m1.8.8.8.9.2" xref="S3.E1.m1.8.8.8.9.2.cmml"><mi id="S3.E1.m1.8.8.8.9.2.2" xref="S3.E1.m1.8.8.8.9.2.2.cmml">e</mi><mrow id="S3.E1.m1.8.8.8.6.2" xref="S3.E1.m1.8.8.8.6.2.cmml"><mi id="S3.E1.m1.8.8.8.6.2.4" xref="S3.E1.m1.8.8.8.6.2.4.cmml">s</mi><mo id="S3.E1.m1.8.8.8.6.2.3" lspace="0.167em" xref="S3.E1.m1.8.8.8.6.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.8.6.2.2.1" xref="S3.E1.m1.8.8.8.6.2.2.2.cmml"><mi id="S3.E1.m1.7.7.7.5.1.1" xref="S3.E1.m1.7.7.7.5.1.1.cmml">cos</mi><mo id="S3.E1.m1.8.8.8.6.2.2.1a" xref="S3.E1.m1.8.8.8.6.2.2.2.cmml">⁡</mo><mrow id="S3.E1.m1.8.8.8.6.2.2.1.1" xref="S3.E1.m1.8.8.8.6.2.2.2.cmml"><mo id="S3.E1.m1.8.8.8.6.2.2.1.1.2" stretchy="false" xref="S3.E1.m1.8.8.8.6.2.2.2.cmml">(</mo><msub id="S3.E1.m1.8.8.8.6.2.2.1.1.1" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1.cmml"><mi id="S3.E1.m1.8.8.8.6.2.2.1.1.1.2" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1.2.cmml">θ</mi><mi id="S3.E1.m1.8.8.8.6.2.2.1.1.1.3" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1.3.cmml">j</mi></msub><mo id="S3.E1.m1.8.8.8.6.2.2.1.1.3" stretchy="false" xref="S3.E1.m1.8.8.8.6.2.2.2.cmml">)</mo></mrow></mrow></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.8b"><apply id="S3.E1.m1.8.9.cmml" xref="S3.E1.m1.8.9"><eq id="S3.E1.m1.8.9.1.cmml" xref="S3.E1.m1.8.9.1"></eq><apply id="S3.E1.m1.8.9.2.cmml" xref="S3.E1.m1.8.9.2"><csymbol cd="ambiguous" id="S3.E1.m1.8.9.2.1.cmml" xref="S3.E1.m1.8.9.2">subscript</csymbol><ci id="S3.E1.m1.8.9.2.2.cmml" xref="S3.E1.m1.8.9.2.2">𝐿</ci><ci id="S3.E1.m1.8.9.2.3a.cmml" xref="S3.E1.m1.8.9.2.3"><mtext id="S3.E1.m1.8.9.2.3.cmml" mathsize="70%" xref="S3.E1.m1.8.9.2.3">CosFace</mtext></ci></apply><apply id="S3.E1.m1.8.9.3.cmml" xref="S3.E1.m1.8.9.3"><minus id="S3.E1.m1.8.9.3.1.cmml" xref="S3.E1.m1.8.9.3.1"></minus><apply id="S3.E1.m1.8.9.3.2.cmml" xref="S3.E1.m1.8.9.3.2"><times id="S3.E1.m1.8.9.3.2.1.cmml" xref="S3.E1.m1.8.9.3.2.1"></times><apply id="S3.E1.m1.8.9.3.2.2.cmml" xref="S3.E1.m1.8.9.3.2.2"><divide id="S3.E1.m1.8.9.3.2.2.1.cmml" xref="S3.E1.m1.8.9.3.2.2"></divide><cn id="S3.E1.m1.8.9.3.2.2.2.cmml" type="integer" xref="S3.E1.m1.8.9.3.2.2.2">1</cn><ci id="S3.E1.m1.8.9.3.2.2.3.cmml" xref="S3.E1.m1.8.9.3.2.2.3">𝑁</ci></apply><apply id="S3.E1.m1.8.9.3.2.3.cmml" xref="S3.E1.m1.8.9.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.9.3.2.3.1.cmml" xref="S3.E1.m1.8.9.3.2.3">subscript</csymbol><sum id="S3.E1.m1.8.9.3.2.3.2.cmml" xref="S3.E1.m1.8.9.3.2.3.2"></sum><apply id="S3.E1.m1.8.9.3.2.3.3.cmml" xref="S3.E1.m1.8.9.3.2.3.3"><in id="S3.E1.m1.8.9.3.2.3.3.1.cmml" xref="S3.E1.m1.8.9.3.2.3.3.1"></in><ci id="S3.E1.m1.8.9.3.2.3.3.2.cmml" xref="S3.E1.m1.8.9.3.2.3.3.2">𝑖</ci><ci id="S3.E1.m1.8.9.3.2.3.3.3.cmml" xref="S3.E1.m1.8.9.3.2.3.3.3">𝑁</ci></apply></apply></apply><apply id="S3.E1.m1.8.9.3.3.cmml" xref="S3.E1.m1.8.9.3.3"><log id="S3.E1.m1.8.9.3.3.1.cmml" xref="S3.E1.m1.8.9.3.3.1"></log><apply id="S3.E1.m1.8.8.cmml" xref="S3.E1.m1.8.8"><divide id="S3.E1.m1.8.8.9.cmml" xref="S3.E1.m1.8.8"></divide><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2">superscript</csymbol><ci id="S3.E1.m1.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.4">𝑒</ci><apply id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2"><times id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.3"></times><ci id="S3.E1.m1.2.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.2.4">𝑠</ci><apply id="S3.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"><minus id="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.2"></minus><apply id="S3.E1.m1.2.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1"><cos id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"></cos><apply id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.2">𝜃</ci><apply id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.2">𝑦</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><ci id="S3.E1.m1.2.2.2.2.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.3">𝑚</ci></apply></apply></apply><apply id="S3.E1.m1.8.8.8.cmml" xref="S3.E1.m1.8.8.8"><plus id="S3.E1.m1.8.8.8.7.cmml" xref="S3.E1.m1.8.8.8.7"></plus><apply id="S3.E1.m1.8.8.8.8.cmml" xref="S3.E1.m1.8.8.8.8"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.8.8.1.cmml" xref="S3.E1.m1.8.8.8.8">superscript</csymbol><ci id="S3.E1.m1.8.8.8.8.2.cmml" xref="S3.E1.m1.8.8.8.8.2">𝑒</ci><apply id="S3.E1.m1.4.4.4.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2"><times id="S3.E1.m1.4.4.4.2.2.3.cmml" xref="S3.E1.m1.4.4.4.2.2.3"></times><ci id="S3.E1.m1.4.4.4.2.2.4.cmml" xref="S3.E1.m1.4.4.4.2.2.4">𝑠</ci><apply id="S3.E1.m1.4.4.4.2.2.2.1.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1"><minus id="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.2"></minus><apply id="S3.E1.m1.4.4.4.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1"><cos id="S3.E1.m1.3.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1"></cos><apply id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.2">𝜃</ci><apply id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.2">𝑦</ci><ci id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><ci id="S3.E1.m1.4.4.4.2.2.2.1.1.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.3">𝑚</ci></apply></apply></apply><apply id="S3.E1.m1.8.8.8.9.cmml" xref="S3.E1.m1.8.8.8.9"><apply id="S3.E1.m1.8.8.8.9.1.cmml" xref="S3.E1.m1.8.8.8.9.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.8.9.1.1.cmml" xref="S3.E1.m1.8.8.8.9.1">superscript</csymbol><apply id="S3.E1.m1.8.8.8.9.1.2.cmml" xref="S3.E1.m1.8.8.8.9.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.8.9.1.2.1.cmml" xref="S3.E1.m1.8.8.8.9.1">subscript</csymbol><sum id="S3.E1.m1.8.8.8.9.1.2.2.cmml" xref="S3.E1.m1.8.8.8.9.1.2.2"></sum><apply id="S3.E1.m1.6.6.6.4.2.3.cmml" xref="S3.E1.m1.6.6.6.4.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.6.4.2.3a.cmml" xref="S3.E1.m1.6.6.6.4.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.5.5.5.3.1.1.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1"><eq id="S3.E1.m1.5.5.5.3.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1"></eq><ci id="S3.E1.m1.5.5.5.3.1.1.1.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.2">𝑗</ci><cn id="S3.E1.m1.5.5.5.3.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.5.5.5.3.1.1.1.3">1</cn></apply><apply id="S3.E1.m1.6.6.6.4.2.2.2.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2"><neq id="S3.E1.m1.6.6.6.4.2.2.2.1.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2.1"></neq><ci id="S3.E1.m1.6.6.6.4.2.2.2.2.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2.2">𝑗</ci><apply id="S3.E1.m1.6.6.6.4.2.2.2.3.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.6.4.2.2.2.3.1.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.6.6.6.4.2.2.2.3.2.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2.3.2">𝑦</ci><ci id="S3.E1.m1.6.6.6.4.2.2.2.3.3.cmml" xref="S3.E1.m1.6.6.6.4.2.2.2.3.3">𝑖</ci></apply></apply></apply></apply><ci id="S3.E1.m1.8.8.8.9.1.3.cmml" xref="S3.E1.m1.8.8.8.9.1.3">𝑐</ci></apply><apply id="S3.E1.m1.8.8.8.9.2.cmml" xref="S3.E1.m1.8.8.8.9.2"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.8.9.2.1.cmml" xref="S3.E1.m1.8.8.8.9.2">superscript</csymbol><ci id="S3.E1.m1.8.8.8.9.2.2.cmml" xref="S3.E1.m1.8.8.8.9.2.2">𝑒</ci><apply id="S3.E1.m1.8.8.8.6.2.cmml" xref="S3.E1.m1.8.8.8.6.2"><times id="S3.E1.m1.8.8.8.6.2.3.cmml" xref="S3.E1.m1.8.8.8.6.2.3"></times><ci id="S3.E1.m1.8.8.8.6.2.4.cmml" xref="S3.E1.m1.8.8.8.6.2.4">𝑠</ci><apply id="S3.E1.m1.8.8.8.6.2.2.2.cmml" xref="S3.E1.m1.8.8.8.6.2.2.1"><cos id="S3.E1.m1.7.7.7.5.1.1.cmml" xref="S3.E1.m1.7.7.7.5.1.1"></cos><apply id="S3.E1.m1.8.8.8.6.2.2.1.1.1.cmml" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.8.6.2.2.1.1.1.1.cmml" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.8.8.8.6.2.2.1.1.1.2.cmml" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1.2">𝜃</ci><ci id="S3.E1.m1.8.8.8.6.2.2.1.1.1.3.cmml" xref="S3.E1.m1.8.8.8.6.2.2.1.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.8c">L_{\text{CosFace}}=\frac{1}{N}\sum_{i\in N}-\log\frac{e^{s(\cos(\theta_{y_{i}}%
)-m)}}{e^{s(\cos(\theta_{y_{i}})-m)}+\sum_{j=1,j\neq y_{i}}^{c}e^{s\cos(\theta%
_{j})}}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.8d">italic_L start_POSTSUBSCRIPT CosFace end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i ∈ italic_N end_POSTSUBSCRIPT - roman_log divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( roman_cos ( italic_θ start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) - italic_m ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( roman_cos ( italic_θ start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) - italic_m ) end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT italic_j = 1 , italic_j ≠ italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_s roman_cos ( italic_θ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.18">where <math alttext="c" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_c</annotation></semantics></math> is the number of classes (identities), <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_N</annotation></semantics></math> is the batch size, <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_m</annotation></semantics></math> is the margin penalty applied on the cosine angle <math alttext="cos(\theta_{y_{i}})" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mrow id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">c</mi><mo id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">⁢</mo><mi id="S3.SS2.p1.4.m4.1.1.4" xref="S3.SS2.p1.4.m4.1.1.4.cmml">o</mi><mo id="S3.SS2.p1.4.m4.1.1.2a" xref="S3.SS2.p1.4.m4.1.1.2.cmml">⁢</mo><mi id="S3.SS2.p1.4.m4.1.1.5" xref="S3.SS2.p1.4.m4.1.1.5.cmml">s</mi><mo id="S3.SS2.p1.4.m4.1.1.2b" xref="S3.SS2.p1.4.m4.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p1.4.m4.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.1.cmml"><mo id="S3.SS2.p1.4.m4.1.1.1.1.2" stretchy="false" xref="S3.SS2.p1.4.m4.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p1.4.m4.1.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.1.1.1.2" xref="S3.SS2.p1.4.m4.1.1.1.1.1.2.cmml">θ</mi><msub id="S3.SS2.p1.4.m4.1.1.1.1.1.3" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.4.m4.1.1.1.1.1.3.2" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.SS2.p1.4.m4.1.1.1.1.1.3.3" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.SS2.p1.4.m4.1.1.1.1.3" stretchy="false" xref="S3.SS2.p1.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><times id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2"></times><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">𝑐</ci><ci id="S3.SS2.p1.4.m4.1.1.4.cmml" xref="S3.SS2.p1.4.m4.1.1.4">𝑜</ci><ci id="S3.SS2.p1.4.m4.1.1.5.cmml" xref="S3.SS2.p1.4.m4.1.1.5">𝑠</ci><apply id="S3.SS2.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1.2">𝜃</ci><apply id="S3.SS2.p1.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3.2">𝑦</ci><ci id="S3.SS2.p1.4.m4.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">cos(\theta_{y_{i}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_c italic_o italic_s ( italic_θ start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math> between the feature representation <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">x</mi><mi id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">𝑥</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> of the sample <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m6.1"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m6.1d">italic_i</annotation></semantics></math> and its class center <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m7.1"><semantics id="S3.SS2.p1.7.m7.1a"><msub id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">y</mi><mi id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">𝑦</ci><ci id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m7.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="s" class="ltx_Math" display="inline" id="S3.SS2.p1.8.m8.1"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.8.m8.1d">italic_s</annotation></semantics></math> is the scale parameter. In all the conducted experiments, the margin <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.p1.9.m9.1"><semantics id="S3.SS2.p1.9.m9.1a"><mi id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.9.m9.1d">italic_m</annotation></semantics></math> is set to 0.35 and the scale parameter <math alttext="s" class="ltx_Math" display="inline" id="S3.SS2.p1.10.m10.1"><semantics id="S3.SS2.p1.10.m10.1a"><mi id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><ci id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.10.m10.1d">italic_s</annotation></semantics></math> to 64, following <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib59" title="">59</a>]</cite>. During the training, we employed Stochastic Gradient Descend (SGD) as an optimizer with an initial learning rate of 0.1. The learning rate is divided by 10 at epochs 22, 30 and 40. In total, the models are trained for 40 epochs using 256 as batch size.
During the training, we also employed data augmentation techniques, following RandAugment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib22" title="">22</a>]</cite>. Its augmentation space includes color and geometric transformations such as horizontal flipping, sharpness adjusting, and translation of the <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.p1.11.m11.1"><semantics id="S3.SS2.p1.11.m11.1a"><mi id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><ci id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.11.m11.1d">italic_x</annotation></semantics></math> and <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p1.12.m12.1"><semantics id="S3.SS2.p1.12.m12.1a"><mi id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><ci id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.12.m12.1d">italic_y</annotation></semantics></math> axes. RandAugment includes two hyper-parameters, <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS2.p1.13.m13.1"><semantics id="S3.SS2.p1.13.m13.1a"><mi id="S3.SS2.p1.13.m13.1.1" xref="S3.SS2.p1.13.m13.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m13.1b"><ci id="S3.SS2.p1.13.m13.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m13.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.13.m13.1d">italic_Q</annotation></semantics></math> and <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p1.14.m14.1"><semantics id="S3.SS2.p1.14.m14.1a"><mi id="S3.SS2.p1.14.m14.1.1" xref="S3.SS2.p1.14.m14.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m14.1b"><ci id="S3.SS2.p1.14.m14.1.1.cmml" xref="S3.SS2.p1.14.m14.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m14.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.14.m14.1d">italic_M</annotation></semantics></math>, to select the number of operations <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS2.p1.15.m15.1"><semantics id="S3.SS2.p1.15.m15.1a"><mi id="S3.SS2.p1.15.m15.1.1" xref="S3.SS2.p1.15.m15.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.15.m15.1b"><ci id="S3.SS2.p1.15.m15.1.1.cmml" xref="S3.SS2.p1.15.m15.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.15.m15.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.15.m15.1d">italic_Q</annotation></semantics></math> and the magnitude <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p1.16.m16.1"><semantics id="S3.SS2.p1.16.m16.1a"><mi id="S3.SS2.p1.16.m16.1.1" xref="S3.SS2.p1.16.m16.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.16.m16.1b"><ci id="S3.SS2.p1.16.m16.1.1.cmml" xref="S3.SS2.p1.16.m16.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.16.m16.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.16.m16.1d">italic_M</annotation></semantics></math> of each transformation. In our experiments, <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p1.17.m17.1"><semantics id="S3.SS2.p1.17.m17.1a"><mi id="S3.SS2.p1.17.m17.1.1" xref="S3.SS2.p1.17.m17.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.17.m17.1b"><ci id="S3.SS2.p1.17.m17.1.1.cmml" xref="S3.SS2.p1.17.m17.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.17.m17.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.17.m17.1d">italic_M</annotation></semantics></math> and <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS2.p1.18.m18.1"><semantics id="S3.SS2.p1.18.m18.1a"><mi id="S3.SS2.p1.18.m18.1.1" xref="S3.SS2.p1.18.m18.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.18.m18.1b"><ci id="S3.SS2.p1.18.m18.1.1.cmml" xref="S3.SS2.p1.18.m18.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.18.m18.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.18.m18.1d">italic_Q</annotation></semantics></math> were set to 16 and 4, as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib4" title="">4</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib17" title="">17</a>]</cite>. Further details are provided in the code repository.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Model Evaluation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We evaluated the trained FR models in terms of verification accuracy on several well-known benchmarks, accompanying the following datasets: LFW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib31" title="">31</a>]</cite>, CFP-FP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib51" title="">51</a>]</cite>, CFP-FF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib51" title="">51</a>]</cite>, AgeDB-30 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib45" title="">45</a>]</cite>, CA-LFW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib66" title="">66</a>]</cite>, CP-LFW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib51" title="">51</a>]</cite> and RFW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#bib.bib61" title="">61</a>]</cite>. The latter has also been used to assess the fairness of the trained FR models. Results for all benchmarks are reported as verification accuracy in percentage, thus adhering to their official, original evaluation protocol.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">In order to assess the fairness of the models, we computed the standard deviation (STD) and the Skewed Error Ratio (SER) on the verification accuracy of the four sub-groups composing the RFW benchmark, with each sub-group composed of 6K mated and 6K non-mated verification pairs. Specifically, error skewness is computed as the ratio of the highest error rate to the lowest error rate among different demographic groups. Formally:</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="SER=\frac{\max_{a}\text{Err}(a)}{\min_{b}\text{Err}(b)}" class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.3" xref="S3.E2.m1.2.3.cmml"><mrow id="S3.E2.m1.2.3.2" xref="S3.E2.m1.2.3.2.cmml"><mi id="S3.E2.m1.2.3.2.2" xref="S3.E2.m1.2.3.2.2.cmml">S</mi><mo id="S3.E2.m1.2.3.2.1" xref="S3.E2.m1.2.3.2.1.cmml">⁢</mo><mi id="S3.E2.m1.2.3.2.3" xref="S3.E2.m1.2.3.2.3.cmml">E</mi><mo id="S3.E2.m1.2.3.2.1a" xref="S3.E2.m1.2.3.2.1.cmml">⁢</mo><mi id="S3.E2.m1.2.3.2.4" xref="S3.E2.m1.2.3.2.4.cmml">R</mi></mrow><mo id="S3.E2.m1.2.3.1" xref="S3.E2.m1.2.3.1.cmml">=</mo><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml"><msub id="S3.E2.m1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.3.1.cmml"><mi id="S3.E2.m1.1.1.1.3.1.2" xref="S3.E2.m1.1.1.1.3.1.2.cmml">max</mi><mi id="S3.E2.m1.1.1.1.3.1.3" xref="S3.E2.m1.1.1.1.3.1.3.cmml">a</mi></msub><mo id="S3.E2.m1.1.1.1.3a" lspace="0.167em" xref="S3.E2.m1.1.1.1.3.cmml">⁡</mo><mtext id="S3.E2.m1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.3.2a.cmml">Err</mtext></mrow><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.4.2" xref="S3.E2.m1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.4.2.1" stretchy="false" xref="S3.E2.m1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">a</mi><mo id="S3.E2.m1.1.1.1.4.2.2" stretchy="false" xref="S3.E2.m1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mrow id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml"><msub id="S3.E2.m1.2.2.2.3.1" xref="S3.E2.m1.2.2.2.3.1.cmml"><mi id="S3.E2.m1.2.2.2.3.1.2" xref="S3.E2.m1.2.2.2.3.1.2.cmml">min</mi><mi id="S3.E2.m1.2.2.2.3.1.3" xref="S3.E2.m1.2.2.2.3.1.3.cmml">b</mi></msub><mo id="S3.E2.m1.2.2.2.3a" lspace="0.167em" xref="S3.E2.m1.2.2.2.3.cmml">⁡</mo><mtext id="S3.E2.m1.2.2.2.3.2" xref="S3.E2.m1.2.2.2.3.2a.cmml">Err</mtext></mrow><mo id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.2.4.2" xref="S3.E2.m1.2.2.2.cmml"><mo id="S3.E2.m1.2.2.2.4.2.1" stretchy="false" xref="S3.E2.m1.2.2.2.cmml">(</mo><mi id="S3.E2.m1.2.2.2.1" xref="S3.E2.m1.2.2.2.1.cmml">b</mi><mo id="S3.E2.m1.2.2.2.4.2.2" stretchy="false" xref="S3.E2.m1.2.2.2.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.3.cmml" xref="S3.E2.m1.2.3"><eq id="S3.E2.m1.2.3.1.cmml" xref="S3.E2.m1.2.3.1"></eq><apply id="S3.E2.m1.2.3.2.cmml" xref="S3.E2.m1.2.3.2"><times id="S3.E2.m1.2.3.2.1.cmml" xref="S3.E2.m1.2.3.2.1"></times><ci id="S3.E2.m1.2.3.2.2.cmml" xref="S3.E2.m1.2.3.2.2">𝑆</ci><ci id="S3.E2.m1.2.3.2.3.cmml" xref="S3.E2.m1.2.3.2.3">𝐸</ci><ci id="S3.E2.m1.2.3.2.4.cmml" xref="S3.E2.m1.2.3.2.4">𝑅</ci></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3"><apply id="S3.E2.m1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.1.1.1.3.1">subscript</csymbol><max id="S3.E2.m1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.1.1.1.3.1.2"></max><ci id="S3.E2.m1.1.1.1.3.1.3.cmml" xref="S3.E2.m1.1.1.1.3.1.3">𝑎</ci></apply><ci id="S3.E2.m1.1.1.1.3.2a.cmml" xref="S3.E2.m1.1.1.1.3.2"><mtext id="S3.E2.m1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.3.2">Err</mtext></ci></apply><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑎</ci></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"></times><apply id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"><apply id="S3.E2.m1.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.3.1.1.cmml" xref="S3.E2.m1.2.2.2.3.1">subscript</csymbol><min id="S3.E2.m1.2.2.2.3.1.2.cmml" xref="S3.E2.m1.2.2.2.3.1.2"></min><ci id="S3.E2.m1.2.2.2.3.1.3.cmml" xref="S3.E2.m1.2.2.2.3.1.3">𝑏</ci></apply><ci id="S3.E2.m1.2.2.2.3.2a.cmml" xref="S3.E2.m1.2.2.2.3.2"><mtext id="S3.E2.m1.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.3.2">Err</mtext></ci></apply><ci id="S3.E2.m1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.1">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">SER=\frac{\max_{a}\text{Err}(a)}{\min_{b}\text{Err}(b)}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_S italic_E italic_R = divide start_ARG roman_max start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT Err ( italic_a ) end_ARG start_ARG roman_min start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT Err ( italic_b ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.2">where <math alttext="a" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_a</annotation></semantics></math> and <math alttext="b" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">b</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_b</annotation></semantics></math> are different demographic groups. In this context, a higher error skewness indicates that the model has a substantial discrepancy in accuracy between the best and worst performing demographic groups, and is thus less fair. On the other hand, the metric based on the standard deviation is defined as:</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="STD=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(E_{i}-\bar{E})^{2}}" class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.2" xref="S3.E3.m1.1.2.cmml"><mrow id="S3.E3.m1.1.2.2" xref="S3.E3.m1.1.2.2.cmml"><mi id="S3.E3.m1.1.2.2.2" xref="S3.E3.m1.1.2.2.2.cmml">S</mi><mo id="S3.E3.m1.1.2.2.1" xref="S3.E3.m1.1.2.2.1.cmml">⁢</mo><mi id="S3.E3.m1.1.2.2.3" xref="S3.E3.m1.1.2.2.3.cmml">T</mi><mo id="S3.E3.m1.1.2.2.1a" xref="S3.E3.m1.1.2.2.1.cmml">⁢</mo><mi id="S3.E3.m1.1.2.2.4" xref="S3.E3.m1.1.2.2.4.cmml">D</mi></mrow><mo id="S3.E3.m1.1.2.1" xref="S3.E3.m1.1.2.1.cmml">=</mo><msqrt id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mfrac id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml"><mn id="S3.E3.m1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.3.2.cmml">1</mn><mi id="S3.E3.m1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.3.3.cmml">N</mi></mfrac><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><munderover id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.1.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E3.m1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.3.2" xref="S3.E3.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E3.m1.1.1.1.1.2.2.3.1" xref="S3.E3.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E3.m1.1.1.1.1.2.2.3.3" xref="S3.E3.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml">N</mi></munderover><msup id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml">E</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml">E</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.1.cmml">¯</mo></mover></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.2.cmml" xref="S3.E3.m1.1.2"><eq id="S3.E3.m1.1.2.1.cmml" xref="S3.E3.m1.1.2.1"></eq><apply id="S3.E3.m1.1.2.2.cmml" xref="S3.E3.m1.1.2.2"><times id="S3.E3.m1.1.2.2.1.cmml" xref="S3.E3.m1.1.2.2.1"></times><ci id="S3.E3.m1.1.2.2.2.cmml" xref="S3.E3.m1.1.2.2.2">𝑆</ci><ci id="S3.E3.m1.1.2.2.3.cmml" xref="S3.E3.m1.1.2.2.3">𝑇</ci><ci id="S3.E3.m1.1.2.2.4.cmml" xref="S3.E3.m1.1.2.2.4">𝐷</ci></apply><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><root id="S3.E3.m1.1.1a.cmml" xref="S3.E3.m1.1.1"></root><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3"><divide id="S3.E3.m1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.3"></divide><cn id="S3.E3.m1.1.1.1.3.2.cmml" type="integer" xref="S3.E3.m1.1.1.1.3.2">1</cn><ci id="S3.E3.m1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.3.3">𝑁</ci></apply><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1"><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3"><eq id="S3.E3.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E3.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.2">𝑖</ci><cn id="S3.E3.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2">𝐸</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3"><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.1">¯</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2">𝐸</ci></apply></apply><cn id="S3.E3.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">STD=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(E_{i}-\bar{E})^{2}}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">italic_S italic_T italic_D = square-root start_ARG divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over¯ start_ARG italic_E end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.4">where <math alttext="E_{i}" class="ltx_Math" display="inline" id="S3.SS3.p6.1.m1.1"><semantics id="S3.SS3.p6.1.m1.1a"><msub id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mi id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2">𝐸</ci><ci id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">E_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the error rate for demographic group <math alttext="i" class="ltx_Math" display="inline" id="S3.SS3.p6.2.m2.1"><semantics id="S3.SS3.p6.2.m2.1a"><mi id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><ci id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.2.m2.1d">italic_i</annotation></semantics></math>, <math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p6.3.m3.1"><semantics id="S3.SS3.p6.3.m3.1a"><mi id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><ci id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.3.m3.1d">italic_N</annotation></semantics></math> is the total number of demographic groups, and <math alttext="\bar{E}" class="ltx_Math" display="inline" id="S3.SS3.p6.4.m4.1"><semantics id="S3.SS3.p6.4.m4.1a"><mover accent="true" id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml"><mi id="S3.SS3.p6.4.m4.1.1.2" xref="S3.SS3.p6.4.m4.1.1.2.cmml">E</mi><mo id="S3.SS3.p6.4.m4.1.1.1" xref="S3.SS3.p6.4.m4.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.1b"><apply id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1"><ci id="S3.SS3.p6.4.m4.1.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1.1">¯</ci><ci id="S3.SS3.p6.4.m4.1.1.2.cmml" xref="S3.SS3.p6.4.m4.1.1.2">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.1c">\bar{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.4.m4.1d">over¯ start_ARG italic_E end_ARG</annotation></semantics></math> is the mean error rate across all groups. A higher standard deviation indicates that the model has substantially different verification accuracies across demographic groups and is therefore less fair.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our experiments initially aimed to assess whether an FR model trained on a demographically balanced synthetic dataset could achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.SS1" title="4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4.1</span></a>). Subsequently, we explored the impact on verification accuracy by training FR models on combined synthetic and authentic data (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.SS2" title="4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and investigated the impact on the fairness of each setting involved in our study (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.SS3" title="4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>RQ1: Accuracy with Separate Synthetic and Real Data Training</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In a first analysis, we assessed whether an FR model trained on a demographically balanced synthetic dataset can achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation. To this end, Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T2" title="Table 2 ‣ 4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">2</span></a> (without data augmentation) and <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T3" title="Table 3 ‣ 4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">3</span></a> (with data augmentation) present the accuracy of the FR models trained on authentic and synthetic datasets, separately, with 5K identities.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.7" style="width:433.6pt;height:142.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.6pt,0.5pt) scale(0.99245301508681,0.99245301508681) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.7.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.7.7.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.1.1">Train Data</span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.2.1">Id/Img.</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.3.1">LFW</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.4.1">CFP-FP</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.5"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.5.1">CFP-FF</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.6"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.6.1">AgeDB-30</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.7"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.7.1">CA-LFW</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.7.7.8.1.8"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.8.1">CP-LFW</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.7.7.8.1.9"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.9.1">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1">BUPT<sub class="ltx_sub" id="S4.T2.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.1.1.1.1">avg</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.3">92.98</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.4">72.18</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.5">92.38</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.6">75.78</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.7">80.78</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.1.1.8">69.45</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.1.1.1.9">80.59</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.2.2.2.1">WF<sub class="ltx_sub" id="S4.T2.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.2.2.2.1.1.1">avg</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.2">5K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.3.1">98.91</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.4.1">92.15</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.5.1">98.92</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.6.1">91.46</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.7.1">91.76</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.2.2.2.8"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.8.1">85.91</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.2.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.9.1">93.19</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.1">BUPT<sub class="ltx_sub" id="S4.T2.3.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.3.3.3.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.3">92.98</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.4">71.18</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.5">92.38</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.6">75.78</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.7">80.78</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.3.3.3.8">69.45</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T2.3.3.3.9">80.59</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.4.4.4.1">WF<sub class="ltx_sub" id="S4.T2.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.4.4.4.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.2">5K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.3"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.3.1">98.95</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.4.1">92.27</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.5.1">98.94</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.6"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.6.1">91.40</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.7"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.7.1">91.93</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.4.8"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.8.1">86.22</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.4.4.4.9"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.1">93.28</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.1">GC<sub class="ltx_sub" id="S4.T2.5.5.5.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.5.5.5.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.3">86.96</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.4">71.67</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.5">85.52</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.6">59.56</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.7">71.83</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T2.5.5.5.8">65.56</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T2.5.5.5.9">73.65</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.6.6.6.1">DC<sub class="ltx_sub" id="S4.T2.6.6.6.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.6.6.6.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.2">5K/48</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.3.1">97.23</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.4"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.4.1">83.45</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.5"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.5.1">97.58</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.6.1">85.95</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.7.1">89.11</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.6.6.6.8"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.8.1">78.06</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.6.6.6.9"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.6.9.1">88.50</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.1">IDF<sub class="ltx_sub" id="S4.T2.7.7.7.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.7.7.7.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.3">96.50</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.4">77.44</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.5">95.15</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.6">80.10</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.7">88.05</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.7.7.7.8">76.55</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S4.T2.7.7.7.9">85.63</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.10.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.11.2" style="font-size:90%;">Verification accuracy of FR models trained on 5K identities <em class="ltx_emph ltx_font_italic" id="S4.T2.11.2.1">without data augmentation</em>. The results are reported for models trained: (i) only on authentic data, averaged across 10 iterations, (ii) only on authentic data, for the best performing iteration, and (iii) only on synthetic, demographically balanced data. The best results for each group are highlighted in bold.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.5" style="width:433.6pt;height:107.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.6pt,0.4pt) scale(0.99245301508681,0.99245301508681) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.5.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.1.1">Train Data</span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.2.1">Id/Img.</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.3.1">LFW</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.4.1">CFP-FP</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.5.1">CFP-FF</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.6.1">AgeDB-30</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.7.1">CA-LFW</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.8.1">CP-LFW</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.5.5.6.1.9"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.6.1.9.1">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1">BUPT<sub class="ltx_sub" id="S4.T3.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.1.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.3">92.90</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.4">75.65</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.5">93.22</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.6">76.78</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.7">81.28</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.1.1.1.8">70.88</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.1.1.9">81.72</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.2.2.2.1">WF<sub class="ltx_sub" id="S4.T3.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2">5K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.3.1">98.91</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.4.1">92.17</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.5.1">99.02</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.6.1">91.30</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.7.1">92.21</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.2.2.2.8"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.8.1">86.03</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.2.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.9.1">93.27</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.1">GC<sub class="ltx_sub" id="S4.T3.3.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.3.3.3.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.3">93.68</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.4">75.38</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.5">91.64</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.6">79.03</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.7">82.31</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.8">72.25</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.3.3.3.9">82.31</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.4.4.4.1">DC<sub class="ltx_sub" id="S4.T3.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.4.4.4.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.2">5K/48</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.3"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.3.1">97.45</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.4.1">86.42</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.5.1">97.32</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.6"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.6.1">87.01</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.7"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.7.1">89.33</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.4.4.4.8"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.8.1">80.00</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.4.4.4.9"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.9.1">89.52</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.1">IDF<sub class="ltx_sub" id="S4.T3.5.5.5.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.5.5.5.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.3">96.91</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.4">80.82</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5">95.24</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.6">82.56</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.7">88.00</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.8">77.53</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S4.T3.5.5.5.9">86.88</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.8.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.9.2" style="font-size:90%;">Verification accuracy of FR models trained on 5K identities <em class="ltx_emph ltx_font_italic" id="S4.T3.9.2.1">with data augmentation</em>. The results are reported for models trained: (i) only on authentic data, averaged across 10 iterations, (ii) only on authentic data, for the best performing iteration, and (iii) only on synthetic, demographically balanced data. The best results for each group are highlighted in bold.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.17">In our investigation, models trained exclusively on authentic data without the application of data augmentation (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T2" title="Table 2 ‣ 4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">2</span></a>, first two groups) consistently exhibited superior verification accuracy when trained on subsets of the CASIA-WebFace dataset. This trend was observed both when considering average performance across iterations (WF<sub class="ltx_sub" id="S4.SS1.p2.17.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.1.1">avg</span></sub>) and the best iteration outcomes (WF<sub class="ltx_sub" id="S4.SS1.p2.17.2"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.2.1">sub</span></sub>), with these models showing an approximately 15% improvement in verification accuracy w.r.t. the respective one trained on demographically balanced subsets of BUPT (BUPT<sub class="ltx_sub" id="S4.SS1.p2.17.3"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.3.1">avg</span></sub> and BUPT<sub class="ltx_sub" id="S4.SS1.p2.17.4"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.4.1">sub</span></sub>). In contrast, among the models trained solely on synthetic images (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T2" title="Table 2 ‣ 4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">2</span></a>, third group), the model trained on the DC<sub class="ltx_sub" id="S4.SS1.p2.17.5"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.5.1">bal</span></sub> subset achieved the highest verification accuracy across all evaluation benchmarks. Specifically, the latter model outperformed the one trained on the IDF<sub class="ltx_sub" id="S4.SS1.p2.17.6"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.6.1">bal</span></sub> subset by an average of 3.35% and the one trained on the GC<sub class="ltx_sub" id="S4.SS1.p2.17.7"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.7.1">bal</span></sub> subset by a substantial 20.16%. Interestingly, we observed a pronounced accuracy degradation of the FR model trained on the GC<sub class="ltx_sub" id="S4.SS1.p2.17.8"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.8.1">bal</span></sub> subset, when evaluated on cross-age benchmarks (AgeDB-30 and CA-LFW columns). For instance, compared to the models trained on DC<sub class="ltx_sub" id="S4.SS1.p2.17.9"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.9.1">bal</span></sub>, GC<sub class="ltx_sub" id="S4.SS1.p2.17.10"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.10.1">bal</span></sub>-trained models exhibited a 30.66% reduction on AgeDB-30 and a 19.39% decrease on CA-LFW.
Comparing between models trained with the two different types of sources separately (authentic and synthetic), models trained exclusively on synthetic data from DC<sub class="ltx_sub" id="S4.SS1.p2.17.11"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.11.1">bal</span></sub> and IDF<sub class="ltx_sub" id="S4.SS1.p2.17.12"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.12.1">bal</span></sub> generally achieved better verification accuracy compared to models trained on the authentic, demographically-balanced BUPT<sub class="ltx_sub" id="S4.SS1.p2.17.13"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.13.1">sub</span></sub> subset. Specifically, the model trained on the DC<sub class="ltx_sub" id="S4.SS1.p2.17.14"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.14.1">bal</span></sub> subset obtained 9.82% higher average verification accuracy, while training on the IDF<sub class="ltx_sub" id="S4.SS1.p2.17.15"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.15.1">bal</span></sub> subset led to a 6.25% gain, on average. Despite the promising results achieved by training an FR model on the best-performing synthetic dataset (DC<sub class="ltx_sub" id="S4.SS1.p2.17.16"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.16.1">bal</span></sub>), a substantial gap of 5.40% in average verification accuracy remains when compared to the best-performing authentic dataset (CASIA<sub class="ltx_sub" id="S4.SS1.p2.17.17"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.17.17.1">sub</span></sub>).</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.7">The impact of data augmentation on models trained solely on synthetic data (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T3" title="Table 3 ‣ 4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">3</span></a>, second group) was notably pronounced, especially for GC<sub class="ltx_sub" id="S4.SS1.p3.7.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.1.1">bal</span></sub>. The model trained on the latter, augmented subset, led to an average accuracy improvement of 11.75% compared to the corresponding model trained without augmentation. This improvement was particularly pronounced on cross-age benchmarks, with a remarkable 34.42% increase in verification accuracy on AgeDB-30 and a 15.59% increase on CA-LFW. Furthermore, all the models trained on synthetic datasets still reported higher verification accuracy compared to those trained on the balanced, augmented authentic data (BUPT<sub class="ltx_sub" id="S4.SS1.p3.7.2"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.2.1">sub</span></sub>), with the smallest improvement observed while training on GC<sub class="ltx_sub" id="S4.SS1.p3.7.3"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.3.1">bal</span></sub> (0.72%) and the highest improvement measured while training on DC<sub class="ltx_sub" id="S4.SS1.p3.7.4"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.4.1">bal</span></sub> (9.54%). On the other hand, adding data augmentation to the training pipeline of models trained exclusively on authentic data (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T3" title="Table 3 ‣ 4.1 RQ1: Accuracy with Separate Synthetic and Real Data Training ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">3</span></a>, first group) resulted in only marginal improvements, where the maximum increase in accuracy was limited to 1.40% (BUPT<sub class="ltx_sub" id="S4.SS1.p3.7.5"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.5.1">sub</span></sub>). Comparing results obtained by training an FR model on DC<sub class="ltx_sub" id="S4.SS1.p3.7.6"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.6.1">bal</span></sub> and CASIA<sub class="ltx_sub" id="S4.SS1.p3.7.7"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.7.7.1">sub</span></sub> while applying data augmentation, it can be noted that the accuracy gap between training on authentic and synthetic data is reduced (4.19%) with respect to the gap obtained by training on the same datasets without data augmentation.</p>
</div>
<div class="ltx_para" id="S4.SS1.1">
<p class="ltx_p ltx_align_center" id="S4.SS1.1.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS1.1.1.1" style="background-color:#F3F3F3;border-color: #FFFFFF;">
<span class="ltx_inline-logical-block ltx_parbox ltx_align_middle" id="S4.SS1.1.1.1.1.1" style="width:390.3pt;">
<span class="ltx_para ltx_noindent" id="S4.SS1.1.1.1.1.1.p1">
<span class="ltx_p" id="S4.SS1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.1.1.1.1.1.p1.1.2">RQ1</span>. <span class="ltx_text ltx_font_italic" id="S4.SS1.1.1.1.1.1.p1.1.1">Models trained on synthetic data, especially when supplemented with data augmentation, tend to get closer (CASIA-WebFace) or even outperform (BUPT) those trained on authentic (balanced) data, with the highest gains observed in cross-age tasks. The integration of data augmentation substantially mitigated performance degradation in models trained on the GC<sub class="ltx_sub" id="S4.SS1.1.1.1.1.1.p1.1.1.1">bal</sub> subset, especially concerning cross-age benchmarks.</span></span>
</span></span>
</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>RQ2: Accuracy with Combined, Balanced Training Data</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In a second analysis, we explored the impact on verification accuracy by training FR models using a combination of synthetic and authentic data. To this end, Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T4" title="Table 4 ‣ 4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4</span></a> (without data augmentation) and <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T5" title="Table 5 ‣ 4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">5</span></a> (with data augmentation) report the verification accuracy of FR models trained on datasets (either entirely authentic or combined), each composed of 10K identities.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.28">Models trained exclusively on authentic data without data augmentation (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T4" title="Table 4 ‣ 4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4</span></a>, first group) highlighted (again) a substantial gap in verification accuracy between the model trained on CASIA-WebFace and the one trained on BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.1"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.1.1">10K</span></sub>, with a 14.32% difference. FR models trained on a demographically balanced combination of synthetic and authentic data without data augmentation (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T4" title="Table 4 ‣ 4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">4</span></a>, second group) consistently outperformed the baseline model trained solely on BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.2"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.2.1">10K</span></sub>. Specifically, these models obtained 4.04% (BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.3"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.3.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.4.m4.1"><semantics id="S4.SS2.p2.4.m4.1a"><mo id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><union id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m4.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.SS2.p2.28.4"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.4.1">bal</span></sub>), 7.36% (BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.5"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.5.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.7.m7.1"><semantics id="S4.SS2.p2.7.m7.1a"><mo id="S4.SS2.p2.7.m7.1.1" xref="S4.SS2.p2.7.m7.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m7.1b"><union id="S4.SS2.p2.7.m7.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m7.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.7.m7.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.SS2.p2.28.6"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.6.1">bal</span></sub>), and 9.71% (BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.7"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.7.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.10.m10.1"><semantics id="S4.SS2.p2.10.m10.1a"><mo id="S4.SS2.p2.10.m10.1.1" xref="S4.SS2.p2.10.m10.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.10.m10.1b"><union id="S4.SS2.p2.10.m10.1.1.cmml" xref="S4.SS2.p2.10.m10.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.10.m10.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.10.m10.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS2.p2.28.8"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.8.1">bal</span></sub>) higher verification accuracy. Notably, when training an FR model on the combined BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.9"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.9.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.13.m13.1"><semantics id="S4.SS2.p2.13.m13.1a"><mo id="S4.SS2.p2.13.m13.1.1" xref="S4.SS2.p2.13.m13.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.13.m13.1b"><union id="S4.SS2.p2.13.m13.1.1.cmml" xref="S4.SS2.p2.13.m13.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.13.m13.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.13.m13.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.SS2.p2.28.10"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.10.1">bal</span></sub> dataset without data augmentation, the accuracy degradation identified on cross-age benchmarks in the previous subsection was not observed, suggesting that the inclusion of a balanced authentic data subset (BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.11"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.11.1">sub</span></sub>) effectively mitigates these issues. The best verification accuracy across all benchmarks was achieved by models trained on the combined dataset including DC<sub class="ltx_sub" id="S4.SS2.p2.28.12"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.12.1">bal</span></sub> as the synthetic component (BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.13"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.13.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.18.m18.1"><semantics id="S4.SS2.p2.18.m18.1a"><mo id="S4.SS2.p2.18.m18.1.1" xref="S4.SS2.p2.18.m18.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.18.m18.1b"><union id="S4.SS2.p2.18.m18.1.1.cmml" xref="S4.SS2.p2.18.m18.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.18.m18.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.18.m18.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS2.p2.28.14"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.14.1">bal</span></sub>). This model showed an average accuracy increase of 1.18% over the one trained on BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.15"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.15.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.21.m21.1"><semantics id="S4.SS2.p2.21.m21.1a"><mo id="S4.SS2.p2.21.m21.1.1" xref="S4.SS2.p2.21.m21.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.21.m21.1b"><union id="S4.SS2.p2.21.m21.1.1.cmml" xref="S4.SS2.p2.21.m21.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.21.m21.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.21.m21.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.SS2.p2.28.16"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.16.1">bal</span></sub> and 5.44% over the one trained on BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.17"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.17.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.24.m24.1"><semantics id="S4.SS2.p2.24.m24.1a"><mo id="S4.SS2.p2.24.m24.1.1" xref="S4.SS2.p2.24.m24.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.24.m24.1b"><union id="S4.SS2.p2.24.m24.1.1.cmml" xref="S4.SS2.p2.24.m24.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.24.m24.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.24.m24.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.SS2.p2.28.18"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.18.1">bal</span></sub>. Comparing results obtained by training an FR model on BUPT<sub class="ltx_sub" id="S4.SS2.p2.28.19"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.19.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p2.27.m27.1"><semantics id="S4.SS2.p2.27.m27.1a"><mo id="S4.SS2.p2.27.m27.1.1" xref="S4.SS2.p2.27.m27.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.27.m27.1b"><union id="S4.SS2.p2.27.m27.1.1.cmml" xref="S4.SS2.p2.27.m27.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.27.m27.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.27.m27.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS2.p2.28.20"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.28.20.1">bal</span></sub> and CASIA-WebFace, it can be noted that while the accuracy gap between training on authentic and combined (authentic and synthetic) data is reduced, it remains remarkable, with a 4.20% difference.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.10" style="width:433.6pt;height:101pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.9pt,3.5pt) scale(0.935497044076079,0.935497044076079) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.10.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.10.10.11.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.1.1">Train Data</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.2.1">Id/Img.</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.3.1">LFW</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.4.1">CFP-FP</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.5.1">CFP-FF</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.6"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.6.1">AgeDB-30</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.7"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.7.1">CA-LFW</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.11.1.8"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.8.1">CP-LFW</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.10.10.11.1.9"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.11.1.9.1">Avg.</span></th>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.1.1.1.1">BUPT<sub class="ltx_sub" id="S4.T4.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.1.1.1.1.1.1">10K</span></sub>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.2">10K/42</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.3">95.55</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.4">74.48</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.5">95.88</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.6">79.95</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.7">85.28</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1.8">69.61</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.9">83.42</th>
</tr>
<tr class="ltx_tr" id="S4.T4.10.10.12.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.1">CASIA-WebFace</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.2">10K/46</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.3"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.3.1">99.46</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.4"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.4.1">95.12</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.5"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.5.1">99.51</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.6"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.6.1">94.61</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.7"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.7.1">93.90</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.10.10.12.2.8"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.8.1">83.63</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.10.10.12.2.9"><span class="ltx_text ltx_font_bold" id="S4.T4.10.10.12.2.9.1">95.37</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.3">BUPT<sub class="ltx_sub" id="S4.T4.4.4.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T4.4.4.4.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T4.3.3.3.2.m2.1"><semantics id="S4.T4.3.3.3.2.m2.1a"><mo id="S4.T4.3.3.3.2.m2.1.1" xref="S4.T4.3.3.3.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.2.m2.1b"><union id="S4.T4.3.3.3.2.m2.1.1.cmml" xref="S4.T4.3.3.3.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.2.m2.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.T4.4.4.4.3.2"><span class="ltx_text ltx_font_italic" id="S4.T4.4.4.4.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.5">97.25</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.6">79.94</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.7">95.57</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.8">82.93</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.9">86.30</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T4.4.4.4.10">78.40</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T4.4.4.4.11">86.79</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.7.7.7.3">BUPT<sub class="ltx_sub" id="S4.T4.7.7.7.3.1"><span class="ltx_text ltx_font_italic" id="S4.T4.7.7.7.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T4.6.6.6.2.m2.1"><semantics id="S4.T4.6.6.6.2.m2.1a"><mo id="S4.T4.6.6.6.2.m2.1.1" xref="S4.T4.6.6.6.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.2.m2.1b"><union id="S4.T4.6.6.6.2.m2.1.1.cmml" xref="S4.T4.6.6.6.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.6.2.m2.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.T4.7.7.7.3.2"><span class="ltx_text ltx_font_italic" id="S4.T4.7.7.7.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.5.1">98.55</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.6"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.6.1">87.72</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.7.1">98.64</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.8"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.8.1">90.33</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.9"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.9.1">91.86</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T4.7.7.7.10"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.10.1">82.20</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.7.7.7.11"><span class="ltx_text ltx_font_bold" id="S4.T4.7.7.7.11.1">91.52</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.3">BUPT<sub class="ltx_sub" id="S4.T4.10.10.10.3.1"><span class="ltx_text ltx_font_italic" id="S4.T4.10.10.10.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T4.9.9.9.2.m2.1"><semantics id="S4.T4.9.9.9.2.m2.1a"><mo id="S4.T4.9.9.9.2.m2.1.1" xref="S4.T4.9.9.9.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.9.2.m2.1b"><union id="S4.T4.9.9.9.2.m2.1.1.cmml" xref="S4.T4.9.9.9.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.9.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T4.9.9.9.2.m2.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.T4.10.10.10.3.2"><span class="ltx_text ltx_font_italic" id="S4.T4.10.10.10.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.5">98.18</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.6">83.82</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.7">97.62</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.8">86.83</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.9">91.26</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.10.10.10.10">81.06</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S4.T4.10.10.10.11">89.86</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.16.2.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.12.1" style="font-size:90%;">Verification accuracy of FR models trained on 10K identities <em class="ltx_emph ltx_font_italic" id="S4.T4.12.1.1">without data augmentation</em>. Results are reported for models (i) trained only on authentic data and (ii) trained on demographically balanced, combined data. BUPT<sub class="ltx_sub" id="S4.T4.12.1.2"><span class="ltx_text ltx_font_italic" id="S4.T4.12.1.2.1">10K</span></sub> denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.10" style="width:433.6pt;height:101pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.9pt,3.5pt) scale(0.935497044076079,0.935497044076079) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.10.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.10.10.11.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.1.1">Train Data</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.2.1">Id/Img.</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.3.1">LFW</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.4"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.4.1">CFP-FP</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.5"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.5.1">CFP-FF</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.6"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.6.1">AgeDB-30</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.7"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.7.1">CA-LFW</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.11.1.8"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.8.1">CP-LFW</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.10.10.11.1.9"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.11.1.9.1">Avg.</span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.1.1.1.1">BUPT<sub class="ltx_sub" id="S4.T5.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T5.1.1.1.1.1.1">10K</span></sub>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.2">10K/42</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.3">93.38</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.4">73.55</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.5">94.45</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.6">76.86</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.7">82.70</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.8">70.65</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.1.9">81.19</th>
</tr>
<tr class="ltx_tr" id="S4.T5.10.10.12.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.1">CASIA-WebFace</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.2">10K/46</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.3"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.3.1">99.50</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.4"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.4.1">95.45</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.5"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.5.1">99.40</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.6"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.6.1">94.15</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.7"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.7.1">93.15</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.10.10.12.2.8"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.8.1">89.95</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.10.10.12.2.9"><span class="ltx_text ltx_font_bold" id="S4.T5.10.10.12.2.9.1">95.26</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.3">BUPT<sub class="ltx_sub" id="S4.T5.4.4.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T5.4.4.4.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T5.3.3.3.2.m2.1"><semantics id="S4.T5.3.3.3.2.m2.1a"><mo id="S4.T5.3.3.3.2.m2.1.1" xref="S4.T5.3.3.3.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.2.m2.1b"><union id="S4.T5.3.3.3.2.m2.1.1.cmml" xref="S4.T5.3.3.3.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.2.m2.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.T5.4.4.4.3.2"><span class="ltx_text ltx_font_italic" id="S4.T5.4.4.4.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.5">97.36</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.6">81.24</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.7">95.70</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.8">84.28</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.9">88.25</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T5.4.4.4.10">78.36</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T5.4.4.4.11">87.56</td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.7.7.7.3">BUPT<sub class="ltx_sub" id="S4.T5.7.7.7.3.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.7.7.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T5.6.6.6.2.m2.1"><semantics id="S4.T5.6.6.6.2.m2.1a"><mo id="S4.T5.6.6.6.2.m2.1.1" xref="S4.T5.6.6.6.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.6.2.m2.1b"><union id="S4.T5.6.6.6.2.m2.1.1.cmml" xref="S4.T5.6.6.6.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.6.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T5.6.6.6.2.m2.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.T5.7.7.7.3.2"><span class="ltx_text ltx_font_italic" id="S4.T5.7.7.7.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.5.1">98.45</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.6"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.6.1">89.62</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.7.1">98.55</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.8"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.8.1">90.20</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.9"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.9.1">91.55</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T5.7.7.7.10"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.10.1">83.85</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.7.7.7.11"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.11.1">92.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.3">BUPT<sub class="ltx_sub" id="S4.T5.10.10.10.3.1"><span class="ltx_text ltx_font_italic" id="S4.T5.10.10.10.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T5.9.9.9.2.m2.1"><semantics id="S4.T5.9.9.9.2.m2.1a"><mo id="S4.T5.9.9.9.2.m2.1.1" xref="S4.T5.9.9.9.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.9.9.2.m2.1b"><union id="S4.T5.9.9.9.2.m2.1.1.cmml" xref="S4.T5.9.9.9.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.9.9.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T5.9.9.9.2.m2.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.T5.10.10.10.3.2"><span class="ltx_text ltx_font_italic" id="S4.T5.10.10.10.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.5">98.13</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.6">84.91</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.7">97.31</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.8">87.23</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.9">90.66</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.10.10.10.10">81.50</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S4.T5.10.10.10.11">89.97</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.16.2.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.12.1" style="font-size:90%;">Verification accuracy of FR models trained on 10K identities <em class="ltx_emph ltx_font_italic" id="S4.T5.12.1.1">with data augmentation</em>. Results are reported for models (i) trained only on authentic data and (ii) trained on demographically balanced, combined data. BUPT<sub class="ltx_sub" id="S4.T5.12.1.2"><span class="ltx_text ltx_font_italic" id="S4.T5.12.1.2.1">10K</span></sub> denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.13">FR models trained with data augmentation only on authentic data (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T5" title="Table 5 ‣ 4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">5</span></a>, first group) showed slight decreases in verification accuracy w.r.t. the non-augmented counterpart, with degradations of 2.67% (BUPT<sub class="ltx_sub" id="S4.SS2.p3.13.1"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.1.1">10K</span></sub>) and 0.11% (CASIA-WebFace). Conversely, while the impact of data augmentation on models trained on combined synthetic and authentic data (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T5" title="Table 5 ‣ 4.2 RQ2: Accuracy with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">5</span></a>, second group) was generally positive, the improvement was minimal. The models reported an increase in average verification accuracy of 0.88% when trained on BUPT<sub class="ltx_sub" id="S4.SS2.p3.13.2"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.2.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><mo id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><union id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.3.m3.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.SS2.p3.13.3"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.3.1">bal</span></sub>, 0.45% on BUPT<sub class="ltx_sub" id="S4.SS2.p3.13.4"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.4.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p3.6.m6.1"><semantics id="S4.SS2.p3.6.m6.1a"><mo id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><union id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.6.m6.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.SS2.p3.13.5"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.5.1">bal</span></sub>, and 0.52% on BUPT<sub class="ltx_sub" id="S4.SS2.p3.13.6"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.6.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p3.9.m9.1"><semantics id="S4.SS2.p3.9.m9.1a"><mo id="S4.SS2.p3.9.m9.1.1" xref="S4.SS2.p3.9.m9.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.9.m9.1b"><union id="S4.SS2.p3.9.m9.1.1.cmml" xref="S4.SS2.p3.9.m9.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.9.m9.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.9.m9.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS2.p3.13.7"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.7.1">bal</span></sub>. As previously observed, including data augmentation in the training pipeline positively affects the verification accuracy gap observed when comparing the results of the FR model trained on the best-performing authentic (CASIA-WebFace) and combined (BUPT<sub class="ltx_sub" id="S4.SS2.p3.13.8"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.8.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS2.p3.12.m12.1"><semantics id="S4.SS2.p3.12.m12.1a"><mo id="S4.SS2.p3.12.m12.1.1" xref="S4.SS2.p3.12.m12.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.12.m12.1b"><union id="S4.SS2.p3.12.m12.1.1.cmml" xref="S4.SS2.p3.12.m12.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.12.m12.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.12.m12.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS2.p3.13.9"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.13.9.1">bal</span></sub>) datasets, leading to a reduced 3.54% difference.</p>
</div>
<div class="ltx_para" id="S4.SS2.1">
<p class="ltx_p ltx_align_center" id="S4.SS2.1.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS2.1.1.1" style="background-color:#F3F3F3;border-color: #FFFFFF;">
<span class="ltx_inline-logical-block ltx_parbox ltx_align_middle" id="S4.SS2.1.1.1.1.1" style="width:390.3pt;">
<span class="ltx_para ltx_noindent" id="S4.SS2.1.1.1.1.1.p1">
<span class="ltx_p" id="S4.SS2.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.1.1.1.1.1.p1.1.1">RQ2</span>. <span class="ltx_text ltx_font_italic" id="S4.SS2.1.1.1.1.1.p1.1.2">Combining demographically balanced synthetic and authentic data can improve verification accuracy compared to training exclusively on authentic data, particularly in the absence of data augmentation. The inclusion of balanced authentic data effectively mitigates potential cross-age accuracy degradation. Data augmentation provides modest changes.</span></span>
</span></span>
</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>RQ3: Fairness with Combined, Balanced Training Data</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In the third and final analysis, we investigated the impact on fairness of each setting involved in our study. To this end, Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T6" title="Table 6 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">6</span></a> (without data augmentation) and <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T7" title="Table 7 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">7</span></a> (with data augmentation) present the verification accuracy for each demographic group, as well as the standard deviation (STD) and the skewed error ratio (SER) on the RFW dataset’s benchmark used to evaluate the fairness of FR models. Higher values of STD and SER indicate a higher level of unfairness.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T6.24" style="width:433.6pt;height:204.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.5pt,14.9pt) scale(0.872979146105058,0.872979146105058) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.24.24">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.7.7.7.8"><span class="ltx_text ltx_font_bold" id="S4.T6.7.7.7.8.1">Train Data</span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.7.7.7.9"><span class="ltx_text ltx_font_bold" id="S4.T6.7.7.7.9.1">Id/Img.</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T6.1.1.1.1.1">African(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.1.1.1.1.1.m1.1"><semantics id="S4.T6.1.1.1.1.1.m1.1a"><mo id="S4.T6.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T6.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.1.1.1.1.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.2.2.1">Asian(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.2.2.2.2.1.m1.1"><semantics id="S4.T6.2.2.2.2.1.m1.1a"><mo id="S4.T6.2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T6.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.2.1.m1.1b"><ci id="S4.T6.2.2.2.2.1.m1.1.1.cmml" xref="S4.T6.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.2.2.2.2.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T6.3.3.3.3.1">Caucasian(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.3.3.3.3.1.m1.1"><semantics id="S4.T6.3.3.3.3.1.m1.1a"><mo id="S4.T6.3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T6.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.3.1.m1.1b"><ci id="S4.T6.3.3.3.3.1.m1.1.1.cmml" xref="S4.T6.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.3.3.3.3.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.4.1">Indian(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.4.4.4.4.1.m1.1"><semantics id="S4.T6.4.4.4.4.1.m1.1a"><mo id="S4.T6.4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T6.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.4.4.1.m1.1b"><ci id="S4.T6.4.4.4.4.1.m1.1.1.cmml" xref="S4.T6.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.4.4.4.4.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.5.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T6.5.5.5.5.1">Avg.(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.5.5.5.5.1.m1.1"><semantics id="S4.T6.5.5.5.5.1.m1.1a"><mo id="S4.T6.5.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T6.5.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.5.5.5.5.1.m1.1b"><ci id="S4.T6.5.5.5.5.1.m1.1.1.cmml" xref="S4.T6.5.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.5.5.5.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.5.5.5.5.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.6.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T6.6.6.6.6.1">STD(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.6.6.6.6.1.m1.1"><semantics id="S4.T6.6.6.6.6.1.m1.1a"><mo id="S4.T6.6.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T6.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.6.6.6.6.1.m1.1b"><ci id="S4.T6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T6.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.6.6.6.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.6.6.6.6.1.m1.1d">↓</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T6.7.7.7.7.1">SER(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.7.7.7.7.1.m1.1"><semantics id="S4.T6.7.7.7.7.1.m1.1a"><mo id="S4.T6.7.7.7.7.1.m1.1.1" stretchy="false" xref="S4.T6.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.7.7.7.7.1.m1.1b"><ci id="S4.T6.7.7.7.7.1.m1.1.1.cmml" xref="S4.T6.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.7.7.7.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.7.7.7.7.1.m1.1d">↓</annotation></semantics></math>)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.8.8.8.1">BUPT<sub class="ltx_sub" id="S4.T6.8.8.8.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.8.8.8.1.1.1">10K</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.2">10K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.3">72.68</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.4">75.93</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.5">79.35</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.6">79.15</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.7">76.77</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.8.8.8.8"><span class="ltx_text ltx_font_bold" id="S4.T6.8.8.8.8.1">2.72</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.8.8.8.9">1.09</td>
</tr>
<tr class="ltx_tr" id="S4.T6.24.24.25.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.1">CASIA-WebFace</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.2">10K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.3"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.25.1.3.1">87.45</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.4"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.25.1.4.1">86.31</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.5"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.25.1.5.1">93.95</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.6"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.25.1.6.1">89.45</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.7"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.25.1.7.1">89.29</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.24.24.25.1.8">2.91</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.24.24.25.1.9"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.25.1.9.1">1.08</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.3">BUPT<sub class="ltx_sub" id="S4.T6.11.11.11.3.1"><span class="ltx_text ltx_font_italic" id="S4.T6.11.11.11.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T6.10.10.10.2.m2.1"><semantics id="S4.T6.10.10.10.2.m2.1a"><mo id="S4.T6.10.10.10.2.m2.1.1" xref="S4.T6.10.10.10.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T6.10.10.10.2.m2.1b"><union id="S4.T6.10.10.10.2.m2.1.1.cmml" xref="S4.T6.10.10.10.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.10.10.10.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T6.10.10.10.2.m2.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.T6.11.11.11.3.2"><span class="ltx_text ltx_font_italic" id="S4.T6.11.11.11.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.5">73.08</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.6">76.10</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.7">79.73</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.8">77.50</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.9">76.60</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.11.11.11.10">2.41</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T6.11.11.11.11">1.09</td>
</tr>
<tr class="ltx_tr" id="S4.T6.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.14.14.14.3">BUPT<sub class="ltx_sub" id="S4.T6.14.14.14.3.1"><span class="ltx_text ltx_font_italic" id="S4.T6.14.14.14.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T6.13.13.13.2.m2.1"><semantics id="S4.T6.13.13.13.2.m2.1a"><mo id="S4.T6.13.13.13.2.m2.1.1" xref="S4.T6.13.13.13.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T6.13.13.13.2.m2.1b"><union id="S4.T6.13.13.13.2.m2.1.1.cmml" xref="S4.T6.13.13.13.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.13.13.13.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T6.13.13.13.2.m2.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.T6.14.14.14.3.2"><span class="ltx_text ltx_font_italic" id="S4.T6.14.14.14.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.5">78.58</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.6">79.96</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.7"><span class="ltx_text ltx_font_bold" id="S4.T6.14.14.14.7.1">86.38</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.8">83.61</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.9">82.13</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.14.14.14.10">3.06</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.14.14.14.11">1.09</td>
</tr>
<tr class="ltx_tr" id="S4.T6.17.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.17.17.17.3">BUPT<sub class="ltx_sub" id="S4.T6.17.17.17.3.1"><span class="ltx_text ltx_font_italic" id="S4.T6.17.17.17.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T6.16.16.16.2.m2.1"><semantics id="S4.T6.16.16.16.2.m2.1a"><mo id="S4.T6.16.16.16.2.m2.1.1" xref="S4.T6.16.16.16.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T6.16.16.16.2.m2.1b"><union id="S4.T6.16.16.16.2.m2.1.1.cmml" xref="S4.T6.16.16.16.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.16.16.16.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T6.16.16.16.2.m2.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.T6.17.17.17.3.2"><span class="ltx_text ltx_font_italic" id="S4.T6.17.17.17.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.5"><span class="ltx_text ltx_font_bold" id="S4.T6.17.17.17.5.1">79.48</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.6"><span class="ltx_text ltx_font_bold" id="S4.T6.17.17.17.6.1">82.00</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.7">85.83</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.8"><span class="ltx_text ltx_font_bold" id="S4.T6.17.17.17.8.1">83.81</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.9"><span class="ltx_text ltx_font_bold" id="S4.T6.17.17.17.9.1">82.78</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.17.17.17.10"><span class="ltx_text ltx_font_bold" id="S4.T6.17.17.17.10.1">2.33</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.17.17.17.11"><span class="ltx_text ltx_font_bold" id="S4.T6.17.17.17.11.1">1.07</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.18.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.1">BUPT<sub class="ltx_sub" id="S4.T6.18.18.18.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.18.18.18.1.1.1">avg</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.3">68.45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.4">72.37</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.5">75.45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.6">74.38</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.7">72.66</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.18.18.18.8"><span class="ltx_text ltx_font_bold" id="S4.T6.18.18.18.8.1">2.67</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T6.18.18.18.9"><span class="ltx_text ltx_font_bold" id="S4.T6.18.18.18.9.1">1.10</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.19.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.19.19.19.1">WF<sub class="ltx_sub" id="S4.T6.19.19.19.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.19.19.19.1.1.1">avg</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.3"><span class="ltx_text ltx_font_bold" id="S4.T6.19.19.19.3.1">80.76</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.4"><span class="ltx_text ltx_font_bold" id="S4.T6.19.19.19.4.1">80.83</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.5"><span class="ltx_text ltx_font_bold" id="S4.T6.19.19.19.5.1">89.71</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.6"><span class="ltx_text ltx_font_bold" id="S4.T6.19.19.19.6.1">84.63</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.7"><span class="ltx_text ltx_font_bold" id="S4.T6.19.19.19.7.1">83.98</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.19.19.19.8">3.65</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.19.19.19.9">1.11</td>
</tr>
<tr class="ltx_tr" id="S4.T6.20.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.1">BUPT<sub class="ltx_sub" id="S4.T6.20.20.20.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.20.20.20.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.3">68.06</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.4">71.66</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.5">75.38</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.6">74.36</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.7">72.37</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.20.20.20.8"><span class="ltx_text ltx_font_bold" id="S4.T6.20.20.20.8.1">2.83</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T6.20.20.20.9"><span class="ltx_text ltx_font_bold" id="S4.T6.20.20.20.9.1">1.10</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.21.21.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.21.21.21.1">WF<sub class="ltx_sub" id="S4.T6.21.21.21.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.21.21.21.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.2">5K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.3"><span class="ltx_text ltx_font_bold" id="S4.T6.21.21.21.3.1">81.31</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.4"><span class="ltx_text ltx_font_bold" id="S4.T6.21.21.21.4.1">80.61</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.5"><span class="ltx_text ltx_font_bold" id="S4.T6.21.21.21.5.1">89.78</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.6"><span class="ltx_text ltx_font_bold" id="S4.T6.21.21.21.6.1">84.60</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.7"><span class="ltx_text ltx_font_bold" id="S4.T6.21.21.21.7.1">84.07</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.21.21.21.8">3.62</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.21.21.21.9">1.11</td>
</tr>
<tr class="ltx_tr" id="S4.T6.22.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.1">GC<sub class="ltx_sub" id="S4.T6.22.22.22.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.22.22.22.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.3">57.95</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.4">64.41</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.5">66.01</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.6">63.65</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.7">63.00</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T6.22.22.22.8"><span class="ltx_text ltx_font_bold" id="S4.T6.22.22.22.8.1">3.04</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T6.22.22.22.9">1.13</td>
</tr>
<tr class="ltx_tr" id="S4.T6.23.23.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.23.23.23.1">DC<sub class="ltx_sub" id="S4.T6.23.23.23.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.23.23.23.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.3">69.98</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.4">74.80</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.5"><span class="ltx_text ltx_font_bold" id="S4.T6.23.23.23.5.1">82.21</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.6">77.81</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.7">76.20</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T6.23.23.23.8">4.45</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.23.23.23.9">1.17</td>
</tr>
<tr class="ltx_tr" id="S4.T6.24.24.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.1">IDF<sub class="ltx_sub" id="S4.T6.24.24.24.1.1"><span class="ltx_text ltx_font_italic" id="S4.T6.24.24.24.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.3"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.24.3.1">71.96</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.4"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.24.4.1">76.90</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.5">81.23</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.6"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.24.6.1">77.95</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.7"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.24.7.1">77.01</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.24.24.24.8">3.32</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S4.T6.24.24.24.9"><span class="ltx_text ltx_font_bold" id="S4.T6.24.24.24.9.1">1.12</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.30.2.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="S4.T6.26.1" style="font-size:90%;">Fairness on RFW demographic groups <em class="ltx_emph ltx_font_italic" id="S4.T6.26.1.1">without data augmentation</em>. We report the verification accuracy, standard deviation, and skewed error for FR models trained: (i) only on authentic data (10K), (ii) on demographically balanced, combined data (10K), (iii) only on authentic data, averaged across ten iterations (5K), (iv) only on authentic data, on the best iteration (5K), and (v) only on synthetic, demographically balanced data. BUPT<sub class="ltx_sub" id="S4.T6.26.1.2"><span class="ltx_text ltx_font_italic" id="S4.T6.26.1.2.1">10K</span></sub> denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T7.22" style="width:433.6pt;height:172.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.5pt,12.6pt) scale(0.872979146105058,0.872979146105058) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T7.22.22">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.7.7.7.8"><span class="ltx_text ltx_font_bold" id="S4.T7.7.7.7.8.1">Train Data</span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.7.7.7.9"><span class="ltx_text ltx_font_bold" id="S4.T7.7.7.7.9.1">Id/Img.</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.1.1.1">African(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.1.1.1.1.1.m1.1"><semantics id="S4.T7.1.1.1.1.1.m1.1a"><mo id="S4.T7.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T7.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.1.1.m1.1b"><ci id="S4.T7.1.1.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.1.1.1.1.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T7.2.2.2.2.1">Asian(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.2.2.2.2.1.m1.1"><semantics id="S4.T7.2.2.2.2.1.m1.1a"><mo id="S4.T7.2.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T7.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.2.2.1.m1.1b"><ci id="S4.T7.2.2.2.2.1.m1.1.1.cmml" xref="S4.T7.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.2.2.2.2.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T7.3.3.3.3.1">Caucasian(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.3.3.3.3.1.m1.1"><semantics id="S4.T7.3.3.3.3.1.m1.1a"><mo id="S4.T7.3.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T7.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.3.3.3.3.1.m1.1b"><ci id="S4.T7.3.3.3.3.1.m1.1.1.cmml" xref="S4.T7.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.3.3.3.3.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T7.4.4.4.4.1">Indian(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.4.4.4.4.1.m1.1"><semantics id="S4.T7.4.4.4.4.1.m1.1a"><mo id="S4.T7.4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T7.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.4.4.4.4.1.m1.1b"><ci id="S4.T7.4.4.4.4.1.m1.1.1.cmml" xref="S4.T7.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.4.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.4.4.4.4.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.5.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T7.5.5.5.5.1">Avg.(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.5.5.5.5.1.m1.1"><semantics id="S4.T7.5.5.5.5.1.m1.1a"><mo id="S4.T7.5.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T7.5.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.5.5.5.5.1.m1.1b"><ci id="S4.T7.5.5.5.5.1.m1.1.1.cmml" xref="S4.T7.5.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.5.5.5.5.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.5.5.5.5.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.6.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T7.6.6.6.6.1">STD(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T7.6.6.6.6.1.m1.1"><semantics id="S4.T7.6.6.6.6.1.m1.1a"><mo id="S4.T7.6.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T7.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.6.6.6.6.1.m1.1b"><ci id="S4.T7.6.6.6.6.1.m1.1.1.cmml" xref="S4.T7.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.6.6.6.6.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.6.6.6.6.1.m1.1d">↓</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T7.7.7.7.7.1">SER(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T7.7.7.7.7.1.m1.1"><semantics id="S4.T7.7.7.7.7.1.m1.1a"><mo id="S4.T7.7.7.7.7.1.m1.1.1" stretchy="false" xref="S4.T7.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.7.7.7.7.1.m1.1b"><ci id="S4.T7.7.7.7.7.1.m1.1.1.cmml" xref="S4.T7.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.7.7.7.7.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.7.7.7.7.1.m1.1d">↓</annotation></semantics></math>)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.8.8.8.1">BUPT<sub class="ltx_sub" id="S4.T7.8.8.8.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.8.8.8.1.1.1">10K</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.2">10K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.3">67.76</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.4">73.11</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.5">76.80</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.6">72.20</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.7">73.47</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.8.8.8.8">3.21</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.8.8.8.9">1.13</td>
</tr>
<tr class="ltx_tr" id="S4.T7.22.22.23.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.1">CASIA-WebFace</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.2">10K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.3"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.3.1">87.00</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.4"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.4.1">85.53</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.5"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.5.1">93.51</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.6"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.6.1">88.90</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.7"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.7.1">88.73</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.22.22.23.1.8"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.8.1">3.00</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.22.22.23.1.9"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.23.1.9.1">1.09</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.3">BUPT<sub class="ltx_sub" id="S4.T7.11.11.11.3.1"><span class="ltx_text ltx_font_italic" id="S4.T7.11.11.11.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T7.10.10.10.2.m2.1"><semantics id="S4.T7.10.10.10.2.m2.1a"><mo id="S4.T7.10.10.10.2.m2.1.1" xref="S4.T7.10.10.10.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T7.10.10.10.2.m2.1b"><union id="S4.T7.10.10.10.2.m2.1.1.cmml" xref="S4.T7.10.10.10.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.10.10.10.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T7.10.10.10.2.m2.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.T7.11.11.11.3.2"><span class="ltx_text ltx_font_italic" id="S4.T7.11.11.11.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.5">71.35</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.6">77.18</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.7">80.53</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.8">77.81</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.9">76.72</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.11.11.11.10">3.34</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T7.11.11.11.11">1.12</td>
</tr>
<tr class="ltx_tr" id="S4.T7.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.14.14.14.3">BUPT<sub class="ltx_sub" id="S4.T7.14.14.14.3.1"><span class="ltx_text ltx_font_italic" id="S4.T7.14.14.14.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T7.13.13.13.2.m2.1"><semantics id="S4.T7.13.13.13.2.m2.1a"><mo id="S4.T7.13.13.13.2.m2.1.1" xref="S4.T7.13.13.13.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T7.13.13.13.2.m2.1b"><union id="S4.T7.13.13.13.2.m2.1.1.cmml" xref="S4.T7.13.13.13.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.13.13.13.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T7.13.13.13.2.m2.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.T7.14.14.14.3.2"><span class="ltx_text ltx_font_italic" id="S4.T7.14.14.14.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.5"><span class="ltx_text ltx_font_bold" id="S4.T7.14.14.14.5.1">79.68</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.6">81.26</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.7"><span class="ltx_text ltx_font_bold" id="S4.T7.14.14.14.7.1">87.58</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.8"><span class="ltx_text ltx_font_bold" id="S4.T7.14.14.14.8.1">84.56</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.9"><span class="ltx_text ltx_font_bold" id="S4.T7.14.14.14.9.1">83.27</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.14.14.14.10"><span class="ltx_text ltx_font_bold" id="S4.T7.14.14.14.10.1">3.04</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.14.14.14.11"><span class="ltx_text ltx_font_bold" id="S4.T7.14.14.14.11.1">1.09</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.17.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.17.17.17.3">BUPT<sub class="ltx_sub" id="S4.T7.17.17.17.3.1"><span class="ltx_text ltx_font_italic" id="S4.T7.17.17.17.3.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.T7.16.16.16.2.m2.1"><semantics id="S4.T7.16.16.16.2.m2.1a"><mo id="S4.T7.16.16.16.2.m2.1.1" xref="S4.T7.16.16.16.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.T7.16.16.16.2.m2.1b"><union id="S4.T7.16.16.16.2.m2.1.1.cmml" xref="S4.T7.16.16.16.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.16.16.16.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.T7.16.16.16.2.m2.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.T7.17.17.17.3.2"><span class="ltx_text ltx_font_italic" id="S4.T7.17.17.17.3.2.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.4">10K/45</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.5">76.65</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.6"><span class="ltx_text ltx_font_bold" id="S4.T7.17.17.17.6.1">82.16</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.7">85.75</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.8">83.41</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.9">82.49</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.17.17.17.10">3.34</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.17.17.17.11">1.11</td>
</tr>
<tr class="ltx_tr" id="S4.T7.18.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.1">BUPT<sub class="ltx_sub" id="S4.T7.18.18.18.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.18.18.18.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.2">5K/42</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.3">64.86</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.4">70.91</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.5">74.60</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.6">73.35</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.7">70.93</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.18.18.18.8"><span class="ltx_text ltx_font_bold" id="S4.T7.18.18.18.8.1">3.74</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T7.18.18.18.9">1.14</td>
</tr>
<tr class="ltx_tr" id="S4.T7.19.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.19.19.19.1">WF<sub class="ltx_sub" id="S4.T7.19.19.19.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.19.19.19.1.1.1">sub</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.2">5K/46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.3"><span class="ltx_text ltx_font_bold" id="S4.T7.19.19.19.3.1">80.76</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.4"><span class="ltx_text ltx_font_bold" id="S4.T7.19.19.19.4.1">80.08</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.5"><span class="ltx_text ltx_font_bold" id="S4.T7.19.19.19.5.1">89.50</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.6"><span class="ltx_text ltx_font_bold" id="S4.T7.19.19.19.6.1">84.81</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.7"><span class="ltx_text ltx_font_bold" id="S4.T7.19.19.19.7.1">83.79</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.19.19.19.8">3.76</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.19.19.19.9"><span class="ltx_text ltx_font_bold" id="S4.T7.19.19.19.9.1">1.11</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.20.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.1">GC<sub class="ltx_sub" id="S4.T7.20.20.20.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.20.20.20.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.3">63.21</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.4">71.46</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.5">73.91</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.6">71.68</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.7">70.00</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S4.T7.20.20.20.8">4.07</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T7.20.20.20.9">1.16</td>
</tr>
<tr class="ltx_tr" id="S4.T7.21.21.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.21.21.21.1">DC<sub class="ltx_sub" id="S4.T7.21.21.21.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.21.21.21.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.2">5K/48</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.3">71.78</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.4">75.95</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.5"><span class="ltx_text ltx_font_bold" id="S4.T7.21.21.21.5.1">83.55</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.6"><span class="ltx_text ltx_font_bold" id="S4.T7.21.21.21.6.1">79.10</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.7">77.59</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T7.21.21.21.8">4.30</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.21.21.21.9">1.16</td>
</tr>
<tr class="ltx_tr" id="S4.T7.22.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.1">IDF<sub class="ltx_sub" id="S4.T7.22.22.22.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.22.22.22.1.1.1">bal</span></sub>
</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.2">5K/47</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.3"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.22.3.1">73.36</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.4"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.22.4.1">77.25</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.5">81.88</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.6">78.80</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.7"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.22.7.1">77.82</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.22.22.22.8"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.22.8.1">3.06</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_t" id="S4.T7.22.22.22.9"><span class="ltx_text ltx_font_bold" id="S4.T7.22.22.22.9.1">1.11</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T7.28.2.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="S4.T7.24.1" style="font-size:90%;">Fairness on RFW demographic groups <em class="ltx_emph ltx_font_italic" id="S4.T7.24.1.1">with data augmentation</em>. We report the verification accuracy, standard deviation, and skewed error for FR models trained: (i) only on authentic data (10K), (ii) on demographically balanced, combined data (10K), (iii) only on authentic data, averaged across ten iterations (5K), (iv) only on authentic data, on the best iteration (5K), and (v) only on synthetic, demographically balanced data. BUPT<sub class="ltx_sub" id="S4.T7.24.1.2"><span class="ltx_text ltx_font_italic" id="S4.T7.24.1.2.1">10K</span></sub> denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.4">On the RFW benchmark, models trained exclusively on authentic data without data augmentation (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T6" title="Table 6 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">6</span></a>, first group) revealed that training on the balanced dataset (BUPT<sub class="ltx_sub" id="S4.SS3.p2.4.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p2.4.1.1">10K</span></sub>) led to lower verification accuracy compared to CASIA-WebFace, with a notable gap of 16.19%. Although training on BUPT<sub class="ltx_sub" id="S4.SS3.p2.4.2"><span class="ltx_text ltx_font_italic" id="S4.SS3.p2.4.2.1">10K</span></sub> led to a slight improvement in terms of fairness, as indicated by a 6.52% reduction in STD, it also showed a slight negative impact on SER. A similar trend was observed when training FR models on smaller subsets with 5K identities, BUPT<sub class="ltx_sub" id="S4.SS3.p2.4.3"><span class="ltx_text ltx_font_italic" id="S4.SS3.p2.4.3.1">sub</span></sub> and WF<sub class="ltx_sub" id="S4.SS3.p2.4.4"><span class="ltx_text ltx_font_italic" id="S4.SS3.p2.4.4.1">sub</span></sub> (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T6" title="Table 6 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">6</span></a>, third and fourth groups), where the balanced subset showed marginally better fairness but still under-performed in verification accuracy.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.21">The results achieved by training FR models on synthetic balanced subsets (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T6" title="Table 6 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">6</span></a>, second and fifth groups), either alone or in combination with BUPT<sub class="ltx_sub" id="S4.SS3.p3.21.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.1.1">sub</span></sub>, slightly diverged from previous observations. Among the models trained solely on synthetic data (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T6" title="Table 6 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">6</span></a>, second group), the model trained on IDF<sub class="ltx_sub" id="S4.SS3.p3.21.2"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.2.1">bal</span></sub> achieved the highest average verification accuracy, outperforming those trained on DC<sub class="ltx_sub" id="S4.SS3.p3.21.3"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.3.1">bal</span></sub> by 1.06% and on GC<sub class="ltx_sub" id="S4.SS3.p3.21.4"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.4.1">bal</span></sub> by 22.23%. Additionally, the model trained on IDF<sub class="ltx_sub" id="S4.SS3.p3.21.5"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.5.1">bal</span></sub> reported the best SER (1.02), while the model trained on GC<sub class="ltx_sub" id="S4.SS3.p3.21.6"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.6.1">bal</span></sub> achieved the lowest STD. Training on combined balanced datasets (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T6" title="Table 6 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">6</span></a>, fifth group) led to similar patterns. The model trained on BUPT<sub class="ltx_sub" id="S4.SS3.p3.21.7"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.7.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p3.8.m8.1"><semantics id="S4.SS3.p3.8.m8.1a"><mo id="S4.SS3.p3.8.m8.1.1" xref="S4.SS3.p3.8.m8.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.8.m8.1b"><union id="S4.SS3.p3.8.m8.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.8.m8.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.8.m8.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S4.SS3.p3.21.8"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.8.1">bal</span></sub> exhibited the best average accuracy across demographic groups (82.78%) and the lowest SER and STD (1.07 and 2.33, respectively). Models trained on the other combined datasets (BUPT<sub class="ltx_sub" id="S4.SS3.p3.21.9"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.9.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p3.11.m11.1"><semantics id="S4.SS3.p3.11.m11.1a"><mo id="S4.SS3.p3.11.m11.1.1" xref="S4.SS3.p3.11.m11.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.11.m11.1b"><union id="S4.SS3.p3.11.m11.1.1.cmml" xref="S4.SS3.p3.11.m11.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.11.m11.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.11.m11.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.SS3.p3.21.10"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.10.1">bal</span></sub> and BUPT<sub class="ltx_sub" id="S4.SS3.p3.21.11"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.11.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p3.14.m14.1"><semantics id="S4.SS3.p3.14.m14.1a"><mo id="S4.SS3.p3.14.m14.1.1" xref="S4.SS3.p3.14.m14.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.14.m14.1b"><union id="S4.SS3.p3.14.m14.1.1.cmml" xref="S4.SS3.p3.14.m14.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.14.m14.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.14.m14.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS3.p3.21.12"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.12.1">bal</span></sub>) reported a SER of 1.09, but differences were noted in average STD and verification accuracy. Specifically, the model trained on BUPT<sub class="ltx_sub" id="S4.SS3.p3.21.13"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.13.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p3.17.m17.1"><semantics id="S4.SS3.p3.17.m17.1a"><mo id="S4.SS3.p3.17.m17.1.1" xref="S4.SS3.p3.17.m17.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.17.m17.1b"><union id="S4.SS3.p3.17.m17.1.1.cmml" xref="S4.SS3.p3.17.m17.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.17.m17.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.17.m17.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS3.p3.21.14"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.14.1">bal</span></sub> achieved 8.06% higher accuracy but a worse STD (-26.97%) compared to the model trained on BUPT<sub class="ltx_sub" id="S4.SS3.p3.21.15"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.15.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p3.20.m20.1"><semantics id="S4.SS3.p3.20.m20.1a"><mo id="S4.SS3.p3.20.m20.1.1" xref="S4.SS3.p3.20.m20.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.20.m20.1b"><union id="S4.SS3.p3.20.m20.1.1.cmml" xref="S4.SS3.p3.20.m20.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.20.m20.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.20.m20.1d">∪</annotation></semantics></math> GC<sub class="ltx_sub" id="S4.SS3.p3.21.16"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.21.16.1">bal</span></sub>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.8">Training with data augmentation (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T7" title="Table 7 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">7</span></a>) had a generally negative impact on models trained solely on authentic data (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T7" title="Table 7 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">7</span></a>, first and third groups), worsening both average verification accuracy and fairness metrics on both the employed authentic datasets. This trend was consistent across the study, with data augmentation resulting in a substantial deterioration of fairness metrics for all models, except for the STD in models trained on DC<sub class="ltx_sub" id="S4.SS3.p4.8.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.8.1.1">bal</span></sub>, IDF<sub class="ltx_sub" id="S4.SS3.p4.8.2"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.8.2.1">bal</span></sub>, and BUPT<sub class="ltx_sub" id="S4.SS3.p4.8.3"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.8.3.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p4.4.m4.1"><semantics id="S4.SS3.p4.4.m4.1a"><mo id="S4.SS3.p4.4.m4.1.1" xref="S4.SS3.p4.4.m4.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m4.1b"><union id="S4.SS3.p4.4.m4.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m4.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.4.m4.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS3.p4.8.4"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.8.4.1">bal</span></sub>. Interestingly, training with data augmentation led to gains in accuracy across all models trained on combined or synthetic datasets (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.02867v1#S4.T7" title="Table 7 ‣ 4.3 RQ3: Fairness with Combined, Balanced Training Data ‣ 4 Experimental Results ‣ The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition"><span class="ltx_text ltx_ref_tag">7</span></a>, second and fourth groups), exception made for BUPT<sub class="ltx_sub" id="S4.SS3.p4.8.5"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.8.5.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S4.SS3.p4.7.m7.1"><semantics id="S4.SS3.p4.7.m7.1a"><mo id="S4.SS3.p4.7.m7.1.1" xref="S4.SS3.p4.7.m7.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.7.m7.1b"><union id="S4.SS3.p4.7.m7.1.1.cmml" xref="S4.SS3.p4.7.m7.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.7.m7.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.7.m7.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S4.SS3.p4.8.6"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.8.6.1">bal</span></sub>.</p>
</div>
<div class="ltx_para" id="S4.SS3.1">
<p class="ltx_p ltx_align_center" id="S4.SS3.1.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS3.1.1.1" style="background-color:#F3F3F3;border-color: #FFFFFF;">
<span class="ltx_inline-logical-block ltx_parbox ltx_align_middle" id="S4.SS3.1.1.1.1.1" style="width:390.3pt;">
<span class="ltx_para ltx_noindent" id="S4.SS3.1.1.1.1.1.p1">
<span class="ltx_p" id="S4.SS3.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.1.1.1.1.1.p1.1.1">RQ3</span>. <span class="ltx_text ltx_font_italic" id="S4.SS3.1.1.1.1.1.p1.1.2">Training on balanced datasets slightly improved fairness metrics but often resulted in reduced accuracy, particularly when using authentic-only data. However, synthetic data, especially when combined with balanced authentic datasets, shows promising outcomes in both accuracy and fairness. Data augmentation typically introduces trade-offs, as it tends to negatively impact fairness, even though it may provide a modest increase in overall verification accuracy.</span></span>
</span></span>
</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.12">In this paper, we explored the impact of using combined authentic and synthetic datasets on both verification accuracy and fairness of FR models by balancing their demographic representation. Our results revealed that training an FR model with an equal amount of demographically balanced authentic and synthetic data can help reduce the accuracy gap. For example, training on BUPT<sub class="ltx_sub" id="S5.p1.12.1"><span class="ltx_text ltx_font_italic" id="S5.p1.12.1.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S5.p1.2.m2.1"><semantics id="S5.p1.2.m2.1a"><mo id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><union id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S5.p1.12.2"><span class="ltx_text ltx_font_italic" id="S5.p1.12.2.1">bal</span></sub> and BUPT<sub class="ltx_sub" id="S5.p1.12.3"><span class="ltx_text ltx_font_italic" id="S5.p1.12.3.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S5.p1.5.m5.1"><semantics id="S5.p1.5.m5.1a"><mo id="S5.p1.5.m5.1.1" xref="S5.p1.5.m5.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S5.p1.5.m5.1b"><union id="S5.p1.5.m5.1.1.cmml" xref="S5.p1.5.m5.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.5.m5.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S5.p1.5.m5.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S5.p1.12.4"><span class="ltx_text ltx_font_italic" id="S5.p1.12.4.1">bal</span></sub> achieved performances comparable to FR models trained solely on the authentic CASIA-WebFace dataset, with the model trained on BUPT<sub class="ltx_sub" id="S5.p1.12.5"><span class="ltx_text ltx_font_italic" id="S5.p1.12.5.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S5.p1.8.m8.1"><semantics id="S5.p1.8.m8.1a"><mo id="S5.p1.8.m8.1.1" xref="S5.p1.8.m8.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S5.p1.8.m8.1b"><union id="S5.p1.8.m8.1.1.cmml" xref="S5.p1.8.m8.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.8.m8.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S5.p1.8.m8.1d">∪</annotation></semantics></math> DC<sub class="ltx_sub" id="S5.p1.12.6"><span class="ltx_text ltx_font_italic" id="S5.p1.12.6.1">bal</span></sub> showing a difference of only 3.53%.
Our study also suggests that training an FR model on a mix of synthetic and authentic demographically balanced datasets can result in a fairer model with lower standard deviation and skewed error ratio. For instance, the model trained on BUPT<sub class="ltx_sub" id="S5.p1.12.7"><span class="ltx_text ltx_font_italic" id="S5.p1.12.7.1">sub</span></sub> <math alttext="\cup" class="ltx_Math" display="inline" id="S5.p1.11.m11.1"><semantics id="S5.p1.11.m11.1a"><mo id="S5.p1.11.m11.1.1" xref="S5.p1.11.m11.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="S5.p1.11.m11.1b"><union id="S5.p1.11.m11.1.1.cmml" xref="S5.p1.11.m11.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.11.m11.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="S5.p1.11.m11.1d">∪</annotation></semantics></math> IDF<sub class="ltx_sub" id="S5.p1.12.8"><span class="ltx_text ltx_font_italic" id="S5.p1.12.8.1">bal</span></sub> achieved an STD of 2.33 and a SER of 1.07, the lowest overall in both metrics. However, the analyses also produced some ambiguous results, where FR models trained on unbalanced datasets achieved better fairness outcomes than those trained on balanced ones.
Finally, we found that while data augmentation typically increases average verification accuracy, it also leads to a rise in standard deviation and skewed error, thereby worsening models’ fairness.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Building upon the findings and limitations of this work, our future efforts will focus on exploring the performance of different combinations using a broader range of architectures, such as ResNet-34 and ResNet-100, as well as various loss functions, including ArcFace and AdaFace. Additionally, we plan to incorporate more advanced data augmentation techniques, refined sampling strategies, domain generalization methods, and active learning and/or knowledge distillation techniques to further enhance the accuracy and fairness of the FR models through an optimized combination of both authentic and synthetic data.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (Text with EEA relevance) (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Albiero, V., Bowyer, K.W.: Is face recognition sexist? no, gendered hairstyles and biology are. In: Proc. of BMVC 2020 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Albiero, V., KS, K., Vangara, K., Zhang, K., King, M.C., Bowyer, K.W.: Analysis of gender inequality in face recognition accuracy. In: Proc. of the IEEE/CVF Winter Conf. on App. of Computer Vision Workshops. pp. 81–89 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Atzori, A., Boutros, F., Damer, N., Fenu, G., Marras, M.: If it’s not enough, make it so: Reducing authentic data demand in face recognition through synthetic faces. In: 2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG). pp. 1–10 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Atzori, A., Fenu, G., Marras, M.: Explaining bias in deep face recognition via image characteristics. In: 2022 IEEE International Joint Conference on Biometrics (IJCB). pp. 1–10 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Atzori, A., Fenu, G., Marras, M.: The more secure, the less equally usable: Gender and ethnicity (un)fairness of deep face recognition along security thresholds. Procedia Computer Science <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">210</span>, 212–217 (2022), the 13th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN) / The 12th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2022) / Affiliated Workshops

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Atzori, A., Fenu, G., Marras, M.: Demographic bias in low-resolution deep face recognition in the wild. IEEE Journal of Selected Topics in Signal Processing <span class="ltx_text ltx_font_bold" id="bib.bib7.1.1">17</span>(3), 599–611 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Atzori, A., Fenu, G., Marras, M.: Fairness of exposure in forensic face rankings. In: Nardini, F.M., Tonellotto, N., Faggioli, G., Ferrara, A. (eds.) Proceedings of the 13th Italian Information Retrieval Workshop (IIR 2023), Pisa, Italy, June 8-9, 2023. CEUR Workshop Proceedings, vol. 3448, pp. 91–96. CEUR-WS.org (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Atzori, A., Fenu, G., Marras, M.: (un)fair exposure in deep face rankings at a distance. In: 2023 IEEE International Joint Conference on Biometrics (IJCB). pp. 1–9 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Bae, G., de La Gorce, M., Baltrusaitis, T., Hewitt, C., Chen, D., Valentin, J.P.C., Cipolla, R., Shen, J.: Digiface-1m: 1 million digital face images for face recognition. In: IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2023, Waikoloa, HI, USA, January 2-7, 2023. pp. 3515–3524. IEEE (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Bansal, A., Nanduri, A., Castillo, C.D., Ranjan, R., Chellappa, R.: Umdfaces: An annotated face dataset for training deep networks. In: 2017 IEEE International Joint Conference on Biometrics, IJCB 2017, Denver, CO, USA, October 1-4, 2017. pp. 464–473. IEEE (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Boratto, L., Fenu, G., Marras, M., Medda, G.: Practical perspectives of consumer fairness in recommendation. Inf. Process. Manag. <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">60</span>(2), 103208 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Boutros, F., Damer, N., Kirchbuchner, F., Kuijper, A.: Elasticface: Elastic margin loss for deep face recognition. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 1578–1587 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Boutros, F., Grebe, J.H., Kuijper, A., Damer, N.: Idiff-face: Synthetic-based face recognition through fizzy identity-conditioned diffusion model. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 19650–19661 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Boutros, F., Huber, M., Siebke, P., Rieber, T., Damer, N.: Sface: Privacy-friendly and accurate face recognition using synthetic data. In: IEEE International Joint Conference on Biometrics, IJCB 2022, Abu Dhabi, United Arab Emirates, October 10-13, 2022. pp. 1–11. IEEE (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Boutros, F., Klemt, M., Fang, M., Kuijper, A., Damer, N.: Exfacegan: Exploring identity directions in gan’s learned latent space for synthetic identity generation. In: IEEE International Joint Conference on Biometrics, IJCB 2023 (September 2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Boutros, F., Klemt, M., Fang, M., Kuijper, A., Damer, N.: Unsupervised face recognition using unlabeled synthetic data. In: 2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG). pp. 1–8. IEEE (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Boutros, F., Siebke, P., Klemt, M., Damer, N., Kirchbuchner, F., Kuijper, A.: Pocketnet: Extreme lightweight face recognition network using neural architecture search and multistep knowledge distillation. IEEE Access <span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">10</span>, 46823–46833 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Boutros, F., Struc, V., Fiérrez, J., Damer, N.: Synthetic data for face recognition: Current state and future prospects. Image Vis. Comput. <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">135</span>, 104688 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Cao, Q., Shen, L., Xie, W., Parkhi, O.M., Zisserman, A.: In: 2018 13th IEEE international conference on automatic face &amp; gesture recognition (FG 2018). pp. 67–74. IEEE (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Cao, Q., Shen, L., Xie, W., Parkhi, O.M., Zisserman, A.: Vggface2: A dataset for recognising faces across pose and age. In: 13th IEEE International Conference on Automatic Face &amp; Gesture Recognition, FG 2018, Xi’an, China, May 15-19, 2018. pp. 67–74. IEEE Computer Society (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Cubuk, E.D., Zoph, B., Shlens, J., Le, Q.V.: Randaugment: Practical automated data augmentation with a reduced search space. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops. pp. 702–703 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
DeAndres-Tame, I., Tolosana, R., Melzi, P., Vera-Rodriguez, R., Kim, M., Rathgeb, C., Liu, X., Morales, A., Fierrez, J., Ortega-Garcia, J., et al.: Frcsyn challenge at cvpr 2024: Face recognition challenge in the era of synthetic data. arXiv preprint arXiv:2404.10378 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Deng, J., Guo, J., Yang, J., Xue, N., Kotsia, I., Zafeiriou, S.: Arcface: Additive angular margin loss for deep face recognition. IEEE Trans. Pattern Anal. Mach. Intell. <span class="ltx_text ltx_font_bold" id="bib.bib24.1.1">44</span>(10), 5962–5979 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Deng, Y., Yang, J., Chen, D., Wen, F., Tong, X.: Disentangled and controllable face image generation via 3d imitative-contrastive learning. In: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020. pp. 5153–5162. Computer Vision Foundation / IEEE (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Fenu, G., Marras, M.: Controlling user access to cloud-connected mobile applications by means of biometrics. IEEE Cloud Comput. <span class="ltx_text ltx_font_bold" id="bib.bib26.1.1">5</span>(4), 47–57 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Guo, Y., Zhang, L., Hu, Y., He, X., Gao, J.: Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. In: Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III. Lecture Notes in Computer Science, vol. 9907, pp. 87–102. Springer (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition pp. 770–778 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib29.1.1">33</span>, 6840–6851 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Howard, J.J., Sirotin, Y.B., Vemury, A.R.: The effect of broad and specific demographic homogeneity on the imposter distributions and false match rates in face recognition algorithm performance. In: Proc. of BTAS 2019. pp. 1–8. IEEE (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Huang, G.B., Mattar, M., Berg, T., Learned-Miller, E.: Labeled faces in the wild: A database forstudying face recognition in unconstrained environments. In: Workshop on faces in’Real-Life’Images: detection, alignment, and recognition (2008)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Hupont, I., Fernández, C.: Demogpairs: Quantifying the impact of demographic imbalance in deep face recognition. In: Proc. of the 14th IEEE In. Conf. on Automatic Face &amp; Gesture Recognition (FG 2019). pp. 1–7. IEEE (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Jr., K.R., Bhardwaj, S., Sodomsky, M.: A review of face recognition against longitudinal child faces. In: Brömme, A., Busch, C., Rathgeb, C., Uhl, A. (eds.) BIOSIG 2015 - Proceedings of the 14th International Conference of the Biometrics Special Interest Group, 9.-11. September 2015, Darmstadt, Germany. LNI, vol. P-245, pp. 15–26. GI (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Karras, T., Aittala, M., Laine, S., Härkönen, E., Hellsten, J., Lehtinen, J., Aila, T.: Alias-free generative adversarial networks. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">34</span>, 852–863 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Karras, T., Laine, S., Aila, T.: A style-based generator architecture for generative adversarial networks. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 4401–4410 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T.: Analyzing and improving the image quality of stylegan. In: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020. pp. 8107–8116. Computer Vision Foundation / IEEE (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Kim, M., Jain, A.K., Liu, X.: Adaface: Quality adaptive margin for face recognition. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 18750–18759 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Kim, M., Liu, F., Jain, A., Liu, X.: Dcface: Synthetic face generation with dual condition diffusion model. In: Proceedings of the ieee/cvf conference on computer vision and pattern recognition. pp. 12715–12725 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Kotwal, K., Marcel, S.: Mitigating demographic bias in face recognition via regularized score calibration. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops. pp. 1150–1159 (January 2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Marras, M., Korus, P., Memon, N.D., Fenu, G.: Adversarial optimization for dictionary attacks on speaker verification. In: Interspeech 2019. pp. 2913–2917. ISCA (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., Galstyan, A.: A survey on bias and fairness in machine learning. ACM Comput. Surv. <span class="ltx_text ltx_font_bold" id="bib.bib41.1.1">54</span>(6) (jul 2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Melzi, P., Rathgeb, C., Tolosana, R., Vera-Rodriguez, R., Lawatsch, D., Domin, F., Schaubert, M.: Gandiffface: Controllable generation of synthetic datasets for face recognition with realistic variations. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 3086–3095 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Melzi, P., Tolosana, R., Vera-Rodriguez, R., Kim, M., Rathgeb, C., Liu, X., DeAndres-Tame, I., Morales, A., Fierrez, J., Ortega-Garcia, J., Zhao, W., Zhu, X., Yan, Z., Zhang, X.Y., Wu, J., Lei, Z., Tripathi, S., Kothari, M., Zama, M.H., Deb, D., Biesseck, B., Vidal, P., Granada, R., Fickel, G., Führ, G., Menotti, D., Unnervik, A., George, A., Ecabert, C., Shahreza, H.O., Rahimi, P., Marcel, S., Sarridis, I., Koutlis, C., Baltsou, G., Papadopoulos, S., Diou, C., Di Domenico, N., Borghi, G., Pellegrini, L., Mas-Candela, E., Sánchez-Pérez, A., Atzori, A., Boutros, F., Damer, N., Fenu, G., Marras, M.: Frcsyn challenge at wacv 2024: Face recognition challenge in the era of synthetic data. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops. pp. 892–901 (January 2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Melzi, P., Tolosana, R., Vera-Rodriguez, R., Kim, M., Rathgeb, C., Liu, X., DeAndres-Tame, I., Morales, A., Fierrez, J., Ortega-Garcia, J., Zhao, W., Zhu, X., Yan, Z., Zhang, X.Y., Wu, J., Lei, Z., Tripathi, S., Kothari, M., Zama, M.H., Deb, D., Biesseck, B., Vidal, P., Granada, R., Fickel, G., Führ, G., Menotti, D., Unnervik, A., George, A., Ecabert, C., Shahreza, H.O., Rahimi, P., Marcel, S., Sarridis, I., Koutlis, C., Baltsou, G., Papadopoulos, S., Diou, C., Domenico, N.D., Borghi, G., Pellegrini, L., Mas-Candela, E., Ángela Sánchez-Pérez, Atzori, A., Boutros, F., Damer, N., Fenu, G., Marras, M.: Frcsyn-ongoing: Benchmarking and comprehensive evaluation of real and synthetic data to improve face recognition systems. Information Fusion <span class="ltx_text ltx_font_bold" id="bib.bib44.1.1">107</span>, 102322 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Moschoglou, S., Papaioannou, A., Sagonas, C., Deng, J., Kotsia, I., Zafeiriou, S.: Agedb: the first manually collected, in-the-wild age database. In: proceedings of the IEEE conference on computer vision and pattern recognition workshops. pp. 51–59 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Nichol, A.Q., Dhariwal, P.: Improved denoising diffusion probabilistic models. In: Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event. Proceedings of Machine Learning Research, vol. 139, pp. 8162–8171. PMLR (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Pereira, T., Marcel, S.: Fairness in biometrics: A figure of merit to assess biometric verification systems. IEEE Transactions on Biometrics, Behavior, and Identity Science <span class="ltx_text ltx_font_bold" id="bib.bib47.1.1">PP</span>,  1–1 (08 2021). https://doi.org/10.1109/TBIOM.2021.3102862

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Qiu, H., Yu, B., Gong, D., Li, Z., Liu, W., Tao, D.: Synface: Face recognition with synthetic data. In: 2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021. pp. 10860–10870. IEEE (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Rathgeb, C., Drozdowski, P., Frings, D.C., Damer, N., Busch, C.: Demographic fairness in biometric systems: What do the experts say? IEEE Technology and Society Magazine <span class="ltx_text ltx_font_bold" id="bib.bib49.1.1">41</span>(4), 71–82 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 10684–10695 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Sengupta, S., Chen, J.C., Castillo, C., Patel, V.M., Chellappa, R., Jacobs, D.W.: Frontal to profile face verification in the wild. In: 2016 IEEE winter conference on applications of computer vision (WACV). pp. 1–9. IEEE (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Serna, I., Peña, A., Morales, A., Fiérrez, J.: Insidebias: Measuring bias in deep networks and application to face gender biometrics. In: Proc. of ICPR 2020. pp. 3720–3727. IEEE (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Shahreza, H.O., Ecabert, C., George, A., Unnervik, A., Marcel, S., Di Domenico, N., Borghi, G., Maltoni, D., Boutros, F., Vogel, J., et al.: Sdfr: Synthetic data for face recognition competition. arXiv preprint arXiv:2404.04580 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Shoshan, A., Bhonker, N., Kviatkovsky, I., Medioni, G.: Gan-control: Explicitly controllable gans. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 14083–14093 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Shoshan, A., Bhonker, N., Kviatkovsky, I., Medioni, G.G.: Gan-control: Explicitly controllable gans. In: 2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021. pp. 14063–14073. IEEE (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Srinivas, N., Hivner, M., Gay, K., Atwal, H., King, M., Ricanek, K.: Exploring automatic face recognition on match performance and gender bias for children. In: Proc. of WACVW 2019. pp. 107–115 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Terhörst, P., Kolf, J.N., Damer, N., Kirchbuchner, F., Kuijper, A.: Post-comparison mitigation of demographic bias in face recognition using fair score normalization. Pattern Recognition Letters <span class="ltx_text ltx_font_bold" id="bib.bib57.1.1">140</span>, 332–338 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Vera-Rodriguez, R., Blazquez, M., Morales, A., Gonzalez-Sosa, E., Neves, J.C., Proença, H.: Facegenderid: Exploiting gender information in dcnns face recognition systems. In: Proc. of the IEEE/CVF Conf. on Computer Vision and Pat. Recog. Workshops (CVPRW 2019) (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Wang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., Li, Z., Liu, W.: Cosface: Large margin cosine loss for deep face recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 5265–5274 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Wang, M., Deng, W.: Mitigating bias in face recognition using skewness-aware reinforcement learning. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 9322–9331 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Wang, M., Deng, W., Hu, J., Tao, X., Huang, Y.: Racial faces in the wild: Reducing racial bias by information maximization adaptation network. In: Proceedings of the ieee/cvf international conference on computer vision. pp. 692–702 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Wang, M., Zhang, Y., Deng, W.: Meta balanced network for fair face recognition. IEEE Tran. on Pat. An. and Mach. Int. pp. 1–1 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Yi, D., Lei, Z., Liao, S., Li, S.Z.: Learning face representation from scratch. arXiv preprint arXiv:1411.7923 (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Yu, J., Hao, X., Xie, H., Yu, Y.: Fair face recognition using data balancing, enhancement and fusion. In: Proc. of ECCV 2020. pp. 492–505. Springer (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Zhang, K., Zhang, Z., Li, Z., Qiao, Y.: Joint face detection and alignment using multitask cascaded convolutional networks. IEEE signal processing letters <span class="ltx_text ltx_font_bold" id="bib.bib65.1.1">23</span>(10), 1499–1503 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Zheng, T., Deng, W., Hu, J.: Cross-age lfw: A database for studying cross-age face recognition in unconstrained environments. arXiv preprint arXiv:1708.08197 (2017)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep  4 16:46:41 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
