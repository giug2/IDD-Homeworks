<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation</title>
<!--Generated on Thu Sep 26 09:19:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.19523v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S1" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S2" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S3" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S3.SS1" title="In 3 Methodology â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Detecting Language-Pair-Relevant Layers</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S3.SS2" title="In 3 Methodology â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Evaluating the Language Awareness of Neurons</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S3.SS3" title="In 3 Methodology â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Routing and Finetuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS1" title="In 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS2" title="In 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Settings and Baselines</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS2.SSS0.Px1" title="In 4.2 Settings and Baselines â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title">Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS2.SSS0.Px2" title="In 4.2 Settings and Baselines â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS3" title="In 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS4" title="In 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS1" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>LANDeRMT Improves Transfer Learning across Languages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS2" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Language-Pair-Relevant Layers for Different Language Pairs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS3" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Neuron Awareness for Different Languages: General and Specific</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS4" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Neuron Awareness for Different Language Pairs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS5" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Results on Other LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS6" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span>Effect of Hyperparameter <math alttext="k" class="ltx_Math" display="inline"><semantics><mi>k</mi><annotation-xml encoding="MathML-Content"><ci>ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex">k</annotation><annotation encoding="application/x-llamapun">italic_k</annotation></semantics></math></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS7" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.7 </span>Effect of Hyperparameter <math alttext="\epsilon" class="ltx_Math" display="inline"><semantics><mi>Ïµ</mi><annotation-xml encoding="MathML-Content"><ci>italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex">\epsilon</annotation><annotation encoding="application/x-llamapun">italic_Ïµ</annotation></semantics></math></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.SS8" title="In 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.8 </span>Language Cluster</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S6" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#A1" title="In LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#A1.SS1" title="In Appendix A Appendix â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Language Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#A1.SS2" title="In Appendix A Appendix â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Taylor Expansion</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shaolin Zhu<sup class="ltx_sup" id="id1.1.id1">1</sup><span class="ltx_note ltx_role_footnote" id="footnotex1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Equal contribution.</span></span></span>, Leiyu Pan<sup class="ltx_sup" id="id2.2.id2">1</sup><span class="ltx_note ltx_role_footnote" id="footnotex2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Equal contribution.</span></span></span>, Bo Li<sup class="ltx_sup" id="id3.3.id3">2,3</sup>, Deyi Xiong<sup class="ltx_sup" id="id4.4.id4">1</sup><span class="ltx_note ltx_role_footnote" id="footnotex3"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Corresponding author.</span></span></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id5.5.id5">1</sup>College of Intelligence and Computing, Tianjin University, Tianjin, China
<br class="ltx_break"/><sup class="ltx_sup" id="id6.6.id6">2</sup>School of Software, Tsinghua University, Beijing, China
<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">3</sup>Baidu APP Technology and Platform R&amp;D Department, Baidu Inc, Beijing, China
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id8.8.id8">{zhushaolin, lypan, dyxiong}@tju.edu.cn
<br class="ltx_break"/>{li-b19}@mails.tsinghua.edu.cn</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id9.id1">Recent advancements in large language models (LLMs) have shown promising results in multilingual translation even with limited bilingual supervision.
The major challenges are catastrophic forgetting and parameter interference<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Regarding catastrophic forgetting and parameter interference, we are specifically addressing issues between languages rather than those between machine translation tasks and other tasks in this paper.</span></span></span> for finetuning LLMs when provided parallel training data.
To address these challenges, we propose LANDeRMT, a <span class="ltx_text ltx_font_bold" id="id9.id1.1">L</span>anguage-<span class="ltx_text ltx_font_bold" id="id9.id1.2">A</span>ware <span class="ltx_text ltx_font_bold" id="id9.id1.3">N</span>euron <span class="ltx_text ltx_font_bold" id="id9.id1.4">De</span>tecting and <span class="ltx_text ltx_font_bold" id="id9.id1.5">R</span>outing framework that selectively finetunes LLMs to <span class="ltx_text ltx_font_bold" id="id9.id1.6">M</span>achine <span class="ltx_text ltx_font_bold" id="id9.id1.7">T</span>ranslation with diverse translation training data.
In LANDeRMT, we evaluate the awareness of neurons to MT tasks and categorize them into language-general and language-specific neurons.
This categorization enables selective parameter updates during finetuning, mitigating parameter interference and catastrophic forgetting issues.
For the detected neurons, we further propose a conditional awareness-based routing mechanism to dynamically adjust language-general and language-specific capacity within LLMs, guided by translation signals.
Experimental results demonstrate that the proposed LANDeRMT is very effective in learning translation knowledge, significantly improving translation quality over various strong baselines for multiple language pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Shaolin Zhu<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">1</sup><span class="ltx_note ltx_role_footnote" id="footnotex4"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex4.1.1.1">2</span></span>Equal contribution.</span></span></span>, Leiyu Pan<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2">1</sup><span class="ltx_note ltx_role_footnote" id="footnotex5"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex5.1.1.1">2</span></span>Equal contribution.</span></span></span>, Bo Li<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3">2,3</sup>, Deyi Xiong<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.4">1</sup><span class="ltx_note ltx_role_footnote" id="footnotex6"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex6.1.1.1">1</span></span>Corresponding author.</span></span></span></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1">1</sup>College of Intelligence and Computing, Tianjin University, Tianjin, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1">2</sup>School of Software, Tsinghua University, Beijing, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1"><sup class="ltx_sup" id="p1.1.2.1.1.4.4.1.1">3</sup>Baidu APP Technology and Platform R&amp;D Department, Baidu Inc, Beijing, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.5.5">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.5.5.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.5.5.1.1">{zhushaolin, lypan, dyxiong}@tju.edu.cn</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.6.6">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.6.6.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.6.6.1.1">{li-b19}@mails.tsinghua.edu.cn</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Conventional neural machine translation (NMT) usually requires a huge amount of parallel training data <cite class="ltx_cite ltx_citemacro_cite">Costa-jussÃ  etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib7" title="">2022</a>); Fedus etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib9" title="">2022</a>); Zhu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib42" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib41" title="">2024b</a>)</cite>.
In contrast, multilingual LLMs, e.g., BLOOM <cite class="ltx_cite ltx_citemacro_cite">Scao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib27" title="">2022</a>)</cite>, LLaMA2 <cite class="ltx_cite ltx_citemacro_cite">Touvron etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib30" title="">2023</a>)</cite>, in spite of being trained with mainly monolingual data, require only a few examples to demonstrate remarkable prowess in multilingual translation via in-context learning (ICL) <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib14" title="">2023</a>); Lyu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib23" title="">2023</a>)</cite>.
However, such LLM-based MT exhibits a major drawback that the quality of yielded translations is highly sensitive to the provided examples in ICL <cite class="ltx_cite ltx_citemacro_cite">Vilar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib31" title="">2023</a>)</cite> and outputs might suffer from overgeneration <cite class="ltx_cite ltx_citemacro_cite">Bawden and Yvon (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib3" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To address these issues, existing studies attempt to use various finetuning methods, such as adapter-based method <cite class="ltx_cite ltx_citemacro_cite">Alves etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib1" title="">2023</a>)</cite>, instruction-based tuning method <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib18" title="">2023a</a>)</cite>.
However, these approaches primarily focus on balancing between the original LLMs and new finetuning translation data
They use only incremental data to acquire new knowledge without considering catastrophic forgetting of knowledge originally captured by LLMs <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib20" title="">2021</a>); Shao and Feng (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib28" title="">2022</a>); Huang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib16" title="">2023</a>)</cite>.
Many studies have shown that catastrophic forgetting indeed exists across languages as LLMs are fine-tuned on one language pair and then used to translate another language on which LLMs are not fine-tuned <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib19" title="">2023b</a>); Zhu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib40" title="">2024a</a>)</cite>.
Additionally, as LLMs are usually generally developed for multiple tasks (i.e., sharing parameters across different tasks), finetuning LLMs for MT task may cause parameter interference for other tasks <cite class="ltx_cite ltx_citemacro_cite">Luo etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib22" title="">2023</a>)</cite>.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS3" title="4.3 Main Results â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we find that full-parameter finetuning of LLMs cannot always improve translation quality on all language pairs.
Therefore, is it possible to design a new finetuning method for LLMs, which can mitigate the issues of catastrophic forgetting and parameter interference during the finetuning process of LLMs to multilingual machine translation?
</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In multilingual NMT, previous efforts evaluate the importance of model neurons to each
language pair and only tune language-specific neurons for the current language pair during training <cite class="ltx_cite ltx_citemacro_cite">Xie etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib35" title="">2021</a>)</cite>.
Recent studies on LLM unveils that many neurons in the feed-forward networks (FFN) are only activated for specific tasks and become â€œdeadâ€ for irrelevant tasks <cite class="ltx_cite ltx_citemacro_cite">Voita etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib32" title="">2023</a>); Conmy etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib6" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Inspired by these studies, we propose LANDeRMT, a language-aware neuron detecting and routing framework for selectively finetuning LLMs to MT, which aims to mitigate the issues of catastrophic forgetting and parameter interference.
First, we evaluate the MT awareness of each neuron in FFNs.
For neurons that are related to multilingual MT tasks, we further evaluate the relevance of each neuron to each language pair.
According to their MT/language â€œawareness/relevanceâ€, we divide neurons into the unactivated neurons, language-general neurons and language-specific neurons.
After that, we finetune LLMs on multilingual parallel training data.
During finetuning, only the parameters of language-general neurons and language-specific neurons for the current language pair are tuned.
This selective finetuning process can alleviate the parameter interference issue.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">As language-general and language-specific capacity matters for MT <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib37" title="">2021</a>); Koishekenov etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib17" title="">2023</a>)</cite>, we propose a conditional awareness routing mechanism to dynamically schedule language-general and language-specific capacity across sub-layers in LLMs under the guidance of translation signals.
In doing so, we can alleviate the catastrophic forgetting issue and facilitate LLMs to be adapted to MT.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The main contributions of this work are summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p7">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose LANDeRMT that aims at mitigating the catastrophic forgetting and parameter interference issues for efficiently finetuning LLMs to MT.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">To well schedule language-general and language-specific capacity across sub-layers in LLMs, we propose a conditional awareness-based routing mechanism.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Experiments on ten language pairs show that our model achieves the state-of-the-art results compared to previous strong baselines and demonstrate the robustness of the proposed model in various settings.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">LLMs, with a few examples provided via in-context learning, have demonstrated impressive capabilities in machine translation without requiring explicit supervision from parallel training data <cite class="ltx_cite ltx_citemacro_cite">Moslem etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib24" title="">2023</a>); Ghazvininejad etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib11" title="">2023</a>); Sia and Duh (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib29" title="">2023</a>); Han etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib13" title="">2022</a>)</cite>.
However, LLMs with ICL for MT suffer from the sensitiveness to the provided examples <cite class="ltx_cite ltx_citemacro_cite">Vilar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib31" title="">2023</a>)</cite> and yielded translations might be overgenerated <cite class="ltx_cite ltx_citemacro_cite">Bawden and Yvon (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib3" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Another line of research on LLMs, known as domain-adaptive pretraining, focuses
on finetuning LLMs to downstream tasks <cite class="ltx_cite ltx_citemacro_cite">Cheng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib5" title="">2023</a>); Dong etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib8" title="">2023</a>)</cite>.
Although these approaches have demonstrated efficacy in adapting various LLMs and result in enhanced performance on downstream tasks <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib34" title="">2023</a>); Gupta etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib12" title="">2023</a>); Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib33" title="">2024</a>); Zhu and Xiong (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib43" title="">2023</a>)</cite>, they rarely apply to multilingual generation tasks, e.g., multilingual MT.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In order to efficiently adapt LLMs to MT, recent years have witnessed efforts on finetuning LLMs for MT <cite class="ltx_cite ltx_citemacro_cite">Vilar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib31" title="">2023</a>); Alves etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib1" title="">2023</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Alves etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib1" title="">2023</a>)</cite> show that adapter-based finetuning with LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib15" title="">2022</a>)</cite> matches the performance of traditional finetuning while reducing the number of training parameters by a factor of 50.
<cite class="ltx_cite ltx_citemacro_citet">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib18" title="">2023a</a>)</cite> investigate the multilingual generalization when finetuning LLMs.
However, they do not explicitly overcome catastrophic forgetting and parameter interference issues.
To address these issues, our work starts with analyzing the neurons within the model, and finetunes LLMs by distinguishing neurons.</p>
</div>
<figure class="ltx_figure" id="S2.F1">
<p class="ltx_p ltx_align_center ltx_align_center" id="S2.F1.1"><span class="ltx_text" id="S2.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="334" id="S2.F1.1.1.g1" src="x1.png" width="512"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of the proposed LANDeRMT.
</figcaption>
</figure>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Research interests in understanding the inner workings of LLMs and NMT models have been growing recently <cite class="ltx_cite ltx_citemacro_cite">RÃ¤uker etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib26" title="">2022</a>); Bills etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib4" title="">2023</a>); Garde etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib10" title="">2023</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Voita etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib32" title="">2023</a>)</cite> focus on neurons inside FFNs and find that the network is sparse and represents many discrete features in LLMs.
They find many of the alive neurons are reserved for discrete features and act as token and n-gram detectors for different languages.
In addition, previous NMT efforts evaluate the importance of NMT neurons in each
language pair and only finetune language-specific neurons for the current language pair participate in training for conventional multilingual NMT <cite class="ltx_cite ltx_citemacro_cite">Xie etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib35" title="">2021</a>); Patel etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib25" title="">2022</a>)</cite>.
Partially motivated by these studies, we propose a language-aware neuron detecting and routing framework for selectively finetuning LLMs to MT.
In our method, we use awareness-based evaluation of neurons in LLMs and divide the neurons into language-general and language-specific neurons.
We only update the parameters of language-general neurons and the corresponding language-specific neurons for the current language pair during training to overcome catastrophic forgetting and parameter interference to enhance the multilingual translation ability of LLMs.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The proposed LANDeRMT is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S2.F1" title="Figure 1 â€£ 2 Related Work â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.
We first propose a method to analyse which FFN layers of LLMs have strong relevance to source-target language pair.
This allows us to exclusively concentrate on layers that are related to the MT task, hence reducing the distraction from unrelated parameters.
Then, we employ Taylor Expansion (TE) <cite class="ltx_cite ltx_citemacro_cite">Xie etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib35" title="">2021</a>)</cite> to evaluate the strength of awareness (relevance) of neurons at those layers to the given language pairs of the MT task.
Finally, we only route and finetune the detected language-aware neurons for the MT task.
This can ensure that we only need to update a small number of relevant parameters of LLMs for MT.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Detecting Language-Pair-Relevant Layers</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.3">We introduce a representation analysis (RA) method to detect language-pair-relevant layers, which is based on the difference in activations between FFN layers.
RA aims to measure the changes in the response of each FFN layer to the input source sentence during the LLM forward propagation process that â€œtranslatesâ€ the source sentence into the target sentence, so as to identify FFN alignment layers that are highly â€œactivatedâ€ for the source-target language pair.
For each consecutive pair of layers <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_i</annotation></semantics></math> and <math alttext="i+1" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">i</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">+</mo><mn id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><plus id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></plus><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘–</ci><cn id="S3.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">i+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_i + 1</annotation></semantics></math> within the LLM, we compute the activation difference <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_D</annotation></semantics></math>, to estimate the degree of change in information representation between these two layers.
The estimation is computed as follows:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="D_{i}=\left|\frac{1}{N}\sum_{n=1}^{N}\textbf{A}_{i,n}-\frac{1}{N}\sum_{n=1}^{N%
}\textbf{A}_{i+1,n}\right|" class="ltx_Math" display="block" id="S3.E1.m1.5"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml"><msub id="S3.E1.m1.5.5.3" xref="S3.E1.m1.5.5.3.cmml"><mi id="S3.E1.m1.5.5.3.2" xref="S3.E1.m1.5.5.3.2.cmml">D</mi><mi id="S3.E1.m1.5.5.3.3" xref="S3.E1.m1.5.5.3.3.cmml">i</mi></msub><mo id="S3.E1.m1.5.5.2" xref="S3.E1.m1.5.5.2.cmml">=</mo><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.2.cmml"><mo id="S3.E1.m1.5.5.1.1.2" xref="S3.E1.m1.5.5.1.2.1.cmml">|</mo><mrow id="S3.E1.m1.5.5.1.1.1" xref="S3.E1.m1.5.5.1.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.2.cmml"><mfrac id="S3.E1.m1.5.5.1.1.1.2.2" xref="S3.E1.m1.5.5.1.1.1.2.2.cmml"><mn id="S3.E1.m1.5.5.1.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.1.2.2.2.cmml">1</mn><mi id="S3.E1.m1.5.5.1.1.1.2.2.3" xref="S3.E1.m1.5.5.1.1.1.2.2.3.cmml">N</mi></mfrac><mo id="S3.E1.m1.5.5.1.1.1.2.1" xref="S3.E1.m1.5.5.1.1.1.2.1.cmml">â¢</mo><mrow id="S3.E1.m1.5.5.1.1.1.2.3" xref="S3.E1.m1.5.5.1.1.1.2.3.cmml"><munderover id="S3.E1.m1.5.5.1.1.1.2.3.1" xref="S3.E1.m1.5.5.1.1.1.2.3.1.cmml"><mo id="S3.E1.m1.5.5.1.1.1.2.3.1.2.2" movablelimits="false" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.2" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.2.cmml">n</mi><mo id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.1" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.3" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.5.5.1.1.1.2.3.1.3" xref="S3.E1.m1.5.5.1.1.1.2.3.1.3.cmml">N</mi></munderover><msub id="S3.E1.m1.5.5.1.1.1.2.3.2" xref="S3.E1.m1.5.5.1.1.1.2.3.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.5.5.1.1.1.2.3.2.2" xref="S3.E1.m1.5.5.1.1.1.2.3.2.2a.cmml">A</mtext><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">i</mi><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">n</mi></mrow></msub></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.cmml">âˆ’</mo><mrow id="S3.E1.m1.5.5.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.3.cmml"><mfrac id="S3.E1.m1.5.5.1.1.1.3.2" xref="S3.E1.m1.5.5.1.1.1.3.2.cmml"><mn id="S3.E1.m1.5.5.1.1.1.3.2.2" xref="S3.E1.m1.5.5.1.1.1.3.2.2.cmml">1</mn><mi id="S3.E1.m1.5.5.1.1.1.3.2.3" xref="S3.E1.m1.5.5.1.1.1.3.2.3.cmml">N</mi></mfrac><mo id="S3.E1.m1.5.5.1.1.1.3.1" xref="S3.E1.m1.5.5.1.1.1.3.1.cmml">â¢</mo><mrow id="S3.E1.m1.5.5.1.1.1.3.3" xref="S3.E1.m1.5.5.1.1.1.3.3.cmml"><munderover id="S3.E1.m1.5.5.1.1.1.3.3.1" xref="S3.E1.m1.5.5.1.1.1.3.3.1.cmml"><mo id="S3.E1.m1.5.5.1.1.1.3.3.1.2.2" movablelimits="false" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.2" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.2.cmml">n</mi><mo id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.1" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.3" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.5.5.1.1.1.3.3.1.3" xref="S3.E1.m1.5.5.1.1.1.3.3.1.3.cmml">N</mi></munderover><msub id="S3.E1.m1.5.5.1.1.1.3.3.2" xref="S3.E1.m1.5.5.1.1.1.3.3.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.5.5.1.1.1.3.3.2.2" xref="S3.E1.m1.5.5.1.1.1.3.3.2.2a.cmml">A</mtext><mrow id="S3.E1.m1.4.4.2.2" xref="S3.E1.m1.4.4.2.3.cmml"><mrow id="S3.E1.m1.4.4.2.2.1" xref="S3.E1.m1.4.4.2.2.1.cmml"><mi id="S3.E1.m1.4.4.2.2.1.2" xref="S3.E1.m1.4.4.2.2.1.2.cmml">i</mi><mo id="S3.E1.m1.4.4.2.2.1.1" xref="S3.E1.m1.4.4.2.2.1.1.cmml">+</mo><mn id="S3.E1.m1.4.4.2.2.1.3" xref="S3.E1.m1.4.4.2.2.1.3.cmml">1</mn></mrow><mo id="S3.E1.m1.4.4.2.2.2" xref="S3.E1.m1.4.4.2.3.cmml">,</mo><mi id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml">n</mi></mrow></msub></mrow></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5"><eq id="S3.E1.m1.5.5.2.cmml" xref="S3.E1.m1.5.5.2"></eq><apply id="S3.E1.m1.5.5.3.cmml" xref="S3.E1.m1.5.5.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.3.1.cmml" xref="S3.E1.m1.5.5.3">subscript</csymbol><ci id="S3.E1.m1.5.5.3.2.cmml" xref="S3.E1.m1.5.5.3.2">ğ·</ci><ci id="S3.E1.m1.5.5.3.3.cmml" xref="S3.E1.m1.5.5.3.3">ğ‘–</ci></apply><apply id="S3.E1.m1.5.5.1.2.cmml" xref="S3.E1.m1.5.5.1.1"><abs id="S3.E1.m1.5.5.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2"></abs><apply id="S3.E1.m1.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1"><minus id="S3.E1.m1.5.5.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1"></minus><apply id="S3.E1.m1.5.5.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2"><times id="S3.E1.m1.5.5.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.1"></times><apply id="S3.E1.m1.5.5.1.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2.2"><divide id="S3.E1.m1.5.5.1.1.1.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.2"></divide><cn id="S3.E1.m1.5.5.1.1.1.2.2.2.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.1.2.2.2">1</cn><ci id="S3.E1.m1.5.5.1.1.1.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.1.2.2.3">ğ‘</ci></apply><apply id="S3.E1.m1.5.5.1.1.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3"><apply id="S3.E1.m1.5.5.1.1.1.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.2.3.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1">superscript</csymbol><apply id="S3.E1.m1.5.5.1.1.1.2.3.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.2.3.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1">subscript</csymbol><sum id="S3.E1.m1.5.5.1.1.1.2.3.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.2"></sum><apply id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3"><eq id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.1"></eq><ci id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.2">ğ‘›</ci><cn id="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.1.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.5.5.1.1.1.2.3.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.1.3">ğ‘</ci></apply><apply id="S3.E1.m1.5.5.1.1.1.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.2.3.2.2a.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.5.5.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2.3.2.2">A</mtext></ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğ‘–</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">ğ‘›</ci></list></apply></apply></apply><apply id="S3.E1.m1.5.5.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3"><times id="S3.E1.m1.5.5.1.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.1"></times><apply id="S3.E1.m1.5.5.1.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.2"><divide id="S3.E1.m1.5.5.1.1.1.3.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.2"></divide><cn id="S3.E1.m1.5.5.1.1.1.3.2.2.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.1.3.2.2">1</cn><ci id="S3.E1.m1.5.5.1.1.1.3.2.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3.2.3">ğ‘</ci></apply><apply id="S3.E1.m1.5.5.1.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3"><apply id="S3.E1.m1.5.5.1.1.1.3.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.3.3.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1">superscript</csymbol><apply id="S3.E1.m1.5.5.1.1.1.3.3.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.3.3.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1">subscript</csymbol><sum id="S3.E1.m1.5.5.1.1.1.3.3.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.2"></sum><apply id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3"><eq id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.1"></eq><ci id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.2">ğ‘›</ci><cn id="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.5.5.1.1.1.3.3.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.1.3">ğ‘</ci></apply><apply id="S3.E1.m1.5.5.1.1.1.3.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.3.3.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.3.3.2.2a.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.5.5.1.1.1.3.3.2.2.cmml" xref="S3.E1.m1.5.5.1.1.1.3.3.2.2">A</mtext></ci><list id="S3.E1.m1.4.4.2.3.cmml" xref="S3.E1.m1.4.4.2.2"><apply id="S3.E1.m1.4.4.2.2.1.cmml" xref="S3.E1.m1.4.4.2.2.1"><plus id="S3.E1.m1.4.4.2.2.1.1.cmml" xref="S3.E1.m1.4.4.2.2.1.1"></plus><ci id="S3.E1.m1.4.4.2.2.1.2.cmml" xref="S3.E1.m1.4.4.2.2.1.2">ğ‘–</ci><cn id="S3.E1.m1.4.4.2.2.1.3.cmml" type="integer" xref="S3.E1.m1.4.4.2.2.1.3">1</cn></apply><ci id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1">ğ‘›</ci></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">D_{i}=\left|\frac{1}{N}\sum_{n=1}^{N}\textbf{A}_{i,n}-\frac{1}{N}\sum_{n=1}^{N%
}\textbf{A}_{i+1,n}\right|</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.5d">italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = | divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT A start_POSTSUBSCRIPT italic_i , italic_n end_POSTSUBSCRIPT - divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT A start_POSTSUBSCRIPT italic_i + 1 , italic_n end_POSTSUBSCRIPT |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.9">where <math alttext="\textbf{A}_{i,n}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.2"><semantics id="S3.SS1.p2.1.m1.2a"><msub id="S3.SS1.p2.1.m1.2.3" xref="S3.SS1.p2.1.m1.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p2.1.m1.2.3.2" xref="S3.SS1.p2.1.m1.2.3.2a.cmml">A</mtext><mrow id="S3.SS1.p2.1.m1.2.2.2.4" xref="S3.SS1.p2.1.m1.2.2.2.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p2.1.m1.2.2.2.4.1" xref="S3.SS1.p2.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS1.p2.1.m1.2.2.2.2" xref="S3.SS1.p2.1.m1.2.2.2.2.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.2b"><apply id="S3.SS1.p2.1.m1.2.3.cmml" xref="S3.SS1.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.3.1.cmml" xref="S3.SS1.p2.1.m1.2.3">subscript</csymbol><ci id="S3.SS1.p2.1.m1.2.3.2a.cmml" xref="S3.SS1.p2.1.m1.2.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p2.1.m1.2.3.2.cmml" xref="S3.SS1.p2.1.m1.2.3.2">A</mtext></ci><list id="S3.SS1.p2.1.m1.2.2.2.3.cmml" xref="S3.SS1.p2.1.m1.2.2.2.4"><ci id="S3.SS1.p2.1.m1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.p2.1.m1.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2">ğ‘›</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.2c">\textbf{A}_{i,n}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.2d">A start_POSTSUBSCRIPT italic_i , italic_n end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\textbf{A}_{i+1,n}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.2"><semantics id="S3.SS1.p2.2.m2.2a"><msub id="S3.SS1.p2.2.m2.2.3" xref="S3.SS1.p2.2.m2.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p2.2.m2.2.3.2" xref="S3.SS1.p2.2.m2.2.3.2a.cmml">A</mtext><mrow id="S3.SS1.p2.2.m2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.3.cmml"><mrow id="S3.SS1.p2.2.m2.2.2.2.2.1" xref="S3.SS1.p2.2.m2.2.2.2.2.1.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.2.1.2" xref="S3.SS1.p2.2.m2.2.2.2.2.1.2.cmml">i</mi><mo id="S3.SS1.p2.2.m2.2.2.2.2.1.1" xref="S3.SS1.p2.2.m2.2.2.2.2.1.1.cmml">+</mo><mn id="S3.SS1.p2.2.m2.2.2.2.2.1.3" xref="S3.SS1.p2.2.m2.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p2.2.m2.2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS1.p2.2.m2.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><apply id="S3.SS1.p2.2.m2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.3.1.cmml" xref="S3.SS1.p2.2.m2.2.3">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.3.2a.cmml" xref="S3.SS1.p2.2.m2.2.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p2.2.m2.2.3.2.cmml" xref="S3.SS1.p2.2.m2.2.3.2">A</mtext></ci><list id="S3.SS1.p2.2.m2.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2"><apply id="S3.SS1.p2.2.m2.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.1"><plus id="S3.SS1.p2.2.m2.2.2.2.2.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.1.1"></plus><ci id="S3.SS1.p2.2.m2.2.2.2.2.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.1.2">ğ‘–</ci><cn id="S3.SS1.p2.2.m2.2.2.2.2.1.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.2.2.2.2.1.3">1</cn></apply><ci id="S3.SS1.p2.2.m2.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1">ğ‘›</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">\textbf{A}_{i+1,n}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.2d">A start_POSTSUBSCRIPT italic_i + 1 , italic_n end_POSTSUBSCRIPT</annotation></semantics></math> represent the activation values at the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_i</annotation></semantics></math>-th and <math alttext="i+1" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">i</mi><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">+</mo><mn id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><plus id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></plus><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">ğ‘–</ci><cn id="S3.SS1.p2.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">i+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_i + 1</annotation></semantics></math>-th layers during the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_n</annotation></semantics></math>-th forward propagation, and <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_N</annotation></semantics></math> is the total number of forward propagations.
In this manner, <math alttext="D_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1"><semantics id="S3.SS1.p2.7.m7.1a"><msub id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">D</mi><mi id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">ğ·</ci><ci id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">D_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m7.1d">italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> captures the extent of change in activation values between adjacent layers along the depth of the model when the input source language is translated into the target language.
The most significant changes in layer representations indicate the most critical layers that are related to the source-target language pair.
Therefore, our layer selection criterion focuses on identifying those layers with the top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m8.1"><semantics id="S3.SS1.p2.8.m8.1a"><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m8.1d">italic_k</annotation></semantics></math> <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m9.1"><semantics id="S3.SS1.p2.9.m9.1a"><mi id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><ci id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m9.1d">italic_D</annotation></semantics></math> values as follows:</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{\text{LPR}}=\arg\max_{top_{k}}\{D_{1},D_{2},...,D_{k}\}" class="ltx_Math" display="block" id="S3.E2.m1.5"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml"><msub id="S3.E2.m1.5.5.6" xref="S3.E2.m1.5.5.6.cmml"><mi id="S3.E2.m1.5.5.6.2" xref="S3.E2.m1.5.5.6.2.cmml">L</mi><mtext id="S3.E2.m1.5.5.6.3" xref="S3.E2.m1.5.5.6.3a.cmml">LPR</mtext></msub><mo id="S3.E2.m1.5.5.5" xref="S3.E2.m1.5.5.5.cmml">=</mo><mrow id="S3.E2.m1.5.5.4" xref="S3.E2.m1.5.5.4.cmml"><mi id="S3.E2.m1.5.5.4.5" xref="S3.E2.m1.5.5.4.5.cmml">arg</mi><mo id="S3.E2.m1.5.5.4a" lspace="0.167em" xref="S3.E2.m1.5.5.4.cmml">â¡</mo><mrow id="S3.E2.m1.5.5.4.4.4" xref="S3.E2.m1.5.5.4.4.5.cmml"><munder id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">max</mi><mrow id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E2.m1.2.2.1.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.1.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.1.3.3.cmml">o</mi><mo id="S3.E2.m1.2.2.1.1.1.1.3.1a" xref="S3.E2.m1.2.2.1.1.1.1.3.1.cmml">â¢</mo><msub id="S3.E2.m1.2.2.1.1.1.1.3.4" xref="S3.E2.m1.2.2.1.1.1.1.3.4.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.4.2" xref="S3.E2.m1.2.2.1.1.1.1.3.4.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.1.1.3.4.3" xref="S3.E2.m1.2.2.1.1.1.1.3.4.3.cmml">k</mi></msub></mrow></munder><mo id="S3.E2.m1.5.5.4.4.4a" xref="S3.E2.m1.5.5.4.4.5.cmml">â¡</mo><mrow id="S3.E2.m1.5.5.4.4.4.4" xref="S3.E2.m1.5.5.4.4.5.cmml"><mo id="S3.E2.m1.5.5.4.4.4.4.4" stretchy="false" xref="S3.E2.m1.5.5.4.4.5.cmml">{</mo><msub id="S3.E2.m1.3.3.2.2.2.2.1" xref="S3.E2.m1.3.3.2.2.2.2.1.cmml"><mi id="S3.E2.m1.3.3.2.2.2.2.1.2" xref="S3.E2.m1.3.3.2.2.2.2.1.2.cmml">D</mi><mn id="S3.E2.m1.3.3.2.2.2.2.1.3" xref="S3.E2.m1.3.3.2.2.2.2.1.3.cmml">1</mn></msub><mo id="S3.E2.m1.5.5.4.4.4.4.5" xref="S3.E2.m1.5.5.4.4.5.cmml">,</mo><msub id="S3.E2.m1.4.4.3.3.3.3.2" xref="S3.E2.m1.4.4.3.3.3.3.2.cmml"><mi id="S3.E2.m1.4.4.3.3.3.3.2.2" xref="S3.E2.m1.4.4.3.3.3.3.2.2.cmml">D</mi><mn id="S3.E2.m1.4.4.3.3.3.3.2.3" xref="S3.E2.m1.4.4.3.3.3.3.2.3.cmml">2</mn></msub><mo id="S3.E2.m1.5.5.4.4.4.4.6" xref="S3.E2.m1.5.5.4.4.5.cmml">,</mo><mi id="S3.E2.m1.1.1" mathvariant="normal" xref="S3.E2.m1.1.1.cmml">â€¦</mi><mo id="S3.E2.m1.5.5.4.4.4.4.7" xref="S3.E2.m1.5.5.4.4.5.cmml">,</mo><msub id="S3.E2.m1.5.5.4.4.4.4.3" xref="S3.E2.m1.5.5.4.4.4.4.3.cmml"><mi id="S3.E2.m1.5.5.4.4.4.4.3.2" xref="S3.E2.m1.5.5.4.4.4.4.3.2.cmml">D</mi><mi id="S3.E2.m1.5.5.4.4.4.4.3.3" xref="S3.E2.m1.5.5.4.4.4.4.3.3.cmml">k</mi></msub><mo id="S3.E2.m1.5.5.4.4.4.4.8" stretchy="false" xref="S3.E2.m1.5.5.4.4.5.cmml">}</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5"><eq id="S3.E2.m1.5.5.5.cmml" xref="S3.E2.m1.5.5.5"></eq><apply id="S3.E2.m1.5.5.6.cmml" xref="S3.E2.m1.5.5.6"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.6.1.cmml" xref="S3.E2.m1.5.5.6">subscript</csymbol><ci id="S3.E2.m1.5.5.6.2.cmml" xref="S3.E2.m1.5.5.6.2">ğ¿</ci><ci id="S3.E2.m1.5.5.6.3a.cmml" xref="S3.E2.m1.5.5.6.3"><mtext id="S3.E2.m1.5.5.6.3.cmml" mathsize="70%" xref="S3.E2.m1.5.5.6.3">LPR</mtext></ci></apply><apply id="S3.E2.m1.5.5.4.cmml" xref="S3.E2.m1.5.5.4"><arg id="S3.E2.m1.5.5.4.5.cmml" xref="S3.E2.m1.5.5.4.5"></arg><apply id="S3.E2.m1.5.5.4.4.5.cmml" xref="S3.E2.m1.5.5.4.4.4"><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1">subscript</csymbol><max id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2"></max><apply id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3"><times id="S3.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1"></times><ci id="S3.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2">ğ‘¡</ci><ci id="S3.E2.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.3">ğ‘œ</ci><apply id="S3.E2.m1.2.2.1.1.1.1.3.4.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.3.4.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.3.4.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.4.2">ğ‘</ci><ci id="S3.E2.m1.2.2.1.1.1.1.3.4.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.4.3">ğ‘˜</ci></apply></apply></apply><apply id="S3.E2.m1.3.3.2.2.2.2.1.cmml" xref="S3.E2.m1.3.3.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.2.2.2.2.1.1.cmml" xref="S3.E2.m1.3.3.2.2.2.2.1">subscript</csymbol><ci id="S3.E2.m1.3.3.2.2.2.2.1.2.cmml" xref="S3.E2.m1.3.3.2.2.2.2.1.2">ğ·</ci><cn id="S3.E2.m1.3.3.2.2.2.2.1.3.cmml" type="integer" xref="S3.E2.m1.3.3.2.2.2.2.1.3">1</cn></apply><apply id="S3.E2.m1.4.4.3.3.3.3.2.cmml" xref="S3.E2.m1.4.4.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.3.3.3.2.1.cmml" xref="S3.E2.m1.4.4.3.3.3.3.2">subscript</csymbol><ci id="S3.E2.m1.4.4.3.3.3.3.2.2.cmml" xref="S3.E2.m1.4.4.3.3.3.3.2.2">ğ·</ci><cn id="S3.E2.m1.4.4.3.3.3.3.2.3.cmml" type="integer" xref="S3.E2.m1.4.4.3.3.3.3.2.3">2</cn></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">â€¦</ci><apply id="S3.E2.m1.5.5.4.4.4.4.3.cmml" xref="S3.E2.m1.5.5.4.4.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.4.4.4.4.3.1.cmml" xref="S3.E2.m1.5.5.4.4.4.4.3">subscript</csymbol><ci id="S3.E2.m1.5.5.4.4.4.4.3.2.cmml" xref="S3.E2.m1.5.5.4.4.4.4.3.2">ğ·</ci><ci id="S3.E2.m1.5.5.4.4.4.4.3.3.cmml" xref="S3.E2.m1.5.5.4.4.4.4.3.3">ğ‘˜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">L_{\text{LPR}}=\arg\max_{top_{k}}\{D_{1},D_{2},...,D_{k}\}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.5d">italic_L start_POSTSUBSCRIPT LPR end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_t italic_o italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT { italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p3.1">where <math alttext="L_{\text{LPR}}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">L</mi><mtext id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3a.cmml">LPR</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ğ¿</ci><ci id="S3.SS1.p3.1.m1.1.1.3a.cmml" xref="S3.SS1.p3.1.m1.1.1.3"><mtext id="S3.SS1.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p3.1.m1.1.1.3">LPR</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">L_{\text{LPR}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_L start_POSTSUBSCRIPT LPR end_POSTSUBSCRIPT</annotation></semantics></math> denotes the optimal language-pair-relevant layers.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluating the Language Awareness of Neurons</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Once we find the language-pair-relevant layer, do we need to finetune all neurons of the layer for the corresponding language pair?
Our experiments show that this all-neuron-finetuning strategy is not as expected (see Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.SS4" title="4.4 Ablation Study â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">4.4</span></a>).
The main reasons are two fold.
First, if all parameters of the detected FFNs are updated for all language pairs, catastrophic forgetting problem still remains <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib20" title="">2021</a>)</cite>.
Second, there is no effective mechanism to overcome the parameter interference issue to preserve the language-general and the language-specific knowledge.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Partially inspired by the studies on the importance-based neuron finetuning for NMT <cite class="ltx_cite ltx_citemacro_cite">Xie etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib35" title="">2021</a>)</cite> and neuron interpretability in LLMs <cite class="ltx_cite ltx_citemacro_cite">Voita etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib32" title="">2023</a>)</cite>, we propose to use the TE to evaluate which neurons are essential to all languages and which neurons are responsible for specific languages.
We first define the awareness score <math alttext="\Phi(i)" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.2" xref="S3.SS2.p2.1.m1.1.2.cmml"><mi id="S3.SS2.p2.1.m1.1.2.2" mathvariant="normal" xref="S3.SS2.p2.1.m1.1.2.2.cmml">Î¦</mi><mo id="S3.SS2.p2.1.m1.1.2.1" xref="S3.SS2.p2.1.m1.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.p2.1.m1.1.2.3.2" xref="S3.SS2.p2.1.m1.1.2.cmml"><mo id="S3.SS2.p2.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS2.p2.1.m1.1.2.cmml">(</mo><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">i</mi><mo id="S3.SS2.p2.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS2.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.2"><times id="S3.SS2.p2.1.m1.1.2.1.cmml" xref="S3.SS2.p2.1.m1.1.2.1"></times><ci id="S3.SS2.p2.1.m1.1.2.2.cmml" xref="S3.SS2.p2.1.m1.1.2.2">Î¦</ci><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\Phi(i)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">roman_Î¦ ( italic_i )</annotation></semantics></math> of a neuron to a certain language:</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\Phi(i)=\left|\Delta\mathcal{L}(\textbf{h}_{i})\right|,i\in{L_{j}}" class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.3.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.3.2" mathvariant="normal" xref="S3.E3.m1.2.2.1.1.3.2.cmml">Î¦</mi><mo id="S3.E3.m1.2.2.1.1.3.1" xref="S3.E3.m1.2.2.1.1.3.1.cmml">â¢</mo><mrow id="S3.E3.m1.2.2.1.1.3.3.2" xref="S3.E3.m1.2.2.1.1.3.cmml"><mo id="S3.E3.m1.2.2.1.1.3.3.2.1" stretchy="false" xref="S3.E3.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.3.3.2.2" stretchy="false" xref="S3.E3.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.2.cmml"><mo id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.2.1.cmml">|</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.3" mathvariant="normal" xref="S3.E3.m1.2.2.1.1.1.1.1.3.cmml">Î”</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.1.4.cmml">â„’</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.2a" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.2.1.cmml">|</mo></mrow></mrow><mo id="S3.E3.m1.3.3.2.3" xref="S3.E3.m1.3.3.3a.cmml">,</mo><mrow id="S3.E3.m1.3.3.2.2" xref="S3.E3.m1.3.3.2.2.cmml"><mi id="S3.E3.m1.3.3.2.2.2" xref="S3.E3.m1.3.3.2.2.2.cmml">i</mi><mo id="S3.E3.m1.3.3.2.2.1" xref="S3.E3.m1.3.3.2.2.1.cmml">âˆˆ</mo><msub id="S3.E3.m1.3.3.2.2.3" xref="S3.E3.m1.3.3.2.2.3.cmml"><mi id="S3.E3.m1.3.3.2.2.3.2" xref="S3.E3.m1.3.3.2.2.3.2.cmml">L</mi><mi id="S3.E3.m1.3.3.2.2.3.3" xref="S3.E3.m1.3.3.2.2.3.3.cmml">j</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3a.cmml" xref="S3.E3.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><eq id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2"></eq><apply id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3"><times id="S3.E3.m1.2.2.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3.1"></times><ci id="S3.E3.m1.2.2.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.2">Î¦</ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘–</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1"><abs id="S3.E3.m1.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2"></abs><apply id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3">Î”</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.4">â„’</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2">h</mtext></ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S3.E3.m1.3.3.2.2.cmml" xref="S3.E3.m1.3.3.2.2"><in id="S3.E3.m1.3.3.2.2.1.cmml" xref="S3.E3.m1.3.3.2.2.1"></in><ci id="S3.E3.m1.3.3.2.2.2.cmml" xref="S3.E3.m1.3.3.2.2.2">ğ‘–</ci><apply id="S3.E3.m1.3.3.2.2.3.cmml" xref="S3.E3.m1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.3.1.cmml" xref="S3.E3.m1.3.3.2.2.3">subscript</csymbol><ci id="S3.E3.m1.3.3.2.2.3.2.cmml" xref="S3.E3.m1.3.3.2.2.3.2">ğ¿</ci><ci id="S3.E3.m1.3.3.2.2.3.3.cmml" xref="S3.E3.m1.3.3.2.2.3.3">ğ‘—</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\Phi(i)=\left|\Delta\mathcal{L}(\textbf{h}_{i})\right|,i\in{L_{j}}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">roman_Î¦ ( italic_i ) = | roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) | , italic_i âˆˆ italic_L start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.6"><math alttext="L_{j}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ¿</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">L_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_L start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_j</annotation></semantics></math>-th layer that is the detected language-pair-relevant layer.
<math alttext="\textbf{h}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2a.cmml">h</mtext><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2a.cmml" xref="S3.SS2.p3.3.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">h</mtext></ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\textbf{h}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the output of neuron <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_i</annotation></semantics></math>.
<math alttext="\Delta\mathcal{L}(\textbf{h}_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mrow id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3" mathvariant="normal" xref="S3.SS2.p3.5.m5.1.1.3.cmml">Î”</mi><mo id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.5.m5.1.1.4" xref="S3.SS2.p3.5.m5.1.1.4.cmml">â„’</mi><mo id="S3.SS2.p3.5.m5.1.1.2a" xref="S3.SS2.p3.5.m5.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p3.5.m5.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.5.m5.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.5.m5.1.1.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2a.cmml">h</mtext><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><times id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2"></times><ci id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">Î”</ci><ci id="S3.SS2.p3.5.m5.1.1.4.cmml" xref="S3.SS2.p3.5.m5.1.1.4">â„’</ci><apply id="S3.SS2.p3.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.2a.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2">h</mtext></ci><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\Delta\mathcal{L}(\textbf{h}_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is the loss change between setting <math alttext="\textbf{h}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2a.cmml">h</mtext><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2a.cmml" xref="S3.SS2.p3.6.m6.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">h</mtext></ci><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">\textbf{h}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.6.1">0</span> and keeping it at its original value.
It can be transformed by TE into the following form:</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\left|\Delta\mathcal{L}\left(\textbf{h}_{i}\right)\right|=\left|\frac{\partial%
\mathcal{L}}{\partial\textbf{h}_{i}}\textbf{h}_{i}\right|" class="ltx_Math" display="block" id="S3.E4.m1.2"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.2.cmml"><mo id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.3" mathvariant="normal" xref="S3.E4.m1.1.1.1.1.1.3.cmml">Î”</mi><mo id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.1.4.cmml">â„’</mi><mo id="S3.E4.m1.1.1.1.1.1.2a" xref="S3.E4.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.2.1.cmml">|</mo></mrow><mo id="S3.E4.m1.2.2.3" xref="S3.E4.m1.2.2.3.cmml">=</mo><mrow id="S3.E4.m1.2.2.2.1" xref="S3.E4.m1.2.2.2.2.cmml"><mo id="S3.E4.m1.2.2.2.1.2" xref="S3.E4.m1.2.2.2.2.1.cmml">|</mo><mrow id="S3.E4.m1.2.2.2.1.1" xref="S3.E4.m1.2.2.2.1.1.cmml"><mfrac id="S3.E4.m1.2.2.2.1.1.2" xref="S3.E4.m1.2.2.2.1.1.2.cmml"><mrow id="S3.E4.m1.2.2.2.1.1.2.2" xref="S3.E4.m1.2.2.2.1.1.2.2.cmml"><mo id="S3.E4.m1.2.2.2.1.1.2.2.1" rspace="0em" xref="S3.E4.m1.2.2.2.1.1.2.2.1.cmml">âˆ‚</mo><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.2.2.2.1.1.2.2.2" xref="S3.E4.m1.2.2.2.1.1.2.2.2.cmml">â„’</mi></mrow><mrow id="S3.E4.m1.2.2.2.1.1.2.3" xref="S3.E4.m1.2.2.2.1.1.2.3.cmml"><mo id="S3.E4.m1.2.2.2.1.1.2.3.1" rspace="0em" xref="S3.E4.m1.2.2.2.1.1.2.3.1.cmml">âˆ‚</mo><msub id="S3.E4.m1.2.2.2.1.1.2.3.2" xref="S3.E4.m1.2.2.2.1.1.2.3.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.2.2.2.1.1.2.3.2.2" xref="S3.E4.m1.2.2.2.1.1.2.3.2.2a.cmml">h</mtext><mi id="S3.E4.m1.2.2.2.1.1.2.3.2.3" xref="S3.E4.m1.2.2.2.1.1.2.3.2.3.cmml">i</mi></msub></mrow></mfrac><mo id="S3.E4.m1.2.2.2.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.cmml">â¢</mo><msub id="S3.E4.m1.2.2.2.1.1.3" xref="S3.E4.m1.2.2.2.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.2.2.2.1.1.3.2" xref="S3.E4.m1.2.2.2.1.1.3.2a.cmml">h</mtext><mi id="S3.E4.m1.2.2.2.1.1.3.3" xref="S3.E4.m1.2.2.2.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.E4.m1.2.2.2.1.3" xref="S3.E4.m1.2.2.2.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><eq id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2.3"></eq><apply id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1"><abs id="S3.E4.m1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2"></abs><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3">Î”</ci><ci id="S3.E4.m1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.1.4">â„’</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">h</mtext></ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.1"><abs id="S3.E4.m1.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.1.2"></abs><apply id="S3.E4.m1.2.2.2.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1"><times id="S3.E4.m1.2.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1"></times><apply id="S3.E4.m1.2.2.2.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.2"><divide id="S3.E4.m1.2.2.2.1.1.2.1.cmml" xref="S3.E4.m1.2.2.2.1.1.2"></divide><apply id="S3.E4.m1.2.2.2.1.1.2.2.cmml" xref="S3.E4.m1.2.2.2.1.1.2.2"><partialdiff id="S3.E4.m1.2.2.2.1.1.2.2.1.cmml" xref="S3.E4.m1.2.2.2.1.1.2.2.1"></partialdiff><ci id="S3.E4.m1.2.2.2.1.1.2.2.2.cmml" xref="S3.E4.m1.2.2.2.1.1.2.2.2">â„’</ci></apply><apply id="S3.E4.m1.2.2.2.1.1.2.3.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3"><partialdiff id="S3.E4.m1.2.2.2.1.1.2.3.1.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3.1"></partialdiff><apply id="S3.E4.m1.2.2.2.1.1.2.3.2.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.2.3.2.1.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.2.3.2.2a.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.2.2.2.1.1.2.3.2.2.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3.2.2">h</mtext></ci><ci id="S3.E4.m1.2.2.2.1.1.2.3.2.3.cmml" xref="S3.E4.m1.2.2.2.1.1.2.3.2.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E4.m1.2.2.2.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.3.1.cmml" xref="S3.E4.m1.2.2.2.1.1.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.3.2a.cmml" xref="S3.E4.m1.2.2.2.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.2.2.2.1.1.3.2.cmml" xref="S3.E4.m1.2.2.2.1.1.3.2">h</mtext></ci><ci id="S3.E4.m1.2.2.2.1.1.3.3.cmml" xref="S3.E4.m1.2.2.2.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">\left|\Delta\mathcal{L}\left(\textbf{h}_{i}\right)\right|=\left|\frac{\partial%
\mathcal{L}}{\partial\textbf{h}_{i}}\textbf{h}_{i}\right|</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.2d">| roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) | = | divide start_ARG âˆ‚ caligraphic_L end_ARG start_ARG âˆ‚ h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">We estimate the loss change as the product of the gradient of the loss function with respect to the activation value and the activation value itself.
The detailed proof can be found in the appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#A1.SS2" title="A.2 Taylor Expansion â€£ Appendix A Appendix â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">A.2</span></a>, which is similar to that by <cite class="ltx_cite ltx_citemacro_citet">Xie etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib35" title="">2021</a>)</cite>.
Then, we determine which neurons are shared across all language pairs (i.e., language-general neurons) and which neurons are only related to specific language pairs.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.4">We define <math alttext="\mathbf{X}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.1"><semantics id="S3.SS2.p6.1.m1.1a"><msub id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml"><mi id="S3.SS2.p6.1.m1.1.1.2" xref="S3.SS2.p6.1.m1.1.1.2.cmml">ğ—</mi><mi id="S3.SS2.p6.1.m1.1.1.3" xref="S3.SS2.p6.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><apply id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p6.1.m1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.1.1.2">ğ—</ci><ci id="S3.SS2.p6.1.m1.1.1.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">\mathbf{X}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.1d">bold_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as the vector of awareness scores of the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">italic_i</annotation></semantics></math>-th neuron for each language. For each neuron, we calculate the variance <math alttext="\sigma(\mathbf{X}_{i})" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><mrow id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml"><mi id="S3.SS2.p6.3.m3.1.1.3" xref="S3.SS2.p6.3.m3.1.1.3.cmml">Ïƒ</mi><mo id="S3.SS2.p6.3.m3.1.1.2" xref="S3.SS2.p6.3.m3.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p6.3.m3.1.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.p6.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p6.3.m3.1.1.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p6.3.m3.1.1.1.1.1.2" xref="S3.SS2.p6.3.m3.1.1.1.1.1.2.cmml">ğ—</mi><mi id="S3.SS2.p6.3.m3.1.1.1.1.1.3" xref="S3.SS2.p6.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p6.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS2.p6.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><apply id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1"><times id="S3.SS2.p6.3.m3.1.1.2.cmml" xref="S3.SS2.p6.3.m3.1.1.2"></times><ci id="S3.SS2.p6.3.m3.1.1.3.cmml" xref="S3.SS2.p6.3.m3.1.1.3">ğœ</ci><apply id="S3.SS2.p6.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p6.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1.1.2">ğ—</ci><ci id="S3.SS2.p6.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p6.3.m3.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">\sigma(\mathbf{X}_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">italic_Ïƒ ( bold_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> of the awareness scores across different languages.
Within a specific layer, we sort the neuron awareness scores based on their variance from the highest to the lowest.
A variance threshold <math alttext="\lambda(i)" class="ltx_Math" display="inline" id="S3.SS2.p6.4.m4.1"><semantics id="S3.SS2.p6.4.m4.1a"><mrow id="S3.SS2.p6.4.m4.1.2" xref="S3.SS2.p6.4.m4.1.2.cmml"><mi id="S3.SS2.p6.4.m4.1.2.2" xref="S3.SS2.p6.4.m4.1.2.2.cmml">Î»</mi><mo id="S3.SS2.p6.4.m4.1.2.1" xref="S3.SS2.p6.4.m4.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.p6.4.m4.1.2.3.2" xref="S3.SS2.p6.4.m4.1.2.cmml"><mo id="S3.SS2.p6.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS2.p6.4.m4.1.2.cmml">(</mo><mi id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml">i</mi><mo id="S3.SS2.p6.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS2.p6.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.1b"><apply id="S3.SS2.p6.4.m4.1.2.cmml" xref="S3.SS2.p6.4.m4.1.2"><times id="S3.SS2.p6.4.m4.1.2.1.cmml" xref="S3.SS2.p6.4.m4.1.2.1"></times><ci id="S3.SS2.p6.4.m4.1.2.2.cmml" xref="S3.SS2.p6.4.m4.1.2.2">ğœ†</ci><ci id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.1c">\lambda(i)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.4.m4.1d">italic_Î» ( italic_i )</annotation></semantics></math> is calculated to distinguish language-general neurons from language-specific neurons as follows:</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\lambda(i)=\mathrm{sort}(\sigma(\mathbf{X_{i}}))_{\lfloor\epsilon\times p%
\rfloor},i\in{L_{j}}" class="ltx_Math" display="block" id="S3.E5.m1.4"><semantics id="S3.E5.m1.4a"><mrow id="S3.E5.m1.4.4.2" xref="S3.E5.m1.4.4.3.cmml"><mrow id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1.3" xref="S3.E5.m1.3.3.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.3.2" xref="S3.E5.m1.3.3.1.1.3.2.cmml">Î»</mi><mo id="S3.E5.m1.3.3.1.1.3.1" xref="S3.E5.m1.3.3.1.1.3.1.cmml">â¢</mo><mrow id="S3.E5.m1.3.3.1.1.3.3.2" xref="S3.E5.m1.3.3.1.1.3.cmml"><mo id="S3.E5.m1.3.3.1.1.3.3.2.1" stretchy="false" xref="S3.E5.m1.3.3.1.1.3.cmml">(</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">i</mi><mo id="S3.E5.m1.3.3.1.1.3.3.2.2" stretchy="false" xref="S3.E5.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.3.3.1.1.2" xref="S3.E5.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.3.3.1.1.1" xref="S3.E5.m1.3.3.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.3.cmml">sort</mi><mo id="S3.E5.m1.3.3.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.2.cmml">â¢</mo><msub id="S3.E5.m1.3.3.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.3.cmml">Ïƒ</mi><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ—</mi><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml">ğ¢</mi></msub><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.2.cmml"><mo id="S3.E5.m1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.2.1.cmml">âŒŠ</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.2.cmml">Ïµ</mi><mo id="S3.E5.m1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E5.m1.1.1.1.1.1.1.cmml">Ã—</mo><mi id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.3.cmml">p</mi></mrow><mo id="S3.E5.m1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.1.1.1.2.1.cmml">âŒ‹</mo></mrow></msub></mrow></mrow><mo id="S3.E5.m1.4.4.2.3" xref="S3.E5.m1.4.4.3a.cmml">,</mo><mrow id="S3.E5.m1.4.4.2.2" xref="S3.E5.m1.4.4.2.2.cmml"><mi id="S3.E5.m1.4.4.2.2.2" xref="S3.E5.m1.4.4.2.2.2.cmml">i</mi><mo id="S3.E5.m1.4.4.2.2.1" xref="S3.E5.m1.4.4.2.2.1.cmml">âˆˆ</mo><msub id="S3.E5.m1.4.4.2.2.3" xref="S3.E5.m1.4.4.2.2.3.cmml"><mi id="S3.E5.m1.4.4.2.2.3.2" xref="S3.E5.m1.4.4.2.2.3.2.cmml">L</mi><mi id="S3.E5.m1.4.4.2.2.3.3" xref="S3.E5.m1.4.4.2.2.3.3.cmml">j</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.4b"><apply id="S3.E5.m1.4.4.3.cmml" xref="S3.E5.m1.4.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3a.cmml" xref="S3.E5.m1.4.4.2.3">formulae-sequence</csymbol><apply id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1"><eq id="S3.E5.m1.3.3.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2"></eq><apply id="S3.E5.m1.3.3.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.3"><times id="S3.E5.m1.3.3.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.3.1"></times><ci id="S3.E5.m1.3.3.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.3.2">ğœ†</ci><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">ğ‘–</ci></apply><apply id="S3.E5.m1.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1"><times id="S3.E5.m1.3.3.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.2"></times><ci id="S3.E5.m1.3.3.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.3">sort</ci><apply id="S3.E5.m1.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1"><times id="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2"></times><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.3">ğœ</ci><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">ğ—</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">ğ¢</ci></apply></apply><apply id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1"><floor id="S3.E5.m1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2"></floor><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1"></times><ci id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2">italic-Ïµ</ci><ci id="S3.E5.m1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply></apply></apply><apply id="S3.E5.m1.4.4.2.2.cmml" xref="S3.E5.m1.4.4.2.2"><in id="S3.E5.m1.4.4.2.2.1.cmml" xref="S3.E5.m1.4.4.2.2.1"></in><ci id="S3.E5.m1.4.4.2.2.2.cmml" xref="S3.E5.m1.4.4.2.2.2">ğ‘–</ci><apply id="S3.E5.m1.4.4.2.2.3.cmml" xref="S3.E5.m1.4.4.2.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.2.2.3.1.cmml" xref="S3.E5.m1.4.4.2.2.3">subscript</csymbol><ci id="S3.E5.m1.4.4.2.2.3.2.cmml" xref="S3.E5.m1.4.4.2.2.3.2">ğ¿</ci><ci id="S3.E5.m1.4.4.2.2.3.3.cmml" xref="S3.E5.m1.4.4.2.2.3.3">ğ‘—</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.4c">\lambda(i)=\mathrm{sort}(\sigma(\mathbf{X_{i}}))_{\lfloor\epsilon\times p%
\rfloor},i\in{L_{j}}</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.4d">italic_Î» ( italic_i ) = roman_sort ( italic_Ïƒ ( bold_X start_POSTSUBSCRIPT bold_i end_POSTSUBSCRIPT ) ) start_POSTSUBSCRIPT âŒŠ italic_Ïµ Ã— italic_p âŒ‹ end_POSTSUBSCRIPT , italic_i âˆˆ italic_L start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p7.4">where <math alttext="p" class="ltx_Math" display="inline" id="S3.SS2.p7.1.m1.1"><semantics id="S3.SS2.p7.1.m1.1a"><mi id="S3.SS2.p7.1.m1.1.1" xref="S3.SS2.p7.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.1.m1.1b"><ci id="S3.SS2.p7.1.m1.1.1.cmml" xref="S3.SS2.p7.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.1.m1.1d">italic_p</annotation></semantics></math> is the number of neurons in the <math alttext="L_{j}" class="ltx_Math" display="inline" id="S3.SS2.p7.2.m2.1"><semantics id="S3.SS2.p7.2.m2.1a"><msub id="S3.SS2.p7.2.m2.1.1" xref="S3.SS2.p7.2.m2.1.1.cmml"><mi id="S3.SS2.p7.2.m2.1.1.2" xref="S3.SS2.p7.2.m2.1.1.2.cmml">L</mi><mi id="S3.SS2.p7.2.m2.1.1.3" xref="S3.SS2.p7.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.2.m2.1b"><apply id="S3.SS2.p7.2.m2.1.1.cmml" xref="S3.SS2.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p7.2.m2.1.1.1.cmml" xref="S3.SS2.p7.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p7.2.m2.1.1.2.cmml" xref="S3.SS2.p7.2.m2.1.1.2">ğ¿</ci><ci id="S3.SS2.p7.2.m2.1.1.3.cmml" xref="S3.SS2.p7.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.2.m2.1c">L_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.2.m2.1d">italic_L start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> layer, <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS2.p7.3.m3.1"><semantics id="S3.SS2.p7.3.m3.1a"><mi id="S3.SS2.p7.3.m3.1.1" xref="S3.SS2.p7.3.m3.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.3.m3.1b"><ci id="S3.SS2.p7.3.m3.1.1.cmml" xref="S3.SS2.p7.3.m3.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.3.m3.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.3.m3.1d">italic_Ïµ</annotation></semantics></math> is a predefined ratio.
For neurons with language awareness score variances below the estimated threshold <math alttext="\lambda(i)" class="ltx_Math" display="inline" id="S3.SS2.p7.4.m4.1"><semantics id="S3.SS2.p7.4.m4.1a"><mrow id="S3.SS2.p7.4.m4.1.2" xref="S3.SS2.p7.4.m4.1.2.cmml"><mi id="S3.SS2.p7.4.m4.1.2.2" xref="S3.SS2.p7.4.m4.1.2.2.cmml">Î»</mi><mo id="S3.SS2.p7.4.m4.1.2.1" xref="S3.SS2.p7.4.m4.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.p7.4.m4.1.2.3.2" xref="S3.SS2.p7.4.m4.1.2.cmml"><mo id="S3.SS2.p7.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS2.p7.4.m4.1.2.cmml">(</mo><mi id="S3.SS2.p7.4.m4.1.1" xref="S3.SS2.p7.4.m4.1.1.cmml">i</mi><mo id="S3.SS2.p7.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS2.p7.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.4.m4.1b"><apply id="S3.SS2.p7.4.m4.1.2.cmml" xref="S3.SS2.p7.4.m4.1.2"><times id="S3.SS2.p7.4.m4.1.2.1.cmml" xref="S3.SS2.p7.4.m4.1.2.1"></times><ci id="S3.SS2.p7.4.m4.1.2.2.cmml" xref="S3.SS2.p7.4.m4.1.2.2">ğœ†</ci><ci id="S3.SS2.p7.4.m4.1.1.cmml" xref="S3.SS2.p7.4.m4.1.1">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.4.m4.1c">\lambda(i)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.4.m4.1d">italic_Î» ( italic_i )</annotation></semantics></math>, we categorize them as language-general neurons, otherwise as language-specific neurons.
Each detected language-specific neuron is assigned to the language with the highest awareness score.</p>
</div>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1">The set of neurons that are specific either to the source language or to the target language are aggregated as the neurons exclusive to that language pair.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Routing and Finetuning</h3>
<figure class="ltx_figure" id="S3.F2">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F2.1"><span class="ltx_text" id="S3.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="197" id="S3.F2.1.1.g1" src="x2.png" width="315"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The model architecture used for routing and training.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In our proposed framework, for a given bilingual dataset of a specific language pair, only the language-general and language-specific neurons of the detected FFNs for this language pair participate in the forward computation and the parameters associated with them are updated during the backward propagation, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S3.F2" title="Figure 2 â€£ 3.3 Routing and Finetuning â€£ 3 Methodology â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>.
Nevertheless, it has been empirically shown that the language signals from language indicator tokens alone are not sufficient <cite class="ltx_cite ltx_citemacro_cite">Arivazhagan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib2" title="">2019</a>)</cite>, making modules or mechanisms dedicated to language-general and language-specific modeling a necessity <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib39" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib37" title="">2021</a>)</cite>.
To address this issue, we propose a conditional awareness-based routing mechanism (CAR) that allows the model to decide and learn what proportion of the outputs of language-general and language-specific neurons should be allocated for the translation of the language pair.
For an input token <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, CAR is evaluated as follows:</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{CAR}(x_{t})=\frac{\sum_{i=1}^{N}\Phi(i)}{\sum_{i=1}^{N}\Phi(i)+\sum_{j=1%
}^{M}\Phi(j)}" class="ltx_Math" display="block" id="S3.E6.m1.4"><semantics id="S3.E6.m1.4a"><mrow id="S3.E6.m1.4.4" xref="S3.E6.m1.4.4.cmml"><mrow id="S3.E6.m1.4.4.1" xref="S3.E6.m1.4.4.1.cmml"><mtext id="S3.E6.m1.4.4.1.3" xref="S3.E6.m1.4.4.1.3a.cmml">CAR</mtext><mo id="S3.E6.m1.4.4.1.2" xref="S3.E6.m1.4.4.1.2.cmml">â¢</mo><mrow id="S3.E6.m1.4.4.1.1.1" xref="S3.E6.m1.4.4.1.1.1.1.cmml"><mo id="S3.E6.m1.4.4.1.1.1.2" stretchy="false" xref="S3.E6.m1.4.4.1.1.1.1.cmml">(</mo><msub id="S3.E6.m1.4.4.1.1.1.1" xref="S3.E6.m1.4.4.1.1.1.1.cmml"><mi id="S3.E6.m1.4.4.1.1.1.1.2" xref="S3.E6.m1.4.4.1.1.1.1.2.cmml">x</mi><mi id="S3.E6.m1.4.4.1.1.1.1.3" xref="S3.E6.m1.4.4.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E6.m1.4.4.1.1.1.3" stretchy="false" xref="S3.E6.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.2" xref="S3.E6.m1.4.4.2.cmml">=</mo><mfrac id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml"><msubsup id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.2.cmml"><mo id="S3.E6.m1.1.1.1.2.2.2" xref="S3.E6.m1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.1.1.1.2.2.3" xref="S3.E6.m1.1.1.1.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.2.2.3.2" xref="S3.E6.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E6.m1.1.1.1.2.2.3.1" xref="S3.E6.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.1.2.2.3.3" xref="S3.E6.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.E6.m1.1.1.1.3" xref="S3.E6.m1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.3.2" mathvariant="normal" xref="S3.E6.m1.1.1.1.3.2.cmml">Î¦</mi><mo id="S3.E6.m1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.3.1.cmml">â¢</mo><mrow id="S3.E6.m1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.3.cmml"><mo id="S3.E6.m1.1.1.1.3.3.2.1" stretchy="false" xref="S3.E6.m1.1.1.1.3.cmml">(</mo><mi id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml">i</mi><mo id="S3.E6.m1.1.1.1.3.3.2.2" stretchy="false" xref="S3.E6.m1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml"><mrow id="S3.E6.m1.3.3.3.4" xref="S3.E6.m1.3.3.3.4.cmml"><msubsup id="S3.E6.m1.3.3.3.4.1" xref="S3.E6.m1.3.3.3.4.1.cmml"><mo id="S3.E6.m1.3.3.3.4.1.2.2" xref="S3.E6.m1.3.3.3.4.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.3.3.3.4.1.2.3" xref="S3.E6.m1.3.3.3.4.1.2.3.cmml"><mi id="S3.E6.m1.3.3.3.4.1.2.3.2" xref="S3.E6.m1.3.3.3.4.1.2.3.2.cmml">i</mi><mo id="S3.E6.m1.3.3.3.4.1.2.3.1" xref="S3.E6.m1.3.3.3.4.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.3.3.3.4.1.2.3.3" xref="S3.E6.m1.3.3.3.4.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.3.3.3.4.1.3" xref="S3.E6.m1.3.3.3.4.1.3.cmml">N</mi></msubsup><mrow id="S3.E6.m1.3.3.3.4.2" xref="S3.E6.m1.3.3.3.4.2.cmml"><mi id="S3.E6.m1.3.3.3.4.2.2" mathvariant="normal" xref="S3.E6.m1.3.3.3.4.2.2.cmml">Î¦</mi><mo id="S3.E6.m1.3.3.3.4.2.1" xref="S3.E6.m1.3.3.3.4.2.1.cmml">â¢</mo><mrow id="S3.E6.m1.3.3.3.4.2.3.2" xref="S3.E6.m1.3.3.3.4.2.cmml"><mo id="S3.E6.m1.3.3.3.4.2.3.2.1" stretchy="false" xref="S3.E6.m1.3.3.3.4.2.cmml">(</mo><mi id="S3.E6.m1.2.2.2.1" xref="S3.E6.m1.2.2.2.1.cmml">i</mi><mo id="S3.E6.m1.3.3.3.4.2.3.2.2" stretchy="false" xref="S3.E6.m1.3.3.3.4.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.3.3.3.3" rspace="0.055em" xref="S3.E6.m1.3.3.3.3.cmml">+</mo><mrow id="S3.E6.m1.3.3.3.5" xref="S3.E6.m1.3.3.3.5.cmml"><msubsup id="S3.E6.m1.3.3.3.5.1" xref="S3.E6.m1.3.3.3.5.1.cmml"><mo id="S3.E6.m1.3.3.3.5.1.2.2" xref="S3.E6.m1.3.3.3.5.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.3.3.3.5.1.2.3" xref="S3.E6.m1.3.3.3.5.1.2.3.cmml"><mi id="S3.E6.m1.3.3.3.5.1.2.3.2" xref="S3.E6.m1.3.3.3.5.1.2.3.2.cmml">j</mi><mo id="S3.E6.m1.3.3.3.5.1.2.3.1" xref="S3.E6.m1.3.3.3.5.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.3.3.3.5.1.2.3.3" xref="S3.E6.m1.3.3.3.5.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.3.3.3.5.1.3" xref="S3.E6.m1.3.3.3.5.1.3.cmml">M</mi></msubsup><mrow id="S3.E6.m1.3.3.3.5.2" xref="S3.E6.m1.3.3.3.5.2.cmml"><mi id="S3.E6.m1.3.3.3.5.2.2" mathvariant="normal" xref="S3.E6.m1.3.3.3.5.2.2.cmml">Î¦</mi><mo id="S3.E6.m1.3.3.3.5.2.1" xref="S3.E6.m1.3.3.3.5.2.1.cmml">â¢</mo><mrow id="S3.E6.m1.3.3.3.5.2.3.2" xref="S3.E6.m1.3.3.3.5.2.cmml"><mo id="S3.E6.m1.3.3.3.5.2.3.2.1" stretchy="false" xref="S3.E6.m1.3.3.3.5.2.cmml">(</mo><mi id="S3.E6.m1.3.3.3.2" xref="S3.E6.m1.3.3.3.2.cmml">j</mi><mo id="S3.E6.m1.3.3.3.5.2.3.2.2" stretchy="false" xref="S3.E6.m1.3.3.3.5.2.cmml">)</mo></mrow></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.4b"><apply id="S3.E6.m1.4.4.cmml" xref="S3.E6.m1.4.4"><eq id="S3.E6.m1.4.4.2.cmml" xref="S3.E6.m1.4.4.2"></eq><apply id="S3.E6.m1.4.4.1.cmml" xref="S3.E6.m1.4.4.1"><times id="S3.E6.m1.4.4.1.2.cmml" xref="S3.E6.m1.4.4.1.2"></times><ci id="S3.E6.m1.4.4.1.3a.cmml" xref="S3.E6.m1.4.4.1.3"><mtext id="S3.E6.m1.4.4.1.3.cmml" xref="S3.E6.m1.4.4.1.3">CAR</mtext></ci><apply id="S3.E6.m1.4.4.1.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.1.1.1">subscript</csymbol><ci id="S3.E6.m1.4.4.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E6.m1.4.4.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.1.1.1.1.3">ğ‘¡</ci></apply></apply><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><divide id="S3.E6.m1.3.3.4.cmml" xref="S3.E6.m1.3.3"></divide><apply id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><apply id="S3.E6.m1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.2">superscript</csymbol><apply id="S3.E6.m1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.2.2.1.cmml" xref="S3.E6.m1.1.1.1.2">subscript</csymbol><sum id="S3.E6.m1.1.1.1.2.2.2.cmml" xref="S3.E6.m1.1.1.1.2.2.2"></sum><apply id="S3.E6.m1.1.1.1.2.2.3.cmml" xref="S3.E6.m1.1.1.1.2.2.3"><eq id="S3.E6.m1.1.1.1.2.2.3.1.cmml" xref="S3.E6.m1.1.1.1.2.2.3.1"></eq><ci id="S3.E6.m1.1.1.1.2.2.3.2.cmml" xref="S3.E6.m1.1.1.1.2.2.3.2">ğ‘–</ci><cn id="S3.E6.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E6.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E6.m1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.3"><times id="S3.E6.m1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.3.1"></times><ci id="S3.E6.m1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.3.2">Î¦</ci><ci id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1">ğ‘–</ci></apply></apply><apply id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"><plus id="S3.E6.m1.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3"></plus><apply id="S3.E6.m1.3.3.3.4.cmml" xref="S3.E6.m1.3.3.3.4"><apply id="S3.E6.m1.3.3.3.4.1.cmml" xref="S3.E6.m1.3.3.3.4.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.4.1.1.cmml" xref="S3.E6.m1.3.3.3.4.1">superscript</csymbol><apply id="S3.E6.m1.3.3.3.4.1.2.cmml" xref="S3.E6.m1.3.3.3.4.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.4.1.2.1.cmml" xref="S3.E6.m1.3.3.3.4.1">subscript</csymbol><sum id="S3.E6.m1.3.3.3.4.1.2.2.cmml" xref="S3.E6.m1.3.3.3.4.1.2.2"></sum><apply id="S3.E6.m1.3.3.3.4.1.2.3.cmml" xref="S3.E6.m1.3.3.3.4.1.2.3"><eq id="S3.E6.m1.3.3.3.4.1.2.3.1.cmml" xref="S3.E6.m1.3.3.3.4.1.2.3.1"></eq><ci id="S3.E6.m1.3.3.3.4.1.2.3.2.cmml" xref="S3.E6.m1.3.3.3.4.1.2.3.2">ğ‘–</ci><cn id="S3.E6.m1.3.3.3.4.1.2.3.3.cmml" type="integer" xref="S3.E6.m1.3.3.3.4.1.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.3.3.3.4.1.3.cmml" xref="S3.E6.m1.3.3.3.4.1.3">ğ‘</ci></apply><apply id="S3.E6.m1.3.3.3.4.2.cmml" xref="S3.E6.m1.3.3.3.4.2"><times id="S3.E6.m1.3.3.3.4.2.1.cmml" xref="S3.E6.m1.3.3.3.4.2.1"></times><ci id="S3.E6.m1.3.3.3.4.2.2.cmml" xref="S3.E6.m1.3.3.3.4.2.2">Î¦</ci><ci id="S3.E6.m1.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.1">ğ‘–</ci></apply></apply><apply id="S3.E6.m1.3.3.3.5.cmml" xref="S3.E6.m1.3.3.3.5"><apply id="S3.E6.m1.3.3.3.5.1.cmml" xref="S3.E6.m1.3.3.3.5.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.5.1.1.cmml" xref="S3.E6.m1.3.3.3.5.1">superscript</csymbol><apply id="S3.E6.m1.3.3.3.5.1.2.cmml" xref="S3.E6.m1.3.3.3.5.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.5.1.2.1.cmml" xref="S3.E6.m1.3.3.3.5.1">subscript</csymbol><sum id="S3.E6.m1.3.3.3.5.1.2.2.cmml" xref="S3.E6.m1.3.3.3.5.1.2.2"></sum><apply id="S3.E6.m1.3.3.3.5.1.2.3.cmml" xref="S3.E6.m1.3.3.3.5.1.2.3"><eq id="S3.E6.m1.3.3.3.5.1.2.3.1.cmml" xref="S3.E6.m1.3.3.3.5.1.2.3.1"></eq><ci id="S3.E6.m1.3.3.3.5.1.2.3.2.cmml" xref="S3.E6.m1.3.3.3.5.1.2.3.2">ğ‘—</ci><cn id="S3.E6.m1.3.3.3.5.1.2.3.3.cmml" type="integer" xref="S3.E6.m1.3.3.3.5.1.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.3.3.3.5.1.3.cmml" xref="S3.E6.m1.3.3.3.5.1.3">ğ‘€</ci></apply><apply id="S3.E6.m1.3.3.3.5.2.cmml" xref="S3.E6.m1.3.3.3.5.2"><times id="S3.E6.m1.3.3.3.5.2.1.cmml" xref="S3.E6.m1.3.3.3.5.2.1"></times><ci id="S3.E6.m1.3.3.3.5.2.2.cmml" xref="S3.E6.m1.3.3.3.5.2.2">Î¦</ci><ci id="S3.E6.m1.3.3.3.2.cmml" xref="S3.E6.m1.3.3.3.2">ğ‘—</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.4c">\text{CAR}(x_{t})=\frac{\sum_{i=1}^{N}\Phi(i)}{\sum_{i=1}^{N}\Phi(i)+\sum_{j=1%
}^{M}\Phi(j)}</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.4d">CAR ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = divide start_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_Î¦ ( italic_i ) end_ARG start_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_Î¦ ( italic_i ) + âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT roman_Î¦ ( italic_j ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{h}_{G}(x_{t})=\text{FFN}_{G}(\text{CAR}(x_{t}).x_{t})" class="ltx_math_unparsed" display="block" id="S3.E7.m1.1"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1b"><msub id="S3.E7.m1.1.1"><mtext class="ltx_mathvariant_bold" id="S3.E7.m1.1.1.2">h</mtext><mi id="S3.E7.m1.1.1.3">G</mi></msub><mrow id="S3.E7.m1.1.2"><mo id="S3.E7.m1.1.2.1" stretchy="false">(</mo><msub id="S3.E7.m1.1.2.2"><mi id="S3.E7.m1.1.2.2.2">x</mi><mi id="S3.E7.m1.1.2.2.3">t</mi></msub><mo id="S3.E7.m1.1.2.3" stretchy="false">)</mo></mrow><mo id="S3.E7.m1.1.3">=</mo><msub id="S3.E7.m1.1.4"><mtext id="S3.E7.m1.1.4.2">FFN</mtext><mi id="S3.E7.m1.1.4.3">G</mi></msub><mrow id="S3.E7.m1.1.5"><mo id="S3.E7.m1.1.5.1" stretchy="false">(</mo><mtext id="S3.E7.m1.1.5.2">CAR</mtext><mrow id="S3.E7.m1.1.5.3"><mo id="S3.E7.m1.1.5.3.1" stretchy="false">(</mo><msub id="S3.E7.m1.1.5.3.2"><mi id="S3.E7.m1.1.5.3.2.2">x</mi><mi id="S3.E7.m1.1.5.3.2.3">t</mi></msub><mo id="S3.E7.m1.1.5.3.3" stretchy="false">)</mo></mrow><mo id="S3.E7.m1.1.5.4" lspace="0em" rspace="0.167em">.</mo><msub id="S3.E7.m1.1.5.5"><mi id="S3.E7.m1.1.5.5.2">x</mi><mi id="S3.E7.m1.1.5.5.3">t</mi></msub><mo id="S3.E7.m1.1.5.6" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\textbf{h}_{G}(x_{t})=\text{FFN}_{G}(\text{CAR}(x_{t}).x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.1d">h start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = FFN start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( CAR ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) . italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{h}_{S}(x_{t})=\text{FFN}_{S}((1-\text{CAR}(x_{t})).x_{t})" class="ltx_math_unparsed" display="block" id="S3.E8.m1.1"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1b"><msub id="S3.E8.m1.1.1"><mtext class="ltx_mathvariant_bold" id="S3.E8.m1.1.1.2">h</mtext><mi id="S3.E8.m1.1.1.3">S</mi></msub><mrow id="S3.E8.m1.1.2"><mo id="S3.E8.m1.1.2.1" stretchy="false">(</mo><msub id="S3.E8.m1.1.2.2"><mi id="S3.E8.m1.1.2.2.2">x</mi><mi id="S3.E8.m1.1.2.2.3">t</mi></msub><mo id="S3.E8.m1.1.2.3" stretchy="false">)</mo></mrow><mo id="S3.E8.m1.1.3">=</mo><msub id="S3.E8.m1.1.4"><mtext id="S3.E8.m1.1.4.2">FFN</mtext><mi id="S3.E8.m1.1.4.3">S</mi></msub><mrow id="S3.E8.m1.1.5"><mo id="S3.E8.m1.1.5.1" stretchy="false">(</mo><mrow id="S3.E8.m1.1.5.2"><mo id="S3.E8.m1.1.5.2.1" stretchy="false">(</mo><mn id="S3.E8.m1.1.5.2.2">1</mn><mo id="S3.E8.m1.1.5.2.3">âˆ’</mo><mtext id="S3.E8.m1.1.5.2.4">CAR</mtext><mrow id="S3.E8.m1.1.5.2.5"><mo id="S3.E8.m1.1.5.2.5.1" stretchy="false">(</mo><msub id="S3.E8.m1.1.5.2.5.2"><mi id="S3.E8.m1.1.5.2.5.2.2">x</mi><mi id="S3.E8.m1.1.5.2.5.2.3">t</mi></msub><mo id="S3.E8.m1.1.5.2.5.3" stretchy="false">)</mo></mrow><mo id="S3.E8.m1.1.5.2.6" stretchy="false">)</mo></mrow><mo id="S3.E8.m1.1.5.3" lspace="0em" rspace="0.167em">.</mo><msub id="S3.E8.m1.1.5.4"><mi id="S3.E8.m1.1.5.4.2">x</mi><mi id="S3.E8.m1.1.5.4.3">t</mi></msub><mo id="S3.E8.m1.1.5.5" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\textbf{h}_{S}(x_{t})=\text{FFN}_{S}((1-\text{CAR}(x_{t})).x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.1d">h start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = FFN start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( ( 1 - CAR ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) . italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p4.9">where <math alttext="G" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">G</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_G</annotation></semantics></math> denotes language-general and <math alttext="S" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_S</annotation></semantics></math> language-specific.
<math alttext="\text{FFN}_{G}" class="ltx_Math" display="inline" id="S3.SS3.p4.3.m3.1"><semantics id="S3.SS3.p4.3.m3.1a"><msub id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mtext id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2a.cmml">FFN</mtext><mi id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml">G</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.2a.cmml" xref="S3.SS3.p4.3.m3.1.1.2"><mtext id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2">FFN</mtext></ci><ci id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3">ğº</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\text{FFN}_{G}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.3.m3.1d">FFN start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\text{FFN}_{S}" class="ltx_Math" display="inline" id="S3.SS3.p4.4.m4.1"><semantics id="S3.SS3.p4.4.m4.1a"><msub id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mtext id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2a.cmml">FFN</mtext><mi id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2a.cmml" xref="S3.SS3.p4.4.m4.1.1.2"><mtext id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2">FFN</mtext></ci><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\text{FFN}_{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.4.m4.1d">FFN start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT</annotation></semantics></math> are language-general and language-specific neurons, respectively.
<math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p4.5.m5.1"><semantics id="S3.SS3.p4.5.m5.1a"><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.5.m5.1d">italic_N</annotation></semantics></math> is the total number of language-specific neurons in a FFN layers for a language pair.
<math alttext="M" class="ltx_Math" display="inline" id="S3.SS3.p4.6.m6.1"><semantics id="S3.SS3.p4.6.m6.1a"><mi id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><ci id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.6.m6.1d">italic_M</annotation></semantics></math> is the total number of language-general neurons in a FFN layers.
We combine <math alttext="\text{FFN}_{G}" class="ltx_Math" display="inline" id="S3.SS3.p4.7.m7.1"><semantics id="S3.SS3.p4.7.m7.1a"><msub id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml"><mtext id="S3.SS3.p4.7.m7.1.1.2" xref="S3.SS3.p4.7.m7.1.1.2a.cmml">FFN</mtext><mi id="S3.SS3.p4.7.m7.1.1.3" xref="S3.SS3.p4.7.m7.1.1.3.cmml">G</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><apply id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.7.m7.1.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p4.7.m7.1.1.2a.cmml" xref="S3.SS3.p4.7.m7.1.1.2"><mtext id="S3.SS3.p4.7.m7.1.1.2.cmml" xref="S3.SS3.p4.7.m7.1.1.2">FFN</mtext></ci><ci id="S3.SS3.p4.7.m7.1.1.3.cmml" xref="S3.SS3.p4.7.m7.1.1.3">ğº</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">\text{FFN}_{G}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.7.m7.1d">FFN start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\text{FFN}_{S}" class="ltx_Math" display="inline" id="S3.SS3.p4.8.m8.1"><semantics id="S3.SS3.p4.8.m8.1a"><msub id="S3.SS3.p4.8.m8.1.1" xref="S3.SS3.p4.8.m8.1.1.cmml"><mtext id="S3.SS3.p4.8.m8.1.1.2" xref="S3.SS3.p4.8.m8.1.1.2a.cmml">FFN</mtext><mi id="S3.SS3.p4.8.m8.1.1.3" xref="S3.SS3.p4.8.m8.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.8.m8.1b"><apply id="S3.SS3.p4.8.m8.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.8.m8.1.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p4.8.m8.1.1.2a.cmml" xref="S3.SS3.p4.8.m8.1.1.2"><mtext id="S3.SS3.p4.8.m8.1.1.2.cmml" xref="S3.SS3.p4.8.m8.1.1.2">FFN</mtext></ci><ci id="S3.SS3.p4.8.m8.1.1.3.cmml" xref="S3.SS3.p4.8.m8.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.8.m8.1c">\text{FFN}_{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.8.m8.1d">FFN start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT</annotation></semantics></math> to alleviate the parameter interference.
The fusion output <math alttext="\textbf{H}^{f}" class="ltx_Math" display="inline" id="S3.SS3.p4.9.m9.1"><semantics id="S3.SS3.p4.9.m9.1a"><msup id="S3.SS3.p4.9.m9.1.1" xref="S3.SS3.p4.9.m9.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p4.9.m9.1.1.2" xref="S3.SS3.p4.9.m9.1.1.2a.cmml">H</mtext><mi id="S3.SS3.p4.9.m9.1.1.3" xref="S3.SS3.p4.9.m9.1.1.3.cmml">f</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.9.m9.1b"><apply id="S3.SS3.p4.9.m9.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.9.m9.1.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1">superscript</csymbol><ci id="S3.SS3.p4.9.m9.1.1.2a.cmml" xref="S3.SS3.p4.9.m9.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p4.9.m9.1.1.2.cmml" xref="S3.SS3.p4.9.m9.1.1.2">H</mtext></ci><ci id="S3.SS3.p4.9.m9.1.1.3.cmml" xref="S3.SS3.p4.9.m9.1.1.3">ğ‘“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.9.m9.1c">\textbf{H}^{f}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.9.m9.1d">H start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT</annotation></semantics></math> is given by:</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{H}^{f}=\textbf{h}_{G}(x_{t})+\textbf{h}_{S}(x_{t})" class="ltx_Math" display="block" id="S3.E9.m1.2"><semantics id="S3.E9.m1.2a"><mrow id="S3.E9.m1.2.2" xref="S3.E9.m1.2.2.cmml"><msup id="S3.E9.m1.2.2.4" xref="S3.E9.m1.2.2.4.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E9.m1.2.2.4.2" xref="S3.E9.m1.2.2.4.2a.cmml">H</mtext><mi id="S3.E9.m1.2.2.4.3" xref="S3.E9.m1.2.2.4.3.cmml">f</mi></msup><mo id="S3.E9.m1.2.2.3" xref="S3.E9.m1.2.2.3.cmml">=</mo><mrow id="S3.E9.m1.2.2.2" xref="S3.E9.m1.2.2.2.cmml"><mrow id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><msub id="S3.E9.m1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E9.m1.1.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1.3.2a.cmml">h</mtext><mi id="S3.E9.m1.1.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.3.3.cmml">G</mi></msub><mo id="S3.E9.m1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E9.m1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.E9.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E9.m1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E9.m1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E9.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E9.m1.2.2.2.3" xref="S3.E9.m1.2.2.2.3.cmml">+</mo><mrow id="S3.E9.m1.2.2.2.2" xref="S3.E9.m1.2.2.2.2.cmml"><msub id="S3.E9.m1.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E9.m1.2.2.2.2.3.2" xref="S3.E9.m1.2.2.2.2.3.2a.cmml">h</mtext><mi id="S3.E9.m1.2.2.2.2.3.3" xref="S3.E9.m1.2.2.2.2.3.3.cmml">S</mi></msub><mo id="S3.E9.m1.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.cmml">â¢</mo><mrow id="S3.E9.m1.2.2.2.2.1.1" xref="S3.E9.m1.2.2.2.2.1.1.1.cmml"><mo id="S3.E9.m1.2.2.2.2.1.1.2" stretchy="false" xref="S3.E9.m1.2.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E9.m1.2.2.2.2.1.1.1" xref="S3.E9.m1.2.2.2.2.1.1.1.cmml"><mi id="S3.E9.m1.2.2.2.2.1.1.1.2" xref="S3.E9.m1.2.2.2.2.1.1.1.2.cmml">x</mi><mi id="S3.E9.m1.2.2.2.2.1.1.1.3" xref="S3.E9.m1.2.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S3.E9.m1.2.2.2.2.1.1.3" stretchy="false" xref="S3.E9.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.2b"><apply id="S3.E9.m1.2.2.cmml" xref="S3.E9.m1.2.2"><eq id="S3.E9.m1.2.2.3.cmml" xref="S3.E9.m1.2.2.3"></eq><apply id="S3.E9.m1.2.2.4.cmml" xref="S3.E9.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.4.1.cmml" xref="S3.E9.m1.2.2.4">superscript</csymbol><ci id="S3.E9.m1.2.2.4.2a.cmml" xref="S3.E9.m1.2.2.4.2"><mtext class="ltx_mathvariant_bold" id="S3.E9.m1.2.2.4.2.cmml" xref="S3.E9.m1.2.2.4.2">H</mtext></ci><ci id="S3.E9.m1.2.2.4.3.cmml" xref="S3.E9.m1.2.2.4.3">ğ‘“</ci></apply><apply id="S3.E9.m1.2.2.2.cmml" xref="S3.E9.m1.2.2.2"><plus id="S3.E9.m1.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.3"></plus><apply id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1"><times id="S3.E9.m1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2"></times><apply id="S3.E9.m1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.2a.cmml" xref="S3.E9.m1.1.1.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E9.m1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.3.2">h</mtext></ci><ci id="S3.E9.m1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.3.3">ğº</ci></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply><apply id="S3.E9.m1.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2"><times id="S3.E9.m1.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2"></times><apply id="S3.E9.m1.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.2.3.1.cmml" xref="S3.E9.m1.2.2.2.2.3">subscript</csymbol><ci id="S3.E9.m1.2.2.2.2.3.2a.cmml" xref="S3.E9.m1.2.2.2.2.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E9.m1.2.2.2.2.3.2.cmml" xref="S3.E9.m1.2.2.2.2.3.2">h</mtext></ci><ci id="S3.E9.m1.2.2.2.2.3.3.cmml" xref="S3.E9.m1.2.2.2.2.3.3">ğ‘†</ci></apply><apply id="S3.E9.m1.2.2.2.2.1.1.1.cmml" xref="S3.E9.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E9.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E9.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E9.m1.2.2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.E9.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E9.m1.2.2.2.2.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.2c">\textbf{H}^{f}=\textbf{h}_{G}(x_{t})+\textbf{h}_{S}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E9.m1.2d">H start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT = h start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) + h start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p5.5">Uppercase <math alttext="\textbf{H}^{f}" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1"><semantics id="S3.SS3.p5.1.m1.1a"><msup id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2a.cmml">H</mtext><mi id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml">f</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p5.1.m1.1.1.2a.cmml" xref="S3.SS3.p5.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">H</mtext></ci><ci id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3">ğ‘“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">\textbf{H}^{f}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.1.m1.1d">H start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT</annotation></semantics></math> is just a notation here for the addition result of <math alttext="\textbf{h}_{G}(x_{t})" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.1"><semantics id="S3.SS3.p5.2.m2.1a"><mrow id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml"><msub id="S3.SS3.p5.2.m2.1.1.3" xref="S3.SS3.p5.2.m2.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.2.m2.1.1.3.2" xref="S3.SS3.p5.2.m2.1.1.3.2a.cmml">h</mtext><mi id="S3.SS3.p5.2.m2.1.1.3.3" xref="S3.SS3.p5.2.m2.1.1.3.3.cmml">G</mi></msub><mo id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p5.2.m2.1.1.1.1" xref="S3.SS3.p5.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS3.p5.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS3.p5.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p5.2.m2.1.1.1.1.1" xref="S3.SS3.p5.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.2.m2.1.1.1.1.1.2" xref="S3.SS3.p5.2.m2.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p5.2.m2.1.1.1.1.1.3" xref="S3.SS3.p5.2.m2.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS3.p5.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS3.p5.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1"><times id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2"></times><apply id="S3.SS3.p5.2.m2.1.1.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.3.1.cmml" xref="S3.SS3.p5.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS3.p5.2.m2.1.1.3.2a.cmml" xref="S3.SS3.p5.2.m2.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.2.m2.1.1.3.2.cmml" xref="S3.SS3.p5.2.m2.1.1.3.2">h</mtext></ci><ci id="S3.SS3.p5.2.m2.1.1.3.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3">ğº</ci></apply><apply id="S3.SS3.p5.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p5.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.2.m2.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">\textbf{h}_{G}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.2.m2.1d">h start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="\textbf{h}_{S}(x_{t})" class="ltx_Math" display="inline" id="S3.SS3.p5.3.m3.1"><semantics id="S3.SS3.p5.3.m3.1a"><mrow id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml"><msub id="S3.SS3.p5.3.m3.1.1.3" xref="S3.SS3.p5.3.m3.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.3.m3.1.1.3.2" xref="S3.SS3.p5.3.m3.1.1.3.2a.cmml">h</mtext><mi id="S3.SS3.p5.3.m3.1.1.3.3" xref="S3.SS3.p5.3.m3.1.1.3.3.cmml">S</mi></msub><mo id="S3.SS3.p5.3.m3.1.1.2" xref="S3.SS3.p5.3.m3.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p5.3.m3.1.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS3.p5.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS3.p5.3.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p5.3.m3.1.1.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.3.m3.1.1.1.1.1.2" xref="S3.SS3.p5.3.m3.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p5.3.m3.1.1.1.1.1.3" xref="S3.SS3.p5.3.m3.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS3.p5.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS3.p5.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><apply id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1"><times id="S3.SS3.p5.3.m3.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1.2"></times><apply id="S3.SS3.p5.3.m3.1.1.3.cmml" xref="S3.SS3.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.1.1.3.1.cmml" xref="S3.SS3.p5.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.p5.3.m3.1.1.3.2a.cmml" xref="S3.SS3.p5.3.m3.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.3.m3.1.1.3.2.cmml" xref="S3.SS3.p5.3.m3.1.1.3.2">h</mtext></ci><ci id="S3.SS3.p5.3.m3.1.1.3.3.cmml" xref="S3.SS3.p5.3.m3.1.1.3.3">ğ‘†</ci></apply><apply id="S3.SS3.p5.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p5.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">\textbf{h}_{S}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.3.m3.1d">h start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>, which is only used to distinguish it from <math alttext="\textbf{h}_{G}(x_{t})" class="ltx_Math" display="inline" id="S3.SS3.p5.4.m4.1"><semantics id="S3.SS3.p5.4.m4.1a"><mrow id="S3.SS3.p5.4.m4.1.1" xref="S3.SS3.p5.4.m4.1.1.cmml"><msub id="S3.SS3.p5.4.m4.1.1.3" xref="S3.SS3.p5.4.m4.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.4.m4.1.1.3.2" xref="S3.SS3.p5.4.m4.1.1.3.2a.cmml">h</mtext><mi id="S3.SS3.p5.4.m4.1.1.3.3" xref="S3.SS3.p5.4.m4.1.1.3.3.cmml">G</mi></msub><mo id="S3.SS3.p5.4.m4.1.1.2" xref="S3.SS3.p5.4.m4.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p5.4.m4.1.1.1.1" xref="S3.SS3.p5.4.m4.1.1.1.1.1.cmml"><mo id="S3.SS3.p5.4.m4.1.1.1.1.2" stretchy="false" xref="S3.SS3.p5.4.m4.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p5.4.m4.1.1.1.1.1" xref="S3.SS3.p5.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.4.m4.1.1.1.1.1.2" xref="S3.SS3.p5.4.m4.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p5.4.m4.1.1.1.1.1.3" xref="S3.SS3.p5.4.m4.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS3.p5.4.m4.1.1.1.1.3" stretchy="false" xref="S3.SS3.p5.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m4.1b"><apply id="S3.SS3.p5.4.m4.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1"><times id="S3.SS3.p5.4.m4.1.1.2.cmml" xref="S3.SS3.p5.4.m4.1.1.2"></times><apply id="S3.SS3.p5.4.m4.1.1.3.cmml" xref="S3.SS3.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.4.m4.1.1.3.1.cmml" xref="S3.SS3.p5.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS3.p5.4.m4.1.1.3.2a.cmml" xref="S3.SS3.p5.4.m4.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.4.m4.1.1.3.2.cmml" xref="S3.SS3.p5.4.m4.1.1.3.2">h</mtext></ci><ci id="S3.SS3.p5.4.m4.1.1.3.3.cmml" xref="S3.SS3.p5.4.m4.1.1.3.3">ğº</ci></apply><apply id="S3.SS3.p5.4.m4.1.1.1.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.4.m4.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p5.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.4.m4.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.1c">\textbf{h}_{G}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.4.m4.1d">h start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="\textbf{h}_{S}(x_{t})" class="ltx_Math" display="inline" id="S3.SS3.p5.5.m5.1"><semantics id="S3.SS3.p5.5.m5.1a"><mrow id="S3.SS3.p5.5.m5.1.1" xref="S3.SS3.p5.5.m5.1.1.cmml"><msub id="S3.SS3.p5.5.m5.1.1.3" xref="S3.SS3.p5.5.m5.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.5.m5.1.1.3.2" xref="S3.SS3.p5.5.m5.1.1.3.2a.cmml">h</mtext><mi id="S3.SS3.p5.5.m5.1.1.3.3" xref="S3.SS3.p5.5.m5.1.1.3.3.cmml">S</mi></msub><mo id="S3.SS3.p5.5.m5.1.1.2" xref="S3.SS3.p5.5.m5.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p5.5.m5.1.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.1.1.cmml"><mo id="S3.SS3.p5.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS3.p5.5.m5.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p5.5.m5.1.1.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.5.m5.1.1.1.1.1.2" xref="S3.SS3.p5.5.m5.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p5.5.m5.1.1.1.1.1.3" xref="S3.SS3.p5.5.m5.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS3.p5.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS3.p5.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m5.1b"><apply id="S3.SS3.p5.5.m5.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1"><times id="S3.SS3.p5.5.m5.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.2"></times><apply id="S3.SS3.p5.5.m5.1.1.3.cmml" xref="S3.SS3.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.3.1.cmml" xref="S3.SS3.p5.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS3.p5.5.m5.1.1.3.2a.cmml" xref="S3.SS3.p5.5.m5.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS3.p5.5.m5.1.1.3.2.cmml" xref="S3.SS3.p5.5.m5.1.1.3.2">h</mtext></ci><ci id="S3.SS3.p5.5.m5.1.1.3.3.cmml" xref="S3.SS3.p5.5.m5.1.1.3.3">ğ‘†</ci></apply><apply id="S3.SS3.p5.5.m5.1.1.1.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p5.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.1c">\textbf{h}_{S}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.5.m5.1d">h start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>.
During the finetuning stage, we only update the parameters of language-general and language-specific neurons for a specific language pair and freeze other parameters of LLMs.
</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We conducted extensive experiments with involving multiple models across various translation directions to evaluate the proposed framework against a set of strong baselines.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">During the finetuning stage, we selected 5 language pairs to tune LLMs.
All the original training data came from the recent WMT general translation
track.
All data followed the license that can be freely used for research purposes.
In addition, we used the way in <cite class="ltx_cite ltx_citemacro_cite">Huang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib16" title="">2023</a>)</cite> to clean training data.
All datasets originated from the Workshop on Machine Translation (WMT)<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.statmt.org/</span></span></span>.
Specifically, we extracted 200,000 sentence pairs for each translation direction. In addition, we employed ten translation instruction finetuning templates sourced from FLAN v2 <cite class="ltx_cite ltx_citemacro_cite">Longpre etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib21" title="">2023</a>)</cite>, adopting them to our parallel data. Each sentence pair from parallel corpus was randomly assigned one translation instruction template.
We assessed our modelâ€™s performance using established test sets like WMT16, WMT14 and OPUS-100.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:411.9pt;height:131.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-48.1pt,15.3pt) scale(0.810722423302273,0.810722423302273) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.2.1">Params</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.1.1.1.1.3">WMT16</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.1.1.1.1.4">WMT16</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.1.1.1.1.5">WMT14</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.1.1.1.1.6">OPUS-100</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S4.T1.1.1.1.1.7">OPUS-100</th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1.8"></th>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S4.T1.1.1.2.2.1">en-de</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S4.T1.1.1.2.2.2">de-en</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S4.T1.1.1.2.2.3">en-it</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S4.T1.1.1.2.2.4">it-en</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S4.T1.1.1.2.2.5">en-fr</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S4.T1.1.1.2.2.6">fr-en</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S4.T1.1.1.2.2.7">en-ar</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S4.T1.1.1.2.2.8">ar-en</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S4.T1.1.1.2.2.9">en-zh</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S4.T1.1.1.2.2.10">zh-en</th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T1.1.1.2.2.11"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.3.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.1.3.1.1">Full finetuning</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.1.3.1.2">7B</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.3.1.3">16.12</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.1.3.1.4">19.39</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.3.1.5">17.98</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.1.3.1.6">24.18</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.3.1.7">29.13</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.1.3.1.8">28.15</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.3.1.9">15.40</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.1.3.1.10">28.83</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.3.1.11">20.87</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.3.1.12">25.52</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.1.3.1.13"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.4.2.1">0-shot</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.4.2.2">â€”â€”</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.2.3">11.71</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.4.2.4">17.82</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.2.5">8.07</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.4.2.6">16.05</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.2.7">19.58</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.4.2.8">18.88</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.2.9">9.46</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.4.2.10">26.37</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.2.11">6.14</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.2.12">22.02</td>
<td class="ltx_td" id="S4.T1.1.1.4.2.13"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.5.3.1">In-context</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.5.3.2">â€”â€”</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.3.3">11.49</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.5.3.4">14.57</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.3.5">9.80</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.5.3.6">13.12</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.3.7">18.74</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.5.3.8">15.29</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.3.9">10.01</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.5.3.10">21.24</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.3.11">6.83</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.3.12">17.19</td>
<td class="ltx_td" id="S4.T1.1.1.5.3.13"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.6.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.6.4.1">Adapter</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.6.4.2">806M</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.4.3">15.61</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.6.4.4">19.67</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.4.5">15.25</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.6.4.6">23.63</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.4.7">28.08</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.6.4.8">27.26</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.4.9">11.28</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.6.4.10">28.07</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.4.11">15.18</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.4.12">25.05</td>
<td class="ltx_td" id="S4.T1.1.1.6.4.13"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.7.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.7.5.1">LoRA</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.7.5.2">31M</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.5.3">15.12</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.7.5.4">19.03</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.5.5">14.82</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.7.5.6">22.85</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.5.7">27.16</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.7.5.8">27.72</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.5.9">11.15</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.7.5.10">27.74</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.5.11">15.72</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.5.12">25.12</td>
<td class="ltx_td" id="S4.T1.1.1.7.5.13"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.8.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.8.6.1">Adapter-LoRA</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.8.6.2">806M</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.6.3">16.31</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.8.6.4">20.23</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.6.5">15.83</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.8.6.6">23.82</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.6.7">28.05</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.8.6.8">28.22</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.6.9">11.78</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.1.8.6.10">28.46</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.6.11">16.32</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.6.12">25.61</td>
<td class="ltx_td" id="S4.T1.1.1.8.6.13"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.9.7">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.1.1.9.7.1">LANDeRMT (Ours)</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.1.1.9.7.2">805M</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.9.7.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.3.1">18.85</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.1.1.9.7.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.4.1">22.03</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.9.7.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.5.1">19.82</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.1.1.9.7.6"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.6.1">25.99</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.9.7.7"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.7.1">31.91</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.1.1.9.7.8"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.8.1">30.55</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.9.7.9"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.9.1">16.97</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.1.1.9.7.10"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.10.1">31.44</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.9.7.11"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.11.1">22.47</span></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.9.7.12"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.9.7.12.1">28.11</span></td>
<td class="ltx_td ltx_border_b" id="S4.T1.1.1.9.7.13"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>BLEU scores on the 10 language pairs for xx-to-English and English-to-xx translation.
The highest score on each translation direction is highlighted in bold.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Settings and Baselines</h3>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Settings</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.2">In the language-pair-relevant layers detection phase, we set <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p1.1.m1.1d">italic_k</annotation></semantics></math> to 4.
We executed a freezing operation on the parameters of the remaining layers while exclusively finetuning the parameters within the chosen four layers.
In the language-aware neurons evaluation phase, we categorized the parameters within the selected layer into language-general and language-specific parameters, setting <math alttext="\epsilon" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S4.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.2.m2.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p1.2.m2.1d">italic_Ïµ</annotation></semantics></math> to 0.9.
During the model finetuning stage, we configured the fintuning hytper-parameters as follows: the finetuning epoch was set to 1, the number of language pairs was specified as 10, the number of iterations per epoch for each language pair was set to 12,500, the batch size was set 8, and the AdamW optimizer was employed.
Additionally, the learning rate was set to 5e-5.
Furthermore, we introduced a gradient accumulation operation, updating the model parameters every 10 iterations to enhance convergence.
The LLMs used for our experiments are BLOOM-7b1 <cite class="ltx_cite ltx_citemacro_cite">Scao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib27" title="">2022</a>)</cite> and Baichuan2-7B-Base <cite class="ltx_cite ltx_citemacro_cite">Yang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib36" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Baselines</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">We compared our approach to the following strong baselines.</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">0-shot: This approach uses instructions directly to make the model perform downstream tasks without providing any in-context demonstrations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">In-context <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib38" title="">2023</a>)</cite>: This is a training-free approach that allows the LLMs to perform downstream tasks. In particular, we use 5 random shots as in-context demonstrations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Adapter: This method facilitates the acquisition of new knowledge by incorporating additional adapter modules following model-specific layers, effectively addressing the issue of catastrophic forgetting.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib15" title="">2022</a>)</cite>: This method efficiently finetunes a model for a downstream task by converting certain structures into low-rank matrices and subsequently finetuning them to suit the task.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">Adapter-LoRA <cite class="ltx_cite ltx_citemacro_cite">Alves etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#bib.bib1" title="">2023</a>)</cite>: It uses adapter-based finetuning with LoRA, which matches the performance of traditional finetuning while reducing the number of training parameters.
</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Main Results</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">For evaluating translation performance, we used two automatic evaluation metrics sacreBLEU<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>BLEU+case.mixed+numrefs.1+smooth.none+tok.13a
<br class="ltx_break"/>+version.2.2.1</span></span></span>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Comparison with ICL</span>
In order to examine the effectiveness of our proposed method, we evaluated LANDeRMT on various test set and multiple language pairs.
As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.T1" title="Table 1 â€£ 4.1 Dataset â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>, our method can use new parallel training data to enhance the translation ability of LLMs.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">Comparison with finetuning baselines</span>
Compared to the baselines, our method is the best for all translation directions in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.T1" title="Table 1 â€£ 4.1 Dataset â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.
For relatively low-resource language pairs, such as English-Chinese, our method achieves significant improvements over baselines.
Compared to the full parameter finetuning approach, our method has a clear parametric advantage since it only fine-tunes parameters in four layers in the model.
Our approach exhibits a notable advantage in terms of the number of parameters to be tuned.
In comparison to other efficient finetuning methods, e.g., the adapter baseline approach, our method finetunes basically the same number of parameters as it.
However, our method is much better than the adapter-based approach in terms of translation quality.
</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:195.1pt;height:72.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-23.2pt,8.7pt) scale(0.807609366734688,0.807609366734688) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T2.1.1.1.1.1"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.2">en-fr</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.3">fr-en</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.4">en-zh</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.5">zh-en</th>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.2.1">Layers</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.2.2">27.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.2.3">27.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.2.4">22.81</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.2.5">24.28</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.3.3">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.3.1">LANDeRMT-LS</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.3.2">22.27</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.3.3">21.46</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.3.4">16.18</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.3.5">23.16</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4.4">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4.1">LANDeRMT-LG</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4.2">28.15</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4.3">27.83</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4.4">23.52</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4.5">25.08</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.5.5.1">LANDeRMT (Ours)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.5.5.2">31.91</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.5.5.3">30.55</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.5.5.4">22.47</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.5.5.5">28.11</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Translation results achieved by finetuning the BLOOM-7b1 model using different ablation experiment settings.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">In the ablation experiments, we employed four distinct experimental setups, denoted as Layers, LANDeRMT-LS, LANDeRMT-LG, and LANDeRMT.
The Layers configuration finetuned all parameters of the lanuage-pair-relevant layer for each language direction.
In the LANDeRMT-LS setup, we finetuned only the language-specific parameters of the selected layers, with each language direction adjusting parameters specific to that language direction.
The LANDeRMT-LG setup focused on finetuning only the language-general parameters of the selected layers, with all language directions adjusting the same language-general parameters.
The LANDeRMT method, proposed in this paper, finetuned both the language-general parameters and language-sepecific parameters to each language pair.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.T2" title="Table 2 â€£ 4.4 Ablation Study â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, we observe that LANDeRMT-LS underperforms the Layers method, likely due to its smaller parameter size, which constitutes only 10% of the parameters in Layers.
In details, we can observe that LANDeRMT achieves a 4.28 BLEU improvement over Layers in en-fr, a 9.64 BLEU improvement over LANDeRMT-LS, and a 3.76 BLEU improvement over LANDeRMT-LG.
These experiments demonstrate the effectiveness of CAR.
Surprisingly, LANDeRMT-LG achieves better results despite finetuning fewer parameters than Layers. This suggests that our selection of language-general parameters effectively captures language alignment, significantly improving translation performance.
However, finetuning the language-general parameters alone, as in LANDeRMT-LG, is insufficient to fully grasp language-specific information.</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<p class="ltx_p ltx_align_center ltx_align_center" id="S4.F3.1"><span class="ltx_text" id="S4.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="240" id="S4.F3.1.1.g1" src="x3.png" width="320"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>BLEU scores improvement achieved on other language pairs using the LANDeRMT method for finetuning only one language pair on the BLOOM-7b model.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Analysis</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>LANDeRMT Improves Transfer Learning across Languages</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We examined the transfer learning ability of LANDeRMT in different translation directions.
We finetuned the model using only parallel data from a particular language direction. In other words, we finetuned only the language-general and language-specific parameters for that language pair, and then observed the performance of the model in other language directions.
The Y-axis of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S4.F3" title="Figure 3 â€£ 4.4 Ablation Study â€£ 4 Experiments â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> shows the single language direction that we have finetuned, and the X-axis shows the language direction of the test data, which is plotted as the improvement in the modelâ€™s translation performance before and after the finetuning.
Since BLOOM-7b is a model that is not mainly trained on a parallel corpus, its translation performance before finetuning is poor, which is the reason for the large improvement in the modelâ€™s translation performance.
We observe that when finetuning one language direction, the results of other language directions can also be significantly improved, which proves that our method is effective in facilitating transfer learning between languages.
However, there are some exceptions.
For example, when finetuning the de-en direction, the ar-en direction does not improve significantly or even decrease to some extent.
We believe that this may be due to the fact that Arabic belongs to a different language family from German, and that the distance between the languages is far, making it difficult for cross-lingual transfer learning.</p>
</div>
<figure class="ltx_figure" id="S5.F4">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F4.1"><span class="ltx_text" id="S5.F4.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="228" id="S5.F4.1.1.g1" src="x4.png" width="304"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Layer-wise average activation across various language pair settings in the BLOOM-7b model.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F5.1"><span class="ltx_text" id="S5.F5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="228" id="S5.F5.1.1.g1" src="x5.png" width="304"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Layer-wise delta average activation across various language pair settings in the BLOOM-7b model.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Language-Pair-Relevant Layers for Different Language Pairs</h3>
<figure class="ltx_figure" id="S5.F6">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F6.1"><span class="ltx_text" id="S5.F6.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="164" id="S5.F6.1.1.g1" src="x6.png" width="492"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Layer-wise average language-general neuron awareness scores across various language settings in the BLOOM-7b1 model.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F7">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F7.1"><span class="ltx_text" id="S5.F7.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="164" id="S5.F7.1.1.g1" src="x7.png" width="492"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Layer-wise average language-specific neuron awareness scores across various language settings in the BLOOM-7b1 model.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F4" title="Figure 4 â€£ 5.1 LANDeRMT Improves Transfer Learning across Languages â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the variation in the average activation values across each layer of the model when inputting translation instructions generated using diverse language pairs.
It is noteworthy that the average activation values of various language pairs exhibit a similar trend of change, particularly in the shallower layers of the model.
Moreover, when interchanging the source and target languages within language pairs, the average activation values consistently follow a more uniform trend, as evidenced by the translation directions of ar-en and en-ar.
This indicate that not only the semantic remains consistent between the source and target languages within the same language pair, but the identical semantic is still existing on across different language pairs.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The absolute value of activation value changes from layer to layer can be calculated by using the average activation values of each layer, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F5" title="Figure 5 â€£ 5.1 LANDeRMT Improves Transfer Learning across Languages â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>. We can find that early and late-stage layers in the model harbor information pertaining to language pairs.
For instance, layers 6 and 7, as well as the final layers, exhibit higher absolute values of activation value changes.
Furthermore, an observation can be made that the early layers of the model encapsulate language pair-related information that is language pair-general, displaying a substantial overlap across different language pairs.
Conversely, the layers towards the end of the model contain language pair-related information that is language pair-specific, characterized by a diminished overlap among different language pairs.</p>
</div>
<figure class="ltx_figure" id="S5.F8">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F8.1"><span class="ltx_text" id="S5.F8.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="152" id="S5.F8.1.1.g1" src="x8.png" width="456"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Layer-wise average neuron awareness scores across various language settings in the BLOOM-7b model.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Neuron Awareness for Different Languages: General and Specific</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The main idea of our proposed method is to distinguish language-general from language-specific neurons.
To verify whether this goal has been achieved, we conducted the following experiments.
As mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S3.SS2" title="3.2 Evaluating the Language Awareness of Neurons â€£ 3 Methodology â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we categorize neurons based on their awareness scores, and we observed significant differences in the awareness scores of language-general and language-specific neurons across layers requiring fine-tuning.
We illustrate this in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F6" title="Figure 6 â€£ 5.2 Language-Pair-Relevant Layers for Different Language Pairs â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F7" title="Figure 7 â€£ 5.2 Language-Pair-Relevant Layers for Different Language Pairs â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>.
We can find that for almost all language pairs, there are noticeable differences in awareness scores between certain intermediate layers and the final layers.
This indicates that our categorization of neurons based on layers accurately reflects the practical scenario.
It also suggests that language-general and language-specific neurons exhibit varying levels of importance across different layers of the model, particularly in layers targeted for finetuning.
Such differences likely stem from the distinct roles that language-general and language-specific neurons play in capturing and processing language-specific and language-general information.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Neuron Awareness for Different Language Pairs</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F8" title="Figure 8 â€£ 5.2 Language-Pair-Relevant Layers for Different Language Pairs â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a> depicts the average neuron awareness scores for each layer of the model, computed using TE with monolingual data inputs in various language pairs.
The employed multidirectionally aligned monolingual data ensures semantic one-to-one correspondence.
The results show consistent trends in neuron awareness scores across different language pairs, particularly in the intermediate layers, indicating the modelâ€™s ability to capture semantic information consistently across language pairs.
Additionally, related languages such as Spanish, English, and French exhibit more similar trends, supporting our hypothesis.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">Furthermore, we observed that language-specific neurons tend to have higher awareness scores in the last layers of the model.
This suggests a heightened focus on encoding and retaining language-specific semantic information during the output phase, particularly in deeper layers.
Notably, language-specific neurons related to English consistently exhibit high awareness scores across all language pairs.
This can be attributed to the prevalence of English data during the modelâ€™s pre-training phase, indicating robust representation and preservation of English language-specific information throughout the model.
</p>
</div>
<figure class="ltx_figure" id="S5.F9">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F9.1"><span class="ltx_text" id="S5.F9.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="276" id="S5.F9.1.1.g1" src="x9.png" width="276"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Comparison of BLEU scores on the OPUS 100 test set across ten language directions for finetuning the Baichuan-7b-base model using adapter-LoRA and our proposed method LANDeRMT.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Results on Other LLMs</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">We also finetuned the Baichuan-7B-Base model using the LANDeRMT method and compared it with the adapter-LoRA finetuning approach.
Results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F9" title="Figure 9 â€£ 5.4 Neuron Awareness for Different Language Pairs â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a>.
We observe that across the 10 language directions selected our proposed method outperforms the adapter-LoRA finetuning method.
This demonstrates the applicability of the LANDeRMT method across different models, achieving optimal results not only in the BLOOM-7b models but also in the Baichuan model.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Effect of Hyperparameter <math alttext="k" class="ltx_Math" display="inline" id="S5.SS6.1.m1.1"><semantics id="S5.SS6.1.m1.1b"><mi id="S5.SS6.1.m1.1.1" xref="S5.SS6.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.1.m1.1c"><ci id="S5.SS6.1.m1.1.1.cmml" xref="S5.SS6.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS6.1.m1.1e">italic_k</annotation></semantics></math>
</h3>
<figure class="ltx_figure" id="S5.F10">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F10.1"><span class="ltx_text" id="S5.F10.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="210" id="S5.F10.1.1.g1" src="x10.png" width="350"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Mean BLEU scores for all language directions at different <math alttext="k" class="ltx_Math" display="inline" id="S5.F10.3.m1.1"><semantics id="S5.F10.3.m1.1b"><mi id="S5.F10.3.m1.1.1" xref="S5.F10.3.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F10.3.m1.1c"><ci id="S5.F10.3.m1.1.1.cmml" xref="S5.F10.3.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F10.3.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.F10.3.m1.1e">italic_k</annotation></semantics></math> value settings.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.5">When the relation of layers for different languages is determined, the number of language pairs associated with each layer can be adjusted according to k.
When <math alttext="k" class="ltx_Math" display="inline" id="S5.SS6.p1.1.m1.1"><semantics id="S5.SS6.p1.1.m1.1a"><mi id="S5.SS6.p1.1.m1.1.1" xref="S5.SS6.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p1.1.m1.1b"><ci id="S5.SS6.p1.1.m1.1.1.cmml" xref="S5.SS6.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS6.p1.1.m1.1d">italic_k</annotation></semantics></math> = 30, the threshold is max, so all layers will be allocated to tune LLMs, and when k = 0, the threshold is 0 so none layers will be tuning for all language pairs just like the 0-shot ICL.
To better show the overall impact of the hyperparameter <math alttext="k" class="ltx_Math" display="inline" id="S5.SS6.p1.2.m2.1"><semantics id="S5.SS6.p1.2.m2.1a"><mi id="S5.SS6.p1.2.m2.1.1" xref="S5.SS6.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p1.2.m2.1b"><ci id="S5.SS6.p1.2.m2.1.1.cmml" xref="S5.SS6.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS6.p1.2.m2.1d">italic_k</annotation></semantics></math>, we vary it from 0 to 30 and the results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F10" title="Figure 10 â€£ 5.6 Effect of Hyperparameter ğ‘˜ â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a>.
As we can see, the translation performance of the proposed approach increases with the increment of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS6.p1.3.m3.1"><semantics id="S5.SS6.p1.3.m3.1a"><mi id="S5.SS6.p1.3.m3.1.1" xref="S5.SS6.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p1.3.m3.1b"><ci id="S5.SS6.p1.3.m3.1.1.cmml" xref="S5.SS6.p1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS6.p1.3.m3.1d">italic_k</annotation></semantics></math> and reach the best performance when <math alttext="k" class="ltx_Math" display="inline" id="S5.SS6.p1.4.m4.1"><semantics id="S5.SS6.p1.4.m4.1a"><mi id="S5.SS6.p1.4.m4.1.1" xref="S5.SS6.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p1.4.m4.1b"><ci id="S5.SS6.p1.4.m4.1.1.cmml" xref="S5.SS6.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS6.p1.4.m4.1d">italic_k</annotation></semantics></math> equals 4.
As <math alttext="k" class="ltx_Math" display="inline" id="S5.SS6.p1.5.m5.1"><semantics id="S5.SS6.p1.5.m5.1a"><mi id="S5.SS6.p1.5.m5.1.1" xref="S5.SS6.p1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p1.5.m5.1b"><ci id="S5.SS6.p1.5.m5.1.1.cmml" xref="S5.SS6.p1.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p1.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS6.p1.5.m5.1d">italic_k</annotation></semantics></math> continues to increase, the performance deteriorates, which indicates that the over-specific layers are bad at capturing the common language-pair-relevant alignment and will lead to performance degradation.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7 </span>Effect of Hyperparameter <math alttext="\epsilon" class="ltx_Math" display="inline" id="S5.SS7.1.m1.1"><semantics id="S5.SS7.1.m1.1b"><mi id="S5.SS7.1.m1.1.1" xref="S5.SS7.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.1.m1.1c"><ci id="S5.SS7.1.m1.1.1.cmml" xref="S5.SS7.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.1.m1.1d">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.1.m1.1e">italic_Ïµ</annotation></semantics></math>
</h3>
<figure class="ltx_figure" id="S5.F11">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F11.1"><span class="ltx_text" id="S5.F11.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="240" id="S5.F11.1.1.g1" src="x11.png" width="320"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Mean BLEU scores for all language directions at different <math alttext="\epsilon" class="ltx_Math" display="inline" id="S5.F11.3.m1.1"><semantics id="S5.F11.3.m1.1b"><mi id="S5.F11.3.m1.1.1" xref="S5.F11.3.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S5.F11.3.m1.1c"><ci id="S5.F11.3.m1.1.1.cmml" xref="S5.F11.3.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F11.3.m1.1d">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S5.F11.3.m1.1e">italic_Ïµ</annotation></semantics></math> value settings.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS7.p1">
<p class="ltx_p" id="S5.SS7.p1.1">We set several different sets of <math alttext="\epsilon" class="ltx_Math" display="inline" id="S5.SS7.p1.1.m1.1"><semantics id="S5.SS7.p1.1.m1.1a"><mi id="S5.SS7.p1.1.m1.1.1" xref="S5.SS7.p1.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.1.m1.1b"><ci id="S5.SS7.p1.1.m1.1.1.cmml" xref="S5.SS7.p1.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.1.m1.1d">italic_Ïµ</annotation></semantics></math> values to classify language-general neurons and language-specific neurons. The experimental outcomes are depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F11" title="Figure 11 â€£ 5.7 Effect of Hyperparameter Ïµ â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">11</span></a>. The figure reveals that the average value of all language-specific BLEU scores peaks when language-general neurons constitute 0.9 of the total neuron count. Below this threshold, the translation efficacy diminishes as the proportion of language-general neurons decreases. Conversely, exceeding the 0.9 threshold results in a decline in performance, with a higher proportion of language-general neurons leading to poorer results.</p>
</div>
<figure class="ltx_figure" id="S5.F12">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F12.1"><span class="ltx_text" id="S5.F12.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="240" id="S5.F12.1.1.g1" src="x12.png" width="320"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Clustering of representations generated by language-general neurons in the mlp.dense_h_to_4h structure in layer 10 of the BLOOM-7b1 model.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F13">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F13.1"><span class="ltx_text" id="S5.F13.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="240" id="S5.F13.1.1.g1" src="x13.png" width="320"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Clustering of representations generated by language-specific neurons in the mlp.dense_h_to_4h structure in layer 10 of the BLOOM-7b1 model.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.8 </span>Language Cluster</h3>
<div class="ltx_para" id="S5.SS8.p1">
<p class="ltx_p" id="S5.SS8.p1.1">The main idea of our proposed method is to let the language-general and the language-specific knowledge be captured by different neurons.
To validate whether the language-general and language-specific neurons of FFNs within LLMs general or specific language knowledge, we plotted the distribution of different neurons across various languages in <math alttext="10" class="ltx_Math" display="inline" id="S5.SS8.p1.1.m1.1"><semantics id="S5.SS8.p1.1.m1.1a"><mn id="S5.SS8.p1.1.m1.1.1" xref="S5.SS8.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.1.m1.1b"><cn id="S5.SS8.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS8.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.1.m1.1d">10</annotation></semantics></math>-th layer, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F12" title="Figure 12 â€£ 5.7 Effect of Hyperparameter Ïµ â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">12</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#S5.F13" title="Figure 13 â€£ 5.7 Effect of Hyperparameter Ïµ â€£ 5 Analysis â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">13</span></a>.
From these figures, it is evident that for the language-general FFNs neurons, the distributions for various languages intersect without clear boundaries, indicating a shared representation of language knowledge.
In contrast, for the language-specific neurons, the boundaries between language distributions are highly distinct, highlighting the independence of language-specific knowledge.
This observation underscores our neurons awareness can make neurons capture and integrate language knowledge in a general manner across multiple languages within the language-general FFNs.
Conversely, the distinct boundaries in the distributions of language-specific FFNs neurons suggest that these neurons are dedicated to encoding language-specific nuances and characteristics.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we have presented a novel approach that not only improves translation quality but also mitigates the risk of forgetting previous knowledge while adapting to new data.
We propose a TE to evaluate neuron awareness scores for MT tasks and categorize them into language-general neurons and language-specific neurons.
The proposed routing mechanism ensures optimal allocation of resources across language-specific and language-general capacities, further enhancing the adaptability of LLMs.
Our experimental results, conducted across ten language pairs, validate the effectiveness of our model, showcasing superior performance compared to existing baselines.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The present research was supported by the National Natural Science Foundation of China Youth Foud (Grant No.62306210) and the Key Research and Development Program of Yunnan Province (Grant No. 202203AA080004).
We would like to thank the anonymous reviewers for their insightful comments.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">Although LANDeRMT is a new approach to finetune LLMs to enhance the translation ability of LLMs.
The finetuning procedure is shorter than training LLMs as the amount of data required during the finetuning stage is much smaller than during the training stage.
This significantly reduces the cost of training model from scratch but maybe still totally overcome parameters interference as we not fully update the parameters of LLMs.
Additionally, due to computational constraints, we are currently unable to design additional experiments to validate how our method enhances the upper limit of translation capabilities of LLMs when more training data is added.</p>
</div>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">This study adheres to the ethical guidelines set forth by our institution and follows the principles outlined in the ACM Code of Ethics and Professional Conduct.
All datasets used in our experiments are publicly available.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alves etÂ al. (2023)</span>
<span class="ltx_bibblock">
Duarte Alves, NunoÂ Miguel Guerreiro, JoÃ£o Alves, JosÃ© Pombal, Ricardo Rei, JosÃ© GuilhermeÂ Camargo deÂ Souza, Pierre Colombo, and AndrÃ© Martins. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.findings-emnlp.744" title="">Steering large language models for machine translation with finetuning and in-context learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 11127â€“11148. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan etÂ al. (2019)</span>
<span class="ltx_bibblock">
Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Dmitry Lepikhin, Melvin Johnson, Maxim Krikun, MiaÂ Xu Chen, Yuan Cao, GeorgeÂ F. Foster, Colin Cherry, Wolfgang Macherey, Zhifeng Chen, and Yonghui Wu. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1907.05019" title="">Massively multilingual neural machine translation in the wild: Findings and challenges</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">CoRR</em>, abs/1907.05019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bawden and Yvon (2023)</span>
<span class="ltx_bibblock">
Rachel Bawden and FranÃ§ois Yvon. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.16" title="">Investigating the translation performance of a large multilingual language model: the case of BLOOM</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation, EAMT 2023, Tampere, Finland, 12-15 June 2023</em>, pages 157â€“170. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bills etÂ al. (2023)</span>
<span class="ltx_bibblock">
Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu, and William Saunders. 2023.

</span>
<span class="ltx_bibblock">Language models can explain neurons in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng etÂ al. (2023)</span>
<span class="ltx_bibblock">
Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.09530" title="">Adapting large language models via reading comprehension</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">CoRR</em>, abs/2309.09530.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conmy etÂ al. (2023)</span>
<span class="ltx_bibblock">
Arthur Conmy, AugustineÂ N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and AdriÃ  Garriga-Alonso. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2304.14997" title="">Towards automated circuit discovery for mechanistic interpretability</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">CoRR</em>, abs/2304.14997.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa-jussÃ  etÂ al. (2022)</span>
<span class="ltx_bibblock">
MartaÂ R. Costa-jussÃ , James Cross, Onur Ã‡elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, AlÂ Youngblood, Bapi Akula, LoÃ¯c Barrault, GabrielÂ Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, KaushikÂ Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, NecipÂ Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco GuzmÃ¡n, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2207.04672" title="">No language left behind: Scaling human-centered machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CoRR</em>, abs/2207.04672.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong etÂ al. (2023)</span>
<span class="ltx_bibblock">
Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, and Jingren Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2310.05492" title="">How abilities in large language models are affected by supervised fine-tuning data composition</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">CoRR</em>, abs/2310.05492.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedus etÂ al. (2022)</span>
<span class="ltx_bibblock">
William Fedus, Barret Zoph, and Noam Shazeer. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v23/21-0998.html" title="">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">J. Mach. Learn. Res.</em>, 23:120:1â€“120:39.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garde etÂ al. (2023)</span>
<span class="ltx_bibblock">
Albert Garde, Esben Kran, and Fazl Barez. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2310.01870" title="">Deepdecipher: Accessing and investigating neuron activation in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">CoRR</em>, abs/2310.01870.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghazvininejad etÂ al. (2023)</span>
<span class="ltx_bibblock">
Marjan Ghazvininejad, Hila Gonen, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2302.07856" title="">Dictionary-based phrase-level prompting of large language models for machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">CoRR</em>, abs/2302.07856.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta etÂ al. (2023)</span>
<span class="ltx_bibblock">
Kshitij Gupta, Benjamin ThÃ©rien, Adam Ibrahim, MatsÂ L. Richter, Quentin Anthony, Eugene Belilovsky, Irina Rish, and TimothÃ©e Lesort. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2308.04014" title="">Continual pre-training of large language models: How to (re)warm your model?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">CoRR</em>, abs/2308.04014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han etÂ al. (2022)</span>
<span class="ltx_bibblock">
Lifeng Han, Gleb Erofeev, Irina Sorokina, Serge Gladkoff, and Goran Nenadic. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.84" title="">Examining large pre-trained language models for machine translation: What you donâ€™t know about it</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the Seventh Conference on Machine Translation, WMT 2022, Abu Dhabi, United Arab Emirates (Hybrid), December 7-8, 2022</em>, pages 908â€“919. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.04118" title="">Exploring human-like translation strategy with large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">CoRR</em>, abs/2305.04118.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2022)</span>
<span class="ltx_bibblock">
EdwardÂ J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, LuÂ Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">Lora: Low-rank adaptation of large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Kaiyu Huang, Peng Li, Jin Ma, Ting Yao, and Yang Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2023.ACL-LONG.852" title="">Knowledge transfer in incremental learning for multilingual neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 15286â€“15304. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koishekenov etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yeskendir Koishekenov, Alexandre Berard, and Vassilina Nikoulina. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2023.ACL-LONG.198" title="">Memory-efficient NLLB-200: language-specific expert pruning of a massively multilingual machine translation model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 3567â€“3585. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Jiahuan Li, Hao Zhou, Shujian Huang, Shanbo Chen, and Jiajun Chen. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.15083" title="">Eliciting the translation ability of large language models via multilingual finetuning with translation instructions</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">CoRR</em>, abs/2305.15083.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Shangjie Li, Xiangpeng Wei, Shaolin Zhu, Jun Xie, Baosong Yang, and Deyi Xiong. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.303" title="">MMNMT: Modularizing multilingual neural machine translation with flexibly assembled MoE and dense blocks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 4978â€“4990, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Huihui Liu, Yiding Yang, and Xinchao Wang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/AAAI.V35I10.17049" title="">Overcoming catastrophic forgetting in graph neural networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021</em>, pages 8653â€“8661. AAAI Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shayne Longpre, LeÂ Hou, TuÂ Vu, Albert Webson, HyungÂ Won Chung, YiÂ Tay, Denny Zhou, QuocÂ V. Le, Barret Zoph, Jason Wei, and Adam Roberts. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v202/longpre23a.html" title="">The flan collection: Designing data and methods for effective instruction tuning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib21.2.2">Proceedings of Machine Learning Research</em>, pages 22631â€“22648. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, and Yue Zhang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2308.08747" title="">An empirical study of catastrophic forgetting in large language models during continual fine-tuning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">CoRR</em>, abs/2308.08747.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chenyang Lyu, Jitao Xu, and Longyue Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.01181" title="">New trends in machine translation using large language models: Case examples with chatgpt</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CoRR</em>, abs/2305.01181.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moslem etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yasmin Moslem, Rejwanul Haque, JohnÂ D. Kelleher, and Andy Way. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.22" title="">Adaptive machine translation with large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation, EAMT 2023, Tampere, Finland, 12-15 June 2023</em>, pages 227â€“237. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patel etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gal Patel, Leshem Choshen, and Omri Abend. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.conll-1.14" title="">On neurons invariant to sentence structural changes in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 26th Conference on Computational Natural Language Learning, CoNLL 2022, Abu Dhabi, United Arab Emirates (Hybrid Event), December 7-8, 2022</em>, pages 194â€“212. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">RÃ¤uker etÂ al. (2022)</span>
<span class="ltx_bibblock">
Tilman RÃ¤uker, Anson Ho, Stephen Casper, and Dylan Hadfield-Menell. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2207.13243" title="">Toward transparent AI: A survey on interpreting the inner structures of deep neural networks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">CoRR</em>, abs/2207.13243.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao etÂ al. (2022)</span>
<span class="ltx_bibblock">
TevenÂ Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman CastagnÃ©, AlexandraÂ Sasha Luccioni, FranÃ§ois Yvon, Matthias GallÃ©, Jonathan Tow, AlexanderÂ M. Rush, Stella Biderman, Albert Webson, PawanÂ Sasanka Ammanamanchi, Thomas Wang, BenoÃ®t Sagot, Niklas Muennighoff, AlbertÂ Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, IzÂ Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, PedroÂ Ortiz Suarez, Victor Sanh, Hugo LaurenÃ§on, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, AlhamÂ Fikri Aji, Amit Alfassy, Anna Rogers, ArielÂ Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, DavidÂ Ifeoluwa Adelani, and etÂ al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2211.05100" title="">BLOOM: A 176b-parameter open-access multilingual language model</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">CoRR</em>, abs/2211.05100.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao and Feng (2022)</span>
<span class="ltx_bibblock">
Chenze Shao and Yang Feng. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2022.ACL-LONG.143" title="">Overcoming catastrophic forgetting beyond continual learning: Balanced training for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 2023â€“2036. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sia and Duh (2023)</span>
<span class="ltx_bibblock">
Suzanna Sia and Kevin Duh. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.03573" title="">In-context learning as maintaining coherency: A study of on-the-fly machine translation using large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">CoRR</em>, abs/2305.03573.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron etÂ al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, PunitÂ Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, EricÂ Michael Smith, Ranjan Subramanian, XiaoqingÂ Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, JianÂ Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, AurÃ©lien Rodriguez, Robert Stojnic, Sergey Edunov,
and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">CoRR</em>, abs/2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vilar etÂ al. (2023)</span>
<span class="ltx_bibblock">
David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and GeorgeÂ F. Foster. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2023.ACL-LONG.859" title="">Prompting palm for translation: Assessing strategies and performance</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 15406â€“15427. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Voita etÂ al. (2023)</span>
<span class="ltx_bibblock">
Elena Voita, Javier Ferrando, and Christoforos Nalmpantis. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.04827" title="">Neurons in large language models: Dead, n-gram, positional</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">CoRR</em>, abs/2309.04827.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Chengyue Wu, Yukang Gan, Yixiao Ge, Zeyu Lu, Jiahao Wang, YeÂ Feng, Ping Luo, and Ying Shan. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2401.02415" title="">Llama pro: Progressive llama with block expansion</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">CoRR</em>, abs/2401.02415.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, DavidÂ S. Rosenberg, and Gideon Mann. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2303.17564" title="">Bloomberggpt: A large language model for finance</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">CoRR</em>, abs/2303.17564.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie etÂ al. (2021)</span>
<span class="ltx_bibblock">
Wanying Xie, Yang Feng, Shuhao Gu, and Dong Yu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2021.ACL-LONG.445" title="">Importance-based neuron allocation for multilingual neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021</em>, pages 5725â€“5737. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, CeÂ Bian, Chao Yin, Chenxu Lv, DaÂ Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, and Zhiying Wu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.10305" title="">Baichuan 2: Open large-scale language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">CoRR</em>, abs/2309.10305.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Biao Zhang, Ankur Bapna, Rico Sennrich, and Orhan Firat. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=Wj4ODo0uyCF" title="">Share or not? learning to schedule language-specific capacity for multilingual translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Biao Zhang, Barry Haddow, and Alexandra Birch. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v202/zhang23m.html" title="">Prompting large language model for machine translation: A case study</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib38.2.2">Proceedings of Machine Learning Research</em>, pages 41092â€“41110. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2020)</span>
<span class="ltx_bibblock">
Biao Zhang, Philip Williams, Ivan Titov, and Rico Sennrich. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2020.ACL-MAIN.148" title="">Improving massively multilingual neural machine translation and zero-shot translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages 1628â€“1639. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Shaolin Zhu, Menglong Cui, and Deyi Xiong. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.lrec-main.1444" title="">Towards robust in-context learning for machine translation with large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>, pages 16619â€“16629, Torino, Italia. ELRA and ICCL.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Shaolin Zhu, Shiwei Gu, Shangjie Li, Lin Xu, and Deyi Xiong. 2024b.

</span>
<span class="ltx_bibblock">Mining parallel sentences from internet with multi-view knowledge distillation for low-resource language pairs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Knowledge and Information Systems</em>, 66(1):187â€“209.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shaolin Zhu, Chenggang Mi, Tianqi Li, Yong Yang, and Chun Xu. 2023.

</span>
<span class="ltx_bibblock">Unsupervised parallel sentences of machine translation for asian language pairs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">ACM Transactions on Asian and Low-Resource Language Information Processing</em>, 22(3):1â€“14.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Xiong (2023)</span>
<span class="ltx_bibblock">
Shaolin Zhu and Deyi Xiong. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.33" title="">TJUNLP:system description for the WMT23 literary task in Chinese to English translation direction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 307â€“311, Singapore. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Language Details</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">We introduce the characteristics of different languages as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19523v1#A1.T3" title="Table 3 â€£ A.1 Language Details â€£ Appendix A Appendix â€£ LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_table" id="A1.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T3.1.1.1.1.1">Code</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T3.1.1.1.2.1">Language</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.1.1.3.1">Genus</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.1.1.4.1">Order</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.2.1.1">en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.2.1.2">English</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.2.1.3">Romance</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.2.1.4">SVO</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.3.2">
<td class="ltx_td ltx_align_center" id="A1.T3.1.3.2.1">ar</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.3.2.2">Arabic</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.3.2.3">Semitic</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.3.2.4">VSO</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.4.3">
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.3.1">fr</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.3.2">French</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.3.3">Romance</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.3.4">SVO</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.5.4">
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.4.1">de</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.4.2">German</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.4.3">Germanic</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.4.4">SVO</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.6.5">
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.5.1">zh</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.5.2">Chinese</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.5.3">Sinitic</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.5.4">SVO</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.7.6">
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.1.7.6.1">it</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.1.7.6.2">Italian</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.1.7.6.3">Romance</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.1.7.6.4">SVO</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The characteristics of languages in our setting.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Taylor Expansion</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">We first express <math alttext="\Delta\mathcal{L}(\textbf{h}_{i})" class="ltx_Math" display="inline" id="A1.SS2.p1.1.m1.1"><semantics id="A1.SS2.p1.1.m1.1a"><mrow id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml"><mi id="A1.SS2.p1.1.m1.1.1.3" mathvariant="normal" xref="A1.SS2.p1.1.m1.1.1.3.cmml">Î”</mi><mo id="A1.SS2.p1.1.m1.1.1.2" xref="A1.SS2.p1.1.m1.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="A1.SS2.p1.1.m1.1.1.4" xref="A1.SS2.p1.1.m1.1.1.4.cmml">â„’</mi><mo id="A1.SS2.p1.1.m1.1.1.2a" xref="A1.SS2.p1.1.m1.1.1.2.cmml">â¢</mo><mrow id="A1.SS2.p1.1.m1.1.1.1.1" xref="A1.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo id="A1.SS2.p1.1.m1.1.1.1.1.2" stretchy="false" xref="A1.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><msub id="A1.SS2.p1.1.m1.1.1.1.1.1" xref="A1.SS2.p1.1.m1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p1.1.m1.1.1.1.1.1.2" xref="A1.SS2.p1.1.m1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.SS2.p1.1.m1.1.1.1.1.1.3" xref="A1.SS2.p1.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS2.p1.1.m1.1.1.1.1.3" stretchy="false" xref="A1.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><apply id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1"><times id="A1.SS2.p1.1.m1.1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2"></times><ci id="A1.SS2.p1.1.m1.1.1.3.cmml" xref="A1.SS2.p1.1.m1.1.1.3">Î”</ci><ci id="A1.SS2.p1.1.m1.1.1.4.cmml" xref="A1.SS2.p1.1.m1.1.1.4">â„’</ci><apply id="A1.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="A1.SS2.p1.1.m1.1.1.1.1.1.2a.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">\Delta\mathcal{L}(\textbf{h}_{i})</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.m1.1d">roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> as loss change as shown in the following equation.</p>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="A1.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\left|\Delta\mathcal{L}\left(\textbf{h}_{i}\right)\right|=\left|\mathcal{L}%
\left(\textbf{H},\textbf{h}_{i}=\textbf{0}\right)-\mathcal{L}\left(\textbf{H},%
\textbf{h}_{i}\right)\right|" class="ltx_Math" display="block" id="A1.Ex1.m1.4"><semantics id="A1.Ex1.m1.4a"><mrow id="A1.Ex1.m1.4.4" xref="A1.Ex1.m1.4.4.cmml"><mrow id="A1.Ex1.m1.3.3.1.1" xref="A1.Ex1.m1.3.3.1.2.cmml"><mo id="A1.Ex1.m1.3.3.1.1.2" xref="A1.Ex1.m1.3.3.1.2.1.cmml">|</mo><mrow id="A1.Ex1.m1.3.3.1.1.1" xref="A1.Ex1.m1.3.3.1.1.1.cmml"><mi id="A1.Ex1.m1.3.3.1.1.1.3" mathvariant="normal" xref="A1.Ex1.m1.3.3.1.1.1.3.cmml">Î”</mi><mo id="A1.Ex1.m1.3.3.1.1.1.2" xref="A1.Ex1.m1.3.3.1.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.3.3.1.1.1.4" xref="A1.Ex1.m1.3.3.1.1.1.4.cmml">â„’</mi><mo id="A1.Ex1.m1.3.3.1.1.1.2a" xref="A1.Ex1.m1.3.3.1.1.1.2.cmml">â¢</mo><mrow id="A1.Ex1.m1.3.3.1.1.1.1.1" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.cmml"><mo id="A1.Ex1.m1.3.3.1.1.1.1.1.2" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.cmml">(</mo><msub id="A1.Ex1.m1.3.3.1.1.1.1.1.1" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.3.3.1.1.1.1.1.1.2" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex1.m1.3.3.1.1.1.1.1.1.3" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex1.m1.3.3.1.1.1.1.1.3" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex1.m1.3.3.1.1.3" xref="A1.Ex1.m1.3.3.1.2.1.cmml">|</mo></mrow><mo id="A1.Ex1.m1.4.4.3" xref="A1.Ex1.m1.4.4.3.cmml">=</mo><mrow id="A1.Ex1.m1.4.4.2.1" xref="A1.Ex1.m1.4.4.2.2.cmml"><mo id="A1.Ex1.m1.4.4.2.1.2" xref="A1.Ex1.m1.4.4.2.2.1.cmml">|</mo><mrow id="A1.Ex1.m1.4.4.2.1.1" xref="A1.Ex1.m1.4.4.2.1.1.cmml"><mrow id="A1.Ex1.m1.4.4.2.1.1.1" xref="A1.Ex1.m1.4.4.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.4.4.2.1.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.1.3.cmml">â„’</mi><mo id="A1.Ex1.m1.4.4.2.1.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.1.2.cmml">â¢</mo><mrow id="A1.Ex1.m1.4.4.2.1.1.1.1.1" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.cmml"><mo id="A1.Ex1.m1.4.4.2.1.1.1.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.cmml"><mrow id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.1.1" xref="A1.Ex1.m1.1.1a.cmml">H</mtext><mo id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub></mrow><mo id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.2.cmml">=</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.3a.cmml">0</mtext></mrow><mo id="A1.Ex1.m1.4.4.2.1.1.1.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex1.m1.4.4.2.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.3.cmml">âˆ’</mo><mrow id="A1.Ex1.m1.4.4.2.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.4.4.2.1.1.2.3" xref="A1.Ex1.m1.4.4.2.1.1.2.3.cmml">â„’</mi><mo id="A1.Ex1.m1.4.4.2.1.1.2.2" xref="A1.Ex1.m1.4.4.2.1.1.2.2.cmml">â¢</mo><mrow id="A1.Ex1.m1.4.4.2.1.1.2.1.1" xref="A1.Ex1.m1.4.4.2.1.1.2.1.2.cmml"><mo id="A1.Ex1.m1.4.4.2.1.1.2.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.2.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.2.2" xref="A1.Ex1.m1.2.2a.cmml">H</mtext><mo id="A1.Ex1.m1.4.4.2.1.1.2.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.2.1.2.cmml">,</mo><msub id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.2" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.3" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex1.m1.4.4.2.1.1.2.1.1.4" xref="A1.Ex1.m1.4.4.2.1.1.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="A1.Ex1.m1.4.4.2.1.3" xref="A1.Ex1.m1.4.4.2.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex1.m1.4b"><apply id="A1.Ex1.m1.4.4.cmml" xref="A1.Ex1.m1.4.4"><eq id="A1.Ex1.m1.4.4.3.cmml" xref="A1.Ex1.m1.4.4.3"></eq><apply id="A1.Ex1.m1.3.3.1.2.cmml" xref="A1.Ex1.m1.3.3.1.1"><abs id="A1.Ex1.m1.3.3.1.2.1.cmml" xref="A1.Ex1.m1.3.3.1.1.2"></abs><apply id="A1.Ex1.m1.3.3.1.1.1.cmml" xref="A1.Ex1.m1.3.3.1.1.1"><times id="A1.Ex1.m1.3.3.1.1.1.2.cmml" xref="A1.Ex1.m1.3.3.1.1.1.2"></times><ci id="A1.Ex1.m1.3.3.1.1.1.3.cmml" xref="A1.Ex1.m1.3.3.1.1.1.3">Î”</ci><ci id="A1.Ex1.m1.3.3.1.1.1.4.cmml" xref="A1.Ex1.m1.3.3.1.1.1.4">â„’</ci><apply id="A1.Ex1.m1.3.3.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="A1.Ex1.m1.3.3.1.1.1.1.1.1.2a.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><apply id="A1.Ex1.m1.4.4.2.2.cmml" xref="A1.Ex1.m1.4.4.2.1"><abs id="A1.Ex1.m1.4.4.2.2.1.cmml" xref="A1.Ex1.m1.4.4.2.1.2"></abs><apply id="A1.Ex1.m1.4.4.2.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1"><minus id="A1.Ex1.m1.4.4.2.1.1.3.cmml" xref="A1.Ex1.m1.4.4.2.1.1.3"></minus><apply id="A1.Ex1.m1.4.4.2.1.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1"><times id="A1.Ex1.m1.4.4.2.1.1.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.2"></times><ci id="A1.Ex1.m1.4.4.2.1.1.1.3.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.3">â„’</ci><apply id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1"><eq id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.2"></eq><list id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1"><ci id="A1.Ex1.m1.1.1a.cmml" xref="A1.Ex1.m1.1.1"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.1.1.cmml" xref="A1.Ex1.m1.1.1">H</mtext></ci><apply id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.2a.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></list><ci id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.3a.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.3.cmml" xref="A1.Ex1.m1.4.4.2.1.1.1.1.1.1.3">0</mtext></ci></apply></apply><apply id="A1.Ex1.m1.4.4.2.1.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2"><times id="A1.Ex1.m1.4.4.2.1.1.2.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.2"></times><ci id="A1.Ex1.m1.4.4.2.1.1.2.3.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.3">â„’</ci><interval closure="open" id="A1.Ex1.m1.4.4.2.1.1.2.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1"><ci id="A1.Ex1.m1.2.2a.cmml" xref="A1.Ex1.m1.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.2.2.cmml" xref="A1.Ex1.m1.2.2">H</mtext></ci><apply id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1"><csymbol cd="ambiguous" id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.1.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1">subscript</csymbol><ci id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.2a.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.2.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.2">h</mtext></ci><ci id="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.3.cmml" xref="A1.Ex1.m1.4.4.2.1.1.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex1.m1.4c">\left|\Delta\mathcal{L}\left(\textbf{h}_{i}\right)\right|=\left|\mathcal{L}%
\left(\textbf{H},\textbf{h}_{i}=\textbf{0}\right)-\mathcal{L}\left(\textbf{H},%
\textbf{h}_{i}\right)\right|</annotation><annotation encoding="application/x-llamapun" id="A1.Ex1.m1.4d">| roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) | = | caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 ) - caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.5"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="A1.SS2.p3.5.1">H</span> is the representation produced by a neuron other than <math alttext="i" class="ltx_Math" display="inline" id="A1.SS2.p3.2.m2.1"><semantics id="A1.SS2.p3.2.m2.1a"><mi id="A1.SS2.p3.2.m2.1.1" xref="A1.SS2.p3.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.2.m2.1b"><ci id="A1.SS2.p3.2.m2.1.1.cmml" xref="A1.SS2.p3.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.2.m2.1d">italic_i</annotation></semantics></math> in the same structure as the <math alttext="i" class="ltx_Math" display="inline" id="A1.SS2.p3.3.m3.1"><semantics id="A1.SS2.p3.3.m3.1a"><mi id="A1.SS2.p3.3.m3.1.1" xref="A1.SS2.p3.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.3.m3.1b"><ci id="A1.SS2.p3.3.m3.1.1.cmml" xref="A1.SS2.p3.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.3.m3.1d">italic_i</annotation></semantics></math> neuron. We then perform a first-order Taylor expansion of <math alttext="\mathcal{L}(\textbf{H},\textbf{h}_{i})" class="ltx_Math" display="inline" id="A1.SS2.p3.4.m4.2"><semantics id="A1.SS2.p3.4.m4.2a"><mrow id="A1.SS2.p3.4.m4.2.2" xref="A1.SS2.p3.4.m4.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS2.p3.4.m4.2.2.3" xref="A1.SS2.p3.4.m4.2.2.3.cmml">â„’</mi><mo id="A1.SS2.p3.4.m4.2.2.2" xref="A1.SS2.p3.4.m4.2.2.2.cmml">â¢</mo><mrow id="A1.SS2.p3.4.m4.2.2.1.1" xref="A1.SS2.p3.4.m4.2.2.1.2.cmml"><mo id="A1.SS2.p3.4.m4.2.2.1.1.2" stretchy="false" xref="A1.SS2.p3.4.m4.2.2.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.4.m4.1.1" xref="A1.SS2.p3.4.m4.1.1a.cmml">H</mtext><mo id="A1.SS2.p3.4.m4.2.2.1.1.3" xref="A1.SS2.p3.4.m4.2.2.1.2.cmml">,</mo><msub id="A1.SS2.p3.4.m4.2.2.1.1.1" xref="A1.SS2.p3.4.m4.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.4.m4.2.2.1.1.1.2" xref="A1.SS2.p3.4.m4.2.2.1.1.1.2a.cmml">h</mtext><mi id="A1.SS2.p3.4.m4.2.2.1.1.1.3" xref="A1.SS2.p3.4.m4.2.2.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS2.p3.4.m4.2.2.1.1.4" stretchy="false" xref="A1.SS2.p3.4.m4.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.4.m4.2b"><apply id="A1.SS2.p3.4.m4.2.2.cmml" xref="A1.SS2.p3.4.m4.2.2"><times id="A1.SS2.p3.4.m4.2.2.2.cmml" xref="A1.SS2.p3.4.m4.2.2.2"></times><ci id="A1.SS2.p3.4.m4.2.2.3.cmml" xref="A1.SS2.p3.4.m4.2.2.3">â„’</ci><interval closure="open" id="A1.SS2.p3.4.m4.2.2.1.2.cmml" xref="A1.SS2.p3.4.m4.2.2.1.1"><ci id="A1.SS2.p3.4.m4.1.1a.cmml" xref="A1.SS2.p3.4.m4.1.1"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.4.m4.1.1.cmml" xref="A1.SS2.p3.4.m4.1.1">H</mtext></ci><apply id="A1.SS2.p3.4.m4.2.2.1.1.1.cmml" xref="A1.SS2.p3.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p3.4.m4.2.2.1.1.1.1.cmml" xref="A1.SS2.p3.4.m4.2.2.1.1.1">subscript</csymbol><ci id="A1.SS2.p3.4.m4.2.2.1.1.1.2a.cmml" xref="A1.SS2.p3.4.m4.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.4.m4.2.2.1.1.1.2.cmml" xref="A1.SS2.p3.4.m4.2.2.1.1.1.2">h</mtext></ci><ci id="A1.SS2.p3.4.m4.2.2.1.1.1.3.cmml" xref="A1.SS2.p3.4.m4.2.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.4.m4.2c">\mathcal{L}(\textbf{H},\textbf{h}_{i})</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.4.m4.2d">caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> at <math alttext="\textbf{h}_{i}=\textbf{0}" class="ltx_Math" display="inline" id="A1.SS2.p3.5.m5.1"><semantics id="A1.SS2.p3.5.m5.1a"><mrow id="A1.SS2.p3.5.m5.1.1" xref="A1.SS2.p3.5.m5.1.1.cmml"><msub id="A1.SS2.p3.5.m5.1.1.2" xref="A1.SS2.p3.5.m5.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.5.m5.1.1.2.2" xref="A1.SS2.p3.5.m5.1.1.2.2a.cmml">h</mtext><mi id="A1.SS2.p3.5.m5.1.1.2.3" xref="A1.SS2.p3.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="A1.SS2.p3.5.m5.1.1.1" xref="A1.SS2.p3.5.m5.1.1.1.cmml">=</mo><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.5.m5.1.1.3" xref="A1.SS2.p3.5.m5.1.1.3a.cmml">0</mtext></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.5.m5.1b"><apply id="A1.SS2.p3.5.m5.1.1.cmml" xref="A1.SS2.p3.5.m5.1.1"><eq id="A1.SS2.p3.5.m5.1.1.1.cmml" xref="A1.SS2.p3.5.m5.1.1.1"></eq><apply id="A1.SS2.p3.5.m5.1.1.2.cmml" xref="A1.SS2.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.p3.5.m5.1.1.2.1.cmml" xref="A1.SS2.p3.5.m5.1.1.2">subscript</csymbol><ci id="A1.SS2.p3.5.m5.1.1.2.2a.cmml" xref="A1.SS2.p3.5.m5.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.5.m5.1.1.2.2.cmml" xref="A1.SS2.p3.5.m5.1.1.2.2">h</mtext></ci><ci id="A1.SS2.p3.5.m5.1.1.2.3.cmml" xref="A1.SS2.p3.5.m5.1.1.2.3">ğ‘–</ci></apply><ci id="A1.SS2.p3.5.m5.1.1.3a.cmml" xref="A1.SS2.p3.5.m5.1.1.3"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p3.5.m5.1.1.3.cmml" xref="A1.SS2.p3.5.m5.1.1.3">0</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.5.m5.1c">\textbf{h}_{i}=\textbf{0}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.5.m5.1d">h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A1.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="A1.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}\left(\textbf{H},\textbf{h}_{i}\right)=\mathcal{L}\left(\textbf{H},%
\textbf{h}_{i}=\textbf{0}\right)+\frac{\partial\mathcal{L}\left(\textbf{H},%
\textbf{h}_{i}\right)}{\partial\textbf{h}_{i}}\textbf{h}_{i}+R_{1}\left(%
\textbf{h}_{i}\right)" class="ltx_Math" display="block" id="A1.Ex2.m1.7"><semantics id="A1.Ex2.m1.7a"><mrow id="A1.Ex2.m1.7.7" xref="A1.Ex2.m1.7.7.cmml"><mrow id="A1.Ex2.m1.5.5.1" xref="A1.Ex2.m1.5.5.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.5.5.1.3" xref="A1.Ex2.m1.5.5.1.3.cmml">â„’</mi><mo id="A1.Ex2.m1.5.5.1.2" xref="A1.Ex2.m1.5.5.1.2.cmml">â¢</mo><mrow id="A1.Ex2.m1.5.5.1.1.1" xref="A1.Ex2.m1.5.5.1.1.2.cmml"><mo id="A1.Ex2.m1.5.5.1.1.1.2" xref="A1.Ex2.m1.5.5.1.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.3.3" xref="A1.Ex2.m1.3.3a.cmml">H</mtext><mo id="A1.Ex2.m1.5.5.1.1.1.3" xref="A1.Ex2.m1.5.5.1.1.2.cmml">,</mo><msub id="A1.Ex2.m1.5.5.1.1.1.1" xref="A1.Ex2.m1.5.5.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.5.5.1.1.1.1.2" xref="A1.Ex2.m1.5.5.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex2.m1.5.5.1.1.1.1.3" xref="A1.Ex2.m1.5.5.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex2.m1.5.5.1.1.1.4" xref="A1.Ex2.m1.5.5.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.Ex2.m1.7.7.4" xref="A1.Ex2.m1.7.7.4.cmml">=</mo><mrow id="A1.Ex2.m1.7.7.3" xref="A1.Ex2.m1.7.7.3.cmml"><mrow id="A1.Ex2.m1.6.6.2.1" xref="A1.Ex2.m1.6.6.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.6.6.2.1.3" xref="A1.Ex2.m1.6.6.2.1.3.cmml">â„’</mi><mo id="A1.Ex2.m1.6.6.2.1.2" xref="A1.Ex2.m1.6.6.2.1.2.cmml">â¢</mo><mrow id="A1.Ex2.m1.6.6.2.1.1.1" xref="A1.Ex2.m1.6.6.2.1.1.1.1.cmml"><mo id="A1.Ex2.m1.6.6.2.1.1.1.2" xref="A1.Ex2.m1.6.6.2.1.1.1.1.cmml">(</mo><mrow id="A1.Ex2.m1.6.6.2.1.1.1.1" xref="A1.Ex2.m1.6.6.2.1.1.1.1.cmml"><mrow id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.4.4" xref="A1.Ex2.m1.4.4a.cmml">H</mtext><mo id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.2" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.2.cmml">,</mo><msub id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.2" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.3" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub></mrow><mo id="A1.Ex2.m1.6.6.2.1.1.1.1.2" xref="A1.Ex2.m1.6.6.2.1.1.1.1.2.cmml">=</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.6.6.2.1.1.1.1.3" xref="A1.Ex2.m1.6.6.2.1.1.1.1.3a.cmml">0</mtext></mrow><mo id="A1.Ex2.m1.6.6.2.1.1.1.3" xref="A1.Ex2.m1.6.6.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex2.m1.7.7.3.3" xref="A1.Ex2.m1.7.7.3.3.cmml">+</mo><mrow id="A1.Ex2.m1.7.7.3.4" xref="A1.Ex2.m1.7.7.3.4.cmml"><mfrac id="A1.Ex2.m1.2.2" xref="A1.Ex2.m1.2.2.cmml"><mrow id="A1.Ex2.m1.2.2.2" xref="A1.Ex2.m1.2.2.2.cmml"><mo id="A1.Ex2.m1.2.2.2.3" rspace="0em" xref="A1.Ex2.m1.2.2.2.3.cmml">âˆ‚</mo><mrow id="A1.Ex2.m1.2.2.2.2" xref="A1.Ex2.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.2.2.2.2.3" xref="A1.Ex2.m1.2.2.2.2.3.cmml">â„’</mi><mo id="A1.Ex2.m1.2.2.2.2.2" xref="A1.Ex2.m1.2.2.2.2.2.cmml">â¢</mo><mrow id="A1.Ex2.m1.2.2.2.2.1.1" xref="A1.Ex2.m1.2.2.2.2.1.2.cmml"><mo id="A1.Ex2.m1.2.2.2.2.1.1.2" xref="A1.Ex2.m1.2.2.2.2.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.1.1.1.1" xref="A1.Ex2.m1.1.1.1.1a.cmml">H</mtext><mo id="A1.Ex2.m1.2.2.2.2.1.1.3" xref="A1.Ex2.m1.2.2.2.2.1.2.cmml">,</mo><msub id="A1.Ex2.m1.2.2.2.2.1.1.1" xref="A1.Ex2.m1.2.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.2.2.2.2.1.1.1.2" xref="A1.Ex2.m1.2.2.2.2.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex2.m1.2.2.2.2.1.1.1.3" xref="A1.Ex2.m1.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex2.m1.2.2.2.2.1.1.4" xref="A1.Ex2.m1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><mrow id="A1.Ex2.m1.2.2.4" xref="A1.Ex2.m1.2.2.4.cmml"><mo id="A1.Ex2.m1.2.2.4.1" rspace="0em" xref="A1.Ex2.m1.2.2.4.1.cmml">âˆ‚</mo><msub id="A1.Ex2.m1.2.2.4.2" xref="A1.Ex2.m1.2.2.4.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.2.2.4.2.2" xref="A1.Ex2.m1.2.2.4.2.2a.cmml">h</mtext><mi id="A1.Ex2.m1.2.2.4.2.3" xref="A1.Ex2.m1.2.2.4.2.3.cmml">i</mi></msub></mrow></mfrac><mo id="A1.Ex2.m1.7.7.3.4.1" xref="A1.Ex2.m1.7.7.3.4.1.cmml">â¢</mo><msub id="A1.Ex2.m1.7.7.3.4.2" xref="A1.Ex2.m1.7.7.3.4.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.7.7.3.4.2.2" xref="A1.Ex2.m1.7.7.3.4.2.2a.cmml">h</mtext><mi id="A1.Ex2.m1.7.7.3.4.2.3" xref="A1.Ex2.m1.7.7.3.4.2.3.cmml">i</mi></msub></mrow><mo id="A1.Ex2.m1.7.7.3.3a" xref="A1.Ex2.m1.7.7.3.3.cmml">+</mo><mrow id="A1.Ex2.m1.7.7.3.2" xref="A1.Ex2.m1.7.7.3.2.cmml"><msub id="A1.Ex2.m1.7.7.3.2.3" xref="A1.Ex2.m1.7.7.3.2.3.cmml"><mi id="A1.Ex2.m1.7.7.3.2.3.2" xref="A1.Ex2.m1.7.7.3.2.3.2.cmml">R</mi><mn id="A1.Ex2.m1.7.7.3.2.3.3" xref="A1.Ex2.m1.7.7.3.2.3.3.cmml">1</mn></msub><mo id="A1.Ex2.m1.7.7.3.2.2" xref="A1.Ex2.m1.7.7.3.2.2.cmml">â¢</mo><mrow id="A1.Ex2.m1.7.7.3.2.1.1" xref="A1.Ex2.m1.7.7.3.2.1.1.1.cmml"><mo id="A1.Ex2.m1.7.7.3.2.1.1.2" xref="A1.Ex2.m1.7.7.3.2.1.1.1.cmml">(</mo><msub id="A1.Ex2.m1.7.7.3.2.1.1.1" xref="A1.Ex2.m1.7.7.3.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.7.7.3.2.1.1.1.2" xref="A1.Ex2.m1.7.7.3.2.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex2.m1.7.7.3.2.1.1.1.3" xref="A1.Ex2.m1.7.7.3.2.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex2.m1.7.7.3.2.1.1.3" xref="A1.Ex2.m1.7.7.3.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex2.m1.7b"><apply id="A1.Ex2.m1.7.7.cmml" xref="A1.Ex2.m1.7.7"><eq id="A1.Ex2.m1.7.7.4.cmml" xref="A1.Ex2.m1.7.7.4"></eq><apply id="A1.Ex2.m1.5.5.1.cmml" xref="A1.Ex2.m1.5.5.1"><times id="A1.Ex2.m1.5.5.1.2.cmml" xref="A1.Ex2.m1.5.5.1.2"></times><ci id="A1.Ex2.m1.5.5.1.3.cmml" xref="A1.Ex2.m1.5.5.1.3">â„’</ci><interval closure="open" id="A1.Ex2.m1.5.5.1.1.2.cmml" xref="A1.Ex2.m1.5.5.1.1.1"><ci id="A1.Ex2.m1.3.3a.cmml" xref="A1.Ex2.m1.3.3"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.3.3.cmml" xref="A1.Ex2.m1.3.3">H</mtext></ci><apply id="A1.Ex2.m1.5.5.1.1.1.1.cmml" xref="A1.Ex2.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex2.m1.5.5.1.1.1.1.1.cmml" xref="A1.Ex2.m1.5.5.1.1.1.1">subscript</csymbol><ci id="A1.Ex2.m1.5.5.1.1.1.1.2a.cmml" xref="A1.Ex2.m1.5.5.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.5.5.1.1.1.1.2.cmml" xref="A1.Ex2.m1.5.5.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex2.m1.5.5.1.1.1.1.3.cmml" xref="A1.Ex2.m1.5.5.1.1.1.1.3">ğ‘–</ci></apply></interval></apply><apply id="A1.Ex2.m1.7.7.3.cmml" xref="A1.Ex2.m1.7.7.3"><plus id="A1.Ex2.m1.7.7.3.3.cmml" xref="A1.Ex2.m1.7.7.3.3"></plus><apply id="A1.Ex2.m1.6.6.2.1.cmml" xref="A1.Ex2.m1.6.6.2.1"><times id="A1.Ex2.m1.6.6.2.1.2.cmml" xref="A1.Ex2.m1.6.6.2.1.2"></times><ci id="A1.Ex2.m1.6.6.2.1.3.cmml" xref="A1.Ex2.m1.6.6.2.1.3">â„’</ci><apply id="A1.Ex2.m1.6.6.2.1.1.1.1.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1"><eq id="A1.Ex2.m1.6.6.2.1.1.1.1.2.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.2"></eq><list id="A1.Ex2.m1.6.6.2.1.1.1.1.1.2.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1"><ci id="A1.Ex2.m1.4.4a.cmml" xref="A1.Ex2.m1.4.4"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.4.4.cmml" xref="A1.Ex2.m1.4.4">H</mtext></ci><apply id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.1.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.2a.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.2.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.3.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></list><ci id="A1.Ex2.m1.6.6.2.1.1.1.1.3a.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.6.6.2.1.1.1.1.3.cmml" xref="A1.Ex2.m1.6.6.2.1.1.1.1.3">0</mtext></ci></apply></apply><apply id="A1.Ex2.m1.7.7.3.4.cmml" xref="A1.Ex2.m1.7.7.3.4"><times id="A1.Ex2.m1.7.7.3.4.1.cmml" xref="A1.Ex2.m1.7.7.3.4.1"></times><apply id="A1.Ex2.m1.2.2.cmml" xref="A1.Ex2.m1.2.2"><divide id="A1.Ex2.m1.2.2.3.cmml" xref="A1.Ex2.m1.2.2"></divide><apply id="A1.Ex2.m1.2.2.2.cmml" xref="A1.Ex2.m1.2.2.2"><partialdiff id="A1.Ex2.m1.2.2.2.3.cmml" xref="A1.Ex2.m1.2.2.2.3"></partialdiff><apply id="A1.Ex2.m1.2.2.2.2.cmml" xref="A1.Ex2.m1.2.2.2.2"><times id="A1.Ex2.m1.2.2.2.2.2.cmml" xref="A1.Ex2.m1.2.2.2.2.2"></times><ci id="A1.Ex2.m1.2.2.2.2.3.cmml" xref="A1.Ex2.m1.2.2.2.2.3">â„’</ci><interval closure="open" id="A1.Ex2.m1.2.2.2.2.1.2.cmml" xref="A1.Ex2.m1.2.2.2.2.1.1"><ci id="A1.Ex2.m1.1.1.1.1a.cmml" xref="A1.Ex2.m1.1.1.1.1"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.1.1.1.1.cmml" xref="A1.Ex2.m1.1.1.1.1">H</mtext></ci><apply id="A1.Ex2.m1.2.2.2.2.1.1.1.cmml" xref="A1.Ex2.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.2.2.2.1.1.1.1.cmml" xref="A1.Ex2.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="A1.Ex2.m1.2.2.2.2.1.1.1.2a.cmml" xref="A1.Ex2.m1.2.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.2.2.2.2.1.1.1.2.cmml" xref="A1.Ex2.m1.2.2.2.2.1.1.1.2">h</mtext></ci><ci id="A1.Ex2.m1.2.2.2.2.1.1.1.3.cmml" xref="A1.Ex2.m1.2.2.2.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply><apply id="A1.Ex2.m1.2.2.4.cmml" xref="A1.Ex2.m1.2.2.4"><partialdiff id="A1.Ex2.m1.2.2.4.1.cmml" xref="A1.Ex2.m1.2.2.4.1"></partialdiff><apply id="A1.Ex2.m1.2.2.4.2.cmml" xref="A1.Ex2.m1.2.2.4.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.2.4.2.1.cmml" xref="A1.Ex2.m1.2.2.4.2">subscript</csymbol><ci id="A1.Ex2.m1.2.2.4.2.2a.cmml" xref="A1.Ex2.m1.2.2.4.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.2.2.4.2.2.cmml" xref="A1.Ex2.m1.2.2.4.2.2">h</mtext></ci><ci id="A1.Ex2.m1.2.2.4.2.3.cmml" xref="A1.Ex2.m1.2.2.4.2.3">ğ‘–</ci></apply></apply></apply><apply id="A1.Ex2.m1.7.7.3.4.2.cmml" xref="A1.Ex2.m1.7.7.3.4.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.7.7.3.4.2.1.cmml" xref="A1.Ex2.m1.7.7.3.4.2">subscript</csymbol><ci id="A1.Ex2.m1.7.7.3.4.2.2a.cmml" xref="A1.Ex2.m1.7.7.3.4.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.7.7.3.4.2.2.cmml" xref="A1.Ex2.m1.7.7.3.4.2.2">h</mtext></ci><ci id="A1.Ex2.m1.7.7.3.4.2.3.cmml" xref="A1.Ex2.m1.7.7.3.4.2.3">ğ‘–</ci></apply></apply><apply id="A1.Ex2.m1.7.7.3.2.cmml" xref="A1.Ex2.m1.7.7.3.2"><times id="A1.Ex2.m1.7.7.3.2.2.cmml" xref="A1.Ex2.m1.7.7.3.2.2"></times><apply id="A1.Ex2.m1.7.7.3.2.3.cmml" xref="A1.Ex2.m1.7.7.3.2.3"><csymbol cd="ambiguous" id="A1.Ex2.m1.7.7.3.2.3.1.cmml" xref="A1.Ex2.m1.7.7.3.2.3">subscript</csymbol><ci id="A1.Ex2.m1.7.7.3.2.3.2.cmml" xref="A1.Ex2.m1.7.7.3.2.3.2">ğ‘…</ci><cn id="A1.Ex2.m1.7.7.3.2.3.3.cmml" type="integer" xref="A1.Ex2.m1.7.7.3.2.3.3">1</cn></apply><apply id="A1.Ex2.m1.7.7.3.2.1.1.1.cmml" xref="A1.Ex2.m1.7.7.3.2.1.1"><csymbol cd="ambiguous" id="A1.Ex2.m1.7.7.3.2.1.1.1.1.cmml" xref="A1.Ex2.m1.7.7.3.2.1.1">subscript</csymbol><ci id="A1.Ex2.m1.7.7.3.2.1.1.1.2a.cmml" xref="A1.Ex2.m1.7.7.3.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex2.m1.7.7.3.2.1.1.1.2.cmml" xref="A1.Ex2.m1.7.7.3.2.1.1.1.2">h</mtext></ci><ci id="A1.Ex2.m1.7.7.3.2.1.1.1.3.cmml" xref="A1.Ex2.m1.7.7.3.2.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex2.m1.7c">\mathcal{L}\left(\textbf{H},\textbf{h}_{i}\right)=\mathcal{L}\left(\textbf{H},%
\textbf{h}_{i}=\textbf{0}\right)+\frac{\partial\mathcal{L}\left(\textbf{H},%
\textbf{h}_{i}\right)}{\partial\textbf{h}_{i}}\textbf{h}_{i}+R_{1}\left(%
\textbf{h}_{i}\right)</annotation><annotation encoding="application/x-llamapun" id="A1.Ex2.m1.7d">caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 ) + divide start_ARG âˆ‚ caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG âˆ‚ h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A1.SS2.p5">
<p class="ltx_p" id="A1.SS2.p5.1">The term <math alttext="R_{1}\left(\textbf{h}_{i}\right)" class="ltx_Math" display="inline" id="A1.SS2.p5.1.m1.1"><semantics id="A1.SS2.p5.1.m1.1a"><mrow id="A1.SS2.p5.1.m1.1.1" xref="A1.SS2.p5.1.m1.1.1.cmml"><msub id="A1.SS2.p5.1.m1.1.1.3" xref="A1.SS2.p5.1.m1.1.1.3.cmml"><mi id="A1.SS2.p5.1.m1.1.1.3.2" xref="A1.SS2.p5.1.m1.1.1.3.2.cmml">R</mi><mn id="A1.SS2.p5.1.m1.1.1.3.3" xref="A1.SS2.p5.1.m1.1.1.3.3.cmml">1</mn></msub><mo id="A1.SS2.p5.1.m1.1.1.2" xref="A1.SS2.p5.1.m1.1.1.2.cmml">â¢</mo><mrow id="A1.SS2.p5.1.m1.1.1.1.1" xref="A1.SS2.p5.1.m1.1.1.1.1.1.cmml"><mo id="A1.SS2.p5.1.m1.1.1.1.1.2" xref="A1.SS2.p5.1.m1.1.1.1.1.1.cmml">(</mo><msub id="A1.SS2.p5.1.m1.1.1.1.1.1" xref="A1.SS2.p5.1.m1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p5.1.m1.1.1.1.1.1.2" xref="A1.SS2.p5.1.m1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.SS2.p5.1.m1.1.1.1.1.1.3" xref="A1.SS2.p5.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS2.p5.1.m1.1.1.1.1.3" xref="A1.SS2.p5.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.1.m1.1b"><apply id="A1.SS2.p5.1.m1.1.1.cmml" xref="A1.SS2.p5.1.m1.1.1"><times id="A1.SS2.p5.1.m1.1.1.2.cmml" xref="A1.SS2.p5.1.m1.1.1.2"></times><apply id="A1.SS2.p5.1.m1.1.1.3.cmml" xref="A1.SS2.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.p5.1.m1.1.1.3.1.cmml" xref="A1.SS2.p5.1.m1.1.1.3">subscript</csymbol><ci id="A1.SS2.p5.1.m1.1.1.3.2.cmml" xref="A1.SS2.p5.1.m1.1.1.3.2">ğ‘…</ci><cn id="A1.SS2.p5.1.m1.1.1.3.3.cmml" type="integer" xref="A1.SS2.p5.1.m1.1.1.3.3">1</cn></apply><apply id="A1.SS2.p5.1.m1.1.1.1.1.1.cmml" xref="A1.SS2.p5.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p5.1.m1.1.1.1.1.1.1.cmml" xref="A1.SS2.p5.1.m1.1.1.1.1">subscript</csymbol><ci id="A1.SS2.p5.1.m1.1.1.1.1.1.2a.cmml" xref="A1.SS2.p5.1.m1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p5.1.m1.1.1.1.1.1.2.cmml" xref="A1.SS2.p5.1.m1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.SS2.p5.1.m1.1.1.1.1.1.3.cmml" xref="A1.SS2.p5.1.m1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.1.m1.1c">R_{1}\left(\textbf{h}_{i}\right)</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p5.1.m1.1d">italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> can be ignored since the derivatives of the activation function of second order and higher in the model tend to zero. So the above equation can be reduced to the following form.</p>
</div>
<div class="ltx_para" id="A1.SS2.p6">
<table class="ltx_equation ltx_eqn_table" id="A1.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}\left(\textbf{H},\textbf{h}_{i}\right)\approx\mathcal{L}\left(%
\textbf{H},\textbf{h}_{i}=\textbf{0}\right)+\frac{\partial\mathcal{L}\left(%
\textbf{H},\textbf{h}_{i}\right)}{\partial\textbf{h}_{i}}\textbf{h}_{i}" class="ltx_Math" display="block" id="A1.Ex3.m1.6"><semantics id="A1.Ex3.m1.6a"><mrow id="A1.Ex3.m1.6.6" xref="A1.Ex3.m1.6.6.cmml"><mrow id="A1.Ex3.m1.5.5.1" xref="A1.Ex3.m1.5.5.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex3.m1.5.5.1.3" xref="A1.Ex3.m1.5.5.1.3.cmml">â„’</mi><mo id="A1.Ex3.m1.5.5.1.2" xref="A1.Ex3.m1.5.5.1.2.cmml">â¢</mo><mrow id="A1.Ex3.m1.5.5.1.1.1" xref="A1.Ex3.m1.5.5.1.1.2.cmml"><mo id="A1.Ex3.m1.5.5.1.1.1.2" xref="A1.Ex3.m1.5.5.1.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.3.3" xref="A1.Ex3.m1.3.3a.cmml">H</mtext><mo id="A1.Ex3.m1.5.5.1.1.1.3" xref="A1.Ex3.m1.5.5.1.1.2.cmml">,</mo><msub id="A1.Ex3.m1.5.5.1.1.1.1" xref="A1.Ex3.m1.5.5.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.5.5.1.1.1.1.2" xref="A1.Ex3.m1.5.5.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex3.m1.5.5.1.1.1.1.3" xref="A1.Ex3.m1.5.5.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex3.m1.5.5.1.1.1.4" xref="A1.Ex3.m1.5.5.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.Ex3.m1.6.6.3" xref="A1.Ex3.m1.6.6.3.cmml">â‰ˆ</mo><mrow id="A1.Ex3.m1.6.6.2" xref="A1.Ex3.m1.6.6.2.cmml"><mrow id="A1.Ex3.m1.6.6.2.1" xref="A1.Ex3.m1.6.6.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex3.m1.6.6.2.1.3" xref="A1.Ex3.m1.6.6.2.1.3.cmml">â„’</mi><mo id="A1.Ex3.m1.6.6.2.1.2" xref="A1.Ex3.m1.6.6.2.1.2.cmml">â¢</mo><mrow id="A1.Ex3.m1.6.6.2.1.1.1" xref="A1.Ex3.m1.6.6.2.1.1.1.1.cmml"><mo id="A1.Ex3.m1.6.6.2.1.1.1.2" xref="A1.Ex3.m1.6.6.2.1.1.1.1.cmml">(</mo><mrow id="A1.Ex3.m1.6.6.2.1.1.1.1" xref="A1.Ex3.m1.6.6.2.1.1.1.1.cmml"><mrow id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.4.4" xref="A1.Ex3.m1.4.4a.cmml">H</mtext><mo id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.2" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.2.cmml">,</mo><msub id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.2" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.3" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub></mrow><mo id="A1.Ex3.m1.6.6.2.1.1.1.1.2" xref="A1.Ex3.m1.6.6.2.1.1.1.1.2.cmml">=</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.6.6.2.1.1.1.1.3" xref="A1.Ex3.m1.6.6.2.1.1.1.1.3a.cmml">0</mtext></mrow><mo id="A1.Ex3.m1.6.6.2.1.1.1.3" xref="A1.Ex3.m1.6.6.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex3.m1.6.6.2.2" xref="A1.Ex3.m1.6.6.2.2.cmml">+</mo><mrow id="A1.Ex3.m1.6.6.2.3" xref="A1.Ex3.m1.6.6.2.3.cmml"><mfrac id="A1.Ex3.m1.2.2" xref="A1.Ex3.m1.2.2.cmml"><mrow id="A1.Ex3.m1.2.2.2" xref="A1.Ex3.m1.2.2.2.cmml"><mo id="A1.Ex3.m1.2.2.2.3" rspace="0em" xref="A1.Ex3.m1.2.2.2.3.cmml">âˆ‚</mo><mrow id="A1.Ex3.m1.2.2.2.2" xref="A1.Ex3.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex3.m1.2.2.2.2.3" xref="A1.Ex3.m1.2.2.2.2.3.cmml">â„’</mi><mo id="A1.Ex3.m1.2.2.2.2.2" xref="A1.Ex3.m1.2.2.2.2.2.cmml">â¢</mo><mrow id="A1.Ex3.m1.2.2.2.2.1.1" xref="A1.Ex3.m1.2.2.2.2.1.2.cmml"><mo id="A1.Ex3.m1.2.2.2.2.1.1.2" xref="A1.Ex3.m1.2.2.2.2.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.1.1.1.1" xref="A1.Ex3.m1.1.1.1.1a.cmml">H</mtext><mo id="A1.Ex3.m1.2.2.2.2.1.1.3" xref="A1.Ex3.m1.2.2.2.2.1.2.cmml">,</mo><msub id="A1.Ex3.m1.2.2.2.2.1.1.1" xref="A1.Ex3.m1.2.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.2.2.2.2.1.1.1.2" xref="A1.Ex3.m1.2.2.2.2.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex3.m1.2.2.2.2.1.1.1.3" xref="A1.Ex3.m1.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex3.m1.2.2.2.2.1.1.4" xref="A1.Ex3.m1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><mrow id="A1.Ex3.m1.2.2.4" xref="A1.Ex3.m1.2.2.4.cmml"><mo id="A1.Ex3.m1.2.2.4.1" rspace="0em" xref="A1.Ex3.m1.2.2.4.1.cmml">âˆ‚</mo><msub id="A1.Ex3.m1.2.2.4.2" xref="A1.Ex3.m1.2.2.4.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.2.2.4.2.2" xref="A1.Ex3.m1.2.2.4.2.2a.cmml">h</mtext><mi id="A1.Ex3.m1.2.2.4.2.3" xref="A1.Ex3.m1.2.2.4.2.3.cmml">i</mi></msub></mrow></mfrac><mo id="A1.Ex3.m1.6.6.2.3.1" xref="A1.Ex3.m1.6.6.2.3.1.cmml">â¢</mo><msub id="A1.Ex3.m1.6.6.2.3.2" xref="A1.Ex3.m1.6.6.2.3.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.6.6.2.3.2.2" xref="A1.Ex3.m1.6.6.2.3.2.2a.cmml">h</mtext><mi id="A1.Ex3.m1.6.6.2.3.2.3" xref="A1.Ex3.m1.6.6.2.3.2.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex3.m1.6b"><apply id="A1.Ex3.m1.6.6.cmml" xref="A1.Ex3.m1.6.6"><approx id="A1.Ex3.m1.6.6.3.cmml" xref="A1.Ex3.m1.6.6.3"></approx><apply id="A1.Ex3.m1.5.5.1.cmml" xref="A1.Ex3.m1.5.5.1"><times id="A1.Ex3.m1.5.5.1.2.cmml" xref="A1.Ex3.m1.5.5.1.2"></times><ci id="A1.Ex3.m1.5.5.1.3.cmml" xref="A1.Ex3.m1.5.5.1.3">â„’</ci><interval closure="open" id="A1.Ex3.m1.5.5.1.1.2.cmml" xref="A1.Ex3.m1.5.5.1.1.1"><ci id="A1.Ex3.m1.3.3a.cmml" xref="A1.Ex3.m1.3.3"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.3.3.cmml" xref="A1.Ex3.m1.3.3">H</mtext></ci><apply id="A1.Ex3.m1.5.5.1.1.1.1.cmml" xref="A1.Ex3.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex3.m1.5.5.1.1.1.1.1.cmml" xref="A1.Ex3.m1.5.5.1.1.1.1">subscript</csymbol><ci id="A1.Ex3.m1.5.5.1.1.1.1.2a.cmml" xref="A1.Ex3.m1.5.5.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.5.5.1.1.1.1.2.cmml" xref="A1.Ex3.m1.5.5.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex3.m1.5.5.1.1.1.1.3.cmml" xref="A1.Ex3.m1.5.5.1.1.1.1.3">ğ‘–</ci></apply></interval></apply><apply id="A1.Ex3.m1.6.6.2.cmml" xref="A1.Ex3.m1.6.6.2"><plus id="A1.Ex3.m1.6.6.2.2.cmml" xref="A1.Ex3.m1.6.6.2.2"></plus><apply id="A1.Ex3.m1.6.6.2.1.cmml" xref="A1.Ex3.m1.6.6.2.1"><times id="A1.Ex3.m1.6.6.2.1.2.cmml" xref="A1.Ex3.m1.6.6.2.1.2"></times><ci id="A1.Ex3.m1.6.6.2.1.3.cmml" xref="A1.Ex3.m1.6.6.2.1.3">â„’</ci><apply id="A1.Ex3.m1.6.6.2.1.1.1.1.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1"><eq id="A1.Ex3.m1.6.6.2.1.1.1.1.2.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.2"></eq><list id="A1.Ex3.m1.6.6.2.1.1.1.1.1.2.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1"><ci id="A1.Ex3.m1.4.4a.cmml" xref="A1.Ex3.m1.4.4"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.4.4.cmml" xref="A1.Ex3.m1.4.4">H</mtext></ci><apply id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.1.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.2a.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.2.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.3.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></list><ci id="A1.Ex3.m1.6.6.2.1.1.1.1.3a.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.6.6.2.1.1.1.1.3.cmml" xref="A1.Ex3.m1.6.6.2.1.1.1.1.3">0</mtext></ci></apply></apply><apply id="A1.Ex3.m1.6.6.2.3.cmml" xref="A1.Ex3.m1.6.6.2.3"><times id="A1.Ex3.m1.6.6.2.3.1.cmml" xref="A1.Ex3.m1.6.6.2.3.1"></times><apply id="A1.Ex3.m1.2.2.cmml" xref="A1.Ex3.m1.2.2"><divide id="A1.Ex3.m1.2.2.3.cmml" xref="A1.Ex3.m1.2.2"></divide><apply id="A1.Ex3.m1.2.2.2.cmml" xref="A1.Ex3.m1.2.2.2"><partialdiff id="A1.Ex3.m1.2.2.2.3.cmml" xref="A1.Ex3.m1.2.2.2.3"></partialdiff><apply id="A1.Ex3.m1.2.2.2.2.cmml" xref="A1.Ex3.m1.2.2.2.2"><times id="A1.Ex3.m1.2.2.2.2.2.cmml" xref="A1.Ex3.m1.2.2.2.2.2"></times><ci id="A1.Ex3.m1.2.2.2.2.3.cmml" xref="A1.Ex3.m1.2.2.2.2.3">â„’</ci><interval closure="open" id="A1.Ex3.m1.2.2.2.2.1.2.cmml" xref="A1.Ex3.m1.2.2.2.2.1.1"><ci id="A1.Ex3.m1.1.1.1.1a.cmml" xref="A1.Ex3.m1.1.1.1.1"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.1.1.1.1.cmml" xref="A1.Ex3.m1.1.1.1.1">H</mtext></ci><apply id="A1.Ex3.m1.2.2.2.2.1.1.1.cmml" xref="A1.Ex3.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="A1.Ex3.m1.2.2.2.2.1.1.1.1.cmml" xref="A1.Ex3.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="A1.Ex3.m1.2.2.2.2.1.1.1.2a.cmml" xref="A1.Ex3.m1.2.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.2.2.2.2.1.1.1.2.cmml" xref="A1.Ex3.m1.2.2.2.2.1.1.1.2">h</mtext></ci><ci id="A1.Ex3.m1.2.2.2.2.1.1.1.3.cmml" xref="A1.Ex3.m1.2.2.2.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply><apply id="A1.Ex3.m1.2.2.4.cmml" xref="A1.Ex3.m1.2.2.4"><partialdiff id="A1.Ex3.m1.2.2.4.1.cmml" xref="A1.Ex3.m1.2.2.4.1"></partialdiff><apply id="A1.Ex3.m1.2.2.4.2.cmml" xref="A1.Ex3.m1.2.2.4.2"><csymbol cd="ambiguous" id="A1.Ex3.m1.2.2.4.2.1.cmml" xref="A1.Ex3.m1.2.2.4.2">subscript</csymbol><ci id="A1.Ex3.m1.2.2.4.2.2a.cmml" xref="A1.Ex3.m1.2.2.4.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.2.2.4.2.2.cmml" xref="A1.Ex3.m1.2.2.4.2.2">h</mtext></ci><ci id="A1.Ex3.m1.2.2.4.2.3.cmml" xref="A1.Ex3.m1.2.2.4.2.3">ğ‘–</ci></apply></apply></apply><apply id="A1.Ex3.m1.6.6.2.3.2.cmml" xref="A1.Ex3.m1.6.6.2.3.2"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.2.3.2.1.cmml" xref="A1.Ex3.m1.6.6.2.3.2">subscript</csymbol><ci id="A1.Ex3.m1.6.6.2.3.2.2a.cmml" xref="A1.Ex3.m1.6.6.2.3.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex3.m1.6.6.2.3.2.2.cmml" xref="A1.Ex3.m1.6.6.2.3.2.2">h</mtext></ci><ci id="A1.Ex3.m1.6.6.2.3.2.3.cmml" xref="A1.Ex3.m1.6.6.2.3.2.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex3.m1.6c">\mathcal{L}\left(\textbf{H},\textbf{h}_{i}\right)\approx\mathcal{L}\left(%
\textbf{H},\textbf{h}_{i}=\textbf{0}\right)+\frac{\partial\mathcal{L}\left(%
\textbf{H},\textbf{h}_{i}\right)}{\partial\textbf{h}_{i}}\textbf{h}_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex3.m1.6d">caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) â‰ˆ caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 ) + divide start_ARG âˆ‚ caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG âˆ‚ h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A1.SS2.p7">
<p class="ltx_p" id="A1.SS2.p7.1">Therefore <math alttext="|\Delta\mathcal{L}(\textbf{h}_{i})|" class="ltx_Math" display="inline" id="A1.SS2.p7.1.m1.1"><semantics id="A1.SS2.p7.1.m1.1a"><mrow id="A1.SS2.p7.1.m1.1.1.1" xref="A1.SS2.p7.1.m1.1.1.2.cmml"><mo id="A1.SS2.p7.1.m1.1.1.1.2" stretchy="false" xref="A1.SS2.p7.1.m1.1.1.2.1.cmml">|</mo><mrow id="A1.SS2.p7.1.m1.1.1.1.1" xref="A1.SS2.p7.1.m1.1.1.1.1.cmml"><mi id="A1.SS2.p7.1.m1.1.1.1.1.3" mathvariant="normal" xref="A1.SS2.p7.1.m1.1.1.1.1.3.cmml">Î”</mi><mo id="A1.SS2.p7.1.m1.1.1.1.1.2" xref="A1.SS2.p7.1.m1.1.1.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="A1.SS2.p7.1.m1.1.1.1.1.4" xref="A1.SS2.p7.1.m1.1.1.1.1.4.cmml">â„’</mi><mo id="A1.SS2.p7.1.m1.1.1.1.1.2a" xref="A1.SS2.p7.1.m1.1.1.1.1.2.cmml">â¢</mo><mrow id="A1.SS2.p7.1.m1.1.1.1.1.1.1" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.cmml"><mo id="A1.SS2.p7.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.2" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.3" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS2.p7.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS2.p7.1.m1.1.1.1.3" stretchy="false" xref="A1.SS2.p7.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p7.1.m1.1b"><apply id="A1.SS2.p7.1.m1.1.1.2.cmml" xref="A1.SS2.p7.1.m1.1.1.1"><abs id="A1.SS2.p7.1.m1.1.1.2.1.cmml" xref="A1.SS2.p7.1.m1.1.1.1.2"></abs><apply id="A1.SS2.p7.1.m1.1.1.1.1.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1"><times id="A1.SS2.p7.1.m1.1.1.1.1.2.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.2"></times><ci id="A1.SS2.p7.1.m1.1.1.1.1.3.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.3">Î”</ci><ci id="A1.SS2.p7.1.m1.1.1.1.1.4.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.4">â„’</ci><apply id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.1.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.2a.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.2.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.3.cmml" xref="A1.SS2.p7.1.m1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p7.1.m1.1c">|\Delta\mathcal{L}(\textbf{h}_{i})|</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p7.1.m1.1d">| roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) |</annotation></semantics></math> can eventually be simplified to the following form.</p>
</div>
<div class="ltx_para" id="A1.SS2.p8">
<table class="ltx_equation ltx_eqn_table" id="A1.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\left|\Delta\mathcal{L}\left(\textbf{h}_{i}\right)\right|\approx\left|\frac{%
\partial\mathcal{L}\left(\textbf{H},\textbf{h}_{i}\right)}{\partial\textbf{h}_%
{i}}\textbf{h}_{i}\right|" class="ltx_Math" display="block" id="A1.Ex4.m1.4"><semantics id="A1.Ex4.m1.4a"><mrow id="A1.Ex4.m1.4.4" xref="A1.Ex4.m1.4.4.cmml"><mrow id="A1.Ex4.m1.3.3.1.1" xref="A1.Ex4.m1.3.3.1.2.cmml"><mo id="A1.Ex4.m1.3.3.1.1.2" xref="A1.Ex4.m1.3.3.1.2.1.cmml">|</mo><mrow id="A1.Ex4.m1.3.3.1.1.1" xref="A1.Ex4.m1.3.3.1.1.1.cmml"><mi id="A1.Ex4.m1.3.3.1.1.1.3" mathvariant="normal" xref="A1.Ex4.m1.3.3.1.1.1.3.cmml">Î”</mi><mo id="A1.Ex4.m1.3.3.1.1.1.2" xref="A1.Ex4.m1.3.3.1.1.1.2.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="A1.Ex4.m1.3.3.1.1.1.4" xref="A1.Ex4.m1.3.3.1.1.1.4.cmml">â„’</mi><mo id="A1.Ex4.m1.3.3.1.1.1.2a" xref="A1.Ex4.m1.3.3.1.1.1.2.cmml">â¢</mo><mrow id="A1.Ex4.m1.3.3.1.1.1.1.1" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.cmml"><mo id="A1.Ex4.m1.3.3.1.1.1.1.1.2" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.cmml">(</mo><msub id="A1.Ex4.m1.3.3.1.1.1.1.1.1" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.3.3.1.1.1.1.1.1.2" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex4.m1.3.3.1.1.1.1.1.1.3" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex4.m1.3.3.1.1.1.1.1.3" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex4.m1.3.3.1.1.3" xref="A1.Ex4.m1.3.3.1.2.1.cmml">|</mo></mrow><mo id="A1.Ex4.m1.4.4.3" xref="A1.Ex4.m1.4.4.3.cmml">â‰ˆ</mo><mrow id="A1.Ex4.m1.4.4.2.1" xref="A1.Ex4.m1.4.4.2.2.cmml"><mo id="A1.Ex4.m1.4.4.2.1.2" xref="A1.Ex4.m1.4.4.2.2.1.cmml">|</mo><mrow id="A1.Ex4.m1.4.4.2.1.1" xref="A1.Ex4.m1.4.4.2.1.1.cmml"><mfrac id="A1.Ex4.m1.2.2" xref="A1.Ex4.m1.2.2.cmml"><mrow id="A1.Ex4.m1.2.2.2" xref="A1.Ex4.m1.2.2.2.cmml"><mo id="A1.Ex4.m1.2.2.2.3" rspace="0em" xref="A1.Ex4.m1.2.2.2.3.cmml">âˆ‚</mo><mrow id="A1.Ex4.m1.2.2.2.2" xref="A1.Ex4.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex4.m1.2.2.2.2.3" xref="A1.Ex4.m1.2.2.2.2.3.cmml">â„’</mi><mo id="A1.Ex4.m1.2.2.2.2.2" xref="A1.Ex4.m1.2.2.2.2.2.cmml">â¢</mo><mrow id="A1.Ex4.m1.2.2.2.2.1.1" xref="A1.Ex4.m1.2.2.2.2.1.2.cmml"><mo id="A1.Ex4.m1.2.2.2.2.1.1.2" xref="A1.Ex4.m1.2.2.2.2.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.1.1.1.1" xref="A1.Ex4.m1.1.1.1.1a.cmml">H</mtext><mo id="A1.Ex4.m1.2.2.2.2.1.1.3" xref="A1.Ex4.m1.2.2.2.2.1.2.cmml">,</mo><msub id="A1.Ex4.m1.2.2.2.2.1.1.1" xref="A1.Ex4.m1.2.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.2.2.2.2.1.1.1.2" xref="A1.Ex4.m1.2.2.2.2.1.1.1.2a.cmml">h</mtext><mi id="A1.Ex4.m1.2.2.2.2.1.1.1.3" xref="A1.Ex4.m1.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex4.m1.2.2.2.2.1.1.4" xref="A1.Ex4.m1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><mrow id="A1.Ex4.m1.2.2.4" xref="A1.Ex4.m1.2.2.4.cmml"><mo id="A1.Ex4.m1.2.2.4.1" rspace="0em" xref="A1.Ex4.m1.2.2.4.1.cmml">âˆ‚</mo><msub id="A1.Ex4.m1.2.2.4.2" xref="A1.Ex4.m1.2.2.4.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.2.2.4.2.2" xref="A1.Ex4.m1.2.2.4.2.2a.cmml">h</mtext><mi id="A1.Ex4.m1.2.2.4.2.3" xref="A1.Ex4.m1.2.2.4.2.3.cmml">i</mi></msub></mrow></mfrac><mo id="A1.Ex4.m1.4.4.2.1.1.1" xref="A1.Ex4.m1.4.4.2.1.1.1.cmml">â¢</mo><msub id="A1.Ex4.m1.4.4.2.1.1.2" xref="A1.Ex4.m1.4.4.2.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.4.4.2.1.1.2.2" xref="A1.Ex4.m1.4.4.2.1.1.2.2a.cmml">h</mtext><mi id="A1.Ex4.m1.4.4.2.1.1.2.3" xref="A1.Ex4.m1.4.4.2.1.1.2.3.cmml">i</mi></msub></mrow><mo id="A1.Ex4.m1.4.4.2.1.3" xref="A1.Ex4.m1.4.4.2.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex4.m1.4b"><apply id="A1.Ex4.m1.4.4.cmml" xref="A1.Ex4.m1.4.4"><approx id="A1.Ex4.m1.4.4.3.cmml" xref="A1.Ex4.m1.4.4.3"></approx><apply id="A1.Ex4.m1.3.3.1.2.cmml" xref="A1.Ex4.m1.3.3.1.1"><abs id="A1.Ex4.m1.3.3.1.2.1.cmml" xref="A1.Ex4.m1.3.3.1.1.2"></abs><apply id="A1.Ex4.m1.3.3.1.1.1.cmml" xref="A1.Ex4.m1.3.3.1.1.1"><times id="A1.Ex4.m1.3.3.1.1.1.2.cmml" xref="A1.Ex4.m1.3.3.1.1.1.2"></times><ci id="A1.Ex4.m1.3.3.1.1.1.3.cmml" xref="A1.Ex4.m1.3.3.1.1.1.3">Î”</ci><ci id="A1.Ex4.m1.3.3.1.1.1.4.cmml" xref="A1.Ex4.m1.3.3.1.1.1.4">â„’</ci><apply id="A1.Ex4.m1.3.3.1.1.1.1.1.1.cmml" xref="A1.Ex4.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="A1.Ex4.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="A1.Ex4.m1.3.3.1.1.1.1.1.1.2a.cmml" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.2">h</mtext></ci><ci id="A1.Ex4.m1.3.3.1.1.1.1.1.1.3.cmml" xref="A1.Ex4.m1.3.3.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><apply id="A1.Ex4.m1.4.4.2.2.cmml" xref="A1.Ex4.m1.4.4.2.1"><abs id="A1.Ex4.m1.4.4.2.2.1.cmml" xref="A1.Ex4.m1.4.4.2.1.2"></abs><apply id="A1.Ex4.m1.4.4.2.1.1.cmml" xref="A1.Ex4.m1.4.4.2.1.1"><times id="A1.Ex4.m1.4.4.2.1.1.1.cmml" xref="A1.Ex4.m1.4.4.2.1.1.1"></times><apply id="A1.Ex4.m1.2.2.cmml" xref="A1.Ex4.m1.2.2"><divide id="A1.Ex4.m1.2.2.3.cmml" xref="A1.Ex4.m1.2.2"></divide><apply id="A1.Ex4.m1.2.2.2.cmml" xref="A1.Ex4.m1.2.2.2"><partialdiff id="A1.Ex4.m1.2.2.2.3.cmml" xref="A1.Ex4.m1.2.2.2.3"></partialdiff><apply id="A1.Ex4.m1.2.2.2.2.cmml" xref="A1.Ex4.m1.2.2.2.2"><times id="A1.Ex4.m1.2.2.2.2.2.cmml" xref="A1.Ex4.m1.2.2.2.2.2"></times><ci id="A1.Ex4.m1.2.2.2.2.3.cmml" xref="A1.Ex4.m1.2.2.2.2.3">â„’</ci><interval closure="open" id="A1.Ex4.m1.2.2.2.2.1.2.cmml" xref="A1.Ex4.m1.2.2.2.2.1.1"><ci id="A1.Ex4.m1.1.1.1.1a.cmml" xref="A1.Ex4.m1.1.1.1.1"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.1.1.1.1.cmml" xref="A1.Ex4.m1.1.1.1.1">H</mtext></ci><apply id="A1.Ex4.m1.2.2.2.2.1.1.1.cmml" xref="A1.Ex4.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="A1.Ex4.m1.2.2.2.2.1.1.1.1.cmml" xref="A1.Ex4.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="A1.Ex4.m1.2.2.2.2.1.1.1.2a.cmml" xref="A1.Ex4.m1.2.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.2.2.2.2.1.1.1.2.cmml" xref="A1.Ex4.m1.2.2.2.2.1.1.1.2">h</mtext></ci><ci id="A1.Ex4.m1.2.2.2.2.1.1.1.3.cmml" xref="A1.Ex4.m1.2.2.2.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply><apply id="A1.Ex4.m1.2.2.4.cmml" xref="A1.Ex4.m1.2.2.4"><partialdiff id="A1.Ex4.m1.2.2.4.1.cmml" xref="A1.Ex4.m1.2.2.4.1"></partialdiff><apply id="A1.Ex4.m1.2.2.4.2.cmml" xref="A1.Ex4.m1.2.2.4.2"><csymbol cd="ambiguous" id="A1.Ex4.m1.2.2.4.2.1.cmml" xref="A1.Ex4.m1.2.2.4.2">subscript</csymbol><ci id="A1.Ex4.m1.2.2.4.2.2a.cmml" xref="A1.Ex4.m1.2.2.4.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.2.2.4.2.2.cmml" xref="A1.Ex4.m1.2.2.4.2.2">h</mtext></ci><ci id="A1.Ex4.m1.2.2.4.2.3.cmml" xref="A1.Ex4.m1.2.2.4.2.3">ğ‘–</ci></apply></apply></apply><apply id="A1.Ex4.m1.4.4.2.1.1.2.cmml" xref="A1.Ex4.m1.4.4.2.1.1.2"><csymbol cd="ambiguous" id="A1.Ex4.m1.4.4.2.1.1.2.1.cmml" xref="A1.Ex4.m1.4.4.2.1.1.2">subscript</csymbol><ci id="A1.Ex4.m1.4.4.2.1.1.2.2a.cmml" xref="A1.Ex4.m1.4.4.2.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="A1.Ex4.m1.4.4.2.1.1.2.2.cmml" xref="A1.Ex4.m1.4.4.2.1.1.2.2">h</mtext></ci><ci id="A1.Ex4.m1.4.4.2.1.1.2.3.cmml" xref="A1.Ex4.m1.4.4.2.1.1.2.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex4.m1.4c">\left|\Delta\mathcal{L}\left(\textbf{h}_{i}\right)\right|\approx\left|\frac{%
\partial\mathcal{L}\left(\textbf{H},\textbf{h}_{i}\right)}{\partial\textbf{h}_%
{i}}\textbf{h}_{i}\right|</annotation><annotation encoding="application/x-llamapun" id="A1.Ex4.m1.4d">| roman_Î” caligraphic_L ( h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) | â‰ˆ | divide start_ARG âˆ‚ caligraphic_L ( H , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG âˆ‚ h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 26 09:19:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
